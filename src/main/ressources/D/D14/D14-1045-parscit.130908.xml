<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007460">
<title confidence="0.9987365">
Composition of Word Representations
Improves Semantic Role Labelling
</title>
<author confidence="0.990217">
Michael Roth and Kristian Woodsend
</author>
<affiliation confidence="0.999329">
Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
</affiliation>
<email confidence="0.997298">
{mroth,kwoodsen}@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.997371" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999910833333333">
State-of-the-art semantic role labelling
systems require large annotated corpora to
achieve full performance. Unfortunately,
such corpora are expensive to produce and
often do not generalize well across do-
mains. Even in domain, errors are often
made where syntactic information does
not provide sufficient cues. In this pa-
per, we mitigate both of these problems
by employing distributional word repre-
sentations gathered from unlabelled data.
While straight-forward word representa-
tions of predicates and arguments improve
performance, we show that further gains
are achieved by composing representa-
tions that model the interaction between
predicate and argument, and capture full
argument spans.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971132075472">
The goal of semantic role labelling (SRL) is to
discover the relations that hold between a pred-
icate and its arguments in a given input sen-
tence (e.g., “who” did “what” to “whom”, “when”,
“where”, and “how”). This semantic knowl-
edge at the predicate-argument level is required
by inference-based NLP tasks in order to iden-
tify meaning-preserving transformations, such as
active/passive, verb alternations and nominaliza-
tions. Several manually-build semantic resources,
including FrameNet (Ruppenhofer et al., 2010)
and PropBank (Palmer et al., 2005), have been
developed with the goal of documenting and pro-
viding examples of such transformations and how
they preserve semantic role information. Given
that labelled corpora are inevitably restricted in
size and coverage, and that syntactic cues are not
by themselves unambiguous or sufficient, the suc-
cess of systems that automatically provide corre-
sponding analyses has been limited in practice.
Recent work on SRL has explored approaches
that can leverage unlabelled data, following a
semi-supervised (F¨urstenau and Lapata, 2012;
Titov and Klementiev, 2012) or unsupervised
learning paradigm (Abend et al., 2009; Titov and
Klementiev, 2011). Unlabelled data provides ad-
ditional statistical strength and can lead to more
consistent models. For instance, latent representa-
tions of words can be computed, based on distri-
butional similarity or language modelling, which
can be used as additional features during tradi-
tional supervised learning. Although we would
expect that extra features would improve classifier
performance, this seems in part counter-intuitive.
Just because one word has a specific representa-
tion does not mean that it should be assigned a
specific argument label. Instead, one would ex-
pect a more complex interplay between predicate,
argument and the context they appear in.
In this paper, we investigate the impact of dis-
tributional word representations for SRL. Initially,
we augment the feature space with word repre-
sentations for a predicate and its argument head.
Furthermore, we use a compositional approach to
model a representation of the full argument, by
composing a joint representation of all words in
the argument span, and we also investigate the in-
teraction between predicate and argument, using
a compositional representation of the dependency
path. We demonstrate the benefits of these com-
positional features using a state-of-the-art seman-
tic role labeller, which we evaluate on the English
part of the CoNLL-2009 data set.
</bodyText>
<sectionHeader confidence="0.999952" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998812">
Research into using distributional information
in SRL dates back to Gildea and Jurafsky
(2002), who used distributions over verb-object
co-occurrence clusters to improve coverage in ar-
gument classification. The distribution of a word
over these soft clusters assignments was added as
</bodyText>
<page confidence="0.966939">
407
</page>
<bodyText confidence="0.980151641509434">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 407–413,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
features to their classifier. The SRL system by
Croce et al. (2010) combines argument clustering
based on co-occurrence frequencies with a lan-
guage model. Collobert et al. (2011) used dis-
tributional word representations in a neural net-
work model that can update representations dur-
ing training. Zapirain et al. (2013) suggested dis-
tributional information as a basis for a selectional
preference model that can be used as a single addi-
tional feature for classifying potential arguments.
Most recently, Hermann et al. (2014) used distri-
butional word representations within pre-defined
syntactic contexts as input to a classifier which
learns to distinguish different predicate senses.
A complementary line of research explores the
representation of sequence information. Promi-
nent examples are the works by Deschacht and
Moens (2009) and Huang and Yates (2010) who
learned and applied Hidden Markov Models to
assign state variables to words and word spans,
which serve as supplementary features for classifi-
cation. One drawback of this approach is that state
variables are discrete and the number of states
(i.e., their granularity) has to be chosen in advance.
The popularity of distributional methods for
word representation has been a motivation for de-
veloping representations of larger constructions
such as phrases and sentences, and there have
been several proposals for computing the meaning
of word combinations in vector spaces. Mitchell
and Lapata (2010) introduced a general frame-
work where composition is formulated as a func-
tion f of two vectors u and v. Depending on
how f is chosen, different composition models
arise, the simplest being an additive model where
f(u, v) = u + v. To capture relational functions,
Baroni and Zamparelli (2010) expanded on this
approach by representing verbs, adjectives and ad-
verbs by matrices which can modify the properties
of nouns (represented by vectors). Socher et al.
(2012) combined word representations with syn-
tactic structure information, through a recursive
neural network that learns vector space represen-
tations for multi-word phrases and sentences. An
empirical comparison of these composition meth-
ods was provided in (Blacoe and Lapata, 2012).
In this work, we use type-based continuous rep-
resentations of words to compose representations
of multiple word sequences and spans, which can
then be incorporated directly as features into SRL
systems.
</bodyText>
<figure confidence="0.926646833333333">
Distributional Feature Computation
Argument a a�
Predicate p p�
Predicate-argument Interaction a� + p�
Argument Span w1 ... w,,, Ez wz
Dependency Path from a to p Ew∈path(a,p) w�
</figure>
<tableCaption confidence="0.976226333333333">
Table 1: Features based on distributional word
representations and additive composition. Vector
w� denotes the representation of word w.
</tableCaption>
<sectionHeader confidence="0.97751" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999982868421053">
Following the set-up of the CoNLL shared task
in 2009, we consider predicate-argument struc-
tures that consist of a verbal or nominal pred-
icate p and PropBank-labelled arguments az E
ja1 ... a,,,}, where each az corresponds to the head
word of the phrase that constitutes the respective
argument. Traditional semantic role labelling ap-
proaches compute a set of applicable features on
each pair (p, az), such as the observed lemma type
of a word and the grammatical relation to its head,
that serve as indicators for a particular role label.
The disadvantage of this approach lies in the
fact that indicator features such as word and
lemma type are often sparse in training data and
hence do not generalize well across domains. In
contrast, features based on distributional represen-
tations (e.g., raw co-occurrence frequencies) can
be computed for every word, given that it occurs
in some unlabelled corpus. In addition to this ob-
vious advantage for out-of-domain settings, dis-
tributional representations can provide a more ro-
bust input signal to the classifier, for instance by
projecting a matrix of co-occurrence frequencies
to a lower-dimensional space. We hence hypoth-
esize that such features enable the model to be-
come more robust out-of-domain, while providing
higher precision in-domain.
Although simply including the components of
a word representation as features to a classifier
can lead to immediate improvements in SRL per-
formance, this observation seems in part counter-
intuitive. Just because one word has a specific
representation does not mean that it should be as-
signed a specific argument label. In fact, one
would expect a more complex interplay between
the representation of an argument az and the con-
text it appears in. To model aspects of this inter-
play, we define an extended set of features that
</bodyText>
<page confidence="0.994078">
408
</page>
<bodyText confidence="0.9999822">
further includes representations for the combina-
tion of p and ai, the set of words in the depen-
dency path between p and ai, and the set of words
in the full span of az. We compute additive com-
positional representations of multiple words, us-
ing the simplest method of Mitchell and Lapata
(2010) where the composed representation is the
uniformly weighted sum of each single represen-
tation. Our full set of feature types based on distri-
butional word representations is listed in Table 1.
</bodyText>
<sectionHeader confidence="0.99737" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999947941176471">
We evaluate the impact of different types of fea-
tures by performing experiments on a benchmark
dataset for semantic role labelling. To assess the
gains of distributional representations realistically,
we incorporate the features described in Section 3
into a state-of-the-art SRL system. The follow-
ing paragraphs summarize the details of our ex-
perimental setup.
Semantic Role Labeller. In all our experi-
ments, we use the publicly available system by
Bj¨orkelund et al. (2010).1 This system com-
bines the first-ranked SRL system and the first-
ranked syntactic parser in the CoNLL 2009 shared
task for English (Bj¨orkelund et al., 2009; Bohnet,
2010). To the best of our knowledge, this
combination represents the current state-of-the-art
for semantic role labelling following the Prop-
Bank/NomBank paradigm (Palmer et al., 2005;
Meyers et al., 2004). To re-train and evaluate mod-
els with different feature sets, we use the same
training, development and test sets as provided
in the CoNLL shared task (Hajiˇc et al., 2009).
Although the employed system features a full
syntactic-semantic parsing pipeline, we only mod-
ify the feature sets of the two components directly
related to the actual role labelling task, namely ar-
gument identification and argument classification.
Word Representations. As a baseline, we sim-
ply added as features the word representations of
the predicate and argument head involved in a
classification decision (first two lines in Table 1).
We experimented with a range of publicly avail-
able sets of word representations, including em-
beddings from various neural language models
</bodyText>
<footnote confidence="0.9999644">
1http://code.google.com/p/mate-tools/
2http://metaoptimize.com/projects/wordreprs/
3http://ai.stanford.edu/%7eehhuang/
4http://lebret.ch/words/
5http://www.cis.upenn.edu/%7eungar/eigenwords/
</footnote>
<table confidence="0.99979975">
Development dims P R F1
None – 86.1 81.0 83.5
Brown clusters2 320 86.2 81.3 83.7
Neural LM2 50 86.2 81.4 83.7
Neural LM+Global3 50 86.2 81.4 83.7
HLBL2 50 86.3 81.3 83.7
H-PCA4 50 86.2 81.3 83.7
Eigenwords5 50 86.2 81.3 83.6
</table>
<tableCaption confidence="0.7253575">
Table 2: Results on the CoNLL-2009 develop-
ment set, using off-the-shelf word representations
for predicates and argument as additional features.
Performance numbers in percent.
</tableCaption>
<bodyText confidence="0.998868866666667">
(Mnih and Hinton, 2009; Collobert et al., 2011;
Huang et al., 2012), eigenvectors (Dhillon et al.,
2011), Brown clusters (Brown et al., 1992), and
post-processed co-occurrence counts (Lebret and
Collobert, 2014). Results on the development set
for various off-the-shelf representations are shown
in Table 2. The numbers reveal that any kind of
word representation can be employed to improve
results. We choose to perform all follow-up exper-
iments using the 50-dimensional embeddings in-
duced by Turian et al. (2010), using the method by
Collobert et al., as they led to slightly better results
in F1-score than other representations. No signif-
icant differences were observed, however, using
other types of representations or vector sizes.
</bodyText>
<sectionHeader confidence="0.999972" genericHeader="method">
5 Results
</sectionHeader>
<bodyText confidence="0.999993684210526">
We evaluate our proposed set of additional fea-
tures on the CoNLL-2009 in-domain and out-of-
domain test sets, using the aforementioned SRL
system and word representations. All results are
computed using the system’s built-in preprocess-
ing pipeline and re-trained models for argument
identification and classification. We report la-
belled precision, recall and semantic F1-score as
computed by the official scorer.
The upper part of Table 3 shows SRL perfor-
mance on the in-domain CoNLL-2009 test set,
with and without (Original) additional features
based on distributional representations. The re-
sults reveal that any type of additional feature
helps to improve precision and recall in this setting
(from 85.2% F1-score up to 85.5%), with signifi-
cant gains for 4 of the 5 additional features (com-
puted using a randomization test; cf. Yeh, 2000).
Interestingly, we find that the features do not seem
</bodyText>
<page confidence="0.99192">
409
</page>
<table confidence="0.999979875">
In-domain P R F1
Original 87.4 83.1 85.2
Original + Argument 87.6 83.3 85.4**
Original + Predicate 87.4 83.2 85.2
Original + Interaction 87.5 83.3 85.3**
Original + Span 87.6 83.5 85.5**
Original + Path 87.5 83.4 85.4**
Original + All 87.6 83.4 85.5**
Out-of-domain P R F1
Original 76.9 71.7 74.2
Original + Argument 77.4 71.9 74.5
Original + Predicate 77.3 72.2 74.7*
Original + Interaction 77.2 72.0 74.5
Original + Span 77.3 72.3 74.7*
Original + Path 77.2 72.3 74.7*
Original + All 77.5 73.0 75.2**
</table>
<tableCaption confidence="0.850853">
Table 3: Results on both CoNLL-2009 test sets.
All numbers in percent. Significant differences
from Original in terms of F1-score are marked by
asterisks (* p&lt;0.05, ** p&lt;0.01).
</tableCaption>
<bodyText confidence="0.999928307692308">
to have a cumulative effect here, as indicated by
the results with all features (+All, 85.5% F1). We
conjecture that this is due to the high volume of
existing in-domain training data, which renders
our full feature set redundant. To test this conjec-
ture, we further assess performance on the out-of-
domain test set of the CoNLL-2009 shared task.
The results for the out-of-domain experiment
are summarized in the lower part of Table 3.
We again observe that each single feature type
improves classification, with absolute gains be-
ing slightly higher than in the in-domain setting.
More interestingly though, we find that the com-
plete feature set boosts performance even further,
achieving an overall gain in precision and recall
of 0.6 and 1.3 percentage points, respectively. The
resulting F1-score of 75.2 lies even higher than the
top score for this particular data set reported in the
CoNLL shared task (Zhao et al., 2009; 74.6 F1).
We next investigate the benefits of compo-
sitional representations over features for single
words by assessing their impact on the overall re-
sult in an ablation study. Table 4 shows results
of ablation tests performed for the three composi-
tional feature types Interaction, Span and Path
on the out-of-domain test set. The results reveal
</bodyText>
<table confidence="0.999873">
Out-of-domain P R F1
Original 76.9 71.7 74.2
Full (Original+All) 77.5 73.0 75.2
Full −Interaction 77.2 72.5 74.8
Full −Span 77.2 72.3 74.7
Full −Path 77.6 72.3 74.8
</table>
<tableCaption confidence="0.998057">
Table 4: Results of an ablation study over features
</tableCaption>
<bodyText confidence="0.814655888888889">
based on compositional representations. All num-
bers in percent.
a considerable loss in recall, indicating the impor-
tance of including compositional word represen-
tations and confirming our intuition that they can
provide additional gains over simple type-level
representations. In the next section, we discuss
this result in more detail and provide examples of
improved classification decisions.
</bodyText>
<sectionHeader confidence="0.999779" genericHeader="method">
6 Discussion
</sectionHeader>
<bodyText confidence="0.999975466666667">
As a more detailed qualitative analysis, we exam-
ined the impact of word representations on SRL
performance with respect to different argument la-
bels and predicate types. Results on the in-domain
data set, shown in the upper part of Table 5, sug-
gest that most improvements in terms of preci-
sion are gained for verbal predicates, while nom-
inal predicates primarily benefit from higher re-
call. One reason for the latter observation might
be that arguments of nominal predicates are gen-
erally much harder to identify for the Original
model, as the cues provided by indicator features
on words and syntax are often inconclusive. For
verbal predicates, the word representations mainly
provide reinforcing signals to the classifier, im-
proving its precision at a slight cost of recall.
The results on the out-of-domain data set pro-
vide more insights regarding the suitability of
word representations for generalization. As shown
in the lower half of Table 5, the additional features
on average have a positive impact on precision and
recall. For verbal predicates, we observe only one
case, namely A0, in which improvements in recall
came with a decline in precision. Regarding nomi-
nal predicates, the trend is similar to what we have
seen in the in-domain setting, with most gains be-
ing achieved in terms of recall.
Apart from assessing quantitative effects, we
further examined cases that directly show the qual-
itative gains of the compositional features defined
</bodyText>
<page confidence="0.99159">
410
</page>
<note confidence="0.555465">
Sentence with predicate and [gold argumentlabel] Original Features required for correction
</note>
<listItem confidence="0.9970302">
(1) He did not resent [theirA0] supervision A1 Interaction
(2) [HeA1] is getting plenty of rest no label Interaction, Path
(3) [HeA0] rose late and went down to have breakfast. no label Path
(4) He was able to sit [for hoursAM-TMP]. A2 Span
(5) Because he had spoken [too softlyAM-MNR]. AM-TMP Span
</listItem>
<tableCaption confidence="0.997305">
Table 6: Example sentences in which distributional features compensated for errors made by Original.
</tableCaption>
<table confidence="0.99995445">
In-domain verbal nominal
Label P R P R
A0 +0.4 +0.4 −0.1 +2.4
A1 +0.2 −0.4 +0.6 +1.5
A2 +1.7 −1.5 – +2.5
AM-ADV +0.8 +0.2 −9.9 −3.1
AM-DIS +0.3 −3.2 – –
AM-LOC +0.8 +1.1 +0.6 +3.0
AM-MNR −0.5 −1.2 +2.7 +0.3
AM-TMP −1.2 −0.7 −1.9 +3.3
Out-of-domain verbal nominal
Label P R P R
A0 −0.9 +2.5 −2.5 −0.4
A1 +1.7 +0.8 +1.0 +3.7
A2 +1.4 +0.7 −2.5 +3.2
AM-ADV +5.6 +0.7 – –
AM-DIS +7.3 – – –
AM-LOC +0.7 +2.4 – +15.0
AM-MNR +6.4 +10.5 +9.7 +10.7
AM-TMP +1.6 +1.8 −6.7 +1.1
</table>
<tableCaption confidence="0.975327">
Table 5: Differences in precision and recall per
</tableCaption>
<bodyText confidence="0.979564814814815">
argument label and predicate word category. All
numbers represent absolute percentage points.
in Section 3. Table 6 lists examples from the
out-of-domain data set that were misclassified by
the Original model but could be correctly pre-
dicted using our enhanced feature set. As illus-
trated by Examples (1) and (2), the Interaction
feature seems to help recall by guiding classifica-
tion decisions towards more meaningful and com-
plete structures.
Improvements using the Path feature can be ob-
served in cases where nested syntactic structures
need to be processed, as required in Example (2).
In another instance, Example (3), the following
path is predicted between argument and predicate:
He SBJ−→ rose COORD
←−−− and CONJ
←−− went OPRD
←−−to IM←−have.
Such cases are particularly problematic for the
Original model because long and potentially er-
roneous paths are sparse in the training data.
Further gains in performance are achieved using
the Span feature, which enables the model to bet-
ter handle infrequent and out-of-vocabulary words
occurring in an argument span, including “hours”
and “softly” in Example (4) and (5), respectively.
</bodyText>
<sectionHeader confidence="0.997609" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999978181818182">
In this paper, we proposed to enhance the feature
space of a state-of-the-art semantic role labeller by
applying and composing distributional word rep-
resentations. Our results indicate that combining
such features with standard syntactic cues leads to
more precise and more robust models, with sig-
nificant improvements both in-domain and out-of-
domain. Ablation tests on an out-of-domain data
set have shown that gains in recall are mostly due
to features based on composed representations.
Given the novelty of these features for SRL, we
believe that this insight is remarkable and deserves
further investigation. In future work, we plan to
apply more sophisticated models of composition-
ality to better represent predicate-argument struc-
tures and to guide classification decisions towards
outcomes that are semantically more plausible.
We anticipate that this line of research will also be
of interest for a range of related tasks beyond tra-
ditional SRL, including predicate-argument struc-
ture alignment (Roth and Frank, 2012) and im-
plicit argument linking (Gerber and Chai, 2012).
</bodyText>
<sectionHeader confidence="0.984582" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997512666666667">
This work has been supported by the FP7 Col-
laborative Project S-CASE (Grant Agreement No
610717) funded by the European Commission
(Michael Roth), and by EPSRC (EP/K017845/1)
in the framework of the CHIST-ERA READERS
project (Kristian Woodsend).
</bodyText>
<page confidence="0.997945">
411
</page>
<sectionHeader confidence="0.826345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.982310693693694">
Omri Abend, Roi Reichart, and Ari Rappoport. 2009.
Unsupervised argument identification for semantic
role labeling. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 28–36, Sun-
tec, Singapore, August.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Representing
adjective-noun constructions in semantic space. In
Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages
1183–1193, Cambridge, MA, October. Association
for Computational Linguistics.
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of the Thirteenth Conference on Compu-
tational Natural Language Learning: Shared Task,
pages 43–48. Association for Computational Lin-
guistics.
Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and
Pierre Nugues. 2010. A high-performance syn-
tactic and semantic dependency parser. In Coling
2010: Demonstration Volume, pages 33–36, Beijing,
China, August. Coling 2010 Organizing Committee.
William Blacoe and Mirella Lapata. 2012. A com-
parison of vector-based representations for seman-
tic composition. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 546–556, Jeju Island, Korea,
July. Association for Computational Linguistics.
Bernd Bohnet. 2010. Top accuracy and fast depen-
dency parsing is not a contradiction. In Proceedings
of the 23rd International Conference on Computa-
tional Linguistics (Coling 2010), pages 89–97, Bei-
jing, China, August.
Peter F Brown, Peter V Desouza, Robert L Mercer,
Vincent J Della Pietra, and Jenifer C Lai. 1992.
Class-based n-gram models of natural language.
Computational linguistics, 18(4):467–479.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. The Journal of Machine Learning Re-
search, 12:2493–2537.
Danilo Croce, Cristina Giannone, Paolo Annesi, and
Roberto Basili. 2010. Towards open-domain se-
mantic role labeling. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics, pages 237–246, Uppsala, Sweden, July.
Association for Computational Linguistics.
Koen Deschacht and Marie-Francine Moens. 2009.
Semi-supervised semantic role labeling using the
Latent Words Language Model. In Proceedings of
the 2009 Conference on Empirical Methods in Nat-
ural Language Processing, pages 21–29, Singapore,
August.
Paramveer Dhillon, Dean P Foster, and Lyle H Ungar.
2011. Multi-view learning of word embeddings via
CCA. In Advances in Neural Information Process-
ing Systems, pages 199–207.
Hagen F¨urstenau and Mirella Lapata. 2012. Semi-
supervised semantic role labeling via structural
alignment. Computational Linguistics, 38(1):135–
171.
Matthew Gerber and Joyce Chai. 2012. Semantic Role
Labeling of Implicit Arguments for Nominal Predi-
cates. Computational Linguistics, 38(4):755–798.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational linguis-
tics, 28(3):245–288.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Martf, Llufs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, et al. 2009. The conll-2009
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 1–18.
Karl Moritz Hermann, Dipanjan Das, Jason Weston,
and Kuzman Ganchev. 2014. Semantic frame
identification with distributed word representations.
In Proceedings of the 52nd Annual Meeting of the
Association for Computational Linguistics, pages
1448–1458, Baltimore, Maryland, June. Association
for Computational Linguistics.
Fei Huang and Alexander Yates. 2010. Open-domain
semantic role labeling by modeling word spans. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics, pages 968–
978, Uppsala, Sweden, July.
Eric Huang, Richard Socher, Christopher Manning,
and Andrew Ng. 2012. Improving word represen-
tations via global context and multiple word proto-
types. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers), pages 873–882, Jeju Island,
Korea, July.
R´emi Lebret and Ronan Collobert. 2014. Word em-
beddings through hellinger pca. In Proceedings of
the 14th Conference of the European Chapter of the
Association for Computational Linguistics, pages
482–490, Gothenburg, Sweden, April. Association
for Computational Linguistics.
A. Meyers, R. Reeves, C. Macleod, R. Szekely,
V. Zielinska, B. Young, and R. Grishman. 2004.
The nombank project: An interim report. In
A. Meyers, editor, HLT-NAACL 2004 Workshop:
Frontiers in Corpus Annotation, pages 24–31,
Boston, Massachusetts, USA, May.
</reference>
<page confidence="0.979912">
412
</page>
<reference confidence="0.9995918125">
Jeff Mitchell and Mirella Lapata. 2010. Composition
in Distributional Models of Semantics. Cognitive
Science, 34(8):1388–1429.
Andriy Mnih and Geoffrey Hinton. 2009. A scal-
able hierarchical distributed language model. In Ad-
vances in Neural Information Processing Systems,
volume 21, pages 1081–1088.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Michael Roth and Anette Frank. 2012. Aligning
predicate argument structures in monolingual com-
parable texts: A new corpus for a new task. In
Proceedings of the First Joint Conference on Lexi-
cal and Computational Semantics, pages 218–227,
Montreal, Canada, June.
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, Christopher R. Johnson, and Jan Schef-
fczyk. 2010. FrameNet II: Extended Theory and
Practice.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
1201–1211, Jeju Island, Korea, July. Association for
Computational Linguistics.
Ivan Titov and Alexandre Klementiev. 2011. A
bayesian model for unsupervised semantic parsing.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies, pages 1445–1455, Port-
land, Oregon, USA, June.
Ivan Titov and Alexandre Klementiev. 2012. Semi-
supervised semantic role labeling: Approaching
from an unsupervised perspective. In Proceedings
of COLING 2012, pages 2635–2652, Mumbai, In-
dia, December.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 384–394, Up-
psala, Sweden, July. Association for Computational
Linguistics.
Alexander Yeh. 2000. More accurate tests for
the statistical significance of result differences.
In Proceedings of the 18th International Confer-
ence on Computational Linguistics, pages 947–953,
Saarbr¨ucken, Germany, August.
Be˜nat Zapirain, Eneko Agirre, Llu´ıs M`arquez, and Mi-
hai Surdeanu. 2013. Selectional preferences for se-
mantic role classification. Computational Linguis-
tics, 39(3):631–663.
Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka
Uchimoto, and Kentaro Torisawa. 2009. Multi-
lingual dependency learning: Exploiting rich fea-
tures for tagging syntactic and semantic dependen-
cies. In Proceedings of the Thirteenth Confer-
ence on Computational Natural Language Learning
(CoNLL 2009): Shared Task, pages 61–66, Boulder,
Colorado, USA, June.
</reference>
<page confidence="0.998988">
413
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.911473">
<title confidence="0.9921405">Composition of Word Improves Semantic Role Labelling</title>
<author confidence="0.941446">Roth</author>
<affiliation confidence="0.987903">Institute for Language, Cognition and School of Informatics, University of</affiliation>
<abstract confidence="0.999604368421053">State-of-the-art semantic role labelling systems require large annotated corpora to achieve full performance. Unfortunately, such corpora are expensive to produce and often do not generalize well across domains. Even in domain, errors are often made where syntactic information does not provide sufficient cues. In this paper, we mitigate both of these problems by employing distributional word representations gathered from unlabelled data. While straight-forward word representations of predicates and arguments improve performance, we show that further gains are achieved by composing representations that model the interaction between predicate and argument, and capture full argument spans.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Omri Abend</author>
<author>Roi Reichart</author>
<author>Ari Rappoport</author>
</authors>
<title>Unsupervised argument identification for semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>28--36</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="2116" citStr="Abend et al., 2009" startWordPosition="297" endWordPosition="300">5), have been developed with the goal of documenting and providing examples of such transformations and how they preserve semantic role information. Given that labelled corpora are inevitably restricted in size and coverage, and that syntactic cues are not by themselves unambiguous or sufficient, the success of systems that automatically provide corresponding analyses has been limited in practice. Recent work on SRL has explored approaches that can leverage unlabelled data, following a semi-supervised (F¨urstenau and Lapata, 2012; Titov and Klementiev, 2012) or unsupervised learning paradigm (Abend et al., 2009; Titov and Klementiev, 2011). Unlabelled data provides additional statistical strength and can lead to more consistent models. For instance, latent representations of words can be computed, based on distributional similarity or language modelling, which can be used as additional features during traditional supervised learning. Although we would expect that extra features would improve classifier performance, this seems in part counter-intuitive. Just because one word has a specific representation does not mean that it should be assigned a specific argument label. Instead, one would expect a m</context>
</contexts>
<marker>Abend, Reichart, Rappoport, 2009</marker>
<rawString>Omri Abend, Roi Reichart, and Ari Rappoport. 2009. Unsupervised argument identification for semantic role labeling. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 28–36, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1183--1193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="5714" citStr="Baroni and Zamparelli (2010)" startWordPosition="848" endWordPosition="851">rity) has to be chosen in advance. The popularity of distributional methods for word representation has been a motivation for developing representations of larger constructions such as phrases and sentences, and there have been several proposals for computing the meaning of word combinations in vector spaces. Mitchell and Lapata (2010) introduced a general framework where composition is formulated as a function f of two vectors u and v. Depending on how f is chosen, different composition models arise, the simplest being an additive model where f(u, v) = u + v. To capture relational functions, Baroni and Zamparelli (2010) expanded on this approach by representing verbs, adjectives and adverbs by matrices which can modify the properties of nouns (represented by vectors). Socher et al. (2012) combined word representations with syntactic structure information, through a recursive neural network that learns vector space representations for multi-word phrases and sentences. An empirical comparison of these composition methods was provided in (Blacoe and Lapata, 2012). In this work, we use type-based continuous representations of words to compose representations of multiple word sequences and spans, which can then b</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1183–1193, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>43--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 43–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Bernd Bohnet</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>A high-performance syntactic and semantic dependency parser.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Coling 2010: Demonstration Volume,</booktitle>
<pages>33--36</pages>
<location>Beijing, China,</location>
<marker>Bj¨orkelund, Bohnet, Hafdell, Nugues, 2010</marker>
<rawString>Anders Bj¨orkelund, Bernd Bohnet, Love Hafdell, and Pierre Nugues. 2010. A high-performance syntactic and semantic dependency parser. In Coling 2010: Demonstration Volume, pages 33–36, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Blacoe</author>
<author>Mirella Lapata</author>
</authors>
<title>A comparison of vector-based representations for semantic composition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>546--556</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="6163" citStr="Blacoe and Lapata, 2012" startWordPosition="914" endWordPosition="917"> how f is chosen, different composition models arise, the simplest being an additive model where f(u, v) = u + v. To capture relational functions, Baroni and Zamparelli (2010) expanded on this approach by representing verbs, adjectives and adverbs by matrices which can modify the properties of nouns (represented by vectors). Socher et al. (2012) combined word representations with syntactic structure information, through a recursive neural network that learns vector space representations for multi-word phrases and sentences. An empirical comparison of these composition methods was provided in (Blacoe and Lapata, 2012). In this work, we use type-based continuous representations of words to compose representations of multiple word sequences and spans, which can then be incorporated directly as features into SRL systems. Distributional Feature Computation Argument a a� Predicate p p� Predicate-argument Interaction a� + p� Argument Span w1 ... w,,, Ez wz Dependency Path from a to p Ew∈path(a,p) w� Table 1: Features based on distributional word representations and additive composition. Vector w� denotes the representation of word w. 3 Method Following the set-up of the CoNLL shared task in 2009, we consider pre</context>
</contexts>
<marker>Blacoe, Lapata, 2012</marker>
<rawString>William Blacoe and Mirella Lapata. 2012. A comparison of vector-based representations for semantic composition. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 546–556, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>89--97</pages>
<location>Beijing, China,</location>
<contexts>
<context position="9668" citStr="Bohnet, 2010" startWordPosition="1483" endWordPosition="1484">nt types of features by performing experiments on a benchmark dataset for semantic role labelling. To assess the gains of distributional representations realistically, we incorporate the features described in Section 3 into a state-of-the-art SRL system. The following paragraphs summarize the details of our experimental setup. Semantic Role Labeller. In all our experiments, we use the publicly available system by Bj¨orkelund et al. (2010).1 This system combines the first-ranked SRL system and the firstranked syntactic parser in the CoNLL 2009 shared task for English (Bj¨orkelund et al., 2009; Bohnet, 2010). To the best of our knowledge, this combination represents the current state-of-the-art for semantic role labelling following the PropBank/NomBank paradigm (Palmer et al., 2005; Meyers et al., 2004). To re-train and evaluate models with different feature sets, we use the same training, development and test sets as provided in the CoNLL shared task (Hajiˇc et al., 2009). Although the employed system features a full syntactic-semantic parsing pipeline, we only modify the feature sets of the two components directly related to the actual role labelling task, namely argument identification and arg</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 89–97, Beijing, China, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V Desouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="11355" citStr="Brown et al., 1992" startWordPosition="1723" endWordPosition="1726">ng/ 4http://lebret.ch/words/ 5http://www.cis.upenn.edu/%7eungar/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significant differences were observed, however, using other types of representations or vector sizes. 5 R</context>
</contexts>
<marker>Brown, Desouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai. 1992. Class-based n-gram models of natural language. Computational linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="4139" citStr="Collobert et al. (2011)" startWordPosition="602" endWordPosition="605">formation in SRL dates back to Gildea and Jurafsky (2002), who used distributions over verb-object co-occurrence clusters to improve coverage in argument classification. The distribution of a word over these soft clusters assignments was added as 407 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 407–413, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics features to their classifier. The SRL system by Croce et al. (2010) combines argument clustering based on co-occurrence frequencies with a language model. Collobert et al. (2011) used distributional word representations in a neural network model that can update representations during training. Zapirain et al. (2013) suggested distributional information as a basis for a selectional preference model that can be used as a single additional feature for classifying potential arguments. Most recently, Hermann et al. (2014) used distributional word representations within pre-defined syntactic contexts as input to a classifier which learns to distinguish different predicate senses. A complementary line of research explores the representation of sequence information. Prominent</context>
<context position="11260" citStr="Collobert et al., 2011" startWordPosition="1708" endWordPosition="1711">le.com/p/mate-tools/ 2http://metaoptimize.com/projects/wordreprs/ 3http://ai.stanford.edu/%7eehhuang/ 4http://lebret.ch/words/ 5http://www.cis.upenn.edu/%7eungar/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significan</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Cristina Giannone</author>
<author>Paolo Annesi</author>
<author>Roberto Basili</author>
</authors>
<title>Towards open-domain semantic role labeling.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>237--246</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4028" citStr="Croce et al. (2010)" startWordPosition="586" endWordPosition="589">aluate on the English part of the CoNLL-2009 data set. 2 Related Work Research into using distributional information in SRL dates back to Gildea and Jurafsky (2002), who used distributions over verb-object co-occurrence clusters to improve coverage in argument classification. The distribution of a word over these soft clusters assignments was added as 407 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 407–413, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics features to their classifier. The SRL system by Croce et al. (2010) combines argument clustering based on co-occurrence frequencies with a language model. Collobert et al. (2011) used distributional word representations in a neural network model that can update representations during training. Zapirain et al. (2013) suggested distributional information as a basis for a selectional preference model that can be used as a single additional feature for classifying potential arguments. Most recently, Hermann et al. (2014) used distributional word representations within pre-defined syntactic contexts as input to a classifier which learns to distinguish different pr</context>
</contexts>
<marker>Croce, Giannone, Annesi, Basili, 2010</marker>
<rawString>Danilo Croce, Cristina Giannone, Paolo Annesi, and Roberto Basili. 2010. Towards open-domain semantic role labeling. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 237–246, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Semi-supervised semantic role labeling using the Latent Words Language Model.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>21--29</pages>
<location>Singapore,</location>
<contexts>
<context position="4792" citStr="Deschacht and Moens (2009)" startWordPosition="699" endWordPosition="702">epresentations in a neural network model that can update representations during training. Zapirain et al. (2013) suggested distributional information as a basis for a selectional preference model that can be used as a single additional feature for classifying potential arguments. Most recently, Hermann et al. (2014) used distributional word representations within pre-defined syntactic contexts as input to a classifier which learns to distinguish different predicate senses. A complementary line of research explores the representation of sequence information. Prominent examples are the works by Deschacht and Moens (2009) and Huang and Yates (2010) who learned and applied Hidden Markov Models to assign state variables to words and word spans, which serve as supplementary features for classification. One drawback of this approach is that state variables are discrete and the number of states (i.e., their granularity) has to be chosen in advance. The popularity of distributional methods for word representation has been a motivation for developing representations of larger constructions such as phrases and sentences, and there have been several proposals for computing the meaning of word combinations in vector spa</context>
</contexts>
<marker>Deschacht, Moens, 2009</marker>
<rawString>Koen Deschacht and Marie-Francine Moens. 2009. Semi-supervised semantic role labeling using the Latent Words Language Model. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 21–29, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramveer Dhillon</author>
<author>Dean P Foster</author>
<author>Lyle H Ungar</author>
</authors>
<title>Multi-view learning of word embeddings via CCA.</title>
<date>2011</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>199--207</pages>
<contexts>
<context position="11318" citStr="Dhillon et al., 2011" startWordPosition="1717" endWordPosition="1720">reprs/ 3http://ai.stanford.edu/%7eehhuang/ 4http://lebret.ch/words/ 5http://www.cis.upenn.edu/%7eungar/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significant differences were observed, however, using other types of</context>
</contexts>
<marker>Dhillon, Foster, Ungar, 2011</marker>
<rawString>Paramveer Dhillon, Dean P Foster, and Lyle H Ungar. 2011. Multi-view learning of word embeddings via CCA. In Advances in Neural Information Processing Systems, pages 199–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hagen F¨urstenau</author>
<author>Mirella Lapata</author>
</authors>
<title>Semisupervised semantic role labeling via structural alignment.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>1</issue>
<pages>171</pages>
<marker>F¨urstenau, Lapata, 2012</marker>
<rawString>Hagen F¨urstenau and Mirella Lapata. 2012. Semisupervised semantic role labeling via structural alignment. Computational Linguistics, 38(1):135– 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Gerber</author>
<author>Joyce Chai</author>
</authors>
<title>Semantic Role Labeling of Implicit Arguments for Nominal Predicates.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>4</issue>
<marker>Gerber, Chai, 2012</marker>
<rawString>Matthew Gerber and Joyce Chai. 2012. Semantic Role Labeling of Implicit Arguments for Nominal Predicates. Computational Linguistics, 38(4):755–798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational linguistics,</journal>
<pages>28--3</pages>
<contexts>
<context position="3573" citStr="Gildea and Jurafsky (2002)" startWordPosition="521" endWordPosition="524">tions for a predicate and its argument head. Furthermore, we use a compositional approach to model a representation of the full argument, by composing a joint representation of all words in the argument span, and we also investigate the interaction between predicate and argument, using a compositional representation of the dependency path. We demonstrate the benefits of these compositional features using a state-of-the-art semantic role labeller, which we evaluate on the English part of the CoNLL-2009 data set. 2 Related Work Research into using distributional information in SRL dates back to Gildea and Jurafsky (2002), who used distributions over verb-object co-occurrence clusters to improve coverage in argument classification. The distribution of a word over these soft clusters assignments was added as 407 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 407–413, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics features to their classifier. The SRL system by Croce et al. (2010) combines argument clustering based on co-occurrence frequencies with a language model. Collobert et al. (2011) used distributional word represen</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Martf</author>
<author>Llufs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
</authors>
<title>The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--18</pages>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Martf, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, et al. 2009. The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karl Moritz Hermann</author>
<author>Dipanjan Das</author>
<author>Jason Weston</author>
<author>Kuzman Ganchev</author>
</authors>
<title>Semantic frame identification with distributed word representations.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1448--1458</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="4483" citStr="Hermann et al. (2014)" startWordPosition="656" endWordPosition="659"> pages 407–413, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics features to their classifier. The SRL system by Croce et al. (2010) combines argument clustering based on co-occurrence frequencies with a language model. Collobert et al. (2011) used distributional word representations in a neural network model that can update representations during training. Zapirain et al. (2013) suggested distributional information as a basis for a selectional preference model that can be used as a single additional feature for classifying potential arguments. Most recently, Hermann et al. (2014) used distributional word representations within pre-defined syntactic contexts as input to a classifier which learns to distinguish different predicate senses. A complementary line of research explores the representation of sequence information. Prominent examples are the works by Deschacht and Moens (2009) and Huang and Yates (2010) who learned and applied Hidden Markov Models to assign state variables to words and word spans, which serve as supplementary features for classification. One drawback of this approach is that state variables are discrete and the number of states (i.e., their gran</context>
</contexts>
<marker>Hermann, Das, Weston, Ganchev, 2014</marker>
<rawString>Karl Moritz Hermann, Dipanjan Das, Jason Weston, and Kuzman Ganchev. 2014. Semantic frame identification with distributed word representations. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1448–1458, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Alexander Yates</author>
</authors>
<title>Open-domain semantic role labeling by modeling word spans.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>968--978</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4819" citStr="Huang and Yates (2010)" startWordPosition="704" endWordPosition="707">ork model that can update representations during training. Zapirain et al. (2013) suggested distributional information as a basis for a selectional preference model that can be used as a single additional feature for classifying potential arguments. Most recently, Hermann et al. (2014) used distributional word representations within pre-defined syntactic contexts as input to a classifier which learns to distinguish different predicate senses. A complementary line of research explores the representation of sequence information. Prominent examples are the works by Deschacht and Moens (2009) and Huang and Yates (2010) who learned and applied Hidden Markov Models to assign state variables to words and word spans, which serve as supplementary features for classification. One drawback of this approach is that state variables are discrete and the number of states (i.e., their granularity) has to be chosen in advance. The popularity of distributional methods for word representation has been a motivation for developing representations of larger constructions such as phrases and sentences, and there have been several proposals for computing the meaning of word combinations in vector spaces. Mitchell and Lapata (2</context>
</contexts>
<marker>Huang, Yates, 2010</marker>
<rawString>Fei Huang and Alexander Yates. 2010. Open-domain semantic role labeling by modeling word spans. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 968– 978, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Huang</author>
<author>Richard Socher</author>
<author>Christopher Manning</author>
<author>Andrew Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>873--882</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="11281" citStr="Huang et al., 2012" startWordPosition="1712" endWordPosition="1715">tp://metaoptimize.com/projects/wordreprs/ 3http://ai.stanford.edu/%7eehhuang/ 4http://lebret.ch/words/ 5http://www.cis.upenn.edu/%7eungar/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significant differences were ob</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric Huang, Richard Socher, Christopher Manning, and Andrew Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 873–882, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R´emi Lebret</author>
<author>Ronan Collobert</author>
</authors>
<title>Word embeddings through hellinger pca.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>482--490</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="11425" citStr="Lebret and Collobert, 2014" startWordPosition="1731" endWordPosition="1734">r/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significant differences were observed, however, using other types of representations or vector sizes. 5 Results We evaluate our proposed set of additional features on the CoNL</context>
</contexts>
<marker>Lebret, Collobert, 2014</marker>
<rawString>R´emi Lebret and Ronan Collobert. 2014. Word embeddings through hellinger pca. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 482–490, Gothenburg, Sweden, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
<author>R Reeves</author>
<author>C Macleod</author>
<author>R Szekely</author>
<author>V Zielinska</author>
<author>B Young</author>
<author>R Grishman</author>
</authors>
<title>The nombank project: An interim report.</title>
<date>2004</date>
<booktitle>HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation,</booktitle>
<pages>24--31</pages>
<editor>In A. Meyers, editor,</editor>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="9867" citStr="Meyers et al., 2004" startWordPosition="1510" endWordPosition="1513">res described in Section 3 into a state-of-the-art SRL system. The following paragraphs summarize the details of our experimental setup. Semantic Role Labeller. In all our experiments, we use the publicly available system by Bj¨orkelund et al. (2010).1 This system combines the first-ranked SRL system and the firstranked syntactic parser in the CoNLL 2009 shared task for English (Bj¨orkelund et al., 2009; Bohnet, 2010). To the best of our knowledge, this combination represents the current state-of-the-art for semantic role labelling following the PropBank/NomBank paradigm (Palmer et al., 2005; Meyers et al., 2004). To re-train and evaluate models with different feature sets, we use the same training, development and test sets as provided in the CoNLL shared task (Hajiˇc et al., 2009). Although the employed system features a full syntactic-semantic parsing pipeline, we only modify the feature sets of the two components directly related to the actual role labelling task, namely argument identification and argument classification. Word Representations. As a baseline, we simply added as features the word representations of the predicate and argument head involved in a classification decision (first two lin</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>A. Meyers, R. Reeves, C. Macleod, R. Szekely, V. Zielinska, B. Young, and R. Grishman. 2004. The nombank project: An interim report. In A. Meyers, editor, HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation, pages 24–31, Boston, Massachusetts, USA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in Distributional Models of Semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="5423" citStr="Mitchell and Lapata (2010)" startWordPosition="797" endWordPosition="800">Huang and Yates (2010) who learned and applied Hidden Markov Models to assign state variables to words and word spans, which serve as supplementary features for classification. One drawback of this approach is that state variables are discrete and the number of states (i.e., their granularity) has to be chosen in advance. The popularity of distributional methods for word representation has been a motivation for developing representations of larger constructions such as phrases and sentences, and there have been several proposals for computing the meaning of word combinations in vector spaces. Mitchell and Lapata (2010) introduced a general framework where composition is formulated as a function f of two vectors u and v. Depending on how f is chosen, different composition models arise, the simplest being an additive model where f(u, v) = u + v. To capture relational functions, Baroni and Zamparelli (2010) expanded on this approach by representing verbs, adjectives and adverbs by matrices which can modify the properties of nouns (represented by vectors). Socher et al. (2012) combined word representations with syntactic structure information, through a recursive neural network that learns vector space represen</context>
<context position="8808" citStr="Mitchell and Lapata (2010)" startWordPosition="1346" endWordPosition="1349">e. Just because one word has a specific representation does not mean that it should be assigned a specific argument label. In fact, one would expect a more complex interplay between the representation of an argument az and the context it appears in. To model aspects of this interplay, we define an extended set of features that 408 further includes representations for the combination of p and ai, the set of words in the dependency path between p and ai, and the set of words in the full span of az. We compute additive compositional representations of multiple words, using the simplest method of Mitchell and Lapata (2010) where the composed representation is the uniformly weighted sum of each single representation. Our full set of feature types based on distributional word representations is listed in Table 1. 4 Experimental Setup We evaluate the impact of different types of features by performing experiments on a benchmark dataset for semantic role labelling. To assess the gains of distributional representations realistically, we incorporate the features described in Section 3 into a state-of-the-art SRL system. The following paragraphs summarize the details of our experimental setup. Semantic Role Labeller. </context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in Distributional Models of Semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andriy Mnih</author>
<author>Geoffrey Hinton</author>
</authors>
<title>A scalable hierarchical distributed language model.</title>
<date>2009</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<volume>21</volume>
<pages>1081--1088</pages>
<contexts>
<context position="11236" citStr="Mnih and Hinton, 2009" startWordPosition="1704" endWordPosition="1707">odels 1http://code.google.com/p/mate-tools/ 2http://metaoptimize.com/projects/wordreprs/ 3http://ai.stanford.edu/%7eehhuang/ 4http://lebret.ch/words/ 5http://www.cis.upenn.edu/%7eungar/eigenwords/ Development dims P R F1 None – 86.1 81.0 83.5 Brown clusters2 320 86.2 81.3 83.7 Neural LM2 50 86.2 81.4 83.7 Neural LM+Global3 50 86.2 81.4 83.7 HLBL2 50 86.3 81.3 83.7 H-PCA4 50 86.2 81.3 83.7 Eigenwords5 50 86.2 81.3 83.6 Table 2: Results on the CoNLL-2009 development set, using off-the-shelf word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other repres</context>
</contexts>
<marker>Mnih, Hinton, 2009</marker>
<rawString>Andriy Mnih and Geoffrey Hinton. 2009. A scalable hierarchical distributed language model. In Advances in Neural Information Processing Systems, volume 21, pages 1081–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="1500" citStr="Palmer et al., 2005" startWordPosition="206" endWordPosition="209">redicate and argument, and capture full argument spans. 1 Introduction The goal of semantic role labelling (SRL) is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). This semantic knowledge at the predicate-argument level is required by inference-based NLP tasks in order to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations. Several manually-build semantic resources, including FrameNet (Ruppenhofer et al., 2010) and PropBank (Palmer et al., 2005), have been developed with the goal of documenting and providing examples of such transformations and how they preserve semantic role information. Given that labelled corpora are inevitably restricted in size and coverage, and that syntactic cues are not by themselves unambiguous or sufficient, the success of systems that automatically provide corresponding analyses has been limited in practice. Recent work on SRL has explored approaches that can leverage unlabelled data, following a semi-supervised (F¨urstenau and Lapata, 2012; Titov and Klementiev, 2012) or unsupervised learning paradigm (Ab</context>
<context position="9845" citStr="Palmer et al., 2005" startWordPosition="1506" endWordPosition="1509">incorporate the features described in Section 3 into a state-of-the-art SRL system. The following paragraphs summarize the details of our experimental setup. Semantic Role Labeller. In all our experiments, we use the publicly available system by Bj¨orkelund et al. (2010).1 This system combines the first-ranked SRL system and the firstranked syntactic parser in the CoNLL 2009 shared task for English (Bj¨orkelund et al., 2009; Bohnet, 2010). To the best of our knowledge, this combination represents the current state-of-the-art for semantic role labelling following the PropBank/NomBank paradigm (Palmer et al., 2005; Meyers et al., 2004). To re-train and evaluate models with different feature sets, we use the same training, development and test sets as provided in the CoNLL shared task (Hajiˇc et al., 2009). Although the employed system features a full syntactic-semantic parsing pipeline, we only modify the feature sets of the two components directly related to the actual role labelling task, namely argument identification and argument classification. Word Representations. As a baseline, we simply added as features the word representations of the predicate and argument head involved in a classification d</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Roth</author>
<author>Anette Frank</author>
</authors>
<title>Aligning predicate argument structures in monolingual comparable texts: A new corpus for a new task.</title>
<date>2012</date>
<booktitle>In Proceedings of the First Joint Conference on Lexical and Computational Semantics,</booktitle>
<pages>218--227</pages>
<location>Montreal, Canada,</location>
<marker>Roth, Frank, 2012</marker>
<rawString>Michael Roth and Anette Frank. 2012. Aligning predicate argument structures in monolingual comparable texts: A new corpus for a new task. In Proceedings of the First Joint Conference on Lexical and Computational Semantics, pages 218–227, Montreal, Canada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Michael Ellsworth</author>
<author>Miriam R L Petruck</author>
<author>Christopher R Johnson</author>
<author>Jan Scheffczyk</author>
</authors>
<title>FrameNet II: Extended Theory and Practice.</title>
<date>2010</date>
<contexts>
<context position="1465" citStr="Ruppenhofer et al., 2010" startWordPosition="200" endWordPosition="203">ons that model the interaction between predicate and argument, and capture full argument spans. 1 Introduction The goal of semantic role labelling (SRL) is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). This semantic knowledge at the predicate-argument level is required by inference-based NLP tasks in order to identify meaning-preserving transformations, such as active/passive, verb alternations and nominalizations. Several manually-build semantic resources, including FrameNet (Ruppenhofer et al., 2010) and PropBank (Palmer et al., 2005), have been developed with the goal of documenting and providing examples of such transformations and how they preserve semantic role information. Given that labelled corpora are inevitably restricted in size and coverage, and that syntactic cues are not by themselves unambiguous or sufficient, the success of systems that automatically provide corresponding analyses has been limited in practice. Recent work on SRL has explored approaches that can leverage unlabelled data, following a semi-supervised (F¨urstenau and Lapata, 2012; Titov and Klementiev, 2012) or</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, Scheffczyk, 2010</marker>
<rawString>Josef Ruppenhofer, Michael Ellsworth, Miriam R. L. Petruck, Christopher R. Johnson, and Jan Scheffczyk. 2010. FrameNet II: Extended Theory and Practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1201--1211</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="5886" citStr="Socher et al. (2012)" startWordPosition="875" endWordPosition="878">h as phrases and sentences, and there have been several proposals for computing the meaning of word combinations in vector spaces. Mitchell and Lapata (2010) introduced a general framework where composition is formulated as a function f of two vectors u and v. Depending on how f is chosen, different composition models arise, the simplest being an additive model where f(u, v) = u + v. To capture relational functions, Baroni and Zamparelli (2010) expanded on this approach by representing verbs, adjectives and adverbs by matrices which can modify the properties of nouns (represented by vectors). Socher et al. (2012) combined word representations with syntactic structure information, through a recursive neural network that learns vector space representations for multi-word phrases and sentences. An empirical comparison of these composition methods was provided in (Blacoe and Lapata, 2012). In this work, we use type-based continuous representations of words to compose representations of multiple word sequences and spans, which can then be incorporated directly as features into SRL systems. Distributional Feature Computation Argument a a� Predicate p p� Predicate-argument Interaction a� + p� Argument Span w</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1201–1211, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A bayesian model for unsupervised semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1445--1455</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="2145" citStr="Titov and Klementiev, 2011" startWordPosition="301" endWordPosition="304">ped with the goal of documenting and providing examples of such transformations and how they preserve semantic role information. Given that labelled corpora are inevitably restricted in size and coverage, and that syntactic cues are not by themselves unambiguous or sufficient, the success of systems that automatically provide corresponding analyses has been limited in practice. Recent work on SRL has explored approaches that can leverage unlabelled data, following a semi-supervised (F¨urstenau and Lapata, 2012; Titov and Klementiev, 2012) or unsupervised learning paradigm (Abend et al., 2009; Titov and Klementiev, 2011). Unlabelled data provides additional statistical strength and can lead to more consistent models. For instance, latent representations of words can be computed, based on distributional similarity or language modelling, which can be used as additional features during traditional supervised learning. Although we would expect that extra features would improve classifier performance, this seems in part counter-intuitive. Just because one word has a specific representation does not mean that it should be assigned a specific argument label. Instead, one would expect a more complex interplay between</context>
</contexts>
<marker>Titov, Klementiev, 2011</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2011. A bayesian model for unsupervised semantic parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1445–1455, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>Semisupervised semantic role labeling: Approaching from an unsupervised perspective.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>2635--2652</pages>
<location>Mumbai, India,</location>
<contexts>
<context position="2062" citStr="Titov and Klementiev, 2012" startWordPosition="289" endWordPosition="292">Net (Ruppenhofer et al., 2010) and PropBank (Palmer et al., 2005), have been developed with the goal of documenting and providing examples of such transformations and how they preserve semantic role information. Given that labelled corpora are inevitably restricted in size and coverage, and that syntactic cues are not by themselves unambiguous or sufficient, the success of systems that automatically provide corresponding analyses has been limited in practice. Recent work on SRL has explored approaches that can leverage unlabelled data, following a semi-supervised (F¨urstenau and Lapata, 2012; Titov and Klementiev, 2012) or unsupervised learning paradigm (Abend et al., 2009; Titov and Klementiev, 2011). Unlabelled data provides additional statistical strength and can lead to more consistent models. For instance, latent representations of words can be computed, based on distributional similarity or language modelling, which can be used as additional features during traditional supervised learning. Although we would expect that extra features would improve classifier performance, this seems in part counter-intuitive. Just because one word has a specific representation does not mean that it should be assigned a </context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. Semisupervised semantic role labeling: Approaching from an unsupervised perspective. In Proceedings of COLING 2012, pages 2635–2652, Mumbai, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="11728" citStr="Turian et al. (2010)" startWordPosition="1779" endWordPosition="1782"> word representations for predicates and argument as additional features. Performance numbers in percent. (Mnih and Hinton, 2009; Collobert et al., 2011; Huang et al., 2012), eigenvectors (Dhillon et al., 2011), Brown clusters (Brown et al., 1992), and post-processed co-occurrence counts (Lebret and Collobert, 2014). Results on the development set for various off-the-shelf representations are shown in Table 2. The numbers reveal that any kind of word representation can be employed to improve results. We choose to perform all follow-up experiments using the 50-dimensional embeddings induced by Turian et al. (2010), using the method by Collobert et al., as they led to slightly better results in F1-score than other representations. No significant differences were observed, however, using other types of representations or vector sizes. 5 Results We evaluate our proposed set of additional features on the CoNLL-2009 in-domain and out-ofdomain test sets, using the aforementioned SRL system and word representations. All results are computed using the system’s built-in preprocessing pipeline and re-trained models for argument identification and classification. We report labelled precision, recall and semantic </context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<pages>947--953</pages>
<location>Saarbr¨ucken, Germany,</location>
<contexts>
<context position="12802" citStr="Yeh, 2000" startWordPosition="1948" endWordPosition="1949">essing pipeline and re-trained models for argument identification and classification. We report labelled precision, recall and semantic F1-score as computed by the official scorer. The upper part of Table 3 shows SRL performance on the in-domain CoNLL-2009 test set, with and without (Original) additional features based on distributional representations. The results reveal that any type of additional feature helps to improve precision and recall in this setting (from 85.2% F1-score up to 85.5%), with significant gains for 4 of the 5 additional features (computed using a randomization test; cf. Yeh, 2000). Interestingly, we find that the features do not seem 409 In-domain P R F1 Original 87.4 83.1 85.2 Original + Argument 87.6 83.3 85.4** Original + Predicate 87.4 83.2 85.2 Original + Interaction 87.5 83.3 85.3** Original + Span 87.6 83.5 85.5** Original + Path 87.5 83.4 85.4** Original + All 87.6 83.4 85.5** Out-of-domain P R F1 Original 76.9 71.7 74.2 Original + Argument 77.4 71.9 74.5 Original + Predicate 77.3 72.2 74.7* Original + Interaction 77.2 72.0 74.5 Original + Span 77.3 72.3 74.7* Original + Path 77.2 72.3 74.7* Original + All 77.5 73.0 75.2** Table 3: Results on both CoNLL-2009 te</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the 18th International Conference on Computational Linguistics, pages 947–953, Saarbr¨ucken, Germany, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Be˜nat Zapirain</author>
</authors>
<title>Eneko Agirre, Llu´ıs M`arquez, and Mihai Surdeanu.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<marker>Zapirain, 2013</marker>
<rawString>Be˜nat Zapirain, Eneko Agirre, Llu´ıs M`arquez, and Mihai Surdeanu. 2013. Selectional preferences for semantic role classification. Computational Linguistics, 39(3):631–663.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Kiyotaka Uchimoto</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>61--66</pages>
<location>Boulder, Colorado, USA,</location>
<contexts>
<context position="14466" citStr="Zhao et al., 2009" startWordPosition="2225" endWordPosition="2228">st set of the CoNLL-2009 shared task. The results for the out-of-domain experiment are summarized in the lower part of Table 3. We again observe that each single feature type improves classification, with absolute gains being slightly higher than in the in-domain setting. More interestingly though, we find that the complete feature set boosts performance even further, achieving an overall gain in precision and recall of 0.6 and 1.3 percentage points, respectively. The resulting F1-score of 75.2 lies even higher than the top score for this particular data set reported in the CoNLL shared task (Zhao et al., 2009; 74.6 F1). We next investigate the benefits of compositional representations over features for single words by assessing their impact on the overall result in an ablation study. Table 4 shows results of ablation tests performed for the three compositional feature types Interaction, Span and Path on the out-of-domain test set. The results reveal Out-of-domain P R F1 Original 76.9 71.7 74.2 Full (Original+All) 77.5 73.0 75.2 Full −Interaction 77.2 72.5 74.8 Full −Span 77.2 72.3 74.7 Full −Path 77.6 72.3 74.8 Table 4: Results of an ablation study over features based on compositional representati</context>
</contexts>
<marker>Zhao, Chen, Kazama, Uchimoto, Torisawa, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa. 2009. Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 61–66, Boulder, Colorado, USA, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>