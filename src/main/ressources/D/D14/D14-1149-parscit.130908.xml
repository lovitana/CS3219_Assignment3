<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001468">
<title confidence="0.987907">
Extracting Clusters of Specialist Terms from Unstructured Text
</title>
<author confidence="0.996801">
Aaron Gerow
</author>
<affiliation confidence="0.996103">
Computation Institute
University of Chicago
</affiliation>
<address confidence="0.710453">
Chicago, IL, USA
</address>
<email confidence="0.9992">
gerow@uchicago.edu
</email>
<sectionHeader confidence="0.993908" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999838541666667">
Automatically identifying related special-
ist terms is a difficult and important task
required to understand the lexical struc-
ture of language. This paper develops
a corpus-based method of extracting co-
herent clusters of satellite terminology —
terms on the edge of the lexicon — us-
ing co-occurrence networks of unstruc-
tured text. Term clusters are identi-
fied by extracting communities in the co-
occurrence graph, after which the largest
is discarded and the remaining words are
ranked by centrality within a community.
The method is tractable on large corpora,
requires no document structure and min-
imal normalization. The results suggest
that the model is able to extract coher-
ent groups of satellite terms in corpora
with varying size, content and structure.
The findings also confirm that language
consists of a densely connected core (ob-
served in dictionaries) and systematic, se-
mantically coherent groups of terms at the
edges of the lexicon.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985923076923">
Natural language consists of a number of rela-
tional structures, many of which can be obscured
by lexical idiosyncrasies, regional variation and
domain-specific conventions. Despite this, pat-
terns of word use exhibit loose semantic struc-
ture, namely that proximate words tend to be re-
lated. This distributional hypothesis has been op-
erationalized in a variety of ways, providing in-
sights and solutions into practical and theoretical
questions about meaning, intention and the use of
language. Distributional analyses rely primarily
on observing natural language to build statistical
representations of words, phrases and documents
(Turney and Pantel, 2010). By studying dictio-
naries and thesauri, lexicographic and terminolog-
ical research has proposed that a core lexicon is
used to define the remaining portions of vocabu-
lary (Itˆo and Mester, 1995; Mass´e et al., 2008).
Though many words that comprise general lan-
guage use reside in this core lexicon, even the
most general language contains specialist or so-
called “satellite” words. This paper introduces a
method of extracting this peripheral structure, with
co-occurrence networks of unstructured text.
The core-periphery structure has been observed
in dictionaries where definitions tend to use a re-
stricted vocabulary, repetitively employing a core
set of words to define others (Sinclair, 1996; Pi-
card et al., 2013). In the farther regions of the lex-
icon, it is more difficult to find systematic seman-
tic definition with corpus-based techniques due to
the overwhelming number of infrequent words.
Unfortunately, the fringe of the lexicon can be
more important than the core because this is where
domain-specific terminology resides — features
that may be more important than frequent.
Examining dictionaries, (Picard et al., 2013)
propose that the lexicon consists of four main
parts: a core set of ubiquitous words used to de-
fine other words, a kernel that makes up most of
the lexicon, a minimal grounding set that includes
most of the core and some of the kernel, leav-
ing a set of satellites in the periphery. This to-
pography, reproduced in Figure 1, has been found
in the way dictionary entries use words to define
one another. In networks of dictionary defini-
tions, the core component tends to form a strongly
connected component (SCC) leaving satellites in
smaller SCCs with relatively weak links to the
core. This paper explores whether these these
satellites form systematic, cohesive groups and
whether they are observable in natural language.
</bodyText>
<page confidence="0.927362">
1426
</page>
<note confidence="0.9906625">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1426–1434,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.996814">
Figure 1: Dictionary studies have proposed that
</figureCaption>
<bodyText confidence="0.9850275625">
the lexicon consists of a strongly connected core,
around which there is a kernel, an asymmetric
grounding set and satellites. Adapted from (Picard
et al., 2013).
Words with relatively specific definitions within
subjects, referred to as terms in lexicographic re-
search, are apparent in nearly all domains of dis-
course. Here, the goal is to explore structure
among these peripheral terms without a dictio-
nary. To do this, a method based on commu-
nity detection in textual co-occurrence networks
is developed. Such graph-based methods have be-
come increasingly popular in a range of language-
related tasks such as word clustering, document
clustering, semantic memory, anaphora resolution
and dependency parsing (see Mihalcea and Radev,
2011 for a review).
This paper seeks to address two important ques-
tions about the observed landscape of the lexicon
in natural language: to investigate whether satel-
lite clusters found in dictionaries can be observed
in text, and more importantly, to explore whether
statistical information in co-occurrence networks
can elucidate this peripheral structure in the lexi-
con. We frame these questions as the task of ex-
tracting clusters of related terms. If satellites are
systematically organized, then we can expect to
find cohesive clusters in this region. Moreover, if
the networked structure of dictionary entries sup-
ports the landscape in Figure 1, a similar structure
may be present in co-occurrence patterns in natu-
ral text.
</bodyText>
<sectionHeader confidence="0.94851" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.9999664">
Word clustering, as a means to explore underly-
ing lexical structure, should accommodate fuzzy
and potentially contradictory notions of similarity.
For example, red and green are at once similar,
being colors, but as colors, they are very differ-
ent. Alternatively, the words car, fast, wheel, ex-
port and motorists share a thematic similarity in
their relation to automobiles. One conception of
word clustering is to construct a thesaurus of syn-
onyms (Calvo et al., 2005), but clustering could
allow other lexical semantic relationships. One
such database, WordNet, defines specific seman-
tic relationships and has been used to group words
according to explicit measures of relatedness and
similarity (Miller, 1995; Pedersen et al., 2004).
Distributional, corpus-based techniques that de-
fine words as feature vectors (eg. word-document
co-occurrences), can address many limitations of
manually created lexicons (see Turney et al., 2010
for a review). Clustering nouns by argument struc-
ture can uncover naturally related objects (Hin-
dle, 1990) and spectral methods can relate dis-
tinct classes of nouns with certain kinds of verbs
to induce selectional preferences (Resnik, 1997;
Sun and Korhonen, 2009; Wilks, 1975) and assist
metaphor processing (Shutova et al., 2013).
A pervasive weakness of many existing ap-
proaches to word-clustering, is an underlying pri-
oritization of frequent words. To help address
this sparsity, many models collapse words into
stems, preclude uncommon words, or underesti-
mate the relevance of infrequent words (Dagan
et al., 1999). Probabilistic topic models have
emerged as a uniquely flexible kind of word-
clustering used in content analysis (Steyvers and
Griffiths, 2007), text classification (Wei and Croft,
2006) and provide an extensible framework to ad-
dress other tasks (Blei, 2012). Because the struc-
ture of satellite terms is not likely to rely on spe-
cific (much less consistent) lexical semantic re-
lationships, we adopt a measure of semantic co-
herence, commonly used to qualify the results of
topic models, as an indirect measure of what peo-
ple tend to view as a cohesive set of words. This
measure, which is defined in the next section, is
particularly attractive because it is corpus-based,
does not assume any specific semantic relationship
and correlates with expert evaluations (Mimno et
al., 2011; Newman et al., 2010). Using semantic
coherence provides a way of measuring the qual-
</bodyText>
<page confidence="0.989859">
1427
</page>
<bodyText confidence="0.992840461538462">
ity of word-associations without appeal to a dic-
tionary or assuming rigid relationships among the
clustered words.
The first step is to construct a co-occurrence
graph from which communities are extracted.
Then the centrality of each word is computed
within a community to generate cluster-specific
rankings. The goal is not to categorize words
into classes, nor to provide partitions that sepa-
rate associated words across a corpus. Instead, the
method is designed to extract qualifiable sets of
specialist terms found in arbitrary text. Crucially,
the method is designed to require no document
structure and minimal pre-processing: stop-words
and non-words are not removed and no phrasal,
sentence or document structure is required. Al-
though stemming or lemmatization could pro-
vide more stream-lined interpretations, the mini-
mal pre-processing allows the method to operate
efficiently on large amounts of unstructured text
of any language.
Co-occurrence networks have been used in a
variety of NLP applications, the basic idea be-
ing to construct a graph where proximate words
are connected. Typically, words are connected
if they are observed in an n-word window. We
set this window to a symmetric 7 words on ei-
ther side of the target and did not use any weight-
ing1. In the resulting network, edge frequen-
cies are set to the number of times the given co-
occurrence is observed. The resulting networks
are typically quite dense and exhibit small-world
structure where most word-pairs are only a few
edges apart (Baronchelli et al., 2013; Ferror i Can-
cho and Sol´e, 2001). To explore the effect of
this density, different minimum node- and edge-
frequencies were tested (analogous to the word-
and co-occurrence frequencies in text). It was
found that not setting any thresholds provided the
best results (see Figure 2), supporting our minimal
pre-processing approach.
To extract clusters from the co-occurrence ma-
trix, the Infomap community detection algorithm
was used. Infomap is an information-theoretic
method that optimizes a compression dictionary
using it to describe flow through connected nodes
(Rosvall and Bergstrom, 2008). By minimizing a
description of this flow, the algorithm can also ex-
tract nested communities (Rosvall and Bergstrom,
17 was found to be the optimal window-size in terms of
coherence. These preliminary results are available at knowl-
edgelab.org/docs/coherent clusters-data.xls.
</bodyText>
<table confidence="0.99685475">
Corpus Docs Tokens Nodes Edges
TASA 38,972 10.7M 58,357 1,319,534
NIPS 3,742 5.2M 28,936 1,612,659
enTenTen 92,327 72.2M 69,745 7,721,413
</table>
<tableCaption confidence="0.999864">
Table 1: Co-occurrence networks of each corpus.
</tableCaption>
<bodyText confidence="0.999992576923077">
2011). In our experiments, we used the co-
occurrence frequencies as edge-weights and ran
50 trials for each run of the algorithm. Co-
occurrence networks tended to form one mono-
lithic community, corresponding to the lexicon’s
core SCC, surrounded by a number of smaller
communities. The monolithic community is dis-
carded out-right, as it represents the core of the
lexicon where few specialist terms reside. As we
will see, the community detection algorithm nat-
urally identifies this SCC, distinguishing satellite
clusters of terminology. Though we do not explore
its effect, the sensitivity of Infomap can be tuned
to vary the relative size of the core SCC compared
to the satellites, effectively allowing less modular
communities to be considered satellites.
To compare and interpret the resulting clus-
ters, various measures of centrality were tested for
ranking words within their communities. The goal
of this ranking is to find words that typify or de-
fine their community without assuming its under-
lying semantics. The results in the next section
show that a number of common centrality mea-
sures work comparably well for this task. The fi-
nal output of the system is a set of communities,
in which words are ranked by their centrality.
</bodyText>
<sectionHeader confidence="0.999078" genericHeader="method">
3 Results &amp; Analysis
</sectionHeader>
<bodyText confidence="0.999974235294118">
Three corpora were used for evaluation: the
TASA, NIPS and enTenTen collections. TASA
consists of paragraph-length excerpts from high-
school level, American English texts (Landauer
and Dumais, 1997). The NIPS collection contains
17 volumes of annual proceedings from the con-
ference of the same name. The enTenTen corpus
is a web-based collection of text-heavy, English
web-sites. Table 1 summarizes the collections and
their co-occurrence networks.
The extracted communities, which consist of
word-centrality pairs, are similarly structured to
the output of topic models. Because appeals to
human judgement are expensive and can introduce
issues of consistency (Chang et al., 2009; Hu et al.,
2011), a corpus-based measure of semantic coher-
ence has been proposed (Mimno et al., 2011). Co-
</bodyText>
<page confidence="0.960408">
1428
</page>
<bodyText confidence="0.965163133333333">
herence is used as a proxy for human judgments.
A general form of semantic coherence can be de-
fined as the mean pair-wise similarity over the top
n words in a topic or cluster t
S(wi, wj)
where S is a symmetric measure of similarity.
Newman, et al. (2010) surveyed a number of simi-
larity metrics and found that mean point-wise mu-
tual information (PMI) correlated best to human
judgements. PMI is a commonly used measure of
how much more information co-occurring words
convey together compared to their independent
contributions (Church and Hanks, 1990; Bouma,
2009). Using PMI as S, we can define a version of
coherence, known as UCI Coherence:
</bodyText>
<equation confidence="0.831368">
log p(wi, wj) p(wi)p(wj)
</equation>
<bodyText confidence="0.977191125">
where p(w) is estimated as relative frequency in
a corpus: �f(w)
i f(wi). Using coherence to optimize
topic models, Mimno et al. (2011) found that a
simplified measure, termed UMass Coherence, is
more strongly correlated to human judgments than
CUCI. For topic t, CUMass is defined as follows:
where D(w) is the number of documents con-
taining w, and D(w, w&apos;) is the number of doc-
uments containing both w and w&apos;. Note that D
relies crucially on document segmentation in the
reference corpus, which is not encoded in the co-
occurrence networks derived by the method de-
scribed above. Thus, though the networks be-
ing analyzed and the coherence scores are both
based on co-occurrence information, they are dis-
tinct from one another. Following convention,
we compute coherence for the top 10 words in a
given community. CUMass was used as the mea-
sure of semantic coherence. and D was computed
over the TASA corpus, which means the resulting
scores are not directly comparable to (Mimno et
al., 2011), though comparisons to other published
results are provided below.
</bodyText>
<subsectionHeader confidence="0.9486595">
3.1 Ranking Functions &amp; Frequency
Thresholds
</subsectionHeader>
<bodyText confidence="0.999620074074074">
After communities are extracted from the co-
occurrence graph, words are ranked by their cen-
trality in a community. Six centrality measures
were tested as ranking functions: degree centrality,
closeness centrality, eigenvector centrality, Page-
rank, hub-score and authority-score (Friedl et al.,
2010). Degree centrality uses a node’s degree
as its centrality under the assumption that highly
connected nodes are central. Closeness centrality
measures the average distance between a node and
all other nodes, promoting nodes that are “close”
to the rest of the network. Eigenvector centrality
favors well-connected nodes that are themselves
connected to well-connected nodes. Pagerank is
similar to eigenvector centrality, but also promotes
nodes that mediate connections between strongly
connected nodes. Hub and authority scores mea-
sure interconnectedness (hubs) and connectedness
to interconnected nodes (authorities). Figure 2
shows the average coherence, across all commu-
nities extracted from the TASA corpus, for each
centrality measure. The average coherence scores
are highest using hub-score, though not signifi-
cantly better than auth-score, eigenvector central-
ity or closeness centrality. In the results that fol-
low, hub-scores were used to rank nodes within
communities.
</bodyText>
<figureCaption confidence="0.961585">
Figure 2: Mean coherence for six centrality mea-
sures. Error-bars are ±2 SE of the mean.
</figureCaption>
<figure confidence="0.984670555555555">
1 n
C(t) = n (wi,wj)∈t
i&lt;j
1 n
CUCI(t) = (wi,wj)∈t
n i&lt;j
1 n D(wi, wj) + 1
CUMass(t) = (wi,wj)∈t log
n i&lt;j D(wj)
</figure>
<page confidence="0.986111">
1429
</page>
<bodyText confidence="0.939765916666667">
Imposing minimum node and edge frequencies
in the co-occurrence graph was also tested. How-
ever, applying no thresholds provided the high-
est average coherence. Figure 3 shows the aver-
age coherence for eight threshold configurations.
Though we used the TASA corpus for these tests,
we have no reason to believe the results would dif-
fer significantly for the other corpora.
Figure 3: Mean coherence for different mini-
mum node and edge frequencies, corresponding
to thresholds for word and co-occurrence counts.
Error-bars are ±2 SE of the mean.
</bodyText>
<subsectionHeader confidence="0.998626">
3.2 Community Coherence
</subsectionHeader>
<bodyText confidence="0.99976045">
Table 2 shows three communities of specialist
terms extracted from each text collection, with
their normalized hub-scores. Normalizing the
scores preserves their rank-ordering and provides
an indication of relative centrality within the com-
munity itself. For example, compare the first
and last words from the top TASA and NIPS
clusters: the difference between thou and craven
(TASA) is considerably more than model and net-
work (NIPS). In general, higher ranked words ap-
pear to typify their communities, with words like
model, university and nuclear in the NIPS ex-
amples. These clusters are typical of those pro-
duced by the method, though in some cases, the
communities contain less than 10 terms and were
not included in the coherence analysis. Note that
these clusters are not systematic in any lexical se-
mantic sense, though in almost every case there
are discernible thematic relations (middle-English
words, Latin America and seafood in TASA).
</bodyText>
<table confidence="0.999389838709678">
TASA NIPS enTenTen
thou 1.00 model 1.00 cortex 1.00
shalt 0.72 learning 0.99 prefrontal 0.88
hast 0.49 data 0.96 anterior 0.41
thyself 0.26 neural 0.94 cingulate 0.33
dost 0.24 using 0.85 medulla 0.28
wilt 0.24 network 0.85 parietal 0.13
canst 0.12 training 0.73 insula 0.13
knowest 0.10 algorithm 0.66 cruciate 0.11
mayest 0.10 function 0.63 striatum 0.11
craven 0.01 networks 0.62 ventral 0.10
peru 1.00 university 1.00 pradesh 1.00
ecuador 0.84 science 0.85 andhra 0.67
bolivia 0.80 computer 0.83 madhya 0.56
argentina 0.67 department 0.74 uttar 0.50
paraguay 0.54 engineering 0.30 bihar 0.21
chile 0.52 report 0.30 rajasthan 0.19
venezuela 0.48 technical 0.29 maharashtra 0.16
uruguay 0.28 institute 0.26 haryana 0.12
lima 0.17 abstract 0.25 himachal 0.10
parana 0.11 california 0.23 arunachal 0.04
clams 1.00 nuclear 1.00 cilia 1.00
crabs 0.87 weapons 0.66 peristomal 0.73
oysters 0.87 race 0.57 stalk 0.62
crab 0.67 countries 0.40 trochal 0.51
lobsters 0.66 rights 0.37 vorticella 0.35
shrimp 0.62 india 0.27 campanella 0.32
hermit 0.50 russia 0.26 hairlike 0.17
mussels 0.27 philippines 0.26 swimmers 0.15
lice 0.23 brazil 0.25 epistylis 0.12
scallops 0.20 waste 0.22 telotroch 0.11
</table>
<tableCaption confidence="0.969921">
Table 2: Sample clusters from the TASA, NIPS
</tableCaption>
<bodyText confidence="0.999397347826087">
and enTenTen collections. Shown are the clusters’
top ten words, ranked by their normalized hub-
score within the community. Note the differences
in hub-score distributions between clusters.
Figure 4 shows the average coherence for our
method, compared to that of a 20-topic latent
Dirichlet allocation (LDA) model fit to the same
corpora. Results from an LDA model fit to our
corpora, as well as from a sample of published
topics, are provided as a baseline to calibrate read-
ers’ intuitions about coherence2. Although topics
from LDA do not necessarily consist of special-
ist terms those in the current model, the expec-
tation of coherence remains: probable or central
words should comprise a cohesive group. In every
case, coherence is calculated over the top 10 words
ranked using within-community hub-scores, for
every community of 10 or more words. The results
show that LDA provides relatively consistent co-
herence across collections, though with generally
more variance than the communities of specialist
terms. The term clusters are more coherent for the
enTenTen collection than the others, which may
</bodyText>
<footnote confidence="0.9739255">
2Coherence was computed for the published results with
CUMass using TASA as the reference corpus.
</footnote>
<page confidence="0.993553">
1430
</page>
<bodyText confidence="0.8630385">
be due to its larger size. This up-tick on the largest
corpus may have to do with the proportional size
of the monolithic community for the less struc-
tured documents in enTenTen. Figure 5 depicts
how the proportional size of the core would effect
the number and size of satellite clusters. It was
found that the largest community (the core SCC)
comprised 95% of TASA, 90% of NIPS and 97%
of enTenTen. It may be that specialized language
will have a proportionally smaller core and more
satellite communities, whereas more general lan-
guage will have a larger core and fewer satellites.
A critical question remains as to whether the
method is actually observing the core-periphery
structure of the lexicon or if it is an artifact. To
test this, the frequencies of words in satellite com-
munities were compared to those in the monolithic
cases. If the monolithic community does indeed
correspond to the core proposed in Figure 1, words
in the satellites should have significantly lower fre-
quencies. Indeed, the monolithic community in
every corpus contained words that were signifi-
cantly more frequent than those in the communi-
ties (Wilcoxon rank-sum test; Table 3). Taken with
Figure 4: Mean coherence (CUmass) for satellite
clusters and topics from LDA on the TASA, NIPS
and enTenTen collections (top). Also shown are
the mean coherence of topics found in published
models (LDA, a dynamic topic model, DTM and a
correlated topic model, CTM; bottom). Error-bars
are ±2 SE of the mean.
the coherence scores, these results show that there
is coherent structure in the periphery of the lexi-
con, that can be extracted from unstructured text.
</bodyText>
<figureCaption confidence="0.4584756">
Figure 5: A proportionally larger core SCC (right)
would force satellite communities to be smaller,
less numerous and more isolated. Alternatively,
with a small core (left), satellite communities
would be more numerous and prominent.
</figureCaption>
<table confidence="0.98566875">
Corpus mean f� mean f3 W df
TASA 112.3 7.3 39985454 40895
NIPS 211.5 10.7 28342663 25077
enTenTen 365.1 15.9 246095083 72695
</table>
<tableCaption confidence="0.997694">
Table 3: Comparison of frequency for core words,
</tableCaption>
<bodyText confidence="0.96253825">
fc, found in the monolithic community and spe-
cialist terms, fs, found in the satellite communities
(Wilcoxon rank-sum test). All differences were
significant at p &lt; 0.001.
</bodyText>
<sectionHeader confidence="0.998843" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.99995025">
The results of our method show that outlying
structure in the lexicon can be extracted directly
from large collections of unstructured text. The
lexicon’s topography, previously explored in dic-
tionary studies, contains modular groups of satel-
lite terms that are observable without appeal to ex-
ternal resources or document structure and with
minimal normalization. The contribution of this
method is two-fold: it confirms the structure of the
observed lexicon is similar to that apparent in the
organization of dictionaries (Picard et al., 2013).
Second, it offers a tractable, reliable means of ex-
tracting and summarizing structure in the fringes
of the lexicon.
The output of the model developed here is sim-
ilar to topic models, but with some important
differences. Topic models produce a probability
distribution over words to define a topic, which
can be summarized by the top 10 to 20 most
likely words. Instead of probabilities, the within-
</bodyText>
<page confidence="0.981603">
1431
</page>
<bodyText confidence="0.999993853658537">
community hub-scores were used to rank words in
each cluster. This means that the actual structure
of the community (to which topics have no ana-
logue) is responsible for producing the scores that
rate words’ internal relevance. Another crucial
difference is that topic size from a single sampling
iteration tends to correlate with coherence (Mimno
et al., 2011), but in the current method, there is
no correlation between cluster size and coherence
(p = 0.98). The other important difference is that
whereas topic models produce a topic-document
mixture that can be used for posterior inference, to
perform such inference with our method, the out-
put would have to be used indirectly.
One understated strength of the community
detection method is the minimal required pre-
processing. Whereas many solutions in NLP
(including topic models) require document seg-
mentation, lexical normalization and statistical
normalizations on the co-occurrence matrix it-
self, the only variable in our method is the co-
occurrence window size. However, lemmatiza-
tion (or stemming) could help collapse morpho-
syntactic variation among terms in the results,
but stop-word removal, sentence segmentation and
TF-IDF weighting appear unnecessary. What
might be most surprising given the examples in Ta-
ble 2 is that word-document occurrence informa-
tion is not used at all. This makes the the method
particularly useful for large collections with little
to no structure.
One question overlooked in our analysis con-
cerns the effect the core has on the satellites. It
could be that the proportional size of a collection’s
core is indicative of the degree of specialist ter-
minology contained in the collection. Also, the
raw number of satellite communities might indi-
cate the level of diversity in a corpus. Addressing
these questions could yield measures of previously
vague and latent variables like specialty or topi-
cal diversity, without employing a direct semantic
analysis. By measuring a collection’s core size,
relative to its satellites, one could also use mea-
sure changes in specialization. The Infomap algo-
rithm could accommodate such an experiment: by
varying the threshold of density that constitutes a
community, the core could be made smaller, yield-
ing more satellites, the coherence of which could
be compared to those reported here. One could ex-
amine the position of individual words in the satel-
lite(s) to explore what features signal important,
emerging and dying terms or to track diachronic
movement of terms like computer or gene from the
specialized periphery to core of the lexicon.
At the level of inter-related term clusters, there
are likely important or central groups that influ-
ence other satellites. There is no agreed upon mea-
sure of “community centrality” in a network sense
(Eaton and Mansbach, 2012). One way to measure
the importance of a community would be to use
significance testing on the internal link mass com-
pared to the external (Csardi and Nepusz, 2006).
However, this approach discards some factors for
which one might want to account, such as cen-
trality in the network of communities and their
composition. Future work could seek to com-
bine graph-theoretic notions of centrality and in-
tuitions about the defining features of term clus-
ters. Another avenue for future research would
be to use mixed membership community detection
(Gopalan and Blei, 2013). Allowing terms to be
represented in more than one community would
accommodate words like nuclear, that might be
found relating to weaponry, energy production and
physics research at the same time. Using co-
occurrence networks to extract clusters of special-
ist terms, though an important task, is perhaps only
a starting point for exploring the observed lexicon.
Network-based analysis of language offers a gen-
eral and powerful potential to address a range of
questions about the lexicon, other NLP tasks and
language more generally.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999833166666667">
Thanks to E. Duede and three reviewers for com-
ments on earlier versions of this manuscript. This
work was supported by a grant from the Templeton
Foundation to the Metaknowledge Research Net-
work and grant #1158803 from the National Sci-
ence Foundation.
</bodyText>
<sectionHeader confidence="0.998611" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9859888">
Andrea Baronchelli, Ramon Ferrer i Cancho, Ro-
mualdo Pastor-Satorras, Nick Chater, and Morten H.
Christiansen. 2013. Networks in cognitive science.
Trends in cognitive sciences, 17(7):348–360.
David M. Blei. 2012. Probabilistic topic models.
Communications of the ACM, 55(4):77–84.
Gerlof Bouma. 2009. Normalized (pointwise) mutual
information in collocation extraction. Proceedings
of the German Society for Computational Linguis-
tics &amp; Language Technology, pages 31–40.
</reference>
<page confidence="0.953248">
1432
</page>
<reference confidence="0.994313330275229">
Hiram Calvo, Alexander Gelbukh, and Adam Kilgar-
riff. 2005. Distributional thesaurus versus word-
net: A comparison of backoff techniques for unsu-
pervised pp attachment. In Computational Linguis-
tics and Intelligent Text Processing, pages 177–188.
Springer.
Jonathan Chang, Jordan Boyd-Graber, Sean Gerrish,
Chong Wang, and David M. Blei. 2009. Reading
tea leaves: How humans interpret topic models. In
Neural Information Processing Systems, volume 22,
pages 288–296.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational linguistics, 16(1):22–29.
Gabor Csardi and Tamas Nepusz. 2006. The igraph
software package for complex network research. In-
terJournal, Complex Systems:1695.
Ido Dagan, Lillian Lee, and Fernando C.N. Pereira.
1999. Similarity-based models of word cooccur-
rence probabilities. Machine Learning, 34(1-3):43–
69.
Eric Eaton and Rachael Mansbach. 2012. A spin-glass
model for semi-supervised community detection. In
Association for the Advancement of Artificial Intel-
ligence.
Ramon Ferror i Cancho and Richard V. Sol´e. 2001.
The small world of human language. Proceedings
of the Royal Society of London. Series B: Biological
Sciences, 268(1482):2261–2265.
Dipl-Math Bettina Friedl, Julia Heidemann, et al.
2010. A critical review of centrality measures in
social networks. Business &amp; Information Systems
Engineering, 2(6):371–385.
Prem K. Gopalan and David M. Blei. 2013. Efficient
discovery of overlapping communities in massive
networks. Proceedings of the National Academy of
Sciences, 110(36):14534–14539.
Donald Hindle. 1990. Noun classification from
predicate-argument structures. In Proceedings of the
28th annual meeting on Association for Computa-
tional Linguistics, pages 268–275.
Yuening Hu, Jordan Boyd-Graber, and Brianna Sati-
noff. 2011. Interactive topic modeling. In Pro-
ceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies-Volume 1, pages 248–257.
Junko Itˆo and Armin Mester. 1995. The core-periphery
structure of the lexicon and constraints on rerank-
ing. University of Massachusetts occasional papers
in linguistics, 18:181–209.
Thomas K. Landauer and Susan T. Dumais. 1997.
A solution to plato’s problem: The latent semantic
analysis theory of acquisition, induction, and rep-
resentation of knowledge. Psychological review,
104(2):211.
A. Blondin Mass´e, Guillaume Chicoisne, Yassine Gar-
gouri, Stevan Harnad, Olivier Picard, and Odile
Marcotte. 2008. How is meaning grounded in
dictionary definitions? In Proceedings of the 3rd
Textgraphs Workshop on Graph-Based Algorithms
for Natural Language Processing, pages 17–24.
Rada Mihalcea and Dragomir Radev. 2011. Graph-
based natural language processing and information
retrieval. Cambridge University Press.
George A. Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.
David Mimno, Hanna M. Wallach, Edmund Talley,
Miriam Leenders, and Andrew McCallum. 2011.
Optimizing semantic coherence in topic models. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 262–
272.
David Newman, Jey Han Lau, Karl Grieser, and Tim-
othy Baldwin. 2010. Automatic evaluation of
topic coherence. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 100–108.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity: measuring the re-
latedness of concepts. In Demonstration Papers at
HLT-NAACL 2004, pages 38–41.
Olivier Picard, M´elanie Lord, Alexandre Blondin-
Mass´e, Odile Marcotte, Marcos Lopes, and Stevan
Harnad. 2013. Hidden structure and function in the
lexicon. NLPCS 2013: 10th International Workshop
on Natural Language Processing and Cognitive Sci-
ence, Marseille, France.
Philip Resnik. 1997. Selectional preference and sense
disambiguation. In Proceedings of the ACL SIGLEX
Workshop on Tagging Text with Lexical Semantics:
Why, What, and How, pages 52–57.
Martin Rosvall and Carl T. Bergstrom. 2008. Maps of
random walks on complex networks reveal commu-
nity structure. Proceedings of the National Academy
of Sciences, 105(4):1118–1123.
Martin Rosvall and Carl T. Bergstrom. 2011. Mul-
tilevel compression of random walks on networks
reveals hierarchical organization in large integrated
systems. PloS one, 6(4):e18209.
Ekaterina Shutova, Simone Teufel, and Anna Korho-
nen. 2013. Statistical metaphor processing. Com-
putational Linguistics, 39(2):301–353.
John Sinclair. 1996. The empty lexicon. International
Journal of Corpus Linguistics, 1(1):99–119.
Mark Steyvers and Tom Griffiths. 2007. Probabilistic
topic models. Handbook of latent semantic analysis,
427(7):424–440.
</reference>
<page confidence="0.595142">
1433
</page>
<reference confidence="0.998582235294118">
Lin Sun and Anna Korhonen. 2009. Improving verb
clustering with automatically acquired selectional
preferences. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language
Processing: Volume 2-Volume 2, pages 638–647.
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37(1):141–188.
Xing Wei and Bruce Croft. 2006. Lda-based docu-
ment models for ad-hoc retrieval. In Proceedings
of the 29th annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, pages 178–185.
Yorick Wilks. 1975. A preferential, pattern-seeking,
semantics for natural language inference. Artificial
Intelligence, 6(1):53–74.
</reference>
<page confidence="0.995069">
1434
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.727174">
<title confidence="0.999485">Extracting Clusters of Specialist Terms from Unstructured Text</title>
<author confidence="0.958291">Aaron</author>
<affiliation confidence="0.917117333333333">Computation University of Chicago, IL,</affiliation>
<email confidence="0.9996">gerow@uchicago.edu</email>
<abstract confidence="0.99960072">Automatically identifying related specialist terms is a difficult and important task required to understand the lexical structure of language. This paper develops a corpus-based method of extracting coherent clusters of satellite terminology — terms on the edge of the lexicon — usco-occurrence networks of unstructext. Term clusters are fied by extracting communities in the cooccurrence graph, after which the largest is discarded and the remaining words are ranked by centrality within a community. The method is tractable on large corpora, requires no document structure and minimal normalization. The results suggest that the model is able to extract coherent groups of satellite terms in corpora with varying size, content and structure. The findings also confirm that language consists of a densely connected core (observed in dictionaries) and systematic, semantically coherent groups of terms at the edges of the lexicon.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrea Baronchelli</author>
</authors>
<title>Ramon Ferrer i Cancho, Romualdo Pastor-Satorras, Nick Chater,</title>
<date>2013</date>
<pages>17--7</pages>
<location>and</location>
<marker>Baronchelli, 2013</marker>
<rawString>Andrea Baronchelli, Ramon Ferrer i Cancho, Romualdo Pastor-Satorras, Nick Chater, and Morten H. Christiansen. 2013. Networks in cognitive science. Trends in cognitive sciences, 17(7):348–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
</authors>
<title>Probabilistic topic models.</title>
<date>2012</date>
<journal>Communications of the ACM,</journal>
<volume>55</volume>
<issue>4</issue>
<contexts>
<context position="7168" citStr="Blei, 2012" startWordPosition="1102" endWordPosition="1103">ilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in the next section, is particularly attractive because it is corpus-based, does not assume any specific semantic relationship and correlates with expert evaluations (Mimno et al., 2011; Newman et al., 2010). Using semantic coherence provides a way of measuring </context>
</contexts>
<marker>Blei, 2012</marker>
<rawString>David M. Blei. 2012. Probabilistic topic models. Communications of the ACM, 55(4):77–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerlof Bouma</author>
</authors>
<title>Normalized (pointwise) mutual information in collocation extraction.</title>
<date>2009</date>
<booktitle>Proceedings of the German Society for Computational Linguistics &amp; Language Technology,</booktitle>
<pages>31--40</pages>
<contexts>
<context position="12986" citStr="Bouma, 2009" startWordPosition="2025" endWordPosition="2026">has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together compared to their independent contributions (Church and Hanks, 1990; Bouma, 2009). Using PMI as S, we can define a version of coherence, known as UCI Coherence: log p(wi, wj) p(wi)p(wj) where p(w) is estimated as relative frequency in a corpus: �f(w) i f(wi). Using coherence to optimize topic models, Mimno et al. (2011) found that a simplified measure, termed UMass Coherence, is more strongly correlated to human judgments than CUCI. For topic t, CUMass is defined as follows: where D(w) is the number of documents containing w, and D(w, w&apos;) is the number of documents containing both w and w&apos;. Note that D relies crucially on document segmentation in the reference corpus, whic</context>
</contexts>
<marker>Bouma, 2009</marker>
<rawString>Gerlof Bouma. 2009. Normalized (pointwise) mutual information in collocation extraction. Proceedings of the German Society for Computational Linguistics &amp; Language Technology, pages 31–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiram Calvo</author>
<author>Alexander Gelbukh</author>
<author>Adam Kilgarriff</author>
</authors>
<title>Distributional thesaurus versus wordnet: A comparison of backoff techniques for unsupervised pp attachment.</title>
<date>2005</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>177--188</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5826" citStr="Calvo et al., 2005" startWordPosition="901" endWordPosition="904">ture of dictionary entries supports the landscape in Figure 1, a similar structure may be present in co-occurrence patterns in natural text. 2 Method Word clustering, as a means to explore underlying lexical structure, should accommodate fuzzy and potentially contradictory notions of similarity. For example, red and green are at once similar, being colors, but as colors, they are very different. Alternatively, the words car, fast, wheel, export and motorists share a thematic similarity in their relation to automobiles. One conception of word clustering is to construct a thesaurus of synonyms (Calvo et al., 2005), but clustering could allow other lexical semantic relationships. One such database, WordNet, defines specific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can rela</context>
</contexts>
<marker>Calvo, Gelbukh, Kilgarriff, 2005</marker>
<rawString>Hiram Calvo, Alexander Gelbukh, and Adam Kilgarriff. 2005. Distributional thesaurus versus wordnet: A comparison of backoff techniques for unsupervised pp attachment. In Computational Linguistics and Intelligent Text Processing, pages 177–188. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Jordan Boyd-Graber</author>
<author>Sean Gerrish</author>
<author>Chong Wang</author>
<author>David M Blei</author>
</authors>
<title>Reading tea leaves: How humans interpret topic models.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems,</booktitle>
<volume>22</volume>
<pages>288--296</pages>
<contexts>
<context position="12309" citStr="Chang et al., 2009" startWordPosition="1907" endWordPosition="1910">TenTen collections. TASA consists of paragraph-length excerpts from highschool level, American English texts (Landauer and Dumais, 1997). The NIPS collection contains 17 volumes of annual proceedings from the conference of the same name. The enTenTen corpus is a web-based collection of text-heavy, English web-sites. Table 1 summarizes the collections and their co-occurrence networks. The extracted communities, which consist of word-centrality pairs, are similarly structured to the output of topic models. Because appeals to human judgement are expensive and can introduce issues of consistency (Chang et al., 2009; Hu et al., 2011), a corpus-based measure of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together comp</context>
</contexts>
<marker>Chang, Boyd-Graber, Gerrish, Wang, Blei, 2009</marker>
<rawString>Jonathan Chang, Jordan Boyd-Graber, Sean Gerrish, Chong Wang, and David M. Blei. 2009. Reading tea leaves: How humans interpret topic models. In Neural Information Processing Systems, volume 22, pages 288–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<booktitle>Computational linguistics,</booktitle>
<pages>16--1</pages>
<contexts>
<context position="12972" citStr="Church and Hanks, 1990" startWordPosition="2021" endWordPosition="2024">e of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together compared to their independent contributions (Church and Hanks, 1990; Bouma, 2009). Using PMI as S, we can define a version of coherence, known as UCI Coherence: log p(wi, wj) p(wi)p(wj) where p(w) is estimated as relative frequency in a corpus: �f(w) i f(wi). Using coherence to optimize topic models, Mimno et al. (2011) found that a simplified measure, termed UMass Coherence, is more strongly correlated to human judgments than CUCI. For topic t, CUMass is defined as follows: where D(w) is the number of documents containing w, and D(w, w&apos;) is the number of documents containing both w and w&apos;. Note that D relies crucially on document segmentation in the referenc</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Csardi</author>
<author>Tamas Nepusz</author>
</authors>
<title>The igraph software package for complex network research.</title>
<date>2006</date>
<journal>InterJournal, Complex Systems:1695.</journal>
<contexts>
<context position="25781" citStr="Csardi and Nepusz, 2006" startWordPosition="4064" endWordPosition="4067">osition of individual words in the satellite(s) to explore what features signal important, emerging and dying terms or to track diachronic movement of terms like computer or gene from the specialized periphery to core of the lexicon. At the level of inter-related term clusters, there are likely important or central groups that influence other satellites. There is no agreed upon measure of “community centrality” in a network sense (Eaton and Mansbach, 2012). One way to measure the importance of a community would be to use significance testing on the internal link mass compared to the external (Csardi and Nepusz, 2006). However, this approach discards some factors for which one might want to account, such as centrality in the network of communities and their composition. Future work could seek to combine graph-theoretic notions of centrality and intuitions about the defining features of term clusters. Another avenue for future research would be to use mixed membership community detection (Gopalan and Blei, 2013). Allowing terms to be represented in more than one community would accommodate words like nuclear, that might be found relating to weaponry, energy production and physics research at the same time. </context>
</contexts>
<marker>Csardi, Nepusz, 2006</marker>
<rawString>Gabor Csardi and Tamas Nepusz. 2006. The igraph software package for complex network research. InterJournal, Complex Systems:1695.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Lillian Lee</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Similarity-based models of word cooccurrence probabilities.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="6910" citStr="Dagan et al., 1999" startWordPosition="1061" endWordPosition="1064">or a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in t</context>
</contexts>
<marker>Dagan, Lee, Pereira, 1999</marker>
<rawString>Ido Dagan, Lillian Lee, and Fernando C.N. Pereira. 1999. Similarity-based models of word cooccurrence probabilities. Machine Learning, 34(1-3):43– 69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Eaton</author>
<author>Rachael Mansbach</author>
</authors>
<title>A spin-glass model for semi-supervised community detection.</title>
<date>2012</date>
<booktitle>In Association for the Advancement of Artificial Intelligence.</booktitle>
<contexts>
<context position="25617" citStr="Eaton and Mansbach, 2012" startWordPosition="4035" endWordPosition="4038">tutes a community, the core could be made smaller, yielding more satellites, the coherence of which could be compared to those reported here. One could examine the position of individual words in the satellite(s) to explore what features signal important, emerging and dying terms or to track diachronic movement of terms like computer or gene from the specialized periphery to core of the lexicon. At the level of inter-related term clusters, there are likely important or central groups that influence other satellites. There is no agreed upon measure of “community centrality” in a network sense (Eaton and Mansbach, 2012). One way to measure the importance of a community would be to use significance testing on the internal link mass compared to the external (Csardi and Nepusz, 2006). However, this approach discards some factors for which one might want to account, such as centrality in the network of communities and their composition. Future work could seek to combine graph-theoretic notions of centrality and intuitions about the defining features of term clusters. Another avenue for future research would be to use mixed membership community detection (Gopalan and Blei, 2013). Allowing terms to be represented </context>
</contexts>
<marker>Eaton, Mansbach, 2012</marker>
<rawString>Eric Eaton and Rachael Mansbach. 2012. A spin-glass model for semi-supervised community detection. In Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramon Ferror i Cancho</author>
<author>Richard V Sol´e</author>
</authors>
<title>The small world of human language.</title>
<date>2001</date>
<journal>Proceedings of the Royal Society of London. Series B: Biological Sciences,</journal>
<volume>268</volume>
<issue>1482</issue>
<marker>Cancho, Sol´e, 2001</marker>
<rawString>Ramon Ferror i Cancho and Richard V. Sol´e. 2001. The small world of human language. Proceedings of the Royal Society of London. Series B: Biological Sciences, 268(1482):2261–2265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipl-Math Bettina Friedl</author>
<author>Julia Heidemann</author>
</authors>
<title>A critical review of centrality measures in social networks.</title>
<date>2010</date>
<journal>Business &amp; Information Systems Engineering,</journal>
<volume>2</volume>
<issue>6</issue>
<marker>Friedl, Heidemann, 2010</marker>
<rawString>Dipl-Math Bettina Friedl, Julia Heidemann, et al. 2010. A critical review of centrality measures in social networks. Business &amp; Information Systems Engineering, 2(6):371–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prem K Gopalan</author>
<author>David M Blei</author>
</authors>
<title>Efficient discovery of overlapping communities in massive networks.</title>
<date>2013</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>110</volume>
<issue>36</issue>
<contexts>
<context position="26182" citStr="Gopalan and Blei, 2013" startWordPosition="4128" endWordPosition="4131"> centrality” in a network sense (Eaton and Mansbach, 2012). One way to measure the importance of a community would be to use significance testing on the internal link mass compared to the external (Csardi and Nepusz, 2006). However, this approach discards some factors for which one might want to account, such as centrality in the network of communities and their composition. Future work could seek to combine graph-theoretic notions of centrality and intuitions about the defining features of term clusters. Another avenue for future research would be to use mixed membership community detection (Gopalan and Blei, 2013). Allowing terms to be represented in more than one community would accommodate words like nuclear, that might be found relating to weaponry, energy production and physics research at the same time. Using cooccurrence networks to extract clusters of specialist terms, though an important task, is perhaps only a starting point for exploring the observed lexicon. Network-based analysis of language offers a general and powerful potential to address a range of questions about the lexicon, other NLP tasks and language more generally. Acknowledgments Thanks to E. Duede and three reviewers for comment</context>
</contexts>
<marker>Gopalan, Blei, 2013</marker>
<rawString>Prem K. Gopalan and David M. Blei. 2013. Efficient discovery of overlapping communities in massive networks. Proceedings of the National Academy of Sciences, 110(36):14534–14539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>Noun classification from predicate-argument structures.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th annual meeting on Association for Computational Linguistics,</booktitle>
<pages>268--275</pages>
<contexts>
<context position="6396" citStr="Hindle, 1990" startWordPosition="983" endWordPosition="985"> thesaurus of synonyms (Calvo et al., 2005), but clustering could allow other lexical semantic relationships. One such database, WordNet, defines specific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclusterin</context>
</contexts>
<marker>Hindle, 1990</marker>
<rawString>Donald Hindle. 1990. Noun classification from predicate-argument structures. In Proceedings of the 28th annual meeting on Association for Computational Linguistics, pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuening Hu</author>
<author>Jordan Boyd-Graber</author>
<author>Brianna Satinoff</author>
</authors>
<title>Interactive topic modeling.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume</booktitle>
<volume>1</volume>
<pages>248--257</pages>
<contexts>
<context position="12327" citStr="Hu et al., 2011" startWordPosition="1911" endWordPosition="1914">TASA consists of paragraph-length excerpts from highschool level, American English texts (Landauer and Dumais, 1997). The NIPS collection contains 17 volumes of annual proceedings from the conference of the same name. The enTenTen corpus is a web-based collection of text-heavy, English web-sites. Table 1 summarizes the collections and their co-occurrence networks. The extracted communities, which consist of word-centrality pairs, are similarly structured to the output of topic models. Because appeals to human judgement are expensive and can introduce issues of consistency (Chang et al., 2009; Hu et al., 2011), a corpus-based measure of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together compared to their inde</context>
</contexts>
<marker>Hu, Boyd-Graber, Satinoff, 2011</marker>
<rawString>Yuening Hu, Jordan Boyd-Graber, and Brianna Satinoff. 2011. Interactive topic modeling. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 248–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junko Itˆo</author>
<author>Armin Mester</author>
</authors>
<title>The core-periphery structure of the lexicon and constraints on reranking.</title>
<date>1995</date>
<booktitle>University of Massachusetts occasional papers in linguistics,</booktitle>
<pages>18--181</pages>
<marker>Itˆo, Mester, 1995</marker>
<rawString>Junko Itˆo and Armin Mester. 1995. The core-periphery structure of the lexicon and constraints on reranking. University of Massachusetts occasional papers in linguistics, 18:181–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Susan T Dumais</author>
</authors>
<title>A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological review,</journal>
<volume>104</volume>
<issue>2</issue>
<contexts>
<context position="11827" citStr="Landauer and Dumais, 1997" startWordPosition="1836" endWordPosition="1839">ntrality were tested for ranking words within their communities. The goal of this ranking is to find words that typify or define their community without assuming its underlying semantics. The results in the next section show that a number of common centrality measures work comparably well for this task. The final output of the system is a set of communities, in which words are ranked by their centrality. 3 Results &amp; Analysis Three corpora were used for evaluation: the TASA, NIPS and enTenTen collections. TASA consists of paragraph-length excerpts from highschool level, American English texts (Landauer and Dumais, 1997). The NIPS collection contains 17 volumes of annual proceedings from the conference of the same name. The enTenTen corpus is a web-based collection of text-heavy, English web-sites. Table 1 summarizes the collections and their co-occurrence networks. The extracted communities, which consist of word-centrality pairs, are similarly structured to the output of topic models. Because appeals to human judgement are expensive and can introduce issues of consistency (Chang et al., 2009; Hu et al., 2011), a corpus-based measure of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herenc</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Thomas K. Landauer and Susan T. Dumais. 1997. A solution to plato’s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review, 104(2):211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blondin Mass´e</author>
<author>Guillaume Chicoisne</author>
<author>Yassine Gargouri</author>
<author>Stevan Harnad</author>
<author>Olivier Picard</author>
<author>Odile Marcotte</author>
</authors>
<title>How is meaning grounded in dictionary definitions?</title>
<date>2008</date>
<booktitle>In Proceedings of the 3rd Textgraphs Workshop on Graph-Based Algorithms for Natural Language Processing,</booktitle>
<pages>17--24</pages>
<marker>Mass´e, Chicoisne, Gargouri, Harnad, Picard, Marcotte, 2008</marker>
<rawString>A. Blondin Mass´e, Guillaume Chicoisne, Yassine Gargouri, Stevan Harnad, Olivier Picard, and Odile Marcotte. 2008. How is meaning grounded in dictionary definitions? In Proceedings of the 3rd Textgraphs Workshop on Graph-Based Algorithms for Natural Language Processing, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Dragomir Radev</author>
</authors>
<title>Graphbased natural language processing and information retrieval.</title>
<date>2011</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4623" citStr="Mihalcea and Radev, 2011" startWordPosition="710" endWordPosition="713">d satellites. Adapted from (Picard et al., 2013). Words with relatively specific definitions within subjects, referred to as terms in lexicographic research, are apparent in nearly all domains of discourse. Here, the goal is to explore structure among these peripheral terms without a dictionary. To do this, a method based on community detection in textual co-occurrence networks is developed. Such graph-based methods have become increasingly popular in a range of languagerelated tasks such as word clustering, document clustering, semantic memory, anaphora resolution and dependency parsing (see Mihalcea and Radev, 2011 for a review). This paper seeks to address two important questions about the observed landscape of the lexicon in natural language: to investigate whether satellite clusters found in dictionaries can be observed in text, and more importantly, to explore whether statistical information in co-occurrence networks can elucidate this peripheral structure in the lexicon. We frame these questions as the task of extracting clusters of related terms. If satellites are systematically organized, then we can expect to find cohesive clusters in this region. Moreover, if the networked structure of dictiona</context>
</contexts>
<marker>Mihalcea, Radev, 2011</marker>
<rawString>Rada Mihalcea and Dragomir Radev. 2011. Graphbased natural language processing and information retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="6068" citStr="Miller, 1995" startWordPosition="937" endWordPosition="938">otentially contradictory notions of similarity. For example, red and green are at once similar, being colors, but as colors, they are very different. Alternatively, the words car, fast, wheel, export and motorists share a thematic similarity in their relation to automobiles. One conception of word clustering is to construct a thesaurus of synonyms (Calvo et al., 2005), but clustering could allow other lexical semantic relationships. One such database, WordNet, defines specific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approa</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Edmund Talley</author>
<author>Miriam Leenders</author>
<author>Andrew McCallum</author>
</authors>
<title>Optimizing semantic coherence in topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>262--272</pages>
<contexts>
<context position="7691" citStr="Mimno et al., 2011" startWordPosition="1188" endWordPosition="1191">n (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in the next section, is particularly attractive because it is corpus-based, does not assume any specific semantic relationship and correlates with expert evaluations (Mimno et al., 2011; Newman et al., 2010). Using semantic coherence provides a way of measuring the qual1427 ity of word-associations without appeal to a dictionary or assuming rigid relationships among the clustered words. The first step is to construct a co-occurrence graph from which communities are extracted. Then the centrality of each word is computed within a community to generate cluster-specific rankings. The goal is not to categorize words into classes, nor to provide partitions that separate associated words across a corpus. Instead, the method is designed to extract qualifiable sets of specialist ter</context>
<context position="12412" citStr="Mimno et al., 2011" startWordPosition="1925" endWordPosition="1928"> texts (Landauer and Dumais, 1997). The NIPS collection contains 17 volumes of annual proceedings from the conference of the same name. The enTenTen corpus is a web-based collection of text-heavy, English web-sites. Table 1 summarizes the collections and their co-occurrence networks. The extracted communities, which consist of word-centrality pairs, are similarly structured to the output of topic models. Because appeals to human judgement are expensive and can introduce issues of consistency (Chang et al., 2009; Hu et al., 2011), a corpus-based measure of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together compared to their independent contributions (Church and Hanks, 1990; Bouma, 2009). Using PMI as S, we can d</context>
<context position="14083" citStr="Mimno et al., 2011" startWordPosition="2212" endWordPosition="2215">of documents containing both w and w&apos;. Note that D relies crucially on document segmentation in the reference corpus, which is not encoded in the cooccurrence networks derived by the method described above. Thus, though the networks being analyzed and the coherence scores are both based on co-occurrence information, they are distinct from one another. Following convention, we compute coherence for the top 10 words in a given community. CUMass was used as the measure of semantic coherence. and D was computed over the TASA corpus, which means the resulting scores are not directly comparable to (Mimno et al., 2011), though comparisons to other published results are provided below. 3.1 Ranking Functions &amp; Frequency Thresholds After communities are extracted from the cooccurrence graph, words are ranked by their centrality in a community. Six centrality measures were tested as ranking functions: degree centrality, closeness centrality, eigenvector centrality, Pagerank, hub-score and authority-score (Friedl et al., 2010). Degree centrality uses a node’s degree as its centrality under the assumption that highly connected nodes are central. Closeness centrality measures the average distance between a node an</context>
<context position="23178" citStr="Mimno et al., 2011" startWordPosition="3649" endWordPosition="3652">loped here is similar to topic models, but with some important differences. Topic models produce a probability distribution over words to define a topic, which can be summarized by the top 10 to 20 most likely words. Instead of probabilities, the within1431 community hub-scores were used to rank words in each cluster. This means that the actual structure of the community (to which topics have no analogue) is responsible for producing the scores that rate words’ internal relevance. Another crucial difference is that topic size from a single sampling iteration tends to correlate with coherence (Mimno et al., 2011), but in the current method, there is no correlation between cluster size and coherence (p = 0.98). The other important difference is that whereas topic models produce a topic-document mixture that can be used for posterior inference, to perform such inference with our method, the output would have to be used indirectly. One understated strength of the community detection method is the minimal required preprocessing. Whereas many solutions in NLP (including topic models) require document segmentation, lexical normalization and statistical normalizations on the co-occurrence matrix itself, the </context>
</contexts>
<marker>Mimno, Wallach, Talley, Leenders, McCallum, 2011</marker>
<rawString>David Mimno, Hanna M. Wallach, Edmund Talley, Miriam Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 262– 272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Jey Han Lau</author>
<author>Karl Grieser</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic evaluation of topic coherence.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>100--108</pages>
<contexts>
<context position="7713" citStr="Newman et al., 2010" startWordPosition="1192" endWordPosition="1195">06) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in the next section, is particularly attractive because it is corpus-based, does not assume any specific semantic relationship and correlates with expert evaluations (Mimno et al., 2011; Newman et al., 2010). Using semantic coherence provides a way of measuring the qual1427 ity of word-associations without appeal to a dictionary or assuming rigid relationships among the clustered words. The first step is to construct a co-occurrence graph from which communities are extracted. Then the centrality of each word is computed within a community to generate cluster-specific rankings. The goal is not to categorize words into classes, nor to provide partitions that separate associated words across a corpus. Instead, the method is designed to extract qualifiable sets of specialist terms found in arbitrary </context>
<context position="12676" citStr="Newman, et al. (2010)" startWordPosition="1976" endWordPosition="1979">o-occurrence networks. The extracted communities, which consist of word-centrality pairs, are similarly structured to the output of topic models. Because appeals to human judgement are expensive and can introduce issues of consistency (Chang et al., 2009; Hu et al., 2011), a corpus-based measure of semantic coherence has been proposed (Mimno et al., 2011). Co1428 herence is used as a proxy for human judgments. A general form of semantic coherence can be defined as the mean pair-wise similarity over the top n words in a topic or cluster t S(wi, wj) where S is a symmetric measure of similarity. Newman, et al. (2010) surveyed a number of similarity metrics and found that mean point-wise mutual information (PMI) correlated best to human judgements. PMI is a commonly used measure of how much more information co-occurring words convey together compared to their independent contributions (Church and Hanks, 1990; Bouma, 2009). Using PMI as S, we can define a version of coherence, known as UCI Coherence: log p(wi, wj) p(wi)p(wj) where p(w) is estimated as relative frequency in a corpus: �f(w) i f(wi). Using coherence to optimize topic models, Mimno et al. (2011) found that a simplified measure, termed UMass Coh</context>
</contexts>
<marker>Newman, Lau, Grieser, Baldwin, 2010</marker>
<rawString>David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 100–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity: measuring the relatedness of concepts. In Demonstration Papers at HLT-NAACL</title>
<date>2004</date>
<pages>38--41</pages>
<contexts>
<context position="6092" citStr="Pedersen et al., 2004" startWordPosition="939" endWordPosition="942">tradictory notions of similarity. For example, red and green are at once similar, being colors, but as colors, they are very different. Alternatively, the words car, fast, wheel, export and motorists share a thematic similarity in their relation to automobiles. One conception of word clustering is to construct a thesaurus of synonyms (Calvo et al., 2005), but clustering could allow other lexical semantic relationships. One such database, WordNet, defines specific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering,</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity: measuring the relatedness of concepts. In Demonstration Papers at HLT-NAACL 2004, pages 38–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Picard</author>
<author>M´elanie Lord</author>
<author>Alexandre BlondinMass´e</author>
<author>Odile Marcotte</author>
<author>Marcos Lopes</author>
<author>Stevan Harnad</author>
</authors>
<date>2013</date>
<booktitle>Hidden structure and function in the lexicon. NLPCS 2013: 10th International Workshop on Natural Language Processing and Cognitive Science,</booktitle>
<location>Marseille, France.</location>
<marker>Picard, Lord, BlondinMass´e, Marcotte, Lopes, Harnad, 2013</marker>
<rawString>Olivier Picard, M´elanie Lord, Alexandre BlondinMass´e, Odile Marcotte, Marcos Lopes, and Stevan Harnad. 2013. Hidden structure and function in the lexicon. NLPCS 2013: 10th International Workshop on Natural Language Processing and Cognitive Science, Marseille, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional preference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How,</booktitle>
<pages>52--57</pages>
<contexts>
<context position="6530" citStr="Resnik, 1997" startWordPosition="1005" endWordPosition="1006">t, defines specific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framewo</context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>Philip Resnik. 1997. Selectional preference and sense disambiguation. In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What, and How, pages 52–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Rosvall</author>
<author>Carl T Bergstrom</author>
</authors>
<title>Maps of random walks on complex networks reveal community structure.</title>
<date>2008</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>105</volume>
<issue>4</issue>
<contexts>
<context position="9909" citStr="Rosvall and Bergstrom, 2008" startWordPosition="1536" endWordPosition="1539">ges apart (Baronchelli et al., 2013; Ferror i Cancho and Sol´e, 2001). To explore the effect of this density, different minimum node- and edgefrequencies were tested (analogous to the wordand co-occurrence frequencies in text). It was found that not setting any thresholds provided the best results (see Figure 2), supporting our minimal pre-processing approach. To extract clusters from the co-occurrence matrix, the Infomap community detection algorithm was used. Infomap is an information-theoretic method that optimizes a compression dictionary using it to describe flow through connected nodes (Rosvall and Bergstrom, 2008). By minimizing a description of this flow, the algorithm can also extract nested communities (Rosvall and Bergstrom, 17 was found to be the optimal window-size in terms of coherence. These preliminary results are available at knowledgelab.org/docs/coherent clusters-data.xls. Corpus Docs Tokens Nodes Edges TASA 38,972 10.7M 58,357 1,319,534 NIPS 3,742 5.2M 28,936 1,612,659 enTenTen 92,327 72.2M 69,745 7,721,413 Table 1: Co-occurrence networks of each corpus. 2011). In our experiments, we used the cooccurrence frequencies as edge-weights and ran 50 trials for each run of the algorithm. Cooccurr</context>
</contexts>
<marker>Rosvall, Bergstrom, 2008</marker>
<rawString>Martin Rosvall and Carl T. Bergstrom. 2008. Maps of random walks on complex networks reveal community structure. Proceedings of the National Academy of Sciences, 105(4):1118–1123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Rosvall</author>
<author>Carl T Bergstrom</author>
</authors>
<title>Multilevel compression of random walks on networks reveals hierarchical organization in large integrated systems.</title>
<date>2011</date>
<journal>PloS one,</journal>
<volume>6</volume>
<issue>4</issue>
<marker>Rosvall, Bergstrom, 2011</marker>
<rawString>Martin Rosvall and Carl T. Bergstrom. 2011. Multilevel compression of random walks on networks reveals hierarchical organization in large integrated systems. PloS one, 6(4):e18209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
<author>Anna Korhonen</author>
</authors>
<title>Statistical metaphor processing.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="6622" citStr="Shutova et al., 2013" startWordPosition="1017" endWordPosition="1020">ng to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not like</context>
</contexts>
<marker>Shutova, Teufel, Korhonen, 2013</marker>
<rawString>Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 2013. Statistical metaphor processing. Computational Linguistics, 39(2):301–353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Sinclair</author>
</authors>
<title>The empty lexicon.</title>
<date>1996</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="2477" citStr="Sinclair, 1996" startWordPosition="373" endWordPosition="374"> has proposed that a core lexicon is used to define the remaining portions of vocabulary (Itˆo and Mester, 1995; Mass´e et al., 2008). Though many words that comprise general language use reside in this core lexicon, even the most general language contains specialist or socalled “satellite” words. This paper introduces a method of extracting this peripheral structure, with co-occurrence networks of unstructured text. The core-periphery structure has been observed in dictionaries where definitions tend to use a restricted vocabulary, repetitively employing a core set of words to define others (Sinclair, 1996; Picard et al., 2013). In the farther regions of the lexicon, it is more difficult to find systematic semantic definition with corpus-based techniques due to the overwhelming number of infrequent words. Unfortunately, the fringe of the lexicon can be more important than the core because this is where domain-specific terminology resides — features that may be more important than frequent. Examining dictionaries, (Picard et al., 2013) propose that the lexicon consists of four main parts: a core set of ubiquitous words used to define other words, a kernel that makes up most of the lexicon, a min</context>
</contexts>
<marker>Sinclair, 1996</marker>
<rawString>John Sinclair. 1996. The empty lexicon. International Journal of Corpus Linguistics, 1(1):99–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Tom Griffiths</author>
</authors>
<title>Probabilistic topic models. Handbook of latent semantic analysis,</title>
<date>2007</date>
<pages>427--7</pages>
<contexts>
<context position="7053" citStr="Steyvers and Griffiths, 2007" startWordPosition="1082" endWordPosition="1085">late distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in the next section, is particularly attractive because it is corpus-based, does not assume any specific semantic relationship and correlates with </context>
</contexts>
<marker>Steyvers, Griffiths, 2007</marker>
<rawString>Mark Steyvers and Tom Griffiths. 2007. Probabilistic topic models. Handbook of latent semantic analysis, 427(7):424–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>638--647</pages>
<contexts>
<context position="6554" citStr="Sun and Korhonen, 2009" startWordPosition="1007" endWordPosition="1010">cific semantic relationships and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other task</context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>Lin Sun and Anna Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 638–647.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="1781" citStr="Turney and Pantel, 2010" startWordPosition="265" endWordPosition="268">number of relational structures, many of which can be obscured by lexical idiosyncrasies, regional variation and domain-specific conventions. Despite this, patterns of word use exhibit loose semantic structure, namely that proximate words tend to be related. This distributional hypothesis has been operationalized in a variety of ways, providing insights and solutions into practical and theoretical questions about meaning, intention and the use of language. Distributional analyses rely primarily on observing natural language to build statistical representations of words, phrases and documents (Turney and Pantel, 2010). By studying dictionaries and thesauri, lexicographic and terminological research has proposed that a core lexicon is used to define the remaining portions of vocabulary (Itˆo and Mester, 1995; Mass´e et al., 2008). Though many words that comprise general language use reside in this core lexicon, even the most general language contains specialist or socalled “satellite” words. This paper introduces a method of extracting this peripheral structure, with co-occurrence networks of unstructured text. The core-periphery structure has been observed in dictionaries where definitions tend to use a re</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37(1):141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Wei</author>
<author>Bruce Croft</author>
</authors>
<title>Lda-based document models for ad-hoc retrieval.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="7096" citStr="Wei and Croft, 2006" startWordPosition="1088" endWordPosition="1091"> verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012). Because the structure of satellite terms is not likely to rely on specific (much less consistent) lexical semantic relationships, we adopt a measure of semantic coherence, commonly used to qualify the results of topic models, as an indirect measure of what people tend to view as a cohesive set of words. This measure, which is defined in the next section, is particularly attractive because it is corpus-based, does not assume any specific semantic relationship and correlates with expert evaluations (Mimno et al., 2011; New</context>
</contexts>
<marker>Wei, Croft, 2006</marker>
<rawString>Xing Wei and Bruce Croft. 2006. Lda-based document models for ad-hoc retrieval. In Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>A preferential, pattern-seeking, semantics for natural language inference.</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="6568" citStr="Wilks, 1975" startWordPosition="1011" endWordPosition="1012">hips and has been used to group words according to explicit measures of relatedness and similarity (Miller, 1995; Pedersen et al., 2004). Distributional, corpus-based techniques that define words as feature vectors (eg. word-document co-occurrences), can address many limitations of manually created lexicons (see Turney et al., 2010 for a review). Clustering nouns by argument structure can uncover naturally related objects (Hindle, 1990) and spectral methods can relate distinct classes of nouns with certain kinds of verbs to induce selectional preferences (Resnik, 1997; Sun and Korhonen, 2009; Wilks, 1975) and assist metaphor processing (Shutova et al., 2013). A pervasive weakness of many existing approaches to word-clustering, is an underlying prioritization of frequent words. To help address this sparsity, many models collapse words into stems, preclude uncommon words, or underestimate the relevance of infrequent words (Dagan et al., 1999). Probabilistic topic models have emerged as a uniquely flexible kind of wordclustering used in content analysis (Steyvers and Griffiths, 2007), text classification (Wei and Croft, 2006) and provide an extensible framework to address other tasks (Blei, 2012)</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Yorick Wilks. 1975. A preferential, pattern-seeking, semantics for natural language inference. Artificial Intelligence, 6(1):53–74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>