<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.997279">
A Cognitive Model of Semantic Network Learning
</title>
<author confidence="0.996982">
Aida Nematzadeh, Afsaneh Fazly, and Suzanne Stevenson
</author>
<affiliation confidence="0.9987495">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.995054">
{aida,afsaneh,suzanne}@cs.toronto.edu
</email>
<sectionHeader confidence="0.997333" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999824375">
Child semantic development includes
learning the meaning of words as well as
the semantic relations among words. A
presumed outcome of semantic develop-
ment is the formation of a semantic net-
work that reflects this knowledge. We
present an algorithm for simultaneously
learning word meanings and gradually
growing a semantic network, which ad-
heres to the cognitive plausibility require-
ments of incrementality and limited com-
putations. We demonstrate that the seman-
tic connections among words in addition
to their context is necessary in forming a
semantic network that resembles an adult’s
semantic knowledge.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998973222222222">
Child semantic development includes the acquisi-
tion of word-to-concept mappings (part of word
learning), and the formation of semantic connec-
tions among words/concepts. There is consid-
erable evidence that understanding the semantic
properties of words improves child vocabulary ac-
quisition. In particular, children are sensitive to
commonalities of semantic categories, and this
abstract knowledge facilitates subsequent word
learning (Jones et al., 1991; Colunga and Smith,
2005). Furthermore, representation of semantic
knowledge is significant as it impacts how word
meanings are stored in, searched for, and retrieved
from memory (Steyvers and Tenenbaum, 2005;
Griffiths et al., 2007).
Semantic knowledge is often represented as a
graph (a semantic network) in which nodes cor-
respond to words/concepts1, and edges specify
</bodyText>
<footnote confidence="0.807687666666667">
1Here we assume that the nodes of a semantic network
are word forms and its edges are determined by the semantic
features of those words.
</footnote>
<bodyText confidence="0.999611829268293">
the semantic relations (Collins and Loftus, 1975;
Steyvers and Tenenbaum, 2005). Steyvers and
Tenenbaum (2005) demonstrated that a seman-
tic network that encodes adult-level knowledge of
words exhibits a small-world and scale-free struc-
ture. That is, it is an overall sparse network with
highly-connected local sub-networks, where these
sub-networks are connected through high-degree
hubs (nodes with many neighbours).
Much experimental research has investigated
the underlying mechanisms of vocabulary learn-
ing and characteristics of semantic knowledge
(Quine, 1960; Bloom, 1973; Carey and Bartlett,
1978; Gleitman, 1990; Samuelson and Smith,
1999; Jones et al., 1991; Jones and Smith,
2005). However, existing computational models
focus on certain aspects of semantic acquisition:
Some researchers develop computational models
of word learning without considering the acqui-
sition of semantic connections that hold among
words, or how this semantic knowledge is struc-
tured (Siskind, 1996; Regier, 2005; Yu and Bal-
lard, 2007; Frank et al., 2009; Fazly et al., 2010).
Another line of work is to model formation of
semantic categories but this work does not take
into account how word meanings/concepts are ac-
quired (Anderson and Matessa, 1992; Griffiths et
al., 2007; Fountain and Lapata, 2011).
Our goal in this work is to provide a cognitively-
plausible and unified account for both acquiring
and representing semantic knowledge. The re-
quirements for cognitive plausibility enforce some
constraints on a model to ensure that it is compa-
rable with the cognitive process it is formulating
(Poibeau et al., 2013). As we model semantic ac-
quisition, the first requirement is incrementality,
which means that the model learns gradually as
it processes the input. Also, there is a limit on
the number of computations the model performs
at each step.
In this paper, we present an algorithm for si-
</bodyText>
<page confidence="0.975175">
244
</page>
<note confidence="0.910347">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 244–254,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99964675">
multaneously learning word meanings and grow-
ing a semantic network, which adheres to the cog-
nitive plausibility requirements of incrementality
and limited computations. We examine networks
created by our model under various conditions,
and explore what is required to obtain a structure
that has appropriate semantic connections and has
a small-world and scale-free structure.
</bodyText>
<sectionHeader confidence="0.999923" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.993484944444444">
Models of Word Learning. Given a word learn-
ing scenario, there are potentially many possible
mappings between words in a sentence and their
meanings (real-world referents), from which only
some mappings are correct (the mapping prob-
lem). One of the most dominant mechanisms
proposed for vocabulary acquisition is cross-
situational learning: people learn word mean-
ings by recognizing and tracking statistical reg-
ularities among the contexts of a word’s usage
across various situations, enabling them to nar-
row in on the meaning of a word that holds across
its usages (Siskind, 1996; Yu and Smith, 2007;
Smith and Yu, 2008). A number of computa-
tional models attempt to solve the mapping prob-
lem by implementing this mechanism, and have
successfully replicated different patterns observed
in child word learning (Siskind, 1996; Yu and Bal-
lard, 2007; Fazly et al., 2010). These models have
provided insight about underlying mechanisms of
word learning, but none of them consider the se-
mantic relations that hold among words, or how
the semantic knowledge is structured. Recently,
we have investigated properties of the semantic
structure of the resulting (final) acquired knowl-
edge of such a learner (Nematzadeh et al., 2014).
However, that work did not address how such
structural knowledge might develop and evolve in-
crementally within the learning model.
Models of Categorization. Computational mod-
els of categorization focus on the problem of form-
ing semantic clusters given a defined set of fea-
tures for words (Anderson and Matessa, 1992;
Griffiths et al., 2007; Sanborn et al., 2010). An-
derson and Matessa (1992) note that a cognitively
plausible categorization algorithm needs to be in-
cremental and only keep track of one potential
partitioning; they propose a Bayesian framework
(the Rational Model of Categorization or RMC)
that specifies the joint distribution on features and
category labels, and allows an unbounded number
of clusters. Sanborn et al. (2010) examine differ-
ent categorization models based on RMC. In par-
ticular, they compare the performance of the ap-
proximation algorithm of Anderson and Matessa
(1992) (local MAP) with two other approximation
algorithms (Gibbs Sampling and Particle Filters)
in various human categorization paradigms. San-
born et al. (2010) find that in most of the simula-
tions the local MAP algorithm performs as well as
the two other algorithms in matching human be-
havior.
The Representation of Semantic Knowledge.
There is limited work on computational models
of semantic acquisition that examine the represen-
tation of the semantic knowledge. Steyvers and
Tenenbaum (2005) propose an algorithm for build-
ing a network with small-world and scale-free
structure. The algorithm starts with a small com-
plete graph, incrementally adds new nodes to the
graph, and for each new node uses a probabilistic
mechanism for selecting a subset of current nodes
to connect to. However, their approach does not
address the problem of learning word meanings or
the semantic connections among them. Fountain
and Lapata (2011) propose an algorithm for learn-
ing categories that also creates a semantic network
by comparing all the possible word pairs. How-
ever, they too do not address the word learning
problem, and do not investigate the structure of the
learned semantic network to see whether it has the
properties observed in adult knowledge.
</bodyText>
<sectionHeader confidence="0.990129" genericHeader="method">
3 The Incremental Network Model
</sectionHeader>
<bodyText confidence="0.999963222222222">
We propose here a model that unifies the incre-
mental acquisition of word meanings and forma-
tion of a semantic network structure that reflects
the similarities among those meanings. We use
an existing model to learn the meanings of words
(Section 3.1), and use those incrementally devel-
oping meanings as the input to the algorithm pro-
posed here for gradually growing a semantic net-
work (Section 3.2).
</bodyText>
<subsectionHeader confidence="0.999266">
3.1 The Word Learner
</subsectionHeader>
<bodyText confidence="0.999458833333333">
We use the model of Fazly et al. (2010); this learn-
ing algorithm is incremental and involves limited
calculations, thus satisfying basic cognitive plausi-
bility requirements. A naturalistic language learn-
ing scenario consists of linguistic data in the con-
text of non-linguistic data, such as the objects,
</bodyText>
<page confidence="0.997695">
245
</page>
<table confidence="0.239616666666667">
Utterance: {let, find, a, picture, to, color }
Scene: {LET, PRONOUN, HAS POSSESSION, CAUSE,
ARTIFACT, WHOLE, CHANGE,... }
</table>
<tableCaption confidence="0.99712">
Table 1: A sample utterance-scene pair.
</tableCaption>
<bodyText confidence="0.999680275862069">
events, and social interactions that a child per-
ceives. This kind of input is modeled here as
a pair of an utterance (the words a child hears)
and a scene (the semantic features representing the
meaning of those words), as shown in Table 1 (and
described in more detail in Section 5.1). The word
learner is an instance of cross-situational learn-
ing applied to a sequence of such input pairs: for
each pair of a word w and a semantic feature f,
the model incrementally learns P(f|w) from co-
occurrences of w and f across all the utterance-
scene pairs.
For each word, the probability distribution
over all semantic features, P(.|w), represents the
word’s meaning. The estimation of P(.|w) is
made possible by introducing a set of latent vari-
ables, alignments, that correspond to the possible
mappings between words and features in a given
utterance–scene pair. The learning problem is then
to find the mappings that best explain the data,
which is solved by using an incremental version
of the expectation–maximization (EM) algorithm
(Neal and Hinton, 1998). We skip the details of
the derivations and only report the resulting for-
mulas.
The model processes one utterance-scene pair at
a time. For the input pair processed at time t, first
the probability of each possible alignment (align-
ment probability) is calculated as:2
</bodyText>
<equation confidence="0.9915185">
P(aij |u, fi) = Pt−fi|wj)|w0) (1)
Ew&apos;∈u P
</equation>
<bodyText confidence="0.999723285714286">
where u is the utterance, and aij is the alignment
variable specifying the word wj that is mapped
to the feature fi. Pt−1(fi|wj) is taken from the
model’s current learned meaning of word wj. Ini-
tially, P0(fi|wj) is uniformly distributed. After
calculating the alignment probabilities, the learned
meanings are updated as:
</bodyText>
<equation confidence="0.989269">
Pt(fi |wj) = Eu∈Ut P(aij |u, fi) (2)
Ef&apos;∈M Eu∈Ut P(aij |u, f0)
</equation>
<bodyText confidence="0.9345676">
where Ut is the set of utterances processed so far,
and M is the set of features that the model has ob-
served. Note that for each w–f pair, the value of
the summations in this formula can be incremen-
tally updated after processing any utterance that
</bodyText>
<footnote confidence="0.526183333333333">
2This corresponds to the expectation step of EM.
contains w; the summation does not have to be cal-
culated at every step.
</footnote>
<subsectionHeader confidence="0.99987">
3.2 Growing a Semantic Network
</subsectionHeader>
<bodyText confidence="0.999975446808511">
In our extended model, as we learn words incre-
mentally (as above), we also structure those words
into a semantic network based on the (partially)
learned meanings. At any given point in time, the
network will include as its nodes all the word types
the word learner has been exposed to. Weighted
edges (capturing semantic distance) will connect
those pairs of word types whose learned meanings
at that point are sufficiently semantically similar
(according to a threshold). Since the probabilis-
tic meaning of a word is adjusted each time it is
observed, a word may either lose or gain connec-
tions in the network after each input is processed.
Thus, to incrementally develop the network, at
each time step, our algorithm must both examine
existing connections (to see which edges should be
removed) and consider potential new connections
(to see which edges should be added).
A simple approach to achieve this is to examine
the current semantic similarity between a word w
in the input and all the current words in the net-
work, and include edges between only those word
pairs that are sufficiently similar. However, com-
paring w to all the words in the network each time
it is observed is computationally intensive (and not
cognitively plausible).
We present an approach for incrementally grow-
ing a semantic network that limits the computa-
tions when processing each input word w; see Al-
gorithm 1. After the meaning of w is updated, we
first check all the words that w is currently (di-
rectly) connected to, to see if any of those edges
need to be removed, or have their weight adjusted.
Next, to look for new connections for w, the idea is
to select only a small subset of words, S, to which
w will be compared. The challenge then is to se-
lect S in a way that will yield a network whose se-
mantic structure reasonably approximates the net-
work that would result from full knowledge of
comparing w to all the words.
Previous work has suggested picking “impor-
tant” words (e.g., high-degree words) indepen-
dently of the target word w — assuming these
might be words for which a learner might need
to understand their relationship to w in the future
(Steyvers and Tenenbaum, 2005). Our proposal
is instead to consider for S those words that are
</bodyText>
<page confidence="0.990563">
246
</page>
<bodyText confidence="0.963288555555555">
Algorithm 1 Growing a network after each in-
put u.
for all w in u do
update P(.|w) using Eqn. (2)
update current connections of w
select S(w), a subset of words in the network
for all w0 in S(w) do
if w and w0 are sufficiently similar then
connect w and w0 with an edge
</bodyText>
<listItem confidence="0.659399666666667">
end if
end for
end for
</listItem>
<bodyText confidence="0.999307368421053">
likely to be similar to w. That is, since the net-
work only needs to connect similar words to w, if
we can guess what (some of) those words are, then
we will do best at approximating the situation of
comparing w to all words.
The question now is how to find semantically
similar words to w that are not already connected
to w in the network. To do so, we incrementally
track semantic similarity among words usages as
their meanings are developing. Specifically we
cluster word tokens (not types) according to their
current word meanings. Since the probabilistic
meanings of words are continually evolving, in-
cremental clusters of word tokens can capture de-
veloping similarities among the various usages of
a word type, and be a clue to which words (types)
w might be similar to. In the next section, we de-
scribe the Bayesian clustering process we use to
identify potentially similar words.
</bodyText>
<subsectionHeader confidence="0.999064">
3.3 Semantic Clustering of Word Tokens
</subsectionHeader>
<bodyText confidence="0.999990692307692">
We use the Bayesian framework of Anderson and
Matessa (1992) to form semantic clusters.3 Recall
that for each word w, the model learns its mean-
ings as a probability distribution over all seman-
tic features, P(.|w). We represent this probability
distribution as a vector F whose length is the num-
ber of possible semantic features. Each element of
the vector holds the value P(f|w) (which is con-
tinuous). Given a word w and its vector F, we
need to calculate the probability that w belongs to
each existing cluster, and also allow for the pos-
sibility of it forming a new cluster. Using Bayes
rule we have:
</bodyText>
<equation confidence="0.991777333333333">
P(k)P(F|k)
P (k|F ) = � (3)
k/ P(k0)P(F|k0)
</equation>
<bodyText confidence="0.879482625">
3The distribution specified by this model is equivalent to
that of a Dirichlet Process Mixture Model (Neal, 2000).
where k is a given cluster. We thus need to calcu-
late the prior probability, P(k), and the likelihood
of each cluster, P(F|k).
Calculation of Prior. The prior probability that
word n + 1 is assigned to cluster k is calculated
as:
</bodyText>
<equation confidence="0.9974642">
� nk nk &gt; 0
P(k) = n+α
n+α nk = 0 (new cluster)
α
(4)
</equation>
<bodyText confidence="0.997949111111111">
where nk is the number of words in cluster k, n
is the number of words observed so far, and α is a
parameter that determines how likely the creation
of a new cluster is. The prior favors larger clusters,
and also discourages the creation of new clusters
in later stages of learning.
Calculation of Likelihood. To calculate the like-
lihood P(F |k) in Eqn. (3), we assume that the fea-
tures are independent:
</bodyText>
<equation confidence="0.989285">
P(F|k) = � P(fi = v|k) (5)
fi∈F
</equation>
<bodyText confidence="0.999985923076923">
where P(fi = v|k) is the probability that the value
of the feature in dimension i is equal to v given
the cluster k. To derive P(fi|k), following An-
derson and Matessa (1992), we assume that each
feature given a cluster follows a Gaussian distri-
bution with an unknown variance σ2 and mean µ.
(In the absence of any prior information about a
variable, it is often assumed to have a Gaussian
distribution.) The mean and variance of this dis-
tribution are inferred using Bayesian analysis: We
assume the variance has an inverse χ2 prior, where
σ20 is the prior variance and a0 is the confidence in
the prior variance:
</bodyText>
<equation confidence="0.997891">
σ2 ∼ Inv-χ2(a0,σ20) (6)
</equation>
<bodyText confidence="0.999966">
The mean given the variance has a Gaussian dis-
tribution with µ0 as the prior mean and λ0 as the
confidence in the prior mean.
</bodyText>
<equation confidence="0.994737">
σ2
µ|σ ∼ N(µ0, ) (7)
λ0
</equation>
<bodyText confidence="0.999946333333333">
Given the above conjugate priors, P(fi|k) can
be calculated analytically and is a Student’s t dis-
tribution with the following parameters:
</bodyText>
<equation confidence="0.9669295">
P(fi|k) ∼ tai(µi, σ2i (1 + 1)) (8)
λi
λi = λ0 + nk (9)
ai = a0 + nk (10)
247
A0µ0 + nk f (11)
A0 + nk
λ0nk
σ2
= a0σ20 + (nk − 1)s2 + λ0+nk (µ0 + f) 2
12
i a0 + nk ( )
</equation>
<bodyText confidence="0.999969434782609">
where f¯ and s2 are the sample mean and variance
of the values of fi in k.
Note that in the above equations, the mean and
variance of the distribution are simply derived by
combining the sample mean and variance with
the prior mean and variance while considering the
confidence in the prior mean (A0) and variance
(a0). This means that the number of computations
to calculate P(F|K) is limited as w is only com-
pared to the “prototype” of each cluster, which is
represented by µi and σi of different features.
Adding a word w to a cluster. We add w to
the cluster k with highest posterior probability,
P(k|F), as calculated in Eqn. (3).4 The parame-
ters of the selected cluster (k, µi, Ai, σi, and ai for
each feature fi) are then updated incrementally.
Using the Clusters to Select the Words in S(w).
We can now form S(w) in Algorithm 1 by select-
ing a given number of words ns whose tokens are
probabilistically chosen from the clusters accord-
ing to how likely each cluster k is given w: the
number of word tokens picked from each k is pro-
portional to P(k|F) and is equal to P(k|F) x ns.
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999977666666667">
We evaluate a semantic network in two regards:
The semantic connectivity of the network – to
what extent the semantically-related words are
connected in the network; and the structure of the
network – whether it exhibits a small-world and
scale-free structure or not.
</bodyText>
<subsectionHeader confidence="0.99517">
4.1 Evaluating Semantic Connectivity
</subsectionHeader>
<bodyText confidence="0.9999582">
The distance between the words in the network in-
dicates their semantic similarity: the more similar
a word pair, the smaller their distance. For word
pairs that are connected via a path in the network,
this distance is the weighted shortest path length
between the two words. If there is no path be-
tween a word pair, their distance is considered to
be oc (which is represented with a large number).
We refer to this distance as the “learned” semantic
similarity.
</bodyText>
<footnote confidence="0.9569305">
4This approach is referred to as local MAP (Sanborn et al.,
2010); because of the incremental nature of the algorithm, it
maximizes the current posterior distribution as opposed to the
“global” posterior.
</footnote>
<bodyText confidence="0.999969725490196">
To evaluate the semantic connectivity of the
learned network, we compare these learned sim-
ilarity scores to “gold-standard” similarity scores
that are calculated using the WordNet similarity
measure of Wu and Palmer (1994) (also known as
the WUP measure). We choose this measure since
it captures the same type of similarity as in our
model: words are considered similar if they belong
to the same semantic category. Moreover, this
measure does not incorporate information about
other types of similarities, for example, words are
not considered similar if they occur in similar con-
texts. Thus, the scores calculated with this mea-
sure are comparable with those of our learned net-
work.
Given the gold-standard similarity scores for
each word pair, we evaluate the semantic con-
nectivity of the network based on two perfor-
mance measures: coefficient of correlation and
the median rank of the first five gold-standard as-
sociates. Correlation is a standard way to com-
pare two lists of similarity scores (Budanitsky
and Hirst, 2006). We create two lists, one con-
taining the gold-standard similarity scores for all
word pairs, and the other containing their corre-
sponding learned similarity scores. We calculate
the Spearman’s rank correlation coefficient, ρ, be-
tween these two lists of similarity scores. Note
that the learned similarity scores reflect the seman-
tic distance among words whereas the WordNet
scores reflect semantic closeness. Thus, a nega-
tive correlation is best in our evaluation, where the
value of -1 corresponds to the maximum correla-
tion.
Following Griffiths et al. (2007), we also cal-
culate the median learned rank of the first five
gold-standard associates for all words: For each
word w, we first create a “gold-standard” asso-
ciates list: we sort all other words based on their
gold-standard similarity to w, and pick the five
most similar words (associates) to w. Similarly,
we create a “learned associate list” for w by sort-
ing all words based on their learned semantic simi-
larity to w. For all words, we find the ranks of their
first five gold-standard associates in their learned
associate list. For each associate, we calculate the
median of these ranks for all words. We only re-
port the results for the first three gold-standard as-
sociates since the pattern of results is similar for
the fourth and fifth associates; we refer to the me-
dian rank of first three gold-standard associates as
</bodyText>
<equation confidence="0.819106">
µi =
</equation>
<page confidence="0.970218">
248
</page>
<note confidence="0.334781">
1st, 2nd, and 3rd.
</note>
<subsectionHeader confidence="0.898958">
4.2 Evaluating the Structure of the Network
</subsectionHeader>
<bodyText confidence="0.999075666666667">
A network exhibits a small-world structure when
it is characterized by short path length between
most nodes and highly-connected neighborhoods
(Watts and Strogatz, 1998). We first explain how
these properties are measured for a graph with N
nodes and E edges. Then we discuss how these
properties are used in assessing the small-world
structure of a graph.5.
Short path lengths. Most of the nodes of
a small-world network are reachable from other
nodes via relatively short paths. For a connected
network (i.e., all the node pairs are reachable from
each other), this can be measured as the average
distance between all node pairs (Watts and Stro-
gatz, 1998). Since our networks are not connected,
we instead measure this property using the median
of the distances (dmedian) between all node pairs
(Robins et al., 2005), which is well-defined even
when some node pairs have a distance of oc.
Highly-connected neighborhoods. The neigh-
borhood of a node n in a graph consists of n and
all of the nodes that are connected to it. A neigh-
borhood is maximally connected if it forms a com-
plete graph —i.e., there is an edge between all
node pairs. Thus, the maximum number of edges
in the neighborhood of n is kn(kn − 1)/2, where
kn is the number of neighbors. A standard metric
for measuring the connectedness of neighbors of
a node n is called the local clustering coefficient
(C) (Watts and Strogatz, 1998), which calculates
the ratio of edges in the neighborhood of n (En)
to the maximum number of edges possible for that
neighborhood:
</bodyText>
<equation confidence="0.98546075">
C
En
= (13)
kn(kn − 1)/2
</equation>
<bodyText confidence="0.9995037">
The local clustering coefficient C ranges between
0 and 1. To estimate the connectedness of all
neighborhoods in a network, we take the average
of C over all nodes, i.e., Cavg.
Small-world structure. A graph exhibits a
small-world structure if dmedian is relatively small
and Cavg is relatively high. To assess this for
a graph g, these values are typically compared
to those of a random graph with the same num-
ber of nodes and edges as g (Watts and Strogatz,
</bodyText>
<footnote confidence="0.5183105">
5We take the description of these measures from Ne-
matzadeh et al. (2014)
</footnote>
<bodyText confidence="0.99861755">
1998; Humphries and Gurney, 2008). The ran-
dom graph is generated by randomly rearranging
the edges of the network under consideration (Er-
dos and R´enyi, 1960). Because any pair of nodes
is equally likely to be connected as any other, the
median of distances between nodes is expected to
be low for a random graph. In a small-world net-
work, this value dmedian is expected to be as small
as that of a random graph: even though the random
graph has edges more uniformly distributed, the
small-world network has many locally-connected
components which are connected via hubs. On the
other hand, Cavg is expected to be much higher
in a small-world network compared to its corre-
sponding random graph, because the edges of a
random graph typically do not fall into clusters
forming highly connected neighborhoods.
Given these two properties, the “small-
worldness” of a graph g is measured as follows
(Humphries and Gurney, 2008):
</bodyText>
<equation confidence="0.99594825">
Cavg(g)
Cavg(random)
dmedian(g)
dmedian(random)
</equation>
<bodyText confidence="0.9961345">
where random is the random graph correspond-
ing to g. In a small-world network, it is ex-
pected that Cavg(g) » Cavg(random) and
dmedian(g) ≥ dmedian(random), and thus Qg &gt;
1.
Note that Steyvers and Tenenbaum (2005) made
the empirical observation that small-world net-
works of semantic knowledge had a single con-
nected component that contained the majority of
nodes in the network. Thus, in addition to Qg,
we also measure the relative size of a network’s
largest connected component having size Nlcc:
</bodyText>
<equation confidence="0.988736">
Nlcc (15)
N
</equation>
<bodyText confidence="0.999078692307692">
Scale-free structure. A scale-free network has
a relatively small number of high-degree nodes
that have a large number of connections to other
nodes, while most of its nodes have a small de-
gree, as they are only connected to a few nodes.
Thus, if a network has a scale-free structure, its de-
gree distribution (i.e., the probability distribution
of degrees over the whole network) will follow a
power-law distribution (which is said to be “scale-
free”). We evaluate this property of a network by
plotting its degree distribution in the logarithmic
scale, which (if a power-law distribution) should
appear as a straight line. None of our networks ex-
</bodyText>
<equation confidence="0.981805">
Qg =
(14)
sizelcc =
</equation>
<page confidence="0.746026">
249
</page>
<figure confidence="0.3017284">
apple: l FOOD:1, SOLID:.72, · · · , PLANT-PART:.22,
PHYSICAL-ENTITY:.17, WHOLE:.06, · · · }
hibit a scale-free structure; thus, we do not report
the results of this evaluation, and leave it to future
work for further investigation.
</figure>
<figureCaption confidence="0.9196">
Figure 1: Sample true meaning features &amp; their scores for
</figureCaption>
<note confidence="0.460718">
apple from Nematzadeh et al. (2012).
</note>
<sectionHeader confidence="0.998001" genericHeader="method">
5 Experimental Set-up
</sectionHeader>
<subsectionHeader confidence="0.967909">
5.1 Input Representation
</subsectionHeader>
<bodyText confidence="0.994964194444445">
Recall that the input to the model consists of a
sequence of utterance–scene pairs intended to re-
flect the linguistic data a child is exposed to, along
with the associated meaning a child might grasp.
As in much previous work (Yu and Ballard, 2007;
Fazly et al., 2010), we take child-directed utter-
ances from the CHILDES database (MacWhinney,
2000) in order to have naturalistic data. In partic-
ular, we use the Manchester corpus (Theakston et
al., 2001), which consists of transcripts of conver-
sations with 12 British children between the ages
of 1; 8 and 3; 0. We represent each utterance as
a bag of lemmatized words (see Utterance in Ta-
ble 1).
For the scene representation, we have no large
corpus to draw on that encodes the semantic por-
tion of language acquisition data.6 We thus auto-
matically generate the semantics associated with
an utterance, using a scheme first introduced in
Fazly et al. (2010). The idea is to first create an
input generation lexicon that provides a mapping
between all the words in the input data and their
associated meanings. A scene is then represented
as a set that contains the meanings of all the words
in the utterance. We use the input generation lexi-
con of Nematzadeh et al. (2012) because the word
meanings reflect information about their semantic
categories, which is crucial to forming the seman-
tic clusters as in Section 3.3.
In this lexicon, the “true” meaning for each
word w is a vector over a set of possible seman-
tic features for each part of speech; in the vec-
tor, each feature is associated with a score for that
word (see Figure 1). Depending on the word’s part
of speech, the features are extracted from various
6Yu and Ballard (2007) created a corpus by hand-coding
the objects and cues that were present in the environment,
but that corpus is very small. Frank et al. (2013) provide a
larger manually annotated corpus (5000 utterances), but it is
still very small for longitudinal simulations of word learn-
ing. (Our corpus contains more than 100,000 utterances.)
Moreover, the corpus of Frank et al. (2013) is limited be-
cause a considerable number of words are not semantically
coded. (Only a subset of concrete objects in the environment
are coded.)
lexical resources such as WordNet7, VerbNet8, and
Harm (2002). The score for each feature is calcu-
lated using a measure similar to tf-idf that reflects
the association of the feature with the word and
with its semantic category: term frequency indi-
cates the strength of association of the feature with
the word, and inverse document frequency (where
the documents are the categories) indicates how
informative a feature is for that category. The se-
mantic categories of nouns (which we focus on in
our networks) are given by WordNet lex-names9,
a set of 25 general categories of entities. (We use
only nouns in our semantic networks because the
semantic similarity of words with different parts
of speech cannot be compared, since their seman-
tic features are drawn from different resources.)
The input generation lexicon is used to generate
a scene representation for an utterance as follows:
For each word w in the utterance, we probabilisti-
cally sample features, in proportion to their score,
from the full set of features in its true meaning.
The probabilistic sampling allows us to simulate
the noise and uncertainty in the input a child per-
ceives by omitting some meaning features from
the scene. The scene representation is the union
of all the features sampled for all the words in the
utterance (see Scene in Table 1).
</bodyText>
<subsectionHeader confidence="0.998156">
5.2 Methods
</subsectionHeader>
<bodyText confidence="0.999883307692308">
We experiment with our network-growth method
that draws on the incremental clustering, and cre-
ate “upper-bound” and baseline networks for com-
parison. Note that all the networks are created
using our Algorithm 1 (page 4) to grow networks
incrementally, drawing on the learned meanings of
words and updating their connections on the basis
of this evolving knowledge. The only difference
in creating the networks resides in how the com-
parison set S(w) is chosen for each target word w
that is being added to the growing network at each
time step. We provide more details in the para-
graphs below.
</bodyText>
<footnote confidence="0.9954068">
7http://wordnet.princeton.edu
8http://verbs.colorado.edu/˜mpalmer/
projects/verbnet.html
9http://wordnet.princeton.edu/wordnet/
man/lexnames.5WN.html
</footnote>
<page confidence="0.995597">
250
</page>
<bodyText confidence="0.999839072727273">
Upper-bound. Recall that one of our main goals
is to substantially reduce the number of similar-
ity comparisons needed to grow a semantic net-
work, in contrast to the straightforward method of
comparing each w to all current words. At the
same time, we need to understand the impact of
the increased efficiency on the quality of the re-
sulting networks. We thus need to compare the
target properties of our networks that are learned
using a small comparison set S, to those of an
“upper-bound” network that takes into account all
the pair-wise comparisons among words. We cre-
ate this upper-bound network by setting S(w) to
contain all words currently in the network.
Baselines. On the other hand, we need to evalu-
ate the (potential) benefit of our cluster-driven se-
lection process over a more simplistic approach to
selecting S(w). To do so, we consider three base-
lines, each using a different criteria for choosing
the comparison set S(w): The Random baseline
chooses the members of this set randomly from
the set of all observed words. The Context base-
line can be seen as an “informed” baseline that at-
tempts to incorporate some semantic knowledge:
Here, we select words that are in the recent context
prior to w in the input, assuming that such words
are likely to be semantically related to w. We also
include a third baseline, Random+Context, that
picks half of the members of S randomly and half
of them from the prior context.
Cluster-based Methods. We report results for
three cluster-based networks that differ in their
choice of S(w) as follows: The Clusters-only net-
work chooses words in S(w) from the set of clus-
ters, proportional to the probability of each clus-
ter k given word w (as explained in Section 3.3).
In order to incorporate different types of semantic
information in selecting S, we also create a Clus-
ters+Context network that picks half of the mem-
bers of S from clusters (as above), and half from
the prior context. For completeness, we include a
Clusters+Random network that similarly chooses
half of words in S from clusters and half randomly
from all observed words.
We have experimented with several other meth-
ods, but they all performed substantially worse
than the baselines, and hence we do not report
them here. E.g., we tried picking words in S from
the best cluster. We also tried a few methods in-
spired by (Steyvers and Tenenbaum, 2005): E.g.,
we examined a method where if a member of S(w)
was sufficiently similar to w, we added the direct
neighbors of that word to S. We also tried to grow
networks by choosing the members of S according
to the degree or frequency of nodes in the network.
</bodyText>
<subsectionHeader confidence="0.997857">
5.3 Experimental Parameters
</subsectionHeader>
<bodyText confidence="0.999898727272727">
We use 20, 000 utterance–scene pairs as our train-
ing data. Recall that we use clustering to help
guide our semantic network growth algorithm.
Given the clustering algorithm in Section 3.3, we
are interested to find the set of clusters that best
explain the data. (Other clustering algorithms can
be used instead of this algorithm.) We perform
a search on the parameter space, and select the
parameter values that result in the best clustering,
based on the number of clusters and their average
F-score. The value of the clustering parameters
are as follows: α = 49, A0 = 1.0, a0 = 2.0,
µ0 = 0.0, and σ0 = 0.05. Two nouns with fea-
ture vectors F1 and F2 are connected in the net-
work if cosine(F1, F2) is greater than or equal to
0.6. (This threshold was selected following em-
pirical examination of the similarity values we ob-
serve among the “true” meaning in our input gen-
eration lexicon.) The weight on the edge that con-
nects these nouns specifies their semantic distance,
which is calculated as 1 − cosine(F1, F2).
Because we aim for a network creation method
that is cognitively plausible in performing a lim-
ited number of word-to-word comparisons, we
need to ensure that all the different methods of
selecting the comparison set S(w) yield roughly
similar numbers of such comparisons. Keeping
the size of S constant does not guarantee this,
because each method can yield differing num-
bers of connections of the target word w to other
words. We thus parameterize the size of S for
each method to keep the number of computations
similar, based on experiments on the development
data. In development work we also found that hav-
ing an increasing size of S over time improved
the results, as more words were compared as the
knowledge of learned meanings improved. To
achieve this, we use a percentage of the words
in the network as the size of S. In practice, the
setting of this parameter yields a number of com-
parisons across all methods that is about 8% of
the maximum possible word-to-word comparisons
that would be performed in the naive (computa-
tionally intensive) approach.
</bodyText>
<page confidence="0.99042">
251
</page>
<bodyText confidence="0.999926">
Note that all the Cluster-based, Random and
Random+Context methods include a random se-
lection mechanism; thus, we run each of these
methods 50 times and report the average p, me-
dian ranks and sizercc (see Section 4). For the net-
works (out of 50 runs) that exhibit a small-world
structure (small-worldness greater than one), we
report the average small-worldness. We also re-
port the percentage of runs whose resulting net-
work exhibit a small-world structure.
</bodyText>
<sectionHeader confidence="0.983465" genericHeader="evaluation">
6 Experimental Results and Discussion
</sectionHeader>
<bodyText confidence="0.998430987012987">
Table 2 presents our results, including the eval-
uation measures explained above, for the Upper-
bound, Baseline, and Cluster-based networks cre-
ated by the various methods described in Sec-
tion 5.2.10
Recall that the Upper-bound network is formed
from examining a word’s similarity to all other
(observed) words when it is added to the network.
We can see that this network is highly connected
(0.85) and has a small-world structure (5.5). There
is a statistically significant correlation of the net-
work’s similarity measures with the gold standard
ones (−0.38). For this Upper-bound structure, the
median ranks of the first three associates are be-
tween 31 and 42. These latter two measures on
the Upper-bound network give an indication of the
difficulty of learning a semantic network whose
knowledge matches gold-standard similarities.
Considering the baseline networks, we note that
the Random network is actually somewhat bet-
ter (in connectivity and median ranks) than the
Context network that we thought would provide
a more informed baseline. Interestingly, the cor-
relation value for both networks is no worse than
for the Upper-bound. The combination of Ran-
dom+Context yields a slightly lower correlation,
and no better ranks or connectivity than Random.
Note that none of the baseline networks exhibit a
small world structure (Qg « 1 for all three, except
for one out of 50 runs for the Random method).
Recall that the Random network is not a net-
work resulting from randomly connecting word
pairs, but one that incrementally compares each
target word with a set of randomly chosen words
when considering possible new connections. We
suspect that this approach performs reasonably
well because it enables the model to find a broad
10All the reported co-efficients of correlation (p) are statis-
tically significant at p &lt; 0.01.
range of similar words to the target; this might be
effective especially because the learned meanings
of words are changing over time.
Turning to the Cluster-based methods, we see
that indeed some diversity in the comparison set
for a target word might be necessary to good
performance. We find that the measures on the
Clusters-only network are roughly the same as on
the Random one, but when we combine the two in
Clusters+Random we see an improvement in the
ranks achieved. It is possible that the selection
from clusters does not have sufficient diversity to
find some of the valid new connections for a word.
We note that the best results overall occur with
the Clusters+Context network, which combines
two approaches to selecting words that have good
potential to be similar to the target word. The
correlation coefficient for this network is at a re-
spectable 0.36, and the median ranks are the sec-
ond best of all the network-growth methods. Im-
portantly, this network shows the desired small-
world structure in most of the runs (77%), with
the highest connectivity and a small-world mea-
sure well over 1.
The fact that the Clusters+Context network is
better overall than the networks of the Clusters-
only and Context methods indicates that both clus-
ters and context are important in making “in-
formed guesses” about which words are likely
to be similar to a target word. Given the small
number of similarity comparisons used in our ex-
periments (only around 8% of all possible word-
to-word comparisons), these observations suggest
that both the linguistic context and the evolving
relations among word usages (captured by the in-
cremental clustering of learned meanings) contain
information crucial to the process of growing a se-
mantic network in a cognitively plausible way.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999977818181818">
We propose a unified model of word learning and
semantic network formation, which creates a net-
work of words in which connections reflect struc-
tured knowledge of semantic similarity between
words. The model adheres to the cognitive plau-
sibility requirements of incrementality and use of
limited computations. That is, when incremen-
tally adding or updating a word’s connections in
the network, the model only looks at a subset of
words rather than comparing the target word to all
the nodes in the network. We demonstrate that
</bodyText>
<page confidence="0.99105">
252
</page>
<table confidence="0.987417">
Comparing all Pairs
Method Semantic Connectivity Small World
p 1st 2nd 3rd sizel,, Qg (%)
Upper-bound −0.38 31 41 42 0.85 5.5
Baselines
Random −0.38 56 76.9 68.9 0.6 5.2 (2)
Context −0.39 97 115 89 0.5 0
Random+Context −0.36 63.3 87.2 79.1 0.6 0 (0)
Cluster-based Methods
Clusters-only −0.32 58.6 72.0 71.6 0.7 5.5 (43)
Clusters+Context −0.36 53.9 67.6 64.8 0.7 7.2 (77)
Clusters+Random −0.35 48.1 61.2 58.1 0.7 6.9 (48)
</table>
<tableCaption confidence="0.991792">
Table 2: Connectivity and small-worldness measures for the Upper-bound, Baseline, and Cluster-based
</tableCaption>
<bodyText confidence="0.962372923076923">
network-growth methods; best performances across the Baseline and Cluster-based methods are shown
in bold. p: co-efficient of correlation between similarities of word pairs in network and in gold-standard;
1st, 2nd, 3rd: median ranks of corresponding gold-standard associates given network similarities; sizel,,:
proportion of network in the largest connected component; Qg: overall “small-worldness”, should be
greater than 1; %: the percentage of runs whose resulting networks exhibit a small-world structure. Note
there are 1074 nouns in each network.
using the evolving knowledge of semantic con-
nections among words as well as their context of
usage enables the model to create a network that
shows the properties of adult semantic knowledge.
This suggests that the information in the semantic
relations among words and their context can effi-
ciently guide semantic network growth.
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99963125">
We would like to thank Varada Kolhatkar for valu-
able discussion and feedback. We are also grateful
for the financial support from NSERC of Canada,
and University of Toronto.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999758625">
John R. Anderson and Michael Matessa. 1992. Ex-
plorations of an incremental, bayesian algorithm for
categorization. Machine Learning, 9(4):275–308.
Lois Bloom. 1973. One word at a time: The use of
single word utterances before syntax, volume 154.
Mouton The Hague.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating wordnet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13–
47.
Susan Carey and Elsa Bartlett. 1978. Acquiring a sin-
gle new word.
Allan M. Collins and Elizabeth F. Loftus. 1975. A
spreading-activation theory of semantic processing.
Psychological review, 82(6):407.
Eliana Colunga and Linda B. Smith. 2005. From the
lexicon to expectations about kinds: A role for asso-
ciative learning. Psychological Review, 112(2):347–
382.
Paul Erdos and Alfr´ed R´enyi. 1960. On the evolution
of random graphs. Publ. Math. Inst. Hungar. Acad.
Sci, 5:17–61.
Afsaneh Fazly, Afra Alishahi, and Suzanne Steven-
son. 2010. A probabilistic computational model of
cross-situational word learning. Cognitive Science,
34(6):1017–1063.
Trevor Fountain and Mirella Lapata. 2011. Incremen-
tal models of natural language category acquisition.
In Proceedings of the 32stAnnual Conference of the
Cognitive Science Society.
Michael C. Frank, Noah D. Goodman, and Joshua B.
Tenenbaum. 2009. Using speakers referential inten-
tions to model early cross-situational word learning.
Psychological Science.
Michael C. Frank, Joshua B. Tenenbaum, and Anne
Fernald. 2013. Social and discourse contributions
to the determination of reference in cross-situational
word learning. Language Learning and Develop-
ment, 9(1):1–24.
Lila Gleitman. 1990. The structural sources of verb
meanings. Language Acquisition, 1(1):3–55.
Thomas L. Griffiths, Mark Steyvers, and Joshua B.
Tenenbaum. 2007. Topics in semantic representa-
tion. Psychological review, 114(2):211.
Michael W. Harm. 2002. Building large scale dis-
tributed semantic feature sets with WordNet. Tech-
nical Report PDP.CNS.02.1, Carnegie Mellon Uni-
versity.
</reference>
<page confidence="0.981941">
253
</page>
<reference confidence="0.999709975">
Mark D. Humphries and Kevin Gurney. 2008. Net-
work small-world-ness: a quantitative method for
determining canonical network equivalence. PLoS
One, 3(4):e0002051.
Susan S. Jones and Linda B. Smith. 2005. Object name
learning and object perception: a deficit in late talk-
ers. J. of Child Language, 32:223–240.
Susan S. Jones, Linda B. Smith, and Barbara Landau.
1991. Object properties and knowledge in early lex-
ical learning. Child Development, 62(3):499–516.
Brian MacWhinney. 2000. The CHILDES Project:
Tools for Analyzing Talk, volume 2: The Database.
Erlbaum, 3rd edition.
Radford M. Neal and Geoffrey E. Hinton. 1998. A
view of the em algorithm that justifies incremental,
sparse, and other variants. In Learning in graphical
models, pages 355–368. Springer.
Radford M. Neal. 2000. Markov chain sampling meth-
ods for dirichlet process mixture models. Journal
of computational and graphical statistics, 9(2):249–
265.
Aida Nematzadeh, Afsaneh Fazly, and Suzanne
Stevenson. 2012. Interaction of word learning and
semantic category formation in late talking. In Proc.
of CogSci’12.
Aida Nematzadeh, Afsaneh Fazly, and Suzanne
Stevenson. 2014. Structural differences in the se-
mantic networks of simulated word learners.
Thierry Poibeau, Aline Villavicencio, Anna Korhonen,
and Afra Alishahi, 2013. Computational Modeling
as a Methodology for Studying Human Language
Learning. Springer.
Willard Van Orman Quine. 1960. Word and Object.
MIT Press.
Terry Regier. 2005. The emergence of words: Atten-
tional learning in form and meaning. Cognitive Sci-
ence, 29:819–865.
Garry Robins, Philippa Pattison, and Jodie Woolcock.
2005. Small and other worlds: Global network
structures from local processes1. American Journal
of Sociology, 110(4):894–936.
Larissa K. Samuelson and Linda B. Smith. 1999. Early
noun vocabularies: do ontology, category structure
and syntax correspond? Cognition, 73(1):1 – 33.
Adam N. Sanborn, Thomas L. Griffiths, and Daniel J.
Navarro. 2010. Rational approximations to rational
models: alternative algorithms for category learning.
Jeffery Mark Siskind. 1996. A computational study
of cross-situational techniques for learning word-to-
meaning mappings. Cognition, 61:39–91.
Linda B. Smith and Chen Yu. 2008. Infants rapidly
learn word-referent mappings via cross-situational
statistics. Cognition, 106(3):1558–1568.
Mark Steyvers and Joshua B. Tenenbaum. 2005. The
large-scale structure of semantic networks: Statisti-
cal analyses and a model of semantic growth. Cog-
nitive science, 29(1):41–78.
Anna L. Theakston, Elena V. Lieven, Julian M. Pine,
and Caroline F. Rowland. 2001. The role of
performance limitations in the acquisition of verb–
argument structure: An alternative account. J. of
Child Language, 28:127–152.
Duncan J. Watts and Steven H. Strogatz. 1998. Col-
lective dynamics of small-worldnetworks. nature,
393(6684):440–442.
Zhibiao Wu and Martha Palmer. 1994. Verbs seman-
tics and lexical selection. In Proceedings of the 32nd
annual meeting on Association for Computational
Linguistics, pages 133–138. Association for Com-
putational Linguistics.
Chen Yu and Dana H. Ballard. 2007. A unified
model of early word learning: Integrating statistical
and social cues. Neurocomputing, 70(1315):2149
– 2165. Selected papers from the 3rd Interna-
tional Conference on Development and Learning
(ICDL 2004), Time series prediction competition:
the CATS benchmark.
Chen Yu and Linda B. Smith. 2007. Rapid word learn-
ing under uncertainty via cross-situational statistics.
Psychological Science, 18(5):414–420.
</reference>
<page confidence="0.998644">
254
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.963578">
<title confidence="0.999665">A Cognitive Model of Semantic Network Learning</title>
<author confidence="0.992203">Aida Nematzadeh</author>
<author confidence="0.992203">Afsaneh Fazly</author>
<author confidence="0.992203">Suzanne</author>
<affiliation confidence="0.9980985">Department of Computer University of</affiliation>
<abstract confidence="0.998527235294118">Child semantic development includes learning the meaning of words as well as the semantic relations among words. A presumed outcome of semantic development is the formation of a semantic network that reflects this knowledge. We present an algorithm for simultaneously learning word meanings and gradually growing a semantic network, which adheres to the cognitive plausibility requirements of incrementality and limited computations. We demonstrate that the semantic connections among words in addition to their context is necessary in forming a semantic network that resembles an adult’s semantic knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John R Anderson</author>
<author>Michael Matessa</author>
</authors>
<title>Explorations of an incremental, bayesian algorithm for categorization.</title>
<date>1992</date>
<booktitle>Machine Learning,</booktitle>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="3029" citStr="Anderson and Matessa, 1992" startWordPosition="438" endWordPosition="441">, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition, the first requirement is incrementality, which means that the model learns gradually as it processes the input. Also, there is a limit on the number of computations the model performs at each step</context>
<context position="5803" citStr="Anderson and Matessa, 1992" startWordPosition="872" endWordPosition="875">erlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of forming semantic clusters given a defined set of features for words (Anderson and Matessa, 1992; Griffiths et al., 2007; Sanborn et al., 2010). Anderson and Matessa (1992) note that a cognitively plausible categorization algorithm needs to be incremental and only keep track of one potential partitioning; they propose a Bayesian framework (the Rational Model of Categorization or RMC) that specifies the joint distribution on features and category labels, and allows an unbounded number of clusters. Sanborn et al. (2010) examine different categorization models based on RMC. In particular, they compare the performance of the approximation algorithm of Anderson and Matessa (1992) (local MAP) </context>
<context position="14225" citStr="Anderson and Matessa (1992)" startWordPosition="2301" endWordPosition="2304">ntally track semantic similarity among words usages as their meanings are developing. Specifically we cluster word tokens (not types) according to their current word meanings. Since the probabilistic meanings of words are continually evolving, incremental clusters of word tokens can capture developing similarities among the various usages of a word type, and be a clue to which words (types) w might be similar to. In the next section, we describe the Bayesian clustering process we use to identify potentially similar words. 3.3 Semantic Clustering of Word Tokens We use the Bayesian framework of Anderson and Matessa (1992) to form semantic clusters.3 Recall that for each word w, the model learns its meanings as a probability distribution over all semantic features, P(.|w). We represent this probability distribution as a vector F whose length is the number of possible semantic features. Each element of the vector holds the value P(f|w) (which is continuous). Given a word w and its vector F, we need to calculate the probability that w belongs to each existing cluster, and also allow for the possibility of it forming a new cluster. Using Bayes rule we have: P(k)P(F|k) P (k|F ) = � (3) k/ P(k0)P(F|k0) 3The distribu</context>
<context position="15820" citStr="Anderson and Matessa (1992)" startWordPosition="2597" endWordPosition="2601">ew cluster) α (4) where nk is the number of words in cluster k, n is the number of words observed so far, and α is a parameter that determines how likely the creation of a new cluster is. The prior favors larger clusters, and also discourages the creation of new clusters in later stages of learning. Calculation of Likelihood. To calculate the likelihood P(F |k) in Eqn. (3), we assume that the features are independent: P(F|k) = � P(fi = v|k) (5) fi∈F where P(fi = v|k) is the probability that the value of the feature in dimension i is equal to v given the cluster k. To derive P(fi|k), following Anderson and Matessa (1992), we assume that each feature given a cluster follows a Gaussian distribution with an unknown variance σ2 and mean µ. (In the absence of any prior information about a variable, it is often assumed to have a Gaussian distribution.) The mean and variance of this distribution are inferred using Bayesian analysis: We assume the variance has an inverse χ2 prior, where σ20 is the prior variance and a0 is the confidence in the prior variance: σ2 ∼ Inv-χ2(a0,σ20) (6) The mean given the variance has a Gaussian distribution with µ0 as the prior mean and λ0 as the confidence in the prior mean. σ2 µ|σ ∼ N</context>
</contexts>
<marker>Anderson, Matessa, 1992</marker>
<rawString>John R. Anderson and Michael Matessa. 1992. Explorations of an incremental, bayesian algorithm for categorization. Machine Learning, 9(4):275–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lois Bloom</author>
</authors>
<title>One word at a time: The use of single word utterances before syntax, volume 154. Mouton The Hague.</title>
<date>1973</date>
<contexts>
<context position="2367" citStr="Bloom, 1973" startWordPosition="337" endWordPosition="338">emantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how w</context>
</contexts>
<marker>Bloom, 1973</marker>
<rawString>Lois Bloom. 1973. One word at a time: The use of single word utterances before syntax, volume 154. Mouton The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating wordnet-based measures of lexical semantic relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>47</pages>
<contexts>
<context position="19838" citStr="Budanitsky and Hirst, 2006" startWordPosition="3313" endWordPosition="3316">emantic category. Moreover, this measure does not incorporate information about other types of similarities, for example, words are not considered similar if they occur in similar contexts. Thus, the scores calculated with this measure are comparable with those of our learned network. Given the gold-standard similarity scores for each word pair, we evaluate the semantic connectivity of the network based on two performance measures: coefficient of correlation and the median rank of the first five gold-standard associates. Correlation is a standard way to compare two lists of similarity scores (Budanitsky and Hirst, 2006). We create two lists, one containing the gold-standard similarity scores for all word pairs, and the other containing their corresponding learned similarity scores. We calculate the Spearman’s rank correlation coefficient, ρ, between these two lists of similarity scores. Note that the learned similarity scores reflect the semantic distance among words whereas the WordNet scores reflect semantic closeness. Thus, a negative correlation is best in our evaluation, where the value of -1 corresponds to the maximum correlation. Following Griffiths et al. (2007), we also calculate the median learned </context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating wordnet-based measures of lexical semantic relatedness. Computational Linguistics, 32(1):13– 47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Carey</author>
<author>Elsa Bartlett</author>
</authors>
<title>Acquiring a single new word.</title>
<date>1978</date>
<contexts>
<context position="2393" citStr="Carey and Bartlett, 1978" startWordPosition="339" endWordPosition="342">res of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are </context>
</contexts>
<marker>Carey, Bartlett, 1978</marker>
<rawString>Susan Carey and Elsa Bartlett. 1978. Acquiring a single new word.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan M Collins</author>
<author>Elizabeth F Loftus</author>
</authors>
<title>A spreading-activation theory of semantic processing.</title>
<date>1975</date>
<journal>Psychological review,</journal>
<volume>82</volume>
<issue>6</issue>
<contexts>
<context position="1837" citStr="Collins and Loftus, 1975" startWordPosition="263" endWordPosition="266">knowledge facilitates subsequent word learning (Jones et al., 1991; Colunga and Smith, 2005). Furthermore, representation of semantic knowledge is significant as it impacts how word meanings are stored in, searched for, and retrieved from memory (Steyvers and Tenenbaum, 2005; Griffiths et al., 2007). Semantic knowledge is often represented as a graph (a semantic network) in which nodes correspond to words/concepts1, and edges specify 1Here we assume that the nodes of a semantic network are word forms and its edges are determined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999;</context>
</contexts>
<marker>Collins, Loftus, 1975</marker>
<rawString>Allan M. Collins and Elizabeth F. Loftus. 1975. A spreading-activation theory of semantic processing. Psychological review, 82(6):407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eliana Colunga</author>
<author>Linda B Smith</author>
</authors>
<title>From the lexicon to expectations about kinds: A role for associative learning.</title>
<date>2005</date>
<journal>Psychological Review,</journal>
<volume>112</volume>
<issue>2</issue>
<pages>382</pages>
<contexts>
<context position="1305" citStr="Colunga and Smith, 2005" startWordPosition="180" endWordPosition="183">mong words in addition to their context is necessary in forming a semantic network that resembles an adult’s semantic knowledge. 1 Introduction Child semantic development includes the acquisition of word-to-concept mappings (part of word learning), and the formation of semantic connections among words/concepts. There is considerable evidence that understanding the semantic properties of words improves child vocabulary acquisition. In particular, children are sensitive to commonalities of semantic categories, and this abstract knowledge facilitates subsequent word learning (Jones et al., 1991; Colunga and Smith, 2005). Furthermore, representation of semantic knowledge is significant as it impacts how word meanings are stored in, searched for, and retrieved from memory (Steyvers and Tenenbaum, 2005; Griffiths et al., 2007). Semantic knowledge is often represented as a graph (a semantic network) in which nodes correspond to words/concepts1, and edges specify 1Here we assume that the nodes of a semantic network are word forms and its edges are determined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demon</context>
</contexts>
<marker>Colunga, Smith, 2005</marker>
<rawString>Eliana Colunga and Linda B. Smith. 2005. From the lexicon to expectations about kinds: A role for associative learning. Psychological Review, 112(2):347– 382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Erdos</author>
<author>Alfr´ed R´enyi</author>
</authors>
<title>On the evolution of random graphs.</title>
<date>1960</date>
<journal>Publ. Math. Inst. Hungar. Acad. Sci,</journal>
<pages>5--17</pages>
<marker>Erdos, R´enyi, 1960</marker>
<rawString>Paul Erdos and Alfr´ed R´enyi. 1960. On the evolution of random graphs. Publ. Math. Inst. Hungar. Acad. Sci, 5:17–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Afra Alishahi</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A probabilistic computational model of cross-situational word learning.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>6</issue>
<contexts>
<context position="2853" citStr="Fazly et al., 2010" startWordPosition="409" endWordPosition="412">has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition, the first requiremen</context>
<context position="5131" citStr="Fazly et al., 2010" startWordPosition="767" endWordPosition="770">he most dominant mechanisms proposed for vocabulary acquisition is crosssituational learning: people learn word meanings by recognizing and tracking statistical regularities among the contexts of a word’s usage across various situations, enabling them to narrow in on the meaning of a word that holds across its usages (Siskind, 1996; Yu and Smith, 2007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of forming semantic cluste</context>
<context position="8126" citStr="Fazly et al. (2010)" startWordPosition="1246" endWordPosition="1249">ot investigate the structure of the learned semantic network to see whether it has the properties observed in adult knowledge. 3 The Incremental Network Model We propose here a model that unifies the incremental acquisition of word meanings and formation of a semantic network structure that reflects the similarities among those meanings. We use an existing model to learn the meanings of words (Section 3.1), and use those incrementally developing meanings as the input to the algorithm proposed here for gradually growing a semantic network (Section 3.2). 3.1 The Word Learner We use the model of Fazly et al. (2010); this learning algorithm is incremental and involves limited calculations, thus satisfying basic cognitive plausibility requirements. A naturalistic language learning scenario consists of linguistic data in the context of non-linguistic data, such as the objects, 245 Utterance: {let, find, a, picture, to, color } Scene: {LET, PRONOUN, HAS POSSESSION, CAUSE, ARTIFACT, WHOLE, CHANGE,... } Table 1: A sample utterance-scene pair. events, and social interactions that a child perceives. This kind of input is modeled here as a pair of an utterance (the words a child hears) and a scene (the semantic </context>
<context position="26177" citStr="Fazly et al., 2010" startWordPosition="4388" endWordPosition="4391">.72, · · · , PLANT-PART:.22, PHYSICAL-ENTITY:.17, WHOLE:.06, · · · } hibit a scale-free structure; thus, we do not report the results of this evaluation, and leave it to future work for further investigation. Figure 1: Sample true meaning features &amp; their scores for apple from Nematzadeh et al. (2012). 5 Experimental Set-up 5.1 Input Representation Recall that the input to the model consists of a sequence of utterance–scene pairs intended to reflect the linguistic data a child is exposed to, along with the associated meaning a child might grasp. As in much previous work (Yu and Ballard, 2007; Fazly et al., 2010), we take child-directed utterances from the CHILDES database (MacWhinney, 2000) in order to have naturalistic data. In particular, we use the Manchester corpus (Theakston et al., 2001), which consists of transcripts of conversations with 12 British children between the ages of 1; 8 and 3; 0. We represent each utterance as a bag of lemmatized words (see Utterance in Table 1). For the scene representation, we have no large corpus to draw on that encodes the semantic portion of language acquisition data.6 We thus automatically generate the semantics associated with an utterance, using a scheme f</context>
</contexts>
<marker>Fazly, Alishahi, Stevenson, 2010</marker>
<rawString>Afsaneh Fazly, Afra Alishahi, and Suzanne Stevenson. 2010. A probabilistic computational model of cross-situational word learning. Cognitive Science, 34(6):1017–1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Fountain</author>
<author>Mirella Lapata</author>
</authors>
<title>Incremental models of natural language category acquisition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 32stAnnual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="3081" citStr="Fountain and Lapata, 2011" startWordPosition="446" endWordPosition="449">1; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition, the first requirement is incrementality, which means that the model learns gradually as it processes the input. Also, there is a limit on the number of computations the model performs at each step. In this paper, we present an algorithm for si244 P</context>
<context position="7314" citStr="Fountain and Lapata (2011)" startWordPosition="1108" endWordPosition="1111">esentation of Semantic Knowledge. There is limited work on computational models of semantic acquisition that examine the representation of the semantic knowledge. Steyvers and Tenenbaum (2005) propose an algorithm for building a network with small-world and scale-free structure. The algorithm starts with a small complete graph, incrementally adds new nodes to the graph, and for each new node uses a probabilistic mechanism for selecting a subset of current nodes to connect to. However, their approach does not address the problem of learning word meanings or the semantic connections among them. Fountain and Lapata (2011) propose an algorithm for learning categories that also creates a semantic network by comparing all the possible word pairs. However, they too do not address the word learning problem, and do not investigate the structure of the learned semantic network to see whether it has the properties observed in adult knowledge. 3 The Incremental Network Model We propose here a model that unifies the incremental acquisition of word meanings and formation of a semantic network structure that reflects the similarities among those meanings. We use an existing model to learn the meanings of words (Section 3.</context>
</contexts>
<marker>Fountain, Lapata, 2011</marker>
<rawString>Trevor Fountain and Mirella Lapata. 2011. Incremental models of natural language category acquisition. In Proceedings of the 32stAnnual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Frank</author>
<author>Noah D Goodman</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Using speakers referential intentions to model early cross-situational word learning.</title>
<date>2009</date>
<publisher>Psychological Science.</publisher>
<contexts>
<context position="2832" citStr="Frank et al., 2009" startWordPosition="405" endWordPosition="408">perimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition,</context>
</contexts>
<marker>Frank, Goodman, Tenenbaum, 2009</marker>
<rawString>Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum. 2009. Using speakers referential intentions to model early cross-situational word learning. Psychological Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Frank</author>
<author>Joshua B Tenenbaum</author>
<author>Anne Fernald</author>
</authors>
<title>Social and discourse contributions to the determination of reference in cross-situational word learning.</title>
<date>2013</date>
<journal>Language Learning and Development,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="27738" citStr="Frank et al. (2013)" startWordPosition="4661" endWordPosition="4664"> al. (2012) because the word meanings reflect information about their semantic categories, which is crucial to forming the semantic clusters as in Section 3.3. In this lexicon, the “true” meaning for each word w is a vector over a set of possible semantic features for each part of speech; in the vector, each feature is associated with a score for that word (see Figure 1). Depending on the word’s part of speech, the features are extracted from various 6Yu and Ballard (2007) created a corpus by hand-coding the objects and cues that were present in the environment, but that corpus is very small. Frank et al. (2013) provide a larger manually annotated corpus (5000 utterances), but it is still very small for longitudinal simulations of word learning. (Our corpus contains more than 100,000 utterances.) Moreover, the corpus of Frank et al. (2013) is limited because a considerable number of words are not semantically coded. (Only a subset of concrete objects in the environment are coded.) lexical resources such as WordNet7, VerbNet8, and Harm (2002). The score for each feature is calculated using a measure similar to tf-idf that reflects the association of the feature with the word and with its semantic cate</context>
</contexts>
<marker>Frank, Tenenbaum, Fernald, 2013</marker>
<rawString>Michael C. Frank, Joshua B. Tenenbaum, and Anne Fernald. 2013. Social and discourse contributions to the determination of reference in cross-situational word learning. Language Learning and Development, 9(1):1–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lila Gleitman</author>
</authors>
<title>The structural sources of verb meanings.</title>
<date>1990</date>
<journal>Language Acquisition,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="2409" citStr="Gleitman, 1990" startWordPosition="343" endWordPosition="344">mantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anders</context>
</contexts>
<marker>Gleitman, 1990</marker>
<rawString>Lila Gleitman. 1990. The structural sources of verb meanings. Language Acquisition, 1(1):3–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Topics in semantic representation.</title>
<date>2007</date>
<journal>Psychological review,</journal>
<volume>114</volume>
<issue>2</issue>
<contexts>
<context position="1513" citStr="Griffiths et al., 2007" startWordPosition="210" endWordPosition="213">ncept mappings (part of word learning), and the formation of semantic connections among words/concepts. There is considerable evidence that understanding the semantic properties of words improves child vocabulary acquisition. In particular, children are sensitive to commonalities of semantic categories, and this abstract knowledge facilitates subsequent word learning (Jones et al., 1991; Colunga and Smith, 2005). Furthermore, representation of semantic knowledge is significant as it impacts how word meanings are stored in, searched for, and retrieved from memory (Steyvers and Tenenbaum, 2005; Griffiths et al., 2007). Semantic knowledge is often represented as a graph (a semantic network) in which nodes correspond to words/concepts1, and edges specify 1Here we assume that the nodes of a semantic network are word forms and its edges are determined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, </context>
<context position="3053" citStr="Griffiths et al., 2007" startWordPosition="442" endWordPosition="445"> 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition, the first requirement is incrementality, which means that the model learns gradually as it processes the input. Also, there is a limit on the number of computations the model performs at each step. In this paper, we pres</context>
<context position="5827" citStr="Griffiths et al., 2007" startWordPosition="876" endWordPosition="879">earning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of forming semantic clusters given a defined set of features for words (Anderson and Matessa, 1992; Griffiths et al., 2007; Sanborn et al., 2010). Anderson and Matessa (1992) note that a cognitively plausible categorization algorithm needs to be incremental and only keep track of one potential partitioning; they propose a Bayesian framework (the Rational Model of Categorization or RMC) that specifies the joint distribution on features and category labels, and allows an unbounded number of clusters. Sanborn et al. (2010) examine different categorization models based on RMC. In particular, they compare the performance of the approximation algorithm of Anderson and Matessa (1992) (local MAP) with two other approxima</context>
<context position="20399" citStr="Griffiths et al. (2007)" startWordPosition="3400" endWordPosition="3403">re two lists of similarity scores (Budanitsky and Hirst, 2006). We create two lists, one containing the gold-standard similarity scores for all word pairs, and the other containing their corresponding learned similarity scores. We calculate the Spearman’s rank correlation coefficient, ρ, between these two lists of similarity scores. Note that the learned similarity scores reflect the semantic distance among words whereas the WordNet scores reflect semantic closeness. Thus, a negative correlation is best in our evaluation, where the value of -1 corresponds to the maximum correlation. Following Griffiths et al. (2007), we also calculate the median learned rank of the first five gold-standard associates for all words: For each word w, we first create a “gold-standard” associates list: we sort all other words based on their gold-standard similarity to w, and pick the five most similar words (associates) to w. Similarly, we create a “learned associate list” for w by sorting all words based on their learned semantic similarity to w. For all words, we find the ranks of their first five gold-standard associates in their learned associate list. For each associate, we calculate the median of these ranks for all wo</context>
</contexts>
<marker>Griffiths, Steyvers, Tenenbaum, 2007</marker>
<rawString>Thomas L. Griffiths, Mark Steyvers, and Joshua B. Tenenbaum. 2007. Topics in semantic representation. Psychological review, 114(2):211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael W Harm</author>
</authors>
<title>Building large scale distributed semantic feature sets with WordNet.</title>
<date>2002</date>
<tech>Technical Report PDP.CNS.02.1,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="28176" citStr="Harm (2002)" startWordPosition="4732" endWordPosition="4733"> various 6Yu and Ballard (2007) created a corpus by hand-coding the objects and cues that were present in the environment, but that corpus is very small. Frank et al. (2013) provide a larger manually annotated corpus (5000 utterances), but it is still very small for longitudinal simulations of word learning. (Our corpus contains more than 100,000 utterances.) Moreover, the corpus of Frank et al. (2013) is limited because a considerable number of words are not semantically coded. (Only a subset of concrete objects in the environment are coded.) lexical resources such as WordNet7, VerbNet8, and Harm (2002). The score for each feature is calculated using a measure similar to tf-idf that reflects the association of the feature with the word and with its semantic category: term frequency indicates the strength of association of the feature with the word, and inverse document frequency (where the documents are the categories) indicates how informative a feature is for that category. The semantic categories of nouns (which we focus on in our networks) are given by WordNet lex-names9, a set of 25 general categories of entities. (We use only nouns in our semantic networks because the semantic similari</context>
</contexts>
<marker>Harm, 2002</marker>
<rawString>Michael W. Harm. 2002. Building large scale distributed semantic feature sets with WordNet. Technical Report PDP.CNS.02.1, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark D Humphries</author>
<author>Kevin Gurney</author>
</authors>
<title>Network small-world-ness: a quantitative method for determining canonical network equivalence.</title>
<date>2008</date>
<journal>PLoS One,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="23418" citStr="Humphries and Gurney, 2008" startWordPosition="3926" endWordPosition="3929">ges possible for that neighborhood: C En = (13) kn(kn − 1)/2 The local clustering coefficient C ranges between 0 and 1. To estimate the connectedness of all neighborhoods in a network, we take the average of C over all nodes, i.e., Cavg. Small-world structure. A graph exhibits a small-world structure if dmedian is relatively small and Cavg is relatively high. To assess this for a graph g, these values are typically compared to those of a random graph with the same number of nodes and edges as g (Watts and Strogatz, 5We take the description of these measures from Nematzadeh et al. (2014) 1998; Humphries and Gurney, 2008). The random graph is generated by randomly rearranging the edges of the network under consideration (Erdos and R´enyi, 1960). Because any pair of nodes is equally likely to be connected as any other, the median of distances between nodes is expected to be low for a random graph. In a small-world network, this value dmedian is expected to be as small as that of a random graph: even though the random graph has edges more uniformly distributed, the small-world network has many locally-connected components which are connected via hubs. On the other hand, Cavg is expected to be much higher in a sm</context>
</contexts>
<marker>Humphries, Gurney, 2008</marker>
<rawString>Mark D. Humphries and Kevin Gurney. 2008. Network small-world-ness: a quantitative method for determining canonical network equivalence. PLoS One, 3(4):e0002051.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan S Jones</author>
<author>Linda B Smith</author>
</authors>
<title>Object name learning and object perception: a deficit in late talkers.</title>
<date>2005</date>
<journal>J. of Child Language,</journal>
<pages>32--223</pages>
<contexts>
<context position="2480" citStr="Jones and Smith, 2005" startWordPosition="353" endWordPosition="356">aum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011</context>
</contexts>
<marker>Jones, Smith, 2005</marker>
<rawString>Susan S. Jones and Linda B. Smith. 2005. Object name learning and object perception: a deficit in late talkers. J. of Child Language, 32:223–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan S Jones</author>
<author>Linda B Smith</author>
<author>Barbara Landau</author>
</authors>
<title>Object properties and knowledge in early lexical learning.</title>
<date>1991</date>
<journal>Child Development,</journal>
<volume>62</volume>
<issue>3</issue>
<contexts>
<context position="1279" citStr="Jones et al., 1991" startWordPosition="176" endWordPosition="179">mantic connections among words in addition to their context is necessary in forming a semantic network that resembles an adult’s semantic knowledge. 1 Introduction Child semantic development includes the acquisition of word-to-concept mappings (part of word learning), and the formation of semantic connections among words/concepts. There is considerable evidence that understanding the semantic properties of words improves child vocabulary acquisition. In particular, children are sensitive to commonalities of semantic categories, and this abstract knowledge facilitates subsequent word learning (Jones et al., 1991; Colunga and Smith, 2005). Furthermore, representation of semantic knowledge is significant as it impacts how word meanings are stored in, searched for, and retrieved from memory (Steyvers and Tenenbaum, 2005; Griffiths et al., 2007). Semantic knowledge is often represented as a graph (a semantic network) in which nodes correspond to words/concepts1, and edges specify 1Here we assume that the nodes of a semantic network are word forms and its edges are determined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers </context>
</contexts>
<marker>Jones, Smith, Landau, 1991</marker>
<rawString>Susan S. Jones, Linda B. Smith, and Barbara Landau. 1991. Object properties and knowledge in early lexical learning. Child Development, 62(3):499–516.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES Project: Tools for Analyzing Talk, volume 2: The Database. Erlbaum, 3rd edition.</title>
<date>2000</date>
<contexts>
<context position="26257" citStr="MacWhinney, 2000" startWordPosition="4401" endWordPosition="4402">-free structure; thus, we do not report the results of this evaluation, and leave it to future work for further investigation. Figure 1: Sample true meaning features &amp; their scores for apple from Nematzadeh et al. (2012). 5 Experimental Set-up 5.1 Input Representation Recall that the input to the model consists of a sequence of utterance–scene pairs intended to reflect the linguistic data a child is exposed to, along with the associated meaning a child might grasp. As in much previous work (Yu and Ballard, 2007; Fazly et al., 2010), we take child-directed utterances from the CHILDES database (MacWhinney, 2000) in order to have naturalistic data. In particular, we use the Manchester corpus (Theakston et al., 2001), which consists of transcripts of conversations with 12 British children between the ages of 1; 8 and 3; 0. We represent each utterance as a bag of lemmatized words (see Utterance in Table 1). For the scene representation, we have no large corpus to draw on that encodes the semantic portion of language acquisition data.6 We thus automatically generate the semantics associated with an utterance, using a scheme first introduced in Fazly et al. (2010). The idea is to first create an input gen</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. 2000. The CHILDES Project: Tools for Analyzing Talk, volume 2: The Database. Erlbaum, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford M Neal</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>A view of the em algorithm that justifies incremental, sparse, and other variants.</title>
<date>1998</date>
<booktitle>In Learning in graphical models,</booktitle>
<pages>355--368</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="9610" citStr="Neal and Hinton, 1998" startWordPosition="1486" endWordPosition="1489">c feature f, the model incrementally learns P(f|w) from cooccurrences of w and f across all the utterancescene pairs. For each word, the probability distribution over all semantic features, P(.|w), represents the word’s meaning. The estimation of P(.|w) is made possible by introducing a set of latent variables, alignments, that correspond to the possible mappings between words and features in a given utterance–scene pair. The learning problem is then to find the mappings that best explain the data, which is solved by using an incremental version of the expectation–maximization (EM) algorithm (Neal and Hinton, 1998). We skip the details of the derivations and only report the resulting formulas. The model processes one utterance-scene pair at a time. For the input pair processed at time t, first the probability of each possible alignment (alignment probability) is calculated as:2 P(aij |u, fi) = Pt−fi|wj)|w0) (1) Ew&apos;∈u P where u is the utterance, and aij is the alignment variable specifying the word wj that is mapped to the feature fi. Pt−1(fi|wj) is taken from the model’s current learned meaning of word wj. Initially, P0(fi|wj) is uniformly distributed. After calculating the alignment probabilities, the </context>
</contexts>
<marker>Neal, Hinton, 1998</marker>
<rawString>Radford M. Neal and Geoffrey E. Hinton. 1998. A view of the em algorithm that justifies incremental, sparse, and other variants. In Learning in graphical models, pages 355–368. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford M Neal</author>
</authors>
<title>Markov chain sampling methods for dirichlet process mixture models.</title>
<date>2000</date>
<journal>Journal of computational and graphical statistics,</journal>
<volume>9</volume>
<issue>2</issue>
<pages>265</pages>
<contexts>
<context position="14925" citStr="Neal, 2000" startWordPosition="2427" endWordPosition="2428">s a probability distribution over all semantic features, P(.|w). We represent this probability distribution as a vector F whose length is the number of possible semantic features. Each element of the vector holds the value P(f|w) (which is continuous). Given a word w and its vector F, we need to calculate the probability that w belongs to each existing cluster, and also allow for the possibility of it forming a new cluster. Using Bayes rule we have: P(k)P(F|k) P (k|F ) = � (3) k/ P(k0)P(F|k0) 3The distribution specified by this model is equivalent to that of a Dirichlet Process Mixture Model (Neal, 2000). where k is a given cluster. We thus need to calculate the prior probability, P(k), and the likelihood of each cluster, P(F|k). Calculation of Prior. The prior probability that word n + 1 is assigned to cluster k is calculated as: � nk nk &gt; 0 P(k) = n+α n+α nk = 0 (new cluster) α (4) where nk is the number of words in cluster k, n is the number of words observed so far, and α is a parameter that determines how likely the creation of a new cluster is. The prior favors larger clusters, and also discourages the creation of new clusters in later stages of learning. Calculation of Likelihood. To c</context>
</contexts>
<marker>Neal, 2000</marker>
<rawString>Radford M. Neal. 2000. Markov chain sampling methods for dirichlet process mixture models. Journal of computational and graphical statistics, 9(2):249– 265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aida Nematzadeh</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Interaction of word learning and semantic category formation in late talking.</title>
<date>2012</date>
<booktitle>In Proc. of CogSci’12.</booktitle>
<contexts>
<context position="25860" citStr="Nematzadeh et al. (2012)" startWordPosition="4334" endWordPosition="4337">network) will follow a power-law distribution (which is said to be “scalefree”). We evaluate this property of a network by plotting its degree distribution in the logarithmic scale, which (if a power-law distribution) should appear as a straight line. None of our networks exQg = (14) sizelcc = 249 apple: l FOOD:1, SOLID:.72, · · · , PLANT-PART:.22, PHYSICAL-ENTITY:.17, WHOLE:.06, · · · } hibit a scale-free structure; thus, we do not report the results of this evaluation, and leave it to future work for further investigation. Figure 1: Sample true meaning features &amp; their scores for apple from Nematzadeh et al. (2012). 5 Experimental Set-up 5.1 Input Representation Recall that the input to the model consists of a sequence of utterance–scene pairs intended to reflect the linguistic data a child is exposed to, along with the associated meaning a child might grasp. As in much previous work (Yu and Ballard, 2007; Fazly et al., 2010), we take child-directed utterances from the CHILDES database (MacWhinney, 2000) in order to have naturalistic data. In particular, we use the Manchester corpus (Theakston et al., 2001), which consists of transcripts of conversations with 12 British children between the ages of 1; 8</context>
<context position="27130" citStr="Nematzadeh et al. (2012)" startWordPosition="4553" endWordPosition="4556">g of lemmatized words (see Utterance in Table 1). For the scene representation, we have no large corpus to draw on that encodes the semantic portion of language acquisition data.6 We thus automatically generate the semantics associated with an utterance, using a scheme first introduced in Fazly et al. (2010). The idea is to first create an input generation lexicon that provides a mapping between all the words in the input data and their associated meanings. A scene is then represented as a set that contains the meanings of all the words in the utterance. We use the input generation lexicon of Nematzadeh et al. (2012) because the word meanings reflect information about their semantic categories, which is crucial to forming the semantic clusters as in Section 3.3. In this lexicon, the “true” meaning for each word w is a vector over a set of possible semantic features for each part of speech; in the vector, each feature is associated with a score for that word (see Figure 1). Depending on the word’s part of speech, the features are extracted from various 6Yu and Ballard (2007) created a corpus by hand-coding the objects and cues that were present in the environment, but that corpus is very small. Frank et al</context>
</contexts>
<marker>Nematzadeh, Fazly, Stevenson, 2012</marker>
<rawString>Aida Nematzadeh, Afsaneh Fazly, and Suzanne Stevenson. 2012. Interaction of word learning and semantic category formation in late talking. In Proc. of CogSci’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aida Nematzadeh</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Structural differences in the semantic networks of simulated word learners.</title>
<date>2014</date>
<contexts>
<context position="5486" citStr="Nematzadeh et al., 2014" startWordPosition="822" endWordPosition="825">007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of forming semantic clusters given a defined set of features for words (Anderson and Matessa, 1992; Griffiths et al., 2007; Sanborn et al., 2010). Anderson and Matessa (1992) note that a cognitively plausible categorization algorithm needs to be incremental and only keep track of one potential partitioning; they propose a Bayesian framework (the Rational Model of Categorization </context>
<context position="23384" citStr="Nematzadeh et al. (2014)" startWordPosition="3920" endWordPosition="3924">En) to the maximum number of edges possible for that neighborhood: C En = (13) kn(kn − 1)/2 The local clustering coefficient C ranges between 0 and 1. To estimate the connectedness of all neighborhoods in a network, we take the average of C over all nodes, i.e., Cavg. Small-world structure. A graph exhibits a small-world structure if dmedian is relatively small and Cavg is relatively high. To assess this for a graph g, these values are typically compared to those of a random graph with the same number of nodes and edges as g (Watts and Strogatz, 5We take the description of these measures from Nematzadeh et al. (2014) 1998; Humphries and Gurney, 2008). The random graph is generated by randomly rearranging the edges of the network under consideration (Erdos and R´enyi, 1960). Because any pair of nodes is equally likely to be connected as any other, the median of distances between nodes is expected to be low for a random graph. In a small-world network, this value dmedian is expected to be as small as that of a random graph: even though the random graph has edges more uniformly distributed, the small-world network has many locally-connected components which are connected via hubs. On the other hand, Cavg is </context>
</contexts>
<marker>Nematzadeh, Fazly, Stevenson, 2014</marker>
<rawString>Aida Nematzadeh, Afsaneh Fazly, and Suzanne Stevenson. 2014. Structural differences in the semantic networks of simulated word learners.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Poibeau</author>
<author>Aline Villavicencio</author>
<author>Anna Korhonen</author>
<author>Afra Alishahi</author>
</authors>
<title>Computational Modeling as a Methodology for Studying Human Language Learning.</title>
<date>2013</date>
<publisher>Springer.</publisher>
<contexts>
<context position="3397" citStr="Poibeau et al., 2013" startWordPosition="497" endWordPosition="500">; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model semantic acquisition, the first requirement is incrementality, which means that the model learns gradually as it processes the input. Also, there is a limit on the number of computations the model performs at each step. In this paper, we present an algorithm for si244 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 244–254, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics multaneously learning word meanings and growing a semantic network, which adheres to the cognitive plausibility requirement</context>
</contexts>
<marker>Poibeau, Villavicencio, Korhonen, Alishahi, 2013</marker>
<rawString>Thierry Poibeau, Aline Villavicencio, Anna Korhonen, and Afra Alishahi, 2013. Computational Modeling as a Methodology for Studying Human Language Learning. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willard Van Orman Quine</author>
</authors>
<title>Word and Object.</title>
<date>1960</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2354" citStr="Quine, 1960" startWordPosition="335" endWordPosition="336">ined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into </context>
</contexts>
<marker>Quine, 1960</marker>
<rawString>Willard Van Orman Quine. 1960. Word and Object. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Regier</author>
</authors>
<title>The emergence of words: Attentional learning in form and meaning.</title>
<date>2005</date>
<journal>Cognitive Science,</journal>
<pages>29--819</pages>
<contexts>
<context position="2790" citStr="Regier, 2005" startWordPosition="398" endWordPosition="399">nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al.</context>
</contexts>
<marker>Regier, 2005</marker>
<rawString>Terry Regier. 2005. The emergence of words: Attentional learning in form and meaning. Cognitive Science, 29:819–865.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Garry Robins</author>
<author>Philippa Pattison</author>
<author>Jodie Woolcock</author>
</authors>
<title>Small and other worlds: Global network structures from local processes1.</title>
<date>2005</date>
<journal>American Journal of Sociology,</journal>
<volume>110</volume>
<issue>4</issue>
<contexts>
<context position="22114" citStr="Robins et al., 2005" startWordPosition="3692" endWordPosition="3695">properties are measured for a graph with N nodes and E edges. Then we discuss how these properties are used in assessing the small-world structure of a graph.5. Short path lengths. Most of the nodes of a small-world network are reachable from other nodes via relatively short paths. For a connected network (i.e., all the node pairs are reachable from each other), this can be measured as the average distance between all node pairs (Watts and Strogatz, 1998). Since our networks are not connected, we instead measure this property using the median of the distances (dmedian) between all node pairs (Robins et al., 2005), which is well-defined even when some node pairs have a distance of oc. Highly-connected neighborhoods. The neighborhood of a node n in a graph consists of n and all of the nodes that are connected to it. A neighborhood is maximally connected if it forms a complete graph —i.e., there is an edge between all node pairs. Thus, the maximum number of edges in the neighborhood of n is kn(kn − 1)/2, where kn is the number of neighbors. A standard metric for measuring the connectedness of neighbors of a node n is called the local clustering coefficient (C) (Watts and Strogatz, 1998), which calculates</context>
</contexts>
<marker>Robins, Pattison, Woolcock, 2005</marker>
<rawString>Garry Robins, Philippa Pattison, and Jodie Woolcock. 2005. Small and other worlds: Global network structures from local processes1. American Journal of Sociology, 110(4):894–936.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larissa K Samuelson</author>
<author>Linda B Smith</author>
</authors>
<title>Early noun vocabularies: do ontology, category structure and syntax correspond?</title>
<date>1999</date>
<journal>Cognition,</journal>
<volume>73</volume>
<issue>1</issue>
<contexts>
<context position="2436" citStr="Samuelson and Smith, 1999" startWordPosition="345" endWordPosition="348"> (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-connected local sub-networks, where these sub-networks are connected through high-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griff</context>
</contexts>
<marker>Samuelson, Smith, 1999</marker>
<rawString>Larissa K. Samuelson and Linda B. Smith. 1999. Early noun vocabularies: do ontology, category structure and syntax correspond? Cognition, 73(1):1 – 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam N Sanborn</author>
<author>Thomas L Griffiths</author>
<author>Daniel J Navarro</author>
</authors>
<title>Rational approximations to rational models: alternative algorithms for category learning.</title>
<date>2010</date>
<contexts>
<context position="5850" citStr="Sanborn et al., 2010" startWordPosition="880" endWordPosition="883">m consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of forming semantic clusters given a defined set of features for words (Anderson and Matessa, 1992; Griffiths et al., 2007; Sanborn et al., 2010). Anderson and Matessa (1992) note that a cognitively plausible categorization algorithm needs to be incremental and only keep track of one potential partitioning; they propose a Bayesian framework (the Rational Model of Categorization or RMC) that specifies the joint distribution on features and category labels, and allows an unbounded number of clusters. Sanborn et al. (2010) examine different categorization models based on RMC. In particular, they compare the performance of the approximation algorithm of Anderson and Matessa (1992) (local MAP) with two other approximation algorithms (Gibbs </context>
<context position="18672" citStr="Sanborn et al., 2010" startWordPosition="3128" endWordPosition="3131">exhibits a small-world and scale-free structure or not. 4.1 Evaluating Semantic Connectivity The distance between the words in the network indicates their semantic similarity: the more similar a word pair, the smaller their distance. For word pairs that are connected via a path in the network, this distance is the weighted shortest path length between the two words. If there is no path between a word pair, their distance is considered to be oc (which is represented with a large number). We refer to this distance as the “learned” semantic similarity. 4This approach is referred to as local MAP (Sanborn et al., 2010); because of the incremental nature of the algorithm, it maximizes the current posterior distribution as opposed to the “global” posterior. To evaluate the semantic connectivity of the learned network, we compare these learned similarity scores to “gold-standard” similarity scores that are calculated using the WordNet similarity measure of Wu and Palmer (1994) (also known as the WUP measure). We choose this measure since it captures the same type of similarity as in our model: words are considered similar if they belong to the same semantic category. Moreover, this measure does not incorporate</context>
</contexts>
<marker>Sanborn, Griffiths, Navarro, 2010</marker>
<rawString>Adam N. Sanborn, Thomas L. Griffiths, and Daniel J. Navarro. 2010. Rational approximations to rational models: alternative algorithms for category learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffery Mark Siskind</author>
</authors>
<title>A computational study of cross-situational techniques for learning word-tomeaning mappings.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--39</pages>
<contexts>
<context position="2776" citStr="Siskind, 1996" startWordPosition="396" endWordPosition="397">h-degree hubs (nodes with many neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (</context>
<context position="4845" citStr="Siskind, 1996" startWordPosition="722" endWordPosition="723">le-free structure. 2 Related Work Models of Word Learning. Given a word learning scenario, there are potentially many possible mappings between words in a sentence and their meanings (real-world referents), from which only some mappings are correct (the mapping problem). One of the most dominant mechanisms proposed for vocabulary acquisition is crosssituational learning: people learn word meanings by recognizing and tracking statistical regularities among the contexts of a word’s usage across various situations, enabling them to narrow in on the meaning of a word that holds across its usages (Siskind, 1996; Yu and Smith, 2007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of</context>
</contexts>
<marker>Siskind, 1996</marker>
<rawString>Jeffery Mark Siskind. 1996. A computational study of cross-situational techniques for learning word-tomeaning mappings. Cognition, 61:39–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda B Smith</author>
<author>Chen Yu</author>
</authors>
<title>Infants rapidly learn word-referent mappings via cross-situational statistics.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>106</volume>
<issue>3</issue>
<contexts>
<context position="4886" citStr="Smith and Yu, 2008" startWordPosition="728" endWordPosition="731">odels of Word Learning. Given a word learning scenario, there are potentially many possible mappings between words in a sentence and their meanings (real-world referents), from which only some mappings are correct (the mapping problem). One of the most dominant mechanisms proposed for vocabulary acquisition is crosssituational learning: people learn word meanings by recognizing and tracking statistical regularities among the contexts of a word’s usage across various situations, enabling them to narrow in on the meaning of a word that holds across its usages (Siskind, 1996; Yu and Smith, 2007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014)</context>
</contexts>
<marker>Smith, Yu, 2008</marker>
<rawString>Linda B. Smith and Chen Yu. 2008. Infants rapidly learn word-referent mappings via cross-situational statistics. Cognition, 106(3):1558–1568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>The large-scale structure of semantic networks: Statistical analyses and a model of semantic growth.</title>
<date>2005</date>
<journal>Cognitive science,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1488" citStr="Steyvers and Tenenbaum, 2005" startWordPosition="206" endWordPosition="209"> the acquisition of word-to-concept mappings (part of word learning), and the formation of semantic connections among words/concepts. There is considerable evidence that understanding the semantic properties of words improves child vocabulary acquisition. In particular, children are sensitive to commonalities of semantic categories, and this abstract knowledge facilitates subsequent word learning (Jones et al., 1991; Colunga and Smith, 2005). Furthermore, representation of semantic knowledge is significant as it impacts how word meanings are stored in, searched for, and retrieved from memory (Steyvers and Tenenbaum, 2005; Griffiths et al., 2007). Semantic knowledge is often represented as a graph (a semantic network) in which nodes correspond to words/concepts1, and edges specify 1Here we assume that the nodes of a semantic network are word forms and its edges are determined by the semantic features of those words. the semantic relations (Collins and Loftus, 1975; Steyvers and Tenenbaum, 2005). Steyvers and Tenenbaum (2005) demonstrated that a semantic network that encodes adult-level knowledge of words exhibits a small-world and scale-free structure. That is, it is an overall sparse network with highly-conne</context>
<context position="6880" citStr="Steyvers and Tenenbaum (2005)" startWordPosition="1038" endWordPosition="1041">tegorization models based on RMC. In particular, they compare the performance of the approximation algorithm of Anderson and Matessa (1992) (local MAP) with two other approximation algorithms (Gibbs Sampling and Particle Filters) in various human categorization paradigms. Sanborn et al. (2010) find that in most of the simulations the local MAP algorithm performs as well as the two other algorithms in matching human behavior. The Representation of Semantic Knowledge. There is limited work on computational models of semantic acquisition that examine the representation of the semantic knowledge. Steyvers and Tenenbaum (2005) propose an algorithm for building a network with small-world and scale-free structure. The algorithm starts with a small complete graph, incrementally adds new nodes to the graph, and for each new node uses a probabilistic mechanism for selecting a subset of current nodes to connect to. However, their approach does not address the problem of learning word meanings or the semantic connections among them. Fountain and Lapata (2011) propose an algorithm for learning categories that also creates a semantic network by comparing all the possible word pairs. However, they too do not address the word</context>
<context position="12876" citStr="Steyvers and Tenenbaum, 2005" startWordPosition="2055" endWordPosition="2058">be removed, or have their weight adjusted. Next, to look for new connections for w, the idea is to select only a small subset of words, S, to which w will be compared. The challenge then is to select S in a way that will yield a network whose semantic structure reasonably approximates the network that would result from full knowledge of comparing w to all the words. Previous work has suggested picking “important” words (e.g., high-degree words) independently of the target word w — assuming these might be words for which a learner might need to understand their relationship to w in the future (Steyvers and Tenenbaum, 2005). Our proposal is instead to consider for S those words that are 246 Algorithm 1 Growing a network after each input u. for all w in u do update P(.|w) using Eqn. (2) update current connections of w select S(w), a subset of words in the network for all w0 in S(w) do if w and w0 are sufficiently similar then connect w and w0 with an edge end if end for end for likely to be similar to w. That is, since the network only needs to connect similar words to w, if we can guess what (some of) those words are, then we will do best at approximating the situation of comparing w to all words. The question n</context>
<context position="24567" citStr="Steyvers and Tenenbaum (2005)" startWordPosition="4117" endWordPosition="4120">onnected via hubs. On the other hand, Cavg is expected to be much higher in a small-world network compared to its corresponding random graph, because the edges of a random graph typically do not fall into clusters forming highly connected neighborhoods. Given these two properties, the “smallworldness” of a graph g is measured as follows (Humphries and Gurney, 2008): Cavg(g) Cavg(random) dmedian(g) dmedian(random) where random is the random graph corresponding to g. In a small-world network, it is expected that Cavg(g) » Cavg(random) and dmedian(g) ≥ dmedian(random), and thus Qg &gt; 1. Note that Steyvers and Tenenbaum (2005) made the empirical observation that small-world networks of semantic knowledge had a single connected component that contained the majority of nodes in the network. Thus, in addition to Qg, we also measure the relative size of a network’s largest connected component having size Nlcc: Nlcc (15) N Scale-free structure. A scale-free network has a relatively small number of high-degree nodes that have a large number of connections to other nodes, while most of its nodes have a small degree, as they are only connected to a few nodes. Thus, if a network has a scale-free structure, its degree distri</context>
<context position="32569" citStr="Steyvers and Tenenbaum, 2005" startWordPosition="5458" endWordPosition="5461">rate different types of semantic information in selecting S, we also create a Clusters+Context network that picks half of the members of S from clusters (as above), and half from the prior context. For completeness, we include a Clusters+Random network that similarly chooses half of words in S from clusters and half randomly from all observed words. We have experimented with several other methods, but they all performed substantially worse than the baselines, and hence we do not report them here. E.g., we tried picking words in S from the best cluster. We also tried a few methods inspired by (Steyvers and Tenenbaum, 2005): E.g., we examined a method where if a member of S(w) was sufficiently similar to w, we added the direct neighbors of that word to S. We also tried to grow networks by choosing the members of S according to the degree or frequency of nodes in the network. 5.3 Experimental Parameters We use 20, 000 utterance–scene pairs as our training data. Recall that we use clustering to help guide our semantic network growth algorithm. Given the clustering algorithm in Section 3.3, we are interested to find the set of clusters that best explain the data. (Other clustering algorithms can be used instead of </context>
</contexts>
<marker>Steyvers, Tenenbaum, 2005</marker>
<rawString>Mark Steyvers and Joshua B. Tenenbaum. 2005. The large-scale structure of semantic networks: Statistical analyses and a model of semantic growth. Cognitive science, 29(1):41–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna L Theakston</author>
<author>Elena V Lieven</author>
<author>Julian M Pine</author>
<author>Caroline F Rowland</author>
</authors>
<title>The role of performance limitations in the acquisition of verb– argument structure: An alternative account.</title>
<date>2001</date>
<journal>J. of Child Language,</journal>
<pages>28--127</pages>
<contexts>
<context position="26362" citStr="Theakston et al., 2001" startWordPosition="4417" endWordPosition="4420"> for further investigation. Figure 1: Sample true meaning features &amp; their scores for apple from Nematzadeh et al. (2012). 5 Experimental Set-up 5.1 Input Representation Recall that the input to the model consists of a sequence of utterance–scene pairs intended to reflect the linguistic data a child is exposed to, along with the associated meaning a child might grasp. As in much previous work (Yu and Ballard, 2007; Fazly et al., 2010), we take child-directed utterances from the CHILDES database (MacWhinney, 2000) in order to have naturalistic data. In particular, we use the Manchester corpus (Theakston et al., 2001), which consists of transcripts of conversations with 12 British children between the ages of 1; 8 and 3; 0. We represent each utterance as a bag of lemmatized words (see Utterance in Table 1). For the scene representation, we have no large corpus to draw on that encodes the semantic portion of language acquisition data.6 We thus automatically generate the semantics associated with an utterance, using a scheme first introduced in Fazly et al. (2010). The idea is to first create an input generation lexicon that provides a mapping between all the words in the input data and their associated mean</context>
</contexts>
<marker>Theakston, Lieven, Pine, Rowland, 2001</marker>
<rawString>Anna L. Theakston, Elena V. Lieven, Julian M. Pine, and Caroline F. Rowland. 2001. The role of performance limitations in the acquisition of verb– argument structure: An alternative account. J. of Child Language, 28:127–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duncan J Watts</author>
<author>Steven H Strogatz</author>
</authors>
<title>Collective dynamics of small-worldnetworks. nature,</title>
<date>1998</date>
<pages>393--6684</pages>
<contexts>
<context position="21465" citStr="Watts and Strogatz, 1998" startWordPosition="3582" endWordPosition="3585">d the ranks of their first five gold-standard associates in their learned associate list. For each associate, we calculate the median of these ranks for all words. We only report the results for the first three gold-standard associates since the pattern of results is similar for the fourth and fifth associates; we refer to the median rank of first three gold-standard associates as µi = 248 1st, 2nd, and 3rd. 4.2 Evaluating the Structure of the Network A network exhibits a small-world structure when it is characterized by short path length between most nodes and highly-connected neighborhoods (Watts and Strogatz, 1998). We first explain how these properties are measured for a graph with N nodes and E edges. Then we discuss how these properties are used in assessing the small-world structure of a graph.5. Short path lengths. Most of the nodes of a small-world network are reachable from other nodes via relatively short paths. For a connected network (i.e., all the node pairs are reachable from each other), this can be measured as the average distance between all node pairs (Watts and Strogatz, 1998). Since our networks are not connected, we instead measure this property using the median of the distances (dmed</context>
<context position="22696" citStr="Watts and Strogatz, 1998" startWordPosition="3798" endWordPosition="3801">etween all node pairs (Robins et al., 2005), which is well-defined even when some node pairs have a distance of oc. Highly-connected neighborhoods. The neighborhood of a node n in a graph consists of n and all of the nodes that are connected to it. A neighborhood is maximally connected if it forms a complete graph —i.e., there is an edge between all node pairs. Thus, the maximum number of edges in the neighborhood of n is kn(kn − 1)/2, where kn is the number of neighbors. A standard metric for measuring the connectedness of neighbors of a node n is called the local clustering coefficient (C) (Watts and Strogatz, 1998), which calculates the ratio of edges in the neighborhood of n (En) to the maximum number of edges possible for that neighborhood: C En = (13) kn(kn − 1)/2 The local clustering coefficient C ranges between 0 and 1. To estimate the connectedness of all neighborhoods in a network, we take the average of C over all nodes, i.e., Cavg. Small-world structure. A graph exhibits a small-world structure if dmedian is relatively small and Cavg is relatively high. To assess this for a graph g, these values are typically compared to those of a random graph with the same number of nodes and edges as g (Watt</context>
</contexts>
<marker>Watts, Strogatz, 1998</marker>
<rawString>Duncan J. Watts and Steven H. Strogatz. 1998. Collective dynamics of small-worldnetworks. nature, 393(6684):440–442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19034" citStr="Wu and Palmer (1994)" startWordPosition="3181" endWordPosition="3184">ords. If there is no path between a word pair, their distance is considered to be oc (which is represented with a large number). We refer to this distance as the “learned” semantic similarity. 4This approach is referred to as local MAP (Sanborn et al., 2010); because of the incremental nature of the algorithm, it maximizes the current posterior distribution as opposed to the “global” posterior. To evaluate the semantic connectivity of the learned network, we compare these learned similarity scores to “gold-standard” similarity scores that are calculated using the WordNet similarity measure of Wu and Palmer (1994) (also known as the WUP measure). We choose this measure since it captures the same type of similarity as in our model: words are considered similar if they belong to the same semantic category. Moreover, this measure does not incorporate information about other types of similarities, for example, words are not considered similar if they occur in similar contexts. Thus, the scores calculated with this measure are comparable with those of our learned network. Given the gold-standard similarity scores for each word pair, we evaluate the semantic connectivity of the network based on two performan</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verbs semantics and lexical selection. In Proceedings of the 32nd annual meeting on Association for Computational Linguistics, pages 133–138. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Dana H Ballard</author>
</authors>
<title>A unified model of early word learning: Integrating statistical and social cues.</title>
<date>2007</date>
<journal>Neurocomputing,</journal>
<booktitle>Selected papers from the 3rd International Conference on Development and Learning (ICDL</booktitle>
<volume>70</volume>
<issue>1315</issue>
<pages>2165</pages>
<contexts>
<context position="2812" citStr="Yu and Ballard, 2007" startWordPosition="400" endWordPosition="404">y neighbours). Much experimental research has investigated the underlying mechanisms of vocabulary learning and characteristics of semantic knowledge (Quine, 1960; Bloom, 1973; Carey and Bartlett, 1978; Gleitman, 1990; Samuelson and Smith, 1999; Jones et al., 1991; Jones and Smith, 2005). However, existing computational models focus on certain aspects of semantic acquisition: Some researchers develop computational models of word learning without considering the acquisition of semantic connections that hold among words, or how this semantic knowledge is structured (Siskind, 1996; Regier, 2005; Yu and Ballard, 2007; Frank et al., 2009; Fazly et al., 2010). Another line of work is to model formation of semantic categories but this work does not take into account how word meanings/concepts are acquired (Anderson and Matessa, 1992; Griffiths et al., 2007; Fountain and Lapata, 2011). Our goal in this work is to provide a cognitivelyplausible and unified account for both acquiring and representing semantic knowledge. The requirements for cognitive plausibility enforce some constraints on a model to ensure that it is comparable with the cognitive process it is formulating (Poibeau et al., 2013). As we model s</context>
<context position="5110" citStr="Yu and Ballard, 2007" startWordPosition="762" endWordPosition="766">ing problem). One of the most dominant mechanisms proposed for vocabulary acquisition is crosssituational learning: people learn word meanings by recognizing and tracking statistical regularities among the contexts of a word’s usage across various situations, enabling them to narrow in on the meaning of a word that holds across its usages (Siskind, 1996; Yu and Smith, 2007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nematzadeh et al., 2014). However, that work did not address how such structural knowledge might develop and evolve incrementally within the learning model. Models of Categorization. Computational models of categorization focus on the problem of fo</context>
<context position="26156" citStr="Yu and Ballard, 2007" startWordPosition="4384" endWordPosition="4387">pple: l FOOD:1, SOLID:.72, · · · , PLANT-PART:.22, PHYSICAL-ENTITY:.17, WHOLE:.06, · · · } hibit a scale-free structure; thus, we do not report the results of this evaluation, and leave it to future work for further investigation. Figure 1: Sample true meaning features &amp; their scores for apple from Nematzadeh et al. (2012). 5 Experimental Set-up 5.1 Input Representation Recall that the input to the model consists of a sequence of utterance–scene pairs intended to reflect the linguistic data a child is exposed to, along with the associated meaning a child might grasp. As in much previous work (Yu and Ballard, 2007; Fazly et al., 2010), we take child-directed utterances from the CHILDES database (MacWhinney, 2000) in order to have naturalistic data. In particular, we use the Manchester corpus (Theakston et al., 2001), which consists of transcripts of conversations with 12 British children between the ages of 1; 8 and 3; 0. We represent each utterance as a bag of lemmatized words (see Utterance in Table 1). For the scene representation, we have no large corpus to draw on that encodes the semantic portion of language acquisition data.6 We thus automatically generate the semantics associated with an uttera</context>
<context position="27596" citStr="Yu and Ballard (2007)" startWordPosition="4636" endWordPosition="4639"> is then represented as a set that contains the meanings of all the words in the utterance. We use the input generation lexicon of Nematzadeh et al. (2012) because the word meanings reflect information about their semantic categories, which is crucial to forming the semantic clusters as in Section 3.3. In this lexicon, the “true” meaning for each word w is a vector over a set of possible semantic features for each part of speech; in the vector, each feature is associated with a score for that word (see Figure 1). Depending on the word’s part of speech, the features are extracted from various 6Yu and Ballard (2007) created a corpus by hand-coding the objects and cues that were present in the environment, but that corpus is very small. Frank et al. (2013) provide a larger manually annotated corpus (5000 utterances), but it is still very small for longitudinal simulations of word learning. (Our corpus contains more than 100,000 utterances.) Moreover, the corpus of Frank et al. (2013) is limited because a considerable number of words are not semantically coded. (Only a subset of concrete objects in the environment are coded.) lexical resources such as WordNet7, VerbNet8, and Harm (2002). The score for each</context>
</contexts>
<marker>Yu, Ballard, 2007</marker>
<rawString>Chen Yu and Dana H. Ballard. 2007. A unified model of early word learning: Integrating statistical and social cues. Neurocomputing, 70(1315):2149 – 2165. Selected papers from the 3rd International Conference on Development and Learning (ICDL 2004), Time series prediction competition: the CATS benchmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Linda B Smith</author>
</authors>
<title>Rapid word learning under uncertainty via cross-situational statistics.</title>
<date>2007</date>
<journal>Psychological Science,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="4865" citStr="Yu and Smith, 2007" startWordPosition="724" endWordPosition="727">re. 2 Related Work Models of Word Learning. Given a word learning scenario, there are potentially many possible mappings between words in a sentence and their meanings (real-world referents), from which only some mappings are correct (the mapping problem). One of the most dominant mechanisms proposed for vocabulary acquisition is crosssituational learning: people learn word meanings by recognizing and tracking statistical regularities among the contexts of a word’s usage across various situations, enabling them to narrow in on the meaning of a word that holds across its usages (Siskind, 1996; Yu and Smith, 2007; Smith and Yu, 2008). A number of computational models attempt to solve the mapping problem by implementing this mechanism, and have successfully replicated different patterns observed in child word learning (Siskind, 1996; Yu and Ballard, 2007; Fazly et al., 2010). These models have provided insight about underlying mechanisms of word learning, but none of them consider the semantic relations that hold among words, or how the semantic knowledge is structured. Recently, we have investigated properties of the semantic structure of the resulting (final) acquired knowledge of such a learner (Nem</context>
</contexts>
<marker>Yu, Smith, 2007</marker>
<rawString>Chen Yu and Linda B. Smith. 2007. Rapid word learning under uncertainty via cross-situational statistics. Psychological Science, 18(5):414–420.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>