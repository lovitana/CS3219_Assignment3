<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.034870">
<title confidence="0.996454">
Semantic Kernels for Semantic Parsing
</title>
<author confidence="0.998402">
Iman Saleh Alessandro Moschitti, Preslav Nakov,
</author>
<affiliation confidence="0.954465">
Faculty of Computers and Information Lluis M`arquez, Shafiq Joty
Cairo University ALT Research Group
iman.saleh@fci-cu.edu.eg Qatar Computing Research Institute
</affiliation>
<email confidence="0.992755">
{amoschitti,pnakov,lmarquez,sjoty}@qf.org.qa
</email>
<sectionHeader confidence="0.993762" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999408125">
We present an empirical study on the use
of semantic information for Concept Seg-
mentation and Labeling (CSL), which is
an important step for semantic parsing.
We represent the alternative analyses out-
put by a state-of-the-art CSL parser with
tree structures, which we rerank with a
classifier trained on two types of seman-
tic tree kernels: one processing structures
built with words, concepts and Brown
clusters, and another one using semantic
similarity among the words composing the
structure. The results on a corpus from the
restaurant domain show that our semantic
kernels exploiting similarity measures out-
perform state-of-the-art rerankers.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98950626984127">
Spoken Language Understanding aims to inter-
pret user utterances and to convert them to logical
forms or, equivalently, to database queries, which
can then be used to satisfy the user’s information
needs. This process is known as Concept Segmen-
tation and Labeling (CSL), also called semantic
parsing in the speech community: it maps utter-
ances into meaning representations based on se-
mantic constituents. The latter are basically word
sequences, often referred to as concepts, attributes
or semantic tags. CSL makes it easy to convert
spoken questions such as “cheap lebanese restau-
rants in doha with take out” into database queries.
First, a language-specific semantic parser tok-
enizes, segments and labels the question:
[Price cheap] [Cuisine lebanese] [Other restaurants in]
[City doha] [Other with] [Amenity take out]
Then, label-specific normalizers are applied to
the segments, with the option to possibly relabel
mislabeled segments:
[Price low] [Cuisine lebanese] [City doha] [Amenity
carry out]
Finally, a database query is formed from the list
of labels and values, and is then executed against
the database, e.g., MongoDB; a backoff mecha-
nism may be used if the query has not succeeded.
{$and [{cuisine:&amp;quot;lebanese&amp;quot;},{city:&amp;quot;doha&amp;quot;},
{price:&amp;quot;low&amp;quot;},{amenity:&amp;quot;carry out&amp;quot;}]}
The state-of-the-art of CSL is represented by
conditional models for sequence labeling such as
Conditional Random Fields (CRFs) (Lafferty et
al., 2001) trained with simple morphological and
lexical features. The basic CRF model was im-
proved by means of reranking (Moschitti et al.,
2006; Dinarelli et al., 2012) using structural ker-
nels (Moschitti, 2006). Although these meth-
ods exploited sentence structure, they did not use
syntax at all. More recently, we applied shal-
low syntactic structures and discourse parsing with
slightly better results (Saleh et al., 2014). How-
ever, the most obvious models for semantic pars-
ing, i.e., rerankers based on semantic structural
kernels (Bloehdorn and Moschitti, 2007b), had not
been applied to semantic structures yet.
In this paper, we study the impact of semantic
information conveyed by Brown Clusters (BCs)
(Brown et al., 1992) and semantic similarity, while
also combining them with innovative features. We
use reranking, similarly to (Saleh et al., 2014),
to select the best hypothesis annotated with con-
cepts predicted by a local model. The competing
hypotheses are represented as innovative trees en-
riched with the semantic concepts and BC labels.
The trees can capture dependencies between sen-
tence constituents, concepts and BCs. However,
extracting explicit features from them is rather
difficult as their number is exponentially large.
Thus, we rely on (i) Support Vector Machines
(Joachims, 1999) to train the reranking functions
and on (ii) structural kernels (Moschitti, 2010;
Moschitti, 2012; Moschitti, 2013) to automatically
encode tree fragments that represent syntactic and
semantic dependencies from words and concepts.
</bodyText>
<page confidence="0.984233">
436
</page>
<note confidence="0.4936815">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.9991635">
(a) Semantic Kernel Structure (SKS)
(b) SKS with Brown Clusters
</figure>
<figureCaption confidence="0.999992">
Figure 1: CSL structures: standard and with Brown Clusters.
</figureCaption>
<bodyText confidence="0.99996016">
We further apply a semantic kernel (SK),
namely the Smoothed Partial Tree Kernel (Croce
et al., 2011), which uses the lexical similarity be-
tween the tree nodes, while computing the sub-
structure space. This is the first time that SKs are
applied to reranking hypotheses. This (i) makes
the global sentence structure along with concepts
available to the learning algorithm, and (ii) enables
computing the similarity between lexicals in syn-
tactic patterns that are enriched by concepts.
We tested our models on the Restaurant do-
main. Our results show that: (i) The basic CRF
parser, which uses semi-Markov CRF, or semi-
CRF (Sarawagi and Cohen, 2004), is already very
accurate; it achieves F1 scores over 83%, mak-
ing any further improvement very hard. (ii) The
upper-bound performance of the reranker is very
high as well, i.e., the correct annotation is gen-
erated in the list of the first 100 hypotheses in
98.72% of the cases. (iii) SKs significantly im-
prove over the semi-CRF baseline and our pre-
vious state-of-the-art reranker exploiting shallow
syntactic patterns (Saleh et al., 2014), as shown
by extensive comparisons using several systems.
(iv) Making BCs effective requires a deeper study.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999883608695652">
One of the early approaches to CSL was that
of Pieraccini et al. (1991), where the word se-
quences and concepts were modeled using Hid-
den Markov Models (HMMs) as observations and
hidden states, respectively. Generative models
were exploited by Seneff (1989) and Miller et
al. (1994), who used stochastic grammars for
CSL. Other discriminative models followed such
preliminary work, e.g., (Rubinstein and Hastie,
1997; Santaf´e et al., 2007; Raymond and Riccardi,
2007). CRF-based models are considered to be the
state of the art in CSL (De Mori et al., 2008).
Another relevant line of research are the seman-
tic kernels, i.e., kernels that use lexical similarity
between features. One of the first that applyed
LSA was (Cristianini et al., 2002), whereas (Bloe-
hdorn et al., 2006; Basili et al., 2006) used Word-
Net. Semantic structural kernels of the type we
use in this paper were first introduced in (Bloe-
hdorn and Moschitti, 2007a; Bloehdorn and Mos-
chitti, 2007b). The most advanced model based on
tree kernels, which we also use in this paper, is the
Smoothed PTK (Croce et al., 2011).
</bodyText>
<sectionHeader confidence="0.998433" genericHeader="method">
3 Reranking for CSL
</sectionHeader>
<bodyText confidence="0.999958923076923">
Reranking is applied to a list of N annotation hy-
potheses, which are generated and sorted by the
probability to be globally correct as estimated us-
ing local classifiers or global classifiers that only
use local features. Then, a reranker, typically a
meta-classifier, tries to select the best hypothe-
sis from the list. The reranker can exploit global
information, and specifically, the dependencies
between the different concepts, which are made
available by the local model. We use semi-CRFs
for the local model as they yield the highest ac-
curacy in CSL (when using a single model) and
preference reranking for the global reranker.
</bodyText>
<subsectionHeader confidence="0.99962">
3.1 Preference Reranking (PR)
</subsectionHeader>
<bodyText confidence="0.999717454545454">
PR uses a classifier C, which takes a pair of hy-
potheses (Hi, Hj) and decides whether Hi is bet-
ter than Hj. Given a training question Q, posi-
tive and negative examples are built for training
the classifier. Let H1 be the hypothesis with the
lowest error rate with respect to the gold standard
among all hypotheses generated for question Q.
We adopt the following approach for example gen-
eration: the pairs (H1, Hi) (i = 2, 3, ... , N) are
positive examples, while (Hi, H1) are considered
negative.
</bodyText>
<page confidence="0.997817">
437
</page>
<bodyText confidence="0.999868666666667">
At testing time, given a new question Q0, C clas-
sifies all pairs (Hi, Hj) generated from the anno-
tation hypotheses of Q0: a positive classification is
a vote for Hi, otherwise the vote is for Hj, where
the classifier score can be used as a weighted vote.
Hk are then ranked according to the number (sum)
of the votes (weighted by score) they receive.
We build our reranker with SVMs using the
following kernel: K((H1, H2), (H01, H2)) =
</bodyText>
<equation confidence="0.99127225">
φ((H1, H2)) - φ((H10, H2)) (φ(H1) −
φ(H2)) - (φ(H01) − φ(H02)) = φ(H1)φ(H01) +
φ(H2)φ(H02) − φ(H1)φ(H02) − φ(H2)φ(H01) =
S(H1, H01) + S(H2, H02) − S(H1, H02) −
</equation>
<bodyText confidence="0.984392666666667">
S(H2, H01). We consider H as a tuple (T,~v) com-
posed of a tree T and a feature vector ~v. Then, we
define S(H, H0) = STK(T, T0) + Sv(~v,~v0), where
STK computes one of the tree kernel functions
defined in 3.2 and 3.3; and Sv is a kernel (see 3.4),
e.g., linear, polynomial, Gaussian, etc.
</bodyText>
<subsectionHeader confidence="0.9973">
3.2 Tree kernels (TKs)
</subsectionHeader>
<bodyText confidence="0.99997705">
TKs measure the similarity between two structures
in terms of the number of substructures they share.
We use two types of tree kernels: (i) Partial Tree
Kernel (PTK), which can be effectively applied
to both constituency and dependency parse trees
(Moschitti, 2006). It generates all possible con-
nected tree fragments, e.g., sibling nodes can be
also separated and can be part of different tree
fragments: a fragment is any possible tree path,
and other tree paths are allowed to depart from its
nodes. Thus, it can generate a very rich feature
space. (ii) The smoothed PTK or semantic kernel
(SK) (Croce et al., 2011), which extends PTK by
allowing soft matching (i.e., via similarity compu-
tation) between nodes associated with different but
related lexical items. The node similarity can be
derived from manually annotated resources, e.g.,
WordNet or Wikipedia, as well as using corpus-
based clustering approaches, e.g., latent semantic
analysis (LSA), as we do in this paper.
</bodyText>
<subsectionHeader confidence="0.999753">
3.3 Semantic structures
</subsectionHeader>
<bodyText confidence="0.994055931034483">
Tree kernels allow us to compute structural simi-
larities between two trees; thus, we engineered a
special structure for the CSL task. In order to cap-
ture the structural dependencies between the se-
mantic tags,1 we use a basic tree (see for exam-
ple Figure 1a), where the words of a sentence are
tagged with their semantic tags.
1They are associated with the following IDs: 0-Other,
1-Rating, 2-Restaurant, 3-Amenity, 4-Cuisine, 5-Dish, 6-
Hours, 7-Location, and 8-Price.
More specifically, the words in the sentence
constitute the leaves of the tree, which are in
turn connected to the pre-terminals containing
the semantic tags in BIO notation (‘B’=begin,
‘I’=inside, ‘O’=outside). The BIO tags are then
generalized in the upper level, and joined to the
Root node. Additionally, part-of-speech (POS)
tags2 are added to each word by concatenating
it with the string “::L”, where L is the first let-
ter of the POS-tags of the words, e.g., along, my
and route, receive i, p and n, which are the first
letters of the POS-tags IN, PRN and NN, respec-
tively. SK applied to the above structure can gen-
erate powerful semantic patterns such as [Root
[4-Cuisine [similar to(stake house)]][7-Loc [simi-
lar to(within a mile)]]], e.g., for correctly labeling
new clauses like Pizza Parlor in three kilometers.
The BC labels, represented as cluster IDs, are sim-
ply added as siblings of words as shown in Fig. 1b.
</bodyText>
<subsectionHeader confidence="0.971883">
3.4 Feature Vectors
</subsectionHeader>
<bodyText confidence="0.9999149">
For the sake of comparison, we also devoted
some effort towards engineering a set of features
to be used in a flat feature-vector representation.
These features can be used in isolation to learn
the reranking function, or in combination with the
kernel-based approach (as a composite kernel us-
ing a linear combination). They belong to the fol-
lowing four categories: (i) CRF-based: these in-
clude the basic features used to train the initial
semi-CRF model; (ii) n-gram based: we collected
3- and 4-grams of the output label sequence at
the level of concepts, with artificial tags inserted
to identify the start (‘S’) and end (‘E’) of the se-
quence.3 (iii) Probability-based, computing the
probability of the label sequence as an average of
the probabilities at the word level in the N-best
list; and (iv) DB-based: a single feature encoding
the number of results returned from the database
when constructing a query using the conjunction
of all semantic segments in the hypothesis.
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9998895">
The experiments aim at investigating the role of
feature vectors, PTK, SK and BCs in reranking.
We first describe the experimental setting and then
we move into the analysis of the results.
</bodyText>
<footnote confidence="0.9664898">
2We use the Stanford tagger (Toutanova et al., 2003).
3For instance, if the output sequence is Other-Rating-
Other-Amenity the 3-gram patterns would be: S-Other-
Rating, Other-Rating-Other, Rating-Other-Amenity, and
Other-Amenity-E.
</footnote>
<page confidence="0.96627">
438
</page>
<table confidence="0.999727666666667">
Train Devel. Test Total
semi-CRF 6,922 739 1,521 9,182
Reranker 7,000 3,695 7,605 39,782
</table>
<tableCaption confidence="0.976178">
Table 1: Number of instances and pairs used to
train the semi-CRF and rerankers, respectively.
</tableCaption>
<subsectionHeader confidence="0.975459">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.998994461538462">
Dataset. In our experiments, we used questions
annotated with semantic tags, which were col-
lected through crowdsourcing on Amazon Me-
chanical Turk and made available4 by McGraw et
al. (2012). We split the dataset into training, de-
velopment and test sets. Table 1 shows the num-
ber of examples and example pairs we used for
the semi-CRF and the reranker, respectively. We
subsequently split the training data randomly into
10 folds. We used cross-validation, i.e., iteratively
training with 9 folds and annotating the remaining
fold, in order to generate the N-best lists of hy-
potheses for the entire training dataset. We com-
puted the 100-best hypotheses for each example.
We then used the development dataset to test and
tune the hyper-parameters of our reranking model.
The results on the development set, which we will
present in Section 4.2 below, were obtained us-
ing semi-CRF and reranking models trained on the
training set.
Data representation. Each hypothesis is repre-
sented by a semantic tree, a feature vector (ex-
plained in Section 3), and two extra features:
(i) the semi-CRF probability of the hypothesis,
and (ii) its reciprocal rank in the N-best list.
Learning algorithm. We used the SVM-Light-
TK5 to train the reranker with a combination of
tree kernels and feature vectors (Moschitti, 2006;
Joachims, 1999). We used the default parameters
and a linear kernel for the feature vectors. As a
baseline, we picked the best-scoring hypothesis in
the list, i.e., the output by the regular semi-CRF
parser. The setting is exactly the same as that de-
scribed in (Saleh et al., 2014).
Evaluation measure. In all experiments, we used
the harmonic mean of precision and recall (F1)
(van Rijsbergen, 1979), computed at the token
level and micro-averaged across the different se-
mantic types.6
</bodyText>
<footnote confidence="0.99493375">
4http://groups.csail.mit.edu/sls/downloads/restaurant/
5http://disi.unitn.it/moschitti/Tree-Kernel.htm
6We do not consider ‘Other’ to be a semantic type; thus,
we did not include it in the F1 calculation.
</footnote>
<table confidence="0.976734">
N 1 2 5 10 100
F1 83.03 87.76 92.63 95.23 98.72
</table>
<tableCaption confidence="0.999243">
Table 2: Oracle F1 score for N-best lists.
</tableCaption>
<bodyText confidence="0.998889166666666">
Brown Clusters. Clustering groups of similar
words together provides a way of generalizing
them. In this work, we explore the use of Brown
clusters (Brown et al., 1992) in both feature vec-
tors and tree kernels. The Brown clustering al-
gorithm uses an n-gram class model. It first as-
signs each word to a distinct cluster, and then it
merges different clusters in a bottom-up fashion.
The merge step is done in a way that minimizes the
loss in average mutual information between clus-
ters. The outcome is hierarchical clustering, which
we use in our reranking algorithm. To create the
Brown clusters, we used the Yelp dataset of re-
views.7 It contains 335,022 reviews about 15,585
businesses; 5,575 of the businesses and 233,839 of
the reviews are restaurant-related. This dataset is
very similar to the dataset of queries about restau-
rants we use in our experiments.
Similarity matrix for SK. We compute the lexi-
cal similarity for SK by applying LSA (Furnas et
al., 1988) to Tripadvisor data. The dataset and the
exact procedure for creating the LSA matrix are
described in (Castellucci et al., 2013; Croce and
Previtali, 2010).
</bodyText>
<sectionHeader confidence="0.699451" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999635">
Oracle accuracy. Table 2 shows the oracle F1
score for N-best lists of different lengths, i.e., the
F1 that is achieved by picking the best candidate
in the N-best list for various values of N. Con-
sidering 5-best lists yields an increase in oracle F1
of almost ten absolute points. Going up to 10-best
lists only adds 2.5 extra F1 points. The complete
100-best lists add 3.5 extra F1 points, for a total
of 98.72. This very high value is explained by the
fact that often the total number of different anno-
tations for a given question is smaller than 100. In
our experiments, we will focus on 5-best lists.
Baseline accuracy. We computed F1 for the semi-
CRF model on both the development and the test
sets, obtaining 83.86 and 83.03, respectively.
Learning Curves. The semantic information in
terms of BCs or semantic similarity derived by
LSA can have a major impact in case of data
scarcity. Therefore, we trained our reranking mod-
els with increasing sizes of training data.
</bodyText>
<footnote confidence="0.996013">
7http://www.yelp.com/dataset challenge/
</footnote>
<page confidence="0.998997">
439
</page>
<figure confidence="0.998702589285714">
Development set
F1-­‐measure
86
85
84
83
82
81
80
79
PTK SK
PTK+BC PTK+all
PTK+BC+all Baseline
F1--‐measure
86
85
84
83
82
81
80
79
PTK SK
SK+BC PTK+all
SK+all SK+BC+all
Baseline
0 1000 2000 3000 4000 5000 6000 7000 0 1000 2000 3000 4000 5000 6000 7000
Training data size Training data size
Test set
F1-measure
86
84
82
80
78
76
74
PTK SK
PTK+BC PTK+all
PTK+BC+all Baseline
F1-measure
85
84
83
82
81
80
79
PTK SK
SK+BC PTK+all
SK+all SK+BC+all
Baseline
0 1000 2000 3000 4000 5000 6000 7000
Training data size
0 1000 2000 3000 4000 5000 6000 7000
Training data size
</figure>
<figureCaption confidence="0.999731">
Figure 2: Learning curves for different reranking models on the development and on the testing sets.
</figureCaption>
<bodyText confidence="0.999964333333333">
The first two graphs in Fig. 2 show the plots
on the development set whereas the last two are
computed on the test set. The reranking models
reported are Baseline, PTK, PTK+BC, PTK+all
(features), PTK+BC+all, SK, SK+BC, SK+all and
SK+BC+all.8 We can see that: (i) PTK alone, i.e.,
without semantic information, has the lowest ac-
curacy; (ii) BCs do not improve significantly any
model; (iii) SK almost always achieves the high-
est accuracy; (iv) PTK+all (i.e., the model also us-
ing features) improves on PTK, but its accuracy
is lower than for any model using SK, i.e., us-
ing semantic similarity; and (v) all features pro-
vide an initial boost to SK, but as soon as the data
increases, their impact decreases.
</bodyText>
<sectionHeader confidence="0.972972" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999411375">
In summary, the learning curves clearly show the
good generalization ability of SK, which improve
the CRF baseline using little data (∼3,000). The
semantic kernel significantly improves over the
semi-CRF baseline and our previous state-of-the-
art reranker exploiting shallow syntactic patterns
(Saleh et al., 2014), which corresponds to PTK+all
in the above comparison.
</bodyText>
<footnote confidence="0.600819">
8Models are split between 2 plots in order to ease reading.
</footnote>
<bodyText confidence="0.999906529411765">
The improvement falls between 1-2 absolute
percent points. This is remarkable as (i) it corre-
sponds to ∼10% relative error reduction, and (ii)
the state-of-the-art baseline system is very difficult
to beat, as confirmed by the low impact of tradi-
tional features and BCs. Although the latter can
generalize over concepts and words, their use is
not straightforward, resulting in no improvement.
In the future, we plan to investigate the use of
semantic similarity from distributional and other
sources (Mihalcea et al., 2006; Pad´o and Lapata,
2007), e.g., Wikipedia (Strube and Ponzetto, 2006;
Mihalcea and Csomai, 2007), Wiktionary (Zesch
et al., 2008), WordNet (Pedersen et al., 2004;
Agirre et al., 2009), FrameNet, VerbNet (Shi and
Mihalcea, 2005), BabelNet (Navigli and Ponzetto,
2010), and LSA, and for different domains.
</bodyText>
<sectionHeader confidence="0.989733" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.95508025">
This research is part of the Interactive sYstems
for Answer Search (Iyas) project, conducted by
the Arabic Language Technologies (ALT) group
at Qatar Computing Research Institute (QCRI)
within the Qatar Foundation. We would like to
thank Danilo Croce, Roberto Basili and Giuseppe
Castellucci for helping and providing us with the
similarity matrix for the semantic kernels.
</bodyText>
<page confidence="0.997552">
440
</page>
<sectionHeader confidence="0.923389" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.989250306306306">
Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana
Kravalova, Marius Pasca, and Aitor Soroa. 2009.
A study on similarity and relatedness using distribu-
tional and wordnet-based approaches. In Proceed-
ings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 19–27, Boulder, Colorado, June.
Roberto Basili, Marco Cammisa, and Alessandro Mos-
chitti. 2006. A semantic kernel to classify texts with
very few training examples. Informatica (Slovenia),
30(2):163–172.
Stephan Bloehdorn and Alessandro Moschitti. 2007a.
Combined syntactic and semantic kernels for text
classification. In Advances in Information Retrieval
- Proceedings of the 29th European Conference on
Information Retrieval (ECIR 2007), pages 307–318,
Rome, Italy.
Stephan Bloehdorn and Alessandro Moschitti. 2007b.
Structure and semantics for expressive text kernels.
In Proceedings of the 16th ACM Conference on
Information and Knowledge Management (CIKM
2007), pages 861–864, Lisbon, Portugal.
Stephan Bloehdorn, Roberto Basili, Marco Cammisa,
and Alessandro Moschitti. 2006. Semantic kernels
for text classification based on topological measures
of feature similarity. In Proceedings of the 6th IEEE
International Conference on Data Mining (ICDM
06), pages 808–812, Hong Kong.
Peter F. Brown, Peter V. deSouza, Robert L. Mer-
cer, Vincent J. Della Pietra, and Jenifer C. Lai.
1992. Class-based n-gram models of natural lan-
guage. Computational Linguistics, 18(4):467–479.
Giuseppe Castellucci, Simone Filice, Danilo Croce,
and Roberto Basili. 2013. UNITOR: Combining
Syntactic and Semantic Kernels for Twitter Senti-
ment Analysis. In Second Joint Conference on Lex-
ical and Computational Semantics (*SEM), Volume
2: Proceedings of the Seventh International Work-
shop on Semantic Evaluation (SemEval 2013), pages
369–374, Atlanta, Georgia, USA.
Nello Cristianini, John Shawe-Taylor, and Huma
Lodhi. 2002. Latent Semantic Kernels. Journal
of Intelligent Information Systems, 18(2):127–152.
Danilo Croce and Daniele Previtali. 2010. Mani-
fold learning for the semi-supervised induction of
framenet predicates: An empirical investigation. In
Proceedings of the 2010 Workshop on GEometrical
Models ofNatural Language Semantics, pages 7–16,
Uppsala, Sweden.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured lexical similarity via con-
volution kernels on dependency trees. In Proceed-
ings of the 2011 Conference on Empirical Methods
in Natural Language Processing, pages 1034–1046,
Edinburgh, Scotland, UK.
Renato De Mori, Frederic B´echet, Dilek Hakkani-T¨ur,
Michael McTear, Giuseppe Riccardi, and Gokhan
Tur. 2008. Spoken Language Understanding. IEEE
Signal Processing Magazine, 25:50–58.
Marco Dinarelli, Alessandro Moschitti, and Giuseppe
Riccardi. 2012. Discriminative reranking for
spoken language understanding. IEEE Transac-
tions on Audio, Speech and Language Processing,
20(2):526–539.
G. W. Furnas, S. Deerwester, S. T. Dumais, T. K. Lan-
dauer, R. A. Harshman, L. A. Streeter, and K. E.
Lochbaum. 1988. Information retrieval using a sin-
gular value decomposition model of latent semantic
structure. In Proceedings of the 11th annual inter-
national ACM SIGIR conference on Research and
development in information retrieval (SIGIR ’88),
pages 465–480, New York, USA.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In B. Schlkopf, C. Burges, and
A. Smola, editors, Advances in Kernel Methods -
Support Vector Learning. MIT Press, Cambridge,
MA, USA.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning (ICML
2001), pages 282–289, Williamstown, MA, USA.
Ian McGraw, Scott Cyphers, Panupong Pasupat,
Jingjing Liu, and Jim Glass. 2012. Automating
crowd-supervised learning for spoken language sys-
tems. In Proceedings of the 13th Annual Conference
of the International Speech Communication Asso-
ciation (INTERSPEECH 2012), pages 2473–2476,
Portland, OR, USA.
Rada Mihalcea and Andras Csomai. 2007. Wikify!
linking documents to encyclopedic knowledge. In
Proceedings of the sixteenth ACM conference on
Conference on information and knowledge manage-
ment (CIKM 2007), pages 233–242, Lisbon, Portu-
gal.
Rada Mihalcea, Courtney Corley, and Carlo Strappa-
rava. 2006. Corpus-based and knowledge-based
measures of text semantic similarity. In Proceed-
ings of the 21st National Conference on Artificial In-
telligence - Volume 1 (AAAI 2006), pages 775–780,
Boston, MA, USA.
Scott Miller, Richard Schwartz, Robert Bobrow, and
Robert Ingria. 1994. Statistical Language Process-
ing using Hidden Understanding Models. In Pro-
ceedings of the workshop on Human Language Tech-
nology (HLT 1994), pages 278–282, Plainsboro, NJ,
USA.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2006. Semantic role labeling via tree kernel
</reference>
<page confidence="0.992128">
441
</page>
<reference confidence="0.99950505">
joint inference. In Proceedings of the Tenth Confer-
ence on Computational Natural Language Learning
(CoNLL-X), pages 61–68, New York City, USA.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In Proceedings of the 17th European Conference on
Machine Learning (ECML 2006), pages 318–329,
Berlin, Germany.
Alessandro Moschitti. 2010. Kernel engineering
for fast and easy design of natural language ap-
plications. In Coling 2010: Kernel Engineering
for Fast and Easy Design of Natural Language
Applications–Tutorial notes, pages 1–91, Beijing,
China.
Alessandro Moschitti. 2012. State-of-the-art kernels
for natural language processing. In Tutorial Ab-
stracts of ACL 2012, page 2, Jeju Island, Korea.
Alessandro Moschitti. 2013. Kernel-based learning to
rank with syntactic and semantic structures. In Tu-
torial abstracts of the 36th Annual ACM SIGIR Con-
ference, page 1128, Dublin, Ireland.
Roberto Navigli and Simone Paolo Ponzetto. 2010.
Babelnet: Building a very large multilingual seman-
tic network. In Proceedings of the 48th annual meet-
ing of the association for computational linguistics
(ACL 2010), pages 216–225, Uppsala, Sweden.
Sebastian Pad´o and Mirella Lapata. 2007.
Dependency-based construction of semantic space
models. Computational Linguistics, 33(2):161–199.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity - measuring the
relatedness of concepts. In HLT-NAACL 2004:
Demonstration Papers, pages 38–41, Boston, Mas-
sachusetts, USA.
Roberto Pieraccini, Esther Levin, and Chin-Hui Lee.
1991. Stochastic Representation of Conceptual
Structure in the ATIS Task. In Proceedings of the
Fourth Joint DARPA Speech and Natural Language
Workshop, pages 121–124, Los Altos, CA, USA.
Christian Raymond and Giuseppe Riccardi. 2007.
Generative and Discriminative Algorithms for Spo-
ken Language Understanding. In Proceedings
of the 8th Annual Conference of the Interna-
tional Speech Communication Association (INTER-
SPEECH 2007), pages 1605–1608, Antwerp, Bel-
gium, August.
Y. Dan Rubinstein and Trevor Hastie. 1997. Discrimi-
native vs Informative Learning. In Proceedings of
the Third International Conference on Knowledge
Discovery and Data Mining (KDD-1997), pages 49–
53, Newport Beach, CA, USA.
Iman Saleh, Scott Cyphers, Jim Glass, Shafiq Joty,
Llu´ıs M`arquez, Alessandro Moschitti, and Preslav
Nakov. 2014. A study of using syntactic and seman-
tic structures for concept segmentation and labeling.
In Proceedings of the 25th International Conference
on Computational Linguistics, COLING ’14, pages
193–202, Dublin, Ireland.
G. Santaf´e, J.A. Lozano, and P. Larra˜naga. 2007.
Discriminative vs. Generative Learning of Bayesian
Network Classifiers. In Proceedings of the 9th Euro-
pean Conference on Symbolic and Quantitative Ap-
proaches to Reasoning with Uncertainty (ECSQARU
2007), pages 453–546, Hammamet, Tunisia.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information
extraction. In Advances in Neural Information Pro-
cessing Systems 17 (NIPS 2004), Vancouver, British
Columbia, Canada.
Stephanie Seneff. 1989. TINA: A Probabilistic Syn-
tactic Parser for Speech Understanding Systems.
In Proceedings of the International Conference on
Acoustics, Speech, and Signal Processing (ICASSP-
89), pages 711–714, Glasgow, UK.
Lei Shi and Rada Mihalcea. 2005. Putting pieces to-
gether: Combining framenet, verbnet and wordnet
for robust semantic parsing. In Computational Lin-
guistics and Intelligent Text Processing, pages 100–
111. Springer Berlin Heidelberg.
Michael Strube and Simone Paolo Ponzetto. 2006.
Wikirelate! computing semantic relatedness using
wikipedia. In Proceedings of the 21st National Con-
ference on Artificial Intelligence (AAAI’06), pages
1419–1424, Boston, Massachusetts, USA.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Human Language Tech-
nology Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics (HLT-NAACL 2003), pages 173–180, Edmon-
ton, Canada.
Cornelis J. van Rijsbergen. 1979. Information
Retrieval. Butterworth-Heinemann Newton, MA,
USA.
Torsten Zesch, Christof M¨uller, and Iryna Gurevych.
2008. Using wiktionary for computing semantic re-
latedness. In Proceedings of the 23rd National Con-
ference on Artificial Intelligence (AAAI’08), pages
861–866, Chicago, Illinois,USA.
</reference>
<page confidence="0.998456">
442
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.845654">
<title confidence="0.999876">Semantic Kernels for Semantic Parsing</title>
<author confidence="0.993074">Iman Saleh Alessandro Moschitti</author>
<author confidence="0.993074">Preslav Nakov</author>
<affiliation confidence="0.958932">of Computers and Information M`arquez, Shafiq Joty Cairo University ALT Research Group Computing Research Institute</affiliation>
<abstract confidence="0.998053117647059">We present an empirical study on the use of semantic information for Concept Segmentation and Labeling (CSL), which is an important step for semantic parsing. We represent the alternative analyses output by a state-of-the-art CSL parser with tree structures, which we rerank with a classifier trained on two types of semantic tree kernels: one processing structures built with words, concepts and Brown clusters, and another one using semantic similarity among the words composing the structure. The results on a corpus from the restaurant domain show that our semantic kernels exploiting similarity measures outperform state-of-the-art rerankers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Enrique Alfonseca</author>
<author>Keith Hall</author>
<author>Jana Kravalova</author>
<author>Marius Pasca</author>
<author>Aitor Soroa</author>
</authors>
<title>A study on similarity and relatedness using distributional and wordnet-based approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>pages</pages>
<location>Boulder, Colorado,</location>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pasca, Soroa, 2009</marker>
<rawString>Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pasca, and Aitor Soroa. 2009. A study on similarity and relatedness using distributional and wordnet-based approaches. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 19–27, Boulder, Colorado, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Basili</author>
<author>Marco Cammisa</author>
<author>Alessandro Moschitti</author>
</authors>
<title>A semantic kernel to classify texts with very few training examples.</title>
<date>2006</date>
<journal>Informatica (Slovenia),</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="6253" citStr="Basili et al., 2006" startWordPosition="945" endWordPosition="948">hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranker, typically a meta-classifier, tries to select the bes</context>
</contexts>
<marker>Basili, Cammisa, Moschitti, 2006</marker>
<rawString>Roberto Basili, Marco Cammisa, and Alessandro Moschitti. 2006. A semantic kernel to classify texts with very few training examples. Informatica (Slovenia), 30(2):163–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Combined syntactic and semantic kernels for text classification.</title>
<date>2007</date>
<booktitle>In Advances in Information Retrieval - Proceedings of the 29th European Conference on Information Retrieval (ECIR</booktitle>
<pages>307--318</pages>
<location>Rome, Italy.</location>
<contexts>
<context position="2949" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="427" endWordPosition="430">labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also combining them with innovative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explic</context>
<context position="6384" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="967" endWordPosition="971">ic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranker, typically a meta-classifier, tries to select the best hypothesis from the list. The reranker can exploit global information, and specifically, the dependencies between the different c</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007a. Combined syntactic and semantic kernels for text classification. In Advances in Information Retrieval - Proceedings of the 29th European Conference on Information Retrieval (ECIR 2007), pages 307–318, Rome, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structure and semantics for expressive text kernels.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>861--864</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="2949" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="427" endWordPosition="430">labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also combining them with innovative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explic</context>
<context position="6384" citStr="Bloehdorn and Moschitti, 2007" startWordPosition="967" endWordPosition="971">ic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranker, typically a meta-classifier, tries to select the best hypothesis from the list. The reranker can exploit global information, and specifically, the dependencies between the different c</context>
</contexts>
<marker>Bloehdorn, Moschitti, 2007</marker>
<rawString>Stephan Bloehdorn and Alessandro Moschitti. 2007b. Structure and semantics for expressive text kernels. In Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM 2007), pages 861–864, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Bloehdorn</author>
<author>Roberto Basili</author>
<author>Marco Cammisa</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Semantic kernels for text classification based on topological measures of feature similarity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 6th IEEE International Conference on Data Mining (ICDM 06),</booktitle>
<pages>808--812</pages>
<location>Hong Kong.</location>
<contexts>
<context position="6231" citStr="Bloehdorn et al., 2006" startWordPosition="940" endWordPosition="944">Ms) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranker, typically a meta-classifier, t</context>
</contexts>
<marker>Bloehdorn, Basili, Cammisa, Moschitti, 2006</marker>
<rawString>Stephan Bloehdorn, Roberto Basili, Marco Cammisa, and Alessandro Moschitti. 2006. Semantic kernels for text classification based on topological measures of feature similarity. In Proceedings of the 6th IEEE International Conference on Data Mining (ICDM 06), pages 808–812, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="3114" citStr="Brown et al., 1992" startWordPosition="454" endWordPosition="457">reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also combining them with innovative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explicit features from them is rather difficult as their number is exponentially large. Thus, we rely on (i) Support Vector Machines (Joachims, 1999) to train the rerankin</context>
<context position="14931" citStr="Brown et al., 1992" startWordPosition="2385" endWordPosition="2388">he harmonic mean of precision and recall (F1) (van Rijsbergen, 1979), computed at the token level and micro-averaged across the different semantic types.6 4http://groups.csail.mit.edu/sls/downloads/restaurant/ 5http://disi.unitn.it/moschitti/Tree-Kernel.htm 6We do not consider ‘Other’ to be a semantic type; thus, we did not include it in the F1 calculation. N 1 2 5 10 100 F1 83.03 87.76 92.63 95.23 98.72 Table 2: Oracle F1 score for N-best lists. Brown Clusters. Clustering groups of similar words together provides a way of generalizing them. In this work, we explore the use of Brown clusters (Brown et al., 1992) in both feature vectors and tree kernels. The Brown clustering algorithm uses an n-gram class model. It first assigns each word to a distinct cluster, and then it merges different clusters in a bottom-up fashion. The merge step is done in a way that minimizes the loss in average mutual information between clusters. The outcome is hierarchical clustering, which we use in our reranking algorithm. To create the Brown clusters, we used the Yelp dataset of reviews.7 It contains 335,022 reviews about 15,585 businesses; 5,575 of the businesses and 233,839 of the reviews are restaurant-related. This </context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Castellucci</author>
<author>Simone Filice</author>
<author>Danilo Croce</author>
<author>Roberto Basili</author>
</authors>
<title>UNITOR: Combining Syntactic and Semantic Kernels for Twitter Sentiment Analysis.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>369--374</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="15858" citStr="Castellucci et al., 2013" startWordPosition="2543" endWordPosition="2546">ween clusters. The outcome is hierarchical clustering, which we use in our reranking algorithm. To create the Brown clusters, we used the Yelp dataset of reviews.7 It contains 335,022 reviews about 15,585 businesses; 5,575 of the businesses and 233,839 of the reviews are restaurant-related. This dataset is very similar to the dataset of queries about restaurants we use in our experiments. Similarity matrix for SK. We compute the lexical similarity for SK by applying LSA (Furnas et al., 1988) to Tripadvisor data. The dataset and the exact procedure for creating the LSA matrix are described in (Castellucci et al., 2013; Croce and Previtali, 2010). 4.2 Results Oracle accuracy. Table 2 shows the oracle F1 score for N-best lists of different lengths, i.e., the F1 that is achieved by picking the best candidate in the N-best list for various values of N. Considering 5-best lists yields an increase in oracle F1 of almost ten absolute points. Going up to 10-best lists only adds 2.5 extra F1 points. The complete 100-best lists add 3.5 extra F1 points, for a total of 98.72. This very high value is explained by the fact that often the total number of different annotations for a given question is smaller than 100. In </context>
</contexts>
<marker>Castellucci, Filice, Croce, Basili, 2013</marker>
<rawString>Giuseppe Castellucci, Simone Filice, Danilo Croce, and Roberto Basili. 2013. UNITOR: Combining Syntactic and Semantic Kernels for Twitter Sentiment Analysis. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 369–374, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nello Cristianini</author>
<author>John Shawe-Taylor</author>
<author>Huma Lodhi</author>
</authors>
<title>Latent Semantic Kernels.</title>
<date>2002</date>
<journal>Journal of Intelligent Information Systems,</journal>
<volume>18</volume>
<issue>2</issue>
<contexts>
<context position="6198" citStr="Cristianini et al., 2002" startWordPosition="935" endWordPosition="938">deled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranke</context>
</contexts>
<marker>Cristianini, Shawe-Taylor, Lodhi, 2002</marker>
<rawString>Nello Cristianini, John Shawe-Taylor, and Huma Lodhi. 2002. Latent Semantic Kernels. Journal of Intelligent Information Systems, 18(2):127–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Daniele Previtali</author>
</authors>
<title>Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on GEometrical Models ofNatural Language Semantics,</booktitle>
<pages>7--16</pages>
<location>Uppsala,</location>
<contexts>
<context position="15886" citStr="Croce and Previtali, 2010" startWordPosition="2547" endWordPosition="2550"> is hierarchical clustering, which we use in our reranking algorithm. To create the Brown clusters, we used the Yelp dataset of reviews.7 It contains 335,022 reviews about 15,585 businesses; 5,575 of the businesses and 233,839 of the reviews are restaurant-related. This dataset is very similar to the dataset of queries about restaurants we use in our experiments. Similarity matrix for SK. We compute the lexical similarity for SK by applying LSA (Furnas et al., 1988) to Tripadvisor data. The dataset and the exact procedure for creating the LSA matrix are described in (Castellucci et al., 2013; Croce and Previtali, 2010). 4.2 Results Oracle accuracy. Table 2 shows the oracle F1 score for N-best lists of different lengths, i.e., the F1 that is achieved by picking the best candidate in the N-best list for various values of N. Considering 5-best lists yields an increase in oracle F1 of almost ten absolute points. Going up to 10-best lists only adds 2.5 extra F1 points. The complete 100-best lists add 3.5 extra F1 points, for a total of 98.72. This very high value is explained by the fact that often the total number of different annotations for a given question is smaller than 100. In our experiments, we will foc</context>
</contexts>
<marker>Croce, Previtali, 2010</marker>
<rawString>Danilo Croce and Daniele Previtali. 2010. Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation. In Proceedings of the 2010 Workshop on GEometrical Models ofNatural Language Semantics, pages 7–16, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1034--1046</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="4347" citStr="Croce et al., 2011" startWordPosition="634" endWordPosition="637">d on (ii) structural kernels (Moschitti, 2010; Moschitti, 2012; Moschitti, 2013) to automatically encode tree fragments that represent syntactic and semantic dependencies from words and concepts. 436 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (a) Semantic Kernel Structure (SKS) (b) SKS with Brown Clusters Figure 1: CSL structures: standard and with Brown Clusters. We further apply a semantic kernel (SK), namely the Smoothed Partial Tree Kernel (Croce et al., 2011), which uses the lexical similarity between the tree nodes, while computing the substructure space. This is the first time that SKs are applied to reranking hypotheses. This (i) makes the global sentence structure along with concepts available to the learning algorithm, and (ii) enables computing the similarity between lexicals in syntactic patterns that are enriched by concepts. We tested our models on the Restaurant domain. Our results show that: (i) The basic CRF parser, which uses semi-Markov CRF, or semiCRF (Sarawagi and Cohen, 2004), is already very accurate; it achieves F1 scores over 8</context>
<context position="6540" citStr="Croce et al., 2011" startWordPosition="996" endWordPosition="999">). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (Croce et al., 2011). 3 Reranking for CSL Reranking is applied to a list of N annotation hypotheses, which are generated and sorted by the probability to be globally correct as estimated using local classifiers or global classifiers that only use local features. Then, a reranker, typically a meta-classifier, tries to select the best hypothesis from the list. The reranker can exploit global information, and specifically, the dependencies between the different concepts, which are made available by the local model. We use semi-CRFs for the local model as they yield the highest accuracy in CSL (when using a single mo</context>
<context position="9253" citStr="Croce et al., 2011" startWordPosition="1473" endWordPosition="1476"> TKs measure the similarity between two structures in terms of the number of substructures they share. We use two types of tree kernels: (i) Partial Tree Kernel (PTK), which can be effectively applied to both constituency and dependency parse trees (Moschitti, 2006). It generates all possible connected tree fragments, e.g., sibling nodes can be also separated and can be part of different tree fragments: a fragment is any possible tree path, and other tree paths are allowed to depart from its nodes. Thus, it can generate a very rich feature space. (ii) The smoothed PTK or semantic kernel (SK) (Croce et al., 2011), which extends PTK by allowing soft matching (i.e., via similarity computation) between nodes associated with different but related lexical items. The node similarity can be derived from manually annotated resources, e.g., WordNet or Wikipedia, as well as using corpusbased clustering approaches, e.g., latent semantic analysis (LSA), as we do in this paper. 3.3 Semantic structures Tree kernels allow us to compute structural similarities between two trees; thus, we engineered a special structure for the CSL task. In order to capture the structural dependencies between the semantic tags,1 we use</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1034–1046, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renato De Mori</author>
<author>Frederic B´echet</author>
<author>Dilek Hakkani-T¨ur</author>
<author>Michael McTear</author>
<author>Giuseppe Riccardi</author>
<author>Gokhan Tur</author>
</authors>
<title>Spoken Language Understanding.</title>
<date>2008</date>
<journal>IEEE Signal Processing Magazine,</journal>
<pages>25--50</pages>
<marker>De Mori, B´echet, Hakkani-T¨ur, McTear, Riccardi, Tur, 2008</marker>
<rawString>Renato De Mori, Frederic B´echet, Dilek Hakkani-T¨ur, Michael McTear, Giuseppe Riccardi, and Gokhan Tur. 2008. Spoken Language Understanding. IEEE Signal Processing Magazine, 25:50–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Discriminative reranking for spoken language understanding.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="2553" citStr="Dinarelli et al., 2012" startWordPosition="367" endWordPosition="370">ese] [City doha] [Amenity carry out] Finally, a database query is formed from the list of labels and values, and is then executed against the database, e.g., MongoDB; a backoff mechanism may be used if the query has not succeeded. {$and [{cuisine:&amp;quot;lebanese&amp;quot;},{city:&amp;quot;doha&amp;quot;}, {price:&amp;quot;low&amp;quot;},{amenity:&amp;quot;carry out&amp;quot;}]} The state-of-the-art of CSL is represented by conditional models for sequence labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also co</context>
</contexts>
<marker>Dinarelli, Moschitti, Riccardi, 2012</marker>
<rawString>Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2012. Discriminative reranking for spoken language understanding. IEEE Transactions on Audio, Speech and Language Processing, 20(2):526–539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G W Furnas</author>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>T K Landauer</author>
<author>R A Harshman</author>
<author>L A Streeter</author>
<author>K E Lochbaum</author>
</authors>
<title>Information retrieval using a singular value decomposition model of latent semantic structure.</title>
<date>1988</date>
<booktitle>In Proceedings of the 11th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR ’88),</booktitle>
<pages>465--480</pages>
<location>New York, USA.</location>
<contexts>
<context position="15730" citStr="Furnas et al., 1988" startWordPosition="2522" endWordPosition="2525">t clusters in a bottom-up fashion. The merge step is done in a way that minimizes the loss in average mutual information between clusters. The outcome is hierarchical clustering, which we use in our reranking algorithm. To create the Brown clusters, we used the Yelp dataset of reviews.7 It contains 335,022 reviews about 15,585 businesses; 5,575 of the businesses and 233,839 of the reviews are restaurant-related. This dataset is very similar to the dataset of queries about restaurants we use in our experiments. Similarity matrix for SK. We compute the lexical similarity for SK by applying LSA (Furnas et al., 1988) to Tripadvisor data. The dataset and the exact procedure for creating the LSA matrix are described in (Castellucci et al., 2013; Croce and Previtali, 2010). 4.2 Results Oracle accuracy. Table 2 shows the oracle F1 score for N-best lists of different lengths, i.e., the F1 that is achieved by picking the best candidate in the N-best list for various values of N. Considering 5-best lists yields an increase in oracle F1 of almost ten absolute points. Going up to 10-best lists only adds 2.5 extra F1 points. The complete 100-best lists add 3.5 extra F1 points, for a total of 98.72. This very high v</context>
</contexts>
<marker>Furnas, Deerwester, Dumais, Landauer, Harshman, Streeter, Lochbaum, 1988</marker>
<rawString>G. W. Furnas, S. Deerwester, S. T. Dumais, T. K. Landauer, R. A. Harshman, L. A. Streeter, and K. E. Lochbaum. 1988. Information retrieval using a singular value decomposition model of latent semantic structure. In Proceedings of the 11th annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR ’88), pages 465–480, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>Advances in Kernel Methods -Support Vector Learning.</booktitle>
<editor>In B. Schlkopf, C. Burges, and A. Smola, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="3692" citStr="Joachims, 1999" startWordPosition="543" endWordPosition="544">n Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also combining them with innovative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explicit features from them is rather difficult as their number is exponentially large. Thus, we rely on (i) Support Vector Machines (Joachims, 1999) to train the reranking functions and on (ii) structural kernels (Moschitti, 2010; Moschitti, 2012; Moschitti, 2013) to automatically encode tree fragments that represent syntactic and semantic dependencies from words and concepts. 436 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (a) Semantic Kernel Structure (SKS) (b) SKS with Brown Clusters Figure 1: CSL structures: standard and with Brown Clusters. We further apply a semantic kernel (SK), namel</context>
<context position="13995" citStr="Joachims, 1999" startWordPosition="2239" endWordPosition="2240">et to test and tune the hyper-parameters of our reranking model. The results on the development set, which we will present in Section 4.2 below, were obtained using semi-CRF and reranking models trained on the training set. Data representation. Each hypothesis is represented by a semantic tree, a feature vector (explained in Section 3), and two extra features: (i) the semi-CRF probability of the hypothesis, and (ii) its reciprocal rank in the N-best list. Learning algorithm. We used the SVM-LightTK5 to train the reranker with a combination of tree kernels and feature vectors (Moschitti, 2006; Joachims, 1999). We used the default parameters and a linear kernel for the feature vectors. As a baseline, we picked the best-scoring hypothesis in the list, i.e., the output by the regular semi-CRF parser. The setting is exactly the same as that described in (Saleh et al., 2014). Evaluation measure. In all experiments, we used the harmonic mean of precision and recall (F1) (van Rijsbergen, 1979), computed at the token level and micro-averaged across the different semantic types.6 4http://groups.csail.mit.edu/sls/downloads/restaurant/ 5http://disi.unitn.it/moschitti/Tree-Kernel.htm 6We do not consider ‘Othe</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale SVM learning practical. In B. Schlkopf, C. Burges, and A. Smola, editors, Advances in Kernel Methods -Support Vector Learning. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning (ICML</booktitle>
<pages>282--289</pages>
<location>Williamstown, MA, USA.</location>
<contexts>
<context position="2393" citStr="Lafferty et al., 2001" startWordPosition="341" endWordPosition="344">ity take out] Then, label-specific normalizers are applied to the segments, with the option to possibly relabel mislabeled segments: [Price low] [Cuisine lebanese] [City doha] [Amenity carry out] Finally, a database query is formed from the list of labels and values, and is then executed against the database, e.g., MongoDB; a backoff mechanism may be used if the query has not succeeded. {$and [{cuisine:&amp;quot;lebanese&amp;quot;},{city:&amp;quot;doha&amp;quot;}, {price:&amp;quot;low&amp;quot;},{amenity:&amp;quot;carry out&amp;quot;}]} The state-of-the-art of CSL is represented by conditional models for sequence labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structu</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML 2001), pages 282–289, Williamstown, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian McGraw</author>
<author>Scott Cyphers</author>
<author>Panupong Pasupat</author>
<author>Jingjing Liu</author>
<author>Jim Glass</author>
</authors>
<title>Automating crowd-supervised learning for spoken language systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Conference of the International Speech Communication Association (INTERSPEECH 2012),</booktitle>
<pages>2473--2476</pages>
<location>Portland, OR, USA.</location>
<contexts>
<context position="12865" citStr="McGraw et al. (2012)" startWordPosition="2052" endWordPosition="2055">he Stanford tagger (Toutanova et al., 2003). 3For instance, if the output sequence is Other-RatingOther-Amenity the 3-gram patterns would be: S-OtherRating, Other-Rating-Other, Rating-Other-Amenity, and Other-Amenity-E. 438 Train Devel. Test Total semi-CRF 6,922 739 1,521 9,182 Reranker 7,000 3,695 7,605 39,782 Table 1: Number of instances and pairs used to train the semi-CRF and rerankers, respectively. 4.1 Experimental setup Dataset. In our experiments, we used questions annotated with semantic tags, which were collected through crowdsourcing on Amazon Mechanical Turk and made available4 by McGraw et al. (2012). We split the dataset into training, development and test sets. Table 1 shows the number of examples and example pairs we used for the semi-CRF and the reranker, respectively. We subsequently split the training data randomly into 10 folds. We used cross-validation, i.e., iteratively training with 9 folds and annotating the remaining fold, in order to generate the N-best lists of hypotheses for the entire training dataset. We computed the 100-best hypotheses for each example. We then used the development dataset to test and tune the hyper-parameters of our reranking model. The results on the d</context>
</contexts>
<marker>McGraw, Cyphers, Pasupat, Liu, Glass, 2012</marker>
<rawString>Ian McGraw, Scott Cyphers, Panupong Pasupat, Jingjing Liu, and Jim Glass. 2012. Automating crowd-supervised learning for spoken language systems. In Proceedings of the 13th Annual Conference of the International Speech Communication Association (INTERSPEECH 2012), pages 2473–2476, Portland, OR, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify! linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management (CIKM</booktitle>
<pages>233--242</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="19370" citStr="Mihalcea and Csomai, 2007" startWordPosition="3135" endWordPosition="3138">ding. The improvement falls between 1-2 absolute percent points. This is remarkable as (i) it corresponds to ∼10% relative error reduction, and (ii) the state-of-the-art baseline system is very difficult to beat, as confirmed by the low impact of traditional features and BCs. Although the latter can generalize over concepts and words, their use is not straightforward, resulting in no improvement. In the future, we plan to investigate the use of semantic similarity from distributional and other sources (Mihalcea et al., 2006; Pad´o and Lapata, 2007), e.g., Wikipedia (Strube and Ponzetto, 2006; Mihalcea and Csomai, 2007), Wiktionary (Zesch et al., 2008), WordNet (Pedersen et al., 2004; Agirre et al., 2009), FrameNet, VerbNet (Shi and Mihalcea, 2005), BabelNet (Navigli and Ponzetto, 2010), and LSA, and for different domains. Acknowledgments This research is part of the Interactive sYstems for Answer Search (Iyas) project, conducted by the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the Qatar Foundation. We would like to thank Danilo Croce, Roberto Basili and Giuseppe Castellucci for helping and providing us with the similarity matrix for the semantic kernels. 44</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify! linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management (CIKM 2007), pages 233–242, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Courtney Corley</author>
<author>Carlo Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence - Volume</booktitle>
<volume>1</volume>
<pages>775--780</pages>
<location>Boston, MA, USA.</location>
<contexts>
<context position="19273" citStr="Mihalcea et al., 2006" startWordPosition="3121" endWordPosition="3124">s to PTK+all in the above comparison. 8Models are split between 2 plots in order to ease reading. The improvement falls between 1-2 absolute percent points. This is remarkable as (i) it corresponds to ∼10% relative error reduction, and (ii) the state-of-the-art baseline system is very difficult to beat, as confirmed by the low impact of traditional features and BCs. Although the latter can generalize over concepts and words, their use is not straightforward, resulting in no improvement. In the future, we plan to investigate the use of semantic similarity from distributional and other sources (Mihalcea et al., 2006; Pad´o and Lapata, 2007), e.g., Wikipedia (Strube and Ponzetto, 2006; Mihalcea and Csomai, 2007), Wiktionary (Zesch et al., 2008), WordNet (Pedersen et al., 2004; Agirre et al., 2009), FrameNet, VerbNet (Shi and Mihalcea, 2005), BabelNet (Navigli and Ponzetto, 2010), and LSA, and for different domains. Acknowledgments This research is part of the Interactive sYstems for Answer Search (Iyas) project, conducted by the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the Qatar Foundation. We would like to thank Danilo Croce, Roberto Basili and Giuseppe</context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Rada Mihalcea, Courtney Corley, and Carlo Strapparava. 2006. Corpus-based and knowledge-based measures of text semantic similarity. In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 1 (AAAI 2006), pages 775–780, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Richard Schwartz</author>
<author>Robert Bobrow</author>
<author>Robert Ingria</author>
</authors>
<title>Statistical Language Processing using Hidden Understanding Models.</title>
<date>1994</date>
<booktitle>In Proceedings of the workshop on Human Language Technology (HLT 1994),</booktitle>
<pages>278--282</pages>
<location>Plainsboro, NJ, USA.</location>
<contexts>
<context position="5736" citStr="Miller et al. (1994)" startWordPosition="861" endWordPosition="864">t of the first 100 hypotheses in 98.72% of the cases. (iii) SKs significantly improve over the semi-CRF baseline and our previous state-of-the-art reranker exploiting shallow syntactic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL was that of Pieraccini et al. (1991), where the word sequences and concepts were modeled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were fi</context>
</contexts>
<marker>Miller, Schwartz, Bobrow, Ingria, 1994</marker>
<rawString>Scott Miller, Richard Schwartz, Robert Bobrow, and Robert Ingria. 1994. Statistical Language Processing using Hidden Understanding Models. In Proceedings of the workshop on Human Language Technology (HLT 1994), pages 278–282, Plainsboro, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Semantic role labeling via tree kernel joint inference.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>61--68</pages>
<location>New York City, USA.</location>
<contexts>
<context position="2528" citStr="Moschitti et al., 2006" startWordPosition="363" endWordPosition="366">rice low] [Cuisine lebanese] [City doha] [Amenity carry out] Finally, a database query is formed from the list of labels and values, and is then executed against the database, e.g., MongoDB; a backoff mechanism may be used if the query has not succeeded. {$and [{cuisine:&amp;quot;lebanese&amp;quot;},{city:&amp;quot;doha&amp;quot;}, {price:&amp;quot;low&amp;quot;},{amenity:&amp;quot;carry out&amp;quot;}]} The state-of-the-art of CSL is represented by conditional models for sequence labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic </context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2006</marker>
<rawString>Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2006. Semantic role labeling via tree kernel joint inference. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 61–68, New York City, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In Proceedings of the 17th European Conference on Machine Learning (ECML</booktitle>
<pages>318--329</pages>
<location>Berlin, Germany.</location>
<contexts>
<context position="2596" citStr="Moschitti, 2006" startWordPosition="375" endWordPosition="376">tabase query is formed from the list of labels and values, and is then executed against the database, e.g., MongoDB; a backoff mechanism may be used if the query has not succeeded. {$and [{cuisine:&amp;quot;lebanese&amp;quot;},{city:&amp;quot;doha&amp;quot;}, {price:&amp;quot;low&amp;quot;},{amenity:&amp;quot;carry out&amp;quot;}]} The state-of-the-art of CSL is represented by conditional models for sequence labeling such as Conditional Random Fields (CRFs) (Lafferty et al., 2001) trained with simple morphological and lexical features. The basic CRF model was improved by means of reranking (Moschitti et al., 2006; Dinarelli et al., 2012) using structural kernels (Moschitti, 2006). Although these methods exploited sentence structure, they did not use syntax at all. More recently, we applied shallow syntactic structures and discourse parsing with slightly better results (Saleh et al., 2014). However, the most obvious models for semantic parsing, i.e., rerankers based on semantic structural kernels (Bloehdorn and Moschitti, 2007b), had not been applied to semantic structures yet. In this paper, we study the impact of semantic information conveyed by Brown Clusters (BCs) (Brown et al., 1992) and semantic similarity, while also combining them with innovative features. We u</context>
<context position="8900" citStr="Moschitti, 2006" startWordPosition="1413" endWordPosition="1414">S(H1, H01) + S(H2, H02) − S(H1, H02) − S(H2, H01). We consider H as a tuple (T,~v) composed of a tree T and a feature vector ~v. Then, we define S(H, H0) = STK(T, T0) + Sv(~v,~v0), where STK computes one of the tree kernel functions defined in 3.2 and 3.3; and Sv is a kernel (see 3.4), e.g., linear, polynomial, Gaussian, etc. 3.2 Tree kernels (TKs) TKs measure the similarity between two structures in terms of the number of substructures they share. We use two types of tree kernels: (i) Partial Tree Kernel (PTK), which can be effectively applied to both constituency and dependency parse trees (Moschitti, 2006). It generates all possible connected tree fragments, e.g., sibling nodes can be also separated and can be part of different tree fragments: a fragment is any possible tree path, and other tree paths are allowed to depart from its nodes. Thus, it can generate a very rich feature space. (ii) The smoothed PTK or semantic kernel (SK) (Croce et al., 2011), which extends PTK by allowing soft matching (i.e., via similarity computation) between nodes associated with different but related lexical items. The node similarity can be derived from manually annotated resources, e.g., WordNet or Wikipedia, a</context>
<context position="13978" citStr="Moschitti, 2006" startWordPosition="2237" endWordPosition="2238">development dataset to test and tune the hyper-parameters of our reranking model. The results on the development set, which we will present in Section 4.2 below, were obtained using semi-CRF and reranking models trained on the training set. Data representation. Each hypothesis is represented by a semantic tree, a feature vector (explained in Section 3), and two extra features: (i) the semi-CRF probability of the hypothesis, and (ii) its reciprocal rank in the N-best list. Learning algorithm. We used the SVM-LightTK5 to train the reranker with a combination of tree kernels and feature vectors (Moschitti, 2006; Joachims, 1999). We used the default parameters and a linear kernel for the feature vectors. As a baseline, we picked the best-scoring hypothesis in the list, i.e., the output by the regular semi-CRF parser. The setting is exactly the same as that described in (Saleh et al., 2014). Evaluation measure. In all experiments, we used the harmonic mean of precision and recall (F1) (van Rijsbergen, 1979), computed at the token level and micro-averaged across the different semantic types.6 4http://groups.csail.mit.edu/sls/downloads/restaurant/ 5http://disi.unitn.it/moschitti/Tree-Kernel.htm 6We do n</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In Proceedings of the 17th European Conference on Machine Learning (ECML 2006), pages 318–329, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel engineering for fast and easy design of natural language applications.</title>
<date>2010</date>
<booktitle>In Coling 2010: Kernel Engineering for Fast and Easy Design of Natural Language Applications–Tutorial notes,</booktitle>
<pages>1--91</pages>
<location>Beijing, China.</location>
<contexts>
<context position="3773" citStr="Moschitti, 2010" startWordPosition="555" endWordPosition="556">ng them with innovative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explicit features from them is rather difficult as their number is exponentially large. Thus, we rely on (i) Support Vector Machines (Joachims, 1999) to train the reranking functions and on (ii) structural kernels (Moschitti, 2010; Moschitti, 2012; Moschitti, 2013) to automatically encode tree fragments that represent syntactic and semantic dependencies from words and concepts. 436 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (a) Semantic Kernel Structure (SKS) (b) SKS with Brown Clusters Figure 1: CSL structures: standard and with Brown Clusters. We further apply a semantic kernel (SK), namely the Smoothed Partial Tree Kernel (Croce et al., 2011), which uses the lexical s</context>
</contexts>
<marker>Moschitti, 2010</marker>
<rawString>Alessandro Moschitti. 2010. Kernel engineering for fast and easy design of natural language applications. In Coling 2010: Kernel Engineering for Fast and Easy Design of Natural Language Applications–Tutorial notes, pages 1–91, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>State-of-the-art kernels for natural language processing.</title>
<date>2012</date>
<booktitle>In Tutorial Abstracts of ACL 2012,</booktitle>
<pages>2</pages>
<location>Jeju Island,</location>
<contexts>
<context position="3790" citStr="Moschitti, 2012" startWordPosition="557" endWordPosition="558">vative features. We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explicit features from them is rather difficult as their number is exponentially large. Thus, we rely on (i) Support Vector Machines (Joachims, 1999) to train the reranking functions and on (ii) structural kernels (Moschitti, 2010; Moschitti, 2012; Moschitti, 2013) to automatically encode tree fragments that represent syntactic and semantic dependencies from words and concepts. 436 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (a) Semantic Kernel Structure (SKS) (b) SKS with Brown Clusters Figure 1: CSL structures: standard and with Brown Clusters. We further apply a semantic kernel (SK), namely the Smoothed Partial Tree Kernel (Croce et al., 2011), which uses the lexical similarity between</context>
</contexts>
<marker>Moschitti, 2012</marker>
<rawString>Alessandro Moschitti. 2012. State-of-the-art kernels for natural language processing. In Tutorial Abstracts of ACL 2012, page 2, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel-based learning to rank with syntactic and semantic structures.</title>
<date>2013</date>
<booktitle>In Tutorial abstracts of the 36th Annual ACM SIGIR Conference,</booktitle>
<pages>1128</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="3808" citStr="Moschitti, 2013" startWordPosition="559" endWordPosition="560">We use reranking, similarly to (Saleh et al., 2014), to select the best hypothesis annotated with concepts predicted by a local model. The competing hypotheses are represented as innovative trees enriched with the semantic concepts and BC labels. The trees can capture dependencies between sentence constituents, concepts and BCs. However, extracting explicit features from them is rather difficult as their number is exponentially large. Thus, we rely on (i) Support Vector Machines (Joachims, 1999) to train the reranking functions and on (ii) structural kernels (Moschitti, 2010; Moschitti, 2012; Moschitti, 2013) to automatically encode tree fragments that represent syntactic and semantic dependencies from words and concepts. 436 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 436–442, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (a) Semantic Kernel Structure (SKS) (b) SKS with Brown Clusters Figure 1: CSL structures: standard and with Brown Clusters. We further apply a semantic kernel (SK), namely the Smoothed Partial Tree Kernel (Croce et al., 2011), which uses the lexical similarity between the tree nodes, w</context>
</contexts>
<marker>Moschitti, 2013</marker>
<rawString>Alessandro Moschitti. 2013. Kernel-based learning to rank with syntactic and semantic structures. In Tutorial abstracts of the 36th Annual ACM SIGIR Conference, page 1128, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Babelnet: Building a very large multilingual semantic network.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th annual meeting of the association for computational linguistics (ACL 2010),</booktitle>
<pages>216--225</pages>
<location>Uppsala,</location>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2010. Babelnet: Building a very large multilingual semantic network. In Proceedings of the 48th annual meeting of the association for computational linguistics (ACL 2010), pages 216–225, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Dependency-based construction of semantic space models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Pad´o, Lapata, 2007</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2007. Dependency-based construction of semantic space models. Computational Linguistics, 33(2):161–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity - measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Demonstration Papers,</booktitle>
<pages>38--41</pages>
<location>Boston, Massachusetts, USA.</location>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity - measuring the relatedness of concepts. In HLT-NAACL 2004: Demonstration Papers, pages 38–41, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Pieraccini</author>
<author>Esther Levin</author>
<author>Chin-Hui Lee</author>
</authors>
<title>Stochastic Representation of Conceptual Structure in the ATIS Task.</title>
<date>1991</date>
<booktitle>In Proceedings of the Fourth Joint DARPA Speech and Natural Language Workshop,</booktitle>
<pages>121--124</pages>
<location>Los Altos, CA, USA.</location>
<contexts>
<context position="5526" citStr="Pieraccini et al. (1991)" startWordPosition="828" endWordPosition="831">y very accurate; it achieves F1 scores over 83%, making any further improvement very hard. (ii) The upper-bound performance of the reranker is very high as well, i.e., the correct annotation is generated in the list of the first 100 hypotheses in 98.72% of the cases. (iii) SKs significantly improve over the semi-CRF baseline and our previous state-of-the-art reranker exploiting shallow syntactic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL was that of Pieraccini et al. (1991), where the word sequences and concepts were modeled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between fe</context>
</contexts>
<marker>Pieraccini, Levin, Lee, 1991</marker>
<rawString>Roberto Pieraccini, Esther Levin, and Chin-Hui Lee. 1991. Stochastic Representation of Conceptual Structure in the ATIS Task. In Proceedings of the Fourth Joint DARPA Speech and Natural Language Workshop, pages 121–124, Los Altos, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Raymond</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Generative and Discriminative Algorithms for Spoken Language Understanding.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th Annual Conference of the International Speech Communication Association (INTERSPEECH</booktitle>
<pages>1605--1608</pages>
<location>Antwerp, Belgium,</location>
<contexts>
<context position="5922" citStr="Raymond and Riccardi, 2007" startWordPosition="887" endWordPosition="890">actic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL was that of Pieraccini et al. (1991), where the word sequences and concepts were modeled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, which we also use in this paper, is the Smoothed PTK (C</context>
</contexts>
<marker>Raymond, Riccardi, 2007</marker>
<rawString>Christian Raymond and Giuseppe Riccardi. 2007. Generative and Discriminative Algorithms for Spoken Language Understanding. In Proceedings of the 8th Annual Conference of the International Speech Communication Association (INTERSPEECH 2007), pages 1605–1608, Antwerp, Belgium, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Dan Rubinstein</author>
<author>Trevor Hastie</author>
</authors>
<title>Discriminative vs Informative Learning.</title>
<date>1997</date>
<booktitle>In Proceedings of the Third International Conference on Knowledge Discovery and Data Mining (KDD-1997),</booktitle>
<pages>49--53</pages>
<location>Newport Beach, CA, USA.</location>
<contexts>
<context position="5870" citStr="Rubinstein and Hastie, 1997" startWordPosition="879" endWordPosition="882">us state-of-the-art reranker exploiting shallow syntactic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL was that of Pieraccini et al. (1991), where the word sequences and concepts were modeled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we use in this paper were first introduced in (Bloehdorn and Moschitti, 2007a; Bloehdorn and Moschitti, 2007b). The most advanced model based on tree kernels, whi</context>
</contexts>
<marker>Rubinstein, Hastie, 1997</marker>
<rawString>Y. Dan Rubinstein and Trevor Hastie. 1997. Discriminative vs Informative Learning. In Proceedings of the Third International Conference on Knowledge Discovery and Data Mining (KDD-1997), pages 49– 53, Newport Beach, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iman Saleh</author>
<author>Scott Cyphers</author>
<author>Jim Glass</author>
<author>Shafiq Joty</author>
<author>Llu´ıs M`arquez</author>
<author>Alessandro Moschitti</author>
<author>Preslav Nakov</author>
</authors>
<title>A study of using syntactic and semantic structures for concept segmentation and labeling.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics, COLING ’14,</booktitle>
<pages>193--202</pages>
<location>Dublin, Ireland.</location>
<marker>Saleh, Cyphers, Glass, Joty, M`arquez, Moschitti, Nakov, 2014</marker>
<rawString>Iman Saleh, Scott Cyphers, Jim Glass, Shafiq Joty, Llu´ıs M`arquez, Alessandro Moschitti, and Preslav Nakov. 2014. A study of using syntactic and semantic structures for concept segmentation and labeling. In Proceedings of the 25th International Conference on Computational Linguistics, COLING ’14, pages 193–202, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Santaf´e</author>
<author>J A Lozano</author>
<author>P Larra˜naga</author>
</authors>
<title>Discriminative vs. Generative Learning of Bayesian Network Classifiers.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU</booktitle>
<pages>453--546</pages>
<location>Hammamet, Tunisia.</location>
<marker>Santaf´e, Lozano, Larra˜naga, 2007</marker>
<rawString>G. Santaf´e, J.A. Lozano, and P. Larra˜naga. 2007. Discriminative vs. Generative Learning of Bayesian Network Classifiers. In Proceedings of the 9th European Conference on Symbolic and Quantitative Approaches to Reasoning with Uncertainty (ECSQARU 2007), pages 453–546, Hammamet, Tunisia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In Advances in Neural Information Processing Systems 17 (NIPS 2004),</booktitle>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="4891" citStr="Sarawagi and Cohen, 2004" startWordPosition="723" endWordPosition="726">emantic kernel (SK), namely the Smoothed Partial Tree Kernel (Croce et al., 2011), which uses the lexical similarity between the tree nodes, while computing the substructure space. This is the first time that SKs are applied to reranking hypotheses. This (i) makes the global sentence structure along with concepts available to the learning algorithm, and (ii) enables computing the similarity between lexicals in syntactic patterns that are enriched by concepts. We tested our models on the Restaurant domain. Our results show that: (i) The basic CRF parser, which uses semi-Markov CRF, or semiCRF (Sarawagi and Cohen, 2004), is already very accurate; it achieves F1 scores over 83%, making any further improvement very hard. (ii) The upper-bound performance of the reranker is very high as well, i.e., the correct annotation is generated in the list of the first 100 hypotheses in 98.72% of the cases. (iii) SKs significantly improve over the semi-CRF baseline and our previous state-of-the-art reranker exploiting shallow syntactic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL w</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In Advances in Neural Information Processing Systems 17 (NIPS 2004), Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>TINA: A Probabilistic Syntactic Parser for Speech Understanding Systems.</title>
<date>1989</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP89),</booktitle>
<pages>711--714</pages>
<location>Glasgow, UK.</location>
<contexts>
<context position="5711" citStr="Seneff (1989)" startWordPosition="858" endWordPosition="859">nerated in the list of the first 100 hypotheses in 98.72% of the cases. (iii) SKs significantly improve over the semi-CRF baseline and our previous state-of-the-art reranker exploiting shallow syntactic patterns (Saleh et al., 2014), as shown by extensive comparisons using several systems. (iv) Making BCs effective requires a deeper study. 2 Related Work One of the early approaches to CSL was that of Pieraccini et al. (1991), where the word sequences and concepts were modeled using Hidden Markov Models (HMMs) as observations and hidden states, respectively. Generative models were exploited by Seneff (1989) and Miller et al. (1994), who used stochastic grammars for CSL. Other discriminative models followed such preliminary work, e.g., (Rubinstein and Hastie, 1997; Santaf´e et al., 2007; Raymond and Riccardi, 2007). CRF-based models are considered to be the state of the art in CSL (De Mori et al., 2008). Another relevant line of research are the semantic kernels, i.e., kernels that use lexical similarity between features. One of the first that applyed LSA was (Cristianini et al., 2002), whereas (Bloehdorn et al., 2006; Basili et al., 2006) used WordNet. Semantic structural kernels of the type we </context>
</contexts>
<marker>Seneff, 1989</marker>
<rawString>Stephanie Seneff. 1989. TINA: A Probabilistic Syntactic Parser for Speech Understanding Systems. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing (ICASSP89), pages 711–714, Glasgow, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing.</title>
<date>2005</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>100--111</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. 2005. Putting pieces together: Combining framenet, verbnet and wordnet for robust semantic parsing. In Computational Linguistics and Intelligent Text Processing, pages 100– 111. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Wikirelate! computing semantic relatedness using wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI’06),</booktitle>
<pages>1419--1424</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="19342" citStr="Strube and Ponzetto, 2006" startWordPosition="3131" endWordPosition="3134"> plots in order to ease reading. The improvement falls between 1-2 absolute percent points. This is remarkable as (i) it corresponds to ∼10% relative error reduction, and (ii) the state-of-the-art baseline system is very difficult to beat, as confirmed by the low impact of traditional features and BCs. Although the latter can generalize over concepts and words, their use is not straightforward, resulting in no improvement. In the future, we plan to investigate the use of semantic similarity from distributional and other sources (Mihalcea et al., 2006; Pad´o and Lapata, 2007), e.g., Wikipedia (Strube and Ponzetto, 2006; Mihalcea and Csomai, 2007), Wiktionary (Zesch et al., 2008), WordNet (Pedersen et al., 2004; Agirre et al., 2009), FrameNet, VerbNet (Shi and Mihalcea, 2005), BabelNet (Navigli and Ponzetto, 2010), and LSA, and for different domains. Acknowledgments This research is part of the Interactive sYstems for Answer Search (Iyas) project, conducted by the Arabic Language Technologies (ALT) group at Qatar Computing Research Institute (QCRI) within the Qatar Foundation. We would like to thank Danilo Croce, Roberto Basili and Giuseppe Castellucci for helping and providing us with the similarity matrix </context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. Wikirelate! computing semantic relatedness using wikipedia. In Proceedings of the 21st National Conference on Artificial Intelligence (AAAI’06), pages 1419–1424, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>173--180</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="12288" citStr="Toutanova et al., 2003" startWordPosition="1969" endWordPosition="1972">’) and end (‘E’) of the sequence.3 (iii) Probability-based, computing the probability of the label sequence as an average of the probabilities at the word level in the N-best list; and (iv) DB-based: a single feature encoding the number of results returned from the database when constructing a query using the conjunction of all semantic segments in the hypothesis. 4 Experiments The experiments aim at investigating the role of feature vectors, PTK, SK and BCs in reranking. We first describe the experimental setting and then we move into the analysis of the results. 2We use the Stanford tagger (Toutanova et al., 2003). 3For instance, if the output sequence is Other-RatingOther-Amenity the 3-gram patterns would be: S-OtherRating, Other-Rating-Other, Rating-Other-Amenity, and Other-Amenity-E. 438 Train Devel. Test Total semi-CRF 6,922 739 1,521 9,182 Reranker 7,000 3,695 7,605 39,782 Table 1: Number of instances and pairs used to train the semi-CRF and rerankers, respectively. 4.1 Experimental setup Dataset. In our experiments, we used questions annotated with semantic tags, which were collected through crowdsourcing on Amazon Mechanical Turk and made available4 by McGraw et al. (2012). We split the dataset </context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2003), pages 173–180, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cornelis J van Rijsbergen</author>
</authors>
<title>Information Retrieval.</title>
<date>1979</date>
<location>Butterworth-Heinemann Newton, MA, USA.</location>
<marker>van Rijsbergen, 1979</marker>
<rawString>Cornelis J. van Rijsbergen. 1979. Information Retrieval. Butterworth-Heinemann Newton, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Zesch</author>
<author>Christof M¨uller</author>
<author>Iryna Gurevych</author>
</authors>
<title>Using wiktionary for computing semantic relatedness.</title>
<date>2008</date>
<booktitle>In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI’08),</booktitle>
<pages>861--866</pages>
<location>Chicago, Illinois,USA.</location>
<marker>Zesch, M¨uller, Gurevych, 2008</marker>
<rawString>Torsten Zesch, Christof M¨uller, and Iryna Gurevych. 2008. Using wiktionary for computing semantic relatedness. In Proceedings of the 23rd National Conference on Artificial Intelligence (AAAI’08), pages 861–866, Chicago, Illinois,USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>