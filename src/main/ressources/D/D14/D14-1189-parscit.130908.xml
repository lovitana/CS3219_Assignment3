<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.018698">
<title confidence="0.981639">
Detecting Non-compositional MWE Components using Wiktionary
</title>
<author confidence="0.993919">
Bahar Salehi,4° Paul Cook° and Timothy Baldwin4°
</author>
<affiliation confidence="0.969584">
♣ NICTA Victoria Research Laboratory
♥ Department of Computing and Information Systems
The University of Melbourne
</affiliation>
<address confidence="0.647037">
Victoria 3010, Australia
</address>
<email confidence="0.9897">
bsalehi@student.unimelb.edu.au, paulcook@unimelb.edu.au, tb@ldwin.net
</email>
<sectionHeader confidence="0.993879" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938545454545">
We propose a simple unsupervised ap-
proach to detecting non-compositional
components in multiword expressions
based on Wiktionary. The approach makes
use of the definitions, synonyms and trans-
lations in Wiktionary, and is applicable to
any type of MWE in any language, assum-
ing the MWE is contained in Wiktionary.
Our experiments show that the proposed
approach achieves higher F-score than
state-of-the-art methods.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999904233333333">
A multiword expression (MWE) is a combina-
tion of words with lexical, syntactic or seman-
tic idiosyncrasy (Sag et al., 2002; Baldwin and
Kim, 2009). An MWE is considered (semanti-
cally) “non-compositional” when its meaning is
not predictable from the meaning of its compo-
nents. Conversely, compositional MWEs are those
whose meaning is predictable from the meaning
of the components. Based on this definition, a
component is compositional within an MWE, if its
meaning is reflected in the meaning of the MWE,
and it is non-compositional otherwise.
Understanding which components are non-
compositional within an MWE is important in
NLP applications in which semantic information
is required. For example, when searching for
spelling bee, we may also be interested in docu-
ments about spelling, but not those which contain
only bee. For research project, on the other hand,
we are likely to be interested in documents which
contain either research or project in isolation, and
for swan song, we are only going to be interested
in documents which contain the phrase swan song,
and not just swan or song.
In this paper, we propose an unsupervised ap-
proach based on Wikitionary for predicting which
components of a given MWE have a composi-
tional usage. Experiments over two widely-used
datasets show that our approach outperforms state-
of-the-art methods.
</bodyText>
<sectionHeader confidence="0.999814" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999975571428571">
Previous studies which have considered MWE
compositionality have focused on either the iden-
tification of non-compositional MWE token in-
stances (Kim and Baldwin, 2007; Fazly et al.,
2009; Forthergill and Baldwin, 2011; Muzny and
Zettlemoyer, 2013), or the prediction of the com-
positionality of MWE types (Reddy et al., 2011;
Salehi and Cook, 2013; Salehi et al., 2014). The
identification of non-compositional MWE tokens
is an important task when a word combination
such as kick the bucket or saw logs is ambiguous
between a compositional (generally non-MWE)
and non-compositional MWE usage. Approaches
have ranged from the unsupervised learning of
type-level preferences (Fazly et al., 2009) to su-
pervised methods specific to particular MWE con-
structions (Kim and Baldwin, 2007) or applica-
ble across multiple constructions using features
similar to those used in all-words word sense
disambiguation (Forthergill and Baldwin, 2011;
Muzny and Zettlemoyer, 2013). The prediction
of the compositionality of MWE types has tradi-
tionally been couched as a binary classification
task (compositional or non-compositional: Bald-
win et al. (2003), Bannard (2006)), but more re-
cent work has moved towards a regression setup,
where the degree of the compositionality is pre-
dicted on a continuous scale (Reddy et al., 2011;
Salehi and Cook, 2013; Salehi et al., 2014). In ei-
ther case, the modelling has been done either over
the whole MWE (Reddy et al., 2011; Salehi and
Cook, 2013), or relative to each component within
the MWE (Baldwin et al., 2003; Bannard, 2006).
In this paper, we focus on the binary classification
of MWE types relative to each component of the
</bodyText>
<page confidence="0.915182">
1792
</page>
<bodyText confidence="0.986849037037037">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1792–1797,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
MWE.
The work that is perhaps most closely related to
this paper is that of Salehi and Cook (2013) and
Salehi et al. (2014), who use translation data to
predict the compositionality of a given MWE rel-
ative to each of its components, and then combine
those scores to derive an overall compositionality
score. In both cases, translations of the MWE and
its components are sourced from PanLex (Bald-
win et al., 2010; Kamholz et al., 2014), and if
there is greater similarity between the translated
components and MWE in a range of languages,
the MWE is predicted to be more compositional.
The basis of the similarity calculation is unsuper-
vised, using either string similarity (Salehi and
Cook, 2013) or distributional similarity (Salehi et
al., 2014). However, the overall method is su-
pervised, as training data is used to select the
languages to aggregate scores across for a given
MWE construction. To benchmark our method,
we use two of the same datasets as these two pa-
pers, and repurpose the best-performing methods
of Salehi and Cook (2013) and Salehi et al. (2014)
for classification of the compositionality of each
MWE component.
</bodyText>
<sectionHeader confidence="0.998151" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.99995845">
Our basic method relies on analysis of lexical
overlap between the component words and the def-
initions of the MWE in Wiktionary, in the man-
ner of Lesk (1986). That is, if a given component
can be found in the definition, then it is inferred
that the MWE carries the meaning of that compo-
nent. For example, the Wiktionary definition of
swimming pool is “An artificially constructed pool
of water used for swimming”, suggesting that the
MWE is compositional relative to both swimming
and pool. If the MWE is not found in Wiktionary,
we use Wikipedia as a backoff, and use the first
paragraph of the (top-ranked) Wikipedia article as
a proxy for the definition.
As detailed below, we further extend the basic
method to incorporate three types of information
found in Wiktionary: (1) definitions of each word
in the definitions, (2) synonyms of the words in the
definitions, and (3) translations of the MWEs and
components.
</bodyText>
<subsectionHeader confidence="0.98619">
3.1 Definition-based Similarity
</subsectionHeader>
<bodyText confidence="0.99944015">
The basic method uses Boolean lexical overlap be-
tween the target component of the MWE and a
definition. A given MWE will often have multiple
definitions, however, begging the question of how
to combine across them, for which we propose the
following three methods.
First Definition (FIRSTDEF): Use only the
first-listed Wiktionary definition for the MWE,
based on the assumption that this is the predom-
inant sense.
All Definitions (ALLDEFS): In the case that
there are multiple definitions for the MWE, cal-
culate the lexical overlap for each independently
and take a majority vote; in the case of a tie, label
the component as non-compositional.
Idiom Tag (ITAG): In Wiktionary, there is fa-
cility for users to tag definitions as idiomatic.1 If,
for a given MWE, there are definitions tagged as
idiomatic, use only those definitions; if there are
no such definitions, use the full set of definitions.
</bodyText>
<subsectionHeader confidence="0.998936">
3.2 Synonym-based Definition Expansion
</subsectionHeader>
<bodyText confidence="0.999883842105263">
In some cases, a component is not explicitly men-
tioned in a definition, but a synonym does occur,
indicating that the definition is compositional in
that component. In order to capture synonym-
based matches, we optionally look for synonyms
of the component word in the definition,2 and ex-
pand our notion of lexical overlap to include these
synonyms.
For example, for the MWE china clay, the defi-
nition is kaolin, which includes neither of the com-
ponents. However, we find the component word
clay in the definition for kaolin, as shown below.
A fine clay, rich in kaolinite, used in ce-
ramics, paper-making, etc.
This method is compatible with the three
definition-based similarity methods described
above, and indicated by the +SYN suffix (e.g.
FIRSTDEF+SYN is FIRSTDEF with synonym-
based expansion).
</bodyText>
<subsectionHeader confidence="0.994971">
3.3 Translations
</subsectionHeader>
<bodyText confidence="0.99997275">
A third information source in Wiktionary that can
be used to predict compositionality is sense-level
translation data. Due to the user-generated na-
ture of Wiktionary, the set of languages for which
</bodyText>
<footnote confidence="0.996653666666667">
1Although the recall of these tags is low (Muzny and
Zettlemoyer, 2013).
2After removing function words, based on a stopword list.
</footnote>
<page confidence="0.83854">
1793
</page>
<table confidence="0.99833175">
ENC EVPC
WordNet 91.1% 87.5%
Wiktionary 96.7% 96.2%
Wiktionary+Wikipedia 100.0% 96.2%
</table>
<tableCaption confidence="0.987331">
Table 1: Lexical coverage of WordNet, Wik-
</tableCaption>
<bodyText confidence="0.995995185185185">
tionary and Wiktionary+Wikipedia over our two
datasets.
translations are provided varies greatly across lexi-
cal entries. Our approach is to take whatever trans-
lations happen to exist in Wiktionary for a given
MWE, and where there are translations in that lan-
guage for the component of interest, use the LCS-
based method of Salehi and Cook (2013) to mea-
sure the string similarity between the translation
of the MWE and the translation of the compo-
nents. Unlike Salehi and Cook (2013), however,
we do not use development data to select the opti-
mal set of languages in a supervised manner, and
instead simply take the average of the string simi-
larity scores across the available languages. In the
case of more than one translation in a given lan-
guage, we use the maximum string similarity for
each pairing of MWE and component translation.
Unlike the definition and synonym-based ap-
proach, the translation-based approach will pro-
duce real rather than binary values. To combine
the two approaches, we discretise the scores given
by the translation approach. In the case of dis-
agreement between the two approaches, we label
the given MWE as non-compositional. This re-
sults in higher recall and lower precision for the
task of detecting compositionality.
</bodyText>
<subsectionHeader confidence="0.997099">
3.4 An Analysis of Wiktionary Coverage
</subsectionHeader>
<bodyText confidence="0.9999863">
A dictionary-based method is only as good as the
dictionary it is applied to. In the case of MWE
compositionality analysis, our primary concern is
lexical coverage in Wiktionary, i.e., what propor-
tion of a representative set of MWEs is contained
in Wiktionary. We measure lexical coverage rela-
tive to the two datasets used in this research (de-
scribed in detail in Section 4), namely 90 En-
glish noun compounds (ENCs) and 160 English
verb particle constructions (EVPCs). In each case,
we calculated the proportion of the dataset that
is found in Wiktionary, Wiktionary+Wikipedia
(where we back off to a Wikipedia document in the
case that a MWE is not found in Wiktionary) and
WordNet (Fellbaum, 1998). The results are found
in Table 1, and indicate perfect coverage in Wik-
tionary+Wikipedia for the ENCs, and very high
coverage for the EVPCs. In both cases, the cov-
erage of WordNet is substantially lower, although
still respectable, at around 90%.
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="method">
4 Datasets
</sectionHeader>
<bodyText confidence="0.999893833333333">
As mentioned above, we evaluate our method over
the same two datasets as Salehi and Cook (2013)
(which were later used, in addition to a third
dataset of German noun compounds, in Salehi
et al. (2014)): (1) 90 binary English noun com-
pounds (ENCs, e.g. spelling bee or swimming
pool); and (2) 160 English verb particle construc-
tions (EVPCs, e.g. stand up and give away). Our
results are not directly comparable with those of
Salehi and Cook (2013) and Salehi et al. (2014),
however, who evaluated in terms of a regression
task, modelling the overall compositionality of the
MWE. In our case, the task setup is a binary clas-
sification task relative to each of the two compo-
nents of the MWE.
The ENC dataset was originally constructed by
Reddy et al. (2011), and annotated on a contin-
uous [0, 5] scale for both overall compositional-
ity and the component-wise compositionality of
each of the modifier and head noun. The sampling
was random in an attempt to make the dataset bal-
anced, with 48% of compositional English noun
compounds, of which 51% are compositional in
the first component and 60% are compositional in
the second component. We generate discrete la-
bels by discretising the component-wise composi-
tionality scores based on the partitions [0, 2.5] and
(2.5, 5]. On average, each NC in this dataset has
1.4 senses (definitions) in Wiktionary.
The EVPC dataset was constructed by Ban-
nard (2006), and manually annotated for com-
positionality on a binary scale for each of the
head verb and particle. For the 160 EVPCs,
76% are verb-compositional and 48% are particle-
compositional. On average, each EVPC in this
dataset has 3.0 senses (definitions) in Wiktionary.
</bodyText>
<sectionHeader confidence="0.999609" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999913571428571">
The baseline for each dataset takes the form of
looking for a user-annotated idiom tag in the Wik-
tionary lexical entry for the MWE: if there is an id-
iomatic tag, both components are considered to be
non-compositional; otherwise, both components
are considered to be compositional. We expect
this method to suffer from low precision for two
</bodyText>
<page confidence="0.980628">
1794
</page>
<table confidence="0.9999240625">
Method First Component Second Component
Precision Recall F-score Precision Recall F-score
Baseline 66.7 68.2 67.4 66.7 83.3 74.1
LCS 60.0 77.7 67.7 81.6 68.1 64.6
DS 62.1 88.6 73.0 80.5 86.4 71.2
DS+DSL2 62.5 92.3 74.5 78.4 89.4 70.6
LCS+DS+DSL2 66.3 87.5 75.4 82.1 80.6 70.1
FIRSTDEF 59.4 93.2 72.6 54.2 88.9 67.4
ALLDEFS 59.5 100.0 74.6 52.9 100.0 69.2
ITAG 60.3 100.0 75.2 54.5 100.0 70.6
FIRSTDEF+SYN 64.9 84.1 73.3 63.8 83.3 72.3
ALLDEFS+SYN 64.5 90.9 75.5 60.4 88.9 71.9
ITAG+SYN 64.5 90.9 75.5 61.8 94.4 74.7
FIRSTDEF+SYN COMB(LCS+DS+DSL2) 82.9 85.3 84.1 81.9 80.0 69.8
ALLDEFS+SYN COMB(LCS+DS+DSL2) 81.2 88.1 84.5 87.3 80.6 73.3
ITAG+SYN COMB(LCS+DS+DSL2) 81.0 88.1 84.1 88.0 81.1 73.9
</table>
<tableCaption confidence="0.99002">
Table 2: Compositionality prediction results over the ENC dataset, relative to the first component (the
</tableCaption>
<bodyText confidence="0.9930412">
modifier noun) and the second component (the head noun)
reasons: first, the guidelines given to the annota-
tors of our datasets might be different from what
Wiktionary contributors assume to be an idiom.
Second, the baseline method assumes that for any
non-compositional MWE, all components must be
equally non-compositional, despite the wealth of
MWEs where one or more components are com-
positional (e.g. from the Wiktionary guidelines
for idiom inclusion,3 computer chess, basketball
player, telephone box).
We also compare our method with: (1) “LCS”,
the string similarity-based method of Salehi and
Cook (2013), in which 54 languages are used;
(2) “DS”, the monolingual distributional similarity
method of Salehi et al. (2014); (3) “DS+DSL2”,
the multilingual distributional similarity method
of Salehi et al. (2014), including supervised lan-
guage selection for a given dataset, based on cross-
validation; and (4) “LCS+DS+DSL2”, whereby
the first three methods are combined using a su-
pervised support vector regression model. In
each case, the continuous output of the model
is equal-width discretised to generate a binary
classification. We additionally present results for
the combination of each of the six methods pro-
posed in this paper with LCS, DS and DSL2, us-
ing a linear-kernel support vector machine (rep-
resented with the suffix “COMB(LCS+DS+DSL2)” for
a given method). The results are based on cross-
</bodyText>
<footnote confidence="0.7950905">
3http://en.wiktionary.org/wiki/
Wiktionary:Idioms_that_survived_RFD
</footnote>
<bodyText confidence="0.999782419354839">
validation, and for direct comparability, the parti-
tions are exactly the same as Salehi et al. (2014).
Tables 2 and 3 provide the results when our pro-
posed method for detecting non-compositionality
is applied to the ENC and EVPC datasets, respec-
tively. The inclusion of translation data was found
to improve all of precision, recall and F-score
across the board for all of the proposed methods.
For reasons of space, results without translation
data are therefore omitted from the paper.
Overall, the simple unsupervised methods pro-
posed in this paper are comparable with the unsu-
pervised and supervised state-of-the-art methods
of Salehi and Cook (2013) and Salehi et al. (2014),
with ITAG achieving the highest F-score for the
ENC dataset and for the verb components of the
EVPC dataset. The inclusion of synonyms boosts
results in most cases.
When we combine each of our proposed meth-
ods with the string and distributional similar-
ity methods of Salehi and Cook (2013) and
Salehi et al. (2014), we see substantial improve-
ments over the comparable combined method of
“LCS+DS+DSL2” in most cases, demonstrating
both the robustness of the proposed methods and
their complementarity with the earlier methods. It
is important to reinforce that the proposed meth-
ods make no language-specific assumptions and
are therefore applicable to any type of MWE and
any language, with the only requirement being that
the MWE of interest be listed in the Wiktionary for
</bodyText>
<page confidence="0.964847">
1795
</page>
<table confidence="0.9999280625">
Method First Component Second Component
Precision Recall F-score Precision Recall F-score
Baseline 24.6 36.8 29.5 59.6 40.5 48.2
LCS 36.5 49.2 39.3 61.5 63.7 60.3
DS 32.8 34.1 33.5 80.9 19.6 29.7
DS+DSL2 31.8 72.4 44.2 74.8 27.5 36.6
LCS+DS+DSL2 36.1 62.6 45.8 77.9 42.8 49.2
FIRSTDEF 24.8 84.2 38.3 54.5 94.0 69.0
ALLDEFS 25.0 97.4 39.8 53.6 97.6 69.2
ITAG 26.2 89.5 40.5 54.6 91.7 68.4
FIRSTDEF+SYN 32.9 65.8 43.9 60.4 65.5 62.9
ALLDEFS+SYN 28.4 81.6 42.1 62.5 77.4 69.1
ITAG+SYN 30.5 65.8 41.7 57.8 61.9 59.8
FIRSTDEF+SYN COMB(LCS+DS+DSL2) 34.0 65.3 44.7 83.6 67.3 65.4
ALLDEFS+SYN COMB(LCS+DS+DSL2) 37.4 70.9 48.9 80.4 65.9 63.0
ITAG+SYN COMB(LCS+DS+DSL2) 35.6 70.9 47.4 83.5 64.9 64.2
</table>
<tableCaption confidence="0.998033">
Table 3: Compositionality prediction results over the EVPC dataset, relative to the first component (the
</tableCaption>
<bodyText confidence="0.761928">
head verb) and the second component (the particle)
that language. onyms and translations). In future work, we hope
to address this problem by first finding the sense
</bodyText>
<listItem confidence="0.600599">
6 Error Analysis which matches best with the sentences given to the
</listItem>
<bodyText confidence="0.986695">
annotators.
We analysed all items in each dataset where the
system score differed from that of the human
annotators. For both datasets, the majority of
incorrectly-labelled items were compositional but
predicted to be non-compositional by our sys-
tem, as can be seen in the relatively low preci-
sion scores in Tables 2 and 3. In many of these
cases, the prediction based on definitions and syn-
onyms was compositional but the prediction based
on translations was non-compositional. In such
cases, we arbitrarily break the tie by labelling the
instance as non-compositional, and in doing so
favour recall over precision.
Some of the incorrectly-labelled ENCs have
a gold-standard annotation of around 2.5, or in
other words are semi-compositional. For exam-
ple, the compositionality score for game in game
plan is 2.82/5, but our system labels it as non-
compositional; a similar thing happens with figure
and the EVPC figure out. Such cases demonstrate
the limitation of approaches to MWE composi-
tionality that treat the problem as a binary clas-
sification task.
On average, the EVPCs have three senses,
which is roughly twice the number for ENCs. This
makes the prediction of compositionality harder,
as there is more information to combine across (an
effect that is compounded with the addition of syn-
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999959909090909">
We have proposed an unsupervised approach for
predicting the compositionality of an MWE rel-
ative to each of its components, based on lexi-
cal overlap using Wiktionary, optionally incorpo-
rating synonym and translation data. Our experi-
ments showed that the various instantiations of our
approach are superior to previous state-of-the-art
supervised methods. All code to replicate the re-
sults in this paper has been made publicly avail-
able at https://github.com/bsalehi/
wiktionary_MWE_compositionality.
</bodyText>
<sectionHeader confidence="0.994985" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999909142857143">
We thank the anonymous reviewers for their
insightful comments and valuable suggestions.
NICTA is funded by the Australian government as
represented by Department of Broadband, Com-
munication and Digital Economy, and the Aus-
tralian Research Council through the ICT Centre
of Excellence programme.
</bodyText>
<sectionHeader confidence="0.996822" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.8702595">
Timothy Baldwin and Su Nam Kim. 2009. Multiword
expressions. In Nitin Indurkhya and Fred J. Dam-
</reference>
<page confidence="0.932278">
1796
</page>
<reference confidence="0.998996773333333">
erau, editors, Handbook of Natural Language Pro-
cessing. CRC Press, Boca Raton, USA, 2nd edition.
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model
of multiword expression decomposability. In Pro-
ceedings of the ACL-2003 Workshop on Multiword
Expressions: Analysis, Acquisition and Treatment,
pages 89–96, Sapporo, Japan.
Timothy Baldwin, Jonathan Pool, and Susan M.
Colowick. 2010. PanLex and LEXTRACT: Trans-
lating all words of all languages of the world. In
Proceedings of the 23rd International Conference on
Computational Linguistics: Demonstrations, pages
37–40, Beijing, China.
Colin James Bannard. 2006. Acquiring Phrasal Lexi-
cons from Corpora. Ph.D. thesis, University of Ed-
inburgh.
Afsaneh Fazly, Paul Cook, and Suzanne Stevenson.
2009. Unsupervised type and token identification of
idiomatic expressions. Computational Linguistics,
35(1):61–103.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
USA.
Richard Forthergill and Timothy Baldwin. 2011.
Fleshing it out: A supervised approach to MWE-
token and MWE-type classification. In Proceedings
of the 5th International Joint Conference on Natural
Language Processing (IJCNLP 2011), pages 911–
919, Chiang Mai, Thailand.
David Kamholz, Jonathan Pool, and Susan Colowick.
2014. PanLex: Building a resource for panlingual
lexical translation. In Proceedings of the Ninth In-
ternational Conference on Language Resources and
Evaluation (LREC’14), pages 3145–3150, Reyk-
javik, Iceland.
Su Nam Kim and Timothy Baldwin. 2007. Detecting
compositionality of English verb-particle construc-
tions using semantic similarity. In Proceedings of
the 7th Meeting of the Pacific Association for Com-
putational Linguistics (PACLING 2007), pages 40–
48, Melbourne, Australia.
Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceedings of
the 5th Annual International Conference on Systems
Documentation, pages 24–26, Ontario, Canada.
Grace Muzny and Luke Zettlemoyer. 2013. Auto-
matic idiom identification in Wiktionary. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1417–
1421, Seattle, USA.
Siva Reddy, Diana McCarthy, and Suresh Manandhar.
2011. An empirical study on compositionality in
compound nouns. In Proceedings of IJCNLP, pages
210–218, Chiang Mai, Thailand.
Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-
take, and Dan Flickinger. 2002. Multiword ex-
pressions: A pain in the neck for NLP. In Pro-
ceedings of the 3rd International Conference on
Intelligent Text Processing Computational Linguis-
tics (CICLing-2002), pages 189–206, Mexico City,
Mexico.
Bahar Salehi and Paul Cook. 2013. Predicting
the compositionality of multiword expressions using
translations in multiple languages. In Proceedings
of the Second Joint Conference on Lexical and Com-
putational Semantics, volume 1, pages 266–275, At-
lanta, USA.
Bahar Salehi, Paul Cook, and Timothy Baldwin. 2014.
Using distributional similarity of multi-way transla-
tions to predict multiword expression composition-
ality. In Proceedings of the 14th Conference of the
EACL (EACL 2014), pages 472–481, Gothenburg,
Sweden.
</reference>
<page confidence="0.993486">
1797
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.460538">
<title confidence="0.99981">Detecting Non-compositional MWE Components using Wiktionary</title>
<author confidence="0.875245">Paul</author>
<author confidence="0.875245">Timothy</author>
<affiliation confidence="0.827703">Victoria Research of Computing and Information The University of</affiliation>
<address confidence="0.916427">Victoria 3010,</address>
<email confidence="0.987338">bsalehi@student.unimelb.edu.au,paulcook@unimelb.edu.au,tb@ldwin.net</email>
<abstract confidence="0.998938416666666">We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary. The approach makes use of the definitions, synonyms and translations in Wiktionary, and is applicable to any type of MWE in any language, assuming the MWE is contained in Wiktionary. Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Su Nam Kim</author>
</authors>
<title>Multiword expressions.</title>
<date>2009</date>
<booktitle>In Nitin Indurkhya</booktitle>
<editor>and Fred J. Damerau, editors,</editor>
<publisher>CRC Press,</publisher>
<location>Boca Raton, USA,</location>
<note>2nd edition.</note>
<contexts>
<context position="904" citStr="Baldwin and Kim, 2009" startWordPosition="121" endWordPosition="124">aulcook@unimelb.edu.au, tb@ldwin.net Abstract We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary. The approach makes use of the definitions, synonyms and translations in Wiktionary, and is applicable to any type of MWE in any language, assuming the MWE is contained in Wiktionary. Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods. 1 Introduction A multiword expression (MWE) is a combination of words with lexical, syntactic or semantic idiosyncrasy (Sag et al., 2002; Baldwin and Kim, 2009). An MWE is considered (semantically) “non-compositional” when its meaning is not predictable from the meaning of its components. Conversely, compositional MWEs are those whose meaning is predictable from the meaning of the components. Based on this definition, a component is compositional within an MWE, if its meaning is reflected in the meaning of the MWE, and it is non-compositional otherwise. Understanding which components are noncompositional within an MWE is important in NLP applications in which semantic information is required. For example, when searching for spelling bee, we may also </context>
</contexts>
<marker>Baldwin, Kim, 2009</marker>
<rawString>Timothy Baldwin and Su Nam Kim. 2009. Multiword expressions. In Nitin Indurkhya and Fred J. Damerau, editors, Handbook of Natural Language Processing. CRC Press, Boca Raton, USA, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="3253" citStr="Baldwin et al. (2003)" startWordPosition="485" endWordPosition="489"> between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar to those used in all-words word sense disambiguation (Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013). The prediction of the compositionality of MWE types has traditionally been couched as a binary classification task (compositional or non-compositional: Baldwin et al. (2003), Bannard (2006)), but more recent work has moved towards a regression setup, where the degree of the compositionality is predicted on a continuous scale (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). In either case, the modelling has been done either over the whole MWE (Reddy et al., 2011; Salehi and Cook, 2013), or relative to each component within the MWE (Baldwin et al., 2003; Bannard, 2006). In this paper, we focus on the binary classification of MWE types relative to each component of the 1792 Proceedings of the 2014 Conference on Empirical Methods in Natural Language </context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proceedings of the ACL-2003 Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89–96, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Jonathan Pool</author>
<author>Susan M Colowick</author>
</authors>
<title>PanLex and LEXTRACT: Translating all words of all languages of the world.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations,</booktitle>
<pages>37--40</pages>
<location>Beijing, China.</location>
<contexts>
<context position="4384" citStr="Baldwin et al., 2010" startWordPosition="676" endWordPosition="680"> of the 1792 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1792–1797, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics MWE. The work that is perhaps most closely related to this paper is that of Salehi and Cook (2013) and Salehi et al. (2014), who use translation data to predict the compositionality of a given MWE relative to each of its components, and then combine those scores to derive an overall compositionality score. In both cases, translations of the MWE and its components are sourced from PanLex (Baldwin et al., 2010; Kamholz et al., 2014), and if there is greater similarity between the translated components and MWE in a range of languages, the MWE is predicted to be more compositional. The basis of the similarity calculation is unsupervised, using either string similarity (Salehi and Cook, 2013) or distributional similarity (Salehi et al., 2014). However, the overall method is supervised, as training data is used to select the languages to aggregate scores across for a given MWE construction. To benchmark our method, we use two of the same datasets as these two papers, and repurpose the best-performing m</context>
</contexts>
<marker>Baldwin, Pool, Colowick, 2010</marker>
<rawString>Timothy Baldwin, Jonathan Pool, and Susan M. Colowick. 2010. PanLex and LEXTRACT: Translating all words of all languages of the world. In Proceedings of the 23rd International Conference on Computational Linguistics: Demonstrations, pages 37–40, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin James Bannard</author>
</authors>
<title>Acquiring Phrasal Lexicons from Corpora.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="3269" citStr="Bannard (2006)" startWordPosition="490" endWordPosition="491">l (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar to those used in all-words word sense disambiguation (Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013). The prediction of the compositionality of MWE types has traditionally been couched as a binary classification task (compositional or non-compositional: Baldwin et al. (2003), Bannard (2006)), but more recent work has moved towards a regression setup, where the degree of the compositionality is predicted on a continuous scale (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). In either case, the modelling has been done either over the whole MWE (Reddy et al., 2011; Salehi and Cook, 2013), or relative to each component within the MWE (Baldwin et al., 2003; Bannard, 2006). In this paper, we focus on the binary classification of MWE types relative to each component of the 1792 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNL</context>
<context position="11933" citStr="Bannard (2006)" startWordPosition="1925" endWordPosition="1927"> [0, 5] scale for both overall compositionality and the component-wise compositionality of each of the modifier and head noun. The sampling was random in an attempt to make the dataset balanced, with 48% of compositional English noun compounds, of which 51% are compositional in the first component and 60% are compositional in the second component. We generate discrete labels by discretising the component-wise compositionality scores based on the partitions [0, 2.5] and (2.5, 5]. On average, each NC in this dataset has 1.4 senses (definitions) in Wiktionary. The EVPC dataset was constructed by Bannard (2006), and manually annotated for compositionality on a binary scale for each of the head verb and particle. For the 160 EVPCs, 76% are verb-compositional and 48% are particlecompositional. On average, each EVPC in this dataset has 3.0 senses (definitions) in Wiktionary. 5 Experiments The baseline for each dataset takes the form of looking for a user-annotated idiom tag in the Wiktionary lexical entry for the MWE: if there is an idiomatic tag, both components are considered to be non-compositional; otherwise, both components are considered to be compositional. We expect this method to suffer from l</context>
</contexts>
<marker>Bannard, 2006</marker>
<rawString>Colin James Bannard. 2006. Acquiring Phrasal Lexicons from Corpora. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Unsupervised type and token identification of idiomatic expressions.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<contexts>
<context position="2304" citStr="Fazly et al., 2009" startWordPosition="344" endWordPosition="347">ther research or project in isolation, and for swan song, we are only going to be interested in documents which contain the phrase swan song, and not just swan or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or app</context>
</contexts>
<marker>Fazly, Cook, Stevenson, 2009</marker>
<rawString>Afsaneh Fazly, Paul Cook, and Suzanne Stevenson. 2009. Unsupervised type and token identification of idiomatic expressions. Computational Linguistics, 35(1):61–103.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, USA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Forthergill</author>
<author>Timothy Baldwin</author>
</authors>
<title>Fleshing it out: A supervised approach to MWEtoken and MWE-type classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011),</booktitle>
<pages>911--919</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="2335" citStr="Forthergill and Baldwin, 2011" startWordPosition="348" endWordPosition="351">ject in isolation, and for swan song, we are only going to be interested in documents which contain the phrase swan song, and not just swan or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constru</context>
</contexts>
<marker>Forthergill, Baldwin, 2011</marker>
<rawString>Richard Forthergill and Timothy Baldwin. 2011. Fleshing it out: A supervised approach to MWEtoken and MWE-type classification. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 911– 919, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kamholz</author>
<author>Jonathan Pool</author>
<author>Susan Colowick</author>
</authors>
<title>PanLex: Building a resource for panlingual lexical translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<pages>3145--3150</pages>
<location>Reykjavik, Iceland.</location>
<contexts>
<context position="4407" citStr="Kamholz et al., 2014" startWordPosition="681" endWordPosition="684">gs of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1792–1797, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics MWE. The work that is perhaps most closely related to this paper is that of Salehi and Cook (2013) and Salehi et al. (2014), who use translation data to predict the compositionality of a given MWE relative to each of its components, and then combine those scores to derive an overall compositionality score. In both cases, translations of the MWE and its components are sourced from PanLex (Baldwin et al., 2010; Kamholz et al., 2014), and if there is greater similarity between the translated components and MWE in a range of languages, the MWE is predicted to be more compositional. The basis of the similarity calculation is unsupervised, using either string similarity (Salehi and Cook, 2013) or distributional similarity (Salehi et al., 2014). However, the overall method is supervised, as training data is used to select the languages to aggregate scores across for a given MWE construction. To benchmark our method, we use two of the same datasets as these two papers, and repurpose the best-performing methods of Salehi and Co</context>
</contexts>
<marker>Kamholz, Pool, Colowick, 2014</marker>
<rawString>David Kamholz, Jonathan Pool, and Susan Colowick. 2014. PanLex: Building a resource for panlingual lexical translation. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 3145–3150, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Detecting compositionality of English verb-particle constructions using semantic similarity.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics (PACLING</booktitle>
<pages>40--48</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="2284" citStr="Kim and Baldwin, 2007" startWordPosition="340" endWordPosition="343">uments which contain either research or project in isolation, and for swan song, we are only going to be interested in documents which contain the phrase swan song, and not just swan or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and B</context>
</contexts>
<marker>Kim, Baldwin, 2007</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2007. Detecting compositionality of English verb-particle constructions using semantic similarity. In Proceedings of the 7th Meeting of the Pacific Association for Computational Linguistics (PACLING 2007), pages 40– 48, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th Annual International Conference on Systems Documentation,</booktitle>
<pages>24--26</pages>
<location>Ontario, Canada.</location>
<contexts>
<context position="5279" citStr="Lesk (1986)" startWordPosition="828" endWordPosition="829">) or distributional similarity (Salehi et al., 2014). However, the overall method is supervised, as training data is used to select the languages to aggregate scores across for a given MWE construction. To benchmark our method, we use two of the same datasets as these two papers, and repurpose the best-performing methods of Salehi and Cook (2013) and Salehi et al. (2014) for classification of the compositionality of each MWE component. 3 Methodology Our basic method relies on analysis of lexical overlap between the component words and the definitions of the MWE in Wiktionary, in the manner of Lesk (1986). That is, if a given component can be found in the definition, then it is inferred that the MWE carries the meaning of that component. For example, the Wiktionary definition of swimming pool is “An artificially constructed pool of water used for swimming”, suggesting that the MWE is compositional relative to both swimming and pool. If the MWE is not found in Wiktionary, we use Wikipedia as a backoff, and use the first paragraph of the (top-ranked) Wikipedia article as a proxy for the definition. As detailed below, we further extend the basic method to incorporate three types of information fo</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual International Conference on Systems Documentation, pages 24–26, Ontario, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Muzny</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Automatic idiom identification in Wiktionary.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1417--1421</pages>
<location>Seattle, USA.</location>
<contexts>
<context position="2365" citStr="Muzny and Zettlemoyer, 2013" startWordPosition="352" endWordPosition="355"> song, we are only going to be interested in documents which contain the phrase swan song, and not just swan or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar </context>
<context position="8097" citStr="Muzny and Zettlemoyer, 2013" startWordPosition="1284" endWordPosition="1287">wever, we find the component word clay in the definition for kaolin, as shown below. A fine clay, rich in kaolinite, used in ceramics, paper-making, etc. This method is compatible with the three definition-based similarity methods described above, and indicated by the +SYN suffix (e.g. FIRSTDEF+SYN is FIRSTDEF with synonymbased expansion). 3.3 Translations A third information source in Wiktionary that can be used to predict compositionality is sense-level translation data. Due to the user-generated nature of Wiktionary, the set of languages for which 1Although the recall of these tags is low (Muzny and Zettlemoyer, 2013). 2After removing function words, based on a stopword list. 1793 ENC EVPC WordNet 91.1% 87.5% Wiktionary 96.7% 96.2% Wiktionary+Wikipedia 100.0% 96.2% Table 1: Lexical coverage of WordNet, Wiktionary and Wiktionary+Wikipedia over our two datasets. translations are provided varies greatly across lexical entries. Our approach is to take whatever translations happen to exist in Wiktionary for a given MWE, and where there are translations in that language for the component of interest, use the LCSbased method of Salehi and Cook (2013) to measure the string similarity between the translation of the</context>
</contexts>
<marker>Muzny, Zettlemoyer, 2013</marker>
<rawString>Grace Muzny and Luke Zettlemoyer. 2013. Automatic idiom identification in Wiktionary. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1417– 1421, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siva Reddy</author>
<author>Diana McCarthy</author>
<author>Suresh Manandhar</author>
</authors>
<title>An empirical study on compositionality in compound nouns.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>210--218</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="2441" citStr="Reddy et al., 2011" startWordPosition="366" endWordPosition="369">ong, and not just swan or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar to those used in all-words word sense disambiguation (Forthergill and Baldwi</context>
<context position="11288" citStr="Reddy et al. (2011)" startWordPosition="1818" endWordPosition="1821">a third dataset of German noun compounds, in Salehi et al. (2014)): (1) 90 binary English noun compounds (ENCs, e.g. spelling bee or swimming pool); and (2) 160 English verb particle constructions (EVPCs, e.g. stand up and give away). Our results are not directly comparable with those of Salehi and Cook (2013) and Salehi et al. (2014), however, who evaluated in terms of a regression task, modelling the overall compositionality of the MWE. In our case, the task setup is a binary classification task relative to each of the two components of the MWE. The ENC dataset was originally constructed by Reddy et al. (2011), and annotated on a continuous [0, 5] scale for both overall compositionality and the component-wise compositionality of each of the modifier and head noun. The sampling was random in an attempt to make the dataset balanced, with 48% of compositional English noun compounds, of which 51% are compositional in the first component and 60% are compositional in the second component. We generate discrete labels by discretising the component-wise compositionality scores based on the partitions [0, 2.5] and (2.5, 5]. On average, each NC in this dataset has 1.4 senses (definitions) in Wiktionary. The E</context>
</contexts>
<marker>Reddy, McCarthy, Manandhar, 2011</marker>
<rawString>Siva Reddy, Diana McCarthy, and Suresh Manandhar. 2011. An empirical study on compositionality in compound nouns. In Proceedings of IJCNLP, pages 210–218, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2002),</booktitle>
<pages>189--206</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="880" citStr="Sag et al., 2002" startWordPosition="117" endWordPosition="120">.unimelb.edu.au, paulcook@unimelb.edu.au, tb@ldwin.net Abstract We propose a simple unsupervised approach to detecting non-compositional components in multiword expressions based on Wiktionary. The approach makes use of the definitions, synonyms and translations in Wiktionary, and is applicable to any type of MWE in any language, assuming the MWE is contained in Wiktionary. Our experiments show that the proposed approach achieves higher F-score than state-of-the-art methods. 1 Introduction A multiword expression (MWE) is a combination of words with lexical, syntactic or semantic idiosyncrasy (Sag et al., 2002; Baldwin and Kim, 2009). An MWE is considered (semantically) “non-compositional” when its meaning is not predictable from the meaning of its components. Conversely, compositional MWEs are those whose meaning is predictable from the meaning of the components. Based on this definition, a component is compositional within an MWE, if its meaning is reflected in the meaning of the MWE, and it is non-compositional otherwise. Understanding which components are noncompositional within an MWE is important in NLP applications in which semantic information is required. For example, when searching for sp</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proceedings of the 3rd International Conference on Intelligent Text Processing Computational Linguistics (CICLing-2002), pages 189–206, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bahar Salehi</author>
<author>Paul Cook</author>
</authors>
<title>Predicting the compositionality of multiword expressions using translations in multiple languages.</title>
<date>2013</date>
<booktitle>In Proceedings of the Second Joint Conference on Lexical and Computational Semantics,</booktitle>
<volume>1</volume>
<pages>266--275</pages>
<location>Atlanta, USA.</location>
<contexts>
<context position="2464" citStr="Salehi and Cook, 2013" startWordPosition="370" endWordPosition="373">an or song. In this paper, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar to those used in all-words word sense disambiguation (Forthergill and Baldwin, 2011; Muzny and Zett</context>
<context position="4071" citStr="Salehi and Cook (2013)" startWordPosition="623" endWordPosition="626">; Salehi et al., 2014). In either case, the modelling has been done either over the whole MWE (Reddy et al., 2011; Salehi and Cook, 2013), or relative to each component within the MWE (Baldwin et al., 2003; Bannard, 2006). In this paper, we focus on the binary classification of MWE types relative to each component of the 1792 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1792–1797, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics MWE. The work that is perhaps most closely related to this paper is that of Salehi and Cook (2013) and Salehi et al. (2014), who use translation data to predict the compositionality of a given MWE relative to each of its components, and then combine those scores to derive an overall compositionality score. In both cases, translations of the MWE and its components are sourced from PanLex (Baldwin et al., 2010; Kamholz et al., 2014), and if there is greater similarity between the translated components and MWE in a range of languages, the MWE is predicted to be more compositional. The basis of the similarity calculation is unsupervised, using either string similarity (Salehi and Cook, 2013) o</context>
<context position="8633" citStr="Salehi and Cook (2013)" startWordPosition="1369" endWordPosition="1372">ages for which 1Although the recall of these tags is low (Muzny and Zettlemoyer, 2013). 2After removing function words, based on a stopword list. 1793 ENC EVPC WordNet 91.1% 87.5% Wiktionary 96.7% 96.2% Wiktionary+Wikipedia 100.0% 96.2% Table 1: Lexical coverage of WordNet, Wiktionary and Wiktionary+Wikipedia over our two datasets. translations are provided varies greatly across lexical entries. Our approach is to take whatever translations happen to exist in Wiktionary for a given MWE, and where there are translations in that language for the component of interest, use the LCSbased method of Salehi and Cook (2013) to measure the string similarity between the translation of the MWE and the translation of the components. Unlike Salehi and Cook (2013), however, we do not use development data to select the optimal set of languages in a supervised manner, and instead simply take the average of the string similarity scores across the available languages. In the case of more than one translation in a given language, we use the maximum string similarity for each pairing of MWE and component translation. Unlike the definition and synonym-based approach, the translation-based approach will produce real rather th</context>
<context position="10629" citStr="Salehi and Cook (2013)" startWordPosition="1702" endWordPosition="1705"> verb particle constructions (EVPCs). In each case, we calculated the proportion of the dataset that is found in Wiktionary, Wiktionary+Wikipedia (where we back off to a Wikipedia document in the case that a MWE is not found in Wiktionary) and WordNet (Fellbaum, 1998). The results are found in Table 1, and indicate perfect coverage in Wiktionary+Wikipedia for the ENCs, and very high coverage for the EVPCs. In both cases, the coverage of WordNet is substantially lower, although still respectable, at around 90%. 4 Datasets As mentioned above, we evaluate our method over the same two datasets as Salehi and Cook (2013) (which were later used, in addition to a third dataset of German noun compounds, in Salehi et al. (2014)): (1) 90 binary English noun compounds (ENCs, e.g. spelling bee or swimming pool); and (2) 160 English verb particle constructions (EVPCs, e.g. stand up and give away). Our results are not directly comparable with those of Salehi and Cook (2013) and Salehi et al. (2014), however, who evaluated in terms of a regression task, modelling the overall compositionality of the MWE. In our case, the task setup is a binary classification task relative to each of the two components of the MWE. The EN</context>
<context position="13970" citStr="Salehi and Cook (2013)" startWordPosition="2247" endWordPosition="2250">ent (the modifier noun) and the second component (the head noun) reasons: first, the guidelines given to the annotators of our datasets might be different from what Wiktionary contributors assume to be an idiom. Second, the baseline method assumes that for any non-compositional MWE, all components must be equally non-compositional, despite the wealth of MWEs where one or more components are compositional (e.g. from the Wiktionary guidelines for idiom inclusion,3 computer chess, basketball player, telephone box). We also compare our method with: (1) “LCS”, the string similarity-based method of Salehi and Cook (2013), in which 54 languages are used; (2) “DS”, the monolingual distributional similarity method of Salehi et al. (2014); (3) “DS+DSL2”, the multilingual distributional similarity method of Salehi et al. (2014), including supervised language selection for a given dataset, based on crossvalidation; and (4) “LCS+DS+DSL2”, whereby the first three methods are combined using a supervised support vector regression model. In each case, the continuous output of the model is equal-width discretised to generate a binary classification. We additionally present results for the combination of each of the six m</context>
<context position="15490" citStr="Salehi and Cook (2013)" startWordPosition="2478" endWordPosition="2481">rability, the partitions are exactly the same as Salehi et al. (2014). Tables 2 and 3 provide the results when our proposed method for detecting non-compositionality is applied to the ENC and EVPC datasets, respectively. The inclusion of translation data was found to improve all of precision, recall and F-score across the board for all of the proposed methods. For reasons of space, results without translation data are therefore omitted from the paper. Overall, the simple unsupervised methods proposed in this paper are comparable with the unsupervised and supervised state-of-the-art methods of Salehi and Cook (2013) and Salehi et al. (2014), with ITAG achieving the highest F-score for the ENC dataset and for the verb components of the EVPC dataset. The inclusion of synonyms boosts results in most cases. When we combine each of our proposed methods with the string and distributional similarity methods of Salehi and Cook (2013) and Salehi et al. (2014), we see substantial improvements over the comparable combined method of “LCS+DS+DSL2” in most cases, demonstrating both the robustness of the proposed methods and their complementarity with the earlier methods. It is important to reinforce that the proposed </context>
</contexts>
<marker>Salehi, Cook, 2013</marker>
<rawString>Bahar Salehi and Paul Cook. 2013. Predicting the compositionality of multiword expressions using translations in multiple languages. In Proceedings of the Second Joint Conference on Lexical and Computational Semantics, volume 1, pages 266–275, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bahar Salehi</author>
<author>Paul Cook</author>
<author>Timothy Baldwin</author>
</authors>
<title>Using distributional similarity of multi-way translations to predict multiword expression compositionality.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the EACL (EACL 2014),</booktitle>
<pages>472--481</pages>
<location>Gothenburg,</location>
<contexts>
<context position="2486" citStr="Salehi et al., 2014" startWordPosition="374" endWordPosition="377">er, we propose an unsupervised approach based on Wikitionary for predicting which components of a given MWE have a compositional usage. Experiments over two widely-used datasets show that our approach outperforms stateof-the-art methods. 2 Related Work Previous studies which have considered MWE compositionality have focused on either the identification of non-compositional MWE token instances (Kim and Baldwin, 2007; Fazly et al., 2009; Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013), or the prediction of the compositionality of MWE types (Reddy et al., 2011; Salehi and Cook, 2013; Salehi et al., 2014). The identification of non-compositional MWE tokens is an important task when a word combination such as kick the bucket or saw logs is ambiguous between a compositional (generally non-MWE) and non-compositional MWE usage. Approaches have ranged from the unsupervised learning of type-level preferences (Fazly et al., 2009) to supervised methods specific to particular MWE constructions (Kim and Baldwin, 2007) or applicable across multiple constructions using features similar to those used in all-words word sense disambiguation (Forthergill and Baldwin, 2011; Muzny and Zettlemoyer, 2013). The pr</context>
<context position="4096" citStr="Salehi et al. (2014)" startWordPosition="628" endWordPosition="631">either case, the modelling has been done either over the whole MWE (Reddy et al., 2011; Salehi and Cook, 2013), or relative to each component within the MWE (Baldwin et al., 2003; Bannard, 2006). In this paper, we focus on the binary classification of MWE types relative to each component of the 1792 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1792–1797, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics MWE. The work that is perhaps most closely related to this paper is that of Salehi and Cook (2013) and Salehi et al. (2014), who use translation data to predict the compositionality of a given MWE relative to each of its components, and then combine those scores to derive an overall compositionality score. In both cases, translations of the MWE and its components are sourced from PanLex (Baldwin et al., 2010; Kamholz et al., 2014), and if there is greater similarity between the translated components and MWE in a range of languages, the MWE is predicted to be more compositional. The basis of the similarity calculation is unsupervised, using either string similarity (Salehi and Cook, 2013) or distributional similari</context>
<context position="10734" citStr="Salehi et al. (2014)" startWordPosition="1721" endWordPosition="1724">nd in Wiktionary, Wiktionary+Wikipedia (where we back off to a Wikipedia document in the case that a MWE is not found in Wiktionary) and WordNet (Fellbaum, 1998). The results are found in Table 1, and indicate perfect coverage in Wiktionary+Wikipedia for the ENCs, and very high coverage for the EVPCs. In both cases, the coverage of WordNet is substantially lower, although still respectable, at around 90%. 4 Datasets As mentioned above, we evaluate our method over the same two datasets as Salehi and Cook (2013) (which were later used, in addition to a third dataset of German noun compounds, in Salehi et al. (2014)): (1) 90 binary English noun compounds (ENCs, e.g. spelling bee or swimming pool); and (2) 160 English verb particle constructions (EVPCs, e.g. stand up and give away). Our results are not directly comparable with those of Salehi and Cook (2013) and Salehi et al. (2014), however, who evaluated in terms of a regression task, modelling the overall compositionality of the MWE. In our case, the task setup is a binary classification task relative to each of the two components of the MWE. The ENC dataset was originally constructed by Reddy et al. (2011), and annotated on a continuous [0, 5] scale f</context>
<context position="14086" citStr="Salehi et al. (2014)" startWordPosition="2265" endWordPosition="2268">s of our datasets might be different from what Wiktionary contributors assume to be an idiom. Second, the baseline method assumes that for any non-compositional MWE, all components must be equally non-compositional, despite the wealth of MWEs where one or more components are compositional (e.g. from the Wiktionary guidelines for idiom inclusion,3 computer chess, basketball player, telephone box). We also compare our method with: (1) “LCS”, the string similarity-based method of Salehi and Cook (2013), in which 54 languages are used; (2) “DS”, the monolingual distributional similarity method of Salehi et al. (2014); (3) “DS+DSL2”, the multilingual distributional similarity method of Salehi et al. (2014), including supervised language selection for a given dataset, based on crossvalidation; and (4) “LCS+DS+DSL2”, whereby the first three methods are combined using a supervised support vector regression model. In each case, the continuous output of the model is equal-width discretised to generate a binary classification. We additionally present results for the combination of each of the six methods proposed in this paper with LCS, DS and DSL2, using a linear-kernel support vector machine (represented with </context>
<context position="15515" citStr="Salehi et al. (2014)" startWordPosition="2483" endWordPosition="2486">e exactly the same as Salehi et al. (2014). Tables 2 and 3 provide the results when our proposed method for detecting non-compositionality is applied to the ENC and EVPC datasets, respectively. The inclusion of translation data was found to improve all of precision, recall and F-score across the board for all of the proposed methods. For reasons of space, results without translation data are therefore omitted from the paper. Overall, the simple unsupervised methods proposed in this paper are comparable with the unsupervised and supervised state-of-the-art methods of Salehi and Cook (2013) and Salehi et al. (2014), with ITAG achieving the highest F-score for the ENC dataset and for the verb components of the EVPC dataset. The inclusion of synonyms boosts results in most cases. When we combine each of our proposed methods with the string and distributional similarity methods of Salehi and Cook (2013) and Salehi et al. (2014), we see substantial improvements over the comparable combined method of “LCS+DS+DSL2” in most cases, demonstrating both the robustness of the proposed methods and their complementarity with the earlier methods. It is important to reinforce that the proposed methods make no language-</context>
</contexts>
<marker>Salehi, Cook, Baldwin, 2014</marker>
<rawString>Bahar Salehi, Paul Cook, and Timothy Baldwin. 2014. Using distributional similarity of multi-way translations to predict multiword expression compositionality. In Proceedings of the 14th Conference of the EACL (EACL 2014), pages 472–481, Gothenburg, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>