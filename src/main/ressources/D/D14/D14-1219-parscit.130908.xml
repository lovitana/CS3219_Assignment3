<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.985592">
Discriminative Reranking of Discourse Parses Using Tree Kernels
</title>
<author confidence="0.871238">
Shafiq Joty and Alessandro Moschitti
</author>
<affiliation confidence="0.884575">
ALT Research Group
Qatar Computing Research Institute
</affiliation>
<email confidence="0.983811">
{sjoty,amoschitti}@qf.org.qa
</email>
<sectionHeader confidence="0.993454" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999755">
In this paper, we present a discrimina-
tive approach for reranking discourse trees
generated by an existing probabilistic dis-
course parser. The reranker relies on tree
kernels (TKs) to capture the global depen-
dencies between discourse units in a tree.
In particular, we design new computa-
tional structures of discourse trees, which
combined with standard TKs, originate
novel discourse TKs. The empirical evalu-
ation shows that our reranker can improve
the state-of-the-art sentence-level parsing
accuracy from 79.77% to 82.15%, a rel-
ative error reduction of 11.8%, which in
turn pushes the state-of-the-art document-
level accuracy from 55.8% to 57.3%.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999963032258065">
Clauses and sentences in a well-written text are
interrelated and exhibit a coherence structure.
Rhetorical Structure Theory (RST) (Mann and
Thompson, 1988) represents the coherence struc-
ture of a text by a labeled tree, called discourse
tree (DT) as shown in Figure 1. The leaves cor-
respond to contiguous clause-like units called ele-
mentary discourse units (EDUs). Adjacent EDUs
and larger discourse units are hierarchically con-
nected by coherence relations (e.g., ELABORA-
TION, CAUSE). Discourse units connected by a re-
lation are further distinguished depending on their
relative importance: nuclei are the core parts of the
relation while satellites are the supportive ones.
Conventionally, discourse analysis in RST in-
volves two subtasks: (i) discourse segmentation:
breaking the text into a sequence of EDUs, and
(ii) discourse parsing: linking the discourse units
to form a labeled tree. Despite the fact that dis-
course analysis is central to many NLP appli-
cations, the state-of-the-art document-level dis-
course parser (Joty et al., 2013) has an f-score
of only 55.83% using manual discourse segmen-
tation on the RST Discourse Treebank (RST-DT).
Although recent work has proposed rich lin-
guistic features (Feng and Hirst, 2012) and pow-
erful parsing models (Joty et al., 2012), discourse
parsing remains a hard task, partly because these
approaches do not consider global features and
long range structural dependencies between DT
constituents. For example, consider the human-
annotated DT (Figure 1a) and the DT generated by
the discourse parser of Joty et al. (2013) (Figure
1b) for the same text. The parser makes a mistake
in finding the right structure: it considers only e3
as the text to be attributed to e2, where all the text
spans from e3 to e6 (linked by CAUSE and ELAB-
ORATION) compose the statement to be attributed.
Such errors occur because existing systems do not
encode long range dependencies between DT con-
stituents such as those between e3 and e4−6.
Reranking models can make the global struc-
tural information available to the system as fol-
lows: first, a base parser produces several DT
hypotheses; and then a classifier exploits the en-
tire information in each hypothesis, e.g., the com-
plete DT with its dependencies, for selecting the
best DT. Designing features capturing such global
properties is however not trivial as it requires the
selection of important DT fragments. This means
selecting subtree patterns from an exponential fea-
ture space. An alternative approach is to implicitly
generate the whole feature space using tree kernels
(TKs) (Collins and Duffy, 2002; Moschitti, 2006).
In this paper, we present reranking models for
discourse parsing based on Support Vector Ma-
chines (SVMs) and TKs. The latter allows us
to represent structured data using the substructure
space thus capturing structural dependencies be-
tween DT constituents, which is essential for ef-
fective discourse parsing. Specifically, we made
the following contributions. First, we extend the
</bodyText>
<page confidence="0.96771">
2049
</page>
<note confidence="0.9762765">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2049–2060,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.997499818181818">
e e
5 6
(a) A human-annotated discourse tree.
Background
e e
5 6
(b) A discourse tree generated by Joty et al. (2013).
Attribution
e3
Cause
Elaboration
e4
Elaboration
e1
e2
Topic-Comment
Elaboration
Attribution
e1
Cause
e2 e3 e4
Elaboration
</figure>
<figureCaption confidence="0.99864075">
Figure 1: Example of human-annotated and system-generated discourse trees for the text [what’s more,]e, [he believes]e,
[seasonal swings in the auto industry this year aren’t occurring at the same time in the past,]e,, [because ofproduction and pric-
ing differences]e, [that are curbing the accuracy of seasonal adjustments]e5] [built into the employment data.]e6 Horizontal
lines indicate text segments; satellites are connected to their nuclei by curved arrows.
</figureCaption>
<bodyText confidence="0.999603972222222">
existing discourse parser1 (Joty et al., 2013) to
produce a list of k most probable parses for each
input text, with associated probabilities that define
the initial ranking.
Second, we define a set of discourse tree ker-
nels (DISCTK) based on the functional composi-
tion of standard TKs with structures representing
the properties of DTs. DISCTK can be used for
any classification task involving discourse trees.
Third, we use DISCTK to define kernels for
reranking and use them in SVMs. Our rerankers
can exploit the complete DT structure using TKs.
They can ascertain if portions of a DT are compat-
ible, incompatible or simply not likely to coexist,
since each substructure is an exploitable feature.
In other words, problematic DTs are expected to
be ranked lower by our reranker.
Finally, we investigate the potential of our ap-
proach by computing the oracle f-scores for both
document- and sentence-level discourse parsing.
However, as demonstrated later in Section 6, for
document-level parsing, the top k parses often
miss the best parse. For example, the oracle f-
scores for 5- and 20-best document-level parsing
are only 56.91% and 57.65%, respectively. Thus
the scope of improvement for the reranker is rather
narrow at the document level. On the other hand,
the oracle f-score for 5-best sentence-level dis-
course parsing is 88.09%, where the base parser
(i.e., 1-best) has an oracle f-score of 79.77%.
Therefore, in this paper we address the following
two questions: (i) how far can a reranker improve
the parsing accuracy at the sentence level? and
(ii) how far can this improvement, if at all, push
the (combined) document-level parsing accuracy?
To this end, our comparative experiments on
</bodyText>
<footnote confidence="0.984898">
1Available from http://alt.qcri.org/tools/
</footnote>
<bodyText confidence="0.996380333333333">
RST-DT show that the sentence-level reranker can
improve the f-score of the state-of-the-art from
79.77% to 82.15%, corresponding to a relative
error reduction of 11.8%, which in turn pushes
the state-of-the-art document-level f-score from
55.8% to 57.3%, an error reduction of 3.4%.
In the rest of the paper, after introducing the TK
technology in Section 2, we illustrate our novel
structures, and how they lead to the design of
novel DISCTKs in Section 3. We present the k-
best discourse parser in Section 4. In Section 5, we
describe our reranking approach using DISCTKs.
We report our experiments in Section 6. We briefly
overview the related work in Section 7, and finally,
we summarize our contributions in Section 8.
</bodyText>
<sectionHeader confidence="0.993176" genericHeader="introduction">
2 Kernels for Structural Representation
</sectionHeader>
<bodyText confidence="0.999728866666667">
Tree kernels (Collins and Duffy, 2002; Shawe-
Taylor and Cristianini, 2004; Moschitti, 2006) are
a viable alternative for representing arbitrary sub-
tree structures in learning algorithms. Their ba-
sic idea is that kernel-based learning algorithms,
e.g., SVMs or perceptron, only need the scalar
product between the feature vectors representing
the data instances to learn and classify; and kernel
functions compute such scalar products in an effi-
cient way. In the following subsections, we briefly
describe the kernel machines and three types of
tree kernels (TKs), which efficiently compute the
scalar product in the subtree space, where the vec-
tor components are all possible substructures of
the corresponding trees.
</bodyText>
<subsectionHeader confidence="0.976043">
2.1 Kernel Machines
</subsectionHeader>
<bodyText confidence="0.967171666666667">
Kernel Machines (Cortes and Vapnik, 1995), e.g.,
SVMs, perform binary classification by learning
a hyperplane H(x) = w� · x� + b = 0, where
</bodyText>
<page confidence="0.89662">
2050
</page>
<figure confidence="0.999922121212121">
c e
b
a
a
g b g
c e
c e
g
b
c e
b
a
S
c e
b
a
a
S b S
c e
S a
b S
c e
c e
b
a
b
e
a
c e
b
a
g
g g
</figure>
<figureCaption confidence="0.675026">
Figure 2: A tree with its STK subtrees; STKb also includes
</figureCaption>
<figure confidence="0.944753375">
leaves as features.
x~ ∈ Rn is the feature vector representation of an
see u . a pr
object o ∈ O to be classified and w~ ∈ Rn and
b ∈ R are parameters learned from the training
data. One can train such machines in the dual
bset Tree A subset tree is a subtree for which the following constrin is sa
space by rewriting the model parameter w~ as a lin-
</figure>
<figureCaption confidence="0.815861">
ed: eiher all of the childre of node belong to the subset tr or ne of hem
</figureCaption>
<bodyText confidence="0.687754">
ear combination of training examples, i.e., w~ =
</bodyText>
<equation confidence="0.85449825">
e P rea u o n b std y co he
t subsettres were defind f eurig the similaty f se trees in ntur
i=1..l yiαi~xi, where yi is equal to 1 for positive
guage applications In that ontet a node alon with all of its cildrn rpree
</equation>
<bodyText confidence="0.926161272727273">
examples and −1 for negative examples, αi ∈ R+
ramm produon igu
and ~xi∀i ∈ {1, .., l} are the training instances.
giv an eampl of a tree aong wth some of
Then, we can use the data object oi ∈ O directly
in the hyperplane equation considering their map-
ping function φ : O → Rn, as follows: H(o) =
P i=1..lyiαi~xi ·~x+b = P i=1..lyiαiφ(oi)·φ(o)+
b = P i=1..lyiαiK(oi, o) + b, where the product
K(oi, o) = hφ(oi) · φ(o)i is the kernel function
(e.g., TK) associated with the mapping φ.
</bodyText>
<subsectionHeader confidence="0.99848">
2.2 Tree Kernels
</subsectionHeader>
<bodyText confidence="0.9935045">
Convolution TKs compute the number of com-
mon tree fragments between two trees T1 and T2
without explicitly considering the whole fragment
space. A TK function over T1 and T2 is defined as:
</bodyText>
<equation confidence="0.908006">
TK(T1,T2) = P Pn2∈NT2 Δ(n1,n2),
n1∈NT1
</equation>
<bodyText confidence="0.9920765">
where NT1 and NT2 are the sets of the nodes of
T1 and T2, respectively, and Δ(n1, n2) is equal
to the number of common fragments rooted in
the n1 and n2 nodes.2 The computation of Δ
function depends on the shape of fragments,
conversely, a different Δ determines the richness
of the kernel space and thus different tree kernels.
In the following, we briefly describe two existing
and well-known tree kernels. Please see several
tutorials on kernels (Moschitti, 2013; Moschitti,
2012; Moschitti, 2010) for more details.3
Syntactic Tree Kernels (STK) produce fragments
such that each of their nodes includes all or none
of its children. Figure 2 shows a tree T and its
three fragments (do not consider the single nodes)
in the STK space on the left and right of the ar-
</bodyText>
<footnote confidence="0.4973605">
2To get a similarity score between 0 and 1, it is
common to apply a normalization in the kernel space,
</footnote>
<equation confidence="0.947876">
T K(T1,T2)
i.e.
S
</equation>
<figureCaption confidence="0.990931">
Figure 3: A tree with its PTK fragments.
</figureCaption>
<bodyText confidence="0.890397388888889">
row, respectively. STK(T ,T ) counts the number
tree. Te outdegree of a nod r an ordered tree rresponds t the number of its
d d
of common fragments, which in this case is the
as te number of noes comprising the th from v to v When not spefied the
number of subtrees of T , i.e., three. In the figure,
node with repect to the depth is compue, is the root
we also show three single nodes, c, e, and g, i.e.,
A tree can be decomposed in many types of substruure
the leaves of T, which are computed by a vari-
se u ree T , spon
ant of the kernel, that we call STKb. The com-
hich fo tr A bte oted nod v ill be idicate ith t hil
putational complexity of STK is O(|NT1||NT2|),
subtree rooted a a generic node v wl be ndicte by (v) When t s used in a
but the average running time tends to be linear
contet whe a node is exected, t refers to the rot node o the ubtr t The
e btees ofe be inatd y r
</bodyText>
<equation confidence="0.6619595">
(i.e. O(|NT1 |+ |NT2|)) for syntactic trees (Mos-
may rer to specfic ty subtrees Figure 2 gives an examp of a tre together
with its subtrees. Var
chitti, 2006).
</equation>
<bodyText confidence="0.993083571428571">
Partial Tree Kernel (PTK) generates a richer set
of tree fragments. Given a target tree T, PTK
can generate any subset of connected nodes of T,
whose edges are in T. For example, Figure 3
shows a tree with its nine fragments including all
single nodes (i.e., the leaves of T). PTK is more
general than STK as its fragments can include any
subsequence of children of a target node. The time
complexity of PTK is O(pρ2|NT1||NT2|), where
p is the largest subsequence of children that one
wants to consider and ρ is the maximal out-degree
observed in the two trees. However, the average
running time again tends to be linear for syntactic
trees (Moschitti, 2006).
</bodyText>
<sectionHeader confidence="0.975915" genericHeader="method">
3 Discourse Tree Kernels (DISCTK)
</sectionHeader>
<bodyText confidence="0.999626277777778">
Engineering features that can capture the depen-
dencies between DT constituents is a difficult task.
In principle, any dependency between words, rela-
tions and structures (see Figure 1) can be an im-
portant feature for discourse parsing. This may
lead to an exponential number of features, which
makes the feature engineering process very hard.
The standard TKs described in the previous sec-
tion serve as a viable option to get useful sub-
tree features automatically. However, the defini-
tion of the input to a TK, i.e., the tree represent-
ing a training instance, is extremely important as
it implicitly affects the subtree space generated by
the TK, where the target learning task is carried
out. This can be shown as follows. Let φM()
be a mapping from linguistic objects oi, e.g., a
discourse parse, to a meaningful tree Ti, and let
φTK() be a mapping into a tree kernel space us-
</bodyText>
<equation confidence="0.395669">
√T K(T1,T1)×TK(T2,T2).
</equation>
<footnote confidence="0.9700505">
3Tutorials notes available at http://disi.unitn.
it/moschitti/
</footnote>
<page confidence="0.978789">
2051
</page>
<figure confidence="0.999944">
(a) JRN
(b) SRN
</figure>
<figureCaption confidence="0.999968">
Figure 4: DISCTK trees: (a) Joint Relation-Nucleus (JRN), and (b) Split Relation Nucleus (SRN).
</figureCaption>
<bodyText confidence="0.894498416666667">
ing one of the TKs described in Section 2.2, i.e.,
TK(T1,T2) = OTK(T1) · OTK(T2). If we apply
TK to the objects oi transformed by OM(), we
obtain TK(OM(o1), OM(o2)) = OTK(OM(o1)) ·
OTK(OM(o2))= (OTK◦OM)(o1)·(OTK◦OM)(o2)
= DiscTK(o1, o2), which is a new kernel4 in-
duced by the mapping ODiscTK = (OTK ◦ OM).
We define two different mappings OM to trans-
form the discourse parses generated by the base
parser into two different tree structures: (i) the
Joint Relation-Nucleus tree (JRN), and (ii) the
Split Relation Nucleus tree (SRN).
</bodyText>
<subsectionHeader confidence="0.998418">
3.1 Joint Relation-Nucleus Tree (JRN)
</subsectionHeader>
<bodyText confidence="0.999646941176471">
As shown in Figure 4a, JRN is a direct mapping
of the parser output, where the nuclearity statuses
(i.e., satellite or nucleus) of the connecting nodes
are attached to the relation labels.5 For example,
the root BACKGROUNDSatellite−Nucleus in Figure
4a denotes a Background relation between a satel-
lite discourse unit on the left and a nucleus unit on
the right. Text spans (i.e., EDUs) are represented
as sequences of Part-of-Speech (POS) tags con-
nected to the associated words, and are grouped
under dummy SPAN nodes. We experiment with
two lexical variations of the trees: (i) All includes
all the words in the EDU, and (ii) Bigram includes
only the first and last two words in the EDU.
When JRN is used with the STK kernel, an ex-
ponential number of fragments are generated. For
example, the upper row of Figure 5 shows two
</bodyText>
<footnote confidence="0.7366178">
4People interested in algorithms may like it more design-
ing a complex algorithm to compute (φTK ◦ φm). However,
the design of φm is conceptually equivalent and more effec-
tive from an engineering viewpoint.
5This is a common standard followed by the parsers.
</footnote>
<bodyText confidence="0.999862916666667">
smallest (atomic) fragments and one subtree com-
posed of two atomic fragments. Note that much
larger structures encoding long range dependen-
cies are also part of the feature space. These frag-
ments can reveal if the discourse units are orga-
nized in a compatible way, and help the reranker
to detect the kind of errors shown earlier in Fig-
ure 1b. However, one problem with JRN repre-
sentation is that since the relation nodes are com-
posed of three different labels, the generated sub-
trees tend to be sparse. In the following, we de-
scribe SRN that attempts to solve this issue.
</bodyText>
<subsectionHeader confidence="0.998258">
3.2 Split Relation Nucleus Tree (SRN)
</subsectionHeader>
<bodyText confidence="0.981721833333333">
SRN is not very different from JRN as shown in
Figure 4b. The only difference is that instead of
attaching the nuclearity statuses to the relation la-
bels, in this representation we assign them to their
respective discourse units. When STK kernel is
applied to SRN it again produces an exponential
number of fragments. For example, the lower row
of Figure 5 shows two atomic fragments and one
subtree composed of two atomic fragments. Com-
paring the two examples in Figure 5, it is easy
to understand that the space of subtrees extracted
from SRN is less sparse than that of JRN.
Note that, as described in Secion 2.2, when the
PTK kernel is applied to JRN and SRN trees, it can
generate a richer feature space, e.g., features that
are paths containing relation labels (e.g., BACK-
GROUND - CAUSE - ELABORATION or ATTRIBU-
TION - CAUSE - ELABORATION).
</bodyText>
<sectionHeader confidence="0.951985" genericHeader="method">
4 Generation of k-best Discourse Parses
</sectionHeader>
<bodyText confidence="0.998964">
In this section we describe the 1-best discourse
parser of Joty et al. (2013), and how we extend
</bodyText>
<page confidence="0.994249">
2052
</page>
<figureCaption confidence="0.998178">
Figure 5: Fragments from JRN in Figure 4a (upper row) and SRN in Figure 4b (lower row).
</figureCaption>
<bodyText confidence="0.999541325581396">
it to k-best discourse parsing.
Joty et al. (2013) decompose the problem of
document-level discourse parsing into two stages
as shown in Figure 6. In the first stage, the intra-
sentential discourse parser produces discourse
subtrees for the individual sentences in a docu-
ment. Then the multi-sentential parser combines
the sentence-level subtrees and produces a DT for
the document. Both parsers have the same two
components: a parsing model and a parsing al-
gorithm. The parsing model explores the search
space of possible DTs and assigns a probability to
every possible DT. Then the parsing algorithm se-
lects the most probable DT(s). While two separate
parsing models are employed for intra- and multi-
sentential parsing, the same parsing algorithm is
used in both parsing conditions. The two-stage
parsing exploits the fact that sentence boundaries
correlate very well with discourse boundaries. For
example, more than 95% of the sentences in RST-
DT have a well-formed discourse subtree in the
full document-level discourse tree.
The choice of using two separate models for
intra- and multi-sentential parsing is well justified
for the following two reasons: (i) it has been ob-
served that discourse relations have different dis-
tributions in the two parsing scenarios, and (ii) the
models could independently pick their own infor-
mative feature sets. The parsing model used for
intra-sentential parsing is a Dynamic Conditional
Random Field (DCRF) (Sutton et al., 2007) shown
in Figure 7. The observed nodes Uj at the bottom
layer represent the discourse units at a certain level
of the DT; the binary nodes 5j at the middle layer
predict whether two adjacent units Uj_1 and Uj
should be connected or not; and the multi-class
nodes Rj at the top layer predict the discourse
relation between Uj_1 and Uj. Notice that the
model represents the structure and the label of a
DT constituent jointly, and captures the sequential
dependencies between the DT constituents. Since
the chain-structured DCRF model does not scale
up to multi-sentential parsing of long documents,
</bodyText>
<figureCaption confidence="0.999683">
Figure 6: The two-stage document-level discourse parser
proposed by Joty et al. (2013).
Figure 7: The intra-sentential parsing model.
</figureCaption>
<bodyText confidence="0.991979590909091">
the multi-sentential parsing model is a CRF which
breaks the chain structure of the DCRF model.
The parsing models are applied recursively at
different levels of the DT in their respective pars-
ing scenarios (i.e., intra- and multi-sentential),
and the probabilities of all possible DT con-
stituents are obtained by computing the posterior
marginals over the relation-structure pairs (i.e.,
P(Rj, 5j=1|U1, · · · , Ut, O), where O are model
parameters). These probabilities are then used in
a CKY-like probabilistic parsing algorithm to find
the globally optimal DT for the given text.
Let Ub x and Uex denote the beginning and
end EDU Ids of a discourse unit Ux, and
R[Ubi , Uem, Uej ] refers to a coherence relation
R that holds between the discourse unit con-
taining EDUs Ubi through Uem and the unit
containing EDUs Uem+1 through Uej . Given n
discourse units, the parsing algorithm uses the
upper-triangular portion of the nxn dynamic
programming table A, where cell A[i, j] (for
i &lt; j) stores:
</bodyText>
<equation confidence="0.874441">
A[i, j] = P(r*[Ubi , Uem∗, Uej ]), where
(m*, r*) = argmax
i&lt;m&lt;j ; R
A[i, m] x A[m + 1, j] (1)
</equation>
<figure confidence="0.964999948717949">
Intra-sentential parser Multi-sentential parser
Sentences
segmented
into EDUs
Algorithm
Model
Algorithm
Model
Document-level
discourse tree
U1
U U U U U
2 3 j t-1 t
S S S S S
2 3 j t-1 t
R R R R R
2 3 j t-1 t
Unit
sequence
at level i
Structure
sequence
Relation
sequence
P(R[Ubi , Uem, Uej ])x
2053
e1 e2
r1
r2
e3 e4
r4
r1 r3 r2
r2 r3
r4
C
B
1 1 2
2 2
3
</figure>
<figureCaption confidence="0.999979">
Figure 8: The B and C dynamic programming tables (left), and the corresponding discourse tree (right).
</figureCaption>
<bodyText confidence="0.999967255813953">
In addition to A, which stores the probability of
the most probable constituents of a DT, the pars-
ing algorithm also simultaneously maintains two
other tables B and C for storing the best structure
(i.e., Uem∗) and the relations (i.e., r∗) of the corre-
sponding DT constituents, respectively. For exam-
ple, given 4 EDUs e1 · · · e4, the B and C tables at
the left side in Figure 8 together represent the DT
shown at the right. More specifically, to generate
the DT, we first look at the top-right entries in the
two tables, and find B[1, 4] = 2 and C[1, 4] = r2,
which specify that the two discourse units e1:2 and
e3:4 should be connected by the relation r2 (the
root in the DT). Then, we see how EDUs e1 and
e2 should be connected by looking at the entries
B[1,2] and C[1,2], and find B[1,2] = 1 and
C[1, 2] = r1, which indicates that these two units
should be connected by the relation r1 (the left
pre-terminal). Finally, to see how EDUs e3 and e4
should be linked, we look at the entries B[3, 4] and
C[3, 4], which tell us that they should be linked by
the relation r4 (the right pre-terminal).
It is straight-forward to generalize the above al-
gorithm to produce k most probable DTs. When
filling up the dynamic programming tables, rather
than storing a single best parse for each subtree,
we store and keep track of k-best candidates si-
multaneously. More specifically, each cell in the
dynamic programming tables (i.e., A, B and C)
should now contain k entries (sorted by their prob-
abilities), and for each such entry there should be a
back-pointer that keeps track of the decoding path.
The algorithm works in polynomial time. For
n discourse units and M number of relations, the
1-best parsing algorithm has a time complexity of
O(n3M) and a space complexity of O(n2), where
the k-best version has a time and space complexi-
ties of O(n3Mk2 log k) and O(n2k), respectively.
There are cleverer ways to reduce the complexity
(e.g., see (Huang and Chiang, 2005) for three such
ways). However, since the efficiency of the algo-
rithm did not limit us to produce k-best parses for
larger k, it was not a priority in this work.
</bodyText>
<sectionHeader confidence="0.997957" genericHeader="method">
5 Kernels for Reranking Discourse Trees
</sectionHeader>
<bodyText confidence="0.999696">
In Section 3, we described DISCTK, which essen-
tially can be used for any classification task involv-
ing discourse trees. For example, given a DT, we
can use DISCTK to classify it as correct vs. in-
correct. However, such classification is not com-
pletely aligned to our purpose, since our goal is
to select the best (i.e., the most correct) DT from
k candidate DTs; i.e., a ranking task. We adopt
a preference reranking technique as described in
(Moschitti et al., 2006; Dinarelli et al., 2011).
</bodyText>
<subsectionHeader confidence="0.99846">
5.1 Preference Reranker
</subsectionHeader>
<bodyText confidence="0.999963777777778">
Preference reranking (PR) uses a classifier C of
pairs of hypotheses (hi, hj), which decides if hi
(i.e., a candidate DT in our case) is better than
hj. We generate positive and negative examples to
train the classifier using the following approach.
The pairs (h1, hi) constitute positive examples,
where h1 has the highest f-score accuracy on the
Relation metric (to be described in Section 6) with
respect to the gold standard among the candidate
hypotheses, and vice versa, (hi, h1) are considered
as negative examples. At test time, C classifies all
pairs (hi, hj) generated from the k-best hypothe-
ses. A positive decision is a vote for hi, and a neg-
ative decision is a vote for hj. Also, the classifier
score can be used as a weighted vote. Hypotheses
are then ranked according to the number (sum) of
the (weighted) votes they get.6
We build our reranker using simple SVMs.7
</bodyText>
<footnote confidence="0.552839857142857">
6As shown by Collins and Duffy (2002), only the classifi-
cation of k hypotheses (paired with the empty one) is needed
in practice, thus the complexity is only O(k).
7Structural kernels, e.g., TKs, cannot be used in more ad-
vanced algorithms working in structured output spaces, e.g.,
SVMstruct. Indeed, to our knowledge, no one could suc-
cessfully find a general and exact solution for the argmax
equation, typically part of such advanced models, when struc-
tural kernels are used. Some approximate solutions for sim-
ple kernels, e.g., polynomial or gaussian kernels, are given in
(Joachims and Yu, 2009), whereas (Severyn and Moschitti,
2011; Severyn and Moschitti, 2012) provide solutions for
using the cutting-plane algorithm (which requires argmax
computation) with structural kernels but in binary SVMs.
</footnote>
<page confidence="0.993686">
2054
</page>
<bodyText confidence="0.999956666666667">
Since in our problem a pair of hypotheses (hi, hj)
constitutes a data instance, we now need to define
the kernel between the pairs. However, notice that
DISCTK only works on a single pair.
Considering that our task is to decide whether
hi is better than hj, it can be convenient to
represent the pairs in terms of differences be-
tween the vectors of the two hypotheses, i.e.,
φK(hi) − φK(hj), where K (i.e., DISCTK) is de-
fined between two hypotheses (not on two pairs
of hypotheses). More specifically, to compute
this difference implicitly, we can use the follow-
ing kernel summation: PK((h1, h2), (h01, h02)) =
(φK(h1) − φK(h2)) ° (φK(h01) − φK(h02)) =
K(h1, h01)+K(h2, h02)−K(h1, h02)−K(h2, h01).
In general, Preference Kernel (PK) works well
because it removes many identical features by tak-
ing differences between two huge implicit TK-
vectors. In our reranking framework, we also in-
clude traditional feature vectors in addition to the
trees. Therefore, each hypothesis h is represented
as a tuple (T,~v) composed of a tree T and a fea-
ture vector ~v. We then define a structural kernel
(i.e., similarity) between two hypotheses h and
h0 as follows: K(h, h0) = DiscTK(T, T0) +
FV (~v,~v0), where DISCTK maps the DTs T and
T0 to JRN or SRN and then applies STK, STKb or
PTK defined in Sections 2.2 and 3, and FV is a
standard kernel, e.g., linear, polynomial, gaussian,
etc., over feature vectors (see next section).
</bodyText>
<subsectionHeader confidence="0.996755">
5.2 Feature Vectors
</subsectionHeader>
<bodyText confidence="0.999814185185185">
We also investigate the impact of traditional
(i.e., not subtree) features for reranking discourse
parses. Our feature vector comprises two types of
features that capture global properties of the DTs.
Basic Features. This set includes eight global
features. The first two are the probability and
the (inverse) rank of the DT given by the base
parser. These two features are expected to help
the reranker to perform at least as good as the base
parser. The other six features encode the structural
properties of the DT, which include depth of the
DT, number of nodes connecting two EDUs (i.e.,
SPANs in Figure 4), number of nodes connecting
two relational nodes, number of nodes connecting
a relational node and an EDU, number of nodes
that connects a relational node as left child and an
EDU as right child, and vice versa.
Relation Features. We encode the relations in
the DT as bag-of-relations (i.e., frequency count).
This will allow us to assess the impact of a flat rep-
resentation of the DT. Note that more important
relational features would be the subtree patterns
extracted from the DT. However, they are already
generated by TKs in a simpler way. See (Pighin
and Moschitti, 2009; Pighin and Moschitti, 2010)
for a way to extract the most relevant features from
a model learned in the kernel space.
</bodyText>
<sectionHeader confidence="0.999495" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9999356">
Our experiments aim to show that reranking of
discourse parses is a promising research direction,
which can improve the state-of-the-art. To achieve
this, we (i) compute the oracle accuracy of the k-
best parser, (ii) test different kernels for reranking
discourse parses by applying standard kernels to
our new structures, (iii) show the reranking perfor-
mance using the best kernel for different number
of hypotheses, and (iv) show the relative impor-
tance of features coming from different sources.
</bodyText>
<subsectionHeader confidence="0.98662">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99995856">
Data. We use the standard RST-DT corpus (Carl-
son et al., 2002), which comes with discourse an-
notations for 385 articles (347 for training and 38
for testing) from the Wall Street Journal. We ex-
tracted sentence-level DTs from a document-level
DT by finding the subtrees that exactly span over
the sentences. This gives 7321 and 951 sentences
in the training and test sets, respectively. Follow-
ing previous work, we use the same 18 coarser re-
lations defined by Carlson and Marcu (2001).
We create the training data for the reranker in a
5-fold cross-validation fashion.8 Specifically, we
split the training set into 5 equal-sized folds, and
train the parsing model on 4 folds and apply to the
rest to produce k most probable DTs for each text.
Then we generate and label the pairs (by compar-
ing with the gold) from the k most probable trees
as described in Section 5.1. Finally, we merge the
5 labeled folds to create the full training data.
SVM Reranker. We use SVM-light-TK to train
our reranking models,9 which enables the use
of tree kernels (Moschitti, 2006) in SVM-light
(Joachims, 1999). We build our new kernels for
reranking exploiting the standard built-in TK func-
tions, such as STK, STKb and PTK. We applied
</bodyText>
<footnote confidence="0.998065">
8Note that our earlier experiments with a 2-fold cross vali-
dation process yielded only 50% of our current improvement.
9http://disi.unitn.it/moschitti/Tree-Kernel.htm
</footnote>
<page confidence="0.996181">
2055
</page>
<bodyText confidence="0.999979571428571">
a linear kernel to standard feature vectors as it
showed to be the best on our development set.
Metrics. The standard procedure to evaluate dis-
course parsing performance is to compute Pre-
cision, Recall and f-score of the unlabeled and
labeled metrics proposed by Marcu (2000b).10
Specifically, the unlabeled metric Span measures
how accurate the parser is in finding the right
structure (i.e., skeleton) of the DT, while the la-
beled metrics Nuclearity and Relation measure the
parser’s ability to find the right labels (nuclearity
and relation) in addition to the right structure. Op-
timization of the Relation metric is considered to
be the hardest and the most desirable goal in dis-
course parsing since it gives aggregated evaluation
on tree structure and relation labels. Therefore,
we measure the oracle accuracy of the k-best dis-
course parser based on the f-scores of the Relation
metric, and our reranking framework aims to op-
timize the Relation metric.11 Specifically, the ora-
cle accuracy for k-best parsing is measured as fol-
</bodyText>
<equation confidence="0.960584666666667">
EN 1 maxk 1 f−scorer(gi,hji)
lows: ORACLE = i= j= , where
N
</equation>
<bodyText confidence="0.999698285714286">
N is the total number of texts (sentences or docu-
ments) evaluated, gi is the gold DT annotation for
text i, hji is the jth parse hypothesis generated by
the k-best parser for text i, and f-scorer(gi, hji) is
the f-score accuracy of hypothesis hji on the Re-
lation metric. In all our experiments we report the
f-scores of the Relation metric.
</bodyText>
<subsectionHeader confidence="0.999752">
6.2 Oracle Accuracy
</subsectionHeader>
<bodyText confidence="0.999878214285714">
Table 1 presents the oracle scores of the k-
best intra-sentential parser PAR-S on the standard
RST-DT test set. The 1-best result corresponds
to the accuracy of the base parser (i.e., 79.77%).
The 2-best shows dramatic oracle-rate improve-
ment (i.e., 4.65% absolute), suggesting that the
base parser often generates the best tree in its
top 2 outputs. 5-best increases the oracle score
to 88.09%. Afterwards, the increase in accuracy
slows down, achieving, e.g., 90.37% and 92.57%
at 10-best and 20-best, respectively.
The results are quite different at the document
level as Table 2 shows the oracle scores of the k-
best document-level parser PAR-D.12 The results
</bodyText>
<footnote confidence="0.994587142857143">
10Precision, Recall and f-score are the same when the dis-
course parser uses manual discourse segmentation. Since all
our experiments in this paper are based on manual discourse
segmentation, we only report the f-scores.
11It is important to note that optimizing Relation metric
may also result in improved Nuclearity scores.
12For document-level parsing, Joty et al. (2013) pro-
</footnote>
<table confidence="0.9656735">
k 1 2 5 10 15 20
PAR-S 79.77 84.42 88.09 90.37 91.74 92.57
</table>
<tableCaption confidence="0.992574">
Table 1: Oracle scores as a function of k of k-best sentence-
level parses on RST-DT test set.
</tableCaption>
<table confidence="0.989363">
k 1 2 5 10 15 20
PAR-D 55.83 56.52 56.91 57.23 57.54 57.65
</table>
<tableCaption confidence="0.996158">
Table 2: Oracle scores as a function of k of k-best
document-level parses on RST-DT test set.
</tableCaption>
<bodyText confidence="0.999994736842105">
suggest that the best tree is often missing in the
top k parses, and the improvement in oracle-rate is
very little as compared to the sentence-level pars-
ing. The 2-best and the 5-best improve over the
base accuracy by only 0.7% and 1.0%, respec-
tively. The improvement becomes even lower for
larger k. For example, the gain from 20-best to
30-best parsing is only 0.09%. This is not sur-
prising because generally document-level DTs are
big with many constituents, and only a very few
of them change from k-best to k+1-best parsing.
These small changes do not contribute much to
the overall f-score accuracy.13 In summary, the
results in Tables 1 and 2 demonstrate that a k-best
reranker can potentially improve the parsing accu-
racy at the sentence level, but may not be a suit-
able option for improving parsing at the document
level. In the following, we report our results for
reranking sentence-level discourse parses.
</bodyText>
<subsectionHeader confidence="0.998603">
6.3 Performance of Different DISCTKs
</subsectionHeader>
<bodyText confidence="0.985423416666666">
Section 3 has pointed out that different DISCTKs
can be obtained by specifying the TK type (e.g.,
STK, STKb, PTK) and the mapping OM (i.e.,
JRN, SRN) in the overall kernel function (OTK ◦
OM) (o1)· (OTK◦OM) (o2). Table 3 reports the per-
formance of such model compositions using the 5-
best hypotheses on the RST-DT test set. Addition-
ally, it also reports the accuracy for the two ver-
sions of JRN and SRN, i.e., Bigram and All. From
these results, we can note the following.
Firstly, the kernels generally perform better on
Bigram than All lexicalization. This suggests that
using all the words from the text spans (i.e., EDUs)
produces sparse models.
pose two approaches to combine intra- and multi-sentential
parsers, namely 1S-1S (1 Sentence-1 Subtree) and Sliding
window. In this work we extend 1S-1S to k-best document-
level parser PAR-D since it is not only time efficient but it
also achieves better results on the Relation metric.
13Note that Joty et al. (2012; 2013) report lower f-scores
both at the sentence level (i.e., 77.1% as opposed to our
79.77%) and at the document level (i.e., 55.73% as opposed
to our 55.83%). We fixed a crucial bug in their (1-best) pars-
ing algorithm, which accounts for the improved performance.
</bodyText>
<page confidence="0.979913">
2056
</page>
<table confidence="0.9974896">
φTx ◦ φar JRN SRN
Bigram All Bigram All
STK 81.28 80.04 82.15 80.04
STKb 81.35 80.28 82.18 80.25
PTK 81.63 78.50 81.42 78.25
</table>
<tableCaption confidence="0.7966355">
Table 5: Comparison of features from different sources for
5-best discourse reranking.
</tableCaption>
<table confidence="0.9844905">
Baseline
Basic feat.
+ Rel. feat.
+ Tree
79.77
79.84
79.81
82.15
</table>
<tableCaption confidence="0.947695">
Table 3: Reranking performance of different discourse tree PAR-D (Joty et al., 2013) With Reranker
kernels on different representations. 55.8 57.3
</tableCaption>
<bodyText confidence="0.999907424242424">
Secondly, while the tree kernels perform sim-
ilarly on the JRN representation, STK performs
significantly better (p-value &lt; 0.01) than PTK
on SRN.14 This result is interesting as it pro-
vides indications of the type of DT fragments use-
ful for improving parsing accuracy. As pointed
out in Section 2.2, PTK includes all features
generated by STK, and additionally, it includes
fragments whose nodes can have any subsets of
the children they have in the original DT. Since
this does not improve the accuracy, we speculate
that complete fragments, e.g., [CAUSE [ATTRI-
BUTION][ELABORATION]] are more meaningful
than the partial ones, e.g., [CAUSE [ATTRIBU-
TION]] and [CAUSE [ELABORATION]], which
may add too much uncertainty on the signature
of the relations contained in the DT. We verified
this hypothesis by running an experiment with
PTK constraining it to only generate fragments
whose nodes preserve all or none of their children.
The accuracy of such fragments approached the
ones of STK, suggesting that relation information
should be used as a whole for engineering features.
Finally, STKb is slightly (but not significantly)
better than STK suggesting that the lexical infor-
mation is already captured by the base parser.
Note that the results in Table 3 confirms many
other experiments we carried out on several devel-
opment sets. For any run: (i) STK always performs
as well as STKb, (ii) STK is always better than
PTK, and (iii) SRN is always better than JRN. In
what follows, we show the reranking performance
based on STK applied to SRN with Bigram.
</bodyText>
<subsectionHeader confidence="0.895772">
6.4 Insights on DISCTK-based Reranking
</subsectionHeader>
<bodyText confidence="0.999814625">
Table 4 reports the performance of our reranker
(RR) in comparison with the oracle (OR) accuracy
for different values of k, where we also show the
corresponding relative error rate reduction (ERR)
with respect to the baseline. To assess the general-
ity of our approach, we evaluated our reranker on
both the standard test set and the entire training set
using 5-fold cross validation.15
</bodyText>
<footnote confidence="0.9964345">
14Statistical significance is verified using paired t-test.
15The reranker was trained on 4 folds and tested on the rest
</footnote>
<tableCaption confidence="0.95122">
Table 6: Document-level parsing results with 5-best
sentence-level discourse reranker.
</tableCaption>
<bodyText confidence="0.999974194444444">
We note that: (i) the best result on the standard
test set is 82.15% for k = 4 and 5, which gives
an ERR of 11.76%, and significantly (p-value &lt;
0.01) outperforms the baseline, (ii) the improve-
ment is consistent when we move from standard
test set to 5-folds, (iii) the best result on the 5-folds
is 80.86 for k = 6, which is significantly (p-value
&lt; 0.01) better than the baseline 78.57, and gives
an ERR of 11.32%. We also experimented with
other values of k in both training and test sets (also
increasing k only in the test set), but we could not
improve over our best result. This suggests that
outperforming the baseline (which in our case is
the state of the art) is rather difficult.16
In this respect, we also investigated the im-
pact of traditional ranking methods based on fea-
ture vectors, and compared it with our TK-based
model. Table 5 shows the 5-best reranking accu-
racy for different feature subsets. The Basic fea-
tures (Section 5.2) alone do not significantly im-
prove over the Baseline. The only relevant fea-
tures are the probability and the rank of each hy-
pothesis, which condense all the information of
the local model (TKs models always used them).
Similarly, adding the relations as bag-of-
relations in the vector (Rel. feat.) does not pro-
vide any gain, whereas the relations encoded in
the tree fragments (Tree) gives improvement. This
shows the importance of using structural depen-
dencies for reranking discourse parses.
Finally, Table 6 shows that if we use our
sentence-level reranker in the document-level
parser of Joty et al. (2013), the accuracy of the lat-
ter increases from 55.8% to 57.3%, which is a sig-
nificant improvement (p &lt; 0.01), and establishes
a new state-of-the-art for document-level parsing.
</bodyText>
<subsectionHeader confidence="0.70876">
6.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.9955045">
We looked at some examples where our reranker
failed to identify the best DT. Unsurprisingly, it
</bodyText>
<footnote confidence="0.51047">
16The human agreement on sentence-level parsing is 83%.
</footnote>
<page confidence="0.967794">
2057
</page>
<table confidence="0.99807">
Standard test set 5-folds (average)
k=1 k=2 k=3 k=4 k=5 k=6 k=1 k=2 k=3 k=4 k=5 k=6
RR 79.77 81.08 81.56 82.15 82.15 82.11 78.57 79.76 80.28 80.68 80.80 80.86
ERR - 6.48 8.85 11.76 11.76 11.57 - 5.88 8.45 10.43 11.02 11.32
OR 79.77 84.42 86.55 87.68 88.09 88.75 78.57 83.20 85.13 86.49 87.35 88.03
</table>
<tableCaption confidence="0.9912015">
Table 4: Reranking performance (RR) in comparison with oracle (OR) accuracy for different values of k on the standard
testset and 5-folds of RST-DT. Second row shows the relative error rate reduction (ERR).
</tableCaption>
<bodyText confidence="0.99962345">
happens many times for small DTs containing
only two or three EDUs, especially when the re-
lations are semantically similar. Figure 9 presents
such a case, where the reranker fails to rank the
DT with Summary ahead of the DT with Elabo-
ration. Although we understand that the reranker
lacks enough structural context to distinguish the
two relations in this example, we expected that in-
cluding the lexical items (e.g., (CFD)) in our DT
representation could help. However, similar short
parenthesized texts are also used to elaborate as
in Senate Majority Leader George Mitchell (D.,
Maine), where the text (D., Maine) (i.e., Democrat
from state Maine) elaborates its preceding text.
This confuses our reranker. We also found er-
ror examples where the reranker failed to distin-
guish between Background and Elaboration, and
between Cause and Elaboration. This suggests
that we need rich semantic representation of the
text to improve our reranker further.
</bodyText>
<sectionHeader confidence="0.999948" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.999955217391304">
Early work on discourse parsing applied hand-
coded rules based on discourse cues and surface
patterns (Marcu, 2000a). Supervised learning was
first attempted by Marcu (2000b) to build a shift-
reduce discourse parser. This work was then con-
siderably improved by Soricut and Marcu (2003).
They presented probabilistic generative models for
sentence-level discourse parsing based on lexico-
syntactic patterns. Sporleder and Lapata (2005)
investigated the necessity of syntax in discourse
analysis. More recently, Hernault et al. (2010)
presented the HILDA discourse parser that itera-
tively employs two SVM classifiers in pipeline to
build a DT in a greedy way. Feng and Hirst (2012)
improved the HILDA parser by incorporating rich
linguistic features, which include lexical seman-
tics and discourse production rules.
Joty et al. (2013) achieved the best prior results
by (i) jointly modeling the structure and the la-
bel of a DT constituent, (ii) performing optimal
rather than greedy decoding, and (iii) discriminat-
ing between intra- and multi-sentential discourse
parsing. However, their model does not con-
</bodyText>
<figure confidence="0.6036615">
Summary
Elaboration
</figure>
<figureCaption confidence="0.998144">
Figure 9: An error made by our reranker.
</figureCaption>
<bodyText confidence="0.9999809">
sider long range dependencies between DT con-
stituents, which are encoded by our kernels. Re-
garding the latter, our work is surely inspired by
(Collins and Duffy, 2002), which uses TK for syn-
tactic parsing reranking or in general discrimina-
tive reranking, e.g., (Collins and Koo, 2005; Char-
niak and Johnson, 2005; Dinarelli et al., 2011).
However, such excellent studies do not regard
discourse parsing, and in absolute they achieved
lower improvements than our methods.
</bodyText>
<sectionHeader confidence="0.995515" genericHeader="conclusions">
8 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99998380952381">
In this paper, we have presented a discriminative
approach for reranking discourse trees generated
by an existing discourse parser. Our reranker uses
tree kernels in SVM preference ranking frame-
work to effectively capture the long range struc-
tural dependencies between the constituents of a
discourse tree. We have shown the reranking per-
formance for sentence-level discourse parsing us-
ing the standard tree kernels (i.e., STK and PTK)
on two different representations (i.e., JRN and
SRN) of the discourse tree, and compare it with
the traditional feature vector-based approach. Our
results show that: (i) the reranker improves only
when it considers subtree features computed by
the tree kernels, (ii) SRN is a better representation
than JRN, (iii) STK performs better than PTK for
reranking discourse trees, and (iv) our best result
outperforms the state-of-the-art significantly.
In the future, we would like to apply our
reranker to the document-level parses. However,
this will require a better hypotheses generator.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.838922285714286">
This research is part of the Interactive sYstems
for Answer Search (Iyas) project, conducted by
the Arabic Language Technologies (ALT) group
at Qatar Computing Research Institute (QCRI)
within the Qatar Foundation.
Same-Unit
On the Big Board, Crawford &amp; Co., Atlanta, (CFD) begins trading today.
</bodyText>
<page confidence="0.941142">
2058
</page>
<sectionHeader confidence="0.994641" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999674570093458">
Lynn Carlson and Daniel Marcu. 2001. Discourse Tag-
ging Reference Manual. Technical Report ISI-TR-
545, University of Southern California Information
Sciences Institute.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2002. RST Discourse Treebank (RST-
DT) LDC2002T07. Linguistic Data Consortium,
Philadelphia.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics, ACL’05, pages 173–180, NJ, USA. ACL.
Michael Collins and Nigel Duffy. 2002. New Ranking
Algorithms for Parsing and Tagging: Kernels over
Discrete Structures, and the Voted Perceptron. In
ACL.
Michael Collins and Terry Koo. 2005. Discriminative
Reranking for Natural Language Parsing. Comput.
Linguist., 31(1):25–70, March.
Corinna Cortes and Vladimir Vapnik. 1995. Support
Vector Networks. Machine Learning, 20:273–297.
Marco Dinarelli, Alessandro Moschitti, and Giuseppe
Riccardi. 2011. Discriminative Reranking for
Spoken Language Understanding. IEEE Transac-
tions on Audio, Speech and Language Processing
(TASLP), 20:526539.
Vanessa Feng and Graeme Hirst. 2012. Text-level Dis-
course Parsing with Rich Linguistic Features. In
Proceedings of the 50th Annual Meeting of the As-
sociation for Computational Linguistics, ACL ’12,
pages 60–68, Jeju Island, Korea. ACL.
Hugo Hernault, Helmut Prendinger, David A. duVerle,
and Mitsuru Ishizuka. 2010. HILDA: A Discourse
Parser Using Support Vector Machine Classification.
Dialogue and Discourse, 1(3):1—33.
Liang Huang and David Chiang. 2005. Better K-
best Parsing. In Proceedings of the Ninth Inter-
national Workshop on Parsing Technology, Parsing
’05, pages 53–64, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Thorsten Joachims and Chun-Nam John Yu. 2009.
Sparse Kernel SVMs via Cutting-Plane Training.
Machine Learning, 76(2-3):179–193. ECML.
Thorsten Joachims. 1999. Making large-Scale SVM
Learning Practical. In Advances in Kernel Methods
- Support Vector Learning.
Shafiq Joty, Giuseppe Carenini, and Raymond T. Ng.
2012. A Novel Discriminative Framework for
Sentence-Level Discourse Analysis. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, EMNLP-CoNLL ’12,
pages 904–915, Jeju Island, Korea. ACL.
Shafiq Joty, Giuseppe Carenini, Raymond T. Ng, and
Yashar Mehdad. 2013. Combining Intra- and
Multi-sentential Rhetorical Parsing for Document-
level Discourse Analysis. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, ACL ’13, Sofia, Bulgaria. ACL.
William Mann and Sandra Thompson. 1988. Rhetor-
ical Structure Theory: Toward a Functional Theory
of Text Organization. Text, 8(3):243–281.
Daniel Marcu. 2000a. The Rhetorical Parsing of Un-
restricted Texts: A Surface-based Approach. Com-
putational Linguistics, 26:395–448.
Daniel Marcu. 2000b. The Theory and Practice of
Discourse Parsing and Summarization. MIT Press,
Cambridge, MA, USA.
Alessandro Moschitti, Daniele Pighin, and Roberto
Basili. 2006. Semantic Role Labeling via Tree Ker-
nel Joint Inference. In Proceedings of the Tenth
Conference on Computational Natural Language
Learning (CoNLL-X), pages 61–68, New York City,
June. Association for Computational Linguistics.
Alessandro Moschitti. 2006. Efficient Convolution
Kernels for Dependency and Constituent Syntactic
Trees. In 17th European Conference on Machine
Learning, pages 318–329. Springer.
Alessandro Moschitti. 2010. Kernel Engineering for
Fast and Easy Design of Natural Language Applica-
tions. In COLING (Tutorials), pages 1–91.
Alessandro Moschitti. 2012. State-of-the-Art Kernels
for Natural Language Processing. In Tutorial Ab-
stracts ofACL 2012, page 2, Jeju Island, Korea, July.
Association for Computational Linguistics.
Alessandro Moschitti. 2013. Kernel-based Learning
to Rank with Syntactic and Semantic Structures. In
SIGIR, page 1128.
Daniele Pighin and Alessandro Moschitti. 2009. Re-
verse Engineering of Tree Kernel Feature Spaces. In
EMNLP, pages 111–120.
Daniele Pighin and Alessandro Moschitti. 2010. On
Reverse Feature Engineering of Syntactic Tree Ker-
nels. In Proceedings of the Fourteenth Confer-
ence on Computational Natural Language Learning,
pages 223–233, Uppsala, Sweden, July. Association
for Computational Linguistics.
Aliaksei Severyn and Alessandro Moschitti. 2011.
Fast Support Vector Machines for Structural Ker-
nels. In ECML/PKDD (3), pages 175–190.
Aliaksei Severyn and Alessandro Moschitti. 2012.
Fast Support Vector Machines for Convolution Tree
Kernels. Data Min. Knowl. Discov., 25(2):325–357.
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press.
</reference>
<page confidence="0.891238">
2059
</page>
<reference confidence="0.998671631578947">
Radu Soricut and Daniel Marcu. 2003. Sentence Level
Discourse Parsing Using Syntactic and Lexical In-
formation. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Language
Technology - Volume 1, NAACL’03, pages 149–156,
Edmonton, Canada. ACL.
Caroline Sporleder and Mirella Lapata. 2005. Dis-
course Chunking and its Application to Sentence
Compression. In Proceedings of the conference
on Human Language Technology and Empirical
Methods in Natural Language Processing, HLT-
EMNLP’05, pages 257–264, Vancouver, British
Columbia, Canada. ACL.
Charles Sutton, Andrew McCallum, and Khashayar
Rohanimanesh. 2007. Dynamic Conditional Ran-
dom Fields: Factorized Probabilistic Models for La-
beling and Segmenting Sequence Data. Journal of
Machine Learning Research (JMLR), 8:693–723.
</reference>
<page confidence="0.990263">
2060
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.565305">
<title confidence="0.999201">Discriminative Reranking of Discourse Parses Using Tree Kernels</title>
<author confidence="0.967912">Joty</author>
<affiliation confidence="0.9763525">ALT Research Qatar Computing Research</affiliation>
<abstract confidence="0.999792375">In this paper, we present a discriminative approach for reranking discourse trees generated by an existing probabilistic discourse parser. The reranker relies on tree kernels (TKs) to capture the global dependencies between discourse units in a tree. In particular, we design new computational structures of discourse trees, which combined with standard TKs, originate novel discourse TKs. The empirical evaluation shows that our reranker can improve the state-of-the-art sentence-level parsing from relerror reduction of in turn pushes the state-of-the-art document-</abstract>
<intro confidence="0.60804">accuracy from</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
</authors>
<title>Discourse Tagging Reference Manual.</title>
<date>2001</date>
<tech>Technical Report ISI-TR545,</tech>
<institution>University of Southern California Information Sciences Institute.</institution>
<contexts>
<context position="28689" citStr="Carlson and Marcu (2001)" startWordPosition="4910" endWordPosition="4913"> for different number of hypotheses, and (iv) show the relative importance of features coming from different sources. 6.1 Experimental Setup Data. We use the standard RST-DT corpus (Carlson et al., 2002), which comes with discourse annotations for 385 articles (347 for training and 38 for testing) from the Wall Street Journal. We extracted sentence-level DTs from a document-level DT by finding the subtrees that exactly span over the sentences. This gives 7321 and 951 sentences in the training and test sets, respectively. Following previous work, we use the same 18 coarser relations defined by Carlson and Marcu (2001). We create the training data for the reranker in a 5-fold cross-validation fashion.8 Specifically, we split the training set into 5 equal-sized folds, and train the parsing model on 4 folds and apply to the rest to produce k most probable DTs for each text. Then we generate and label the pairs (by comparing with the gold) from the k most probable trees as described in Section 5.1. Finally, we merge the 5 labeled folds to create the full training data. SVM Reranker. We use SVM-light-TK to train our reranking models,9 which enables the use of tree kernels (Moschitti, 2006) in SVM-light (Joachim</context>
</contexts>
<marker>Carlson, Marcu, 2001</marker>
<rawString>Lynn Carlson and Daniel Marcu. 2001. Discourse Tagging Reference Manual. Technical Report ISI-TR545, University of Southern California Information Sciences Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
<author>Mary Ellen Okurowski</author>
</authors>
<date>2002</date>
<booktitle>RST Discourse Treebank (RSTDT) LDC2002T07. Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="28268" citStr="Carlson et al., 2002" startWordPosition="4838" endWordPosition="4842">ed in the kernel space. 6 Experiments Our experiments aim to show that reranking of discourse parses is a promising research direction, which can improve the state-of-the-art. To achieve this, we (i) compute the oracle accuracy of the kbest parser, (ii) test different kernels for reranking discourse parses by applying standard kernels to our new structures, (iii) show the reranking performance using the best kernel for different number of hypotheses, and (iv) show the relative importance of features coming from different sources. 6.1 Experimental Setup Data. We use the standard RST-DT corpus (Carlson et al., 2002), which comes with discourse annotations for 385 articles (347 for training and 38 for testing) from the Wall Street Journal. We extracted sentence-level DTs from a document-level DT by finding the subtrees that exactly span over the sentences. This gives 7321 and 951 sentences in the training and test sets, respectively. Following previous work, we use the same 18 coarser relations defined by Carlson and Marcu (2001). We create the training data for the reranker in a 5-fold cross-validation fashion.8 Specifically, we split the training set into 5 equal-sized folds, and train the parsing model</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2002</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski. 2002. RST Discourse Treebank (RSTDT) LDC2002T07. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL’05,</booktitle>
<pages>173--180</pages>
<publisher>ACL.</publisher>
<location>NJ, USA.</location>
<contexts>
<context position="42050" citStr="Charniak and Johnson, 2005" startWordPosition="7125" endWordPosition="7129"> prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our work is surely inspired by (Collins and Duffy, 2002), which uses TK for syntactic parsing reranking or in general discriminative reranking, e.g., (Collins and Koo, 2005; Charniak and Johnson, 2005; Dinarelli et al., 2011). However, such excellent studies do not regard discourse parsing, and in absolute they achieved lower improvements than our methods. 8 Conclusions and Future Work In this paper, we have presented a discriminative approach for reranking discourse trees generated by an existing discourse parser. Our reranker uses tree kernels in SVM preference ranking framework to effectively capture the long range structural dependencies between the constituents of a discourse tree. We have shown the reranking performance for sentence-level discourse parsing using the standard tree ker</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL’05, pages 173–180, NJ, USA. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Nigel Duffy</author>
</authors>
<title>New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron.</title>
<date>2002</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="3451" citStr="Collins and Duffy, 2002" startWordPosition="533" endWordPosition="536"> Reranking models can make the global structural information available to the system as follows: first, a base parser produces several DT hypotheses; and then a classifier exploits the entire information in each hypothesis, e.g., the complete DT with its dependencies, for selecting the best DT. Designing features capturing such global properties is however not trivial as it requires the selection of important DT fragments. This means selecting subtree patterns from an exponential feature space. An alternative approach is to implicitly generate the whole feature space using tree kernels (TKs) (Collins and Duffy, 2002; Moschitti, 2006). In this paper, we present reranking models for discourse parsing based on Support Vector Machines (SVMs) and TKs. The latter allows us to represent structured data using the substructure space thus capturing structural dependencies between DT constituents, which is essential for effective discourse parsing. Specifically, we made the following contributions. First, we extend the 2049 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2049–2060, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistic</context>
<context position="7302" citStr="Collins and Duffy, 2002" startWordPosition="1134" endWordPosition="1137"> turn pushes the state-of-the-art document-level f-score from 55.8% to 57.3%, an error reduction of 3.4%. In the rest of the paper, after introducing the TK technology in Section 2, we illustrate our novel structures, and how they lead to the design of novel DISCTKs in Section 3. We present the kbest discourse parser in Section 4. In Section 5, we describe our reranking approach using DISCTKs. We report our experiments in Section 6. We briefly overview the related work in Section 7, and finally, we summarize our contributions in Section 8. 2 Kernels for Structural Representation Tree kernels (Collins and Duffy, 2002; ShaweTaylor and Cristianini, 2004; Moschitti, 2006) are a viable alternative for representing arbitrary subtree structures in learning algorithms. Their basic idea is that kernel-based learning algorithms, e.g., SVMs or perceptron, only need the scalar product between the feature vectors representing the data instances to learn and classify; and kernel functions compute such scalar products in an efficient way. In the following subsections, we briefly describe the kernel machines and three types of tree kernels (TKs), which efficiently compute the scalar product in the subtree space, where t</context>
<context position="24155" citStr="Collins and Duffy (2002)" startWordPosition="4154" endWordPosition="4157">ples, where h1 has the highest f-score accuracy on the Relation metric (to be described in Section 6) with respect to the gold standard among the candidate hypotheses, and vice versa, (hi, h1) are considered as negative examples. At test time, C classifies all pairs (hi, hj) generated from the k-best hypotheses. A positive decision is a vote for hi, and a negative decision is a vote for hj. Also, the classifier score can be used as a weighted vote. Hypotheses are then ranked according to the number (sum) of the (weighted) votes they get.6 We build our reranker using simple SVMs.7 6As shown by Collins and Duffy (2002), only the classification of k hypotheses (paired with the empty one) is needed in practice, thus the complexity is only O(k). 7Structural kernels, e.g., TKs, cannot be used in more advanced algorithms working in structured output spaces, e.g., SVMstruct. Indeed, to our knowledge, no one could successfully find a general and exact solution for the argmax equation, typically part of such advanced models, when structural kernels are used. Some approximate solutions for simple kernels, e.g., polynomial or gaussian kernels, are given in (Joachims and Yu, 2009), whereas (Severyn and Moschitti, 2011</context>
<context position="41906" citStr="Collins and Duffy, 2002" startWordPosition="7102" endWordPosition="7105">y incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our work is surely inspired by (Collins and Duffy, 2002), which uses TK for syntactic parsing reranking or in general discriminative reranking, e.g., (Collins and Koo, 2005; Charniak and Johnson, 2005; Dinarelli et al., 2011). However, such excellent studies do not regard discourse parsing, and in absolute they achieved lower improvements than our methods. 8 Conclusions and Future Work In this paper, we have presented a discriminative approach for reranking discourse trees generated by an existing discourse parser. Our reranker uses tree kernels in SVM preference ranking framework to effectively capture the long range structural dependencies betwee</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>Michael Collins and Nigel Duffy. 2002. New Ranking Algorithms for Parsing and Tagging: Kernels over Discrete Structures, and the Voted Perceptron. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Discriminative Reranking for Natural Language Parsing.</title>
<date>2005</date>
<journal>Comput. Linguist.,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="42022" citStr="Collins and Koo, 2005" startWordPosition="7121" endWordPosition="7124">2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our work is surely inspired by (Collins and Duffy, 2002), which uses TK for syntactic parsing reranking or in general discriminative reranking, e.g., (Collins and Koo, 2005; Charniak and Johnson, 2005; Dinarelli et al., 2011). However, such excellent studies do not regard discourse parsing, and in absolute they achieved lower improvements than our methods. 8 Conclusions and Future Work In this paper, we have presented a discriminative approach for reranking discourse trees generated by an existing discourse parser. Our reranker uses tree kernels in SVM preference ranking framework to effectively capture the long range structural dependencies between the constituents of a discourse tree. We have shown the reranking performance for sentence-level discourse parsing</context>
</contexts>
<marker>Collins, Koo, 2005</marker>
<rawString>Michael Collins and Terry Koo. 2005. Discriminative Reranking for Natural Language Parsing. Comput. Linguist., 31(1):25–70, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support Vector Networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<pages>20--273</pages>
<contexts>
<context position="8043" citStr="Cortes and Vapnik, 1995" startWordPosition="1245" endWordPosition="1248">uctures in learning algorithms. Their basic idea is that kernel-based learning algorithms, e.g., SVMs or perceptron, only need the scalar product between the feature vectors representing the data instances to learn and classify; and kernel functions compute such scalar products in an efficient way. In the following subsections, we briefly describe the kernel machines and three types of tree kernels (TKs), which efficiently compute the scalar product in the subtree space, where the vector components are all possible substructures of the corresponding trees. 2.1 Kernel Machines Kernel Machines (Cortes and Vapnik, 1995), e.g., SVMs, perform binary classification by learning a hyperplane H(x) = w� · x� + b = 0, where 2050 c e b a a g b g c e c e g b c e b a S c e b a a S b S c e S a b S c e c e b a b e a c e b a g g g Figure 2: A tree with its STK subtrees; STKb also includes leaves as features. x~ ∈ Rn is the feature vector representation of an see u . a pr object o ∈ O to be classified and w~ ∈ Rn and b ∈ R are parameters learned from the training data. One can train such machines in the dual bset Tree A subset tree is a subtree for which the following constrin is sa space by rewriting the model parameter w</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Support Vector Networks. Machine Learning, 20:273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Dinarelli</author>
<author>Alessandro Moschitti</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Discriminative Reranking for Spoken Language Understanding.</title>
<date>2011</date>
<journal>IEEE Transactions on Audio, Speech and Language Processing (TASLP),</journal>
<pages>20--526539</pages>
<contexts>
<context position="23212" citStr="Dinarelli et al., 2011" startWordPosition="3992" endWordPosition="3995"> did not limit us to produce k-best parses for larger k, it was not a priority in this work. 5 Kernels for Reranking Discourse Trees In Section 3, we described DISCTK, which essentially can be used for any classification task involving discourse trees. For example, given a DT, we can use DISCTK to classify it as correct vs. incorrect. However, such classification is not completely aligned to our purpose, since our goal is to select the best (i.e., the most correct) DT from k candidate DTs; i.e., a ranking task. We adopt a preference reranking technique as described in (Moschitti et al., 2006; Dinarelli et al., 2011). 5.1 Preference Reranker Preference reranking (PR) uses a classifier C of pairs of hypotheses (hi, hj), which decides if hi (i.e., a candidate DT in our case) is better than hj. We generate positive and negative examples to train the classifier using the following approach. The pairs (h1, hi) constitute positive examples, where h1 has the highest f-score accuracy on the Relation metric (to be described in Section 6) with respect to the gold standard among the candidate hypotheses, and vice versa, (hi, h1) are considered as negative examples. At test time, C classifies all pairs (hi, hj) gener</context>
<context position="42075" citStr="Dinarelli et al., 2011" startWordPosition="7130" endWordPosition="7133">y modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our work is surely inspired by (Collins and Duffy, 2002), which uses TK for syntactic parsing reranking or in general discriminative reranking, e.g., (Collins and Koo, 2005; Charniak and Johnson, 2005; Dinarelli et al., 2011). However, such excellent studies do not regard discourse parsing, and in absolute they achieved lower improvements than our methods. 8 Conclusions and Future Work In this paper, we have presented a discriminative approach for reranking discourse trees generated by an existing discourse parser. Our reranker uses tree kernels in SVM preference ranking framework to effectively capture the long range structural dependencies between the constituents of a discourse tree. We have shown the reranking performance for sentence-level discourse parsing using the standard tree kernels (i.e., STK and PTK) </context>
</contexts>
<marker>Dinarelli, Moschitti, Riccardi, 2011</marker>
<rawString>Marco Dinarelli, Alessandro Moschitti, and Giuseppe Riccardi. 2011. Discriminative Reranking for Spoken Language Understanding. IEEE Transactions on Audio, Speech and Language Processing (TASLP), 20:526539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Feng</author>
<author>Graeme Hirst</author>
</authors>
<title>Text-level Discourse Parsing with Rich Linguistic Features.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, ACL ’12,</booktitle>
<pages>60--68</pages>
<publisher>ACL.</publisher>
<location>Jeju Island,</location>
<contexts>
<context position="2089" citStr="Feng and Hirst, 2012" startWordPosition="309" endWordPosition="312">re parts of the relation while satellites are the supportive ones. Conventionally, discourse analysis in RST involves two subtasks: (i) discourse segmentation: breaking the text into a sequence of EDUs, and (ii) discourse parsing: linking the discourse units to form a labeled tree. Despite the fact that discourse analysis is central to many NLP applications, the state-of-the-art document-level discourse parser (Joty et al., 2013) has an f-score of only 55.83% using manual discourse segmentation on the RST Discourse Treebank (RST-DT). Although recent work has proposed rich linguistic features (Feng and Hirst, 2012) and powerful parsing models (Joty et al., 2012), discourse parsing remains a hard task, partly because these approaches do not consider global features and long range structural dependencies between DT constituents. For example, consider the humanannotated DT (Figure 1a) and the DT generated by the discourse parser of Joty et al. (2013) (Figure 1b) for the same text. The parser makes a mistake in finding the right structure: it considers only e3 as the text to be attributed to e2, where all the text spans from e3 to e6 (linked by CAUSE and ELABORATION) compose the statement to be attributed. </context>
<context position="41254" citStr="Feng and Hirst (2012)" startWordPosition="7000" endWordPosition="7003"> based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our </context>
</contexts>
<marker>Feng, Hirst, 2012</marker>
<rawString>Vanessa Feng and Graeme Hirst. 2012. Text-level Discourse Parsing with Rich Linguistic Features. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, ACL ’12, pages 60–68, Jeju Island, Korea. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Hernault</author>
<author>Helmut Prendinger</author>
<author>David A duVerle</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>HILDA: A Discourse Parser Using Support Vector Machine Classification. Dialogue and Discourse,</title>
<date>2010</date>
<contexts>
<context position="41107" citStr="Hernault et al. (2010)" startWordPosition="6974" endWordPosition="6977">eed rich semantic representation of the text to improve our reranker further. 7 Related Work Early work on discourse parsing applied handcoded rules based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9:</context>
</contexts>
<marker>Hernault, Prendinger, duVerle, Ishizuka, 2010</marker>
<rawString>Hugo Hernault, Helmut Prendinger, David A. duVerle, and Mitsuru Ishizuka. 2010. HILDA: A Discourse Parser Using Support Vector Machine Classification. Dialogue and Discourse, 1(3):1—33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Better Kbest Parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth International Workshop on Parsing Technology, Parsing ’05,</booktitle>
<pages>53--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="22520" citStr="Huang and Chiang, 2005" startWordPosition="3869" endWordPosition="3872">imultaneously. More specifically, each cell in the dynamic programming tables (i.e., A, B and C) should now contain k entries (sorted by their probabilities), and for each such entry there should be a back-pointer that keeps track of the decoding path. The algorithm works in polynomial time. For n discourse units and M number of relations, the 1-best parsing algorithm has a time complexity of O(n3M) and a space complexity of O(n2), where the k-best version has a time and space complexities of O(n3Mk2 log k) and O(n2k), respectively. There are cleverer ways to reduce the complexity (e.g., see (Huang and Chiang, 2005) for three such ways). However, since the efficiency of the algorithm did not limit us to produce k-best parses for larger k, it was not a priority in this work. 5 Kernels for Reranking Discourse Trees In Section 3, we described DISCTK, which essentially can be used for any classification task involving discourse trees. For example, given a DT, we can use DISCTK to classify it as correct vs. incorrect. However, such classification is not completely aligned to our purpose, since our goal is to select the best (i.e., the most correct) DT from k candidate DTs; i.e., a ranking task. We adopt a pre</context>
</contexts>
<marker>Huang, Chiang, 2005</marker>
<rawString>Liang Huang and David Chiang. 2005. Better Kbest Parsing. In Proceedings of the Ninth International Workshop on Parsing Technology, Parsing ’05, pages 53–64, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
<author>Chun-Nam John Yu</author>
</authors>
<title>Sparse Kernel SVMs via Cutting-Plane Training.</title>
<date>2009</date>
<booktitle>Machine Learning,</booktitle>
<pages>76--2</pages>
<publisher>ECML.</publisher>
<contexts>
<context position="24717" citStr="Joachims and Yu, 2009" startWordPosition="4245" endWordPosition="4248">er using simple SVMs.7 6As shown by Collins and Duffy (2002), only the classification of k hypotheses (paired with the empty one) is needed in practice, thus the complexity is only O(k). 7Structural kernels, e.g., TKs, cannot be used in more advanced algorithms working in structured output spaces, e.g., SVMstruct. Indeed, to our knowledge, no one could successfully find a general and exact solution for the argmax equation, typically part of such advanced models, when structural kernels are used. Some approximate solutions for simple kernels, e.g., polynomial or gaussian kernels, are given in (Joachims and Yu, 2009), whereas (Severyn and Moschitti, 2011; Severyn and Moschitti, 2012) provide solutions for using the cutting-plane algorithm (which requires argmax computation) with structural kernels but in binary SVMs. 2054 Since in our problem a pair of hypotheses (hi, hj) constitutes a data instance, we now need to define the kernel between the pairs. However, notice that DISCTK only works on a single pair. Considering that our task is to decide whether hi is better than hj, it can be convenient to represent the pairs in terms of differences between the vectors of the two hypotheses, i.e., φK(hi) − φK(hj)</context>
</contexts>
<marker>Joachims, Yu, 2009</marker>
<rawString>Thorsten Joachims and Chun-Nam John Yu. 2009. Sparse Kernel SVMs via Cutting-Plane Training. Machine Learning, 76(2-3):179–193. ECML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-Scale SVM Learning Practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods - Support Vector Learning.</booktitle>
<contexts>
<context position="29297" citStr="Joachims, 1999" startWordPosition="5017" endWordPosition="5018"> (2001). We create the training data for the reranker in a 5-fold cross-validation fashion.8 Specifically, we split the training set into 5 equal-sized folds, and train the parsing model on 4 folds and apply to the rest to produce k most probable DTs for each text. Then we generate and label the pairs (by comparing with the gold) from the k most probable trees as described in Section 5.1. Finally, we merge the 5 labeled folds to create the full training data. SVM Reranker. We use SVM-light-TK to train our reranking models,9 which enables the use of tree kernels (Moschitti, 2006) in SVM-light (Joachims, 1999). We build our new kernels for reranking exploiting the standard built-in TK functions, such as STK, STKb and PTK. We applied 8Note that our earlier experiments with a 2-fold cross validation process yielded only 50% of our current improvement. 9http://disi.unitn.it/moschitti/Tree-Kernel.htm 2055 a linear kernel to standard feature vectors as it showed to be the best on our development set. Metrics. The standard procedure to evaluate discourse parsing performance is to compute Precision, Recall and f-score of the unlabeled and labeled metrics proposed by Marcu (2000b).10 Specifically, the unla</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-Scale SVM Learning Practical. In Advances in Kernel Methods - Support Vector Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shafiq Joty</author>
<author>Giuseppe Carenini</author>
<author>Raymond T Ng</author>
</authors>
<title>A Novel Discriminative Framework for Sentence-Level Discourse Analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>904--915</pages>
<publisher>ACL.</publisher>
<location>Jeju Island,</location>
<contexts>
<context position="2137" citStr="Joty et al., 2012" startWordPosition="318" endWordPosition="321">upportive ones. Conventionally, discourse analysis in RST involves two subtasks: (i) discourse segmentation: breaking the text into a sequence of EDUs, and (ii) discourse parsing: linking the discourse units to form a labeled tree. Despite the fact that discourse analysis is central to many NLP applications, the state-of-the-art document-level discourse parser (Joty et al., 2013) has an f-score of only 55.83% using manual discourse segmentation on the RST Discourse Treebank (RST-DT). Although recent work has proposed rich linguistic features (Feng and Hirst, 2012) and powerful parsing models (Joty et al., 2012), discourse parsing remains a hard task, partly because these approaches do not consider global features and long range structural dependencies between DT constituents. For example, consider the humanannotated DT (Figure 1a) and the DT generated by the discourse parser of Joty et al. (2013) (Figure 1b) for the same text. The parser makes a mistake in finding the right structure: it considers only e3 as the text to be attributed to e2, where all the text spans from e3 to e6 (linked by CAUSE and ELABORATION) compose the statement to be attributed. Such errors occur because existing systems do no</context>
<context position="34313" citStr="Joty et al. (2012" startWordPosition="5857" endWordPosition="5860">ports the accuracy for the two versions of JRN and SRN, i.e., Bigram and All. From these results, we can note the following. Firstly, the kernels generally perform better on Bigram than All lexicalization. This suggests that using all the words from the text spans (i.e., EDUs) produces sparse models. pose two approaches to combine intra- and multi-sentential parsers, namely 1S-1S (1 Sentence-1 Subtree) and Sliding window. In this work we extend 1S-1S to k-best documentlevel parser PAR-D since it is not only time efficient but it also achieves better results on the Relation metric. 13Note that Joty et al. (2012; 2013) report lower f-scores both at the sentence level (i.e., 77.1% as opposed to our 79.77%) and at the document level (i.e., 55.73% as opposed to our 55.83%). We fixed a crucial bug in their (1-best) parsing algorithm, which accounts for the improved performance. 2056 φTx ◦ φar JRN SRN Bigram All Bigram All STK 81.28 80.04 82.15 80.04 STKb 81.35 80.28 82.18 80.25 PTK 81.63 78.50 81.42 78.25 Table 5: Comparison of features from different sources for 5-best discourse reranking. Baseline Basic feat. + Rel. feat. + Tree 79.77 79.84 79.81 82.15 Table 3: Reranking performance of different discou</context>
</contexts>
<marker>Joty, Carenini, Ng, 2012</marker>
<rawString>Shafiq Joty, Giuseppe Carenini, and Raymond T. Ng. 2012. A Novel Discriminative Framework for Sentence-Level Discourse Analysis. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 904–915, Jeju Island, Korea. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shafiq Joty</author>
<author>Giuseppe Carenini</author>
<author>Raymond T Ng</author>
<author>Yashar Mehdad</author>
</authors>
<title>Combining Intra- and Multi-sentential Rhetorical Parsing for Documentlevel Discourse Analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL ’13,</booktitle>
<publisher>ACL.</publisher>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1901" citStr="Joty et al., 2013" startWordPosition="279" endWordPosition="282"> connected by coherence relations (e.g., ELABORATION, CAUSE). Discourse units connected by a relation are further distinguished depending on their relative importance: nuclei are the core parts of the relation while satellites are the supportive ones. Conventionally, discourse analysis in RST involves two subtasks: (i) discourse segmentation: breaking the text into a sequence of EDUs, and (ii) discourse parsing: linking the discourse units to form a labeled tree. Despite the fact that discourse analysis is central to many NLP applications, the state-of-the-art document-level discourse parser (Joty et al., 2013) has an f-score of only 55.83% using manual discourse segmentation on the RST Discourse Treebank (RST-DT). Although recent work has proposed rich linguistic features (Feng and Hirst, 2012) and powerful parsing models (Joty et al., 2012), discourse parsing remains a hard task, partly because these approaches do not consider global features and long range structural dependencies between DT constituents. For example, consider the humanannotated DT (Figure 1a) and the DT generated by the discourse parser of Joty et al. (2013) (Figure 1b) for the same text. The parser makes a mistake in finding the</context>
<context position="4170" citStr="Joty et al. (2013)" startWordPosition="642" endWordPosition="645"> Vector Machines (SVMs) and TKs. The latter allows us to represent structured data using the substructure space thus capturing structural dependencies between DT constituents, which is essential for effective discourse parsing. Specifically, we made the following contributions. First, we extend the 2049 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2049–2060, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics e e 5 6 (a) A human-annotated discourse tree. Background e e 5 6 (b) A discourse tree generated by Joty et al. (2013). Attribution e3 Cause Elaboration e4 Elaboration e1 e2 Topic-Comment Elaboration Attribution e1 Cause e2 e3 e4 Elaboration Figure 1: Example of human-annotated and system-generated discourse trees for the text [what’s more,]e, [he believes]e, [seasonal swings in the auto industry this year aren’t occurring at the same time in the past,]e,, [because ofproduction and pricing differences]e, [that are curbing the accuracy of seasonal adjustments]e5] [built into the employment data.]e6 Horizontal lines indicate text segments; satellites are connected to their nuclei by curved arrows. existing disc</context>
<context position="16699" citStr="Joty et al. (2013)" startWordPosition="2849" endWordPosition="2852">of Figure 5 shows two atomic fragments and one subtree composed of two atomic fragments. Comparing the two examples in Figure 5, it is easy to understand that the space of subtrees extracted from SRN is less sparse than that of JRN. Note that, as described in Secion 2.2, when the PTK kernel is applied to JRN and SRN trees, it can generate a richer feature space, e.g., features that are paths containing relation labels (e.g., BACKGROUND - CAUSE - ELABORATION or ATTRIBUTION - CAUSE - ELABORATION). 4 Generation of k-best Discourse Parses In this section we describe the 1-best discourse parser of Joty et al. (2013), and how we extend 2052 Figure 5: Fragments from JRN in Figure 4a (upper row) and SRN in Figure 4b (lower row). it to k-best discourse parsing. Joty et al. (2013) decompose the problem of document-level discourse parsing into two stages as shown in Figure 6. In the first stage, the intrasentential discourse parser produces discourse subtrees for the individual sentences in a document. Then the multi-sentential parser combines the sentence-level subtrees and produces a DT for the document. Both parsers have the same two components: a parsing model and a parsing algorithm. The parsing model exp</context>
<context position="18962" citStr="Joty et al. (2013)" startWordPosition="3215" endWordPosition="3218">esent the discourse units at a certain level of the DT; the binary nodes 5j at the middle layer predict whether two adjacent units Uj_1 and Uj should be connected or not; and the multi-class nodes Rj at the top layer predict the discourse relation between Uj_1 and Uj. Notice that the model represents the structure and the label of a DT constituent jointly, and captures the sequential dependencies between the DT constituents. Since the chain-structured DCRF model does not scale up to multi-sentential parsing of long documents, Figure 6: The two-stage document-level discourse parser proposed by Joty et al. (2013). Figure 7: The intra-sentential parsing model. the multi-sentential parsing model is a CRF which breaks the chain structure of the DCRF model. The parsing models are applied recursively at different levels of the DT in their respective parsing scenarios (i.e., intra- and multi-sentential), and the probabilities of all possible DT constituents are obtained by computing the posterior marginals over the relation-structure pairs (i.e., P(Rj, 5j=1|U1, · · · , Ut, O), where O are model parameters). These probabilities are then used in a CKY-like probabilistic parsing algorithm to find the globally </context>
<context position="32083" citStr="Joty et al. (2013)" startWordPosition="5467" endWordPosition="5470">se in accuracy slows down, achieving, e.g., 90.37% and 92.57% at 10-best and 20-best, respectively. The results are quite different at the document level as Table 2 shows the oracle scores of the kbest document-level parser PAR-D.12 The results 10Precision, Recall and f-score are the same when the discourse parser uses manual discourse segmentation. Since all our experiments in this paper are based on manual discourse segmentation, we only report the f-scores. 11It is important to note that optimizing Relation metric may also result in improved Nuclearity scores. 12For document-level parsing, Joty et al. (2013) prok 1 2 5 10 15 20 PAR-S 79.77 84.42 88.09 90.37 91.74 92.57 Table 1: Oracle scores as a function of k of k-best sentencelevel parses on RST-DT test set. k 1 2 5 10 15 20 PAR-D 55.83 56.52 56.91 57.23 57.54 57.65 Table 2: Oracle scores as a function of k of k-best document-level parses on RST-DT test set. suggest that the best tree is often missing in the top k parses, and the improvement in oracle-rate is very little as compared to the sentence-level parsing. The 2-best and the 5-best improve over the base accuracy by only 0.7% and 1.0%, respectively. The improvement becomes even lower for </context>
<context position="34947" citStr="Joty et al., 2013" startWordPosition="5964" endWordPosition="5967">ower f-scores both at the sentence level (i.e., 77.1% as opposed to our 79.77%) and at the document level (i.e., 55.73% as opposed to our 55.83%). We fixed a crucial bug in their (1-best) parsing algorithm, which accounts for the improved performance. 2056 φTx ◦ φar JRN SRN Bigram All Bigram All STK 81.28 80.04 82.15 80.04 STKb 81.35 80.28 82.18 80.25 PTK 81.63 78.50 81.42 78.25 Table 5: Comparison of features from different sources for 5-best discourse reranking. Baseline Basic feat. + Rel. feat. + Tree 79.77 79.84 79.81 82.15 Table 3: Reranking performance of different discourse tree PAR-D (Joty et al., 2013) With Reranker kernels on different representations. 55.8 57.3 Secondly, while the tree kernels perform similarly on the JRN representation, STK performs significantly better (p-value &lt; 0.01) than PTK on SRN.14 This result is interesting as it provides indications of the type of DT fragments useful for improving parsing accuracy. As pointed out in Section 2.2, PTK includes all features generated by STK, and additionally, it includes fragments whose nodes can have any subsets of the children they have in the original DT. Since this does not improve the accuracy, we speculate that complete fragm</context>
<context position="38756" citStr="Joty et al. (2013)" startWordPosition="6597" endWordPosition="6600">ion 5.2) alone do not significantly improve over the Baseline. The only relevant features are the probability and the rank of each hypothesis, which condense all the information of the local model (TKs models always used them). Similarly, adding the relations as bag-ofrelations in the vector (Rel. feat.) does not provide any gain, whereas the relations encoded in the tree fragments (Tree) gives improvement. This shows the importance of using structural dependencies for reranking discourse parses. Finally, Table 6 shows that if we use our sentence-level reranker in the document-level parser of Joty et al. (2013), the accuracy of the latter increases from 55.8% to 57.3%, which is a significant improvement (p &lt; 0.01), and establishes a new state-of-the-art for document-level parsing. 6.5 Error Analysis We looked at some examples where our reranker failed to identify the best DT. Unsurprisingly, it 16The human agreement on sentence-level parsing is 83%. 2057 Standard test set 5-folds (average) k=1 k=2 k=3 k=4 k=5 k=6 k=1 k=2 k=3 k=4 k=5 k=6 RR 79.77 81.08 81.56 82.15 82.15 82.11 78.57 79.76 80.28 80.68 80.80 80.86 ERR - 6.48 8.85 11.76 11.76 11.57 - 5.88 8.45 10.43 11.02 11.32 OR 79.77 84.42 86.55 87.68</context>
<context position="41406" citStr="Joty et al. (2013)" startWordPosition="7022" endWordPosition="7025">ser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and multi-sentential discourse parsing. However, their model does not conSummary Elaboration Figure 9: An error made by our reranker. sider long range dependencies between DT constituents, which are encoded by our kernels. Regarding the latter, our work is surely inspired by (Collins and Duffy, 2002), which uses TK for syntactic parsing reranking or in general discriminative reranking, e.g., (Colli</context>
</contexts>
<marker>Joty, Carenini, Ng, Mehdad, 2013</marker>
<rawString>Shafiq Joty, Giuseppe Carenini, Raymond T. Ng, and Yashar Mehdad. 2013. Combining Intra- and Multi-sentential Rhetorical Parsing for Documentlevel Discourse Analysis. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, ACL ’13, Sofia, Bulgaria. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
<author>Sandra Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a Functional Theory of Text Organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="1014" citStr="Mann and Thompson, 1988" startWordPosition="141" endWordPosition="144">lobal dependencies between discourse units in a tree. In particular, we design new computational structures of discourse trees, which combined with standard TKs, originate novel discourse TKs. The empirical evaluation shows that our reranker can improve the state-of-the-art sentence-level parsing accuracy from 79.77% to 82.15%, a relative error reduction of 11.8%, which in turn pushes the state-of-the-art documentlevel accuracy from 55.8% to 57.3%. 1 Introduction Clauses and sentences in a well-written text are interrelated and exhibit a coherence structure. Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) represents the coherence structure of a text by a labeled tree, called discourse tree (DT) as shown in Figure 1. The leaves correspond to contiguous clause-like units called elementary discourse units (EDUs). Adjacent EDUs and larger discourse units are hierarchically connected by coherence relations (e.g., ELABORATION, CAUSE). Discourse units connected by a relation are further distinguished depending on their relative importance: nuclei are the core parts of the relation while satellites are the supportive ones. Conventionally, discourse analysis in RST involves two subtasks: (i) discourse </context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William Mann and Sandra Thompson. 1988. Rhetorical Structure Theory: Toward a Functional Theory of Text Organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Rhetorical Parsing of Unrestricted Texts: A Surface-based Approach.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<pages>26--395</pages>
<contexts>
<context position="29869" citStr="Marcu (2000" startWordPosition="5106" endWordPosition="5107">ti, 2006) in SVM-light (Joachims, 1999). We build our new kernels for reranking exploiting the standard built-in TK functions, such as STK, STKb and PTK. We applied 8Note that our earlier experiments with a 2-fold cross validation process yielded only 50% of our current improvement. 9http://disi.unitn.it/moschitti/Tree-Kernel.htm 2055 a linear kernel to standard feature vectors as it showed to be the best on our development set. Metrics. The standard procedure to evaluate discourse parsing performance is to compute Precision, Recall and f-score of the unlabeled and labeled metrics proposed by Marcu (2000b).10 Specifically, the unlabeled metric Span measures how accurate the parser is in finding the right structure (i.e., skeleton) of the DT, while the labeled metrics Nuclearity and Relation measure the parser’s ability to find the right labels (nuclearity and relation) in addition to the right structure. Optimization of the Relation metric is considered to be the hardest and the most desirable goal in discourse parsing since it gives aggregated evaluation on tree structure and relation labels. Therefore, we measure the oracle accuracy of the k-best discourse parser based on the f-scores of th</context>
<context position="40691" citStr="Marcu, 2000" startWordPosition="6917" endWordPosition="6918">, similar short parenthesized texts are also used to elaborate as in Senate Majority Leader George Mitchell (D., Maine), where the text (D., Maine) (i.e., Democrat from state Maine) elaborates its preceding text. This confuses our reranker. We also found error examples where the reranker failed to distinguish between Background and Elaboration, and between Cause and Elaboration. This suggests that we need rich semantic representation of the text to improve our reranker further. 7 Related Work Early work on discourse parsing applied handcoded rules based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorpo</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000a. The Rhetorical Parsing of Unrestricted Texts: A Surface-based Approach. Computational Linguistics, 26:395–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="29869" citStr="Marcu (2000" startWordPosition="5106" endWordPosition="5107">ti, 2006) in SVM-light (Joachims, 1999). We build our new kernels for reranking exploiting the standard built-in TK functions, such as STK, STKb and PTK. We applied 8Note that our earlier experiments with a 2-fold cross validation process yielded only 50% of our current improvement. 9http://disi.unitn.it/moschitti/Tree-Kernel.htm 2055 a linear kernel to standard feature vectors as it showed to be the best on our development set. Metrics. The standard procedure to evaluate discourse parsing performance is to compute Precision, Recall and f-score of the unlabeled and labeled metrics proposed by Marcu (2000b).10 Specifically, the unlabeled metric Span measures how accurate the parser is in finding the right structure (i.e., skeleton) of the DT, while the labeled metrics Nuclearity and Relation measure the parser’s ability to find the right labels (nuclearity and relation) in addition to the right structure. Optimization of the Relation metric is considered to be the hardest and the most desirable goal in discourse parsing since it gives aggregated evaluation on tree structure and relation labels. Therefore, we measure the oracle accuracy of the k-best discourse parser based on the f-scores of th</context>
<context position="40691" citStr="Marcu, 2000" startWordPosition="6917" endWordPosition="6918">, similar short parenthesized texts are also used to elaborate as in Senate Majority Leader George Mitchell (D., Maine), where the text (D., Maine) (i.e., Democrat from state Maine) elaborates its preceding text. This confuses our reranker. We also found error examples where the reranker failed to distinguish between Background and Elaboration, and between Cause and Elaboration. This suggests that we need rich semantic representation of the text to improve our reranker further. 7 Related Work Early work on discourse parsing applied handcoded rules based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorpo</context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000b. The Theory and Practice of Discourse Parsing and Summarization. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Daniele Pighin</author>
<author>Roberto Basili</author>
</authors>
<title>Semantic Role Labeling via Tree Kernel Joint Inference.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X),</booktitle>
<pages>61--68</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<contexts>
<context position="23187" citStr="Moschitti et al., 2006" startWordPosition="3988" endWordPosition="3991">iciency of the algorithm did not limit us to produce k-best parses for larger k, it was not a priority in this work. 5 Kernels for Reranking Discourse Trees In Section 3, we described DISCTK, which essentially can be used for any classification task involving discourse trees. For example, given a DT, we can use DISCTK to classify it as correct vs. incorrect. However, such classification is not completely aligned to our purpose, since our goal is to select the best (i.e., the most correct) DT from k candidate DTs; i.e., a ranking task. We adopt a preference reranking technique as described in (Moschitti et al., 2006; Dinarelli et al., 2011). 5.1 Preference Reranker Preference reranking (PR) uses a classifier C of pairs of hypotheses (hi, hj), which decides if hi (i.e., a candidate DT in our case) is better than hj. We generate positive and negative examples to train the classifier using the following approach. The pairs (h1, hi) constitute positive examples, where h1 has the highest f-score accuracy on the Relation metric (to be described in Section 6) with respect to the gold standard among the candidate hypotheses, and vice versa, (hi, h1) are considered as negative examples. At test time, C classifies</context>
</contexts>
<marker>Moschitti, Pighin, Basili, 2006</marker>
<rawString>Alessandro Moschitti, Daniele Pighin, and Roberto Basili. 2006. Semantic Role Labeling via Tree Kernel Joint Inference. In Proceedings of the Tenth Conference on Computational Natural Language Learning (CoNLL-X), pages 61–68, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees.</title>
<date>2006</date>
<booktitle>In 17th European Conference on Machine Learning,</booktitle>
<pages>318--329</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3469" citStr="Moschitti, 2006" startWordPosition="537" endWordPosition="538">e the global structural information available to the system as follows: first, a base parser produces several DT hypotheses; and then a classifier exploits the entire information in each hypothesis, e.g., the complete DT with its dependencies, for selecting the best DT. Designing features capturing such global properties is however not trivial as it requires the selection of important DT fragments. This means selecting subtree patterns from an exponential feature space. An alternative approach is to implicitly generate the whole feature space using tree kernels (TKs) (Collins and Duffy, 2002; Moschitti, 2006). In this paper, we present reranking models for discourse parsing based on Support Vector Machines (SVMs) and TKs. The latter allows us to represent structured data using the substructure space thus capturing structural dependencies between DT constituents, which is essential for effective discourse parsing. Specifically, we made the following contributions. First, we extend the 2049 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2049–2060, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics e e 5 6 (a) A hu</context>
<context position="7355" citStr="Moschitti, 2006" startWordPosition="1143" endWordPosition="1144">m 55.8% to 57.3%, an error reduction of 3.4%. In the rest of the paper, after introducing the TK technology in Section 2, we illustrate our novel structures, and how they lead to the design of novel DISCTKs in Section 3. We present the kbest discourse parser in Section 4. In Section 5, we describe our reranking approach using DISCTKs. We report our experiments in Section 6. We briefly overview the related work in Section 7, and finally, we summarize our contributions in Section 8. 2 Kernels for Structural Representation Tree kernels (Collins and Duffy, 2002; ShaweTaylor and Cristianini, 2004; Moschitti, 2006) are a viable alternative for representing arbitrary subtree structures in learning algorithms. Their basic idea is that kernel-based learning algorithms, e.g., SVMs or perceptron, only need the scalar product between the feature vectors representing the data instances to learn and classify; and kernel functions compute such scalar products in an efficient way. In the following subsections, we briefly describe the kernel machines and three types of tree kernels (TKs), which efficiently compute the scalar product in the subtree space, where the vector components are all possible substructures o</context>
<context position="12354" citStr="Moschitti, 2006" startWordPosition="2111" endWordPosition="2112">er set of tree fragments. Given a target tree T, PTK can generate any subset of connected nodes of T, whose edges are in T. For example, Figure 3 shows a tree with its nine fragments including all single nodes (i.e., the leaves of T). PTK is more general than STK as its fragments can include any subsequence of children of a target node. The time complexity of PTK is O(pρ2|NT1||NT2|), where p is the largest subsequence of children that one wants to consider and ρ is the maximal out-degree observed in the two trees. However, the average running time again tends to be linear for syntactic trees (Moschitti, 2006). 3 Discourse Tree Kernels (DISCTK) Engineering features that can capture the dependencies between DT constituents is a difficult task. In principle, any dependency between words, relations and structures (see Figure 1) can be an important feature for discourse parsing. This may lead to an exponential number of features, which makes the feature engineering process very hard. The standard TKs described in the previous section serve as a viable option to get useful subtree features automatically. However, the definition of the input to a TK, i.e., the tree representing a training instance, is ex</context>
<context position="29267" citStr="Moschitti, 2006" startWordPosition="5013" endWordPosition="5014">ns defined by Carlson and Marcu (2001). We create the training data for the reranker in a 5-fold cross-validation fashion.8 Specifically, we split the training set into 5 equal-sized folds, and train the parsing model on 4 folds and apply to the rest to produce k most probable DTs for each text. Then we generate and label the pairs (by comparing with the gold) from the k most probable trees as described in Section 5.1. Finally, we merge the 5 labeled folds to create the full training data. SVM Reranker. We use SVM-light-TK to train our reranking models,9 which enables the use of tree kernels (Moschitti, 2006) in SVM-light (Joachims, 1999). We build our new kernels for reranking exploiting the standard built-in TK functions, such as STK, STKb and PTK. We applied 8Note that our earlier experiments with a 2-fold cross validation process yielded only 50% of our current improvement. 9http://disi.unitn.it/moschitti/Tree-Kernel.htm 2055 a linear kernel to standard feature vectors as it showed to be the best on our development set. Metrics. The standard procedure to evaluate discourse parsing performance is to compute Precision, Recall and f-score of the unlabeled and labeled metrics proposed by Marcu (20</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient Convolution Kernels for Dependency and Constituent Syntactic Trees. In 17th European Conference on Machine Learning, pages 318–329. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel Engineering for Fast and Easy Design of Natural Language Applications.</title>
<date>2010</date>
<booktitle>In COLING (Tutorials),</booktitle>
<pages>1--91</pages>
<contexts>
<context position="10224" citStr="Moschitti, 2010" startWordPosition="1693" endWordPosition="1694">dering the whole fragment space. A TK function over T1 and T2 is defined as: TK(T1,T2) = P Pn2∈NT2 Δ(n1,n2), n1∈NT1 where NT1 and NT2 are the sets of the nodes of T1 and T2, respectively, and Δ(n1, n2) is equal to the number of common fragments rooted in the n1 and n2 nodes.2 The computation of Δ function depends on the shape of fragments, conversely, a different Δ determines the richness of the kernel space and thus different tree kernels. In the following, we briefly describe two existing and well-known tree kernels. Please see several tutorials on kernels (Moschitti, 2013; Moschitti, 2012; Moschitti, 2010) for more details.3 Syntactic Tree Kernels (STK) produce fragments such that each of their nodes includes all or none of its children. Figure 2 shows a tree T and its three fragments (do not consider the single nodes) in the STK space on the left and right of the ar2To get a similarity score between 0 and 1, it is common to apply a normalization in the kernel space, T K(T1,T2) i.e. S Figure 3: A tree with its PTK fragments. row, respectively. STK(T ,T ) counts the number tree. Te outdegree of a nod r an ordered tree rresponds t the number of its d d of common fragments, which in this case is t</context>
<context position="27580" citStr="Moschitti, 2010" startWordPosition="4729" endWordPosition="4730"> Figure 4), number of nodes connecting two relational nodes, number of nodes connecting a relational node and an EDU, number of nodes that connects a relational node as left child and an EDU as right child, and vice versa. Relation Features. We encode the relations in the DT as bag-of-relations (i.e., frequency count). This will allow us to assess the impact of a flat representation of the DT. Note that more important relational features would be the subtree patterns extracted from the DT. However, they are already generated by TKs in a simpler way. See (Pighin and Moschitti, 2009; Pighin and Moschitti, 2010) for a way to extract the most relevant features from a model learned in the kernel space. 6 Experiments Our experiments aim to show that reranking of discourse parses is a promising research direction, which can improve the state-of-the-art. To achieve this, we (i) compute the oracle accuracy of the kbest parser, (ii) test different kernels for reranking discourse parses by applying standard kernels to our new structures, (iii) show the reranking performance using the best kernel for different number of hypotheses, and (iv) show the relative importance of features coming from different source</context>
</contexts>
<marker>Moschitti, 2010</marker>
<rawString>Alessandro Moschitti. 2010. Kernel Engineering for Fast and Easy Design of Natural Language Applications. In COLING (Tutorials), pages 1–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>State-of-the-Art Kernels for Natural Language Processing.</title>
<date>2012</date>
<booktitle>In Tutorial Abstracts ofACL 2012,</booktitle>
<pages>2</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="10206" citStr="Moschitti, 2012" startWordPosition="1691" endWordPosition="1692"> explicitly considering the whole fragment space. A TK function over T1 and T2 is defined as: TK(T1,T2) = P Pn2∈NT2 Δ(n1,n2), n1∈NT1 where NT1 and NT2 are the sets of the nodes of T1 and T2, respectively, and Δ(n1, n2) is equal to the number of common fragments rooted in the n1 and n2 nodes.2 The computation of Δ function depends on the shape of fragments, conversely, a different Δ determines the richness of the kernel space and thus different tree kernels. In the following, we briefly describe two existing and well-known tree kernels. Please see several tutorials on kernels (Moschitti, 2013; Moschitti, 2012; Moschitti, 2010) for more details.3 Syntactic Tree Kernels (STK) produce fragments such that each of their nodes includes all or none of its children. Figure 2 shows a tree T and its three fragments (do not consider the single nodes) in the STK space on the left and right of the ar2To get a similarity score between 0 and 1, it is common to apply a normalization in the kernel space, T K(T1,T2) i.e. S Figure 3: A tree with its PTK fragments. row, respectively. STK(T ,T ) counts the number tree. Te outdegree of a nod r an ordered tree rresponds t the number of its d d of common fragments, which</context>
<context position="24785" citStr="Moschitti, 2012" startWordPosition="4256" endWordPosition="4257">ssification of k hypotheses (paired with the empty one) is needed in practice, thus the complexity is only O(k). 7Structural kernels, e.g., TKs, cannot be used in more advanced algorithms working in structured output spaces, e.g., SVMstruct. Indeed, to our knowledge, no one could successfully find a general and exact solution for the argmax equation, typically part of such advanced models, when structural kernels are used. Some approximate solutions for simple kernels, e.g., polynomial or gaussian kernels, are given in (Joachims and Yu, 2009), whereas (Severyn and Moschitti, 2011; Severyn and Moschitti, 2012) provide solutions for using the cutting-plane algorithm (which requires argmax computation) with structural kernels but in binary SVMs. 2054 Since in our problem a pair of hypotheses (hi, hj) constitutes a data instance, we now need to define the kernel between the pairs. However, notice that DISCTK only works on a single pair. Considering that our task is to decide whether hi is better than hj, it can be convenient to represent the pairs in terms of differences between the vectors of the two hypotheses, i.e., φK(hi) − φK(hj), where K (i.e., DISCTK) is defined between two hypotheses (not on t</context>
</contexts>
<marker>Moschitti, 2012</marker>
<rawString>Alessandro Moschitti. 2012. State-of-the-Art Kernels for Natural Language Processing. In Tutorial Abstracts ofACL 2012, page 2, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel-based Learning to Rank with Syntactic and Semantic Structures.</title>
<date>2013</date>
<booktitle>In SIGIR,</booktitle>
<pages>1128</pages>
<contexts>
<context position="10189" citStr="Moschitti, 2013" startWordPosition="1689" endWordPosition="1690">T1 and T2 without explicitly considering the whole fragment space. A TK function over T1 and T2 is defined as: TK(T1,T2) = P Pn2∈NT2 Δ(n1,n2), n1∈NT1 where NT1 and NT2 are the sets of the nodes of T1 and T2, respectively, and Δ(n1, n2) is equal to the number of common fragments rooted in the n1 and n2 nodes.2 The computation of Δ function depends on the shape of fragments, conversely, a different Δ determines the richness of the kernel space and thus different tree kernels. In the following, we briefly describe two existing and well-known tree kernels. Please see several tutorials on kernels (Moschitti, 2013; Moschitti, 2012; Moschitti, 2010) for more details.3 Syntactic Tree Kernels (STK) produce fragments such that each of their nodes includes all or none of its children. Figure 2 shows a tree T and its three fragments (do not consider the single nodes) in the STK space on the left and right of the ar2To get a similarity score between 0 and 1, it is common to apply a normalization in the kernel space, T K(T1,T2) i.e. S Figure 3: A tree with its PTK fragments. row, respectively. STK(T ,T ) counts the number tree. Te outdegree of a nod r an ordered tree rresponds t the number of its d d of common</context>
</contexts>
<marker>Moschitti, 2013</marker>
<rawString>Alessandro Moschitti. 2013. Kernel-based Learning to Rank with Syntactic and Semantic Structures. In SIGIR, page 1128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniele Pighin</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Reverse Engineering of Tree Kernel Feature Spaces. In</title>
<date>2009</date>
<booktitle>EMNLP,</booktitle>
<pages>111--120</pages>
<contexts>
<context position="27551" citStr="Pighin and Moschitti, 2009" startWordPosition="4723" endWordPosition="4726">des connecting two EDUs (i.e., SPANs in Figure 4), number of nodes connecting two relational nodes, number of nodes connecting a relational node and an EDU, number of nodes that connects a relational node as left child and an EDU as right child, and vice versa. Relation Features. We encode the relations in the DT as bag-of-relations (i.e., frequency count). This will allow us to assess the impact of a flat representation of the DT. Note that more important relational features would be the subtree patterns extracted from the DT. However, they are already generated by TKs in a simpler way. See (Pighin and Moschitti, 2009; Pighin and Moschitti, 2010) for a way to extract the most relevant features from a model learned in the kernel space. 6 Experiments Our experiments aim to show that reranking of discourse parses is a promising research direction, which can improve the state-of-the-art. To achieve this, we (i) compute the oracle accuracy of the kbest parser, (ii) test different kernels for reranking discourse parses by applying standard kernels to our new structures, (iii) show the reranking performance using the best kernel for different number of hypotheses, and (iv) show the relative importance of features</context>
</contexts>
<marker>Pighin, Moschitti, 2009</marker>
<rawString>Daniele Pighin and Alessandro Moschitti. 2009. Reverse Engineering of Tree Kernel Feature Spaces. In EMNLP, pages 111–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniele Pighin</author>
<author>Alessandro Moschitti</author>
</authors>
<title>On Reverse Feature Engineering of Syntactic Tree Kernels.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>223--233</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="27580" citStr="Pighin and Moschitti, 2010" startWordPosition="4727" endWordPosition="4730">., SPANs in Figure 4), number of nodes connecting two relational nodes, number of nodes connecting a relational node and an EDU, number of nodes that connects a relational node as left child and an EDU as right child, and vice versa. Relation Features. We encode the relations in the DT as bag-of-relations (i.e., frequency count). This will allow us to assess the impact of a flat representation of the DT. Note that more important relational features would be the subtree patterns extracted from the DT. However, they are already generated by TKs in a simpler way. See (Pighin and Moschitti, 2009; Pighin and Moschitti, 2010) for a way to extract the most relevant features from a model learned in the kernel space. 6 Experiments Our experiments aim to show that reranking of discourse parses is a promising research direction, which can improve the state-of-the-art. To achieve this, we (i) compute the oracle accuracy of the kbest parser, (ii) test different kernels for reranking discourse parses by applying standard kernels to our new structures, (iii) show the reranking performance using the best kernel for different number of hypotheses, and (iv) show the relative importance of features coming from different source</context>
</contexts>
<marker>Pighin, Moschitti, 2010</marker>
<rawString>Daniele Pighin and Alessandro Moschitti. 2010. On Reverse Feature Engineering of Syntactic Tree Kernels. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 223–233, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Fast Support Vector Machines for Structural Kernels. In</title>
<date>2011</date>
<journal>ECML/PKDD</journal>
<volume>3</volume>
<pages>175--190</pages>
<contexts>
<context position="24755" citStr="Severyn and Moschitti, 2011" startWordPosition="4250" endWordPosition="4253">by Collins and Duffy (2002), only the classification of k hypotheses (paired with the empty one) is needed in practice, thus the complexity is only O(k). 7Structural kernels, e.g., TKs, cannot be used in more advanced algorithms working in structured output spaces, e.g., SVMstruct. Indeed, to our knowledge, no one could successfully find a general and exact solution for the argmax equation, typically part of such advanced models, when structural kernels are used. Some approximate solutions for simple kernels, e.g., polynomial or gaussian kernels, are given in (Joachims and Yu, 2009), whereas (Severyn and Moschitti, 2011; Severyn and Moschitti, 2012) provide solutions for using the cutting-plane algorithm (which requires argmax computation) with structural kernels but in binary SVMs. 2054 Since in our problem a pair of hypotheses (hi, hj) constitutes a data instance, we now need to define the kernel between the pairs. However, notice that DISCTK only works on a single pair. Considering that our task is to decide whether hi is better than hj, it can be convenient to represent the pairs in terms of differences between the vectors of the two hypotheses, i.e., φK(hi) − φK(hj), where K (i.e., DISCTK) is defined be</context>
</contexts>
<marker>Severyn, Moschitti, 2011</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2011. Fast Support Vector Machines for Structural Kernels. In ECML/PKDD (3), pages 175–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Fast Support Vector Machines for Convolution Tree Kernels.</title>
<date>2012</date>
<journal>Data Min. Knowl. Discov.,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="24785" citStr="Severyn and Moschitti, 2012" startWordPosition="4254" endWordPosition="4257">only the classification of k hypotheses (paired with the empty one) is needed in practice, thus the complexity is only O(k). 7Structural kernels, e.g., TKs, cannot be used in more advanced algorithms working in structured output spaces, e.g., SVMstruct. Indeed, to our knowledge, no one could successfully find a general and exact solution for the argmax equation, typically part of such advanced models, when structural kernels are used. Some approximate solutions for simple kernels, e.g., polynomial or gaussian kernels, are given in (Joachims and Yu, 2009), whereas (Severyn and Moschitti, 2011; Severyn and Moschitti, 2012) provide solutions for using the cutting-plane algorithm (which requires argmax computation) with structural kernels but in binary SVMs. 2054 Since in our problem a pair of hypotheses (hi, hj) constitutes a data instance, we now need to define the kernel between the pairs. However, notice that DISCTK only works on a single pair. Considering that our task is to decide whether hi is better than hj, it can be convenient to represent the pairs in terms of differences between the vectors of the two hypotheses, i.e., φK(hi) − φK(hj), where K (i.e., DISCTK) is defined between two hypotheses (not on t</context>
</contexts>
<marker>Severyn, Moschitti, 2012</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2012. Fast Support Vector Machines for Convolution Tree Kernels. Data Min. Knowl. Discov., 25(2):325–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence Level Discourse Parsing Using Syntactic and Lexical Information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -</booktitle>
<volume>1</volume>
<pages>149--156</pages>
<publisher>ACL.</publisher>
<location>Edmonton, Canada.</location>
<contexts>
<context position="40861" citStr="Soricut and Marcu (2003)" startWordPosition="6942" endWordPosition="6945">mocrat from state Maine) elaborates its preceding text. This confuses our reranker. We also found error examples where the reranker failed to distinguish between Background and Elaboration, and between Cause and Elaboration. This suggests that we need rich semantic representation of the text to improve our reranker further. 7 Related Work Early work on discourse parsing applied handcoded rules based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modelin</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence Level Discourse Parsing Using Syntactic and Lexical Information. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL’03, pages 149–156, Edmonton, Canada. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Sporleder</author>
<author>Mirella Lapata</author>
</authors>
<title>Discourse Chunking and its Application to Sentence Compression.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLTEMNLP’05,</booktitle>
<pages>257--264</pages>
<publisher>ACL.</publisher>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="41009" citStr="Sporleder and Lapata (2005)" startWordPosition="6960" endWordPosition="6963">tinguish between Background and Elaboration, and between Cause and Elaboration. This suggests that we need rich semantic representation of the text to improve our reranker further. 7 Related Work Early work on discourse parsing applied handcoded rules based on discourse cues and surface patterns (Marcu, 2000a). Supervised learning was first attempted by Marcu (2000b) to build a shiftreduce discourse parser. This work was then considerably improved by Soricut and Marcu (2003). They presented probabilistic generative models for sentence-level discourse parsing based on lexicosyntactic patterns. Sporleder and Lapata (2005) investigated the necessity of syntax in discourse analysis. More recently, Hernault et al. (2010) presented the HILDA discourse parser that iteratively employs two SVM classifiers in pipeline to build a DT in a greedy way. Feng and Hirst (2012) improved the HILDA parser by incorporating rich linguistic features, which include lexical semantics and discourse production rules. Joty et al. (2013) achieved the best prior results by (i) jointly modeling the structure and the label of a DT constituent, (ii) performing optimal rather than greedy decoding, and (iii) discriminating between intra- and </context>
</contexts>
<marker>Sporleder, Lapata, 2005</marker>
<rawString>Caroline Sporleder and Mirella Lapata. 2005. Discourse Chunking and its Application to Sentence Compression. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLTEMNLP’05, pages 257–264, Vancouver, British Columbia, Canada. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
<author>Khashayar Rohanimanesh</author>
</authors>
<title>Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence Data.</title>
<date>2007</date>
<journal>Journal of Machine Learning Research (JMLR),</journal>
<pages>8--693</pages>
<contexts>
<context position="18278" citStr="Sutton et al., 2007" startWordPosition="3102" endWordPosition="3105">es correlate very well with discourse boundaries. For example, more than 95% of the sentences in RSTDT have a well-formed discourse subtree in the full document-level discourse tree. The choice of using two separate models for intra- and multi-sentential parsing is well justified for the following two reasons: (i) it has been observed that discourse relations have different distributions in the two parsing scenarios, and (ii) the models could independently pick their own informative feature sets. The parsing model used for intra-sentential parsing is a Dynamic Conditional Random Field (DCRF) (Sutton et al., 2007) shown in Figure 7. The observed nodes Uj at the bottom layer represent the discourse units at a certain level of the DT; the binary nodes 5j at the middle layer predict whether two adjacent units Uj_1 and Uj should be connected or not; and the multi-class nodes Rj at the top layer predict the discourse relation between Uj_1 and Uj. Notice that the model represents the structure and the label of a DT constituent jointly, and captures the sequential dependencies between the DT constituents. Since the chain-structured DCRF model does not scale up to multi-sentential parsing of long documents, Fi</context>
</contexts>
<marker>Sutton, McCallum, Rohanimanesh, 2007</marker>
<rawString>Charles Sutton, Andrew McCallum, and Khashayar Rohanimanesh. 2007. Dynamic Conditional Random Fields: Factorized Probabilistic Models for Labeling and Segmenting Sequence Data. Journal of Machine Learning Research (JMLR), 8:693–723.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>