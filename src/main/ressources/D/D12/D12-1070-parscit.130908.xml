<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999362">
Cross-Lingual Language Modeling with Syntactic Reordering for
Low-Resource Speech Recognition
</title>
<author confidence="0.997377">
Ping Xu and Pascale Fung
</author>
<affiliation confidence="0.995628666666667">
Human Language Technology Center
Department of Electronic and Computer Engineering
The Hong Kong University of Science and Technology, Clear Water Bay, Hong Kong
</affiliation>
<email confidence="0.98531">
xuping@ust.hk, pascale@ece.ust.hk
</email>
<sectionHeader confidence="0.994859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999868">
This paper proposes cross-lingual language
modeling for transcribing source resource-
poor languages and translating them into tar-
get resource-rich languages if necessary. Our
focus is to improve the speech recognition
performance of low-resource languages by
leveraging the language model statistics from
resource-rich languages. The most challeng-
ing work of cross-lingual language modeling
is to solve the syntactic discrepancies between
the source and target languages. We therefore
propose syntactic reordering for cross-lingual
language modeling, and present a first result
that compares inversion transduction grammar
(ITG) reordering constraints to IBM and lo-
cal constraints in an integrated speech tran-
scription and translation system. Evaluations
on resource-poor Cantonese speech transcrip-
tion and Cantonese to resource-rich Mandarin
translation tasks show that our proposed ap-
proach improves the system performance sig-
nificantly, up to 3.4% relative WER reduction
in Cantonese transcription and 13.3% relative
bilingual evaluation understudy (BLEU) score
improvement in Mandarin transcription com-
pared with the system without reordering.
</bodyText>
<sectionHeader confidence="0.998127" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999887975">
Statistical language modeling techniques have
achieved remarkable success in speech and language
processing (Clarkson and Rosenfeld, 1997; Stolcke,
2002). However, this success largely depends on the
availability of a large amount of suitable text data in
a language. Without sufficient text data for training,
it is very difficult to build a practical and usable sta-
tistical language model. Therefore, most of the ad-
vances have been reported in so called resource-rich
language such as English, Mandarin and Japanese,
after creating linguistic resources of these languages
at considerable cost. Today there are more than
6000 living languages spoken in the world (Gordon
et al., 2005), and most of them have little transcribed
texts and are considered as resource-poor languages
(Nakov and Ng, 2009). Many of these languages are
actually spoken by a huge number of speakers (e.g.
some Chinese and Indian languages), and thus there
is still a great demand to build speech and language
processing systems for these languages.
Owing to data scarcity, most often an interpo-
lation (Bellegarda, 2004) of language models be-
tween a resource-poor language and a resource-rich
language is used in most low-resource ASR sys-
tems. Some researchers have proposed transform-
ing resource-rich language models to resource-poor
language models by word-level transduction, either
in a context-independent or context-dependent man-
ner (Hori et al., 2003; Akita and Kawahara, 2006;
Jensson et al., 2009; Neubig et al., 2010). In (Jens-
son et al., 2009), a simple dictionary based context-
independent transduction from a resource-rich lan-
guage to a resource-poor language is exploited to
improve speech recognition of the resource-poor
language. In (Hori et al., 2003; Akita and Kawahara,
2006; Neubig et al., 2010), context-dependent trans-
duction is exploited. In their case, the resource-poor
language is a spoken language, and the resource-rich
language is a written language. They carried out lan-
guage model transformation since the input speech
</bodyText>
<note confidence="0.927257333333333">
766
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 766–776, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999677975609756">
is in speaking-style and the output text is in written-
style.
Others have investigated cross-lingual informa-
tion between a resource-poor language and a
resource-rich language. In (Khudanpur and Kim,
2002), cross-language cues are used to improve a
language model of a resource-poor language. They
used cross-lingual unigram probabilities trained
from a story-specific parallel corpus of the resource-
poor and resource-rich languages. They interpo-
late the language model of the resource-poor lan-
guage with those unigram probabilities. In (Kim and
Khudanpur, 2003), an n-gram language model in a
resource-poor language is interpolated with cross-
lingual unigram trigger probabilities. These triggers
are word pairs of the resource-poor and resource-
rich languages with the highest mutual information
across these two languages. Another way of esti-
mating those unigram probabilities is using latent
semantic analysis by measuring cosine similarities
from a document-aligned corpus for any given word
pair (Kim and Khudanpur, 2004).
Both interpolation and word-level transduction
approaches fail to meet the challenge of syntac-
tic discrepancies between the resource-poor and
resource-rich languages. This syntactic discrepan-
cies exist, for example, even between the Sinitic lan-
guages and Indian languages1 of the same family.
Sinitic languages such as Cantonese/Yue, Shang-
hai/Wu, etc. are officially considered as ”dialects”
of the standard Chinese Mandarin (or Putonghua)2.
However, they differ greatly from Mandarin in all
aspects and are not mutually comprehensible. For
instance, in addition to lexical and pronunciation
differences, Cantonese Chinese (Lee, 2011) differs
syntactically from Mandarin as well - we found that
there are approximately 10% syntactic inversions
between sentences of the two forms of Chinese.
We suggest that a better approach than interpo-
lation and word-level transduction is to use cross-
lingual language modeling with syntactic reorder-
</bodyText>
<footnote confidence="0.853893">
1For example, Hindi and Malayalam (Geethakumary, 2002).
2Since Cantonese does not have an official written form,
</footnote>
<bodyText confidence="0.954280945945946">
there are very few written texts available for training language
models. In this paper, we treat Cantonese as a typical resource-
poor language and Mandarin as a typical resource-rich lan-
guage. This language pair will be used for illustration purposes
throughout this paper.
ing. A reordering model with reordering constraints,
such as ITG constraints (Wu, 1997), IBM con-
straints (Berger et al., 1996), and local constraints
(Kumar and Byrne, 2005) can account for the syn-
tactic differences. It has been shown in (Zens and
Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007)
that ITG constraints perform better than other con-
straints when tackling the reordering between many
language pairs. Previous work on weighted finite-
state transducer (WFST) based speech translation
such as (Casacuberta et al., 2004; Zhou et al., 2005;
Zhou et al., 2006; Mathias and Byrne, 2006; Ma-
tusov et al., 2006; Saon and Picheny, 2007) only
train the reordering model using IBM constraints,
local constraints or ad hoc rules. We will use
ITG constraints, which have only been applied to
text translation tasks before, to model the syntactic
differences in cross-lingual language modeling for
speech recognition.
We will implement a cross-lingual language
model using WFSTs, and integrate it into a WFST-
based speech recognition search space to give both
resource-poor language and resource-rich language
transcriptions. This creates an integrated speech
transcription and translation framework.
This paper is organized as follows: Section 2
presents our proposed cross-lingual language mod-
eling with syntactic reordering. In Section 3, we dis-
cuss speech recognition with cross-lingual language
models. Section 4 and 5 give the experimental setup
and results. We conclude our work at the end of this
paper.
</bodyText>
<sectionHeader confidence="0.90744" genericHeader="method">
2 Cross-lingual Language Modeling with
</sectionHeader>
<subsectionHeader confidence="0.852493">
Syntactic Reordering
</subsectionHeader>
<bodyText confidence="0.99982825">
In automatic speech recognition (ASR), given an ob-
served source speech vector X, the decoding pro-
cess searches the best word sequence vI1 (consists
of words v1, v2,..., vI) by maximizing the posterior
probability P(vI1|X), where vI1 is the source tran-
script representing the transcription of the source
speech (see Eq. (1)). According to Bayes’ law,
we can decompose P(vI1|X) into an acoustic model
P(X|vI1) and a language model P(vI1). If a source
language Lv is a resource-rich language, then the
language model P(vI1) can be well estimated from
sufficient training texts. However, if the source lan-
</bodyText>
<page confidence="0.689812">
767
</page>
<bodyText confidence="0.983935666666667">
guage Lv is a resource-poor language, then the lan-
guage model P(vI1) cannot be reliably or robustly
estimated due to lack of training texts.
</bodyText>
<equation confidence="0.748188">
vI1 = arg max P(vI1|X) (1)
</equation>
<table confidence="0.9116335">
vI
1
=arg max P(X|vI1)P(vI1)
vI
1
= arg max 1: P(vI1|wJ1 )P(wJ1 )
vI P(X|vI 1)
1 w�
1
≈ arg max P(X|vI1)max P(vI1|wJ1 )P(wJ1 )
vI w�
1 1
</table>
<bodyText confidence="0.997252454545455">
Since this paper tackles the language modeling
challenge for low-resource speech recognition, here
we just assume that the source language Lv is a
resource-poor language. We further assume that
there is a target language Lw, which is a resource-
rich language closely related to the language Lv.
In order to improve the language model P(vI1)
of the resource-poor language Lv, we introduce
cross-lingual language modeling by decomposing
the language model P(vI1) into a translation model
P(vI1|wJ1 ) and a language model P(wJ1 ) of the
resource-rich language Lw (see Eq. (1)). wJ1 is
the target resource-rich language transcript that con-
sists of words w1, w2,..., wJ. P(vI1|wJ1 )P(wJ1 ) is
defined as a cross-lingual language model. It lever-
ages the abundant statistics from the language model
P(wJ1 ) to improve the language model P(vI1) of the
resource-poor language.
The translation model P(vI1|wJ1 ) can be esti-
mated by addressing the discrepancies between the
resource-poor language Lv and the resource-rich
language Lw, which can be modeled from a paral-
lel corpus of the Lv transcript vI1 and the Lw tran-
script wJ1 . For the syntactic inversions, we reorder
the word or phrase positions of the Lw language
model into those of the Lv language model. We
have observed that most of the words are aligned
monotonically between Lv and Lw within a phrase.
This paper, therefore only considers phrase-level re-
ordering, which effectively preserves the monotonic
word sequences within phrases, and significantly re-
duces the number of reordering paths compared with
word-level reordering.
</bodyText>
<subsectionHeader confidence="0.9659315">
2.1 Preprocessing: Phrase Extraction and
Segmentation
</subsectionHeader>
<bodyText confidence="0.955593333333333">
Our discussion starts with phrase extraction from the
parallel corpus. We define a phrase sequence vK1
(consists of phrases v1, v2, ..., vK) segmented from
the word-level Lv transcript vI1 and wK1 (consists of
phrases w1, w2, ..., wK) segmented from the word-
level Lw transcript wJ1 . Furthermore, we define a
reordering sequence rK1 , of which the detail can be
found in Section 2.2.
The phrase-level translation model P(vI1|wJ1 ) is
decomposed into four components (see Eq. (2)):
segmentation model P( wK 1 |wJ1), phrasal reorder-
ing model P(rK1  |wK1 ,wJ1 ), phrase-to-phrase trans-
K,
duction model P( vK1  |rK1 171 wJ1 ) and reconstruc-
tion model P(vI1 |vK1 ,rK1 , wK1 ,wJ1 ). Before present-
ing each component model, we need to extract two
phrase tables for the Lv transcript and the Lw tran-
script, respectively.
</bodyText>
<equation confidence="0.999819285714286">
P(vI1|wJ1 ) ≈ max
K K K
v1 ,r1 , wl
P(rK1  |wK1 , wJ1 ) ·
P(vP( vK 1 |rK1 , wK1 , wJ1 ) ·
I K K K J
1  |v1 , r1 , w1 , w1 ) (2)
</equation>
<bodyText confidence="0.999940714285714">
The phrase extraction is based on word-to-word
alignments of the parallel corpus. We train word
alignments in both directions with GIZA++, and
then symmetrize the two alignments using the re-
fined method (Och and Ney, 2003). Figure 1 shows
an example of word-to-word alignment results be-
tween an Lv transcript (Cantonese) and an Lw
transcript (Mandarin), from which phrase-to-phrase
alignments are derived by identifying deletion, sub-
stitution, insertion and inversion.
Prior to phrasal reordering, the segmentation
model P( wK1 |wJ1 ) implemented by a segmentation
WFST 5w is applied to segment a word sequence
wJ1 in the Lw language model into a phrase sequence
{ w1, w2, ..., wK}. The maximum number of words
that can be segmented into one phrase is controlled
by a segmentation order s. An example of 5w is
shown in Figure 3(a1). It segments a word sequence
{w1, w2, w3} into a phrase sequence {w1, w2 w3}
after performing composition (Mohri, 2009) with the
target Lw language model (see Figure 3(b1 &amp; b2))3.
</bodyText>
<equation confidence="0.970305">
3The “ ” symbol is used to indicate the concatenation of con-
P( wK1 |wJ1 ) ·
</equation>
<page confidence="0.537882">
768
</page>
<subsectionHeader confidence="0.679949">
Substitution Substitution Deletion Substitution Inversion Inversion &amp; Insertion
</subsectionHeader>
<figureCaption confidence="0.938371166666667">
Figure 1: An example (in English: Please give me an ad-
dress first) of phrase extraction from word-to-word align-
ments. i and j are word indexes. k′ and k are phrase
indexes. i↔j represents the word-to-word alignment.
k↔k′ represents the indentified phrase-to-phrase align-
ment.
</figureCaption>
<subsectionHeader confidence="0.997378">
2.2 Phrasal Reordering Model
</subsectionHeader>
<bodyText confidence="0.97297495">
Given a phrase sequence { w1, w2, ..., CVK} of the
Lw transcript, the role of the reordering model
P(rK1  |wK1 ,wJ1 ) is to reorder phrase positions of the
Lw transcript into those of the Lv transcript by per-
mutation of wK1 according to a reordering sequence
{rK The
1 : rk ∈ {1, 2, ..., K}, rk =6 rk′�k}.
phrase sequence { w1, w2, ..., wK} is therefore re-
ordered into { wr1, 27vr2, ..., wrK } consequently (see
Figure 2 where K = 3). Since arbitrary permuta-
tions of K phrases are NP-hard (Knight, 1999), re-
ordering constraints have to be set over rK1 to reduce
the number of permutations.
There are three reordering constraints widely used
in statistical machine translation, namely local con-
straints, IBM constraints and ITG constraints. Here
we would like to point out that this is the first
time that reordering constraints have been incorpo-
rated into a cross-lingual language model for speech
recognition.
</bodyText>
<subsectionHeader confidence="0.854948">
Reordering Constraints
</subsectionHeader>
<bodyText confidence="0.9784966">
Local constraints make the restriction that one
phrase can jump at most L−1 phrases either forward
or backward, where L is the reordering distance (or
window size of permutation)4. The generation of rK1
under local constraints can be viewed as solving of
the following problem (Kløve, 2009):
secutive words forming a phrase.
4The concept of reordering distance also applies to other
constraints.
How many permutations of
{1,2,... k ..., K} satisfy |rk − k |&lt; L
for all k?
IBM constraints, a superset of local constraints
(Dreyer et al., 2007), generate permutations rK 1 de-
viate from the monotonic phrase order {rK1 : rk =
k}. More specifically, any phrase position rk can be
selected from the positions of the first m yet uncov-
ered phrases (see Eq. (3)). A typical value of m is 4
(Zens and Ney, 2003), and we write IBM constraints
with m = 4 as IBM(4).
</bodyText>
<construct confidence="0.97451325">
{ {1, 2, ..., k − 1 + m; rk =6 rk′=,4k}
if k ≤ K + 1 − m,
{1, 2, ..., K; rk =6 rk′�k}
if K + 1 − m &lt; k ≤ K.
</construct>
<bodyText confidence="0.974555774193548">
ITG constraints provide a more faithful coverage
of syntactic reordering in the parallel data than lo-
cal constraints and IBM constraints. Our presenta-
tion of ITG constraints starts with defining of some
permutation sets. Let SK be the set of permuta-
tions on {1,2,...,K}. A permutation rK1 ∈ SK,
where rK1 = r1r2 ... rK, contains a subsequence
of type τ ∈ SM if and only if a sequence of in-
dices 1 ≤ i1 &lt; i2 &lt; ... &lt; iM ≤ K exists such
that ri1ri2 ... rim has all the same pairwise compar-
isons as τ. We denote the set of permutations of SK
not containing subsequences of type τ by SK(τ). If
we have sets SK(τ1), ... , SK(τp), we denote the set
SK(τ1) ∩ ... ∩ SK(τp) by SK(τ1, ... , τp) (Barcucci
et al., 2000). ITG constraints allow the permutation
set SK(3142, 2413), which forbids subsequence of
type (3, 1, 4, 2) and its dual (2, 4, 1, 3). Explicitly,
ITG constraints avoid any permutation rK1 satisfy-
ing either ri2 &lt; ri¢ &lt; ri1 &lt; ri3 or ri3 &lt; ri1 &lt;
ri¢ &lt; ri2, where 1 ≤ i1 &lt; i2 &lt; i3 &lt; i4 ≤ K. In
(Wu, 1997), these forbidden subsequences are called
“inside-out” transpositions. They are fairly distorted
matchings, and hardly observed in real parallel data.
In order to get an intuitive sense of the reordering
capability of those three constraints, we list the num-
ber of permutations under local constraints, IBM
constraints as well as ITG constraints5 in Table 1.
5Interestingly, when K = L, the number of permuta-
tions under ITG constraints NITG = |SK(3142, 2413)|, and
|SK(3142, 2413) |equals the K −1-th Schr¨oder numbers sK−1
(Ehrenfeucht et al., 1998)
</bodyText>
<figure confidence="0.994513807017544">
i j
1-1
2-2
3-4
4-6
4-7
5-8
6-5
7-3 8-3
i
1
3
4
5
6
7
8
␩ᶨὪ
k’=1
恋
1 2
k=1
Ἀ
Ἀ
k=2
⃰
3
k’=2
ᾦ
k=3
䴎
4
k’=3
ᾳ
k=4
ㆹ ᶨ ᾳ
5
⛘⛨
k’=4
6 7
k=5
k’=5
ㆹ
⛘⛨
k=6
8
⃰ ⏨
k’=6
2
vi
v~k&apos;
wk~
wj
j
rk ∈
(3)
769
</figure>
<tableCaption confidence="0.985643">
Table 1: Comparison of permutation number under local constraints (NLocal), IBM constraints (NIBM(4)) and ITG
constraints (NITG). The comparison is constrained by the phrase number K and the reordering distance L.
</tableCaption>
<table confidence="0.9998094375">
K=2 K=3 K=4 K=5 K=6 K=7 K=8 K=9 K=10
NLocal 2 3 5 8 13 21 34 55 89
L=2 NIBM(4) 2 3 5 8 13 21 34 55 89
NITG 2 3 5 8 13 21 34 55 89
NLocal 2 6 14 31 73 172 400 932 2177
L=3 NIBM(4) 2 6 14 31 73 172 400 932 2177
NITG 2 6 12 25 57 124 268 588 1285
NLocal 2 6 24 78 230 675 2069 6404 19708
L=4 NIBM(4) 2 6 24 78 230 675 2069 6404 19708
NITG 2 6 22 52 122 321 885 2304 5880
NLocal 2 6 24 120 504 1902 6902 25231 95401
L=5 NIBM(4) 2 6 24 96 330 1066 3451 11581 39264
NITG 2 6 22 90 236 602 1714 5269 16385
NLocal 2 6 24 120 720 3720 17304 76110 329462
L=6 NIBM(4) 2 6 24 96 384 1374 4718 16275 57749
NITG 2 6 22 90 394 1108 3014 9038 29618
</table>
<bodyText confidence="0.997718526315789">
We can see that given the same K (K ≤ 10) and
L (L ≤ 6), IBM constraints have less permutations
than local constraints, and ITG constraints have less
permutations than IBM constraints in general (only
one exception when K = L = 6). These obser-
vations indicate that ITG constraints can filter out
more unlikely permutations for a fixed reordering
distance, resulting in longer distance reordering ca-
pability.
Table 1 also tells us that the phrase number K
and the reordering distance L for any of the con-
straints cannot be too large for practical implemen-
tation. For instance, if L = 6 and K goes from 6 to
7, the order of magnitude of NLocal, NIBM(4) and
NITG increases from 2 to 3. Hence, phrases for per-
mutation should be selective to cover the most pos-
sible re-orderings. If long reordering distances are
allowed, unlikely permutations should be pruned so
that the memory consumption becomes manageable.
</bodyText>
<subsectionHeader confidence="0.725344">
Reordering Sequence Distribution
</subsectionHeader>
<bodyText confidence="0.9998923">
So far we have discussed the issue that how to
generate permutations for the reordering model us-
ing reordering constraints. Another issue is how to
parameterize the reordering sequence distribution.
Both ITG constraints and other constraints assume
that all permutations are equally probable. However,
it makes sense to restrict those non-monotonic re-
orderings when performing the translation. This not
only helps the search of the most likely permutation,
but also guides the pruning of unlikely permutations.
</bodyText>
<equation confidence="0.997624833333333">
K
P(rK1  |�wK1 , wJ1 ) = P(r1) ri P(rk|rk−1, �wK1 )
k=2
K
= P(r1) ri P(rk|rk−1) (4)
k=2
</equation>
<bodyText confidence="0.966140272727273">
We make a first order Markov assumption over the
phrasal reordering model P(rK1  |wK1 , wJ1 ) (see Eq.
(4)). The reordering sequence distribution is param-
eterized to assign decreasing likelihood to phrase re-
orderings { wr1, 17vr2, ... , �wrK } that diverge from the
original word order (Och et al., 1999; Kumar et al.,
2005). Suppose wrk = wl′
l and wrk−1 = wq′ q, the
reordering sequence distribution is set as Eq. (5),
where p0 is a tuning factor. We normalize the proba-
bilities P(rk|rk−1) such that �Kk′=1,k′6=rk−1 P(rk =
</bodyText>
<equation confidence="0.955254666666667">
k′|rk−1) = 1.
P(rk|rk−1) = p|l−q′−1|
0
1 (5)
P(r1 = k) = K ; k ∈ {1, 2,..., K}
770
</equation>
<bodyText confidence="0.9997103">
Assume that we have a phrase sequence
{ ˜w1, ˜w2, ˜w3}, Figure 2 shows the phrasal reordering
model implemented by a reordering WFST Ωr under
the first order Markov assumption for this phrase se-
quence.
Figure 3(a2) gives one more example of Ωr,
which reorders the phrase sequence {w1, w2 w3}
into {w2 w3, w1}6. Within the WFST paradigm, re-
ordering models under any of those constraints can
be integrated into the cross-lingual language model.
</bodyText>
<equation confidence="0.982660333333333">
~ wr:w1 /P(r1) ~wr2 w2 P r2 r1 ~
: / (  |) ~wr 3 w3 P r3 r2
: / (  |)
</equation>
<figureCaption confidence="0.649416">
Figure 2: An example of reordering WFST Ω, imple-
menting the phrasal reordering model under the first or-
der Markov assumption.
</figureCaption>
<subsectionHeader confidence="0.993932">
2.3 Phrase-to-Phrase Transduction Model
</subsectionHeader>
<bodyText confidence="0.991716705882353">
Once the phrase sequence of the Lw transcript
is reordered into the Lv transcript order, we use
the phrase-to-phrase transduction model specified in
Eq. (6) to perform the cross-language transduction.
Given sufficient parallel training data, the context-
dependent phrase-to-phrase transduction model can
be estimated using the GIATI method (Casacu-
berta and Vidal, 2004). However, for the trans-
lation task with scarce training data, the context-
dependent transduction probabilities may not be re-
liably estimated. Therefore, we assume that a phrase
˜vk is generated independently by each phrase ˜wrk.
C(˜vk, ˜wrk) is the number of times that phrase ˜vk is
aligned to ˜wrk in the parallel corpus. This model can
be implemented by a WFST Tvw which transduces
˜vk to ˜wrk. Figure 3(a3) shows an example of Tvw
transducing v2 v3 to w2 w3.
</bodyText>
<equation confidence="0.90006025">
P(˜vK1 |rK1 , ˜wK 1 , wJ 1 ) = P (˜vK 1 |rK 1 , ˜wK 1 )
Pk(˜vk |˜wrk)
C(˜vk, ˜wrk)(6)
Evk C(˜vk, ˜wrk)
</equation>
<subsectionHeader confidence="0.835325">
2.4 Reconstruction Model
</subsectionHeader>
<bodyText confidence="0.852717">
Reconstruction model P(vI1|˜vK1 ,rK1 , ˜wK1 ,wJ1 ) oper-
ates in the opposite direction as the segmentation
</bodyText>
<footnote confidence="0.5183215">
6For simplicity, reordering sequence distributions are not
shown there.
</footnote>
<bodyText confidence="0.9996132">
model. It generates a word sequence vI1 from a
phrase sequence ˜vK1 . The reconstruction model can
be implemented by a WFST Rv. An example of
Rv is shown in Figure 3(a4), which reconstructs a
phrase v2 v3 into a word sequence {v2, v3}.
</bodyText>
<sectionHeader confidence="0.766602" genericHeader="method">
3 Speech Recognition with Cross-Lingual
Language Models
</sectionHeader>
<bodyText confidence="0.9935016">
The translation model P(vI1|wJ1 ) can be constructed
via WFST composition (denoted by ◦) (Mohri,
2009) of all the component models as shown in Eq.
(7) and Figure 3, where T is the final composed
WFST that transduces vI1 to wJ1 .
</bodyText>
<equation confidence="0.99852">
T = Rv ◦ Tvw ◦ Ωr ◦ Sw (7)
</equation>
<bodyText confidence="0.999253">
The cross-lingual language model Gcl is con-
structed through composition (see Eq. (8)) of
the translation model and a resource-rich language
model G.
</bodyText>
<equation confidence="0.989535">
Gcl = T ◦ G = Rv ◦ Tvw ◦ Ωr ◦ Sw ◦ G (8)
</equation>
<bodyText confidence="0.999983357142857">
As the way of integrating a resource-rich lan-
guage model G into ASR search space (Mohri et al.,
2008), we can integrate the cross-lingual language
model Gcl into ASR search space in a globally op-
timized way as well. The search space can be im-
plemented using a transducer ASR, which is for-
mulated with a unified WFST approach as shown
in Eq. (9). Here H transduces HMM states to
context-dependent phones. C represents a trans-
duction from context-dependent phones to context-
independent phones. L is a lexicon transducer which
maps context-independent phone sequences to word
strings restricted to the input symbols of the cross-
lingual language model transducer Gcl.
</bodyText>
<equation confidence="0.98139">
ASR = H ◦ C ◦ L ◦ Gcl (9)
</equation>
<bodyText confidence="0.996836111111111">
Eq. (9) outputs the recognition result in a resource-
rich language. If recognition system requires recog-
nition outputs in a resource-poor language, then the
search space should be constructed as Eq. (10),
where π is a projection (Mohri, 2009) operator
which projects the input label to the output label.
Before decoding, the recognition transducer ASR
can be optimized by a determinization operation
right after each composition.
</bodyText>
<equation confidence="0.984030285714286">
ASR = H ◦ C ◦ L ◦ π(Gcl) (10)
K
= H
k=1
K
= H
k=1
</equation>
<page confidence="0.421036">
771
</page>
<figure confidence="0.994860536082475">
(a3) Phrase-to-phrase transduction WFST Tvw (b3) Qr o Sw o G
(a1) Segmentation WFST Sw (b1) Written-style language model G
w2:w2
w3:w3
2
w 1 : w 1
0 1
4
w 2 _ w 3 : w 2 -:w3
3
(a2) Reordering WFST Qr (b2) Sw o G
w2�w3:w2
wl:wl
1
w2�w3:w1
wl:w2
0
2
-:w3
w3:w3
6
3
5
w2:w2
�
�������� �� �� �����
� �
w2:w2
wl:wl
w2_w3:w2 l 0 wl:wl l w2:w2 2 w3:w3 3
-:w3
0
w3:w3
v2�v3�#l:w2�w3�#l
wl�#l:wl�#l
v2�v3:w2�w3
w3:w3
wl:wl
w2:w2
0
w2_w3_#l:w2_w3
wl_#l:wl
w3:w3
w2:w2
0
w2_w3:w2_w3
w2_w3:wl
wl:w2_w3
wl:wl
2
l
w1:w1
-:-
1
w2:w2
2
-:-
w3:w3
3
-:-
-:-
11 0
v2:v2�v3
4
v3:-
-:-
7
v2:v2�v3�#1
6
v3:-
w1:w1�#1
9
#1:-
5
#1:-
-:-
8
10
-:-
v2_v3:w2
w1:w1
1
v2_v3:w1
0
4
-:w3
w1_#1:w1
6
w3:w3
3
5
w2:w2
w1:w2
2
v2_v3_#1:w2
(a4) Reconstruction WFST Rv (b4) Tvw o Qr o Sw o G
(b5) Rv o Tvw o Qr o Sw o G
</figure>
<figureCaption confidence="0.9878475">
Figure 3: Illustration of constructing a cross-lingual language model via WFSTs: a word sequence {w1, w2, w31
represented by the L,,, language model G (b1) is segmented into a phrase sequence {w1, w2 w31 (b2); {w1, w2 w31 is
reordered into {w2 w3, w11 (b3); phrase w2 w3 is transduced to v2 v3 (b4); phrase v2 v3 is reconstructed into a word
sequence {v2, v31 (b5). wk and vk represent wk and vk, respectively. ”-” refers to ǫ or null symbol. Auxiliary symbols
#1,#2,··· are used to make the WFST determinizable (Mohri, 2009) such that the transducer can be optimized by a
determinization (Mohri, 2009) operation which significantly reduces the search network size.
</figureCaption>
<figure confidence="0.989122341463415">
772
v2:wl
v3:-
4
���
7
wl:w2
10
-:w3
14
2
���
0 1
wl:wl
3
���
5
v2:w2
8
v3:-
11
-:w3
15
����
6
���
9
v2:w2
12
v3:-
16
#1:-
18
-:w3
20
w2:w2
13
���
17
w3:w3
19
</figure>
<sectionHeader confidence="0.971527" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.999002">
4.1 Corpus and Model Training
</subsectionHeader>
<bodyText confidence="0.998868681818182">
To investigate the performance of our proposed
cross-lingual language models, we have chosen
Cantonese as a resource-poor language and Man-
darin as a resource-rich language. We have col-
lected Cantonese parliamentary speech from the
Hong Kong Legislative Council. Currently we only
have 4152 parallel transcribed sentences containing
19.4 hours of speech. It is separated into three sets,
a training set (11.9 hours, 2700 sentences), a de-
velopment set (3.7 hours, 788 sentences), and an
evaluation set (3.8 hours, 664 sentences). The sen-
tences in the evaluation set are a bit longer than
those in the development set. The parallel transcrip-
tions of the training set constitute a parallel cor-
pus, which includes Cantonese transcription (man-
ual transcription) of 106k words and Mandarin tran-
scription (Hansard7 transcription) of 80k words. The
statistics of substitutions, insertions, deletions and
inversions identified in the parallel corpus are shown
in Table 2. Besides the parallel corpus, we have a
set of additional Mandarin transcriptions, which has
31M words.
</bodyText>
<tableCaption confidence="0.960431">
Table 2: No. of substitutions, insertions, deletions and
inversions identified in the parallel corpus with different
segmentation order s.
</tableCaption>
<table confidence="0.997268833333333">
Segmentation Order s = 2 s = 3 s = 4 s = 5
Substitutions 30921 22723 19011 17106
Insertions 4657 3820 3641 3295
Deletions 1365 1158 1066 1030
Inversions 3000 2876 2814 2779
Total 39943 30577 26532 24210
</table>
<bodyText confidence="0.957166318181818">
The training set is used for training an acous-
tic model (including H and C) using a Maximum
Likelihood criterion. It adopts 13 MFCC coeffi-
cients, together with 13 delta coefficients and 13 ac-
celeration coefficients as the acoustic features. The
acoustic model comprises 73 Hidden Markov Mod-
els (HMMs) to represent 70 Cantonese phonemes as
well as silence, short pause, and noise. During the
acoustic model training, tied-state cross-word tri-
phones are constructed by decision tree clustering.
7Hansard is a name of the printed transcripts of parliamen-
tary debates.
The parallel corpus is used for training the trans-
lation model T . Together with the parallel corpus,
the additional Mandarin transcriptions are used for
training an interpolated word-level trigram language
model G, where the lexicon size is about 28K. A
modified scheme of Kneser-Ney discounting is ap-
plied for the language model G with a back-off
threshold of 1 for unigram and 2 for bigram. The
cross-lingual language model G,l can be obtained
by composition of T and G.
</bodyText>
<subsectionHeader confidence="0.998414">
4.2 Decoding and Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999237">
Decoding of the speech recognition search space
ASR is performed by T3 Decoder (Dixon et
al., 2009), which is a state-of-the-art WFST-based
LVCSR speech decoder. Decoding of ASR in Eq.
(9) gives Mandarin outputs. Decoding of ASR in
Eq. (10) gives Cantonese outputs.
In our experiments, we use the following evalua-
tion criteria:
WER (word error rate). The WER is computed
as the minimum number of substitution, insertion
and deletion operations that have to be performed
to convert the generated sentence into the reference
sentence (Zens et al., 2004). The WER relates the
speech recognition accuracy. The lower WER, the
better.
BLEU (bilingual evaluation understudy) score.
The BLEU score measures the precision of n-grams
(unigrams, bigrams, trigrams and fourgrams) with
respect to a reference translation with a penalty for
too short sentences (Papineni et al., 2002). The
BLEU score reflects the translation accuracy. The
larger BLEU score, the better.
We perform WER evaluation of decoding out-
puts of Eq. (10) and BLEU score evaluation of
decoding outputs of Eq. (9) using the evaluation
set. The WER evaluation is on the Cantonese output
against the Cantonese reference transcription (man-
ual transcription). The BLEU score evaluation is on
the Mandarin output against the Mandarin reference
transcription (Hansard transcription).
</bodyText>
<subsectionHeader confidence="0.999145">
4.3 Parameter Settings
</subsectionHeader>
<bodyText confidence="0.99997275">
The performance of our proposed cross-lingual lan-
guage models is sensitive to many parameters.
Firstly, segmentation order s affects phrase extrac-
tion. The optimal value depends on the language
</bodyText>
<page confidence="0.93206">
773
</page>
<tableCaption confidence="0.829512">
Table 3: WER and BLEU score for decoding results of H ◦ C ◦ L ◦ G, H ◦ C ◦ L ◦ 7r(Goi) without reordering, and
H ◦ C ◦ L ◦ 7r(Goi) with reordering under various constraints.
</tableCaption>
<table confidence="0.995891833333333">
Models H ◦ C ◦ L ◦ G H ◦ C ◦ L ◦ 7r(Gcl) H ◦ C ◦ L ◦ 7r(Gcl)
Gcl = T3 ◦ G Gcl = T3 ◦ G,T3 = Rv ◦ Tvw ◦ 0r ◦ Sw
T3 = Rv ◦ Tvw ◦ Sw
Local Constraints IBM Constraints ITG Constraints
WER(%) 29.85 27.05 26.35 26.20 26.13
BLEU N/A 29.23 32.29 32.81 33.12
</table>
<bodyText confidence="0.999801555555556">
pair and the size of corpus. Secondly, p0 in the
first order Markov assumption affects the decoding
results. Thirdly, the number of reordering permu-
tations or paths are formidable when the reorder-
ing distance L is long as suggested by Table 1.
Therefore, we apply histogram pruning to reorder-
ing paths, which only maintains top N most likely
ones. The development set is used for tuning param-
eters p0 and N.
</bodyText>
<sectionHeader confidence="0.998215" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.98161784">
The evaluation results of the proposed cross-lingual
language models Gcl with reordering under various
constraints are presented in Table 3, where Gcl =
Ts◦G = T3◦G.8 In general, reordering has a signif-
icant effect on enhancing the performance of recog-
nition and translation in the sense of WER reduc-
tion and BLEU improvement. Compared with the
cross-lingual language model without reordering,
the cross-lingual language model with reordering
under local constraints gives 0.70% absolute WER
reduction and 3.06 absolute BLEU improvement.
The cross-lingual language model with reordering
under IBM constraints gives 0.85% absolute WER
reduction and 3.58 absolute BLEU improvement.
The cross-lingual language model with reordering
under ITG constraints yields the best performance,
with 0.92% absolute WER reduction and 3.89 abso-
lute BLEU improvement. All WER improvements
pointed out here are statistically significant at 99%
confidence according to a two-proportional z-test,
and all BLEU improvements are statistically signifi-
cant at 95% confidence according to a paired student
t-test using bootstrap resampling.
8We have chosen segmentation order s = 3 because it works
the best in our system.
</bodyText>
<sectionHeader confidence="0.999322" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999989486486486">
We have proposed cross-lingual language model-
ing with phrase-level syntactic reordering for low-
resource speech recognition. The cross-lingual lan-
guage modeling enriches a resource-poor language
model by leveraging the language model from a
closely related resource-rich language. It provides
an effective method to solve the low-resource lan-
guage modeling challenge by using a large amount
of resource-rich language (e.g. Mandarin) data
and a small amount of resource-poor language (e.g.
Cantonese) data, as well as some parallel data of
resource-poor and resource-rich languages. With
a cross-lingual language model, our ASR system
can decode speech into transcriptions, either in a
resource-poor language or a resource-rich language,
using a single WFST-based speech decoder.
We have presented a first end-to-end WFST
source to target language transcription and transla-
tion system with syntactic reordering and global op-
timization. Our work is the first to use ITG con-
straints for the syntactic reordering in such an in-
tegrated system. We also did comparative study
of ITG constraints, IBM constraints and local con-
straints in the reordering model, for completeness.
We have also presented the determinizable design of
each transducer for composing a cross-lingual lan-
guage model such that we can optimize the search
network by determinization. This is crucially im-
portant to successfully build a practical integrated
system, and, of course, the work is extremely chal-
lenging.
Experiments on Cantonese recognition and Can-
tonese to Mandarin translation tasks have shown that
our proposed cross-lingual language model substan-
tially improves the performance of the recognition
and translation. The best system gives 12.5% rel-
ative WER reduction in Cantonese (resource-poor
</bodyText>
<page confidence="0.701605">
774
</page>
<bodyText confidence="0.999898166666667">
language) transcriptions over the system using inter-
polation. The best reordering model gives 3.4% rela-
tive WER reduction and 13.3% relative BLEU score
improvement in Mandarin (resource-rich language)
transcriptions over the system without reordering.
The improvements have been found to be statisti-
cally significant.
Even though the objective of our work is for
speech recognition, our proposed cross-lingual lan-
guage modeling can be easily applied to speech
translation of other language pairs for efficient di-
rect decoding from source speech to target text.
</bodyText>
<sectionHeader confidence="0.998627" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.9995801">
This work is partially supported by ITS/189/09 and
CERG#612211. The authors would like to thank Dr.
Tasuku Oonishi for providing access to the T3 de-
coder, and thank Prof. Sadaoki Furui and his team
for useful discussions. Thanks should go to Yue Yu
and Percy Cheung for collecting the Cantonese and
Mandarin parallel data. Thanks also go to Ricky
Chan for training the Cantonese acoustic model and
Dr. Markus Saers for helping on training the GIZA
word-to-word alignment models.
</bodyText>
<sectionHeader confidence="0.994913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997522039473684">
Y. Akita and T. Kawahara. 2006. Efficient estimation
of language model statistics of spontaneous speech via
statistical transformation model. In Proceedings of the
IEEE International Conference on Acoustics, Speech
and Signal Processing, volume 1, pages 1049–1052.
E. Barcucci, A. Del Lungo, E. Pergola, and R. Pinzani.
2000. Permutations avoiding an increasing number
of length-increasing forbidden subsequences. Dis-
crete Mathematics and Theoretical Computer Science,
4(1):31–44.
J.R. Bellegarda. 2004. Statistical language model adap-
tation: review and perspectives. Speech communica-
tion, 42(1):93–108.
A.L. Berger, P.F. Brown, S.A. Della Pietra, V.J.
Della Pietra, A.S. Kehler, and R.L. Mercer. 1996.
Language translation apparatus and method us-
ing context-based translation models. US Patent
5,510,981.
F. Casacuberta and E. Vidal. 2004. Machine translation
with inferred stochastic finite-state transducers. Com-
putational Linguistics, 30(2):205–225.
F. Casacuberta, H. Ney, F.J. Och, et al. 2004. Some ap-
proaches to statistical and finite-state speech-to-speech
translation. Computer Speech &amp; Language, 18(1):25–
47.
P. Clarkson and R. Rosenfeld. 1997. Statistical lan-
guage modeling using the cmu-cambridge toolkit. In
5th European Conference on Speech Communication
and Technology.
P.R. Dixon, T. Oonishi, K. Iwano, and S. Furui. 2009.
Recent development of wfst-based speech recognition
decoder. In Proceedings of2009 APSIPA Annual Sum-
mit and Conference, pages 138–147, Sapporo, Japan.
M. Dreyer, K. Hall, and S. Khudanpur. 2007. Compar-
ing reordering constraints for smt using efficient bleu
oracle computation. In Proceedings of SSST, NAACL-
HLT 2007 /AMTA Workshop on Syntax and Structure
in Statistical Translation, pages 103–110, Rochester,
New York.
A. Ehrenfeucht, T. Harju, P. Ten Pas, and G. Rozenberg.
1998. Permutations, parenthesis words, and schr¨oder
numbers. Discrete mathematics, 190(1):259–264.
V. Geethakumary. 2002. A contrastive analysis of hindi
and malayalam. Language in India.
R.G. Gordon, B.F. Grimes, and Summer Institute of Lin-
guistics. 2005. Ethnologue: Languages of the world,
volume 15. SIL International, Dallas TX, USA.
T. Hori, D. Willett, and Y. Minami. 2003. Lan-
guage model adaptation using wfst-based speaking-
style translation. In Proceedings of the IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing, volume 1, pages 228–231.
A.T. Jensson, T. Oonishi, K. Iwano, and S. Furui. 2009.
Development of a wfst based speech recognition sys-
tem for a resource deficient language using machine
translation. In Proceedings of APSIPA ASC 2009:
Asia-Pacific Signal and Information Processing Asso-
ciation, 2009 Annual Summit and Conference, pages
50–56.
S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney.
2005. Novel reordering approaches in phrase-based
statistical machine translation. In Proceedings of the
ACL Workshop on Building and Using Parallel Texts,
pages 167–174. Association for Computational Lin-
guistics.
S. Khudanpur and W. Kim. 2002. Using cross-language
cues for story-specific language modeling. In 7th In-
ternational Conference on Spoken Language Process-
ing.
W. Kim and S. Khudanpur. 2003. Cross-lingual lexical
triggers in statistical language modeling. In Proceed-
ings of the 2003 conference on Empirical methods in
natural language processing, pages 17–24. Associa-
tion for Computational Linguistics.
W. Kim and S. Khudanpur. 2004. Cross-lingual latent
semantic analysis for language modeling. In Proceed-
</reference>
<page confidence="0.555742">
775
</page>
<reference confidence="0.999834782608696">
ings of the IEEE International Conference on Acous-
tics, Speech and Signal Processing, volume 1, pages
I257–I260. IEEE.
T. Kløve. 2009. Generating functions for the number
of permutations with limited displacement. The Elec-
tronic Journal of Combinatorics, 16(R104).
K. Knight. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607–615.
S. Kumar and W. Byrne. 2005. Local phrase reorder-
ing models for statistical machine translation. In
Proceedings of Human Language Technology Confer-
ence / Conference on Empirical Methods in Natural
Language Processing (HLT/EMNLP), pages 161–168,
Vancouver, Canada.
S. Kumar, Y. Deng, and W. Byrne. 2005. A weighted
finite state transducer translation template model for
statistical machine translation. Natural Language En-
gineering, 12(1):35–75.
J. Lee. 2011. Toward a parallel corpus of spoken can-
tonese and written chinese. In Proceedings of the 5th
International Joint Conference on Natural Language
Processing, pages 1462–1466, Chiang Mai, Thailand.
L. Mathias and W. Byrne. 2006. Statistical phrase-based
speech translation. In Proceedings of the IEEE Inter-
national Conference on Acoustics, Speech and Signal
Processing, volume 1, pages 561–564.
E. Matusov, S. Kanthak, and H. Ney. 2006. Integrating
speech recognition and machine translation: Where do
we stand? In Proceedings of the IEEE International
Conference on Acoustics, Speech and Signal Process-
ing, volume 5, pages V1217–V1220. IEEE.
M. Mohri, F. C. N. Pereira, and M. Riley. 2008.
Speech recognition with weighted finite-state trans-
ducers. Handbook on Speech Processing and Speech
Communication, Part E: Speech Recognition.
M. Mohri. 2009. Weighted automata algorithms. Hand-
book of Weighted Automata, pages 213–254.
P. Nakov and H.T. Ng. 2009. Improved statistical ma-
chine translation for resource-poor languages using re-
lated resource-rich languages. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing, volume 3, pages 1358–1367.
Association for Computational Linguistics.
G. Neubig, Y. Akita, S. Mori, and T. Kawahara. 2010.
Improved statistical models for smt-based speaking
style transformation. In Proceedings of the IEEE In-
ternational Conference on Acoustics, Speech and Sig-
nal Processing, pages 5206–5209.
F.J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–51.
F.J. Och, C. Tillmann, and H. Ney. 1999. Improved
alignment models for statistical machine translation.
In Proceedings of the Joint SIGDAT Conf. on EMNLP
and VLC, pages 20–28, College Park, MD, USA.
K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002.
Bleu: a method for automatic evaluation of machine
translation. In Proceedings of the 40th annual meet-
ing on association for computational linguistics, pages
311–318. Association for Computational Linguistics.
G. Saon and M. Picheny. 2007. Lattice-based viterbi
decoding techniques for speech translation. In Au-
tomatic Speech Recognition &amp; Understanding, 2007.
ASRU. IEEE Workshop on, pages 386–389. IEEE.
A. Stolcke. 2002. Srilm-an extensible language model-
ing toolkit. In 7th International Conference on Spoken
Language Processing.
D. Wu. 1997. Stochastic inversion transduction gram-
mars and bilingual parsing of parallel corpora. Com-
putationalLinguistics, 23(3):377–403.
R. Zens and H. Ney. 2003. A comparative study on re-
ordering constraints in statistical machine translation.
In Proceedings of the 41st Annual Meeting on Associ-
ation for Computational Linguistics, pages 144–151,
Sapporo, Japan. Association for Computational Lin-
guistics.
R. Zens, H. Ney, T. Watanabe, and E. Sumita. 2004.
Reordering constraints for phrase-based statistical ma-
chine translation. In Proceedings of the 20th interna-
tional conference on Computational Linguistics, pages
205–211, Geneva, Switzerland. Association for Com-
putational Linguistics.
B. Zhou, S.F. Chen, and Y. Gao. 2005. Constrained
phrase-based translation using weighted finite-state
transducers. In Proceedings of the IEEE International
Conference on Acoustics, Speech and Signal Process-
ing, volume 1, pages 1017–1020.
B. Zhou, S. F. Chen, and Y. Gao. 2006. Folsom: A fast
and memory-efficient phrase-based approach to statis-
tical machine translation. In Spoken Language Tech-
nology Workshop, pages 226–229. IEEE.
</reference>
<page confidence="0.929665">
776
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.231494">
<title confidence="0.901250666666667">Cross-Lingual Language Modeling with Syntactic Reordering Low-Resource Speech Recognition Ping Xu and Pascale</title>
<author confidence="0.618557">Human Language Technology</author>
<affiliation confidence="0.766293">Department of Electronic and Computer</affiliation>
<author confidence="0.684727">The Hong Kong University of Science</author>
<author confidence="0.684727">Clear Water Bay Technology</author>
<author confidence="0.684727">Hong</author>
<email confidence="0.980712">xuping@ust.hk,pascale@ece.ust.hk</email>
<abstract confidence="0.995252814814815">This paper proposes cross-lingual language modeling for transcribing source resourcepoor languages and translating them into target resource-rich languages if necessary. Our focus is to improve the speech recognition performance of low-resource languages by leveraging the language model statistics from resource-rich languages. The most challenging work of cross-lingual language modeling is to solve the syntactic discrepancies between the source and target languages. We therefore propose syntactic reordering for cross-lingual language modeling, and present a first result that compares inversion transduction grammar (ITG) reordering constraints to IBM and local constraints in an integrated speech transcription and translation system. Evaluations on resource-poor Cantonese speech transcription and Cantonese to resource-rich Mandarin translation tasks show that our proposed approach improves the system performance significantly, up to 3.4% relative WER reduction in Cantonese transcription and 13.3% relative bilingual evaluation understudy (BLEU) score improvement in Mandarin transcription compared with the system without reordering.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Akita</author>
<author>T Kawahara</author>
</authors>
<title>Efficient estimation of language model statistics of spontaneous speech via statistical transformation model.</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>1049--1052</pages>
<contexts>
<context position="2944" citStr="Akita and Kawahara, 2006" startWordPosition="416" endWordPosition="419">ally spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al., 2003; Akita and Kawahara, 2006; Jensson et al., 2009; Neubig et al., 2010). In (Jensson et al., 2009), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language. In (Hori et al., 2003; Akita and Kawahara, 2006; Neubig et al., 2010), context-dependent transduction is exploited. In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language. They carried out language model transformation since the input speech 766 Proceedings of the 2012 Joint</context>
</contexts>
<marker>Akita, Kawahara, 2006</marker>
<rawString>Y. Akita and T. Kawahara. 2006. Efficient estimation of language model statistics of spontaneous speech via statistical transformation model. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 1, pages 1049–1052.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Barcucci</author>
<author>A Del Lungo</author>
<author>E Pergola</author>
<author>R Pinzani</author>
</authors>
<title>Permutations avoiding an increasing number of length-increasing forbidden subsequences.</title>
<date>2000</date>
<journal>Discrete Mathematics and Theoretical Computer Science,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="15236" citStr="Barcucci et al., 2000" startWordPosition="2450" endWordPosition="2453">lel data than local constraints and IBM constraints. Our presentation of ITG constraints starts with defining of some permutation sets. Let SK be the set of permutations on {1,2,...,K}. A permutation rK1 ∈ SK, where rK1 = r1r2 ... rK, contains a subsequence of type τ ∈ SM if and only if a sequence of indices 1 ≤ i1 &lt; i2 &lt; ... &lt; iM ≤ K exists such that ri1ri2 ... rim has all the same pairwise comparisons as τ. We denote the set of permutations of SK not containing subsequences of type τ by SK(τ). If we have sets SK(τ1), ... , SK(τp), we denote the set SK(τ1) ∩ ... ∩ SK(τp) by SK(τ1, ... , τp) (Barcucci et al., 2000). ITG constraints allow the permutation set SK(3142, 2413), which forbids subsequence of type (3, 1, 4, 2) and its dual (2, 4, 1, 3). Explicitly, ITG constraints avoid any permutation rK1 satisfying either ri2 &lt; ri¢ &lt; ri1 &lt; ri3 or ri3 &lt; ri1 &lt; ri¢ &lt; ri2, where 1 ≤ i1 &lt; i2 &lt; i3 &lt; i4 ≤ K. In (Wu, 1997), these forbidden subsequences are called “inside-out” transpositions. They are fairly distorted matchings, and hardly observed in real parallel data. In order to get an intuitive sense of the reordering capability of those three constraints, we list the number of permutations under local constraint</context>
</contexts>
<marker>Barcucci, Lungo, Pergola, Pinzani, 2000</marker>
<rawString>E. Barcucci, A. Del Lungo, E. Pergola, and R. Pinzani. 2000. Permutations avoiding an increasing number of length-increasing forbidden subsequences. Discrete Mathematics and Theoretical Computer Science, 4(1):31–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Bellegarda</author>
</authors>
<title>Statistical language model adaptation: review and perspectives. Speech communication,</title>
<date>2004</date>
<pages>42--1</pages>
<contexts>
<context position="2581" citStr="Bellegarda, 2004" startWordPosition="366" endWordPosition="367"> such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost. Today there are more than 6000 living languages spoken in the world (Gordon et al., 2005), and most of them have little transcribed texts and are considered as resource-poor languages (Nakov and Ng, 2009). Many of these languages are actually spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al., 2003; Akita and Kawahara, 2006; Jensson et al., 2009; Neubig et al., 2010). In (Jensson et al., 2009), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of th</context>
</contexts>
<marker>Bellegarda, 2004</marker>
<rawString>J.R. Bellegarda. 2004. Statistical language model adaptation: review and perspectives. Speech communication, 42(1):93–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Berger</author>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>A S Kehler</author>
<author>R L Mercer</author>
</authors>
<title>Language translation apparatus and method using context-based translation models.</title>
<date>1996</date>
<tech>US Patent 5,510,981.</tech>
<contexts>
<context position="6226" citStr="Berger et al., 1996" startWordPosition="896" endWordPosition="899">an interpolation and word-level transduction is to use crosslingual language modeling with syntactic reorder1For example, Hindi and Malayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc</context>
</contexts>
<marker>Berger, Brown, Pietra, Pietra, Kehler, Mercer, 1996</marker>
<rawString>A.L. Berger, P.F. Brown, S.A. Della Pietra, V.J. Della Pietra, A.S. Kehler, and R.L. Mercer. 1996. Language translation apparatus and method using context-based translation models. US Patent 5,510,981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Casacuberta</author>
<author>E Vidal</author>
</authors>
<title>Machine translation with inferred stochastic finite-state transducers.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>2</issue>
<contexts>
<context position="20318" citStr="Casacuberta and Vidal, 2004" startWordPosition="3405" endWordPosition="3409">s-lingual language model. ~ wr:w1 /P(r1) ~wr2 w2 P r2 r1 ~ : / ( |) ~wr 3 w3 P r3 r2 : / ( |) Figure 2: An example of reordering WFST Ω, implementing the phrasal reordering model under the first order Markov assumption. 2.3 Phrase-to-Phrase Transduction Model Once the phrase sequence of the Lw transcript is reordered into the Lv transcript order, we use the phrase-to-phrase transduction model specified in Eq. (6) to perform the cross-language transduction. Given sufficient parallel training data, the contextdependent phrase-to-phrase transduction model can be estimated using the GIATI method (Casacuberta and Vidal, 2004). However, for the translation task with scarce training data, the contextdependent transduction probabilities may not be reliably estimated. Therefore, we assume that a phrase ˜vk is generated independently by each phrase ˜wrk. C(˜vk, ˜wrk) is the number of times that phrase ˜vk is aligned to ˜wrk in the parallel corpus. This model can be implemented by a WFST Tvw which transduces ˜vk to ˜wrk. Figure 3(a3) shows an example of Tvw transducing v2 v3 to w2 w3. P(˜vK1 |rK1 , ˜wK 1 , wJ 1 ) = P (˜vK 1 |rK 1 , ˜wK 1 ) Pk(˜vk |˜wrk) C(˜vk, ˜wrk)(6) Evk C(˜vk, ˜wrk) 2.4 Reconstruction Model Reconstru</context>
</contexts>
<marker>Casacuberta, Vidal, 2004</marker>
<rawString>F. Casacuberta and E. Vidal. 2004. Machine translation with inferred stochastic finite-state transducers. Computational Linguistics, 30(2):205–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Casacuberta</author>
<author>H Ney</author>
<author>F J Och</author>
</authors>
<title>Some approaches to statistical and finite-state speech-to-speech translation.</title>
<date>2004</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>18</volume>
<issue>1</issue>
<pages>47</pages>
<contexts>
<context position="6633" citStr="Casacuberta et al., 2004" startWordPosition="961" endWordPosition="964">language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This c</context>
</contexts>
<marker>Casacuberta, Ney, Och, 2004</marker>
<rawString>F. Casacuberta, H. Ney, F.J. Och, et al. 2004. Some approaches to statistical and finite-state speech-to-speech translation. Computer Speech &amp; Language, 18(1):25– 47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Clarkson</author>
<author>R Rosenfeld</author>
</authors>
<title>Statistical language modeling using the cmu-cambridge toolkit.</title>
<date>1997</date>
<booktitle>In 5th European Conference on Speech Communication and Technology.</booktitle>
<contexts>
<context position="1623" citStr="Clarkson and Rosenfeld, 1997" startWordPosition="211" endWordPosition="214">straints in an integrated speech transcription and translation system. Evaluations on resource-poor Cantonese speech transcription and Cantonese to resource-rich Mandarin translation tasks show that our proposed approach improves the system performance significantly, up to 3.4% relative WER reduction in Cantonese transcription and 13.3% relative bilingual evaluation understudy (BLEU) score improvement in Mandarin transcription compared with the system without reordering. 1 Introduction Statistical language modeling techniques have achieved remarkable success in speech and language processing (Clarkson and Rosenfeld, 1997; Stolcke, 2002). However, this success largely depends on the availability of a large amount of suitable text data in a language. Without sufficient text data for training, it is very difficult to build a practical and usable statistical language model. Therefore, most of the advances have been reported in so called resource-rich language such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost. Today there are more than 6000 living languages spoken in the world (Gordon et al., 2005), and most of them have little transcribed texts and</context>
</contexts>
<marker>Clarkson, Rosenfeld, 1997</marker>
<rawString>P. Clarkson and R. Rosenfeld. 1997. Statistical language modeling using the cmu-cambridge toolkit. In 5th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Dixon</author>
<author>T Oonishi</author>
<author>K Iwano</author>
<author>S Furui</author>
</authors>
<title>Recent development of wfst-based speech recognition decoder.</title>
<date>2009</date>
<booktitle>In Proceedings of2009 APSIPA Annual Summit and Conference,</booktitle>
<pages>138--147</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="27237" citStr="Dixon et al., 2009" startWordPosition="4632" endWordPosition="4635">y debates. The parallel corpus is used for training the translation model T . Together with the parallel corpus, the additional Mandarin transcriptions are used for training an interpolated word-level trigram language model G, where the lexicon size is about 28K. A modified scheme of Kneser-Ney discounting is applied for the language model G with a back-off threshold of 1 for unigram and 2 for bigram. The cross-lingual language model G,l can be obtained by composition of T and G. 4.2 Decoding and Evaluation Method Decoding of the speech recognition search space ASR is performed by T3 Decoder (Dixon et al., 2009), which is a state-of-the-art WFST-based LVCSR speech decoder. Decoding of ASR in Eq. (9) gives Mandarin outputs. Decoding of ASR in Eq. (10) gives Cantonese outputs. In our experiments, we use the following evaluation criteria: WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence (Zens et al., 2004). The WER relates the speech recognition accuracy. The lower WER, the better. BLEU (bilingual evaluation understudy) score. The BLEU score measures </context>
</contexts>
<marker>Dixon, Oonishi, Iwano, Furui, 2009</marker>
<rawString>P.R. Dixon, T. Oonishi, K. Iwano, and S. Furui. 2009. Recent development of wfst-based speech recognition decoder. In Proceedings of2009 APSIPA Annual Summit and Conference, pages 138–147, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
<author>K Hall</author>
<author>S Khudanpur</author>
</authors>
<title>Comparing reordering constraints for smt using efficient bleu oracle computation.</title>
<date>2007</date>
<booktitle>In Proceedings of SSST, NAACLHLT 2007 /AMTA Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>103--110</pages>
<location>Rochester, New York.</location>
<contexts>
<context position="6401" citStr="Dreyer et al., 2007" startWordPosition="927" endWordPosition="930">onese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for s</context>
<context position="14108" citStr="Dreyer et al., 2007" startWordPosition="2212" endWordPosition="2215">a cross-lingual language model for speech recognition. Reordering Constraints Local constraints make the restriction that one phrase can jump at most L−1 phrases either forward or backward, where L is the reordering distance (or window size of permutation)4. The generation of rK1 under local constraints can be viewed as solving of the following problem (Kløve, 2009): secutive words forming a phrase. 4The concept of reordering distance also applies to other constraints. How many permutations of {1,2,... k ..., K} satisfy |rk − k |&lt; L for all k? IBM constraints, a superset of local constraints (Dreyer et al., 2007), generate permutations rK 1 deviate from the monotonic phrase order {rK1 : rk = k}. More specifically, any phrase position rk can be selected from the positions of the first m yet uncovered phrases (see Eq. (3)). A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m = 4 as IBM(4). { {1, 2, ..., k − 1 + m; rk =6 rk′=,4k} if k ≤ K + 1 − m, {1, 2, ..., K; rk =6 rk′�k} if K + 1 − m &lt; k ≤ K. ITG constraints provide a more faithful coverage of syntactic reordering in the parallel data than local constraints and IBM constraints. Our presentation of ITG constraints start</context>
</contexts>
<marker>Dreyer, Hall, Khudanpur, 2007</marker>
<rawString>M. Dreyer, K. Hall, and S. Khudanpur. 2007. Comparing reordering constraints for smt using efficient bleu oracle computation. In Proceedings of SSST, NAACLHLT 2007 /AMTA Workshop on Syntax and Structure in Statistical Translation, pages 103–110, Rochester, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ehrenfeucht</author>
<author>T Harju</author>
<author>P Ten Pas</author>
<author>G Rozenberg</author>
</authors>
<title>Permutations, parenthesis words, and schr¨oder numbers. Discrete mathematics,</title>
<date>1998</date>
<contexts>
<context position="16086" citStr="Ehrenfeucht et al., 1998" startWordPosition="2599" endWordPosition="2602">i3 or ri3 &lt; ri1 &lt; ri¢ &lt; ri2, where 1 ≤ i1 &lt; i2 &lt; i3 &lt; i4 ≤ K. In (Wu, 1997), these forbidden subsequences are called “inside-out” transpositions. They are fairly distorted matchings, and hardly observed in real parallel data. In order to get an intuitive sense of the reordering capability of those three constraints, we list the number of permutations under local constraints, IBM constraints as well as ITG constraints5 in Table 1. 5Interestingly, when K = L, the number of permutations under ITG constraints NITG = |SK(3142, 2413)|, and |SK(3142, 2413) |equals the K −1-th Schr¨oder numbers sK−1 (Ehrenfeucht et al., 1998) i j 1-1 2-2 3-4 4-6 4-7 5-8 6-5 7-3 8-3 i 1 3 4 5 6 7 8 ᶨὪ k’=1 恋 1 2 k=1 Ἀ Ἀ k=2  3 k’=2 ᾦ k=3 䴎 4 k’=3 ᾳ k=4  ᶨ ᾳ 5  k’=4 6 7 k=5 k’=5   k=6 8   k’=6 2 vi v~k&apos; wk~ wj j rk ∈ (3) 769 Table 1: Comparison of permutation number under local constraints (NLocal), IBM constraints (NIBM(4)) and ITG constraints (NITG). The comparison is constrained by the phrase number K and the reordering distance L. K=2 K=3 K=4 K=5 K=6 K=7 K=8 K=9 K=10 NLocal 2 3 5 8 13 21 34 55 89 L=2 NIBM(4) 2 3 5 8 13 21 34 55 89 NITG 2 3 5 8 13 21 34 55 89 NLocal 2 6 14 31 73 172 400 932 2177 L=3 NIBM(4) 2 6 14 31 73</context>
</contexts>
<marker>Ehrenfeucht, Harju, Pas, Rozenberg, 1998</marker>
<rawString>A. Ehrenfeucht, T. Harju, P. Ten Pas, and G. Rozenberg. 1998. Permutations, parenthesis words, and schr¨oder numbers. Discrete mathematics, 190(1):259–264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Geethakumary</author>
</authors>
<title>A contrastive analysis of hindi and malayalam. Language in India.</title>
<date>2002</date>
<contexts>
<context position="5768" citStr="Geethakumary, 2002" startWordPosition="826" endWordPosition="827">sidered as ”dialects” of the standard Chinese Mandarin (or Putonghua)2. However, they differ greatly from Mandarin in all aspects and are not mutually comprehensible. For instance, in addition to lexical and pronunciation differences, Cantonese Chinese (Lee, 2011) differs syntactically from Mandarin as well - we found that there are approximately 10% syntactic inversions between sentences of the two forms of Chinese. We suggest that a better approach than interpolation and word-level transduction is to use crosslingual language modeling with syntactic reorder1For example, Hindi and Malayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak e</context>
</contexts>
<marker>Geethakumary, 2002</marker>
<rawString>V. Geethakumary. 2002. A contrastive analysis of hindi and malayalam. Language in India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R G Gordon</author>
<author>B F Grimes</author>
</authors>
<title>and Summer Institute of Linguistics.</title>
<date>2005</date>
<journal>Ethnologue: Languages of the world,</journal>
<volume>15</volume>
<publisher>SIL International,</publisher>
<location>Dallas TX, USA.</location>
<marker>Gordon, Grimes, 2005</marker>
<rawString>R.G. Gordon, B.F. Grimes, and Summer Institute of Linguistics. 2005. Ethnologue: Languages of the world, volume 15. SIL International, Dallas TX, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hori</author>
<author>D Willett</author>
<author>Y Minami</author>
</authors>
<title>Language model adaptation using wfst-based speakingstyle translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>228--231</pages>
<contexts>
<context position="2918" citStr="Hori et al., 2003" startWordPosition="412" endWordPosition="415"> languages are actually spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al., 2003; Akita and Kawahara, 2006; Jensson et al., 2009; Neubig et al., 2010). In (Jensson et al., 2009), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language. In (Hori et al., 2003; Akita and Kawahara, 2006; Neubig et al., 2010), context-dependent transduction is exploited. In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language. They carried out language model transformation since the input speech 766 Pro</context>
</contexts>
<marker>Hori, Willett, Minami, 2003</marker>
<rawString>T. Hori, D. Willett, and Y. Minami. 2003. Language model adaptation using wfst-based speakingstyle translation. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 1, pages 228–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A T Jensson</author>
<author>T Oonishi</author>
<author>K Iwano</author>
<author>S Furui</author>
</authors>
<title>Development of a wfst based speech recognition system for a resource deficient language using machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of APSIPA ASC 2009: Asia-Pacific Signal and Information Processing Association, 2009 Annual Summit and Conference,</booktitle>
<pages>50--56</pages>
<contexts>
<context position="2966" citStr="Jensson et al., 2009" startWordPosition="420" endWordPosition="423">er of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al., 2003; Akita and Kawahara, 2006; Jensson et al., 2009; Neubig et al., 2010). In (Jensson et al., 2009), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language. In (Hori et al., 2003; Akita and Kawahara, 2006; Neubig et al., 2010), context-dependent transduction is exploited. In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language. They carried out language model transformation since the input speech 766 Proceedings of the 2012 Joint Conference on Empiric</context>
</contexts>
<marker>Jensson, Oonishi, Iwano, Furui, 2009</marker>
<rawString>A.T. Jensson, T. Oonishi, K. Iwano, and S. Furui. 2009. Development of a wfst based speech recognition system for a resource deficient language using machine translation. In Proceedings of APSIPA ASC 2009: Asia-Pacific Signal and Information Processing Association, 2009 Annual Summit and Conference, pages 50–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kanthak</author>
<author>D Vilar</author>
<author>E Matusov</author>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Novel reordering approaches in phrase-based statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>167--174</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6379" citStr="Kanthak et al., 2005" startWordPosition="923" endWordPosition="926">ry, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual l</context>
</contexts>
<marker>Kanthak, Vilar, Matusov, Zens, Ney, 2005</marker>
<rawString>S. Kanthak, D. Vilar, E. Matusov, R. Zens, and H. Ney. 2005. Novel reordering approaches in phrase-based statistical machine translation. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 167–174. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Khudanpur</author>
<author>W Kim</author>
</authors>
<title>Using cross-language cues for story-specific language modeling.</title>
<date>2002</date>
<booktitle>In 7th International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="3957" citStr="Khudanpur and Kim, 2002" startWordPosition="565" endWordPosition="568">ase, the resource-poor language is a spoken language, and the resource-rich language is a written language. They carried out language model transformation since the input speech 766 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 766–776, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics is in speaking-style and the output text is in writtenstyle. Others have investigated cross-lingual information between a resource-poor language and a resource-rich language. In (Khudanpur and Kim, 2002), cross-language cues are used to improve a language model of a resource-poor language. They used cross-lingual unigram probabilities trained from a story-specific parallel corpus of the resourcepoor and resource-rich languages. They interpolate the language model of the resource-poor language with those unigram probabilities. In (Kim and Khudanpur, 2003), an n-gram language model in a resource-poor language is interpolated with crosslingual unigram trigger probabilities. These triggers are word pairs of the resource-poor and resourcerich languages with the highest mutual information across th</context>
</contexts>
<marker>Khudanpur, Kim, 2002</marker>
<rawString>S. Khudanpur and W. Kim. 2002. Using cross-language cues for story-specific language modeling. In 7th International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kim</author>
<author>S Khudanpur</author>
</authors>
<title>Cross-lingual lexical triggers in statistical language modeling.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 conference on Empirical methods in natural language processing,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4314" citStr="Kim and Khudanpur, 2003" startWordPosition="616" endWordPosition="619">–14 July 2012. c�2012 Association for Computational Linguistics is in speaking-style and the output text is in writtenstyle. Others have investigated cross-lingual information between a resource-poor language and a resource-rich language. In (Khudanpur and Kim, 2002), cross-language cues are used to improve a language model of a resource-poor language. They used cross-lingual unigram probabilities trained from a story-specific parallel corpus of the resourcepoor and resource-rich languages. They interpolate the language model of the resource-poor language with those unigram probabilities. In (Kim and Khudanpur, 2003), an n-gram language model in a resource-poor language is interpolated with crosslingual unigram trigger probabilities. These triggers are word pairs of the resource-poor and resourcerich languages with the highest mutual information across these two languages. Another way of estimating those unigram probabilities is using latent semantic analysis by measuring cosine similarities from a document-aligned corpus for any given word pair (Kim and Khudanpur, 2004). Both interpolation and word-level transduction approaches fail to meet the challenge of syntactic discrepancies between the resource-po</context>
</contexts>
<marker>Kim, Khudanpur, 2003</marker>
<rawString>W. Kim and S. Khudanpur. 2003. Cross-lingual lexical triggers in statistical language modeling. In Proceedings of the 2003 conference on Empirical methods in natural language processing, pages 17–24. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kim</author>
<author>S Khudanpur</author>
</authors>
<title>Cross-lingual latent semantic analysis for language modeling.</title>
<date>2004</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>257--260</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="4777" citStr="Kim and Khudanpur, 2004" startWordPosition="683" endWordPosition="686">oor and resource-rich languages. They interpolate the language model of the resource-poor language with those unigram probabilities. In (Kim and Khudanpur, 2003), an n-gram language model in a resource-poor language is interpolated with crosslingual unigram trigger probabilities. These triggers are word pairs of the resource-poor and resourcerich languages with the highest mutual information across these two languages. Another way of estimating those unigram probabilities is using latent semantic analysis by measuring cosine similarities from a document-aligned corpus for any given word pair (Kim and Khudanpur, 2004). Both interpolation and word-level transduction approaches fail to meet the challenge of syntactic discrepancies between the resource-poor and resource-rich languages. This syntactic discrepancies exist, for example, even between the Sinitic languages and Indian languages1 of the same family. Sinitic languages such as Cantonese/Yue, Shanghai/Wu, etc. are officially considered as ”dialects” of the standard Chinese Mandarin (or Putonghua)2. However, they differ greatly from Mandarin in all aspects and are not mutually comprehensible. For instance, in addition to lexical and pronunciation differ</context>
</contexts>
<marker>Kim, Khudanpur, 2004</marker>
<rawString>W. Kim and S. Khudanpur. 2004. Cross-lingual latent semantic analysis for language modeling. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 1, pages I257–I260. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kløve</author>
</authors>
<title>Generating functions for the number of permutations with limited displacement.</title>
<date>2009</date>
<journal>The Electronic Journal of Combinatorics,</journal>
<pages>16--104</pages>
<contexts>
<context position="13856" citStr="Kløve, 2009" startWordPosition="2171" endWordPosition="2172">ring constraints widely used in statistical machine translation, namely local constraints, IBM constraints and ITG constraints. Here we would like to point out that this is the first time that reordering constraints have been incorporated into a cross-lingual language model for speech recognition. Reordering Constraints Local constraints make the restriction that one phrase can jump at most L−1 phrases either forward or backward, where L is the reordering distance (or window size of permutation)4. The generation of rK1 under local constraints can be viewed as solving of the following problem (Kløve, 2009): secutive words forming a phrase. 4The concept of reordering distance also applies to other constraints. How many permutations of {1,2,... k ..., K} satisfy |rk − k |&lt; L for all k? IBM constraints, a superset of local constraints (Dreyer et al., 2007), generate permutations rK 1 deviate from the monotonic phrase order {rK1 : rk = k}. More specifically, any phrase position rk can be selected from the positions of the first m yet uncovered phrases (see Eq. (3)). A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m = 4 as IBM(4). { {1, 2, ..., k − 1 + m; rk =6 rk′=</context>
</contexts>
<marker>Kløve, 2009</marker>
<rawString>T. Kløve. 2009. Generating functions for the number of permutations with limited displacement. The Electronic Journal of Combinatorics, 16(R104).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
</authors>
<title>Decoding complexity in wordreplacement translation models.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="13135" citStr="Knight, 1999" startWordPosition="2059" endWordPosition="2060">rd-to-word alignment. k↔k′ represents the indentified phrase-to-phrase alignment. 2.2 Phrasal Reordering Model Given a phrase sequence { w1, w2, ..., CVK} of the Lw transcript, the role of the reordering model P(rK1 |wK1 ,wJ1 ) is to reorder phrase positions of the Lw transcript into those of the Lv transcript by permutation of wK1 according to a reordering sequence {rK The 1 : rk ∈ {1, 2, ..., K}, rk =6 rk′�k}. phrase sequence { w1, w2, ..., wK} is therefore reordered into { wr1, 27vr2, ..., wrK } consequently (see Figure 2 where K = 3). Since arbitrary permutations of K phrases are NP-hard (Knight, 1999), reordering constraints have to be set over rK1 to reduce the number of permutations. There are three reordering constraints widely used in statistical machine translation, namely local constraints, IBM constraints and ITG constraints. Here we would like to point out that this is the first time that reordering constraints have been incorporated into a cross-lingual language model for speech recognition. Reordering Constraints Local constraints make the restriction that one phrase can jump at most L−1 phrases either forward or backward, where L is the reordering distance (or window size of per</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>K. Knight. 1999. Decoding complexity in wordreplacement translation models. Computational Linguistics, 25(4):607–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Byrne</author>
</authors>
<title>Local phrase reordering models for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>161--168</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="6273" citStr="Kumar and Byrne, 2005" startWordPosition="903" endWordPosition="906">is to use crosslingual language modeling with syntactic reorder1For example, Hindi and Malayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have</context>
</contexts>
<marker>Kumar, Byrne, 2005</marker>
<rawString>S. Kumar and W. Byrne. 2005. Local phrase reordering models for statistical machine translation. In Proceedings of Human Language Technology Conference / Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 161–168, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>Y Deng</author>
<author>W Byrne</author>
</authors>
<title>A weighted finite state transducer translation template model for statistical machine translation.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="18989" citStr="Kumar et al., 2005" startWordPosition="3173" endWordPosition="3176">it makes sense to restrict those non-monotonic reorderings when performing the translation. This not only helps the search of the most likely permutation, but also guides the pruning of unlikely permutations. K P(rK1 |�wK1 , wJ1 ) = P(r1) ri P(rk|rk−1, �wK1 ) k=2 K = P(r1) ri P(rk|rk−1) (4) k=2 We make a first order Markov assumption over the phrasal reordering model P(rK1 |wK1 , wJ1 ) (see Eq. (4)). The reordering sequence distribution is parameterized to assign decreasing likelihood to phrase reorderings { wr1, 17vr2, ... , �wrK } that diverge from the original word order (Och et al., 1999; Kumar et al., 2005). Suppose wrk = wl′ l and wrk−1 = wq′ q, the reordering sequence distribution is set as Eq. (5), where p0 is a tuning factor. We normalize the probabilities P(rk|rk−1) such that �Kk′=1,k′6=rk−1 P(rk = k′|rk−1) = 1. P(rk|rk−1) = p|l−q′−1| 0 1 (5) P(r1 = k) = K ; k ∈ {1, 2,..., K} 770 Assume that we have a phrase sequence { ˜w1, ˜w2, ˜w3}, Figure 2 shows the phrasal reordering model implemented by a reordering WFST Ωr under the first order Markov assumption for this phrase sequence. Figure 3(a2) gives one more example of Ωr, which reorders the phrase sequence {w1, w2 w3} into {w2 w3, w1}6. Withi</context>
</contexts>
<marker>Kumar, Deng, Byrne, 2005</marker>
<rawString>S. Kumar, Y. Deng, and W. Byrne. 2005. A weighted finite state transducer translation template model for statistical machine translation. Natural Language Engineering, 12(1):35–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
</authors>
<title>Toward a parallel corpus of spoken cantonese and written chinese.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1462--1466</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="5413" citStr="Lee, 2011" startWordPosition="773" endWordPosition="774">ord-level transduction approaches fail to meet the challenge of syntactic discrepancies between the resource-poor and resource-rich languages. This syntactic discrepancies exist, for example, even between the Sinitic languages and Indian languages1 of the same family. Sinitic languages such as Cantonese/Yue, Shanghai/Wu, etc. are officially considered as ”dialects” of the standard Chinese Mandarin (or Putonghua)2. However, they differ greatly from Mandarin in all aspects and are not mutually comprehensible. For instance, in addition to lexical and pronunciation differences, Cantonese Chinese (Lee, 2011) differs syntactically from Mandarin as well - we found that there are approximately 10% syntactic inversions between sentences of the two forms of Chinese. We suggest that a better approach than interpolation and word-level transduction is to use crosslingual language modeling with syntactic reorder1For example, Hindi and Malayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich lang</context>
</contexts>
<marker>Lee, 2011</marker>
<rawString>J. Lee. 2011. Toward a parallel corpus of spoken cantonese and written chinese. In Proceedings of the 5th International Joint Conference on Natural Language Processing, pages 1462–1466, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mathias</author>
<author>W Byrne</author>
</authors>
<title>Statistical phrase-based speech translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>561--564</pages>
<contexts>
<context position="6696" citStr="Mathias and Byrne, 2006" startWordPosition="973" endWordPosition="976">ses throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This creates an integrated speech transcription and translation frame</context>
</contexts>
<marker>Mathias, Byrne, 2006</marker>
<rawString>L. Mathias and W. Byrne. 2006. Statistical phrase-based speech translation. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 1, pages 561–564.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Matusov</author>
<author>S Kanthak</author>
<author>H Ney</author>
</authors>
<title>Integrating speech recognition and machine translation: Where do we stand?</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>5</volume>
<pages>1217--1220</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6718" citStr="Matusov et al., 2006" startWordPosition="977" endWordPosition="981">. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This creates an integrated speech transcription and translation framework. This paper is or</context>
</contexts>
<marker>Matusov, Kanthak, Ney, 2006</marker>
<rawString>E. Matusov, S. Kanthak, and H. Ney. 2006. Integrating speech recognition and machine translation: Where do we stand? In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 5, pages V1217–V1220. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohri</author>
<author>F C N Pereira</author>
<author>M Riley</author>
</authors>
<title>Speech recognition with weighted finite-state transducers. Handbook on Speech Processing and Speech Communication, Part E: Speech Recognition.</title>
<date>2008</date>
<contexts>
<context position="21926" citStr="Mohri et al., 2008" startWordPosition="3702" endWordPosition="3705">uence {v2, v3}. 3 Speech Recognition with Cross-Lingual Language Models The translation model P(vI1|wJ1 ) can be constructed via WFST composition (denoted by ◦) (Mohri, 2009) of all the component models as shown in Eq. (7) and Figure 3, where T is the final composed WFST that transduces vI1 to wJ1 . T = Rv ◦ Tvw ◦ Ωr ◦ Sw (7) The cross-lingual language model Gcl is constructed through composition (see Eq. (8)) of the translation model and a resource-rich language model G. Gcl = T ◦ G = Rv ◦ Tvw ◦ Ωr ◦ Sw ◦ G (8) As the way of integrating a resource-rich language model G into ASR search space (Mohri et al., 2008), we can integrate the cross-lingual language model Gcl into ASR search space in a globally optimized way as well. The search space can be implemented using a transducer ASR, which is formulated with a unified WFST approach as shown in Eq. (9). Here H transduces HMM states to context-dependent phones. C represents a transduction from context-dependent phones to contextindependent phones. L is a lexicon transducer which maps context-independent phone sequences to word strings restricted to the input symbols of the crosslingual language model transducer Gcl. ASR = H ◦ C ◦ L ◦ Gcl (9) Eq. (9) out</context>
</contexts>
<marker>Mohri, Pereira, Riley, 2008</marker>
<rawString>M. Mohri, F. C. N. Pereira, and M. Riley. 2008. Speech recognition with weighted finite-state transducers. Handbook on Speech Processing and Speech Communication, Part E: Speech Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mohri</author>
</authors>
<title>Weighted automata algorithms. Handbook of Weighted Automata,</title>
<date>2009</date>
<pages>213--254</pages>
<contexts>
<context position="12107" citStr="Mohri, 2009" startWordPosition="1876" endWordPosition="1877">pt (Mandarin), from which phrase-to-phrase alignments are derived by identifying deletion, substitution, insertion and inversion. Prior to phrasal reordering, the segmentation model P( wK1 |wJ1 ) implemented by a segmentation WFST 5w is applied to segment a word sequence wJ1 in the Lw language model into a phrase sequence { w1, w2, ..., wK}. The maximum number of words that can be segmented into one phrase is controlled by a segmentation order s. An example of 5w is shown in Figure 3(a1). It segments a word sequence {w1, w2, w3} into a phrase sequence {w1, w2 w3} after performing composition (Mohri, 2009) with the target Lw language model (see Figure 3(b1 &amp; b2))3. 3The “ ” symbol is used to indicate the concatenation of conP( wK1 |wJ1 ) · 768 Substitution Substitution Deletion Substitution Inversion Inversion &amp; Insertion Figure 1: An example (in English: Please give me an address first) of phrase extraction from word-to-word alignments. i and j are word indexes. k′ and k are phrase indexes. i↔j represents the word-to-word alignment. k↔k′ represents the indentified phrase-to-phrase alignment. 2.2 Phrasal Reordering Model Given a phrase sequence { w1, w2, ..., CVK} of the Lw transcript, the role</context>
<context position="21481" citStr="Mohri, 2009" startWordPosition="3610" endWordPosition="3611">k C(˜vk, ˜wrk) 2.4 Reconstruction Model Reconstruction model P(vI1|˜vK1 ,rK1 , ˜wK1 ,wJ1 ) operates in the opposite direction as the segmentation 6For simplicity, reordering sequence distributions are not shown there. model. It generates a word sequence vI1 from a phrase sequence ˜vK1 . The reconstruction model can be implemented by a WFST Rv. An example of Rv is shown in Figure 3(a4), which reconstructs a phrase v2 v3 into a word sequence {v2, v3}. 3 Speech Recognition with Cross-Lingual Language Models The translation model P(vI1|wJ1 ) can be constructed via WFST composition (denoted by ◦) (Mohri, 2009) of all the component models as shown in Eq. (7) and Figure 3, where T is the final composed WFST that transduces vI1 to wJ1 . T = Rv ◦ Tvw ◦ Ωr ◦ Sw (7) The cross-lingual language model Gcl is constructed through composition (see Eq. (8)) of the translation model and a resource-rich language model G. Gcl = T ◦ G = Rv ◦ Tvw ◦ Ωr ◦ Sw ◦ G (8) As the way of integrating a resource-rich language model G into ASR search space (Mohri et al., 2008), we can integrate the cross-lingual language model Gcl into ASR search space in a globally optimized way as well. The search space can be implemented usin</context>
<context position="22756" citStr="Mohri, 2009" startWordPosition="3844" endWordPosition="3845">roach as shown in Eq. (9). Here H transduces HMM states to context-dependent phones. C represents a transduction from context-dependent phones to contextindependent phones. L is a lexicon transducer which maps context-independent phone sequences to word strings restricted to the input symbols of the crosslingual language model transducer Gcl. ASR = H ◦ C ◦ L ◦ Gcl (9) Eq. (9) outputs the recognition result in a resourcerich language. If recognition system requires recognition outputs in a resource-poor language, then the search space should be constructed as Eq. (10), where π is a projection (Mohri, 2009) operator which projects the input label to the output label. Before decoding, the recognition transducer ASR can be optimized by a determinization operation right after each composition. ASR = H ◦ C ◦ L ◦ π(Gcl) (10) K = H k=1 K = H k=1 771 (a3) Phrase-to-phrase transduction WFST Tvw (b3) Qr o Sw o G (a1) Segmentation WFST Sw (b1) Written-style language model G w2:w2 w3:w3 2 w 1 : w 1 0 1 4 w 2 _ w 3 : w 2 -:w3 3 (a2) Reordering WFST Qr (b2) Sw o G w2�w3:w2 wl:wl 1 w2�w3:w1 wl:w2 0 2 -:w3 w3:w3 6 3 5 w2:w2 � �������� �� �� ����� � � w2:w2 wl:wl w2_w3:w2 l 0 wl:wl l w2:w2 2 w3:w3 3 -:w3 0 w3:w</context>
<context position="24306" citStr="Mohri, 2009" startWordPosition="4151" endWordPosition="4152">3_#1:w2 (a4) Reconstruction WFST Rv (b4) Tvw o Qr o Sw o G (b5) Rv o Tvw o Qr o Sw o G Figure 3: Illustration of constructing a cross-lingual language model via WFSTs: a word sequence {w1, w2, w31 represented by the L,,, language model G (b1) is segmented into a phrase sequence {w1, w2 w31 (b2); {w1, w2 w31 is reordered into {w2 w3, w11 (b3); phrase w2 w3 is transduced to v2 v3 (b4); phrase v2 v3 is reconstructed into a word sequence {v2, v31 (b5). wk and vk represent wk and vk, respectively. ”-” refers to ǫ or null symbol. Auxiliary symbols #1,#2,··· are used to make the WFST determinizable (Mohri, 2009) such that the transducer can be optimized by a determinization (Mohri, 2009) operation which significantly reduces the search network size. 772 v2:wl v3:- 4 ��� 7 wl:w2 10 -:w3 14 2 ��� 0 1 wl:wl 3 ��� 5 v2:w2 8 v3:- 11 -:w3 15 ���� 6 ��� 9 v2:w2 12 v3:- 16 #1:- 18 -:w3 20 w2:w2 13 ��� 17 w3:w3 19 4 Experimental Setup 4.1 Corpus and Model Training To investigate the performance of our proposed cross-lingual language models, we have chosen Cantonese as a resource-poor language and Mandarin as a resource-rich language. We have collected Cantonese parliamentary speech from the Hong Kong Legislat</context>
</contexts>
<marker>Mohri, 2009</marker>
<rawString>M. Mohri. 2009. Weighted automata algorithms. Handbook of Weighted Automata, pages 213–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
<author>H T Ng</author>
</authors>
<title>Improved statistical machine translation for resource-poor languages using related resource-rich languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>3</volume>
<pages>1358--1367</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2286" citStr="Nakov and Ng, 2009" startWordPosition="316" endWordPosition="319">ely depends on the availability of a large amount of suitable text data in a language. Without sufficient text data for training, it is very difficult to build a practical and usable statistical language model. Therefore, most of the advances have been reported in so called resource-rich language such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost. Today there are more than 6000 living languages spoken in the world (Gordon et al., 2005), and most of them have little transcribed texts and are considered as resource-poor languages (Nakov and Ng, 2009). Many of these languages are actually spoken by a huge number of speakers (e.g. some Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dep</context>
</contexts>
<marker>Nakov, Ng, 2009</marker>
<rawString>P. Nakov and H.T. Ng. 2009. Improved statistical machine translation for resource-poor languages using related resource-rich languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, volume 3, pages 1358–1367. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Neubig</author>
<author>Y Akita</author>
<author>S Mori</author>
<author>T Kawahara</author>
</authors>
<title>Improved statistical models for smt-based speaking style transformation.</title>
<date>2010</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<pages>5206--5209</pages>
<contexts>
<context position="2988" citStr="Neubig et al., 2010" startWordPosition="424" endWordPosition="427">ome Chinese and Indian languages), and thus there is still a great demand to build speech and language processing systems for these languages. Owing to data scarcity, most often an interpolation (Bellegarda, 2004) of language models between a resource-poor language and a resource-rich language is used in most low-resource ASR systems. Some researchers have proposed transforming resource-rich language models to resource-poor language models by word-level transduction, either in a context-independent or context-dependent manner (Hori et al., 2003; Akita and Kawahara, 2006; Jensson et al., 2009; Neubig et al., 2010). In (Jensson et al., 2009), a simple dictionary based contextindependent transduction from a resource-rich language to a resource-poor language is exploited to improve speech recognition of the resource-poor language. In (Hori et al., 2003; Akita and Kawahara, 2006; Neubig et al., 2010), context-dependent transduction is exploited. In their case, the resource-poor language is a spoken language, and the resource-rich language is a written language. They carried out language model transformation since the input speech 766 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural </context>
</contexts>
<marker>Neubig, Akita, Mori, Kawahara, 2010</marker>
<rawString>G. Neubig, Y. Akita, S. Mori, and T. Kawahara. 2010. Improved statistical models for smt-based speaking style transformation. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, pages 5206–5209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="11378" citStr="Och and Ney, 2003" startWordPosition="1753" endWordPosition="1756">(rK1 |wK1 ,wJ1 ), phrase-to-phrase transK, duction model P( vK1 |rK1 171 wJ1 ) and reconstruction model P(vI1 |vK1 ,rK1 , wK1 ,wJ1 ). Before presenting each component model, we need to extract two phrase tables for the Lv transcript and the Lw transcript, respectively. P(vI1|wJ1 ) ≈ max K K K v1 ,r1 , wl P(rK1 |wK1 , wJ1 ) · P(vP( vK 1 |rK1 , wK1 , wJ1 ) · I K K K J 1 |v1 , r1 , w1 , w1 ) (2) The phrase extraction is based on word-to-word alignments of the parallel corpus. We train word alignments in both directions with GIZA++, and then symmetrize the two alignments using the refined method (Och and Ney, 2003). Figure 1 shows an example of word-to-word alignment results between an Lv transcript (Cantonese) and an Lw transcript (Mandarin), from which phrase-to-phrase alignments are derived by identifying deletion, substitution, insertion and inversion. Prior to phrasal reordering, the segmentation model P( wK1 |wJ1 ) implemented by a segmentation WFST 5w is applied to segment a word sequence wJ1 in the Lw language model into a phrase sequence { w1, w2, ..., wK}. The maximum number of words that can be segmented into one phrase is controlled by a segmentation order s. An example of 5w is shown in Fig</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conf. on EMNLP and VLC,</booktitle>
<pages>20--28</pages>
<location>College Park, MD, USA.</location>
<contexts>
<context position="18968" citStr="Och et al., 1999" startWordPosition="3169" endWordPosition="3172">robable. However, it makes sense to restrict those non-monotonic reorderings when performing the translation. This not only helps the search of the most likely permutation, but also guides the pruning of unlikely permutations. K P(rK1 |�wK1 , wJ1 ) = P(r1) ri P(rk|rk−1, �wK1 ) k=2 K = P(r1) ri P(rk|rk−1) (4) k=2 We make a first order Markov assumption over the phrasal reordering model P(rK1 |wK1 , wJ1 ) (see Eq. (4)). The reordering sequence distribution is parameterized to assign decreasing likelihood to phrase reorderings { wr1, 17vr2, ... , �wrK } that diverge from the original word order (Och et al., 1999; Kumar et al., 2005). Suppose wrk = wl′ l and wrk−1 = wq′ q, the reordering sequence distribution is set as Eq. (5), where p0 is a tuning factor. We normalize the probabilities P(rk|rk−1) such that �Kk′=1,k′6=rk−1 P(rk = k′|rk−1) = 1. P(rk|rk−1) = p|l−q′−1| 0 1 (5) P(r1 = k) = K ; k ∈ {1, 2,..., K} 770 Assume that we have a phrase sequence { ˜w1, ˜w2, ˜w3}, Figure 2 shows the phrasal reordering model implemented by a reordering WFST Ωr under the first order Markov assumption for this phrase sequence. Figure 3(a2) gives one more example of Ωr, which reorders the phrase sequence {w1, w2 w3} int</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>F.J. Och, C. Tillmann, and H. Ney. 1999. Improved alignment models for statistical machine translation. In Proceedings of the Joint SIGDAT Conf. on EMNLP and VLC, pages 20–28, College Park, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th annual meeting on association for computational linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28008" citStr="Papineni et al., 2002" startWordPosition="4751" endWordPosition="4754">antonese outputs. In our experiments, we use the following evaluation criteria: WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence (Zens et al., 2004). The WER relates the speech recognition accuracy. The lower WER, the better. BLEU (bilingual evaluation understudy) score. The BLEU score measures the precision of n-grams (unigrams, bigrams, trigrams and fourgrams) with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2002). The BLEU score reflects the translation accuracy. The larger BLEU score, the better. We perform WER evaluation of decoding outputs of Eq. (10) and BLEU score evaluation of decoding outputs of Eq. (9) using the evaluation set. The WER evaluation is on the Cantonese output against the Cantonese reference transcription (manual transcription). The BLEU score evaluation is on the Mandarin output against the Mandarin reference transcription (Hansard transcription). 4.3 Parameter Settings The performance of our proposed cross-lingual language models is sensitive to many parameters. Firstly, segment</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W.J. Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Saon</author>
<author>M Picheny</author>
</authors>
<title>Lattice-based viterbi decoding techniques for speech translation.</title>
<date>2007</date>
<booktitle>In Automatic Speech Recognition &amp; Understanding,</booktitle>
<pages>386--389</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6743" citStr="Saon and Picheny, 2007" startWordPosition="982" endWordPosition="985">del with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This creates an integrated speech transcription and translation framework. This paper is organized as follows: Secti</context>
</contexts>
<marker>Saon, Picheny, 2007</marker>
<rawString>G. Saon and M. Picheny. 2007. Lattice-based viterbi decoding techniques for speech translation. In Automatic Speech Recognition &amp; Understanding, 2007. ASRU. IEEE Workshop on, pages 386–389. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>Srilm-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In 7th International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="1639" citStr="Stolcke, 2002" startWordPosition="215" endWordPosition="216">ch transcription and translation system. Evaluations on resource-poor Cantonese speech transcription and Cantonese to resource-rich Mandarin translation tasks show that our proposed approach improves the system performance significantly, up to 3.4% relative WER reduction in Cantonese transcription and 13.3% relative bilingual evaluation understudy (BLEU) score improvement in Mandarin transcription compared with the system without reordering. 1 Introduction Statistical language modeling techniques have achieved remarkable success in speech and language processing (Clarkson and Rosenfeld, 1997; Stolcke, 2002). However, this success largely depends on the availability of a large amount of suitable text data in a language. Without sufficient text data for training, it is very difficult to build a practical and usable statistical language model. Therefore, most of the advances have been reported in so called resource-rich language such as English, Mandarin and Japanese, after creating linguistic resources of these languages at considerable cost. Today there are more than 6000 living languages spoken in the world (Gordon et al., 2005), and most of them have little transcribed texts and are considered </context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. Srilm-an extensible language modeling toolkit. In 7th International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>ComputationalLinguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="6187" citStr="Wu, 1997" startWordPosition="891" endWordPosition="892">st that a better approach than interpolation and word-level transduction is to use crosslingual language modeling with syntactic reorder1For example, Hindi and Malayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM c</context>
<context position="15536" citStr="Wu, 1997" startWordPosition="2516" endWordPosition="2517"> i1 &lt; i2 &lt; ... &lt; iM ≤ K exists such that ri1ri2 ... rim has all the same pairwise comparisons as τ. We denote the set of permutations of SK not containing subsequences of type τ by SK(τ). If we have sets SK(τ1), ... , SK(τp), we denote the set SK(τ1) ∩ ... ∩ SK(τp) by SK(τ1, ... , τp) (Barcucci et al., 2000). ITG constraints allow the permutation set SK(3142, 2413), which forbids subsequence of type (3, 1, 4, 2) and its dual (2, 4, 1, 3). Explicitly, ITG constraints avoid any permutation rK1 satisfying either ri2 &lt; ri¢ &lt; ri1 &lt; ri3 or ri3 &lt; ri1 &lt; ri¢ &lt; ri2, where 1 ≤ i1 &lt; i2 &lt; i3 &lt; i4 ≤ K. In (Wu, 1997), these forbidden subsequences are called “inside-out” transpositions. They are fairly distorted matchings, and hardly observed in real parallel data. In order to get an intuitive sense of the reordering capability of those three constraints, we list the number of permutations under local constraints, IBM constraints as well as ITG constraints5 in Table 1. 5Interestingly, when K = L, the number of permutations under ITG constraints NITG = |SK(3142, 2413)|, and |SK(3142, 2413) |equals the K −1-th Schr¨oder numbers sK−1 (Ehrenfeucht et al., 1998) i j 1-1 2-2 3-4 4-6 4-7 5-8 6-5 7-3 8-3 i 1 3 4 5</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>D. Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. ComputationalLinguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>A comparative study on reordering constraints in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>144--151</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan.</location>
<contexts>
<context position="6357" citStr="Zens and Ney, 2003" startWordPosition="919" endWordPosition="922">alayalam (Geethakumary, 2002). 2Since Cantonese does not have an official written form, there are very few written texts available for training language models. In this paper, we treat Cantonese as a typical resourcepoor language and Mandarin as a typical resource-rich language. This language pair will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differen</context>
<context position="14368" citStr="Zens and Ney, 2003" startWordPosition="2262" endWordPosition="2265">e generation of rK1 under local constraints can be viewed as solving of the following problem (Kløve, 2009): secutive words forming a phrase. 4The concept of reordering distance also applies to other constraints. How many permutations of {1,2,... k ..., K} satisfy |rk − k |&lt; L for all k? IBM constraints, a superset of local constraints (Dreyer et al., 2007), generate permutations rK 1 deviate from the monotonic phrase order {rK1 : rk = k}. More specifically, any phrase position rk can be selected from the positions of the first m yet uncovered phrases (see Eq. (3)). A typical value of m is 4 (Zens and Ney, 2003), and we write IBM constraints with m = 4 as IBM(4). { {1, 2, ..., k − 1 + m; rk =6 rk′=,4k} if k ≤ K + 1 − m, {1, 2, ..., K; rk =6 rk′�k} if K + 1 − m &lt; k ≤ K. ITG constraints provide a more faithful coverage of syntactic reordering in the parallel data than local constraints and IBM constraints. Our presentation of ITG constraints starts with defining of some permutation sets. Let SK be the set of permutations on {1,2,...,K}. A permutation rK1 ∈ SK, where rK1 = r1r2 ... rK, contains a subsequence of type τ ∈ SM if and only if a sequence of indices 1 ≤ i1 &lt; i2 &lt; ... &lt; iM ≤ K exists such that </context>
</contexts>
<marker>Zens, Ney, 2003</marker>
<rawString>R. Zens and H. Ney. 2003. A comparative study on reordering constraints in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 144–151, Sapporo, Japan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
<author>T Watanabe</author>
<author>E Sumita</author>
</authors>
<title>Reordering constraints for phrase-based statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>205--211</pages>
<institution>Geneva, Switzerland. Association for Computational Linguistics.</institution>
<contexts>
<context position="27689" citStr="Zens et al., 2004" startWordPosition="4704" endWordPosition="4707">ined by composition of T and G. 4.2 Decoding and Evaluation Method Decoding of the speech recognition search space ASR is performed by T3 Decoder (Dixon et al., 2009), which is a state-of-the-art WFST-based LVCSR speech decoder. Decoding of ASR in Eq. (9) gives Mandarin outputs. Decoding of ASR in Eq. (10) gives Cantonese outputs. In our experiments, we use the following evaluation criteria: WER (word error rate). The WER is computed as the minimum number of substitution, insertion and deletion operations that have to be performed to convert the generated sentence into the reference sentence (Zens et al., 2004). The WER relates the speech recognition accuracy. The lower WER, the better. BLEU (bilingual evaluation understudy) score. The BLEU score measures the precision of n-grams (unigrams, bigrams, trigrams and fourgrams) with respect to a reference translation with a penalty for too short sentences (Papineni et al., 2002). The BLEU score reflects the translation accuracy. The larger BLEU score, the better. We perform WER evaluation of decoding outputs of Eq. (10) and BLEU score evaluation of decoding outputs of Eq. (9) using the evaluation set. The WER evaluation is on the Cantonese output against</context>
</contexts>
<marker>Zens, Ney, Watanabe, Sumita, 2004</marker>
<rawString>R. Zens, H. Ney, T. Watanabe, and E. Sumita. 2004. Reordering constraints for phrase-based statistical machine translation. In Proceedings of the 20th international conference on Computational Linguistics, pages 205–211, Geneva, Switzerland. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zhou</author>
<author>S F Chen</author>
<author>Y Gao</author>
</authors>
<title>Constrained phrase-based translation using weighted finite-state transducers.</title>
<date>2005</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>1017--1020</pages>
<contexts>
<context position="6652" citStr="Zhou et al., 2005" startWordPosition="965" endWordPosition="968">ir will be used for illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This creates an integrate</context>
</contexts>
<marker>Zhou, Chen, Gao, 2005</marker>
<rawString>B. Zhou, S.F. Chen, and Y. Gao. 2005. Constrained phrase-based translation using weighted finite-state transducers. In Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing, volume 1, pages 1017–1020.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Zhou</author>
<author>S F Chen</author>
<author>Y Gao</author>
</authors>
<title>Folsom: A fast and memory-efficient phrase-based approach to statistical machine translation.</title>
<date>2006</date>
<booktitle>In Spoken Language Technology Workshop,</booktitle>
<pages>226--229</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6671" citStr="Zhou et al., 2006" startWordPosition="969" endWordPosition="972"> illustration purposes throughout this paper. ing. A reordering model with reordering constraints, such as ITG constraints (Wu, 1997), IBM constraints (Berger et al., 1996), and local constraints (Kumar and Byrne, 2005) can account for the syntactic differences. It has been shown in (Zens and Ney, 2003; Kanthak et al., 2005; Dreyer et al., 2007) that ITG constraints perform better than other constraints when tackling the reordering between many language pairs. Previous work on weighted finitestate transducer (WFST) based speech translation such as (Casacuberta et al., 2004; Zhou et al., 2005; Zhou et al., 2006; Mathias and Byrne, 2006; Matusov et al., 2006; Saon and Picheny, 2007) only train the reordering model using IBM constraints, local constraints or ad hoc rules. We will use ITG constraints, which have only been applied to text translation tasks before, to model the syntactic differences in cross-lingual language modeling for speech recognition. We will implement a cross-lingual language model using WFSTs, and integrate it into a WFSTbased speech recognition search space to give both resource-poor language and resource-rich language transcriptions. This creates an integrated speech transcript</context>
</contexts>
<marker>Zhou, Chen, Gao, 2006</marker>
<rawString>B. Zhou, S. F. Chen, and Y. Gao. 2006. Folsom: A fast and memory-efficient phrase-based approach to statistical machine translation. In Spoken Language Technology Workshop, pages 226–229. IEEE.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>