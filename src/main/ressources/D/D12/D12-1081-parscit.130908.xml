<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.970747">
Identifying Constant and Unique Relations by using Time-Series Text
</title>
<author confidence="0.988525">
Yohei Takaku* Nobuhiro Kaji and Naoki Yoshinaga
</author>
<affiliation confidence="0.942029">
Toyo Keizai Inc. Institute of Industrial Science,
Chuo-ku, Tokyo 103-8345, Japan University of Tokyo
</affiliation>
<email confidence="0.6884005">
takaku.yohei@gmail.com Meguro-ku, Tokyo 153-8505, Japan
{kaji,ynaga}@tkl.iis.u-tokyo.ac.jp
</email>
<author confidence="0.990443">
Masashi Toyoda
</author>
<affiliation confidence="0.938436333333333">
Institute of Industrial Science,
University of Tokyo
Meguro-ku, Tokyo 153-8505, Japan
</affiliation>
<email confidence="0.998102">
toyoda@tkl.iis.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.995637" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999494875">
Because the real world evolves over time, nu-
merous relations between entities written in
presently available texts are already obsolete
or will potentially evolve in the future. This
study aims at resolving the intricacy in con-
sistently compiling relations extracted from
text, and presents a method for identifying
constancy and uniqueness of the relations in
the context of supervised learning. We ex-
ploit massive time-series web texts to induce
features on the basis of time-series frequency
and linguistic cues. Experimental results con-
firmed that the time-series frequency distribu-
tions contributed much to the recall of con-
stancy identification and the precision of the
uniqueness identification.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997022833333333">
We have witnessed a number of success stories in
acquiring semantic relations between entities from
ever-increasing text on the web (Pantel and Pennac-
chiotti, 2006; Banko et al., 2007; Suchanek et al.,
2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al.,
2009; Wu and Weld, 2010). These studies have suc-
cessfully revealed to us millions of relations between
real-world entities, which have been proven to be
beneficial in solving knowledge-rich problems such
as question answering and textual entailment (Fer-
rucci et al., 2010).
&apos;This work was conducted while the first author was a grad-
uate student at University of Tokyo.
There exists, however, a great challenge to com-
pile consistently relations extracted from text by
these methods, because they assume a simplifying
assumption that relations are time-invariant. In other
words, they implicitly disregard the fact that state-
ments in texts actually reflect the state of the world
at the time when they were written, which follows
that relations extracted from such texts eventually
become outdated as the real world evolves over time.
Let us consider that relations are extracted from
the following sentences:1
</bodyText>
<listItem confidence="0.57793225">
(1) a. 1Q84 is written by Haruki Murakami.
b. Moselle river flows through Germany.
c. U.S.’s president is George Bush.
d. Pentax sells K-5, a digital SLR.
</listItem>
<bodyText confidence="0.99818075">
Here, italicized predicates represent the relations,
while underlined entities are their arguments. The
relations in statements 1a and 1b are true across
time, so we can simply accumulate all the relation
instances. The relations in 1c and 1d in contrast
evolve over time. The relation written in 1c be-
comes outdated when the other person takes the
position, so we need to supersede it when a new
relation is extracted from text (e.g., U.S’s president
is Barack Obama). For the relation in 1d, we do not
always need to supersede it with a new relation.
This study is motivated from the above consider-
</bodyText>
<footnote confidence="0.55584725">
&apos;Since our task settings are language-independent, we here-
after employ English examples as much as possible to widen
the potential readership of the paper, although we conducted
experiments with relations between entities in Japanese.
</footnote>
<page confidence="0.975014">
883
</page>
<note confidence="0.8084775">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 883–892, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999881241379311">
ations and proposes a method for identifying con-
stancy and uniqueness of relations in order to se-
lect an appropriate strategy to maintain relation in-
stances extracted from text. For example, the rela-
tions written in statements 1a and 1b are constant,
while those in 1c and 1d are non-constant; the re-
lation in 1c is unique,2 whereas the relation in 1d
is non-unique. With these properties of relations in
mind, we can accumulate constant relations while
appropriately superseding non-constant, unique re-
lations with newly acquired relations.
We locate each identification task in the context
of supervised classification. The key challenge in
solving these classification tasks is how to induce an
effective feature that identifies unique, non-constant
relations (statement 1c) that seemingly appear as
non-unique relations on text (statement 1b). We ex-
ploit massive time-series web text to observe actual
evolutions of relation instances and induce features
from the relation instances taken from a time sliding
window and linguistic cues modifying the predicate
and arguments of the target relation.
We evaluated our method on 1000 relations ex-
tracted from 6-year’s worth of Japanese blog posts
with 2.3-billion sentences. We have thereby con-
firmed that the features induced from this time-series
text contributed much to improve the classification
accuracy.
The main contributions of this paper are twofold:
</bodyText>
<listItem confidence="0.968290125">
• We have introduced a novel task for identify-
ing constancy relations. Since most of the ex-
isting studies assume that relations are time-
invariant as discussed by Weikum et al. (2011),
non-constant relations prevalent in their out-
come incur a serious problem in maintaining
the acquired relations. The notion of constancy
is meant to resolve this stalemate.
• We have for the first time demonstrated the
usefulness of a time-series text in relation ac-
quisition and confirmed its impact in the two
relation classification tasks. The features in-
duced from the time-series text have greatly
contributed to the accuracy of the classification
based on uniqueness as well as the recall of the
classification based on constancy.
</listItem>
<footnote confidence="0.795373166666667">
2This kind of relation is referred to as functional relation in
the literature (Ritter et al., 2008; Lin et al., 2010).
Constant Non-constant
arg1 was born in arg2 arg1’s president is arg2
arg1 is a father of arg2 arg1 belongs to arg2
arg1 is written by arg2 arg1 lives in arg2
</footnote>
<tableCaption confidence="0.998475">
Table 1: Examples of constant, non-constant relations.
</tableCaption>
<bodyText confidence="0.999619222222222">
The reminder of this paper is structured as fol-
lows. Section 2 introduces the two properties of
relations (constancy and uniqueness) and then de-
fines the task setting of this study. Sections 3 and 4
describe the features induced from time-series text
for constancy and uniqueness classification, respec-
tively. Section 5 reports experimental results. Sec-
tion 6 addresses work related to this study. Section 7
concludes this study and mentions future work.
</bodyText>
<sectionHeader confidence="0.997318" genericHeader="introduction">
2 Classification of Relations based on
Constancy and Uniqueness
</sectionHeader>
<subsectionHeader confidence="0.9989">
2.1 Constancy and uniqueness
</subsectionHeader>
<bodyText confidence="0.999956772727273">
We introduce two properties of relations: constancy
and uniqueness.
A relation is constant if, for most values of arg1,
the value of arg2 is independent of time (Table 1).
For example, (arg1 was born in arg2) is a constant
relation since one’s birthplace never changes. On the
other hand, (arg1 ’s president is arg2) is an example
of non-constant relations. This can be checked by
noting that, for example, the president of the United
States was Barack Obama in 2011 but was previ-
ously George Bush and Bill Clinton before him.
A relation is unique if, for most values of arg1,
there exists, at any given point in time, only one
value of arg2 that satisfies the relation (Table 2). For
example, (arg1 was born in arg2) is obviously a
unique relation. The relation (arg1 is headquartered
in arg2) is also unique, while it is non-constant. No-
tice that there is usually only one headquarters at any
point in time, although the location of a headquarters
can change. In contrast, the relation (arg1 is funded
by arg2) is a non-unique relation since it is likely
that there exist more than one funder.
</bodyText>
<subsectionHeader confidence="0.979031">
2.2 Discussion
</subsectionHeader>
<bodyText confidence="0.98690925">
Both constancy and uniqueness are properties that
usually, not always, hold for most, not all, of the
arg1’s values. To see this, let us examine the relation
(arg1 ’s president is arg2). Although this relation is
</bodyText>
<page confidence="0.999325">
884
</page>
<tableCaption confidence="0.9824234">
Unique Non-unique
arg1 was born in arg2 arg1 is funded by arg2
arg1 is headquartered in arg2 arg1 consists of arg2
arg1’s president is arg2 arg1 borders on arg2
Table 2: Examples of unique and non-unique relations.
</tableCaption>
<bodyText confidence="0.9997245">
non-constant and unique (Table 1 and 2), it is still
possible to find exceptional cases. For example, a
country might exist in which the president has never
changed; a country might have more than one pres-
ident at the same time during civil war. However,
since such situations are rare, the relation (arg1 ’s
president is arg2) is considered as neither constant
nor non-unique.
The above discussion implies that the constancy
and uniqueness of relations can not be determined
completely objectively. We, nevertheless, claim that
these properties of relations are intuitively accept-
able and thus they can be identified with moderate
agreement by different people (see section 5).
</bodyText>
<subsectionHeader confidence="0.995431">
2.3 Task and our approach
</subsectionHeader>
<bodyText confidence="0.999907454545454">
This paper explores classifying given relations on
the basis of constancy and uniqueness. We treat
the problem as two independent binary classification
tasks, and train supervised classifiers.
The technical challenge we address in this paper
is how to design features for the two tasks. Section
3 presents features based on time-series frequency
and linguistic cues for classifying constant and non-
constant relations. Similarly, section 4 presents
analogous features for classifying unique and non-
unique relations.
</bodyText>
<sectionHeader confidence="0.999715" genericHeader="method">
3 Features for Constancy Classification
</sectionHeader>
<subsectionHeader confidence="0.996025">
3.1 Time-series frequency
</subsectionHeader>
<bodyText confidence="0.9978998">
It is intuitive to identify constant relations by com-
paring frequency distributions over arg2 in different
time periods. This idea leads us to use frequency
estimates from time-series text as features.
Time-series text For a time-series text, we used
Japanese blog posts that had been gathered from
Feb. 2006 to Sep. 2011 (68 months). These data in-
clude 2.3 billions of sentences. These posts were ag-
gregated on a monthly basis by using time stamps at-
tached with them, i.e., the unit of time is one month
</bodyText>
<figure confidence="0.611312">
Mar-08 Sep-08 Mar-09 Sep-09 Mar-10 Sep-10 Mar-11 Sep-11
</figure>
<figureCaption confidence="0.999309">
Figure 1: Time-series frequency distribution of (arg1 be-
longs to arg2) when arg1 takes Keisuke Honda.
</figureCaption>
<bodyText confidence="0.9975138">
in our corpus.
Basic idea For constant relations (e.g., (arg1 was
born in arg2)), we can expect that the frequency dis-
tributions over arg2 for a given arg1 (e.g., Mozart)
are similar to each other irrespective of the time win-
dows that are used to estimate frequency.
In the case of non-constant relations (e.g., (arg1
belongs to arg2)), on the other hand, the frequency
distributions over arg2 for a given arg1 significantly
differ depending on the time window. For exam-
ple, Figure 1 illustrates the frequency distributions
of arg2s for (arg1 belongs to arg2) in which arg1
takes Keisuke Honda, a famous football player. We
can clearly observe that due to Keisuke Honda being
sold from VVV Venlo to CSKA Moscow, the distri-
butions differ greatly between 2008 and 2010.
As is evident from the above discussions, the sta-
bility/change in the distribution over arg2 is a good
indicator of constant/non-constant relations. The
following subsection addresses how to encode such
information as features.
Feature computation Let us examine using as
features the cosine similarity between frequency dis-
tributions over arg2. Averaging such similarities
over representative values of arg1, we have
</bodyText>
<equation confidence="0.991705">
1 ∑
N
eE£N(r)
</equation>
<bodyText confidence="0.99825075">
where r is a relation (e.g., (arg1 ’s president is
arg2)), e is a named entity (e.g., United States) ap-
pearing in arg1, and F,,,(r, e) is the frequency distri-
bution over arg2 when arg1 takes e. The subscripts
</bodyText>
<figure confidence="0.991795428571429">
PAO Chelsea
Chairman Haiberuden Luzhniki Stadium
Dutch league Italy
VVV VVV Venlo
CSKA Moscow
8
6
4
2
0
Frequency
12
10
cos(F7A11(r, e), F,,12(r, e)),
</figure>
<page confidence="0.992866">
885
</page>
<bodyText confidence="0.999573357142857">
w1 and w2 denote the time window (e.g., from Jan.
2011 to Feb. 2011) used to estimate the frequency
distribution. EN(r) denotes a set of top N frequent
entities appearing in arg1. We use the entire time-
series text to obtain EN(r).
Unfortunately, this idea is not suitable for our pur-
pose. The problem is that it is not clear how to deter-
mine the two time windows, w1 and w2. To identify
non-constant relations, arg2 must have different val-
ues in the two time periods. Such time windows are,
however, impossible to know of in advance.
We propose avoiding this difficulty by using av-
erage, maximum and minimum similarity over all
possible time windows:
</bodyText>
<equation confidence="0.9993428">
1 ∑
N
eE£N(r)
cos(Fw1(r, e), Fw2(r, e)),
cos(Fw1(r, e), Fw2(r, e)),
</equation>
<bodyText confidence="0.9999433">
where WT is a set of all time windows of the size
T. For example, if we set T to 3 (months) in the
68-month’s worth of blog posts, WT consists of 66
(= 68−3+1) time windows. Although we still have
to specify the number of entities N and the window
size T, this is not a serious problem in practice. We
set N to 100. We use four window sizes (1, 3, 6, and
12 months) and induce different features for each
window size. As a result, we have 12 real-valued
features.
</bodyText>
<subsectionHeader confidence="0.999653">
3.2 Linguistic cues
</subsectionHeader>
<bodyText confidence="0.999059">
This subsection presents two types of linguistically-
motivated features for discriminating between con-
stant and non-constant relations.
Nominal modifiers We observe that non-constant
relations could be indicated by some nominal modi-
fiers:
</bodyText>
<listItem confidence="0.8500545">
(2) a. George Bush, ex-president of USA.
b. Lincoln is the first president of the USA.
</listItem>
<bodyText confidence="0.9062604">
The use of the prefix ex- and the adjective first im-
plies that the president changes, and hence the rela-
tion (arg1 ’s president is arg2) is not constant.
I1 (ex-), W (present), �M (next), irc (former), ff (new),
IR (old), IIe (successive), �UIe (first), �9 (first)
</bodyText>
<tableCaption confidence="0.856419">
Table 3: Japanese prefixes and adjectives indicating non-
constant relations. The translations are provided in the
parentheses.
</tableCaption>
<bodyText confidence="0.9882245">
We propose making use of such modifiers as fea-
tures. Although the above examples are in English,
we think modifiers also exist that have similar mean-
ings in other languages including Japanese, our tar-
get language.
Our new features are induced as follows:
</bodyText>
<listItem confidence="0.923983105263158">
• First, we manually list eight nominal modifiers
that indicate the non-constancy (Table 3).
• Next, we extract nouns from a relation to
be classified (e.g., president), and count the
frequency with which each modifier modifies
those nouns. We use the same blog posts as in
section 3.1 for counting the frequency. Since
time information is not important in this case,
the frequency is simply accumulated over the
entire time span.
• We then generate eight features, one for each of
the eight modifiers. The value of the features
is one if the frequency exceeds threshold 01,3
otherwise it is zero. Note that the value of this
feature is always zero if the relation includes no
nouns.
Tense and aspect Tense and aspect of verbs are
also important indicators of the non-constancy:
(3) The U.S. president was George Bush.
</listItem>
<bodyText confidence="0.935506">
If a relation, such as (arg1 ’s president is arg2), can
often be rephrased in the past tense as in (3), it is
likely to be, if not always, a non-constant relation.
It is, fortunately, straightforward to recognize
tense and aspect in Japanese, because they are ex-
pressed by attaching suffixes to verbs. In this study,
we use three common suffixes: “Pt”, “-C�6”, and
“-C6”. The first suffix expresses past tense, while
the other two express present continuous or progres-
sive aspects depending on context.
</bodyText>
<figure confidence="0.721119222222222">
3θ1 = 10 in our experiment.
ave cos(Fw1(r, e), Fw2(r, e)),
w1,w2EWT
1 ∑ max
N w1,w2EWT
eE£N(r)
1 ∑ min
N w1,w2EWT
eE£N(r)
</figure>
<page confidence="0.99342">
886
</page>
<bodyText confidence="0.999895272727273">
A given relation is transformed into different
forms by attaching the suffixes to a verb in the rela-
tion, and their frequencies are counted. By using the
frequency estimates, we generate three new features,
each of which corresponds to one of the three suf-
fixes. The value of the new features is one if the fre-
quency exceeds threshold 82,4 otherwise it is zero.
The frequency is counted in the same way as in
the case of the nominal modifiers. The value of
this feature is always zero if the relation includes no
verbs.
</bodyText>
<sectionHeader confidence="0.999816" genericHeader="method">
4 Features for Uniqueness Classification
</sectionHeader>
<bodyText confidence="0.9998945">
This section provides features for identifying unique
relations. These features are also based on the time-
series text and linguistic cues, as in the case of con-
stancy classification.
</bodyText>
<subsectionHeader confidence="0.976574">
4.1 Time-series frequency
</subsectionHeader>
<bodyText confidence="0.99999108">
Number of entity types A straightforward ap-
proach to identifying unique relations is, for a given
arg1, to count the number of entity types appear-
ing in arg2 (Lin et al., 2010). For unique relations,
the number of entity types should be one in an ideal
noiseless situation. Even if the estimate is contam-
inated by noise, a small number of entity types can
still be considered to indicate the uniqueness of the
relation.
A shortcoming of such a simple approach is that
it never considers the (non-)constancy of relations.
Presume counting the number of entity types in arg2
of the relation (arg1 is headquartered in arg2),
which is non-constant and unique. If we use large
size of time window to obtain counts, we will ob-
serve multiple types of entities in arg2, not because
the relation is non-unique, but because it is non-
constant. This problem cannot be resolved by triv-
ially using very small windows, since a time win-
dow that is too small in turn causes a data sparseness
problem.
This problem is attributed to the difficulty in de-
termining the appropriate size of the time window.
We tackle this problem by using the same technique
presented in section 3.1. Specifically, we use the fol-
</bodyText>
<equation confidence="0.970380454545455">
4θ2 = 3000 in our experiment.
lowing three measures as features:
1 ∑
N
eE£N(r)
1 ∑
N
eE£N(r)
1 ∑
N
eE£N(r)
</equation>
<bodyText confidence="0.999800636363636">
where the function #type(·) denotes the number of
entity types appearing in arg2.
Ratio of entity frequency Since it is not reliable
enough to use only the number of entity types, we
also exploit the frequency of the entity. Let e1st and
e2nd be the most and the second most frequent enti-
ties found in arg2. If the frequency of e1st is much
larger than that of e2nd, the relation is likely to be
constant.
To encode this intuition, the following measures
are used as features:
</bodyText>
<equation confidence="0.647660666666667">
fw(e, r, e1st)
fw(e, r, e2nd)
fw(e, r, e1st)
fw(e, r, e2nd)
fw(e, r, e1st)
fw(e, r, e2nd)
</equation>
<bodyText confidence="0.999878333333333">
where the fw(e, r, e&apos;) is the frequency of the relation
r in which arg1 and arg2 take e and e&apos;, respectively.
The subscript w denotes the time window.
</bodyText>
<subsectionHeader confidence="0.9388">
4.2 Linguistic cues
</subsectionHeader>
<listItem confidence="0.84113525">
Coordination structures and some keywords indicate
non-unique relations:
(4) a. France borders on Italy and Spain.
b. France borders on Italy etc.
</listItem>
<bodyText confidence="0.9986968">
The coordination structure in the first example im-
plies an entity can border on more than one entity,
and hence the relation (arg1 borders on arg2) is not
unique. The keyword etc. in the second example also
indicates the non-uniqueness.
</bodyText>
<figure confidence="0.993518285714286">
ave #type(Fw(r, e)),
wEWT
max #type(Fw(r, e)),
wEWT
min #type(Fw(r, e)),
wEWT
1 ∑
N
eE£N(r)
1 ∑
N
eE£N(r)
1 ∑
N
eE£N(r)
ave
wEWT
max
wEWT
min
wEWT
</figure>
<page confidence="0.973574">
887
</page>
<tableCaption confidence="0.892775333333333">
と, とか, や, やら, だの, なり, か
Table 4: List of Japanese particles that are used to form
coordination structures.
</tableCaption>
<bodyText confidence="0.999814444444445">
To capture this intuition, we introduce two types
of linguistic features for classifying unique and non-
unique relations. The first feature checks whether
entities in arg2 form coordination structures. The
feature is fired if the number of times that coordina-
tion structures are found in arg2 exceeds threshold
83.5 Coordination structures are identified by a list
of Japanese particles, which roughly correspond to
and or or in English (Table 4). If two entities are
connected by one of those particles, they are seen as
forming a coordination structure.
The second feature exploits such keywords as etc.
for identifying non-unique relations. We list four
Japanese keywords that have similar meaning to the
English word etc., and induce another binary fea-
ture6. The feature is fired if the number of times that
an entity in arg2 is followed by one of the four key-
words exceeds threshold 03.
</bodyText>
<sectionHeader confidence="0.99083" genericHeader="method">
5 Experiments and discussions
</sectionHeader>
<bodyText confidence="0.999864">
We built labeled data and examine the classification
performance of the proposed method. We also an-
alyzed the influence of window size T on the per-
formance, as well as major errors caused by our
method.
</bodyText>
<subsectionHeader confidence="0.952266">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999990363636364">
We built a dataset for evaluation by extracting rela-
tions from the time-series text (section 3.1) and then
manually annotating 1000 relations. The detailed
procedure is as follows.
First, we parsed the time-series text and extracted
as relation dependency paths connecting two named
entities. We used J.DepP,7 an efficient shift-reduce
parser with feature sequence trie (Yoshinaga and
Kitsuregawa, 2009; Yoshinaga and Kitsuregawa,
2010), for parsing. All Japanese words that conju-
gate were normalized into standard forms.
</bodyText>
<footnote confidence="0.857385">
5θ3 = 10 in our experiment.
6The keywords we used are 等, ら, たち, and 達.
7http://www.tkl.iis.u-tokyo.ac.jp/
—ynaga/jdepp/
</footnote>
<figure confidence="0.965514">
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.9971635">
Figure 2: Recall-precision curve (constancy classifica-
tion).
</figureCaption>
<bodyText confidence="0.99999325">
Then, annotators were asked to label 1000 rela-
tions as not only constant or non-constant but also
unique or non-unique. Three annotators were as-
signed to each relation, and the goldstandard label
is determined by majority vote. The Fleiss kappa
(Fleiss, 1971) was 0.346 for constancy classification
and was 0.428 for uniqueness classification. They
indicate fair and moderate agreement, respectively
(Landis and Koch, 1977).
We have briefly investigated the relations whose
labels assigned by the annotators conflicted. The
major cause was that the annotators sometimes as-
sumed different types of named entities as values
of arguments. A typical case in which this problem
arises is that the relation has polysemous meanings,
e.g., (arg1 was born in arg2), or a vague meaning,
e.g., (arg1 makes arg2). For example, arg2 of (arg1
was born in arg2) can be filled with different types
of entities such as date and place. We can address
this problem by typing arguments (Lin et al., 2010).
</bodyText>
<subsectionHeader confidence="0.975377">
5.2 Result
</subsectionHeader>
<bodyText confidence="0.997605666666667">
Using the dataset, we performed 5-fold cross-
validation for both classification tasks. We used
the passive-aggressive algorithm for our classifier
(Crammer et al., 2006).
Constancy classification Figure 2 illustrates the
recall-precision curve in constancy classification.
Because we are unaware of any previous methods
for classifying constant and non-constant relations,
a simple method based on the cosine similarity was
</bodyText>
<figure confidence="0.973365181818182">
Proposed
Baseline
Precision 1.0
0.8
0.6
0.4
0.2
0
888
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.9700055">
Figure 3: Recall-precision curve (uniqueness classifica-
tion).
</figureCaption>
<figure confidence="0.994716">
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.9816805">
Figure 4: Comparison with the methods varying a value
of N for constancy classification.
</figureCaption>
<figure confidence="0.921040363636364">
Proposed
Baseline
N = 2
N = 10
N = 20
N = 100
Precision 1.0
0.8
0.6
0.4
0.2
0
Precision 1.0
0.8
0.6
0.4
0.2
0
used as a baseline: COS(Fw1(r, e), Fw2(r, e)),
1 ∑
N
eE£N(r)
</figure>
<bodyText confidence="0.999784296296297">
where the time windows w1 and w2 are determined
as the first and last month in which the relation r
is observed. A given relation is classified as non-
constant if the above similarity exceeds a threshold.
The recall-precision curve was drawn by changing
the threshold.
The results demonstrated that our method outper-
forms the baseline. This indicates the effectiveness
of using time-series frequency and linguistic cues as
features.
The poor performance of the baseline was mainly
due to data sparseness. Since the baseline method is
dependent on the frequency estimates obtained from
only two months of texts, it is less reliable than the
proposed method.
Uniqueness classification Figure 3 illustrates the
recall-precision curve in uniqueness classification.
As a baseline we implemented the method proposed
by Lin et al. (2010). While they have presented
three methods (KLFUNC, KLDIFF, and their aver-
age), we report the results of the last one because it
performed the best among the three in our experi-
ment.
From the figure, we can again see that the pro-
posed method outperforms the baseline method.
Lin’s method is similar to ours, but differs in that
they do not exploit time-series information at all.
</bodyText>
<figure confidence="0.927946">
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.965056">
Figure 5: Comparison with the methods varying a value
of N for uniqueness classification.
</figureCaption>
<bodyText confidence="0.999846">
We hence conclude time-series information is use-
ful for classifying not only constant but also unique
relations.
</bodyText>
<subsectionHeader confidence="0.96178">
5.3 Investigation into the number of entities, N
</subsectionHeader>
<bodyText confidence="0.9996475">
We ranged the value of N in 12,10,20, 1001. Set-
ting N to a larger value yields the better recall for
constancy classification and the better precision for
uniqueness classification (Figures 4 and 5). These
results meet our expectations, since features derived
from frequency distributions of arg2 over various
arg1s capture the generic nature of the target rela-
tion.
</bodyText>
<figure confidence="0.981018333333333">
Precision
0.6
0.4
0.2
0
1.0
</figure>
<equation confidence="0.8012968">
N = 2
N = 10
N = 20
N = 100
0.8
</equation>
<page confidence="0.892161">
889
</page>
<figure confidence="0.994142">
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.996455">
Figure 6: Comparison with the methods using only a sin-
gle value of T for constancy classification.
</figureCaption>
<figure confidence="0.990313">
0 0.2 0.4 0.6 0.8 1.0
Recall
</figure>
<figureCaption confidence="0.9946975">
Figure 7: Comparison with the methods using only a sin-
gle value of T for uniqueness classification.
</figureCaption>
<subsectionHeader confidence="0.907593">
5.4 Investigation into the window size, T
</subsectionHeader>
<bodyText confidence="0.999929357142857">
Our method uses multiple time windows of different
sizes (i.e., different values of T) to induce features,
as detailed in sections 3.1 and 4.1. To confirm the
effect of this technique, we investigated the perfor-
mance when we use only a single value of T (Fig-
ures 6 and 7).
The results in the uniqueness classification task
demonstrated that our method achieves better over-
all results than the methods using a single value of
T. We can therefore consider that using multiple
values of T as features is a reasonable strategy. On
the other hand, we could not confirm the effect of
using multiple time windows of different sizes in the
constancy classification task.
</bodyText>
<subsectionHeader confidence="0.95305">
5.5 Error analysis
</subsectionHeader>
<bodyText confidence="0.999750302325582">
We randomly selected and analyzed 200 misclassi-
fied relations for both tasks. The analysis revealed
four types of errors.
Paraphrases We observed that constant relations
are prone to be miss-classified as non-constant when
more than one paraphrase appear in arg2 and thus
the value of arg2 is pretended to change. For exam-
ple, America was also referred to as USA or United
States of America. A similar problem was observed
for unique relations as well.
Topical bias Topics mentioned in the blog posts
are sometimes biased, and such bias can have a neg-
ative effect on classification, especially when a rela-
tion takes a small number of entity types in arg2 for
given arg1. For example, Jaden Smith, who is one
of Will Smith’s sons, is frequently mentioned in our
time-series text because he co-starred with his father
in a movie, while Will Smith’s other sons never ap-
peared in our text. We consider this a possible rea-
son for our method wrongly identifying (arg1 ’s son
is arg2) as a unique relation.
Short-/Long-term evolution Since we have ag-
gregated on a monthly basis the 6-year’s worth of
blog posts, the induced features cannot capture evo-
lutions that occur in shorter or longer intervals. For
example, consider relation (arg1 beats arg2) tak-
ing Real Madrid as arg1. Since Real Madrid usually
have more than one football match in a month, they
can beat several teams in a month, which misleads
the classifier to recognize the relation as non-unique.
Similarly when a relation takes more than 6 years to
evolve, it will be regarded as constant.
Reference to past, future, or speculative facts
The blog authors sometimes refer to relations that do
not occur around when they write their posts; such
relations actually occurred in the past, will occur in
the future, or even speculative. Since our method
exploits the time stamps attached to the posts to as-
sociate the relations with time, those relations in-
troduce noises in the frequency distributions. Al-
though our robust feature induction could in most
cases avoid an adverse effect caused by these noises,
they sometimes leaded to misclassification.
</bodyText>
<equation confidence="0.991561181818182">
T = 1,3,6,12
T = 1
T = 3
T = 6
T = 12
0.8
T = 1, 3,6,12
T = 1
T = 3
T = 6
T = 12
</equation>
<figure confidence="0.9825215">
0.6
0.4
0.2
0
Precision
1.0
Precision 1.0
0.8
0.6
0.4
0.2
0
</figure>
<page confidence="0.986241">
890
</page>
<sectionHeader confidence="0.999849" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999985933333333">
In recent years, much attention has been given to
extracting relations from a massive amount of tex-
tual data, especially the web (cf. section 1). Most of
those studies, however, explored just extracting re-
lations from text. Only a few studies, as described
below, have discussed classifying those relations.
There has been no previous work on identify-
ing the constancy of relations. The most relevant
research topic is the temporal information extrac-
tion (Verhagen et al., 2007; Verhagen et al., 2010;
Ling and Weld, 2010; Wang et al., 2010; Hovy et
al., 2012). This is the task of extracting from textual
data an event and the time it happened, e.g., Othello
was written by Shakespeare in 1602. Such tempo-
ral information alone is not sufficient for identifying
the constancy of relations, while we think it would
be helpful.
On the other hand, the uniqueness of relations has
so far been discussed in some studies. Ritter et al.
(2008) have pointed out the importance of identi-
fying unique relations for various NLP tasks such
as contradiction detection, quantifier scope disam-
biguation, and synonym resolution. They proposed
an EM-style algorithm for scoring the uniqueness
of relations. Lin et al. (2010) also proposed three
algorithms for identifying unique relations. While
those studies discussed the same problem as this pa-
per, they did not point out the importance of the
constancy in identifying unique relations (cf. sec-
tion 4.1).
</bodyText>
<sectionHeader confidence="0.998485" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999954875">
This paper discussed that the notion of constancy
is essential in compiling relations between enti-
ties extracted from real-world text and proposed a
method for classifying relations on the basis of con-
stancy and uniqueness. The time-series web text
was fully exploited to induce frequency-based fea-
tures from time-series frequency distribution on re-
lation instances as well as language-based features
tailored for individual classification tasks. Exper-
imental results confirmed that the frequency-based
features contributed much to the precision and recall
in both identification tasks.
We will utilize the identified properties of the re-
lations to adopt an appropriate strategy to compile
their instances. We also plan to start a spin-off re-
search that acquires paraphrases by grouping values
of arg2s for each value of arg1 in a constant, unique
relation.
We consider that the notion of constancy will even
be beneficial in acquiring world knowledge, other
than relations between entities, from text; we aim
at extending the notion of constancy to other types
of knowledge involving real-world entities, such as
concept-instance relations.
</bodyText>
<sectionHeader confidence="0.99828" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999117875">
This work was supported by the Multimedia Web
Analysis Framework towards Development of So-
cial Analysis Software program of the Ministry of
Education, Culture, Sports, Science and Technol-
ogy, Japan. The authors thank the annotators for
their hard work. The authors are also indebted to the
three anonymous reviewers for their valuable com-
ments.
</bodyText>
<sectionHeader confidence="0.999085" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999900814814815">
Michele Banko, Michael J. Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the web. In Proceedings of
IJCAI, pages 2670–2676.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shawartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research, 7:551–583.
David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James
Fan, David Gondek, Aditya A. Kalyanpur, Adam
Lally, J. William Murdock, Eric Nyberg, John Prager,
Nico Schlaefer, and Chris Welty. 2010. Building Wat-
son: An overview of the DeepQA project. AI Maga-
zine, 31(3):59–79.
Joseph L. Fleiss. 1971. Measuring nominal scale agree-
ment among many raters. Psychological Bulletin,
76(5):378–382.
Dirk Hovy, James Fan, Alfio Gliozzo, Siddharth Patward-
han, and Christopher Welty. 2012. When did that hap-
pen? — linking events and relations to timestamps. In
Proceedings of EACL, pages 185–193.
Richard J. Landis and Gary G. Koch. 1977. The mea-
surement of observer agreement for categorical data.
Biometrics, 1(33):159–174.
Thomas Lin, Mausam, and Oren Etzioni. 2010. Identify-
ing functional relation in web text. In Proceedings of
EMNLP, pages 1266–1276.
</reference>
<page confidence="0.981738">
891
</page>
<reference confidence="0.999869320754717">
Xiao Ling and Daniel S. Weld. 2010. Temporal informa-
tion extraction. In Proceedings of AAAI, pages 1385–
1390.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extraction
without labeled data. In Proceedings of ACL-IJCNLP,
pages 1003–1011.
Patrick Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging generic patterns for automatically harvest-
ing semantic relations. In Proceedings of ACL, pages
113–120.
Alan Ritter, Doug Downey, Stephen Soderland, and Oren
Etzioni. 2008. It’s a contradiction—no, it’s not: A
case study using functional relations. In Proceedings
of EMNLP, pages 11–20.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. YAGO: A core of semantic knowl-
edge unifying WordNet and Wikipedia. In Proceed-
ings of WWW, pages 697–706.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 task 15: TempEval temporal
relation identification. In Proceedings of SemEval,
pages 75–80.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 task 13:
TempEval-2. In Proceedings of SemEval, pages 57–
62.
Yafang Wang, Mingjie Zhu, Lizhen Qu, Marc Spaniol,
and Gerhard Weikum. 2010. Timely YAGO: har-
vesting, querying, and visualizing temporal knowledge
from Wikipedia. In Proceedings of EDBT, pages 697–
700.
Gerhard Weikum, Srikanta Bedathur, and Ralf Schenkel.
2011. Temporal knowledge for timely intelligence. In
Proceedings of BIRTE, pages 1–6.
Fei Wu and Daniel S. Weld. 2010. Open information
extraction using Wikipedia. In Proceedings of ACL,
pages 118–127.
Fei Wu, Raphael Hoffmann, and Daniel S. Weld. 2008.
Information extraction from Wikipedia: moving down
the long tail. In Proceedings of KDD, pages 731–739.
Naoki Yoshinaga and Masaru Kitsuregawa. 2009. Poly-
nomial to linear: Efficient classification with conjunc-
tive features. In Proceedings of EMNLP, pages 1542–
1551.
Naoki Yoshinaga and Masaru Kitsuregawa. 2010. Kernel
slicing: Scalable online training with conjunctive fea-
tures. In Proceedings of COLING, pages 1245–1253.
Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and Ji-
Rong Wen. 2009. StatSnowball: a statistical approach
to extracting entity relationships. In Proceedings of
WWW, pages 101–110.
</reference>
<page confidence="0.998274">
892
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.272231">
<title confidence="0.999169">Identifying Constant and Unique Relations by using Time-Series Text</title>
<author confidence="0.992369">Yohei Kaji Yoshinaga</author>
<affiliation confidence="0.966913">Toyo Keizai Inc. Institute of Industrial Science,</affiliation>
<address confidence="0.7510705">Chuo-ku, Tokyo 103-8345, Japan University of Tokyo Tokyo 153-8505, Japan</address>
<email confidence="0.522482">Masashi</email>
<affiliation confidence="0.999562">Institute of Industrial University of</affiliation>
<address confidence="0.975036">Meguro-ku, Tokyo 153-8505,</address>
<email confidence="0.970909">toyoda@tkl.iis.u-tokyo.ac.jp</email>
<abstract confidence="0.998980823529412">Because the real world evolves over time, numerous relations between entities written in presently available texts are already obsolete or will potentially evolve in the future. This study aims at resolving the intricacy in consistently compiling relations extracted from text, and presents a method for identifying constancy and uniqueness of the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="1348" citStr="Banko et al., 2007" startWordPosition="183" endWordPosition="186">resents a method for identifying constancy and uniqueness of the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J. Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of IJCAI, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShawartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="21732" citStr="Crammer et al., 2006" startWordPosition="3566" endWordPosition="3569"> the annotators sometimes assumed different types of named entities as values of arguments. A typical case in which this problem arises is that the relation has polysemous meanings, e.g., (arg1 was born in arg2), or a vague meaning, e.g., (arg1 makes arg2). For example, arg2 of (arg1 was born in arg2) can be filled with different types of entities such as date and place. We can address this problem by typing arguments (Lin et al., 2010). 5.2 Result Using the dataset, we performed 5-fold crossvalidation for both classification tasks. We used the passive-aggressive algorithm for our classifier (Crammer et al., 2006). Constancy classification Figure 2 illustrates the recall-precision curve in constancy classification. Because we are unaware of any previous methods for classifying constant and non-constant relations, a simple method based on the cosine similarity was Proposed Baseline Precision 1.0 0.8 0.6 0.4 0.2 0 888 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 3: Recall-precision curve (uniqueness classification). 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 4: Comparison with the methods varying a value of N for constancy classification. Proposed Baseline N = 2 N = 10 N = 20 N = 100 Precision 1.0 0.8 0.6 0.4 0.2 0 Prec</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShawartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShawartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. Journal of Machine Learning Research, 7:551–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Eric Brown</author>
<author>Jennifer Chu-Carroll</author>
<author>James Fan</author>
<author>David Gondek</author>
<author>Aditya A Kalyanpur</author>
<author>Adam Lally</author>
<author>J William Murdock</author>
</authors>
<title>Eric Nyberg,</title>
<date>2010</date>
<journal>AI Magazine,</journal>
<volume>31</volume>
<issue>3</issue>
<location>John Prager, Nico</location>
<contexts>
<context position="1694" citStr="Ferrucci et al., 2010" startWordPosition="239" endWordPosition="243"> constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are time-invariant. In other words, they implicitly disregard the fact that statements in texts actually reflect the state of the world at the time when they were written, which follows that relations extracted from such texts eventually become outdated as the real world evolves over time. Let us consider that relations are extr</context>
</contexts>
<marker>Ferrucci, Brown, Chu-Carroll, Fan, Gondek, Kalyanpur, Lally, Murdock, 2010</marker>
<rawString>David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A. Kalyanpur, Adam Lally, J. William Murdock, Eric Nyberg, John Prager, Nico Schlaefer, and Chris Welty. 2010. Building Watson: An overview of the DeepQA project. AI Magazine, 31(3):59–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<volume>76</volume>
<issue>5</issue>
<contexts>
<context position="20826" citStr="Fleiss, 1971" startWordPosition="3425" endWordPosition="3426">ga and Kitsuregawa, 2009; Yoshinaga and Kitsuregawa, 2010), for parsing. All Japanese words that conjugate were normalized into standard forms. 5θ3 = 10 in our experiment. 6The keywords we used are 等, ら, たち, and 達. 7http://www.tkl.iis.u-tokyo.ac.jp/ —ynaga/jdepp/ 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 2: Recall-precision curve (constancy classification). Then, annotators were asked to label 1000 relations as not only constant or non-constant but also unique or non-unique. Three annotators were assigned to each relation, and the goldstandard label is determined by majority vote. The Fleiss kappa (Fleiss, 1971) was 0.346 for constancy classification and was 0.428 for uniqueness classification. They indicate fair and moderate agreement, respectively (Landis and Koch, 1977). We have briefly investigated the relations whose labels assigned by the annotators conflicted. The major cause was that the annotators sometimes assumed different types of named entities as values of arguments. A typical case in which this problem arises is that the relation has polysemous meanings, e.g., (arg1 was born in arg2), or a vague meaning, e.g., (arg1 makes arg2). For example, arg2 of (arg1 was born in arg2) can be fille</context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Hovy</author>
<author>James Fan</author>
<author>Alfio Gliozzo</author>
<author>Siddharth Patwardhan</author>
<author>Christopher Welty</author>
</authors>
<title>When did that happen? — linking events and relations to timestamps.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>185--193</pages>
<contexts>
<context position="28149" citStr="Hovy et al., 2012" startWordPosition="4674" endWordPosition="4677">on 1.0 Precision 1.0 0.8 0.6 0.4 0.2 0 890 6 Related Work In recent years, much attention has been given to extracting relations from a massive amount of textual data, especially the web (cf. section 1). Most of those studies, however, explored just extracting relations from text. Only a few studies, as described below, have discussed classifying those relations. There has been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym resolution. They proposed an EM-style algorithm for scoring</context>
</contexts>
<marker>Hovy, Fan, Gliozzo, Patwardhan, Welty, 2012</marker>
<rawString>Dirk Hovy, James Fan, Alfio Gliozzo, Siddharth Patwardhan, and Christopher Welty. 2012. When did that happen? — linking events and relations to timestamps. In Proceedings of EACL, pages 185–193.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard J Landis</author>
<author>Gary G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<volume>1</volume>
<issue>33</issue>
<contexts>
<context position="20990" citStr="Landis and Koch, 1977" startWordPosition="3445" endWordPosition="3448"> our experiment. 6The keywords we used are 等, ら, たち, and 達. 7http://www.tkl.iis.u-tokyo.ac.jp/ —ynaga/jdepp/ 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 2: Recall-precision curve (constancy classification). Then, annotators were asked to label 1000 relations as not only constant or non-constant but also unique or non-unique. Three annotators were assigned to each relation, and the goldstandard label is determined by majority vote. The Fleiss kappa (Fleiss, 1971) was 0.346 for constancy classification and was 0.428 for uniqueness classification. They indicate fair and moderate agreement, respectively (Landis and Koch, 1977). We have briefly investigated the relations whose labels assigned by the annotators conflicted. The major cause was that the annotators sometimes assumed different types of named entities as values of arguments. A typical case in which this problem arises is that the relation has polysemous meanings, e.g., (arg1 was born in arg2), or a vague meaning, e.g., (arg1 makes arg2). For example, arg2 of (arg1 was born in arg2) can be filled with different types of entities such as date and place. We can address this problem by typing arguments (Lin et al., 2010). 5.2 Result Using the dataset, we perf</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>Richard J. Landis and Gary G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 1(33):159–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lin</author>
<author>Mausam</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying functional relation in web text.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1266--1276</pages>
<contexts>
<context position="5814" citStr="Lin et al., 2010" startWordPosition="890" endWordPosition="893">eir outcome incur a serious problem in maintaining the acquired relations. The notion of constancy is meant to resolve this stalemate. • We have for the first time demonstrated the usefulness of a time-series text in relation acquisition and confirmed its impact in the two relation classification tasks. The features induced from the time-series text have greatly contributed to the accuracy of the classification based on uniqueness as well as the recall of the classification based on constancy. 2This kind of relation is referred to as functional relation in the literature (Ritter et al., 2008; Lin et al., 2010). Constant Non-constant arg1 was born in arg2 arg1’s president is arg2 arg1 is a father of arg2 arg1 belongs to arg2 arg1 is written by arg2 arg1 lives in arg2 Table 1: Examples of constant, non-constant relations. The reminder of this paper is structured as follows. Section 2 introduces the two properties of relations (constancy and uniqueness) and then defines the task setting of this study. Sections 3 and 4 describe the features induced from time-series text for constancy and uniqueness classification, respectively. Section 5 reports experimental results. Section 6 addresses work related to</context>
<context position="16201" citStr="Lin et al., 2010" startWordPosition="2637" endWordPosition="2640">shold 82,4 otherwise it is zero. The frequency is counted in the same way as in the case of the nominal modifiers. The value of this feature is always zero if the relation includes no verbs. 4 Features for Uniqueness Classification This section provides features for identifying unique relations. These features are also based on the timeseries text and linguistic cues, as in the case of constancy classification. 4.1 Time-series frequency Number of entity types A straightforward approach to identifying unique relations is, for a given arg1, to count the number of entity types appearing in arg2 (Lin et al., 2010). For unique relations, the number of entity types should be one in an ideal noiseless situation. Even if the estimate is contaminated by noise, a small number of entity types can still be considered to indicate the uniqueness of the relation. A shortcoming of such a simple approach is that it never considers the (non-)constancy of relations. Presume counting the number of entity types in arg2 of the relation (arg1 is headquartered in arg2), which is non-constant and unique. If we use large size of time window to obtain counts, we will observe multiple types of entities in arg2, not because th</context>
<context position="21551" citStr="Lin et al., 2010" startWordPosition="3540" endWordPosition="3543">moderate agreement, respectively (Landis and Koch, 1977). We have briefly investigated the relations whose labels assigned by the annotators conflicted. The major cause was that the annotators sometimes assumed different types of named entities as values of arguments. A typical case in which this problem arises is that the relation has polysemous meanings, e.g., (arg1 was born in arg2), or a vague meaning, e.g., (arg1 makes arg2). For example, arg2 of (arg1 was born in arg2) can be filled with different types of entities such as date and place. We can address this problem by typing arguments (Lin et al., 2010). 5.2 Result Using the dataset, we performed 5-fold crossvalidation for both classification tasks. We used the passive-aggressive algorithm for our classifier (Crammer et al., 2006). Constancy classification Figure 2 illustrates the recall-precision curve in constancy classification. Because we are unaware of any previous methods for classifying constant and non-constant relations, a simple method based on the cosine similarity was Proposed Baseline Precision 1.0 0.8 0.6 0.4 0.2 0 888 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 3: Recall-precision curve (uniqueness classification). 0 0.2 0.4 0.6 0.8 1</context>
<context position="23250" citStr="Lin et al. (2010)" startWordPosition="3815" endWordPosition="3818">ll-precision curve was drawn by changing the threshold. The results demonstrated that our method outperforms the baseline. This indicates the effectiveness of using time-series frequency and linguistic cues as features. The poor performance of the baseline was mainly due to data sparseness. Since the baseline method is dependent on the frequency estimates obtained from only two months of texts, it is less reliable than the proposed method. Uniqueness classification Figure 3 illustrates the recall-precision curve in uniqueness classification. As a baseline we implemented the method proposed by Lin et al. (2010). While they have presented three methods (KLFUNC, KLDIFF, and their average), we report the results of the last one because it performed the best among the three in our experiment. From the figure, we can again see that the proposed method outperforms the baseline method. Lin’s method is similar to ours, but differs in that they do not exploit time-series information at all. 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 5: Comparison with the methods varying a value of N for uniqueness classification. We hence conclude time-series information is useful for classifying not only constant but also unique </context>
<context position="28796" citStr="Lin et al. (2010)" startWordPosition="4779" endWordPosition="4782">ng from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym resolution. They proposed an EM-style algorithm for scoring the uniqueness of relations. Lin et al. (2010) also proposed three algorithms for identifying unique relations. While those studies discussed the same problem as this paper, they did not point out the importance of the constancy in identifying unique relations (cf. section 4.1). 7 Conclusion This paper discussed that the notion of constancy is essential in compiling relations between entities extracted from real-world text and proposed a method for classifying relations on the basis of constancy and uniqueness. The time-series web text was fully exploited to induce frequency-based features from time-series frequency distribution on relati</context>
</contexts>
<marker>Lin, Mausam, Etzioni, 2010</marker>
<rawString>Thomas Lin, Mausam, and Oren Etzioni. 2010. Identifying functional relation in web text. In Proceedings of EMNLP, pages 1266–1276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of AAAI,</booktitle>
<pages>1385--1390</pages>
<contexts>
<context position="28110" citStr="Ling and Weld, 2010" startWordPosition="4666" endWordPosition="4669">T = 3 T = 6 T = 12 0.6 0.4 0.2 0 Precision 1.0 Precision 1.0 0.8 0.6 0.4 0.2 0 890 6 Related Work In recent years, much attention has been given to extracting relations from a massive amount of textual data, especially the web (cf. section 1). Most of those studies, however, explored just extracting relations from text. Only a few studies, as described below, have discussed classifying those relations. There has been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym resolution. They pro</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of AAAI, pages 1385– 1390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="1426" citStr="Mintz et al., 2009" startWordPosition="199" endWordPosition="202">the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are time-invariant. In other words, they implicitly disregard </context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACL-IJCNLP, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="1328" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="178" endWordPosition="182">tions extracted from text, and presents a method for identifying constancy and uniqueness of the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a si</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging generic patterns for automatically harvesting semantic relations. In Proceedings of ACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Doug Downey</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>It’s a contradiction—no, it’s not: A case study using functional relations.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>11--20</pages>
<contexts>
<context position="5795" citStr="Ritter et al., 2008" startWordPosition="886" endWordPosition="889">tions prevalent in their outcome incur a serious problem in maintaining the acquired relations. The notion of constancy is meant to resolve this stalemate. • We have for the first time demonstrated the usefulness of a time-series text in relation acquisition and confirmed its impact in the two relation classification tasks. The features induced from the time-series text have greatly contributed to the accuracy of the classification based on uniqueness as well as the recall of the classification based on constancy. 2This kind of relation is referred to as functional relation in the literature (Ritter et al., 2008; Lin et al., 2010). Constant Non-constant arg1 was born in arg2 arg1’s president is arg2 arg1 is a father of arg2 arg1 belongs to arg2 arg1 is written by arg2 arg1 lives in arg2 Table 1: Examples of constant, non-constant relations. The reminder of this paper is structured as follows. Section 2 introduces the two properties of relations (constancy and uniqueness) and then defines the task setting of this study. Sections 3 and 4 describe the features induced from time-series text for constancy and uniqueness classification, respectively. Section 5 reports experimental results. Section 6 addres</context>
<context position="28525" citStr="Ritter et al. (2008)" startWordPosition="4739" endWordPosition="4742">s been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym resolution. They proposed an EM-style algorithm for scoring the uniqueness of relations. Lin et al. (2010) also proposed three algorithms for identifying unique relations. While those studies discussed the same problem as this paper, they did not point out the importance of the constancy in identifying unique relations (cf. section 4.1). 7 Conclusion This paper discussed that the notion of constancy is essential in compiling relati</context>
</contexts>
<marker>Ritter, Downey, Soderland, Etzioni, 2008</marker>
<rawString>Alan Ritter, Doug Downey, Stephen Soderland, and Oren Etzioni. 2008. It’s a contradiction—no, it’s not: A case study using functional relations. In Proceedings of EMNLP, pages 11–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>YAGO: A core of semantic knowledge unifying WordNet and Wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>697--706</pages>
<contexts>
<context position="1371" citStr="Suchanek et al., 2007" startWordPosition="187" endWordPosition="190"> identifying constancy and uniqueness of the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are tim</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. YAGO: A core of semantic knowledge unifying WordNet and Wikipedia. In Proceedings of WWW, pages 697–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 task 15: TempEval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval,</booktitle>
<pages>75--80</pages>
<contexts>
<context position="28066" citStr="Verhagen et al., 2007" startWordPosition="4658" endWordPosition="4661"> 1 T = 3 T = 6 T = 12 0.8 T = 1, 3,6,12 T = 1 T = 3 T = 6 T = 12 0.6 0.4 0.2 0 Precision 1.0 Precision 1.0 0.8 0.6 0.4 0.2 0 890 6 Related Work In recent years, much attention has been given to extracting relations from a massive amount of textual data, especially the web (cf. section 1). Most of those studies, however, explored just extracting relations from text. Only a few studies, as described below, have discussed classifying those relations. There has been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disa</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. SemEval-2007 task 15: TempEval temporal relation identification. In Proceedings of SemEval, pages 75–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 task 13: TempEval-2. In Proceedings of SemEval,</booktitle>
<pages>57--62</pages>
<contexts>
<context position="28089" citStr="Verhagen et al., 2010" startWordPosition="4662" endWordPosition="4665">.8 T = 1, 3,6,12 T = 1 T = 3 T = 6 T = 12 0.6 0.4 0.2 0 Precision 1.0 Precision 1.0 0.8 0.6 0.4 0.2 0 890 6 Related Work In recent years, much attention has been given to extracting relations from a massive amount of textual data, especially the web (cf. section 1). Most of those studies, however, explored just extracting relations from text. Only a few studies, as described below, have discussed classifying those relations. There has been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 task 13: TempEval-2. In Proceedings of SemEval, pages 57– 62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yafang Wang</author>
<author>Mingjie Zhu</author>
<author>Lizhen Qu</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>Timely YAGO: harvesting, querying, and visualizing temporal knowledge from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of EDBT,</booktitle>
<pages>697--700</pages>
<contexts>
<context position="28129" citStr="Wang et al., 2010" startWordPosition="4670" endWordPosition="4673">6 0.4 0.2 0 Precision 1.0 Precision 1.0 0.8 0.6 0.4 0.2 0 890 6 Related Work In recent years, much attention has been given to extracting relations from a massive amount of textual data, especially the web (cf. section 1). Most of those studies, however, explored just extracting relations from text. Only a few studies, as described below, have discussed classifying those relations. There has been no previous work on identifying the constancy of relations. The most relevant research topic is the temporal information extraction (Verhagen et al., 2007; Verhagen et al., 2010; Ling and Weld, 2010; Wang et al., 2010; Hovy et al., 2012). This is the task of extracting from textual data an event and the time it happened, e.g., Othello was written by Shakespeare in 1602. Such temporal information alone is not sufficient for identifying the constancy of relations, while we think it would be helpful. On the other hand, the uniqueness of relations has so far been discussed in some studies. Ritter et al. (2008) have pointed out the importance of identifying unique relations for various NLP tasks such as contradiction detection, quantifier scope disambiguation, and synonym resolution. They proposed an EM-style a</context>
</contexts>
<marker>Wang, Zhu, Qu, Spaniol, Weikum, 2010</marker>
<rawString>Yafang Wang, Mingjie Zhu, Lizhen Qu, Marc Spaniol, and Gerhard Weikum. 2010. Timely YAGO: harvesting, querying, and visualizing temporal knowledge from Wikipedia. In Proceedings of EDBT, pages 697– 700.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Weikum</author>
<author>Srikanta Bedathur</author>
<author>Ralf Schenkel</author>
</authors>
<title>Temporal knowledge for timely intelligence.</title>
<date>2011</date>
<booktitle>In Proceedings of BIRTE,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="5157" citStr="Weikum et al. (2011)" startWordPosition="784" endWordPosition="787">ion instances taken from a time sliding window and linguistic cues modifying the predicate and arguments of the target relation. We evaluated our method on 1000 relations extracted from 6-year’s worth of Japanese blog posts with 2.3-billion sentences. We have thereby confirmed that the features induced from this time-series text contributed much to improve the classification accuracy. The main contributions of this paper are twofold: • We have introduced a novel task for identifying constancy relations. Since most of the existing studies assume that relations are timeinvariant as discussed by Weikum et al. (2011), non-constant relations prevalent in their outcome incur a serious problem in maintaining the acquired relations. The notion of constancy is meant to resolve this stalemate. • We have for the first time demonstrated the usefulness of a time-series text in relation acquisition and confirmed its impact in the two relation classification tasks. The features induced from the time-series text have greatly contributed to the accuracy of the classification based on uniqueness as well as the recall of the classification based on constancy. 2This kind of relation is referred to as functional relation </context>
</contexts>
<marker>Weikum, Bedathur, Schenkel, 2011</marker>
<rawString>Gerhard Weikum, Srikanta Bedathur, and Ralf Schenkel. 2011. Temporal knowledge for timely intelligence. In Proceedings of BIRTE, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>118--127</pages>
<contexts>
<context position="1446" citStr="Wu and Weld, 2010" startWordPosition="203" endWordPosition="206">vised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are time-invariant. In other words, they implicitly disregard the fact that statem</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S. Weld. 2010. Open information extraction using Wikipedia. In Proceedings of ACL, pages 118–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Raphael Hoffmann</author>
<author>Daniel S Weld</author>
</authors>
<title>Information extraction from Wikipedia: moving down the long tail.</title>
<date>2008</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>731--739</pages>
<contexts>
<context position="1388" citStr="Wu et al., 2008" startWordPosition="191" endWordPosition="194">and uniqueness of the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are time-invariant. In o</context>
</contexts>
<marker>Wu, Hoffmann, Weld, 2008</marker>
<rawString>Fei Wu, Raphael Hoffmann, and Daniel S. Weld. 2008. Information extraction from Wikipedia: moving down the long tail. In Proceedings of KDD, pages 731–739.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoki Yoshinaga</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Polynomial to linear: Efficient classification with conjunctive features.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1542--1551</pages>
<contexts>
<context position="20237" citStr="Yoshinaga and Kitsuregawa, 2009" startWordPosition="3332" endWordPosition="3335"> and discussions We built labeled data and examine the classification performance of the proposed method. We also analyzed the influence of window size T on the performance, as well as major errors caused by our method. 5.1 Data We built a dataset for evaluation by extracting relations from the time-series text (section 3.1) and then manually annotating 1000 relations. The detailed procedure is as follows. First, we parsed the time-series text and extracted as relation dependency paths connecting two named entities. We used J.DepP,7 an efficient shift-reduce parser with feature sequence trie (Yoshinaga and Kitsuregawa, 2009; Yoshinaga and Kitsuregawa, 2010), for parsing. All Japanese words that conjugate were normalized into standard forms. 5θ3 = 10 in our experiment. 6The keywords we used are 等, ら, たち, and 達. 7http://www.tkl.iis.u-tokyo.ac.jp/ —ynaga/jdepp/ 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 2: Recall-precision curve (constancy classification). Then, annotators were asked to label 1000 relations as not only constant or non-constant but also unique or non-unique. Three annotators were assigned to each relation, and the goldstandard label is determined by majority vote. The Fleiss kappa (Fleiss, 1971) was 0.346 </context>
</contexts>
<marker>Yoshinaga, Kitsuregawa, 2009</marker>
<rawString>Naoki Yoshinaga and Masaru Kitsuregawa. 2009. Polynomial to linear: Efficient classification with conjunctive features. In Proceedings of EMNLP, pages 1542– 1551.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoki Yoshinaga</author>
<author>Masaru Kitsuregawa</author>
</authors>
<title>Kernel slicing: Scalable online training with conjunctive features.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>1245--1253</pages>
<contexts>
<context position="20271" citStr="Yoshinaga and Kitsuregawa, 2010" startWordPosition="3336" endWordPosition="3339"> data and examine the classification performance of the proposed method. We also analyzed the influence of window size T on the performance, as well as major errors caused by our method. 5.1 Data We built a dataset for evaluation by extracting relations from the time-series text (section 3.1) and then manually annotating 1000 relations. The detailed procedure is as follows. First, we parsed the time-series text and extracted as relation dependency paths connecting two named entities. We used J.DepP,7 an efficient shift-reduce parser with feature sequence trie (Yoshinaga and Kitsuregawa, 2009; Yoshinaga and Kitsuregawa, 2010), for parsing. All Japanese words that conjugate were normalized into standard forms. 5θ3 = 10 in our experiment. 6The keywords we used are 等, ら, たち, and 達. 7http://www.tkl.iis.u-tokyo.ac.jp/ —ynaga/jdepp/ 0 0.2 0.4 0.6 0.8 1.0 Recall Figure 2: Recall-precision curve (constancy classification). Then, annotators were asked to label 1000 relations as not only constant or non-constant but also unique or non-unique. Three annotators were assigned to each relation, and the goldstandard label is determined by majority vote. The Fleiss kappa (Fleiss, 1971) was 0.346 for constancy classification and w</context>
</contexts>
<marker>Yoshinaga, Kitsuregawa, 2010</marker>
<rawString>Naoki Yoshinaga and Masaru Kitsuregawa. 2010. Kernel slicing: Scalable online training with conjunctive features. In Proceedings of COLING, pages 1245–1253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Zhu</author>
<author>Zaiqing Nie</author>
<author>Xiaojiang Liu</author>
<author>Bo Zhang</author>
<author>JiRong Wen</author>
</authors>
<title>StatSnowball: a statistical approach to extracting entity relationships.</title>
<date>2009</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>101--110</pages>
<contexts>
<context position="1406" citStr="Zhu et al., 2009" startWordPosition="195" endWordPosition="198"> the relations in the context of supervised learning. We exploit massive time-series web texts to induce features on the basis of time-series frequency and linguistic cues. Experimental results confirmed that the time-series frequency distributions contributed much to the recall of constancy identification and the precision of the uniqueness identification. 1 Introduction We have witnessed a number of success stories in acquiring semantic relations between entities from ever-increasing text on the web (Pantel and Pennacchiotti, 2006; Banko et al., 2007; Suchanek et al., 2007; Wu et al., 2008; Zhu et al., 2009; Mintz et al., 2009; Wu and Weld, 2010). These studies have successfully revealed to us millions of relations between real-world entities, which have been proven to be beneficial in solving knowledge-rich problems such as question answering and textual entailment (Ferrucci et al., 2010). &apos;This work was conducted while the first author was a graduate student at University of Tokyo. There exists, however, a great challenge to compile consistently relations extracted from text by these methods, because they assume a simplifying assumption that relations are time-invariant. In other words, they i</context>
</contexts>
<marker>Zhu, Nie, Liu, Zhang, Wen, 2009</marker>
<rawString>Jun Zhu, Zaiqing Nie, Xiaojiang Liu, Bo Zhang, and JiRong Wen. 2009. StatSnowball: a statistical approach to extracting entity relationships. In Proceedings of WWW, pages 101–110.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>