<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.96714">
A Discriminative Model for Query Spelling Correction with Latent
Structural SVM
</title>
<author confidence="0.998557">
Huizhong Duan, Yanen Li, ChengXiang Zhai and Dan Roth
</author>
<affiliation confidence="0.99918">
University of Illinois at Urbana-Champaign
</affiliation>
<address confidence="0.923695">
201 N Goodwin Ave
Urbana, IL 61801
</address>
<email confidence="0.979004">
{duan9, yanenli2, czhai, danr}@illinois.edu
</email>
<sectionHeader confidence="0.998402" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999622583333333">
Discriminative training in query spelling cor-
rection is difficult due to the complex inter-
nal structures of the data. Recent work on
query spelling correction suggests a two stage
approach a noisy channel model that is used
to retrieve a number of candidate corrections,
followed by discriminatively trained ranker
applied to these candidates. The ranker, how-
ever, suffers from the fact the low recall of the
first, suboptimal, search stage.
This paper proposes to directly optimize the
search stage with a discriminative model
based on latent structural SVM. In this model,
we treat query spelling correction as a multi-
class classification problem with structured in-
put and output. The latent structural informa-
tion is used to model the alignment of words
in the spelling correction process. Experiment
results show that as a standalone speller, our
model outperforms all the baseline systems. It
also attains a higher recall compared with the
noisy channel model, and can therefore serve
as a better filtering stage when combined with
a ranker.
</bodyText>
<sectionHeader confidence="0.999628" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998075">
Query spelling correction has become a crucial com-
ponent in modern information systems. Particularly,
search engine users rely heavily on the query cor-
rection mechanism to formulate effective queries.
Given a user query q, which is potentially mis-
spelled, the goal of query spelling correction is to
find a correction of the query c that could lead to a
better search experience. A typical query spelling
correction system employs a noisy channel model
(Kernighan et al., 1990). The model assumes that
the correct query c is formed in the user’s mind be-
fore entering the noisy channels, e.g., typing, and
get misspelled. Formally, the model maximizes the
posterior probability p(c|q):
</bodyText>
<equation confidence="0.9678455">
c� = arg max p(c|q). (1)
c
</equation>
<bodyText confidence="0.9047915">
Applying Bayes rule, the formulation can be
rewritten as:
</bodyText>
<equation confidence="0.9861715">
p(q|c)p(c)
[log p(q|c) + log p(c)]. (2)
</equation>
<bodyText confidence="0.999975117647059">
The model uses two probabilities. The prior prob-
ability p(c) represents how likely it is that c is the
original correct query in the user’s mind. The prob-
ability is usually modeled by a language model es-
timated from a sizable corpus. The transformation
probability p(q|c) measures how likely it is that q is
the output given that c has been formed by the user.
This probability can be either heuristic-based (edit
distance) or learned from samples of well aligned
corrections. One problem with the noisy channel
model is that there is no weighting for the two kinds
of probabilities, and since they are estimated from
different sources, there are usually issues regarding
their scale and comparability, resulting in subopti-
mal performance (Gao et al., 2010). Another limita-
tion of this generative model is that it is not able to
take advantage of additional useful features.
</bodyText>
<equation confidence="0.690768">
c� = arg max
c
= arg max
c
</equation>
<page confidence="0.913214">
1511
</page>
<note confidence="0.8129395">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1511–1521, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999982104651163">
A discriminative model may solve these problems
by adding the flexibility of using features and apply-
ing weights. But training such a model is not easy.
The difficulty is that the output space of query cor-
rection is enormous, as the candidate corrections for
each a query term could be the entire vocabulary.
This is even worse when word boundary errors (i.e.
merging and splitting of words) exist. The problem
is intractable with standard discriminative models as
we cannot enumerate every candidate correction.
To solve the problem, (Gao et al., 2010) proposed
a two stage approach. In this approach, a ranker is
trained to score each candidate correction of a query.
When a query is issued, the system first uses the
noisy channel model with a standard search algo-
rithm to find the 20 best candidates. Then the ranker
is used to re-rank these candidates and find the best
correction for the query. This ranker based system
has one critical limitation, though. Since the ranking
stage is decoupled from the search, it relies on the
outsourced search algorithm to find the candidates.
Because query spelling correction is an online oper-
ation, only a small number of candidates can enter
the ranker due to efficiency concerns, thus limiting
the ability of the ranker to the ceiling of recall set by
the suboptimal search phase.
The research question we address here is whether
we can directly optimize the search phase of query
spelling correction using a discriminative model
without loss of efficiency. More specifically, we
want 1) a learning process that is aware of the
search phase and interacts with its result; 2) an ef-
ficient search algorithm that is able to incorporate
the learned model and guide the search to the target
spelling correction.
In this paper, we propose a new discriminative
model for query correction that maintains the ad-
vantage of a discriminative model in accommodat-
ing flexible combination of features and naturally in-
corporates an efficient search algorithm in learning
and inference. Similarly to (Chang et al., 2010) we
collapse a two stage process into a single discrim-
inatively trained process, by considering the output
of the first stage as an intermediate latent represen-
tation for the joint learning process. Specifically, we
make use of the latent structural SVM (LS-SVM)
(Yu and Joachims, 2009) formulation. We formu-
late the problem query spelling correction as a multi-
class classification problem on structured inputs and
outputs. The advantage of the structural SVM model
is that it allows task specific, customizable solutions
for the inference problem. This allows us to adapt
the model to make it work directly with the search
algorithm we use for finding the best correction of
the query. To account for word boundary errors, we
model the word alignment between the query and
the correction as a latent structural variable. The
LS-SVM model allows us to jointly search over the
output space and the latent structure space.
As the inference algorithm in the proposed dis-
criminative model we use an algorithm that resem-
bles a traditional noisy channel model. To adapt
the LS-SVM model to enable the efficient search of
query spelling correction, we study how features can
be designed. We analyze the properties of features
that can be used in the search algorithm and propose
a criteria for selecting and designing new features.
We demonstrate the use of the criteria by design-
ing separate features for different types of spelling
errors (e.g. splitting, merging). With the proposed
discriminative model, we can directly optimize the
search phase of query spelling correction without
loss of efficiency. Our model can be used not only as
a standalone speller with high accuracy, but also as
a high recall candidate generation stage for a ranker
based system.
Experiments verify the effectiveness of the dis-
criminative model, as the accuracy of correction can
be improved significantly over baseline systems in-
cluding an award winning query spelling system.
Even though the optimization is primarily based on
the top correction, the weights trained by LS-SVM
can be used to search for more candidate corrections.
The improvement in recall at different levels over the
noisy channel model demonstrates that our model is
superior even when used in the two-stage approach..
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999948428571429">
Spelling correction has a long history (Levenshtein,
1966). Traditional techniques were on small scale
and depended on having a small trusted lexicons
(Kukich, 1992). Later, statistical generative mod-
els were shown to be effective in spelling correc-
tion, where a source language model and an er-
ror model were identified as two major components
</bodyText>
<page confidence="0.99093">
1512
</page>
<bodyText confidence="0.999804819444445">
(Brill and Moore, 2000). Note that we are not deal-
ing here with the standard models in context sen-
sitive spelling (Golding and Roth, 1999) where the
set of candidate correction is a known “confusion
set”. Query spelling correction, a special form of
the problem, has received much attention in recent
years. Compared with traditional spelling correc-
tion task, query spelling deals with more complex
types of misspellings and a much larger scale of lan-
guage. Research in this direction includes utiliz-
ing large web corpora and query log (Chen et al.,
2007; Cucerzan and Brill, 2004; Ahmad and Kon-
drak, 2005), employing large-scale n-gram models,
training phrase-based error model from clickthrough
data (Sun et al., 2010) and developing additional fea-
tures (Gao et al., 2010).
Query alteration/refinement is a very relevant
topic to query spelling correction. The goal of
query alteration/refinement is to modify the inef-
fective query so that it could . Researches on this
track include query expansion (Xu and Croft, 1996;
Qiu and Frei, 1993; Mitra et al., 1998), query con-
traction(Kumaran and Allan, 2008; Bendersky and
Croft, 2008; Kumaran and Carvalho, 2009) and
other types of query reformulations for bridging the
vocabulary gap (Wang and Zhai, 2008). (Guo et al.,
2008) proposed a unified model to perform a broad
set of query refinements including correction, seg-
mentation and stemming. However, it has very lim-
ited ability in query correction. In this paper, we
study the discriminative training of query spelling
correction, which is potentially beneficial to many
existing studies.
Noisy channel model (or source channel model)
has been widely used in NLP. Many approaches have
been proposed to perform discriminative training of
the model (McCallum et al., 2000; Lafferty, 2001).
However, these approaches mostly deal with a rela-
tively small search space where the number of can-
didates at each step is limited (e.g. POS tagging). A
typically used search algorithm is dynamic program-
ming. In spelling correction, however, the search
space is much bigger and the existing approaches
featuring dynamic programming are difficult to be
applied.
Structural learning and latent structural learning
has been studied a lot in NLP in recent years(Chang
et al., 2010; Dyer et al., 2011), and has been
shown to be useful in a range of NLP applications
from Textual Entailment, Paraphrasing and Translit-
eration (Chang et al., 2010) to sentiment analysis
(Yessenalina et al., 2010).
Work has also been done on integrating discrimi-
native learning in search. Freitag and Khadivi used a
perceptron algorithm to train for sequence alignment
problem. A beam search algorithm was utilized in
the search (Freitag and Khadivi, 2007). Daume et
al. proposed the Searn framework for search based
structural prediction (Daume et al., 2009). Our
model differs from the Searn framework in that it
learns to make global decisions rather than accumu-
lating local decisions. The global decision was made
possible by an efficient search algorithm.
Query spelling correction also shares many sim-
ilarities with statistical machine translation (SMT).
Sun et al. (2010) has formulated the problem within
an SMT framework. However, SMT usually in-
volves more complex alignments, while in query
spelling correction search is the more challenging
part. Our main contribution in this paper is a novel
unified way to directly optimize the search phase of
query spelling correction with the use of LS-SVM.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="method">
3 Discriminative Model for Query Spelling
</sectionHeader>
<subsectionHeader confidence="0.592027">
Correction Based on LS-SVM
</subsectionHeader>
<bodyText confidence="0.99999025">
In this section, we first present the discriminative
formulation of the problem of query spelling correc-
tion. Then we introduce in detail the model we use
for solving the problem.
</bodyText>
<subsectionHeader confidence="0.9888395">
3.1 The Discriminative Form of Query Spelling
Correction
</subsectionHeader>
<bodyText confidence="0.9999525">
In query spelling correction, given a user entered
query q, which is potentially misspelled, the goal is
to find a correction c, such that it could be a more
effective query which improves the quality of search
results. A general discriminative formulation of the
problem is of the following form:
</bodyText>
<equation confidence="0.9359495">
f(q) = arg max [w · IF(q, c)], (3)
CEV*
</equation>
<bodyText confidence="0.99999475">
where IF(q, c) is a vector of features and w is the
model parameter. This discriminative formulation is
more general compared to the noisy channel model.
It has the flexibility of using features and applying
</bodyText>
<page confidence="0.925367">
1513
</page>
<bodyText confidence="0.999931136363637">
weights. The noisy channel model is a special case
of the discriminative form where only two features,
the source probability and the transformation proba-
bility, are used and uniform weightings are applied.
However, this problem formulation does not give us
much insight on how to proceed to design the model.
Especially, it is unclear how Ψ(q, c) can be com-
puted.
To enhance the formulation, we explore the fact
that spelling correction follows a word-by-word pro-
cedure. Let us first consider a scenario where word
boundary errors does not exist. In this scenario,
each query term matches and only matches to a sin-
gle term in the correction. Formally, let us denote
q = q1, ..., qn and c = c1, ..., cm as structured ob-
jects from the space of V*, where V is our vocabu-
lary of words and V* is all possible phrases formed
by words in V. Both q and c have an intrinsic se-
quential structure. When no word boundary error
exists, |c |= |q |holds for any candidate correction
c. qi and ci establish a one-to-one mapping. In this
case, we have a more detailed discriminative form:
</bodyText>
<equation confidence="0.9540005">
f(q) = arg max
cEV|e|
</equation>
<bodyText confidence="0.999098904761905">
where Ψ0 is a vector of normalizing factors,
Ψ1(qi, ci) is the decomposed computation of Ψ(q, c)
for each query term qi and ci, for i = 1 to |q|.
Equation 4 is a clearer formulation. The major
challenge of solving this discriminative problem is
the complexity. Theoretically, each term has |V|
candidates and it is impossible to enumerate over
all possible combinations. To make it even worse,
merging and splitting errors are quite common in
misspelling. As a result, the assumption of one-to-
one mapping does not hold in practice.
To account for these word boundary errors and
enhance the discriminative formulation, we intro-
duce a latent variable a to model the unobserved
structural information. More specifically, a =
a1, a2, ...a|a |is the alignment between q and c. Each
alignment node at is a represented by a quadruple
(qstart, qend, cstart, cend). Figure 1 shows a com-
mon merge error and its best alignment. The phrase
”credit card”, in this case, is incorrectly merged into
one word ”creditcard” by the user. Figure 2 shows
</bodyText>
<figureCaption confidence="0.999998">
Figure 1: Example of Merge Error and Alignment
Figure 2: Example of Split Error and Alignment
</figureCaption>
<bodyText confidence="0.997512333333333">
the best alignment for a common split error, where
the word ”gamespot” is incorrectly split into a two
word phrase ”game spot”.
Taking into consideration the latent variable, we
arrive at our final discriminative form of query
spelling correction:
</bodyText>
<equation confidence="0.8756924">
f(q) = arg max(c,a)EVnxA[w &apos; Ψ(q, c, a)]
= arg max(c,a)EV*xA[w &apos; (Ψ0
+ �|a|
t=0 Ψ1(qat, cat, at))],
(5)
</equation>
<bodyText confidence="0.9999717">
The challenges of successfully applying a dis-
criminative model to this problem formulation are
1) how can we design a learning algorithm to learn
the model parameter w to directly optimize the max-
imization problem; 2) how can we solve the maxi-
mization efficiently without having to enumerate all
candidates; 3) how can we design features to guar-
antee the correctness of the search algorithm. In the
following subsections we introduce our solutions to
the three challenges in detail.
</bodyText>
<subsectionHeader confidence="0.999947">
3.2 Latent Structural SVM
</subsectionHeader>
<bodyText confidence="0.999979">
We employ the latent structural SVM (LS-SVM)
model for learning the discriminative model of query
spelling correction. LS-SVM is a large margin
method that deals with structured prediction prob-
lems with latent structural information (Yu and
Joachims, 2009). LS-SVM has the merit of allowing
</bodyText>
<equation confidence="0.991592">
[w &apos; (Ψ0 + � |q |Ψ1(qi, ci))], (4)
i=1
</equation>
<page confidence="0.92154">
1514
</page>
<bodyText confidence="0.999869636363636">
task specific, customizable solutions for the infer-
ence problem. This makes it easy to adapt to learn-
ing the model parameters for different problems.
The following is a brief introduction of LS-SVM
that largely mirrors the work by (Yu and Joachims,
2009).
Without loss of generality, let us aim at learning
a prediction function f : X —* Y that maps input
x E X to an output y E Y with latent structural
information h E X The decision function is of the
following form:
</bodyText>
<equation confidence="0.9972865">
f(x) = arg max [w · IF(x, y, h)], (6)
(y,h)EYXW
</equation>
<bodyText confidence="0.998425142857143">
where IF(x, y, h) is the set of feature functions de-
fined jointly over the input x, the output y and the
latent variable h. w is the parameter of the model.
Given a set of training examples that consist of input
and output pairs I(x1, y1), ...(xn, yn)I E (X X Y)n,
the LS-SVM method solves the following optimiza-
tion problem:
</bodyText>
<equation confidence="0.986137666666667">
minw �I IwI I2
1
(7)
</equation>
<bodyText confidence="0.999815285714286">
where A(yi, y) is the loss function for the ith ex-
ample. The details of the derivation is omitted in
this paper. Readers who are interested can read more
from (Yu and Joachims, 2009).
There are two maximization problems that are es-
sential in Equation 7. The first one is the loss aug-
mented decision function:
</bodyText>
<equation confidence="0.852316">
(y,�h)EYXW
max [w · IF(xi, y, h) + A(yi, �y)], (8)
</equation>
<bodyText confidence="0.982113">
and the second is the inference of latent variable
given the label of the training data:
</bodyText>
<equation confidence="0.7281195">
max [w · �(xi, yi, h)]. (9)
hEW
</equation>
<bodyText confidence="0.99974447826087">
The Latent Structural SVM framework does not
specify how the maximization problems in Equation
8 and Equation 9 are solved, as well as the infer-
ence problem in 6. These maximization problems
are task dependent. Being able to efficiently solve
them is the key to successfully applying the Latent
Structural SVM method. We will show in detail how
we solve these maximization problems to make LS-
SVM work for query spelling correction in the fol-
lowing subsection.
For training the LS-SVM model, a Concave-
Convex Procedure (CCCP) was proposed to solve
this optimization problem (Yu and Joachims, 2009).
The method resembles the Expect-Maximization
(EM) training method as it updates the model by it-
eratively recomputing the latent variable. However,
rather than performing “sum-product” training as in
EM where a distribution over the hidden variable is
maintained, the CCCP method used for LS-SVM is
more similar to the “max-product” paradigm where
we “guess” the best hidden variable in each iteration,
except here we “guess” by minimizing a regularized
loss function instead of maximizing the likelihood.
</bodyText>
<subsectionHeader confidence="0.999659">
3.3 Solving the Inference Problems
</subsectionHeader>
<bodyText confidence="0.9999512">
The essential inference problem is to find the correc-
tion that maximizes the scoring function according
to the model (i.e., the decision function in Equation
6). For this purpose we design a best first search al-
gorithm similar to the standard search algorithm in
the noisy channel model. The essence of the search
algorithm is to bound the score of each candidate
so that we could evaluate the most promising candi-
dates first. The algorithm is given in Algorithm 1.
Essentially, the algorithm maintains a priority
queue of all search paths. Each time the best path is
de-queued, it is expanded with up to m − 1 words
in q by searching over a vocabulary trie of up to
m-gram. Each path is represented as a quadruple
(pos, str, sc, a), representing the current term posi-
tion in query, the string of the path, the path’s score
and the alignment so far. The priority queue is sorted
according to the score of each path in descending or-
der. The Get5uggestions() function retrieves the
top n similar words to the given word with a vocab-
ulary trie according to an error model.
Splitting errors are dealt with in Algorithm 1 by
“looking forward” m words in the query when gen-
erating candidate words. Merging errors are ac-
counted for by including up to m-gram in the vocab-
</bodyText>
<equation confidence="0.620485285714286">
+C n max [w · IF(xi, y, h) + A(yi, y)]
i=1 (y,�h)EYXW
max [w · IF(xi, yi, h)],
hEW
n
−C
i=1
</equation>
<page confidence="0.875413">
1515
</page>
<bodyText confidence="0.952034333333333">
ulary trie. It is worth mentioning that performance
of Algorithm 1 could be further improved by com-
puting heuristic scores for each path.
</bodyText>
<table confidence="0.952222">
Algorithm 1: Best First Search Algorithm
Input: Vocabulary Trie V , query q, output size k,
max order m, candidate pool size n
Output: List l of top k corrections for q
1 Initialize List l;
2 Initialize PriorityQueue pq;
</table>
<tableCaption confidence="0.667677">
3 Enqueue to pq a start path with position set to 0,
string set to empty string, score set to w · Ψ0, and
path alignment set to empty set;
</tableCaption>
<table confidence="0.29568925">
4 while pq is not Empty do
Path π ← pq.Dequeue();
if π.pos &lt; q.terms.length then
for i ← 0 to m do
ph ← q.terms[π.pos + 1...π.pos + i];
sug ← GetSuggestions(ph, V, n);
foreach s in sug do
pos&apos; ← π.pos + i;
str&apos; ← concat(π.str, s.str);
a&apos; ← π.a ∪ s.a;
sc&apos; ← π.sc+w·Ψ1(qs.a, cs.a, s.a);
Enqueue pq with the new path
(pos&apos;, str&apos;, sc&apos;, a&apos;);
Add suggestion string π.str to l;
if l.Count &gt; k then return l;
19 return l;
</table>
<bodyText confidence="0.999275483870968">
As Algorithm 1 originates from the noisy channel
model, the two known features that work with the
algorithm are log p(c) and log p(q|c) from the noisy
channel model. However, it is unknown whether
other features can work with the search algorithm
and how we can develop new features to ensure it.
After analyzing the properties of the features and the
search algorithm, we find that a feature ψ has to sat-
isfy the following monotonicity constraint in order
to be used in Algorithm 1.
Monotonicity Property. Given query q, for
any alignment At = At−1 ∪ {at} at time t,
ψ(qAt,cAt,At) ≤ ψ(qAt_1,cAt_1,At−1), where
qAt is the concatenation of qa0 to qat and cAt is the
concatenation of ca0 to cat.
That is, the value of the feature (which is com-
puted in an accumulative manner) cannot increase
as the candidate is extended with a new term at
any search step. This ensures that the score of the
best candidate at any search step is guaranteed to be
higher than the score of any future candidates. It
also implies ψt(qat, cat, at) ≤ 0 for any t ∈ T. The
monotonicity feature ensures the correctness of Al-
gorithm 1. We show how we design features with
the guidance of the monotonicity constraint in Sec-
tion 4.
The solution to to the loss augmented inference
depends on the loss function we use. In spelling cor-
rection, usually only one correction is valid for an
input query. Therefore, we apply the 0-1 loss to our
model:
</bodyText>
<equation confidence="0.982203">
Δ(c, ˆc) = { 0 C�� C (10)
l
</equation>
<bodyText confidence="0.9999753125">
Given this loss function, the loss augmented infer-
ence problem can be solved easily with an algorithm
similar to Algorithm 1. This is done by initializing
the loss to be 1 at the beginning of each search path.
During the search procedure, we check if the loss
decreases to 0 given the correction string so far. If
this is the case, we decreases the score by 1 and add
the path back to the priority queue. More advanced
functions may also be used (Dreyer et al., 2006),
which may lead to better training performance. We
plan to further study different loss functions in our
future work.
The inference of the latent alignment variable can
be solved with dynamic programming, as the num-
ber of possible alignments is limited given the query
and the correction.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.99984125">
In the following discussions, we will describe how
the features in our discriminative model are devel-
oped under the guidance of the monotonicity con-
straint.
</bodyText>
<subsectionHeader confidence="0.984721">
4.1 Source Probability and Transformation
Probability
</subsectionHeader>
<bodyText confidence="0.999990333333333">
We know from empirical experience that the source
probability and the transformation probability are
the two most important features in query spelling
correction. We include them in our model in a nor-
malized form. Taking the source probability for ex-
ample, we define the following feature:
</bodyText>
<figure confidence="0.9962566">
5
6
7
8
9
10
11
12
13
14
15
16
17
18
else
</figure>
<page confidence="0.93828">
1516
</page>
<equation confidence="0.950828142857143">
µ+y|a |log p(c)
(q, c, a) =µ ( )
1 + E|
a |log p(c) 11 ,
1
where µ is a normalizing factor computed as:
µ = −|q |log pmin, (12)
</equation>
<bodyText confidence="0.98673525">
where pmin is the smallest probability we use in
practice.
The formula fits the general form we define in 5
in that ψ0 = 1 and ψ1(qat, cat, at) = log p(c)
</bodyText>
<equation confidence="0.65705">
µ for any
t = 1 to |a|.
</equation>
<bodyText confidence="0.999964833333333">
Similarly, we have the follow feature for the trans-
formation probability:
We use the web Microsoft n-gram model1 to com-
pute source model p(c). We train the unigram trans-
formation model for the transformation probability
p(q|c) according to (Duan and Hsu, 2011).
In generative models, we treat transformation
probabilities from merging and splitting errors in the
same way as single word errors. In our discrimi-
native model we can assign separate weight to the
transformation probabilities resulted from different
types of errors. This allows fine tuning of the query
spelling correction system, making it more adaptive
to environments where the ratio of different types of
errors may vary. Moreover, the model also allows
us to include language models trained over different
resources, such as query log, title of webpages or
anchor texts.
</bodyText>
<subsectionHeader confidence="0.997527">
4.2 Local Heuristic Features
</subsectionHeader>
<bodyText confidence="0.999515857142857">
Despite the goal of query spelling correction is to
deal with misspellings, in real world most queries
are correctly spelled. A good query spelling correc-
tion system shall prevent as much as possible from
misjudging an correctly spelled query as misspelled.
With this idea in mind, we invent some heuristic
functions to avoid misjudging.
</bodyText>
<footnote confidence="0.676598">
1http://research.microsoft.com/en-
us/collaboration/focus/cs/web-ngram.aspx
</footnote>
<bodyText confidence="0.997337833333333">
Local Heuristic 1. When a query term is matched
against trustable vocabulary, it increases the chance
that the term is already in its correct form. For ex-
ample, we extract a reliable vocabulary from the title
field of Wikipedia2. We therefore design the follow-
ing feature:
</bodyText>
<equation confidence="0.929818111111111">
|a|
φ(q, c, a) = 1 + L φ1(qat, cat, at), (14)
t=1
where φ1(qat, cat, at) is defined as:
0 qat ∈/ W
0 qat ∈ W, qat = ct
− 1
|q |qat ∈ W, qat =6 cat
(15)
</equation>
<bodyText confidence="0.999698615384615">
where W is the vocabulary of Wikipedia titles.
Since |q |&gt; |a |always holds, the feature is normal-
ized between 0 and 1.
Local Heuristic 2. Another heuristic is that
words with numbers in it, despite usually not in-
cluded in any vocabulary, should be treated care-
fully as they tend to be correct words. Such words
could be a model, a serial number or a special en-
tity name. Since the number keys on keyboard are
away from the letter keys, they are more likely to be
intentionally typed in if found in user queries. Simi-
lar to Heuristic 1, we design the following feature to
capture this heuristic:
</bodyText>
<equation confidence="0.946518333333333">
|a|
φ0(q, c, a) = 1 + L φ01(qat, cat, at), (16)
t=1
where φ01(qat, cat, at) is defined as:
0 [0...9] ∈/ qat
0 [0...9] ∈ qat, qat = cat
1
|q |[0...9] ∈ qat, qat =6 cat
(17)
</equation>
<subsectionHeader confidence="0.998794">
4.3 Global Heuristic Features
</subsectionHeader>
<bodyText confidence="0.9830245">
Some global heuristics are also important in query
spelling correction. For instance, the total number
</bodyText>
<footnote confidence="0.936697">
2http://www.wikipedia.org
</footnote>
<equation confidence="0.9974695">
ψ0(q, c, a) =µ+�|a|
1 log p(q|c)
µ (13)
=1 + E|a |log p(q|c)
µ .
1
φ1(qat, cat, at) = {
φ01(qat, cat, aat) = {
</equation>
<page confidence="0.961715">
1517
</page>
<bodyText confidence="0.99998525">
of words being corrected in the query may be an
indicator of whether the system has leaned towards
overcorrecting. To account for this global heuristic,
we design the following feature:
</bodyText>
<equation confidence="0.971177">
� 1 wc(q, c, a) &lt; wcmax
cp(q, c, a) = (18)
0 otherwise
</equation>
<bodyText confidence="0.999991142857143">
where wc(q, c, a) is the number of word changes
at step t, wcmax is the maximum number of word
changes we allow in our system (in a soft way). Sim-
ilarly, other thresholded features can be designed
such as the number of total edit operations. The use
of global features is similar to the use of loss func-
tion in the search algorithm.
</bodyText>
<sectionHeader confidence="0.999451" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999605">
In order to test the effectiveness and efficiency of our
proposed discriminative training method, in this sec-
tion we conduct extensive experiments on two web
query spelling datasets. Below we first present the
dataset and evaluation metrics, followed by the ex-
periment results on query spelling correction.
</bodyText>
<subsectionHeader confidence="0.992994">
5.1 Dataset Preparation
</subsectionHeader>
<bodyText confidence="0.999993571428572">
The experiments are conducted on two query
spelling correction datasets. One is the TREC
dataset based on the publicly available TREC
queries (2008 Million Query Track). This dataset
contains 5892 queries and the corresponding correc-
tions annotated by the MSR Speller Challenge 3 or-
ganizers. There could be more than one plausible
corrections for a query. In this dataset only 5.3% of
queries are judged as misspelled.
We have also annotated another dataset that con-
tains 4926 MSN queries, where for each query there
is at most one correction. Three experts are involved
in the annotation process. For each query, we con-
sult the speller from two major search engines (i.e.
Google and Bing). If they agree on the returned
results (including the case if the query is just un-
changed), we take it as the corrected form of the in-
put query. If the results are not the same from the
two, as least one human expert will manually anno-
tate the most likely corrected form of the query. Fi-
nally, about 13% of queries are judged as misspelled
</bodyText>
<footnote confidence="0.794794">
3http://web-ngram.research.microsoft.com/spellerchallenge/
</footnote>
<bodyText confidence="0.9992722">
in this dataset, which is close to the error rate of real
web queries. We’ve made this dataset publicly avail-
able to all researchers4.
Both the two datasets are split randomly into two
equal subsets for training and testing.
</bodyText>
<subsectionHeader confidence="0.998985">
5.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.998763222222222">
We evaluate our system based on the evaluation met-
rics proposed in Microsoft Speller Challenge, in-
cluding expected precision, expected recall and ex-
pected F1 measure.
Let q be a user query and C(q) = (c1, c2, , ck)
be the set of system output with posterior probabil-
ities P(cZ|q). Let S(q) denote the set of plausible
spelling variations annotated by the human experts
for q. Expected Precision is computed as:
</bodyText>
<equation confidence="0.740676">
Ip(c, q)P(c|q), (19)
</equation>
<bodyText confidence="0.9911915">
where Ip(c, q) = 1 if c E S(q), and 0 otherwise.
And expected recall is defined as:
</bodyText>
<equation confidence="0.99835">
1 � Recall =
|Q |qEQ
</equation>
<bodyText confidence="0.9665285">
where I,(C(q), a) = 1 if a E C(q) for a E S(q),
and 0 otherwise. We use R@N to denote recall for
systems limited to output top N corrections.
Expected F1 measure can be computed as:
</bodyText>
<equation confidence="0.8317905">
F1 = 2 · precision · recall (21)
precision + recall
</equation>
<subsectionHeader confidence="0.999336">
5.3 Experiment Results
</subsectionHeader>
<bodyText confidence="0.9996535">
Table 1 compares the performance of our LS-SVM
based model with two strong baseline systems. The
first baseline system is an Echo system which sim-
ply echos the input. The echo system is usually con-
sidered as a strong baseline in query spelling cor-
rection as the majority of the queries are correctly
spelled queries. The second baseline Lueck-2011
we use is a award winning speller system5 (Luec,
2011), which was ranked at the first place in Mi-
crosoft Spelling Challenge 2011.
</bodyText>
<footnote confidence="0.999895">
4http://times.cs.uiuc.edu/duan9/msn speller.tar.gz
5http://www.phraselink.com
</footnote>
<figure confidence="0.9445445">
�
|Q |qEQ
�
cEC(q)
1
P recision =
� I,(C(q), a)/|S(q)|, (20)
aES(q)
</figure>
<page confidence="0.96149">
1518
</page>
<tableCaption confidence="0.999763">
Table 1: LSSVM vs Baselines Serving as Standalone Speller
</tableCaption>
<table confidence="0.99965175">
All Queries Misspelled Queries
Dataset Method Precision R@10 F1 Precision R@10 F1
Echo 0.949 0.876 0.911 0 0 0
TREC Lueck-2011 0.963 0.932 0.947 0.391 0.479 0.430
LS-SVM 0.955 0.944 0.949 0.331 0.678† 0.445†
Echo 0.869 0.869 0.869 0 0 0
MSN Lueck-2011 0.896 0.921 0.908 0.334 0.397 0.363
LS-SVM 0.903 0.953 0.928 0.353† 0.662† 0.461†
</table>
<bodyText confidence="0.999829361111111">
We show performances for the entire query sets
as well as the query sets consisting only the mis-
spelled queries. As we can see, our system out-
performs both baseline systems on almost all met-
rics, except the precision of Lueck-2011 is better
than ours on TREC dataset. We perform statistical
test and measures where our system shows statisti-
cal significant improvement over both baseline sys-
tems are noted by †. It is theoretically impossible
to achieve statistical significance in the entire query
set as majority queries have almost identical perfor-
mance in different systems due to the large amount
of correct queries. But our method shows signifi-
cant improvement in the dealing with the misspelled
queries. This experiment verified the effectiveness
of our proposed discriminative model. As a stan-
dalone speller, our system achieves very high accu-
racy.
Despite we are primarily focused on optimizing
the top correction in our discriminative model, we
can also use the trained system to output multiple
candidate corrections. Table 2 compare our system
with the noisy channel model (N-C) in terms of re-
call at different levels of cutoff. For all levels, we see
that our system achieves higher recall than the noisy
channel model. This indicates that when used to-
gether with a secondary ranker, our system serves as
a better filtering method than the unoptimized noisy
channel model. Since the ranker makes use of arbi-
trary features, it has the potential of further improv-
ing the accuracy of query spelling correction. We
plan to further explore this idea as a future work.
In Table 3 we study the effect of treating the trans-
formation probability of merging and splitting er-
rors as separate features and including the local and
global heuristic features (rich features). We see that
</bodyText>
<tableCaption confidence="0.9549945">
Table 2: LS-SVM vs Noisy Channel Model Serving as
Filtering Method
</tableCaption>
<table confidence="0.998987">
Dataset Method R@5 R@10 R@20
TREC N-C 0.896 0.899 0.901
LS-SVM 0.923 0.944 0.955
MSN N-C 0.870 0.873 0.876
LS-SVM 0.950 0.953 0.960
</table>
<bodyText confidence="0.999726642857143">
the precision of query spelling correction can bene-
fits from the use of rich features. However, it does
not result in much improvement in recall. This is
reasonable as the additional features are primarily
designed to improve the accuracy of the top correc-
tion generated by the system. In doing so, it actu-
ally regularizes the ability of the system in retrieving
diversified results. For instance, the global heuris-
tic feature on the number of word change tries to
prevent the system from returning candidates hav-
ing more than a certain number of changed words.
For the TREC collection where more than one cor-
rections can be labeled for a query, this phenomena
is aggravated.
</bodyText>
<tableCaption confidence="0.999162">
Table 3: LSSVM w/ and w/o Rich Features
</tableCaption>
<table confidence="0.9997474">
Dataset Method Precision R@10 F1
TREC w/o 0.942 0.946 0.944
w/ 0.955 0.944 0.949
MSN w/o 0.898 0.952 0.924
w/ 0.903 0.953 0.928
</table>
<sectionHeader confidence="0.999428" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.997194">
In this paper, we present a novel discriminative
model for query spelling correction. The paper made
the following contributions:
</bodyText>
<page confidence="0.985608">
1519
</page>
<bodyText confidence="0.999982130434782">
First, to the best of our knowledge, this is a novel
exploration of directly optimizing the search phase
in query spelling correction with a discriminative
model. By modeling word alignment as the latent
structural information, our formulation also deals
with word boundary errors. We propose to use LS-
SVM for learning the discriminative model which
naturally incorporates search in the learning process.
Second, we develop an efficient search algorithm
that solves the inference problems in the LS-SVM
based model. We analyze the criteria for selecting
and designing features to ensure the correctness and
efficiency of the search algorithm. Third, we explore
effective features to improve the accuracy of the
model. Finally, experiments are conducted to verify
the effectiveness of the proposed model. It is shown
that as a standalone speller our system achieves high
accuracy. When used in a two stage approach, it at-
tains higher recall than the noisy channel model and
can thus serve as a superior method for candidate
generation. We also verify that through the use of
rich features, we can further improve the accuracy
of our query spelling correction system.
</bodyText>
<sectionHeader confidence="0.999074" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999938">
This paper is based upon work supported in part by
MIAS, the Multimodal Information Access and Syn-
thesis center at UIUC, part of CCICADA, a DHS
Center of Excellence, and by the National Science
Foundation under grant CNS-1027965, and by a Mi-
crosoft grant.
</bodyText>
<sectionHeader confidence="0.998975" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998891260869565">
F. Ahmad and G. Kondrak. 2005. Learning a spelling
error model from search query logs. In HLT/EMNLP.
The Association for Computational Linguistics.
M. Bendersky and W. B. Croft. 2008. Discovering key
concepts in verbose queries. In Proceedings of the 31st
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’08. ACM, New York, NY, USA, 491-498.
E. Brill and R. Moore. 2000. An improved error model
for noisy channel spelling correction. In Proceed-
ings of the 38th Annual Meeting of the Association for
Computational Linguistics, Hong Kong.
M. Chang, D. Goldwasser, D. Roth and V. Srikumar.
2010. Discriminative Learning over Constrained La-
tent Representations. In Proceedings of NAACL.
Q. Chen, M. Li, and M. Zhou. 2007. Improving
query spelling correction using web search results. In
EMNLP-CoNLL, pages 181–189.
S. Cucerzan and E. Brill. 2004. Spelling correction as an
iterative process that exploits the collective knowledge
of web users. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
H. Daume, J. Langford and D. Marcu. 2009. Search-
based Structured Prediction. Machine Learning Jour-
nal (MLJ).
M. Dreyer, D. Smith and N. Smith. 2006. Vine parsing
and minimum risk reranking for speed and precision.
In Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning. 201-205.
H. Duan and B.-J. P. Hsu. 2011. Online spelling correc-
tion for query completion. In Proceedings of the 20th
international conference on World wide web, WWW
’11, pages 117–126, New York, NY, USA.
C. Dyer, J. H. Clark, A. Lavie, and N. A. Smith. 2011.
Unsupervised Word Alignment with Arbitrary Fea-
tures. In Proceedings of ACL.
D. Freitag, S. Khadivi. 2007. A Sequence Alignment
Model Based on the Averaged Perceptron. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning. 238-247.
J. Gao, X. Li, D. Micol, C. Quirk, and X. Sun. 2010.
A large scale ranker-based system for search query
spelling correction. In COLING, pages 358–366.
A. R. Golding and D. Roth 1999. A Winnow based ap-
proach to Context-Sensitive Spelling Correction. In
Machine Learning, vol 34, pages 107–130.
J. Guo, G. Xu, H. Li, and X. Cheng. 2008. A unified and
discriminative model for query refinement. In Pro-
ceedings of the 31st annual international ACM SIGIR,
SIGIR ’08, pages 379–386, New York, NY, USA.
C. John Yu and T. Joachims. 2009. Learning structural
SVMs with latent variables. In Proceedings of the 26th
Annual International Conference on Machine Learn-
ing (ICML ’09). ACM, New York, NY, USA, 1169-
1176.
M. D. Kernighan , K. W. Church, W. A. Gale. 1990. A
spelling correction program based on a noisy channel
model. In Proceedings of the 13th conference on Com-
putational linguistics. 205-210. August 20-25, 1990,
Helsinki, Finland.
K. Kukich. 1992. Techniques for automatically correct-
ing words in text. ACM computing surveys, 24(4).
G. Kumaran and J. Allan. 2008. Effective and efficient
user interaction for long queries. In Proceedings of
the 31st annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’08. ACM, New York, NY, USA.
</reference>
<page confidence="0.761489">
1520
</page>
<reference confidence="0.99934102">
G. Kumaran and V. R. Carvalho. 2009. Reducing long
queries using query quality predictors. In Proceed-
ings of the 32nd international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’09. ACM, New York, NY, USA, 564-571.
J. Lafferty. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings of the Eighteenth International Con-
ference on Machine Learning (ICML ’01). 282–289.
V. I. Levenshtein. 1966. Binary codes capable of cor-
recting deletions, insertions, and reversals. In Soviet
Physics Doklady, 10(8), 707-710.
G. Luec. 2011. A data-driven approach for correcting
search quaries. In Spelling Alteration for Web Search
Workshop.
A. McCallum, D. Freitag, and F. Pereira. 2000. Maxi-
mum Entropy Markov Models for Information Extrac-
tion and Segmentation. In Proceedings of the Seven-
teenth International Conference on Machine Learning
(ICML ’00). 591-598.
M. Mitra, A. Singhal, and C. Buckley. 1998. Improving
automatic query expansion. In Proceedings of the 21st
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’98.
Y. Qiu and H. Frei. 1993. Concept based query expan-
sion. In Proceedings of the 16th annual international
ACM SIGIR conference on Research and development
in information retrieval, SIGIR ’93. ACM, New York,
NY, USA, 160-169.
X. Sun, J. Gao, D. Micol, and C. Quirk. 2010. Learning
phrase-based spelling error models from clickthrough
data. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, ACL
’10, pages 266–274, Stroudsburg, PA, USA.
X. Wang, C. Zhai. 2008. Mining Term Association Pat-
terns from Search Logs for Effective Query Reformu-
lation. In Proceedings of the 17th ACM International
Conference on Information and Knowledge Manage-
ment 2008, CIKM’08. 479-488.
J. Xu and W. B. Croft. 1996. Query expansion using
local and global document analysis. In Proceedings of
the 19th annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’96. ACM, New York, NY.
A. Yessenalina, Y. Yue, C. Cardie. 2010. Multi-
level Structured Models for Document-level Sentiment
Classification. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP ’10). 10461056.
</reference>
<page confidence="0.992841">
1521
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.414559">
<title confidence="0.9849265">A Discriminative Model for Query Spelling Correction with Structural SVM</title>
<author confidence="0.989489">Huizhong Duan</author>
<author confidence="0.989489">Yanen Li</author>
<author confidence="0.989489">ChengXiang Zhai</author>
<author confidence="0.989489">Dan</author>
<affiliation confidence="0.997435">University of Illinois at</affiliation>
<address confidence="0.746835">201 N Goodwin Urbana, IL</address>
<email confidence="0.761846">yanenli2,czhai,</email>
<abstract confidence="0.99914448">Discriminative training in query spelling correction is difficult due to the complex internal structures of the data. Recent work on query spelling correction suggests a two stage approach a noisy channel model that is used to retrieve a number of candidate corrections, followed by discriminatively trained ranker applied to these candidates. The ranker, however, suffers from the fact the low recall of the first, suboptimal, search stage. This paper proposes to directly optimize the search stage with a discriminative model based on latent structural SVM. In this model, we treat query spelling correction as a multiclass classification problem with structured input and output. The latent structural information is used to model the alignment of words in the spelling correction process. Experiment results show that as a standalone speller, our model outperforms all the baseline systems. It also attains a higher recall compared with the noisy channel model, and can therefore serve as a better filtering stage when combined with a ranker.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Ahmad</author>
<author>G Kondrak</author>
</authors>
<title>Learning a spelling error model from search query logs.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP. The Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8571" citStr="Ahmad and Kondrak, 2005" startWordPosition="1385" endWordPosition="1389">r components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for </context>
</contexts>
<marker>Ahmad, Kondrak, 2005</marker>
<rawString>F. Ahmad and G. Kondrak. 2005. Learning a spelling error model from search query logs. In HLT/EMNLP. The Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bendersky</author>
<author>W B Croft</author>
</authors>
<title>Discovering key concepts in verbose queries.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08.</booktitle>
<pages>491--498</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="9097" citStr="Bendersky and Croft, 2008" startWordPosition="1467" endWordPosition="1470">ge web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative trai</context>
</contexts>
<marker>Bendersky, Croft, 2008</marker>
<rawString>M. Bendersky and W. B. Croft. 2008. Discovering key concepts in verbose queries. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08. ACM, New York, NY, USA, 491-498.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>R Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Hong Kong.</location>
<contexts>
<context position="7988" citStr="Brill and Moore, 2000" startWordPosition="1288" endWordPosition="1291">ghts trained by LS-SVM can be used to search for more candidate corrections. The improvement in recall at different levels over the noisy channel model demonstrates that our model is superior even when used in the two-stage approach.. 2 Related Work Spelling correction has a long history (Levenshtein, 1966). Traditional techniques were on small scale and depended on having a small trusted lexicons (Kukich, 1992). Later, statistical generative models were shown to be effective in spelling correction, where a source language model and an error model were identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>E. Brill and R. Moore. 2000. An improved error model for noisy channel spelling correction. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>D Goldwasser</author>
<author>D Roth</author>
<author>V Srikumar</author>
</authors>
<title>Discriminative Learning over Constrained Latent Representations.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="5335" citStr="Chang et al., 2010" startWordPosition="861" endWordPosition="864">lling correction using a discriminative model without loss of efficiency. More specifically, we want 1) a learning process that is aware of the search phase and interacts with its result; 2) an efficient search algorithm that is able to incorporate the learned model and guide the search to the target spelling correction. In this paper, we propose a new discriminative model for query correction that maintains the advantage of a discriminative model in accommodating flexible combination of features and naturally incorporates an efficient search algorithm in learning and inference. Similarly to (Chang et al., 2010) we collapse a two stage process into a single discriminatively trained process, by considering the output of the first stage as an intermediate latent representation for the joint learning process. Specifically, we make use of the latent structural SVM (LS-SVM) (Yu and Joachims, 2009) formulation. We formulate the problem query spelling correction as a multiclass classification problem on structured inputs and outputs. The advantage of the structural SVM model is that it allows task specific, customizable solutions for the inference problem. This allows us to adapt the model to make it work d</context>
<context position="10231" citStr="Chang et al., 2010" startWordPosition="1645" endWordPosition="1648">idely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small search space where the number of candidates at each step is limited (e.g. POS tagging). A typically used search algorithm is dynamic programming. In spelling correction, however, the search space is much bigger and the existing approaches featuring dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing and Transliteration (Chang et al., 2010) to sentiment analysis (Yessenalina et al., 2010). Work has also been done on integrating discriminative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framewo</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>M. Chang, D. Goldwasser, D. Roth and V. Srikumar. 2010. Discriminative Learning over Constrained Latent Representations. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Chen</author>
<author>M Li</author>
<author>M Zhou</author>
</authors>
<title>Improving query spelling correction using web search results. In EMNLP-CoNLL,</title>
<date>2007</date>
<pages>181--189</pages>
<contexts>
<context position="8519" citStr="Chen et al., 2007" startWordPosition="1377" endWordPosition="1380">nd an error model were identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho</context>
</contexts>
<marker>Chen, Li, Zhou, 2007</marker>
<rawString>Q. Chen, M. Li, and M. Zhou. 2007. Improving query spelling correction using web search results. In EMNLP-CoNLL, pages 181–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
<author>E Brill</author>
</authors>
<title>Spelling correction as an iterative process that exploits the collective knowledge of web users.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="8545" citStr="Cucerzan and Brill, 2004" startWordPosition="1381" endWordPosition="1384">ere identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of</context>
</contexts>
<marker>Cucerzan, Brill, 2004</marker>
<rawString>S. Cucerzan and E. Brill. 2004. Spelling correction as an iterative process that exploits the collective knowledge of web users. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daume</author>
<author>J Langford</author>
<author>D Marcu</author>
</authors>
<title>Searchbased Structured Prediction.</title>
<date>2009</date>
<journal>Machine Learning Journal (MLJ).</journal>
<contexts>
<context position="10789" citStr="Daume et al., 2009" startWordPosition="1734" endWordPosition="1737"> been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing and Transliteration (Chang et al., 2010) to sentiment analysis (Yessenalina et al., 2010). Work has also been done on integrating discriminative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framework in that it learns to make global decisions rather than accumulating local decisions. The global decision was made possible by an efficient search algorithm. Query spelling correction also shares many similarities with statistical machine translation (SMT). Sun et al. (2010) has formulated the problem within an SMT framework. However, SMT usually involves more complex alignments, while in query spelling correction search is the more challenging part. Our main contribution in this paper is a novel unified way to directly optimize the search phase of q</context>
</contexts>
<marker>Daume, Langford, Marcu, 2009</marker>
<rawString>H. Daume, J. Langford and D. Marcu. 2009. Searchbased Structured Prediction. Machine Learning Journal (MLJ).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
<author>D Smith</author>
<author>N Smith</author>
</authors>
<title>Vine parsing and minimum risk reranking for speed and precision.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning.</booktitle>
<pages>201--205</pages>
<contexts>
<context position="22380" citStr="Dreyer et al., 2006" startWordPosition="3781" endWordPosition="3784">spelling correction, usually only one correction is valid for an input query. Therefore, we apply the 0-1 loss to our model: Δ(c, ˆc) = { 0 C�� C (10) l Given this loss function, the loss augmented inference problem can be solved easily with an algorithm similar to Algorithm 1. This is done by initializing the loss to be 1 at the beginning of each search path. During the search procedure, we check if the loss decreases to 0 given the correction string so far. If this is the case, we decreases the score by 1 and add the path back to the priority queue. More advanced functions may also be used (Dreyer et al., 2006), which may lead to better training performance. We plan to further study different loss functions in our future work. The inference of the latent alignment variable can be solved with dynamic programming, as the number of possible alignments is limited given the query and the correction. 4 Features In the following discussions, we will describe how the features in our discriminative model are developed under the guidance of the monotonicity constraint. 4.1 Source Probability and Transformation Probability We know from empirical experience that the source probability and the transformation pro</context>
</contexts>
<marker>Dreyer, Smith, Smith, 2006</marker>
<rawString>M. Dreyer, D. Smith and N. Smith. 2006. Vine parsing and minimum risk reranking for speed and precision. In Proceedings of the Tenth Conference on Computational Natural Language Learning. 201-205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Duan</author>
<author>B-J P Hsu</author>
</authors>
<title>Online spelling correction for query completion.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference on World wide web, WWW ’11,</booktitle>
<pages>117--126</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="23796" citStr="Duan and Hsu, 2011" startWordPosition="4037" endWordPosition="4040">ure: 5 6 7 8 9 10 11 12 13 14 15 16 17 18 else 1516 µ+y|a |log p(c) (q, c, a) =µ ( ) 1 + E| a |log p(c) 11 , 1 where µ is a normalizing factor computed as: µ = −|q |log pmin, (12) where pmin is the smallest probability we use in practice. The formula fits the general form we define in 5 in that ψ0 = 1 and ψ1(qat, cat, at) = log p(c) µ for any t = 1 to |a|. Similarly, we have the follow feature for the transformation probability: We use the web Microsoft n-gram model1 to compute source model p(c). We train the unigram transformation model for the transformation probability p(q|c) according to (Duan and Hsu, 2011). In generative models, we treat transformation probabilities from merging and splitting errors in the same way as single word errors. In our discriminative model we can assign separate weight to the transformation probabilities resulted from different types of errors. This allows fine tuning of the query spelling correction system, making it more adaptive to environments where the ratio of different types of errors may vary. Moreover, the model also allows us to include language models trained over different resources, such as query log, title of webpages or anchor texts. 4.2 Local Heuristic </context>
</contexts>
<marker>Duan, Hsu, 2011</marker>
<rawString>H. Duan and B.-J. P. Hsu. 2011. Online spelling correction for query completion. In Proceedings of the 20th international conference on World wide web, WWW ’11, pages 117–126, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>J H Clark</author>
<author>A Lavie</author>
<author>N A Smith</author>
</authors>
<title>Unsupervised Word Alignment with Arbitrary Features.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="10251" citStr="Dyer et al., 2011" startWordPosition="1649" endWordPosition="1652">any approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small search space where the number of candidates at each step is limited (e.g. POS tagging). A typically used search algorithm is dynamic programming. In spelling correction, however, the search space is much bigger and the existing approaches featuring dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing and Transliteration (Chang et al., 2010) to sentiment analysis (Yessenalina et al., 2010). Work has also been done on integrating discriminative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framework in that it learns</context>
</contexts>
<marker>Dyer, Clark, Lavie, Smith, 2011</marker>
<rawString>C. Dyer, J. H. Clark, A. Lavie, and N. A. Smith. 2011. Unsupervised Word Alignment with Arbitrary Features. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
<author>S Khadivi</author>
</authors>
<title>A Sequence Alignment Model Based on the Averaged Perceptron.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<pages>238--247</pages>
<contexts>
<context position="10686" citStr="Freitag and Khadivi, 2007" startWordPosition="1718" endWordPosition="1721">turing dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing and Transliteration (Chang et al., 2010) to sentiment analysis (Yessenalina et al., 2010). Work has also been done on integrating discriminative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framework in that it learns to make global decisions rather than accumulating local decisions. The global decision was made possible by an efficient search algorithm. Query spelling correction also shares many similarities with statistical machine translation (SMT). Sun et al. (2010) has formulated the problem within an SMT framework. However, SMT usually involves more complex alignments, while in query spelling correction search is the more challenging part</context>
</contexts>
<marker>Freitag, Khadivi, 2007</marker>
<rawString>D. Freitag, S. Khadivi. 2007. A Sequence Alignment Model Based on the Averaged Perceptron. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. 238-247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gao</author>
<author>X Li</author>
<author>D Micol</author>
<author>C Quirk</author>
<author>X Sun</author>
</authors>
<title>A large scale ranker-based system for search query spelling correction.</title>
<date>2010</date>
<booktitle>In COLING,</booktitle>
<pages>358--366</pages>
<contexts>
<context position="2894" citStr="Gao et al., 2010" startWordPosition="461" endWordPosition="464">mind. The probability is usually modeled by a language model estimated from a sizable corpus. The transformation probability p(q|c) measures how likely it is that q is the output given that c has been formed by the user. This probability can be either heuristic-based (edit distance) or learned from samples of well aligned corrections. One problem with the noisy channel model is that there is no weighting for the two kinds of probabilities, and since they are estimated from different sources, there are usually issues regarding their scale and comparability, resulting in suboptimal performance (Gao et al., 2010). Another limitation of this generative model is that it is not able to take advantage of additional useful features. c� = arg max c = arg max c 1511 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1511–1521, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics A discriminative model may solve these problems by adding the flexibility of using features and applying weights. But training such a model is not easy. The difficulty is that the output space of query correct</context>
<context position="8739" citStr="Gao et al., 2010" startWordPosition="1410" endWordPosition="1413">andidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segment</context>
</contexts>
<marker>Gao, Li, Micol, Quirk, Sun, 2010</marker>
<rawString>J. Gao, X. Li, D. Micol, C. Quirk, and X. Sun. 2010. A large scale ranker-based system for search query spelling correction. In COLING, pages 358–366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Golding</author>
<author>D Roth</author>
</authors>
<title>A Winnow based approach to Context-Sensitive Spelling Correction.</title>
<date>1999</date>
<booktitle>In Machine Learning,</booktitle>
<volume>34</volume>
<pages>107--130</pages>
<contexts>
<context position="8103" citStr="Golding and Roth, 1999" startWordPosition="1309" endWordPosition="1312">t levels over the noisy channel model demonstrates that our model is superior even when used in the two-stage approach.. 2 Related Work Spelling correction has a long history (Levenshtein, 1966). Traditional techniques were on small scale and depended on having a small trusted lexicons (Kukich, 1992). Later, statistical generative models were shown to be effective in spelling correction, where a source language model and an error model were identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing ad</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>A. R. Golding and D. Roth 1999. A Winnow based approach to Context-Sensitive Spelling Correction. In Machine Learning, vol 34, pages 107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Guo</author>
<author>G Xu</author>
<author>H Li</author>
<author>X Cheng</author>
</authors>
<title>A unified and discriminative model for query refinement.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR, SIGIR ’08,</booktitle>
<pages>379--386</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="9240" citStr="Guo et al., 2008" startWordPosition="1490" endWordPosition="1493">se-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small search space where the</context>
</contexts>
<marker>Guo, Xu, Li, Cheng, 2008</marker>
<rawString>J. Guo, G. Xu, H. Li, and X. Cheng. 2008. A unified and discriminative model for query refinement. In Proceedings of the 31st annual international ACM SIGIR, SIGIR ’08, pages 379–386, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C John Yu</author>
<author>T Joachims</author>
</authors>
<title>Learning structural SVMs with latent variables.</title>
<date>2009</date>
<booktitle>In Proceedings of the 26th Annual International Conference on Machine Learning (ICML ’09).</booktitle>
<pages>1169--1176</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="5621" citStr="Yu and Joachims, 2009" startWordPosition="907" endWordPosition="910">arch to the target spelling correction. In this paper, we propose a new discriminative model for query correction that maintains the advantage of a discriminative model in accommodating flexible combination of features and naturally incorporates an efficient search algorithm in learning and inference. Similarly to (Chang et al., 2010) we collapse a two stage process into a single discriminatively trained process, by considering the output of the first stage as an intermediate latent representation for the joint learning process. Specifically, we make use of the latent structural SVM (LS-SVM) (Yu and Joachims, 2009) formulation. We formulate the problem query spelling correction as a multiclass classification problem on structured inputs and outputs. The advantage of the structural SVM model is that it allows task specific, customizable solutions for the inference problem. This allows us to adapt the model to make it work directly with the search algorithm we use for finding the best correction of the query. To account for word boundary errors, we model the word alignment between the query and the correction as a latent structural variable. The LS-SVM model allows us to jointly search over the output spa</context>
<context position="15635" citStr="Yu and Joachims, 2009" startWordPosition="2550" endWordPosition="2553">rn the model parameter w to directly optimize the maximization problem; 2) how can we solve the maximization efficiently without having to enumerate all candidates; 3) how can we design features to guarantee the correctness of the search algorithm. In the following subsections we introduce our solutions to the three challenges in detail. 3.2 Latent Structural SVM We employ the latent structural SVM (LS-SVM) model for learning the discriminative model of query spelling correction. LS-SVM is a large margin method that deals with structured prediction problems with latent structural information (Yu and Joachims, 2009). LS-SVM has the merit of allowing [w &apos; (Ψ0 + � |q |Ψ1(qi, ci))], (4) i=1 1514 task specific, customizable solutions for the inference problem. This makes it easy to adapt to learning the model parameters for different problems. The following is a brief introduction of LS-SVM that largely mirrors the work by (Yu and Joachims, 2009). Without loss of generality, let us aim at learning a prediction function f : X —* Y that maps input x E X to an output y E Y with latent structural information h E X The decision function is of the following form: f(x) = arg max [w · IF(x, y, h)], (6) (y,h)EYXW whe</context>
<context position="17655" citStr="Yu and Joachims, 2009" startWordPosition="2921" endWordPosition="2924">w · �(xi, yi, h)]. (9) hEW The Latent Structural SVM framework does not specify how the maximization problems in Equation 8 and Equation 9 are solved, as well as the inference problem in 6. These maximization problems are task dependent. Being able to efficiently solve them is the key to successfully applying the Latent Structural SVM method. We will show in detail how we solve these maximization problems to make LSSVM work for query spelling correction in the following subsection. For training the LS-SVM model, a ConcaveConvex Procedure (CCCP) was proposed to solve this optimization problem (Yu and Joachims, 2009). The method resembles the Expect-Maximization (EM) training method as it updates the model by iteratively recomputing the latent variable. However, rather than performing “sum-product” training as in EM where a distribution over the hidden variable is maintained, the CCCP method used for LS-SVM is more similar to the “max-product” paradigm where we “guess” the best hidden variable in each iteration, except here we “guess” by minimizing a regularized loss function instead of maximizing the likelihood. 3.3 Solving the Inference Problems The essential inference problem is to find the correction </context>
</contexts>
<marker>Yu, Joachims, 2009</marker>
<rawString>C. John Yu and T. Joachims. 2009. Learning structural SVMs with latent variables. In Proceedings of the 26th Annual International Conference on Machine Learning (ICML ’09). ACM, New York, NY, USA, 1169-1176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>W A Gale</author>
</authors>
<title>A spelling correction program based on a noisy channel model.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th conference on Computational linguistics.</booktitle>
<pages>205--210</pages>
<location>Helsinki, Finland.</location>
<marker>Church, Gale, 1990</marker>
<rawString>M. D. Kernighan , K. W. Church, W. A. Gale. 1990. A spelling correction program based on a noisy channel model. In Proceedings of the 13th conference on Computational linguistics. 205-210. August 20-25, 1990, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>ACM computing surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="7781" citStr="Kukich, 1992" startWordPosition="1255" endWordPosition="1256">acy of correction can be improved significantly over baseline systems including an award winning query spelling system. Even though the optimization is primarily based on the top correction, the weights trained by LS-SVM can be used to search for more candidate corrections. The improvement in recall at different levels over the noisy channel model demonstrates that our model is superior even when used in the two-stage approach.. 2 Related Work Spelling correction has a long history (Levenshtein, 1966). Traditional techniques were on small scale and depended on having a small trusted lexicons (Kukich, 1992). Later, statistical generative models were shown to be effective in spelling correction, where a source language model and an error model were identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspell</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>K. Kukich. 1992. Techniques for automatically correcting words in text. ACM computing surveys, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kumaran</author>
<author>J Allan</author>
</authors>
<title>Effective and efficient user interaction for long queries.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08.</booktitle>
<publisher>ACM,</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="9070" citStr="Kumaran and Allan, 2008" startWordPosition="1462" endWordPosition="1466">on includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to </context>
</contexts>
<marker>Kumaran, Allan, 2008</marker>
<rawString>G. Kumaran and J. Allan. 2008. Effective and efficient user interaction for long queries. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08. ACM, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kumaran</author>
<author>V R Carvalho</author>
</authors>
<title>Reducing long queries using query quality predictors.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09.</booktitle>
<pages>564--571</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="9126" citStr="Kumaran and Carvalho, 2009" startWordPosition="1471" endWordPosition="1474">g (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum e</context>
</contexts>
<marker>Kumaran, Carvalho, 2009</marker>
<rawString>G. Kumaran and V. R. Carvalho. 2009. Reducing long queries using query quality predictors. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09. ACM, New York, NY, USA, 564-571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning (ICML</booktitle>
<volume>01</volume>
<pages>282--289</pages>
<contexts>
<context position="9754" citStr="Lafferty, 2001" startWordPosition="1571" endWordPosition="1572">pes of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small search space where the number of candidates at each step is limited (e.g. POS tagging). A typically used search algorithm is dynamic programming. In spelling correction, however, the search space is much bigger and the existing approaches featuring dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing </context>
</contexts>
<marker>Lafferty, 2001</marker>
<rawString>J. Lafferty. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML ’01). 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<booktitle>In Soviet Physics Doklady,</booktitle>
<volume>10</volume>
<issue>8</issue>
<pages>707--710</pages>
<contexts>
<context position="7674" citStr="Levenshtein, 1966" startWordPosition="1239" endWordPosition="1240"> stage for a ranker based system. Experiments verify the effectiveness of the discriminative model, as the accuracy of correction can be improved significantly over baseline systems including an award winning query spelling system. Even though the optimization is primarily based on the top correction, the weights trained by LS-SVM can be used to search for more candidate corrections. The improvement in recall at different levels over the noisy channel model demonstrates that our model is superior even when used in the two-stage approach.. 2 Related Work Spelling correction has a long history (Levenshtein, 1966). Traditional techniques were on small scale and depended on having a small trusted lexicons (Kukich, 1992). Later, statistical generative models were shown to be effective in spelling correction, where a source language model and an error model were identified as two major components 1512 (Brill and Moore, 2000). Note that we are not dealing here with the standard models in context sensitive spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. C</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>V. I. Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. In Soviet Physics Doklady, 10(8), 707-710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Luec</author>
</authors>
<title>A data-driven approach for correcting search quaries. In Spelling Alteration for Web Search Workshop.</title>
<date>2011</date>
<contexts>
<context position="29737" citStr="Luec, 2011" startWordPosition="5075" endWordPosition="5076">and 0 otherwise. We use R@N to denote recall for systems limited to output top N corrections. Expected F1 measure can be computed as: F1 = 2 · precision · recall (21) precision + recall 5.3 Experiment Results Table 1 compares the performance of our LS-SVM based model with two strong baseline systems. The first baseline system is an Echo system which simply echos the input. The echo system is usually considered as a strong baseline in query spelling correction as the majority of the queries are correctly spelled queries. The second baseline Lueck-2011 we use is a award winning speller system5 (Luec, 2011), which was ranked at the first place in Microsoft Spelling Challenge 2011. 4http://times.cs.uiuc.edu/duan9/msn speller.tar.gz 5http://www.phraselink.com � |Q |qEQ � cEC(q) 1 P recision = � I,(C(q), a)/|S(q)|, (20) aES(q) 1518 Table 1: LSSVM vs Baselines Serving as Standalone Speller All Queries Misspelled Queries Dataset Method Precision R@10 F1 Precision R@10 F1 Echo 0.949 0.876 0.911 0 0 0 TREC Lueck-2011 0.963 0.932 0.947 0.391 0.479 0.430 LS-SVM 0.955 0.944 0.949 0.331 0.678† 0.445† Echo 0.869 0.869 0.869 0 0 0 MSN Lueck-2011 0.896 0.921 0.908 0.334 0.397 0.363 LS-SVM 0.903 0.953 0.928 0.</context>
</contexts>
<marker>Luec, 2011</marker>
<rawString>G. Luec. 2011. A data-driven approach for correcting search quaries. In Spelling Alteration for Web Search Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>D Freitag</author>
<author>F Pereira</author>
</authors>
<title>Maximum Entropy Markov Models for Information Extraction and Segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning (ICML</booktitle>
<volume>00</volume>
<pages>591--598</pages>
<contexts>
<context position="9737" citStr="McCallum et al., 2000" startWordPosition="1567" endWordPosition="1570">lho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small search space where the number of candidates at each step is limited (e.g. POS tagging). A typically used search algorithm is dynamic programming. In spelling correction, however, the search space is much bigger and the existing approaches featuring dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailme</context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>A. McCallum, D. Freitag, and F. Pereira. 2000. Maximum Entropy Markov Models for Information Extraction and Segmentation. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML ’00). 591-598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mitra</author>
<author>A Singhal</author>
<author>C Buckley</author>
</authors>
<title>Improving automatic query expansion.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’98.</booktitle>
<contexts>
<context position="9027" citStr="Mitra et al., 1998" startWordPosition="1457" endWordPosition="1460">e of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in </context>
</contexts>
<marker>Mitra, Singhal, Buckley, 1998</marker>
<rawString>M. Mitra, A. Singhal, and C. Buckley. 1998. Improving automatic query expansion. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qiu</author>
<author>H Frei</author>
</authors>
<title>Concept based query expansion.</title>
<date>1993</date>
<booktitle>In Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’93.</booktitle>
<pages>160--169</pages>
<publisher>ACM,</publisher>
<location>New York, NY, USA,</location>
<contexts>
<context position="9006" citStr="Qiu and Frei, 1993" startWordPosition="1453" endWordPosition="1456">d a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has</context>
</contexts>
<marker>Qiu, Frei, 1993</marker>
<rawString>Y. Qiu and H. Frei. 1993. Concept based query expansion. In Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’93. ACM, New York, NY, USA, 160-169.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Sun</author>
<author>J Gao</author>
<author>D Micol</author>
<author>C Quirk</author>
</authors>
<title>Learning phrase-based spelling error models from clickthrough data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>266--274</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8685" citStr="Sun et al., 2010" startWordPosition="1401" endWordPosition="1404">e spelling (Golding and Roth, 1999) where the set of candidate correction is a known “confusion set”. Query spelling correction, a special form of the problem, has received much attention in recent years. Compared with traditional spelling correction task, query spelling deals with more complex types of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad </context>
<context position="11108" citStr="Sun et al. (2010)" startWordPosition="1783" endWordPosition="1786">inative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framework in that it learns to make global decisions rather than accumulating local decisions. The global decision was made possible by an efficient search algorithm. Query spelling correction also shares many similarities with statistical machine translation (SMT). Sun et al. (2010) has formulated the problem within an SMT framework. However, SMT usually involves more complex alignments, while in query spelling correction search is the more challenging part. Our main contribution in this paper is a novel unified way to directly optimize the search phase of query spelling correction with the use of LS-SVM. 3 Discriminative Model for Query Spelling Correction Based on LS-SVM In this section, we first present the discriminative formulation of the problem of query spelling correction. Then we introduce in detail the model we use for solving the problem. 3.1 The Discriminativ</context>
</contexts>
<marker>Sun, Gao, Micol, Quirk, 2010</marker>
<rawString>X. Sun, J. Gao, D. Micol, and C. Quirk. 2010. Learning phrase-based spelling error models from clickthrough data. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 266–274, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wang</author>
<author>C Zhai</author>
</authors>
<title>Mining Term Association Patterns from Search Logs for Effective Query Reformulation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM International Conference on Information and Knowledge Management</booktitle>
<pages>08--479</pages>
<contexts>
<context position="9220" citStr="Wang and Zhai, 2008" startWordPosition="1486" endWordPosition="1489">m models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or source channel model) has been widely used in NLP. Many approaches have been proposed to perform discriminative training of the model (McCallum et al., 2000; Lafferty, 2001). However, these approaches mostly deal with a relatively small se</context>
</contexts>
<marker>Wang, Zhai, 2008</marker>
<rawString>X. Wang, C. Zhai. 2008. Mining Term Association Patterns from Search Logs for Effective Query Reformulation. In Proceedings of the 17th ACM International Conference on Information and Knowledge Management 2008, CIKM’08. 479-488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Xu</author>
<author>W B Croft</author>
</authors>
<title>Query expansion using local and global document analysis.</title>
<date>1996</date>
<booktitle>In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’96.</booktitle>
<publisher>ACM,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="8986" citStr="Xu and Croft, 1996" startWordPosition="1449" endWordPosition="1452">s of misspellings and a much larger scale of language. Research in this direction includes utilizing large web corpora and query log (Chen et al., 2007; Cucerzan and Brill, 2004; Ahmad and Kondrak, 2005), employing large-scale n-gram models, training phrase-based error model from clickthrough data (Sun et al., 2010) and developing additional features (Gao et al., 2010). Query alteration/refinement is a very relevant topic to query spelling correction. The goal of query alteration/refinement is to modify the ineffective query so that it could . Researches on this track include query expansion (Xu and Croft, 1996; Qiu and Frei, 1993; Mitra et al., 1998), query contraction(Kumaran and Allan, 2008; Bendersky and Croft, 2008; Kumaran and Carvalho, 2009) and other types of query reformulations for bridging the vocabulary gap (Wang and Zhai, 2008). (Guo et al., 2008) proposed a unified model to perform a broad set of query refinements including correction, segmentation and stemming. However, it has very limited ability in query correction. In this paper, we study the discriminative training of query spelling correction, which is potentially beneficial to many existing studies. Noisy channel model (or sourc</context>
</contexts>
<marker>Xu, Croft, 1996</marker>
<rawString>J. Xu and W. B. Croft. 1996. Query expansion using local and global document analysis. In Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’96. ACM, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yessenalina</author>
<author>Y Yue</author>
<author>C Cardie</author>
</authors>
<title>Multilevel Structured Models for Document-level Sentiment Classification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP ’10).</booktitle>
<pages>10461056</pages>
<contexts>
<context position="10443" citStr="Yessenalina et al., 2010" startWordPosition="1680" endWordPosition="1683">search space where the number of candidates at each step is limited (e.g. POS tagging). A typically used search algorithm is dynamic programming. In spelling correction, however, the search space is much bigger and the existing approaches featuring dynamic programming are difficult to be applied. Structural learning and latent structural learning has been studied a lot in NLP in recent years(Chang et al., 2010; Dyer et al., 2011), and has been shown to be useful in a range of NLP applications from Textual Entailment, Paraphrasing and Transliteration (Chang et al., 2010) to sentiment analysis (Yessenalina et al., 2010). Work has also been done on integrating discriminative learning in search. Freitag and Khadivi used a perceptron algorithm to train for sequence alignment problem. A beam search algorithm was utilized in the search (Freitag and Khadivi, 2007). Daume et al. proposed the Searn framework for search based structural prediction (Daume et al., 2009). Our model differs from the Searn framework in that it learns to make global decisions rather than accumulating local decisions. The global decision was made possible by an efficient search algorithm. Query spelling correction also shares many similarit</context>
</contexts>
<marker>Yessenalina, Yue, Cardie, 2010</marker>
<rawString>A. Yessenalina, Y. Yue, C. Cardie. 2010. Multilevel Structured Models for Document-level Sentiment Classification. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP ’10). 10461056.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>