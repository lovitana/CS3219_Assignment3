<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000290">
<title confidence="0.996636">
Improving Transition-Based Dependency Parsing with Buffer Transitions
</title>
<author confidence="0.990378">
Daniel Fern´andez-Gonz´alez
</author>
<affiliation confidence="0.9072435">
Departamento de Inform´atica
Universidade de Vigo
</affiliation>
<address confidence="0.919022">
Campus As Lagoas, 32004
Ourense, Spain
</address>
<email confidence="0.997394">
danifg@uvigo.es
</email>
<author confidence="0.926513">
Carlos G´omez-Rodriguez
</author>
<affiliation confidence="0.836928">
Departamento de Computaci´on
Universidade da Coru˜na
</affiliation>
<address confidence="0.881802">
Campus de Elvi˜na, 15071
A Coru˜na, Spain
</address>
<email confidence="0.998284">
carlos.gomez@udc.es
</email>
<sectionHeader confidence="0.998593" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998055">
In this paper, we show that significant im-
provements in the accuracy of well-known
transition-based parsers can be obtained, with-
out sacrificing efficiency, by enriching the
parsers with simple transitions that act on
buffer nodes.
First, we show how adding a specific tran-
sition to create either a left or right arc of
length one between the first two buffer nodes
produces improvements in the accuracy of
Nivre’s arc-eager projective parser on a num-
ber of datasets from the CoNLL-X shared
task. Then, we show that accuracy can also be
improved by adding transitions involving the
topmost stack node and the second buffer node
(allowing a limited form of non-projectivity).
None of these transitions has a negative im-
pact on the computational complexity of the
algorithm. Although the experiments in this
paper use the arc-eager parser, the approach is
generic enough to be applicable to any stack-
based dependency parser.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99948">
Dependency parsing has become a very active re-
search area in natural language processing in re-
cent years. The dependency representation of syn-
tax simplifies the syntactic parsing task, since no
non-lexical nodes need to be postulated by the
parsers; while being convenient in practice, since
dependency representations directly show the head-
modifier and head-complement relationships which
form the basis of predicate-argument structure. This
has led to the development of various data-driven
dependency parsers, such as those by Yamada and
Matsumoto (2003), Nivre et al. (2004), McDonald
et al. (2005), Martins et al. (2009), Huang and Sagae
(2010) or Tratz and Hovy (2011), which can be
trained directly from annotated data and produce ac-
curate analyses very efficiently.
Most current data-driven dependency parsers can
be classified into two families, commonly called
graph-based and transition-based parsers (Mc-
Donald and Nivre, 2011). Graph-based parsers (Eis-
ner, 1996; McDonald et al., 2005) are based on
global optimization of models that work by scoring
subtrees. On the other hand, transition-based parsers
(Yamada and Matsumoto, 2003; Nivre et al., 2004),
which are the focus of this work, use local training
to make greedy decisions that deterministically se-
lect the next parser state. Among the advantages of
transition-based parsers are the linear time complex-
ity of many of them and the possibility of using rich
feature models (Zhang and Nivre, 2011).
In particular, many transition-based parsers
(Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii,
2008; Nivre, 2009; Huang and Sagae, 2010; G´omez-
Rodr´ıguez and Nivre, 2010) are stack-based (Nivre,
2008), meaning that they keep a stack of partially
processed tokens and an input buffer of unread to-
kens. In this paper, we show how the accuracy of
this kind of parsers can be improved, without com-
promising efficiency, by extending their set of avail-
able transitions with buffer transitions. These are
transitions that create a dependency arc involving
some node in the buffer, which would typically be
considered unavailable for linking by these algo-
</bodyText>
<page confidence="0.980336">
308
</page>
<note confidence="0.754562">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 308–319, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999872545454546">
rithms. The rationale is that buffer transitions con-
struct some “easy” dependency arcs in advance, be-
fore the involved nodes reach the stack, so that the
classifier’s job when choosing among standard tran-
sitions is simplified.
To test the approach, we use the well-known arc-
eager parser by (Nivre, 2003; Nivre et al., 2004) as
a baseline, showing improvements in accuracy on
most datasets of the CoNLL-X shared task (Buch-
holz and Marsi, 2006). However, the techniques dis-
cussed in this paper are generic and can also be ap-
plied to other stack-based dependency parsers.
The rest of this paper is structured as follows:
Section 2 is an introduction to transition-based
parsers and the arc-eager parsing algorithm. Section
3 presents the first novel contribution of this paper,
projective buffer transitions, and discusses their
empirical results on CoNLL-X datasets. Section 4
does the same for a more complex set of transitions,
non-projective buffer transitions. Finally, Section
5 discusses related work and Section 6 sums up the
conclusions and points out avenues for future work.
</bodyText>
<sectionHeader confidence="0.99692" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999864666666667">
We now briefly present some basic definitions for
transition-based dependency parsing; a more thor-
ough explanation can be found in (Nivre, 2008).
</bodyText>
<subsectionHeader confidence="0.944315">
2.1 Dependency graphs
</subsectionHeader>
<bodyText confidence="0.997819117647059">
Let w = wi ... w,,, be an input string. A depen-
dency graph for w is a directed graph G = (U„, A);
where U„ = {0, 1, ... , n} is a set of nodes, and
A C_ U„ x L x U„ is a set of labelled arcs. Each
node in U„ encodes the position of a token in w,
where 0 is a dummy node used as artificial root. An
arc (i, l, j) will also be called a dependency link la-
belled l from i to j. We say that i is the syntactic
head of j and, conversely, that j is a dependent of
i. The length of the arc (i, l, j) is the value |j − i|.
Most dependency representations of syntax do not
allow arbitrary dependency graphs. Instead, they re-
quire dependency graphs to be forests, i.e., acyclic
graphs where each node has at most one head. In this
paper, we will work with parsers that assume depen-
dency graphs G = (U„, A) to satisfy the following
properties:
</bodyText>
<listItem confidence="0.962747666666667">
• Single-head: every node has at most one in-
coming arc (if (i, l, j) E A, then for every
k =� i, (k, l&apos;, j) E� A).
• Acyclicity: there are no directed cycles in G.
• Node 0 is a root, i.e., there are no arcs of the
form (i, l, 0) in A.
</listItem>
<bodyText confidence="0.9993608125">
A dependency forest with a single root (i.e., where
all the nodes but one have at least one incoming arc)
is called a tree. Every dependency forest can triv-
ially be represented as a tree by adding arcs from
the dummy root node 0 to every other root node.
For reasons of computational efficiency, many de-
pendency parsers are restricted to work with forests
satisfying an additional restriction called projectiv-
ity. A dependency forest is said to be projective
if the set of nodes reachable by traversing zero or
more arcs from any given node k corresponds to a
continuous substring of the input (i.e., is an interval
{x E U„  |i &lt; x &lt; j}). For trees with a dummy
root node at position 0, this is equivalent to not al-
lowing dependency links to cross when drawn above
the nodes (planarity).
</bodyText>
<subsectionHeader confidence="0.999371">
2.2 Transition systems
</subsectionHeader>
<bodyText confidence="0.99548">
A transition system is a nondeterministic state ma-
chine that maps input strings to dependency graphs.
In this paper, we will focus on stack-based transi-
tion systems. A stack-based transition system is a
quadruple 5 = (C, T, cs, Ct) where
</bodyText>
<listItem confidence="0.9974985">
• C is a set of parser configurations. Each con-
figuration is of the form c = (Q, 0, A) where Q
is a list of nodes of U„ called the stack, Q is a
list of nodes of U„ called the buffer, and A is a
set of dependency arcs,
• T is a finite set of transitions, each of which is
a partial function t : C —* C,
• cs is an initialization function, mapping a sen-
tence wi ... w,,, to an initial configuration
cs = ([0], [1, ... , n], 0),
• Ct is the set of terminal configurations Ct =
(Q, [], A) E C.
</listItem>
<bodyText confidence="0.986804333333333">
Transition systems are nondeterministic devices,
since several transitions may be applicable to the
same configuration. To obtain a deterministic parser
</bodyText>
<page confidence="0.99872">
309
</page>
<bodyText confidence="0.999602571428572">
from a transition system, a classifier is trained to
greedily select the best transition at each state. This
training is typically done by using an oracle, which
is a function o : C → T that selects a single transi-
tion at each configuration, given a tree in the training
set. The classifier is then trained to approximate this
oracle when the target tree is unknown.
</bodyText>
<subsectionHeader confidence="0.999838">
2.3 The arc-eager parser
</subsectionHeader>
<bodyText confidence="0.9999466">
Nivre’s arc-eager dependency parser (Nivre, 2003;
Nivre et al., 2004) is one of the most widely known
and used transition-based parsers (see for example
(Zhang and Clark, 2008; Zhang and Nivre, 2011)).
This parser works by reading the input sentence
from left to right and creating dependency links as
soon as possible. This means that links are created in
a strict left-to-right order, and implies that while left-
ward links are built in a bottom-up fashion, a right-
ward link a → b will be created before the node b
has collected its right dependents.
The arc-eager transition system has the following
four transitions (note that, for convenience, we write
a stack with node i on top as σ|i, and a buffer whose
first node is i as i|β):
</bodyText>
<listItem confidence="0.999706714285714">
• SHIFT : (σ, i|β, A) ⇒ (σ|i, β, A).
• REDUCE : (σ|i, β, A) ⇒ (σ, β, A). Precondi-
tion: ∃k, l&apos;  |(k, l&apos;, i) ∈ A.
• LEFT-ARCI : (σ|i, j|β, A) ⇒ (σ, j|β, A ∪
{(j,l, i)}). Preconditions: i 7� 0 and 6∃k, l&apos; |
(k, l&apos;, i) ∈ A (single-head)
• RIGHT-ARCI :
</listItem>
<equation confidence="0.433614">
(σ|i, j|β, A) ⇒ (σ|i|j,β,A ∪ {(i,l, j)}).
</equation>
<bodyText confidence="0.9999431">
The SHIFT transition reads an input word by re-
moving the first node from the buffer and placing it
on top of the stack. The REDUCE transition pops
the stack, and it can only be executed if the topmost
stack node has already been assigned a head. The
LEFT-ARC transition creates an arc from the first
node in the buffer to the node on top of the stack,
and then pops the stack. It can only be executed if
the node on top of the stack does not already have
a head. Finally, the RIGHT-ARC transition creates
an arc from the top of the stack to the first buffer
node, and then removes the latter from the buffer
and moves it to the stack.
The arc-eager parser has linear time complex-
ity. In principle, it is restricted to projective depen-
dency forests, but it can be used in conjunction with
the pseudo-projective transformation (Nivre et al.,
2006) in order to capture a restricted subset of non-
projective forests. Using this setup, it scored as one
of the top two systems in the CoNLL-X shared task.
</bodyText>
<sectionHeader confidence="0.972932" genericHeader="method">
3 Projective buffer transitions
</sectionHeader>
<bodyText confidence="0.9998065">
In this section, we show that the accuracy of stack-
based transition systems can benefit from adding one
of a pair of new transitions, which we call projective
buffer transitions, to their transition sets.
</bodyText>
<subsectionHeader confidence="0.998651">
3.1 The transitions
</subsectionHeader>
<bodyText confidence="0.999422">
The two projective buffer transitions are defined as
follows:
</bodyText>
<listItem confidence="0.81822875">
• LEFT-BUFFER-ARCI :
(σ,i|j|β,A) ⇒ (σ, j|β,A ∪ {(j,l,i)}).
• RIGHT-BUFFER-ARCI :
(σ, i|j|β, A) ⇒ (σ, i|β, A ∪ {(i,l, j)}).
</listItem>
<bodyText confidence="0.97735708">
The LEFT-BUFFER-ARC transition creates a left-
ward dependency link from the second node to
the first node in the buffer, and then removes the
first node from the buffer. Conversely, the RIGHT-
BUFFER-ARC transition creates a rightward depen-
dency link from the first node to the second node
in the buffer, and then removes the second node.
We call these transitions projective buffer transitions
because, since they act on contiguous buffer nodes,
they can only create projective arcs.
Adding one (or both) of these transitions to a
projective or non-projective stack-based transition
system does not affect its correctness, as long as
this starting system cannot generate configurations
(σ, β, A) where a buffer node has a head in A1: it
cannot affect completeness because we are not re-
moving existing transitions, and therefore any de-
pendency graph that the original system could build
1Most stack-based transition systems in the literature disal-
low such configurations. However, in parsers that allow them
(such as those defined by G´omez-Rodriguez and Nivre (2010)),
projective buffer transitions can still be added without affecting
correctness if we impose explicit single-head and acyclicity pre-
conditions on them. We have not included these preconditions
by default for simplicity of presentation.
</bodyText>
<page confidence="0.988355">
310
</page>
<bodyText confidence="0.999991393442623">
will still be obtainable by the augmented one; and it
cannot affect soundness (be it for projective depen-
dency forests or for any superset of them) because
the new transitions can only create projective arcs
and cannot violate the single-head or acyclicity con-
straints, given that a buffer node cannot have a head.
The idea behind projective buffer transitions is to
create dependency arcs of length one (i.e., arcs in-
volving contiguous nodes) in advance of the stan-
dard arc-building transitions that need at least one of
the nodes to get to the stack (LEFT-ARC and RIGHT-
ARC in the case of the arc-eager transition system).
Our hypothesis is that, as it is known that
short-distance dependencies are easier to learn for
transition-based parsers than long-distance ones
(McDonald and Nivre, 2007), handling these short
arcs in advance and removing their dependent nodes
will make it easier for the classifier to learn how
to make decisions involving the standard arc tran-
sitions.
Note that the fact that projective buffer transitions
create arcs of length 1 is not explicit in the defini-
tion of the transitions. For instance, if we add the
LEFT-BUFFER-ARCI transition only to the arc-eager
transition system, LEFT-BUFFER-ARCI will only be
able to create arcs of length 1, since it is easy to see
that the first two buffer nodes are contiguous in all
the accessible configurations. However, if we add
RIGHT-BUFFER-ARCI, this transition will have the
potential to create arcs of length greater than 1: for
example, if two consecutive RIGHT-BUFFER-ARCI
transitions are applied starting from a configuration
(Q, i|i + 1|i + 2|0, A), the second application will
create an arc i —* i + 2 of length 2.
Although we could have added the length-1 re-
striction to the transition definitions, we have cho-
sen the more generic approach of leaving it to the
oracle instead. While the oracle typically used for
the arc-eager system follows the simple principle of
executing transitions that create an arc as soon as
it has the chance to, adding projective buffer transi-
tions opens up new possibilities: we may now have
several ways of creating an arc, and we have to de-
cide in which cases we train the parser to use one of
the buffer transitions and in which cases we prefer
to train it to ignore the buffer transitions and dele-
gate to the standard ones. Following the hypothe-
sis explained above, our policy has been to train the
parser to use buffer transitions whenever possible for
arcs of length one, and to not use them for arcs of
length larger than one. To test this idea, we also
conducted experiments with the alternative policy
“use buffer transitions whenever possible, regardless
of arc length”: as expected, the obtained accuracies
were (slightly) worse.
The chosen oracle policy is generic and can be
plugged into any stack-based parser: for a given
transition, first check whether it is possible to build a
gold-standard arc of length 1 with a projective buffer
transition.2 If so, choose that transition, and if not,
just delegate to the original parser’s oracle.
</bodyText>
<subsectionHeader confidence="0.979313">
3.2 Experiments
</subsectionHeader>
<bodyText confidence="0.999443161290323">
To empirically evaluate the effect of projective
buffer transitions on parsing accuracy, we have con-
ducted experiments on eight datasets of the CoNLL-
X shared task (Buchholz and Marsi, 2006): Arabic
(Hajiˇc et al., 2004), Chinese (Chen et al., 2003),
Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003),
German (Brants et al., 2002), Portuguese (Afonso et
al., 2002), Swedish (Nilsson et al., 2005) and Turk-
ish (Oflazer et al., 2003; Atalay et al., 2003).
As our baseline parser, we use the arc-eager pro-
jective transition system by Nivre (2003). Table 1
compares the accuracy obtained by this system alone
with that obtained when the LEFT-BUFFER-ARC
and RIGHT-BUFFER-ARC transitions are added to
it as explained in Section 3.1.
Accuracy is reported in terms of labelled (LAS)
and unlabelled (UAS) attachment score. We used
SVM classifiers from the LIBSVM package (Chang
and Lin, 2001) for all languages except for Chinese,
Czech and German. In these, we used the LIB-
LINEAR package (Fan et al., 2008) for classifica-
tion, since it reduces training time in these larger
datasets. Feature models for all parsers were specif-
ically tuned for each language.3
2In this context, “possible” means that we can create the arc
without losing the possibility of creating other gold-standard
arcs. In the case of RIGHT-BUFFER-ARC, this involves check-
ing that the candidate dependent node has no dependents in the
gold-standard tree (if it has any, we cannot remove it from the
stack or it would not be able to collect its dependents, so we do
not use the buffer transition).
</bodyText>
<footnote confidence="0.513487333333333">
3All the experimental settings and feature models used are
included in the supplementary material and also available at
http://www.grupolys.org/˜cgomezr/exp/.
</footnote>
<page confidence="0.994125">
311
</page>
<table confidence="0.9999107">
Language NE NE+LBA NE+RBA
LAS UAS LAS UAS LAS UAS
Arabic 66.43 77.19 67.78 78.26 63.87 74.63
Chinese 86.46 90.18 82.47 86.14 86.62 90.64
Czech 77.24 83.40 78.70 84.24 78.28 83.94
Danish 84.91 89.80 85.21 90.20 82.53 87.35
German 86.18 88.60 84.31 86.50 86.48 88.90
Portug. 86.60 90.20 86.92 90.58 85.55 89.28
Swedish 83.33 88.83 82.81 88.03 81.66 88.03
Turkish 63.77 74.35 57.42 66.24 64.33 74.73
</table>
<tableCaption confidence="0.99949">
Table 1: Parsing accuracy (LAS and UAS, excluding punctuation) of Nivre’s arc-eager parser without modification
</tableCaption>
<bodyText confidence="0.979335193548387">
(NE), with the LEFT-BUFFER-ARC transition added (NE+LBA) and with the RIGHT-BUFFER-ARC transition added
(NE+RBA). Best results for each language are shown in boldface.
As can be seen in Table 1, adding a projective
buffer transition improves the performance of the
parser in seven out of the eight tested languages. The
improvements in LAS are statistically significant at
the .01 level4 in the Arabic and Czech treebanks.
Note that the decision of which buffer transition
to add strongly depends on the dataset. In the
majority of the treebanks, we can see that when
the LEFT-BUFFER-ARC transition improves perfor-
mance the RIGHT-BUFFER-ARC transition harms it,
and vice versa. The exceptions are Czech, where
both transitions are beneficial, and Swedish, where
both are harmful. Therefore, when using projective
buffer transitions in practice, the language and anno-
tation scheme should be taken into account (or tests
should be made) to decide which one to use.
Table 2 hints at the reason for this treebank-
sensitiveness. By analyzing the relative frequency
of leftward and rightward dependency links (and,
in particular, of leftward and rightward links of
length 1) in the different treebanks, we see a rea-
sonably clear tendency: the LEFT-BUFFER-ARC
transition works better in treebanks that contain a
large proportion of rightward arcs of length 1, and
the RIGHT-BUFFER-ARC transition works better in
treebanks with a large proportion of leftward arcs of
length 1. Note that, while this might seem coun-
terintuitive at a first glance, it is coherent with the
hypothesis that we formulated in Section 3.1: the
</bodyText>
<footnote confidence="0.988552333333333">
4Statistical significance was assessed using Dan Bikel’s ran-
domized parsing evaluation comparator: http://www.cis.
upenn.edu/˜dbikel/software.html#comparator
</footnote>
<table confidence="0.999941111111111">
Language L% R% L1% R1% Best PBT
Arabic 12.3 87.7 6.5 55.1 LBA
Chinese 58.4 41.6 35.8 15.1 RBA
Czech 41.4 58.6 22.1 24.9 LBA*
Danish 17.1 82.9 10.9 43.0 LBA
German 39.8 60.2 20.3 19.9 RBA
Portug. 32.6 67.4 22.5 26.9 LBA
Swedish 38.2 61.8 24.1 21.8 LBA*
Turkish 77.8 22.2 47.2 10.4 RBA
</table>
<tableCaption confidence="0.995131">
Table 2: Analysis of the datasets used in the experiments
</tableCaption>
<bodyText confidence="0.992177727272727">
in terms of: percentage of leftward and rightward links
(L%, R%), percentage of leftward and rightward links
of length 1 (L1%, R1%), and which projective buffer
transition works better for each dataset according to the
results in Table 1 (LBA = LEFT-BUFFER-ARC, RBA
= RIGHT-BUFFER-ARC). Languages where both tran-
sitions are beneficial (Czech) or harmful (Swedish) are
marked with an asterisk.
advantage of projective buffer transitions is not that
they build arcs more accurately than standard arc-
building transitions (in fact the opposite might be
expected, since they work on nodes while they are
still on the buffer and we have less information about
their surrounding nodes in our feature models), but
that they make it easier for the classifier to decide
among standard transitions. The analysis on Table
2 agrees with that explanation: LEFT-BUFFER-ARC
improves performance in treebanks where it is not
used too often but it can filter out leftward arcs of
length 1, making it easier for the parser to be accu-
rate on rightward arcs of length 1; and the converse
happens for RIGHT-BUFFER-ARC.
</bodyText>
<page confidence="0.986069">
312
</page>
<table confidence="0.9998918">
Language NE NE+LBA NE+RBA NE+LBA+RBA
LA RA LA* RA LBA LA RA* RBA LA* RA* LBA RBA
Arabic 58.28 67.77 42.61 68.65 77.46 55.88 60.63 79.70 37.40 62.28 66.78 75.94
Chinese 85.69 85.79 80.92 84.19 89.00 85.96 84.77 88.01 81.08 79.46 87.72 86.33
Czech 85.73 76.44 80.79 78.34 91.07 86.25 76.62 82.58 79.49 75.98 90.26 81.97
Danish 89.47 83.92 88.65 84.16 91.72 86.27 78.04 92.30 90.23 77.52 88.79 92.10
German 89.15 87.11 83.75 87.23 94.30 89.55 84.38 95.98 79.26 81.60 91.66 90.73
Portuguese 94.77 84.91 90.83 85.11 97.07 93.84 81.86 92.29 88.72 79.86 96.02 89.26
Swedish 87.75 80.74 84.62 81.30 92.83 87.12 74.77 90.73 78.10 72.50 90.86 89.89
Turkish 59.68 74.21 53.02 74.01 72.78 60.23 69.23 73.91 49.34 48.48 65.57 41.94
</table>
<tableCaption confidence="0.7046134">
Table 3: Labelled precision of the arcs built by each transition of Nivre’s arc-eager parser without modification (NE),
with a projective buffer transition added (NE+LBA, NE+RBA) and with both projective buffer transitions added
(NE+LBA+RBA). We mark a standard LEFT-ARC (LA) or RIGHT-ARC (LA) transition with an asterisk (LA*, RA*)
when it is acting only on a “hard” subset of leftward (rightward) arcs, and thus its precision is not directly comparable
to that of (LA, RA). Best results for each language and transition are shown in boldface.
</tableCaption>
<bodyText confidence="0.999565121212121">
To further test this idea, we computed the la-
belled precision of each individual transition of the
parsers with and without projective buffer transi-
tions, as shown in Table 3. As we can see, projec-
tive buffer transitions achieve better precision than
standard transitions, but this is not surprising since
they act only on “easy” arcs of length 1. There-
fore, this high precision does not mean that they ac-
tually build arcs more accurately than the standard
transitions, since it is not measured on the same set
of arcs. Similarly, adding a projective buffer tran-
sition decreases the precision of its corresponding
standard transition, but this is because the standard
transition is then dealing only with “harder” arcs of
length greather than 1, not because it is making more
errors. A more interesting insight comes from com-
paring transitions that are acting on the same tar-
get set of arcs: we see that, in the languages where
LEFT-BUFFER-ARC is beneficial, the addition of
this transition always improves the precision of the
standard RIGHT-ARC transition; and the converse
happens with RIGHT-BUFFER-ARC with respect to
LEFT-ARC. This further backs the hypothesis that
the filtering of “easy” links achieved by projective
buffer transitions makes it easier for the classifier to
decide among standard transitions.
We also conducted experiments adding both tran-
sitions at the same time (NE+LBA+RBA), but the
results were worse than adding the suitable transi-
tion for each dataset. Table 3 hints at the reason: the
precision of buffer transitions noticeably decreases
when both of them are added at the same time, pre-
sumably because it is difficult for the classifier to
</bodyText>
<table confidence="0.9997843">
Language NE+LBA/RBA NE+PP (CoNLL X)
LAS UAS LAS UAS
Arabic 67.78 78.26 66.71 77.52
Chinese 86.62 90.64 86.92 90.54
Czech 78.70 84.24 78.42 84.80
Danish 85.21 90.20 84.77 89.80
German 86.48 88.90 85.82 88.76
Portug. 86.92 90.58 87.60 91.22
Swedish 82.81 88.03 84.58 89.50
Turkish 64.33 74.73 65.68 75.82
</table>
<tableCaption confidence="0.968439">
Table 4: Comparison of the parsing accuracy (LAS
</tableCaption>
<figureCaption confidence="0.8163255">
and UAS, excluding punctuation) of Nivre’s arc-eager
parser with projective buffer transitions (NE+LBA/RBA)
and the parser with the pseudo-projective transformation
(Nivre et al., 2006)
</figureCaption>
<bodyText confidence="0.999791">
decide between both with the restricted feature in-
formation available for buffer nodes.
To further put the obtained results into context,
Table 4 compares the performance of the arc-eager
parser with the projective buffer transition most suit-
able for each dataset with the results obtained by the
parser with the pseudo-projective transformation by
Nivre et al. (2006) in the CoNLL-X shared task, one
of the top two performing systems in that event. The
reader should be aware that the purpose of this ta-
ble is only to provide a broad idea of how our ap-
proach performs with respect to a well-known refer-
ence point, and not to make a detailed comparison,
since the two parsers have not been tuned in homo-
geneous conditions: on the one hand, we had access
to the CoNLL-X test sets which were unavailable
</bodyText>
<page confidence="0.998605">
313
</page>
<table confidence="0.992956833333333">
System Arabic Danish
Nivre et al. (2006) 66.71 84.77
McDonald et al. (2006) 66.91 84.79
Nivre (2009) 67.3 84.7
G´omez-Rodriguez and Nivre (2010) N/A 83.81
NE+LBA/RBA 67.78 85.21
</table>
<tableCaption confidence="0.91686175">
Table 5: Comparison of the Arabic and Danish LAS ob-
tained by the arc-eager parser with projective buffer tran-
sitions in comparison to other parsers in the literature that
report results on these datasets.
</tableCaption>
<bodyText confidence="0.999906868421053">
for the participants in the shared task; on the other
hand, we did not fine-tune the classifier parameters
for each dataset like Nivre et al. (2006), but used de-
fault values for all languages.
As can be seen in the table, even though the
pseudo-projective parser is able to capture non-
projective syntactic phenomena, the algorithm with
projective buffer transitions (which is strictly pro-
jective) outperforms it in four of the eight treebanks,
including non-projective treebanks such as the Ger-
man one.
Furthermore, to our knowledge, our LAS results
for Arabic and Danish are currently the best pub-
lished results for a single-parser system on these
datasets, not only outperforming the systems partic-
ipating in CoNLL-X but also other parsers tested on
these treebanks in more recent years (see Table 5).
Finally, it is worth noting that adding projective
buffer transitions has no negative impact on effi-
ciency, either in terms of computational complex-
ity or of empirical runtime. Since each projective
buffer transition removes a node from the buffer, no
more than n such transitions can be executed for
a sentence of length n, so adding these transitions
cannot increase the complexity of a transition-based
parser. In the particular case of the arc-eager parser,
using projective buffer transitions reduces the aver-
age number of transitions needed to obtain a given
dependency forest, as some nodes can be dispatched
by a single transition rather than being shifted and
later popped from the stack. In practice, we ob-
served that the training and parsing times of the arc-
eager parser with projective buffer transitions were
slightly faster than without them on the Arabic, Chi-
nese, Swedish and Turkish treebanks, and slightly
slower than without them on the other four tree-
banks, so adding these transitions does not seem to
noticeably degrade (or improve) practical efficiency.
</bodyText>
<sectionHeader confidence="0.939911" genericHeader="method">
4 Non-projective buffer transitions
</sectionHeader>
<bodyText confidence="0.999930333333333">
We now present a second set of transitions that still
follow the idea of early processing of some depen-
dency arcs, as in Section 3; but which are able to
create arcs skipping over a buffer node, so that they
can create some non-projective arcs. For this reason,
we call them non-projective buffer transitions.
</bodyText>
<subsectionHeader confidence="0.995971">
4.1 The transitions
</subsectionHeader>
<bodyText confidence="0.9914125">
The two non-projective buffer transitions are defined
as follows:
</bodyText>
<listItem confidence="0.919748">
• LEFT-NONPROJ-BUFFER-ARCI :
</listItem>
<equation confidence="0.8599668">
(ali, jIkI0,A) ==&gt;- (a, jJkJ0,A U {(k,l,i)}).
Preconditions: i 74 0 and /�m, l&apos; 1 (m, l&apos;, i) E
A (single-head)
• RIGHT-NONPROJ-BUFFER-ARCI :
(ali, jIkJ0,A) ==&gt;- (ali, j10,AU {(i,l,k)}).
</equation>
<bodyText confidence="0.999351125">
The LEFT-NONPROJ-BUFFER-ARC transition
creates a leftward arc from the second buffer node
to the node on top of the stack, and then pops the
stack. It can only be executed if the node on top of
the stack does not already have a head. The RIGHT-
NONPROJ-BUFFER-ARC transition creates an arc
from the top of the stack to the second node in the
buffer, and then removes the latter from the buffer.
Note that these transitions are analogous to projec-
tive buffer transitions, and they use the second node
in the buffer in the same way, but they create arcs
involving the node on top of the stack rather than
the first buffer node. This change makes the pre-
condition that checks for a head necessary for the
transition LEFT-NONPROJ-BUFFER-ARC to respect
the single-head constraint, since many stack-based
parsers can generate configurations where the node
on top of the stack has a head.
We call these transitions non-projective buffer
transitions because, as they act on non-contiguous
nodes in the stack and buffer, they allow the creation
of a limited set of non-projective dependency arcs.
This means that, when added to a projective parser,
they will increase its coverage.5 On the other hand,
</bodyText>
<footnote confidence="0.988794">
5They may also increase the coverage of parsers allowing
restricted forms of non-projectivity, but that depends on the par-
</footnote>
<page confidence="0.995221">
314
</page>
<table confidence="0.999924">
Language NE NE+LNBA NE+RNBA
LAS UAS LAS UAS LAS UAS
Arabic 66.43 77.19 67.13 77.90 67.21 77.92
Chinese 86.46 90.18 87.71 91.39 86.98 90.76
Czech 77.24 83.40 78.88 84.72 78.12 83.78
Danish 84.91 89.80 85.17 90.10 84.25 88.92
German 86.18 88.60 86.96 88.98 85.56 88.30
Portug. 86.60 90.20 86.78 90.34 86.07 89.92
Swedish 83.33 88.83 83.55 89.30 83.17 88.59
Turkish 63.77 74.35 63.04 73.99 65.01 75.70
</table>
<tableCaption confidence="0.954976333333333">
Table 6: Parsing accuracy (LAS and UAS, excluding punctuation) of Nivre’s arc-eager parser without modifica-
tion (NE), with the LEFT-NONPROJ-BUFFER-ARC transition added (NE+LNBA) and with the RIGHT-NONPROJ-
BUFFER-ARC transition added (NE+RNBA). Best results for each language are shown in boldface.
</tableCaption>
<bodyText confidence="0.999477307692308">
adding these transitions to a stack-based transition
system does not affect soundness under the same
conditions and for the same reasons explained for
projective buffer transitions in Section 3.1.
Note that the fact that non-projective buffer tran-
sitions are able to create non-projective dependency
arcs does not mean that all the arcs that they build
are non-projective, since an arc on non-contiguous
nodes in the stack and buffer may or may not cross
other arcs. This means that non-projective buffer
transitions serve a dual purpose: not only they
increase coverage, but they also can create some
“easy” dependency links in advance of standard
transitions, just like projective buffer transitions.
Contrary to projective buffer transitions, we do
not impose any arc length restrictions on non-
projective buffer transitions (either as a hard con-
straint in the transitions themselves or as a policy in
the training oracle), since we would like the increase
in coverage to be as large as possible. We wish to
allow the parsers to create non-projective arcs in a
straightforward way and without compromising effi-
ciency. Therefore, to train the parser with these tran-
sitions, we use an oracle that employs them when-
ever possible, and delegates to the original parser’s
oracle otherwise.
</bodyText>
<subsectionHeader confidence="0.960015">
4.2 Experiments
</subsectionHeader>
<bodyText confidence="0.990615861111111">
We evaluate the impact of non-projective buffer tran-
sitions on parsing accuracy by using the same base-
ticular subset of non-projective structures captured by each such
parser.
line parser, datasets and experimental settings as for
projective buffer transitions in Section 3.2. As can
be seen in Table 6, adding a non-projective buffer
transition to the arc-eager parser improves its per-
formance on all eight datasets. The improvements in
LAS are statistically significant at the .01 level (Dan
Bikel’s comparator) for Chinese, Czech and Turk-
ish. Note that the Chinese treebank is fully projec-
tive, this means that non-projective buffer transitions
are also beneficial when creating projective arcs.
While with projective buffer transitions we ob-
served that each of them was beneficial for about
half of the treebanks, and we related this to the
amount of leftward and rightward links of length 1 in
each; in the case of non-projective buffer transitions
we do not observe this tendency. In this case, LEFT-
NONPROJ-BUFFER-ARC works better than RIGHT-
NONPROJ-BUFFER-ARC in all datasets except for
Turkish and Arabic.
As with the projective transitions, we gathered
data about the individual precision of each of the
transitions. The results were similar to those for
the projective transitions, and show that adding a
non-projective buffer transition improves the preci-
sion of the standard transitions. We also experimen-
tally checked that adding both non-projective buffer
transitions at the same time (NE+LNBA+RNBA)
achieved worse performance than adding only the
most suitable transition for each dataset.
Table 7 compares the performance of the arc-
eager parser with the best non-projective buffer tran-
sition for each dataset with the results obtained by
</bodyText>
<page confidence="0.997124">
315
</page>
<table confidence="0.9999366">
Language NE+LNBA/RNBA NE+PP (CoNLL X)
LAS UAS LAS UAS
Arabic 67.21 77.92 66.71 77.52
Chinese 87.71 91.39 86.92 90.54
Czech 78.88 84.72 78.42 84.80
Danish 85.09 89.98 84.77 89.80
German 86.96 88.98 85.82 88.76
Portug. 86.78 90.34 87.60 91.22
Swedish 83.55 89.30 84.58 89.50
Turkish 65.01 75.70 65.68 75.82
</table>
<tableCaption confidence="0.984958">
Table 7: Comparison of the parsing accuracy (LAS
and UAS, excluding punctuation) of Nivre’s arc-
eager parser with non-projective buffer transitions
(NE+LNBA/RNBA) and the parser with the pseudo-
projective transformation (Nivre et al., 2006).
</tableCaption>
<table confidence="0.999633">
System PP PR NP NR
NE 80.40 80.76 - -
NE+LNBA/RNBA 80.96 81.33 58.87 15.66
NE+PP (CoNLL-X) 80.71 81.00 50.72 29.57
</table>
<tableCaption confidence="0.983716">
Table 8: Comparison of the precision and recall for pro-
</tableCaption>
<figureCaption confidence="0.3683688">
jective (PP, PR) and non-projective (NP, NR) arcs, av-
eraged over all datasets, obtained by Nivre’s arc-eager
parser with and without non-projective buffer transitions
(NE+LNBA/RNBA, NE) and the parser with the pseudo-
projective transformation (Nivre et al., 2006).
</figureCaption>
<bodyText confidence="0.999972703703704">
the parser with the pseudo-projective transformation
by Nivre et al. (2006) in the CoNLL-X shared task.
Note that, like the one in Table 4, this should not
be interpreted as a homogeneous comparison. We
can see that the algorithm with non-projective buffer
transitions obtains better LAS in five out of the eight
treebanks. Precision and recall data on projective
and non-projective arcs (Table 8) show that, while
our parser does not capture as many non-projective
arcs as the pseudo-projective transformation (unsur-
prisingly, as it can only build non-projective arcs in
one direction: that of the particular non-projective
buffer transition used for each dataset); it does so
with greater precision and is more accurate than that
algorithm in projective arcs.
Like projective buffer transitions, non-projective
transitions do not increase the computational com-
plexity of stack-based parsers. The observed train-
ing and parsing times for the arc-eager parser with
non-projective buffer transitions showed a small
overhead with respect to the original arc-eager
(7.1% average increase in training time, 17.0% in
parsing time). For comparison, running the arc-
eager parser with the pseudo-projective transforma-
tion (Nivre et al., 2006) on the same machine pro-
duced a 23.5% increase in training time and a 87.5%
increase in parsing time.
</bodyText>
<sectionHeader confidence="0.999844" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999983">
The approach of adding an extra transition to a
parser to improve its accuracy has been applied in
the past by Choi and Palmer (2011). In that pa-
per, the LEFT-ARC transition from Nivre’s arc-eager
transition system is added to a list-based parser.
However, the goal of that transition is different
from ours (selecting between projective and non-
projective parsing, rather than building some arcs in
advance) and the approach is specific to one algo-
rithm while ours is generic – for example, the LEFT-
ARC transition cannot be added to the arc-standard
and arc-eager parsers, or to extensions of those like
the ones by Attardi (2006) or Nivre (2009), because
these already have it.
The idea of creating dependency arcs of length 1
in advance to help the classifier has been used by
Cheng et al. (2006). However, their system creates
such arcs in a separate preprocessing step rather than
dynamically by adding a transition to the parser, and
our approach obtains better LAS and UAS results on
all the tested datasets.
The projective buffer transitions presented here
bear some resemblance to the easy-first parser by
Goldberg and Elhadad (2010), which allows cre-
ation of dependency arcs between any pair of con-
tiguous nodes and is based on the idea of “easy” de-
pendency links being created first. However, while
the easy-first parser is an entirely new O(n log(n))
algorithm, our approach is a generic extension for
stack-based parsers that does not increase their com-
plexity (so, for example, applying it to the arc-eager
system as in the experiments in this paper yields
O(n) complexity).
Non-projective transitions that create dependency
arcs between non-contiguous nodes have been used
in the transition-based parser by Attardi (2006).
However, the transitions in that parser do not use
the second buffer node, since they are not intended
</bodyText>
<page confidence="0.997392">
316
</page>
<bodyText confidence="0.998897666666667">
to create some arcs in advance. The non-projective
buffer transitions presented in this paper can also be
added to Attardi’s parser.
</bodyText>
<sectionHeader confidence="0.999718" genericHeader="conclusions">
6 Discussion
</sectionHeader>
<bodyText confidence="0.9999967">
We have presented a set of two transitions, called
projective buffer transitions, and showed that adding
one of them to Nivre’s arc-eager parser improves its
accuracy in seven out of eight tested datasets from
the CoNLL-X shared task. Furthermore, adding one
of a set of non-projective buffer transitions achieves
accuracy improvements in all of the eight datasets.
The obtained improvements are statistically signif-
icant for several of the treebanks, and the parser
with projective buffer transitions surpassed the best
published single-parser LAS results on two of them.
This comes at no cost either on computational com-
plexity or (in the case of projective transitions) on
empirical training and parsing times with respect to
the original parser.
While we have chosen Nivre’s well-known arc-
eager parser as our baseline, we have shown that
these transitions can be added to any stack-based de-
pendency parser, and we are not aware of any spe-
cific property of arc-eager that would make them
work better in practice on this parser than on others.
Therefore, future work will include an evaluation of
the impact of buffer transitions on more transition-
based parsers. Other research directions involve in-
vestigating the set of non-projective arcs allowed
by non-projective buffer transitions, defining dif-
ferent variants of buffer transitions (such as non-
projective buffer transitions that work with nodes lo-
cated deeper in the buffer) or using projective and
non-projective buffer transitions at the same time.
</bodyText>
<sectionHeader confidence="0.998142" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.976853">
This research has been partially funded by the
Spanish Ministry of Economy and Competitive-
ness and FEDER (projects TIN2010-18552-C03-01
and TIN2010-18552-C03-02), Ministry of Educa-
tion (FPU Grant Program) and Xunta de Galicia
(Rede Galega de Recursos Ling¨uisticos para unha
Sociedade do Co˜necemento).
</bodyText>
<sectionHeader confidence="0.992345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998461115384615">
Susana Afonso, Eckhard Bick, Renato Haber, and Diana
Santos. 2002. “Floresta sint´a(c)tica”: a treebank for
Portuguese. In Proceedings of the 3rd International
Conference on Language Resources and Evaluation
(LREC 2002), pages 1968–1703, Paris, France. ELRA.
Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2003. The
annotation process in the Turkish treebank. In Pro-
ceedings of EACL Workshop on Linguistically Inter-
preted Corpora (LINC-03), pages 243–246, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Giuseppe Attardi. 2006. Experiments with a multilan-
guage non-projective dependency parser. In Proceed-
ings of the 10th Conference on Computational Natural
Language Learning (CoNLL), pages 166–170.
Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang
Lezius, and George Smith. 2002. The tiger treebank.
In Proceedings of the Workshop on Treebanks and Lin-
guistic Theories, September 20-21, Sozopol, Bulgaria.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
shared task on multilingual dependency parsing. In
Proceedings of the 10th Conference on Computational
Natural Language Learning (CoNLL), pages 149–164.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: A
Library for Support Vector Machines. Software avail-
able at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.
K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,
and Z. Gao. 2003. Sinica treebank: Design criteria,
representational issues and implementation. In Anne
Abeill´e, editor, Treebanks: Building and Using Parsed
Corpora, chapter 13, pages 231–248. Kluwer.
Yuchang Cheng, Masayuki Asahara, and Yuji Mat-
sumoto. 2006. Multi-lingual dependency parsing at
NAIST. In Proceedings of the Tenth Conference on
Computational Natural Language Learning, CoNLL-
X ’06, pages 191–195, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Jinho D. Choi and Martha Palmer. 2011. Getting the
most out of transition-based dependency parsing. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers - Volume 2, HLT
’11, pages 687–692, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Jason M. Eisner. 1996. Three new probabilistic models
for dependency parsing: An exploration. In Proceed-
ings of the 16th International Conference on Compu-
tational Linguistics (COLING), pages 340–345.
R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and
C.-J. Lin. 2008. LIBLINEAR: A library for large lin-
ear classification. Journal of Machine Learning Re-
search, 9:1871–1874.
</reference>
<page confidence="0.983173">
317
</page>
<reference confidence="0.99976687735849">
Yoav Goldberg and Michael Elhadad. 2010. An effi-
cient algorithm for easy-first non-directional depen-
dency parsing. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Linguis-
tics (NAACL HLT), pages 742–750.
Carlos G´omez-Rodr´ıguez and Joakim Nivre. 2010. A
transition-based parser for 2-planar dependency struc-
tures. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, ACL
’10, pages 1492–1501, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf, and
Emanuel Beˇska. 2004. Prague Arabic Dependency
Treebank: Development in data and tools. In Proceed-
ings of the NEMLAR International Conference on Ara-
bic Language Resources and Tools.
Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila
Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı
Havelka, and Marie Mikulov´a. 2006. Prague Depen-
dency Treebank 2.0. CDROM CAT: LDC2006T01,
ISBN 1-58563-370-4. Linguistic Data Consortium.
Liang Huang and Kenji Sagae. 2010. Dynamic program-
ming for linear-time incremental parsing. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, ACL ’10, pages 1077–
1086, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Matthias T. Kromann. 2003. The Danish dependency
treebank and the underlying linguistic theory. In Pro-
ceedings of the 2nd Workshop on Treebanks and Lin-
guistic Theories (TLT), pages 217–220, V¨axj¨o, Swe-
den. V¨axj¨o University Press.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP (ACL-IJCNLP), pages 342–
350.
Ryan McDonald and Joakim Nivre. 2007. Charac-
terizing the errors of data-driven dependency parsing
models. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL), pages 122–131.
Ryan McDonald and Joakim Nivre. 2011. Analyzing
and integrating dependency parsers. Comput. Lin-
guist., 37:197–230.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajiˇc. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings
of the Human Language Technology Conference and
the Conference on Empirical Methods in Natural Lan-
guage Processing (HLT/EMNLP), pages 523–530.
Ryan McDonald, Kevin Lerman, and Fernando Pereira.
2006. Multilingual dependency analysis with a two-
stage discriminative parser. In Proceedings of the
10th Conference on Computational Natural Language
Learning (CoNLL), pages 216–220.
Jens Nilsson, Johan Hall, and Joakim Nivre. 2005.
MAMBA meets TIGER: Reconstructing a Swedish
treebank from Antiquity. In Peter Juel Henrichsen, ed-
itor, Proceedings of the NODALIDA Special Session
on Treebanks.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2004.
Memory-based dependency parsing. In Proceedings
of the 8th Conference on Computational Natural Lan-
guage Learning (CoNLL-2004), pages 49–56, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Joakim Nivre, Johan Hall, Jens Nilsson, G¨ulsen Eryi˘git,
and Svetoslav Marinov. 2006. Labeled pseudo-
projective dependency parsing with support vector ma-
chines. In Proceedings of the 10th Conference on
Computational Natural Language Learning (CoNLL),
pages 221–225.
Joakim Nivre. 2003. An efficient algorithm for projec-
tive dependency parsing. In Proceedings of the 8th In-
ternational Workshop on Parsing Technologies (IWPT
03), pages 149–160. ACL/SIGPARSE.
Joakim Nivre. 2008. Algorithms for Deterministic Incre-
mental Dependency Parsing. Computational Linguis-
tics, 34(4):513–553.
Joakim Nivre. 2009. Non-projective dependency parsing
in expected linear time. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP (ACL-IJCNLP), pages
351–359.
Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur,
and G¨okhan T¨ur. 2003. Building a Turkish treebank.
In Anne Abeill´e, editor, Treebanks: Building and Us-
ing Parsed Corpora, pages 261–277. Kluwer.
Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce de-
pendency DAG parsing. In Proceedings of the 22nd
International Conference on Computational Linguis-
tics (COLING), pages 753–760.
Stephen Tratz and Eduard Hovy. 2011. A fast, accurate,
non-projective, semantically-enriched parser. In Pro-
ceedings of the 2011 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1257–
1268, Edinburgh, Scotland, UK., July. Association for
Computational Linguistics.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statisti-
cal dependency analysis with support vector machines.
</reference>
<page confidence="0.986412">
318
</page>
<reference confidence="0.997774071428571">
In Proceedings of the 8th International Workshop on
Parsing Technologies (IWPT), pages 195–206.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 562–571.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers - Volume 2, HLT
’11, pages 188–193, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
</reference>
<page confidence="0.999357">
319
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.218563">
<title confidence="0.99995">Improving Transition-Based Dependency Parsing with Buffer Transitions</title>
<author confidence="0.994434">Daniel</author>
<affiliation confidence="0.916672666666667">Departamento de Universidade de Campus As Lagoas,</affiliation>
<address confidence="0.97632">Ourense,</address>
<email confidence="0.968398">danifg@uvigo.es</email>
<abstract confidence="0.957772892857143">Carlos Departamento de da de carlos.gomez@udc.es Abstract In this paper, we show that significant improvements in the accuracy of well-known transition-based parsers can be obtained, without sacrificing efficiency, by enriching the parsers with simple transitions that act on buffer nodes. First, we show how adding a specific transition to create either a left or right arc of length one between the first two buffer nodes produces improvements in the accuracy of Nivre’s arc-eager projective parser on a number of datasets from the CoNLL-X shared task. Then, we show that accuracy can also be improved by adding transitions involving the topmost stack node and the second buffer node (allowing a limited form of non-projectivity). None of these transitions has a negative impact on the computational complexity of the algorithm. Although the experiments in this paper use the arc-eager parser, the approach is generic enough to be applicable to any stackbased dependency parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Susana Afonso</author>
<author>Eckhard Bick</author>
<author>Renato Haber</author>
<author>Diana Santos</author>
</authors>
<title>Floresta sint´a(c)tica”: a treebank for Portuguese.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1968--1703</pages>
<location>Paris, France. ELRA.</location>
<contexts>
<context position="15287" citStr="Afonso et al., 2002" startWordPosition="2603" endWordPosition="2606">ed parser: for a given transition, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LI</context>
</contexts>
<marker>Afonso, Bick, Haber, Santos, 2002</marker>
<rawString>Susana Afonso, Eckhard Bick, Renato Haber, and Diana Santos. 2002. “Floresta sint´a(c)tica”: a treebank for Portuguese. In Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC 2002), pages 1968–1703, Paris, France. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nart B Atalay</author>
<author>Kemal Oflazer</author>
<author>Bilge Say</author>
</authors>
<title>The annotation process in the Turkish treebank.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL Workshop on Linguistically Interpreted Corpora (LINC-03),</booktitle>
<pages>243--246</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="15375" citStr="Atalay et al., 2003" startWordPosition="2619" endWordPosition="2622">andard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LIBLINEAR package (Fan et al., 2008) for classification, since it reduces training time in</context>
</contexts>
<marker>Atalay, Oflazer, Say, 2003</marker>
<rawString>Nart B. Atalay, Kemal Oflazer, and Bilge Say. 2003. The annotation process in the Turkish treebank. In Proceedings of EACL Workshop on Linguistically Interpreted Corpora (LINC-03), pages 243–246, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Attardi</author>
</authors>
<title>Experiments with a multilanguage non-projective dependency parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>166--170</pages>
<contexts>
<context position="2835" citStr="Attardi, 2006" startWordPosition="425" endWordPosition="426">2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; Nivre, 2009; Huang and Sagae, 2010; G´omezRodr´ıguez and Nivre, 2010) are stack-based (Nivre, 2008), meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens. In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions. These are transitions that create a dependency arc involving some node in the buffer, which would typically be considered unavailable for linking by these algo308 Proceedings of the 2012 </context>
<context position="35586" citStr="Attardi (2006)" startWordPosition="5862" endWordPosition="5863">adding an extra transition to a parser to improve its accuracy has been applied in the past by Choi and Palmer (2011). In that paper, the LEFT-ARC transition from Nivre’s arc-eager transition system is added to a list-based parser. However, the goal of that transition is different from ours (selecting between projective and nonprojective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic – for example, the LEFTARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. The idea of creating dependency arcs of length 1 in advance to help the classifier has been used by Cheng et al. (2006). However, their system creates such arcs in a separate preprocessing step rather than dynamically by adding a transition to the parser, and our approach obtains better LAS and UAS results on all the tested datasets. The projective buffer transitions presented here bear some resemblance to the easy-first parser by Goldberg and Elhadad (2010), which allows creation of dependency arcs between any pair of contiguous nodes and is ba</context>
</contexts>
<marker>Attardi, 2006</marker>
<rawString>Giuseppe Attardi. 2006. Experiments with a multilanguage non-projective dependency parser. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 166–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Silvia Hansen</author>
<author>Wolfgang Lezius</author>
<author>George Smith</author>
</authors>
<title>The tiger treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Treebanks and Linguistic Theories,</booktitle>
<location>Sozopol, Bulgaria.</location>
<contexts>
<context position="15253" citStr="Brants et al., 2002" startWordPosition="2598" endWordPosition="2601"> can be plugged into any stack-based parser: for a given transition, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech an</context>
</contexts>
<marker>Brants, Dipper, Hansen, Lezius, Smith, 2002</marker>
<rawString>Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolfgang Lezius, and George Smith. 2002. The tiger treebank. In Proceedings of the Workshop on Treebanks and Linguistic Theories, September 20-21, Sozopol, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>149--164</pages>
<contexts>
<context position="4092" citStr="Buchholz and Marsi, 2006" startWordPosition="621" endWordPosition="625">thods in Natural Language Processing and Computational Natural Language Learning, pages 308–319, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics rithms. The rationale is that buffer transitions construct some “easy” dependency arcs in advance, before the involved nodes reach the stack, so that the classifier’s job when choosing among standard transitions is simplified. To test the approach, we use the well-known arceager parser by (Nivre, 2003; Nivre et al., 2004) as a baseline, showing improvements in accuracy on most datasets of the CoNLL-X shared task (Buchholz and Marsi, 2006). However, the techniques discussed in this paper are generic and can also be applied to other stack-based dependency parsers. The rest of this paper is structured as follows: Section 2 is an introduction to transition-based parsers and the arc-eager parsing algorithm. Section 3 presents the first novel contribution of this paper, projective buffer transitions, and discusses their empirical results on CoNLL-X datasets. Section 4 does the same for a more complex set of transitions, non-projective buffer transitions. Finally, Section 5 discusses related work and Section 6 sums up the conclusions</context>
<context position="15111" citStr="Buchholz and Marsi, 2006" startWordPosition="2575" endWordPosition="2578">s whenever possible, regardless of arc length”: as expected, the obtained accuracies were (slightly) worse. The chosen oracle policy is generic and can be plugged into any stack-based parser: for a given transition, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelle</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</title>
<date>2001</date>
<contexts>
<context position="15806" citStr="Chang and Lin, 2001" startWordPosition="2687" endWordPosition="2690">et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LIBLINEAR package (Fan et al., 2008) for classification, since it reduces training time in these larger datasets. Feature models for all parsers were specifically tuned for each language.3 2In this context, “possible” means that we can create the arc without losing the possibility of creating other gold-standard arcs. In the case of RIGHT-BUFFER-ARC, this involves checking that the candidate dependent node has no dependents in the gold-standard tree (if it has any, we cannot remove it from the stack or it would not </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: A Library for Support Vector Machines. Software available at http://www.csie.ntu.edu.tw/∼cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Chen</author>
<author>C Luo</author>
<author>M Chang</author>
<author>F Chen</author>
<author>C Chen</author>
<author>C Huang</author>
<author>Z Gao</author>
</authors>
<title>Sinica treebank: Design criteria, representational issues and implementation.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora, chapter 13,</booktitle>
<pages>231--248</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="15170" citStr="Chen et al., 2003" startWordPosition="2585" endWordPosition="2588">btained accuracies were (slightly) worse. The chosen oracle policy is generic and can be plugged into any stack-based parser: for a given transition, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the </context>
</contexts>
<marker>Chen, Luo, Chang, Chen, Chen, Huang, Gao, 2003</marker>
<rawString>K. Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang, and Z. Gao. 2003. Sinica treebank: Design criteria, representational issues and implementation. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 13, pages 231–248. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuchang Cheng</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Multi-lingual dependency parsing at NAIST.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLLX ’06,</booktitle>
<pages>191--195</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35754" citStr="Cheng et al. (2006)" startWordPosition="5891" endWordPosition="5894">Nivre’s arc-eager transition system is added to a list-based parser. However, the goal of that transition is different from ours (selecting between projective and nonprojective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic – for example, the LEFTARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. The idea of creating dependency arcs of length 1 in advance to help the classifier has been used by Cheng et al. (2006). However, their system creates such arcs in a separate preprocessing step rather than dynamically by adding a transition to the parser, and our approach obtains better LAS and UAS results on all the tested datasets. The projective buffer transitions presented here bear some resemblance to the easy-first parser by Goldberg and Elhadad (2010), which allows creation of dependency arcs between any pair of contiguous nodes and is based on the idea of “easy” dependency links being created first. However, while the easy-first parser is an entirely new O(n log(n)) algorithm, our approach is a generic</context>
</contexts>
<marker>Cheng, Asahara, Matsumoto, 2006</marker>
<rawString>Yuchang Cheng, Masayuki Asahara, and Yuji Matsumoto. 2006. Multi-lingual dependency parsing at NAIST. In Proceedings of the Tenth Conference on Computational Natural Language Learning, CoNLLX ’06, pages 191–195, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinho D Choi</author>
<author>Martha Palmer</author>
</authors>
<title>Getting the most out of transition-based dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>687--692</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="35089" citStr="Choi and Palmer (2011)" startWordPosition="5778" endWordPosition="5781">omplexity of stack-based parsers. The observed training and parsing times for the arc-eager parser with non-projective buffer transitions showed a small overhead with respect to the original arc-eager (7.1% average increase in training time, 17.0% in parsing time). For comparison, running the arceager parser with the pseudo-projective transformation (Nivre et al., 2006) on the same machine produced a 23.5% increase in training time and a 87.5% increase in parsing time. 5 Related work The approach of adding an extra transition to a parser to improve its accuracy has been applied in the past by Choi and Palmer (2011). In that paper, the LEFT-ARC transition from Nivre’s arc-eager transition system is added to a list-based parser. However, the goal of that transition is different from ours (selecting between projective and nonprojective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic – for example, the LEFTARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. The idea of creating dependency arcs of length 1 in ad</context>
</contexts>
<marker>Choi, Palmer, 2011</marker>
<rawString>Jinho D. Choi and Martha Palmer. 2011. Getting the most out of transition-based dependency parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 687–692, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason M Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>340--345</pages>
<contexts>
<context position="2262" citStr="Eisner, 1996" startWordPosition="333" endWordPosition="335">mplement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; N</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason M. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of the 16th International Conference on Computational Linguistics (COLING), pages 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R-E Fan</author>
<author>K-W Chang</author>
<author>C-J Hsieh</author>
<author>X-R Wang</author>
<author>C-J Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="15921" citStr="Fan et al., 2008" startWordPosition="2708" endWordPosition="2711">n et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LIBLINEAR package (Fan et al., 2008) for classification, since it reduces training time in these larger datasets. Feature models for all parsers were specifically tuned for each language.3 2In this context, “possible” means that we can create the arc without losing the possibility of creating other gold-standard arcs. In the case of RIGHT-BUFFER-ARC, this involves checking that the candidate dependent node has no dependents in the gold-standard tree (if it has any, we cannot remove it from the stack or it would not be able to collect its dependents, so we do not use the buffer transition). 3All the experimental settings and feat</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>R.-E. Fan, K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Michael Elhadad</author>
</authors>
<title>An efficient algorithm for easy-first non-directional dependency parsing.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT),</booktitle>
<pages>742--750</pages>
<contexts>
<context position="36097" citStr="Goldberg and Elhadad (2010)" startWordPosition="5944" endWordPosition="5947">cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. The idea of creating dependency arcs of length 1 in advance to help the classifier has been used by Cheng et al. (2006). However, their system creates such arcs in a separate preprocessing step rather than dynamically by adding a transition to the parser, and our approach obtains better LAS and UAS results on all the tested datasets. The projective buffer transitions presented here bear some resemblance to the easy-first parser by Goldberg and Elhadad (2010), which allows creation of dependency arcs between any pair of contiguous nodes and is based on the idea of “easy” dependency links being created first. However, while the easy-first parser is an entirely new O(n log(n)) algorithm, our approach is a generic extension for stack-based parsers that does not increase their complexity (so, for example, applying it to the arc-eager system as in the experiments in this paper yields O(n) complexity). Non-projective transitions that create dependency arcs between non-contiguous nodes have been used in the transition-based parser by Attardi (2006). Howe</context>
</contexts>
<marker>Goldberg, Elhadad, 2010</marker>
<rawString>Yoav Goldberg and Michael Elhadad. 2010. An efficient algorithm for easy-first non-directional dependency parsing. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT), pages 742–750.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Joakim Nivre</author>
</authors>
<title>A transition-based parser for 2-planar dependency structures.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1492--1501</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>G´omez-Rodr´ıguez, Nivre, 2010</marker>
<rawString>Carlos G´omez-Rodr´ıguez and Joakim Nivre. 2010. A transition-based parser for 2-planar dependency structures. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1492–1501, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Otakar Smrˇz</author>
<author>Petr Zem´anek</author>
<author>Jan ˇSnaidauf</author>
<author>Emanuel Beˇska</author>
</authors>
<title>Prague Arabic Dependency Treebank: Development in data and tools.</title>
<date>2004</date>
<booktitle>In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools.</booktitle>
<marker>Hajiˇc, Smrˇz, Zem´anek, ˇSnaidauf, Beˇska, 2004</marker>
<rawString>Jan Hajiˇc, Otakar Smrˇz, Petr Zem´anek, Jan ˇSnaidauf, and Emanuel Beˇska. 2004. Prague Arabic Dependency Treebank: Development in data and tools. In Proceedings of the NEMLAR International Conference on Arabic Language Resources and Tools.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jarmila Panevov´a</author>
<author>Eva Hajiˇcov´a</author>
<author>Jarmila Panevov´a</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan ˇStˇep´anek</author>
<author>Jiˇr´ı Havelka</author>
<author>Marie Mikulov´a</author>
</authors>
<date>2006</date>
<booktitle>Prague Dependency Treebank 2.0. CDROM CAT: LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium.</booktitle>
<marker>Hajiˇc, Panevov´a, Hajiˇcov´a, Panevov´a, Sgall, Pajas, ˇStˇep´anek, Havelka, Mikulov´a, 2006</marker>
<rawString>Jan Hajiˇc, Jarmila Panevov´a, Eva Hajiˇcov´a, Jarmila Panevov´a, Petr Sgall, Petr Pajas, Jan ˇStˇep´anek, Jiˇr´ı Havelka, and Marie Mikulov´a. 2006. Prague Dependency Treebank 2.0. CDROM CAT: LDC2006T01, ISBN 1-58563-370-4. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>1077--1086</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1938" citStr="Huang and Sagae (2010)" startWordPosition="285" endWordPosition="288">me a very active research area in natural language processing in recent years. The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that </context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 1077– 1086, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias T Kromann</author>
</authors>
<title>The Danish dependency treebank and the underlying linguistic theory.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories (TLT),</booktitle>
<pages>217--220</pages>
<publisher>V¨axj¨o University Press.</publisher>
<location>V¨axj¨o,</location>
<contexts>
<context position="15223" citStr="Kromann, 2003" startWordPosition="2595" endWordPosition="2596">le policy is generic and can be plugged into any stack-based parser: for a given transition, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all language</context>
</contexts>
<marker>Kromann, 2003</marker>
<rawString>Matthias T. Kromann. 2003. The Danish dependency treebank and the underlying linguistic theory. In Proceedings of the 2nd Workshop on Treebanks and Linguistic Theories (TLT), pages 217–220, V¨axj¨o, Sweden. V¨axj¨o University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP),</booktitle>
<pages>342--350</pages>
<contexts>
<context position="1914" citStr="Martins et al. (2009)" startWordPosition="281" endWordPosition="284">ndency parsing has become a very active research area in natural language processing in recent years. The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to mak</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP), pages 342– 350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>122--131</pages>
<contexts>
<context position="12639" citStr="McDonald and Nivre, 2007" startWordPosition="2158" endWordPosition="2161">tions can only create projective arcs and cannot violate the single-head or acyclicity constraints, given that a buffer node cannot have a head. The idea behind projective buffer transitions is to create dependency arcs of length one (i.e., arcs involving contiguous nodes) in advance of the standard arc-building transitions that need at least one of the nodes to get to the stack (LEFT-ARC and RIGHTARC in the case of the arc-eager transition system). Our hypothesis is that, as it is known that short-distance dependencies are easier to learn for transition-based parsers than long-distance ones (McDonald and Nivre, 2007), handling these short arcs in advance and removing their dependent nodes will make it easier for the classifier to learn how to make decisions involving the standard arc transitions. Note that the fact that projective buffer transitions create arcs of length 1 is not explicit in the definition of the transitions. For instance, if we add the LEFT-BUFFER-ARCI transition only to the arc-eager transition system, LEFT-BUFFER-ARCI will only be able to create arcs of length 1, since it is easy to see that the first two buffer nodes are contiguous in all the accessible configurations. However, if we </context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 122–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Analyzing and integrating dependency parsers.</title>
<date>2011</date>
<journal>Comput. Linguist.,</journal>
<pages>37--197</pages>
<contexts>
<context position="2227" citStr="McDonald and Nivre, 2011" startWordPosition="326" endWordPosition="330">tions directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attar</context>
</contexts>
<marker>McDonald, Nivre, 2011</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2011. Analyzing and integrating dependency parsers. Comput. Linguist., 37:197–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>523--530</pages>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajiˇc. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Kevin Lerman</author>
<author>Fernando Pereira</author>
</authors>
<title>Multilingual dependency analysis with a twostage discriminative parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>216--220</pages>
<contexts>
<context position="24720" citStr="McDonald et al. (2006)" startWordPosition="4129" endWordPosition="4132">aset with the results obtained by the parser with the pseudo-projective transformation by Nivre et al. (2006) in the CoNLL-X shared task, one of the top two performing systems in that event. The reader should be aware that the purpose of this table is only to provide a broad idea of how our approach performs with respect to a well-known reference point, and not to make a detailed comparison, since the two parsers have not been tuned in homogeneous conditions: on the one hand, we had access to the CoNLL-X test sets which were unavailable 313 System Arabic Danish Nivre et al. (2006) 66.71 84.77 McDonald et al. (2006) 66.91 84.79 Nivre (2009) 67.3 84.7 G´omez-Rodriguez and Nivre (2010) N/A 83.81 NE+LBA/RBA 67.78 85.21 Table 5: Comparison of the Arabic and Danish LAS obtained by the arc-eager parser with projective buffer transitions in comparison to other parsers in the literature that report results on these datasets. for the participants in the shared task; on the other hand, we did not fine-tune the classifier parameters for each dataset like Nivre et al. (2006), but used default values for all languages. As can be seen in the table, even though the pseudo-projective parser is able to capture nonproject</context>
</contexts>
<marker>McDonald, Lerman, Pereira, 2006</marker>
<rawString>Ryan McDonald, Kevin Lerman, and Fernando Pereira. 2006. Multilingual dependency analysis with a twostage discriminative parser. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 216–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jens Nilsson</author>
<author>Johan Hall</author>
<author>Joakim Nivre</author>
</authors>
<title>MAMBA meets TIGER: Reconstructing a Swedish treebank from Antiquity.</title>
<date>2005</date>
<booktitle>Proceedings of the NODALIDA Special Session on Treebanks.</booktitle>
<editor>In Peter Juel Henrichsen, editor,</editor>
<contexts>
<context position="15319" citStr="Nilsson et al., 2005" startWordPosition="2608" endWordPosition="2611">on, first check whether it is possible to build a gold-standard arc of length 1 with a projective buffer transition.2 If so, choose that transition, and if not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LIBLINEAR package (Fan et al., 200</context>
</contexts>
<marker>Nilsson, Hall, Nivre, 2005</marker>
<rawString>Jens Nilsson, Johan Hall, and Joakim Nivre. 2005. MAMBA meets TIGER: Reconstructing a Swedish treebank from Antiquity. In Peter Juel Henrichsen, editor, Proceedings of the NODALIDA Special Session on Treebanks.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Memory-based dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL-2004),</booktitle>
<pages>49--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1867" citStr="Nivre et al. (2004)" startWordPosition="273" endWordPosition="276">kbased dependency parser. 1 Introduction Dependency parsing has become a very active research area in natural language processing in recent years. The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are th</context>
<context position="3973" citStr="Nivre et al., 2004" startWordPosition="602" endWordPosition="605">y be considered unavailable for linking by these algo308 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 308–319, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics rithms. The rationale is that buffer transitions construct some “easy” dependency arcs in advance, before the involved nodes reach the stack, so that the classifier’s job when choosing among standard transitions is simplified. To test the approach, we use the well-known arceager parser by (Nivre, 2003; Nivre et al., 2004) as a baseline, showing improvements in accuracy on most datasets of the CoNLL-X shared task (Buchholz and Marsi, 2006). However, the techniques discussed in this paper are generic and can also be applied to other stack-based dependency parsers. The rest of this paper is structured as follows: Section 2 is an introduction to transition-based parsers and the arc-eager parsing algorithm. Section 3 presents the first novel contribution of this paper, projective buffer transitions, and discusses their empirical results on CoNLL-X datasets. Section 4 does the same for a more complex set of transiti</context>
<context position="8142" citStr="Nivre et al., 2004" startWordPosition="1381" endWordPosition="1384"> Transition systems are nondeterministic devices, since several transitions may be applicable to the same configuration. To obtain a deterministic parser 309 from a transition system, a classifier is trained to greedily select the best transition at each state. This training is typically done by using an oracle, which is a function o : C → T that selects a single transition at each configuration, given a tree in the training set. The classifier is then trained to approximate this oracle when the target tree is unknown. 2.3 The arc-eager parser Nivre’s arc-eager dependency parser (Nivre, 2003; Nivre et al., 2004) is one of the most widely known and used transition-based parsers (see for example (Zhang and Clark, 2008; Zhang and Nivre, 2011)). This parser works by reading the input sentence from left to right and creating dependency links as soon as possible. This means that links are created in a strict left-to-right order, and implies that while leftward links are built in a bottom-up fashion, a rightward link a → b will be created before the node b has collected its right dependents. The arc-eager transition system has the following four transitions (note that, for convenience, we write a stack with</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2004</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2004. Memory-based dependency parsing. In Proceedings of the 8th Conference on Computational Natural Language Learning (CoNLL-2004), pages 49–56, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
<author>G¨ulsen Eryi˘git</author>
<author>Svetoslav Marinov</author>
</authors>
<title>Labeled pseudoprojective dependency parsing with support vector machines.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>221--225</pages>
<marker>Nivre, Hall, Nilsson, Eryi˘git, Marinov, 2006</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, G¨ulsen Eryi˘git, and Svetoslav Marinov. 2006. Labeled pseudoprojective dependency parsing with support vector machines. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL), pages 221–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03),</booktitle>
<pages>149--160</pages>
<publisher>ACL/SIGPARSE.</publisher>
<contexts>
<context position="3952" citStr="Nivre, 2003" startWordPosition="600" endWordPosition="601">ould typically be considered unavailable for linking by these algo308 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 308–319, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics rithms. The rationale is that buffer transitions construct some “easy” dependency arcs in advance, before the involved nodes reach the stack, so that the classifier’s job when choosing among standard transitions is simplified. To test the approach, we use the well-known arceager parser by (Nivre, 2003; Nivre et al., 2004) as a baseline, showing improvements in accuracy on most datasets of the CoNLL-X shared task (Buchholz and Marsi, 2006). However, the techniques discussed in this paper are generic and can also be applied to other stack-based dependency parsers. The rest of this paper is structured as follows: Section 2 is an introduction to transition-based parsers and the arc-eager parsing algorithm. Section 3 presents the first novel contribution of this paper, projective buffer transitions, and discusses their empirical results on CoNLL-X datasets. Section 4 does the same for a more co</context>
<context position="8121" citStr="Nivre, 2003" startWordPosition="1379" endWordPosition="1380">, [], A) E C. Transition systems are nondeterministic devices, since several transitions may be applicable to the same configuration. To obtain a deterministic parser 309 from a transition system, a classifier is trained to greedily select the best transition at each state. This training is typically done by using an oracle, which is a function o : C → T that selects a single transition at each configuration, given a tree in the training set. The classifier is then trained to approximate this oracle when the target tree is unknown. 2.3 The arc-eager parser Nivre’s arc-eager dependency parser (Nivre, 2003; Nivre et al., 2004) is one of the most widely known and used transition-based parsers (see for example (Zhang and Clark, 2008; Zhang and Nivre, 2011)). This parser works by reading the input sentence from left to right and creating dependency links as soon as possible. This means that links are created in a strict left-to-right order, and implies that while leftward links are built in a bottom-up fashion, a rightward link a → b will be created before the node b has collected its right dependents. The arc-eager transition system has the following four transitions (note that, for convenience, </context>
<context position="15466" citStr="Nivre (2003)" startWordPosition="2636" endWordPosition="2637">not, just delegate to the original parser’s oracle. 3.2 Experiments To empirically evaluate the effect of projective buffer transitions on parsing accuracy, we have conducted experiments on eight datasets of the CoNLLX shared task (Buchholz and Marsi, 2006): Arabic (Hajiˇc et al., 2004), Chinese (Chen et al., 2003), Czech (Hajiˇc et al., 2006), Danish (Kromann, 2003), German (Brants et al., 2002), Portuguese (Afonso et al., 2002), Swedish (Nilsson et al., 2005) and Turkish (Oflazer et al., 2003; Atalay et al., 2003). As our baseline parser, we use the arc-eager projective transition system by Nivre (2003). Table 1 compares the accuracy obtained by this system alone with that obtained when the LEFT-BUFFER-ARC and RIGHT-BUFFER-ARC transitions are added to it as explained in Section 3.1. Accuracy is reported in terms of labelled (LAS) and unlabelled (UAS) attachment score. We used SVM classifiers from the LIBSVM package (Chang and Lin, 2001) for all languages except for Chinese, Czech and German. In these, we used the LIBLINEAR package (Fan et al., 2008) for classification, since it reduces training time in these larger datasets. Feature models for all parsers were specifically tuned for each lan</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03), pages 149–160. ACL/SIGPARSE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for Deterministic Incremental Dependency Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="2960" citStr="Nivre, 2008" startWordPosition="444" endWordPosition="445">ng subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; Nivre, 2009; Huang and Sagae, 2010; G´omezRodr´ıguez and Nivre, 2010) are stack-based (Nivre, 2008), meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens. In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions. These are transitions that create a dependency arc involving some node in the buffer, which would typically be considered unavailable for linking by these algo308 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 308–3</context>
<context position="4893" citStr="Nivre, 2008" startWordPosition="747" endWordPosition="748">an introduction to transition-based parsers and the arc-eager parsing algorithm. Section 3 presents the first novel contribution of this paper, projective buffer transitions, and discusses their empirical results on CoNLL-X datasets. Section 4 does the same for a more complex set of transitions, non-projective buffer transitions. Finally, Section 5 discusses related work and Section 6 sums up the conclusions and points out avenues for future work. 2 Preliminaries We now briefly present some basic definitions for transition-based dependency parsing; a more thorough explanation can be found in (Nivre, 2008). 2.1 Dependency graphs Let w = wi ... w,,, be an input string. A dependency graph for w is a directed graph G = (U„, A); where U„ = {0, 1, ... , n} is a set of nodes, and A C_ U„ x L x U„ is a set of labelled arcs. Each node in U„ encodes the position of a token in w, where 0 is a dummy node used as artificial root. An arc (i, l, j) will also be called a dependency link labelled l from i to j. We say that i is the syntactic head of j and, conversely, that j is a dependent of i. The length of the arc (i, l, j) is the value |j − i|. Most dependency representations of syntax do not allow arbitra</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for Deterministic Incremental Dependency Parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Non-projective dependency parsing in expected linear time.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP),</booktitle>
<pages>351--359</pages>
<contexts>
<context position="2872" citStr="Nivre, 2009" startWordPosition="431" endWordPosition="432">6; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; Nivre, 2009; Huang and Sagae, 2010; G´omezRodr´ıguez and Nivre, 2010) are stack-based (Nivre, 2008), meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens. In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions. These are transitions that create a dependency arc involving some node in the buffer, which would typically be considered unavailable for linking by these algo308 Proceedings of the 2012 Joint Conference on Empirical Methods</context>
<context position="24745" citStr="Nivre (2009)" startWordPosition="4135" endWordPosition="4136">he parser with the pseudo-projective transformation by Nivre et al. (2006) in the CoNLL-X shared task, one of the top two performing systems in that event. The reader should be aware that the purpose of this table is only to provide a broad idea of how our approach performs with respect to a well-known reference point, and not to make a detailed comparison, since the two parsers have not been tuned in homogeneous conditions: on the one hand, we had access to the CoNLL-X test sets which were unavailable 313 System Arabic Danish Nivre et al. (2006) 66.71 84.77 McDonald et al. (2006) 66.91 84.79 Nivre (2009) 67.3 84.7 G´omez-Rodriguez and Nivre (2010) N/A 83.81 NE+LBA/RBA 67.78 85.21 Table 5: Comparison of the Arabic and Danish LAS obtained by the arc-eager parser with projective buffer transitions in comparison to other parsers in the literature that report results on these datasets. for the participants in the shared task; on the other hand, we did not fine-tune the classifier parameters for each dataset like Nivre et al. (2006), but used default values for all languages. As can be seen in the table, even though the pseudo-projective parser is able to capture nonprojective syntactic phenomena, </context>
<context position="35602" citStr="Nivre (2009)" startWordPosition="5865" endWordPosition="5866">ansition to a parser to improve its accuracy has been applied in the past by Choi and Palmer (2011). In that paper, the LEFT-ARC transition from Nivre’s arc-eager transition system is added to a list-based parser. However, the goal of that transition is different from ours (selecting between projective and nonprojective parsing, rather than building some arcs in advance) and the approach is specific to one algorithm while ours is generic – for example, the LEFTARC transition cannot be added to the arc-standard and arc-eager parsers, or to extensions of those like the ones by Attardi (2006) or Nivre (2009), because these already have it. The idea of creating dependency arcs of length 1 in advance to help the classifier has been used by Cheng et al. (2006). However, their system creates such arcs in a separate preprocessing step rather than dynamically by adding a transition to the parser, and our approach obtains better LAS and UAS results on all the tested datasets. The projective buffer transitions presented here bear some resemblance to the easy-first parser by Goldberg and Elhadad (2010), which allows creation of dependency arcs between any pair of contiguous nodes and is based on the idea </context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Non-projective dependency parsing in expected linear time. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP), pages 351–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur.</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora,</booktitle>
<pages>261--277</pages>
<editor>In Anne Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>Oflazer, 2003</marker>
<rawString>Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-T¨ur, and G¨okhan T¨ur. 2003. Building a Turkish treebank. In Anne Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, pages 261–277. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Shift-reduce dependency DAG parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>753--760</pages>
<contexts>
<context position="2859" citStr="Sagae and Tsujii, 2008" startWordPosition="427" endWordPosition="430">sed parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; Nivre, 2009; Huang and Sagae, 2010; G´omezRodr´ıguez and Nivre, 2010) are stack-based (Nivre, 2008), meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens. In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions. These are transitions that create a dependency arc involving some node in the buffer, which would typically be considered unavailable for linking by these algo308 Proceedings of the 2012 Joint Conference on Empi</context>
</contexts>
<marker>Sagae, Tsujii, 2008</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce dependency DAG parsing. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 753–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Tratz</author>
<author>Eduard Hovy</author>
</authors>
<title>A fast, accurate, non-projective, semantically-enriched parser.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1257--1268</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="1963" citStr="Tratz and Hovy (2011)" startWordPosition="290" endWordPosition="293">area in natural language processing in recent years. The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select </context>
</contexts>
<marker>Tratz, Hovy, 2011</marker>
<rawString>Stephen Tratz and Eduard Hovy. 2011. A fast, accurate, non-projective, semantically-enriched parser. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1257– 1268, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<contexts>
<context position="1846" citStr="Yamada and Matsumoto (2003)" startWordPosition="269" endWordPosition="272"> to be applicable to any stackbased dependency parser. 1 Introduction Dependency parsing has become a very active research area in natural language processing in recent years. The dependency representation of syntax simplifies the syntactic parsing task, since no non-lexical nodes need to be postulated by the parsers; while being convenient in practice, since dependency representations directly show the headmodifier and head-complement relationships which form the basis of predicate-argument structure. This has led to the development of various data-driven dependency parsers, such as those by Yamada and Matsumoto (2003), Nivre et al. (2004), McDonald et al. (2005), Martins et al. (2009), Huang and Sagae (2010) or Tratz and Hovy (2011), which can be trained directly from annotated data and produce accurate analyses very efficiently. Most current data-driven dependency parsers can be classified into two families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al.</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines.</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT),</booktitle>
<pages>195--206</pages>
<marker></marker>
<rawString>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT), pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>562--571</pages>
<contexts>
<context position="8248" citStr="Zhang and Clark, 2008" startWordPosition="1399" endWordPosition="1402">e configuration. To obtain a deterministic parser 309 from a transition system, a classifier is trained to greedily select the best transition at each state. This training is typically done by using an oracle, which is a function o : C → T that selects a single transition at each configuration, given a tree in the training set. The classifier is then trained to approximate this oracle when the target tree is unknown. 2.3 The arc-eager parser Nivre’s arc-eager dependency parser (Nivre, 2003; Nivre et al., 2004) is one of the most widely known and used transition-based parsers (see for example (Zhang and Clark, 2008; Zhang and Nivre, 2011)). This parser works by reading the input sentence from left to right and creating dependency links as soon as possible. This means that links are created in a strict left-to-right order, and implies that while leftward links are built in a bottom-up fashion, a rightward link a → b will be created before the node b has collected its right dependents. The arc-eager transition system has the following four transitions (note that, for convenience, we write a stack with node i on top as σ|i, and a buffer whose first node is i as i|β): • SHIFT : (σ, i|β, A) ⇒ (σ|i, β, A). • </context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 562–571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>188--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2754" citStr="Zhang and Nivre, 2011" startWordPosition="412" endWordPosition="415">o families, commonly called graph-based and transition-based parsers (McDonald and Nivre, 2011). Graph-based parsers (Eisner, 1996; McDonald et al., 2005) are based on global optimization of models that work by scoring subtrees. On the other hand, transition-based parsers (Yamada and Matsumoto, 2003; Nivre et al., 2004), which are the focus of this work, use local training to make greedy decisions that deterministically select the next parser state. Among the advantages of transition-based parsers are the linear time complexity of many of them and the possibility of using rich feature models (Zhang and Nivre, 2011). In particular, many transition-based parsers (Nivre et al., 2004; Attardi, 2006; Sagae and Tsujii, 2008; Nivre, 2009; Huang and Sagae, 2010; G´omezRodr´ıguez and Nivre, 2010) are stack-based (Nivre, 2008), meaning that they keep a stack of partially processed tokens and an input buffer of unread tokens. In this paper, we show how the accuracy of this kind of parsers can be improved, without compromising efficiency, by extending their set of available transitions with buffer transitions. These are transitions that create a dependency arc involving some node in the buffer, which would typicall</context>
<context position="8272" citStr="Zhang and Nivre, 2011" startWordPosition="1403" endWordPosition="1406">ain a deterministic parser 309 from a transition system, a classifier is trained to greedily select the best transition at each state. This training is typically done by using an oracle, which is a function o : C → T that selects a single transition at each configuration, given a tree in the training set. The classifier is then trained to approximate this oracle when the target tree is unknown. 2.3 The arc-eager parser Nivre’s arc-eager dependency parser (Nivre, 2003; Nivre et al., 2004) is one of the most widely known and used transition-based parsers (see for example (Zhang and Clark, 2008; Zhang and Nivre, 2011)). This parser works by reading the input sentence from left to right and creating dependency links as soon as possible. This means that links are created in a strict left-to-right order, and implies that while leftward links are built in a bottom-up fashion, a rightward link a → b will be created before the node b has collected its right dependents. The arc-eager transition system has the following four transitions (note that, for convenience, we write a stack with node i on top as σ|i, and a buffer whose first node is i as i|β): • SHIFT : (σ, i|β, A) ⇒ (σ|i, β, A). • REDUCE : (σ|i, β, A) ⇒ (</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 188–193, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>