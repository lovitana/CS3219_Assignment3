<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000088">
<title confidence="0.95447">
Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation
</title>
<author confidence="0.769372">
Roberto Navigli and Simone Paolo Ponzetto
</author>
<affiliation confidence="0.480741">
Dipartimento di Informatica
</affiliation>
<address confidence="0.374859">
Sapienza Universit`a di Roma
</address>
<email confidence="0.982598">
{navigli,ponzetto}@di.uniroma1.it
</email>
<sectionHeader confidence="0.993424" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998540923076923">
We present a multilingual joint approach
to Word Sense Disambiguation (WSD). Our
method exploits BabelNet, a very large mul-
tilingual knowledge base, to perform graph-
based WSD across different languages, and
brings together empirical evidence from these
languages using ensemble methods. The re-
sults show that, thanks to complementing
wide-coverage multilingual lexical knowledge
with robust graph-based algorithms and com-
bination methods, we are able to achieve the
state of the art in both monolingual and multi-
lingual WSD settings.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999825963636364">
Nowadays the textual information needed by a user
accessing websites for content such as news re-
ports, commentaries and encyclopedic knowledge
is provided in an increasingly wide range of lan-
guages. For example, even though English is still
the majority language of the Web, the Chinese and
Spanish languages are moving fast to capture their
“juicy share”, and more languages are about to join
them in the near future. This language explosion
clearly forces researchers to focus on the challeng-
ing problem of being able to analyze and under-
stand text written in any language. However, it also
opens up novel perspectives for multilingual Natural
Language Processing (NLP) such as, for instance,
the development of approaches aimed at “joining
forces” and taking advantage of the lexico-semantic
knowledge provided in the different languages to
improve text understanding. These two aspects are
strongly intertwined: on the one hand, enabling
language-independent text understanding would al-
low for the harvesting of more knowledge in arbi-
trary languages, while, on the other hand, bringing
together the lexical and semantic information avail-
able in different languages would improve the qual-
ity of text understanding in arbitrary languages.
However, these two goals have hitherto never
been achieved, as is attested to by the fact that re-
search in a core language understanding task such as
Word Sense Disambiguation (Navigli, 2009, WSD)
has always been focused mostly on English. His-
torically, English became established as the lan-
guage used and understood by the scientific com-
munity and, consequently, most resources were de-
veloped for it, including large-scale computational
lexicons like WordNet (Fellbaum, 1998) and sense-
tagged corpora like SemCor (Miller et al., 1993).
As a result WSD in other languages was hindered
by a lack of resources, which in turn led to poor re-
sults or low involvement on the part of the research
community (Magnini et al., 2004; M`arquez et al.,
2004; Orhan et al., 2007; Okumura et al., 2010).
Nonetheless, already in the 1990s it had been re-
marked that WSD could be improved by means of
multilingual information: a recurring idea proposed
by several researchers was that plausible transla-
tions of a word in context would restrict its pos-
sible senses to a manageable subset of meanings
(Dagan et al., 1991; Gale et al., 1992; Resnik and
Yarowsky, 1999). While the lack of resources at that
time hampered the development of effective multi-
lingual approaches to WSD, recently this idea has
been revamped with the organization of SemEval
tasks dealing with cross-lingual WSD (Lefever and
Hoste, 2010) and cross-lingual lexical substitution
(Mihalcea et al., 2010). At the same time, new re-
</bodyText>
<page confidence="0.978105">
1399
</page>
<note confidence="0.7731335">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999821576923077">
search on the topic has been done, including the use
of statistical translations of sentences into many lan-
guages as features for supervised models (Banea and
Mihalcea, 2011; Lefever et al., 2011), and the pro-
jection of monolingual knowledge onto another lan-
guage (Khapra et al., 2011).
Yet the above two goals, i.e., disambiguating in
an arbitrary language and using lexical and seman-
tic knowledge from many languages in a joint way
to improve the WSD task, have not hitherto been
attained. In this paper, we address both objectives
and propose a graph-based approach to multilingual
joint Word Sense Disambiguation. Our proposal
brings together the lexical knowledge from differ-
ent languages by exploiting empirical evidence for
disambiguation from each of them, and then com-
bining this information in a synergistic way: each
language provides a piece of sense evidence for the
meaning of a target word in context, and subsequent
integration of these various pieces enables them to
(soft) constrain each other. The results show that
this way we are able to improve over previous, high-
performing graph-based methods in both a monolin-
gual and multilingual setting, thus showing for the
first time the beneficial effects of exploiting multi-
lingual knowledge in a joint fashion.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999856875">
Parallel corpora have been used in the literature
for the automatic creation of a sense-tagged dataset
for supervised WSD in different languages (Gale
et al., 1992; Chan and Ng, 2005; Zhong and Ng,
2009). Other approaches include the use of a coher-
ence index for identifying the tendency to lexicalize
senses differently across languages (Ide, 2000) and
the clustering of source words which translate into
the same target word, then used to perform WSD
using a similarity measure (Diab, 2003). A histori-
cal approach (Brown et al., 1991) uses bilingual cor-
pora to perform unsupervised word alignment and
determine the most appropriate translation for a tar-
get word from a set of contextual features.
All the above approaches to multilingual or cross-
lingual WSD rely on bilingual corpora, including
those which exploit existing multilingual WordNet-
like resources (Ide et al., 2002), or use automatically
induced multilingual co-occurrence graphs (Silberer
and Ponzetto, 2010). However, this requirement is
often very hard to satisfy, especially if we need wide
coverage. To overcome this limitation, in this work
we make use of BabelNet (Navigli and Ponzetto,
2010), a very large multilingual lexical knowledge
base. This resource – complementary in nature
to other recent efforts presented by de Melo and
Weikum (2010), Nastase et al. (2010) and Meyer and
Gurevych (2012), inter alia – provides a truly multi-
lingual semantic network by combining Wikipedia’s
multilinguality with the output of a state-of-the-art
machine translation system to achieve high cover-
age for all languages. The key insight here is that
Word Sense Disambiguation and Machine Transla-
tion (MT) are highly intertwined tasks, as previously
shown by Carpuat and Wu (2007) and Chan et al.
(2007), who successfully used sense information to
boost state-of-the-art statistical MT. In this work we
focus instead on the benefits of using multilingual
information for WSD by exploiting the structure of
a multilingual semantic network.
</bodyText>
<sectionHeader confidence="0.995476" genericHeader="method">
3 Multilingual Joint WSD
</sectionHeader>
<bodyText confidence="0.999902142857143">
We present our methodology for multilingual WSD:
we first introduce BabelNet, the resource used in our
work (Section 3.1) and then present our algorithm
for multilingual joint WSD (Section 3.2), including
its main components, namely graph-based WSD, en-
semble methods and translation weighting (sections
3.3, 3.4 and 3.5).
</bodyText>
<subsectionHeader confidence="0.998052">
3.1 BabelNet
</subsectionHeader>
<bodyText confidence="0.999847461538461">
BabelNet (Navigli and Ponzetto, 2010) follows the
structure of a traditional lexical knowledge base and,
accordingly, consists of a labeled directed graph
whose nodes represent concepts and named entities,
and whose edges express semantic relations between
them. Concepts and relations are harvested from
the largest available semantic lexicon of English,
i.e., WordNet, and a wide-coverage collaboratively-
edited encyclopedia, i.e., Wikipedia1, thus making
BabelNet a multilingual ‘encyclopedic dictionary’
which combines lexicographic information with en-
cyclopedic knowledge on the basis of an unsuper-
vised mapping framework. In addition to a core
</bodyText>
<footnote confidence="0.9995175">
1http://www.wikipedia.org. In the following, we
refer to Wikipedia pages and senses using SMALL CAPS.
</footnote>
<page confidence="0.991469">
1400
</page>
<bodyText confidence="0.999962516129032">
semantic network, BabelNet provides a multilin-
gual lexical dimension. Each of its nodes, called
Babel synsets, contains a set of lexicalizations of
the concept for different languages, e.g., f bankENn ,
BankDE
n , bancaITn , ... , bancoES n }2. Multilin-
gual lexicalizations for all concepts are collected
from Wikipedia’s inter-language links (e.g., the En-
glish Wikipedia page BANK links to the Italian
BANCA), as well as by acquiring missing trans-
lations by means of a statistical machine transla-
tion system applied to sense-tagged data from Sem-
Cor and Wikipedia itself – for instance, most oc-
currences of bank1n in SemCor3 are translated into
German and Italian as Ufer and riva, respectively.
As a result of combining human-edited translations
from Wikipedia and automatically generated ones
from sense-labeled data, BabelNet is able to achieve
wide coverage for all its languages (Catalan, En-
glish, French, German, Italian and Spanish): accord-
ingly, we chose it to perform graph-based WSD in
a multilingual setting since it is specifically focused
on lexical knowledge. In addition, BabelNet is avail-
able for any language required to perform standard
SemEval cross-lingual disambiguation tasks (e.g.,
Spanish, in order to perform cross-lingual lexical
substitution). Since previous work in knowledge-
based WSD shows the benefits of using rich lexical
resources (Navigli and Lapata, 2010; Ponzetto and
Navigli, 2010), BabelNet is a suitable choice for per-
forming graph-based multilingual WSD.
</bodyText>
<subsectionHeader confidence="0.9799325">
3.2 Exploiting multilingual information in a
knowledge-based WSD framework
</subsectionHeader>
<bodyText confidence="0.9973256">
We present a multilingual approach to WSD
which exploits three main factors:
i) the fact that translations of a target word pro-
vide complementary information on the range
of its candidate senses in context;
</bodyText>
<figure confidence="0.6322205">
Algorithm 1 Multilingual joint WSD
Input: a word sequence Q = (w1, ... , w,,,)
a target word w E Q
BabelNet BN
an ensemble method M
Output: a distribution of scores for the senses of w
(D indicates a comment)
1: S +— SynsetsBN(w)
2: T +— fw}
3: for each s E S
4: T +— T U getTranslations(s)
5: ctx +— Q − fw}
6: D LScore := flScorei,j}i=1,...,|T|,j=1,...,|S|
7: for each ti E T
8: Q0 +— fti} U ctx
9: D Gi := (Vi, Ei)
10: Gi +— createGraph(Q0, BN)
11: for each sj E S n Vi
12: lScorei,j +— score(Gi, sj)
13: D Score := (score1,..., score|S|)
14: Score +— M(LScore)
15: return Score
</figure>
<bodyText confidence="0.970927421052632">
We call this approach multilingual joint WSD,
since disambiguation is performed by exploiting dif-
ferent languages together at the same time. To this
end, we first perform graph-based WSD using the
target word in context as input, and then combine
sense evidence from its translations using an ensem-
ble method. The key idea of our joint approach is
that sense evidence from different translations pro-
vides complementary views for the senses of a tar-
get word in context. Therefore, combining such ev-
idence should produce more accurate sense predic-
tions. We view WSD as a sense ranking problem.
Given a word sequence Q = (w1, ... , wn), we dis-
ambiguate a target word w E Q by scoring each of
its senses and selecting the highest-ranking one:
ii) the wide-coverage, multilingual lexical knowl- s� = arg max score(s) , (1)
edge stored in BabelNet; s E SynsetsBN(w)
iii) the support for disambiguation from different
languages in a synergistic, unified way.
</bodyText>
<footnote confidence="0.8688366">
2BabelNet senses are referred to with wP, namely the sense
of a word w in a language l with part of speech p.
3We denote WordNet senses with w,,, namely the i-th sense
of a word w with part of speech p.
where SynsetsBAw) is the set of Babel synsets con-
taining the different senses for w.4 We score these
4Babel synsets unambiguously identify different senses
of the target word, e.g., f bankEN n , BankDE n , bancoESn .. . ,
bancaITn } corresponds to the ‘financial institute’ sense of
bankENn (i.e., bank&apos; in WordNet).
</footnote>
<page confidence="0.994738">
1401
</page>
<bodyText confidence="0.990539714285714">
synsets using Algorithm 1, which we illustrate in
the following by means of the example sentence
‘bank bonuses are paid in stock’, where we focus on
bankEnN as the target word and { bonusENn , payEN
v ,
stockENn } as its context. The following steps are
performed:
Initialization. We start by gathering the data re-
quired for disambiguation (lines 1–5). First, we
collect in line 1 the set S of Babel synsets corre-
sponding to the different senses of the target word w
– namely, the synsets containing the ‘financial in-
stitution’, ‘money container’, ‘building’ senses of
bankENn , among others. Next, we obtain the multi-
lingual lexicalizations of the target word: to this end,
we first include in T the word w itself (line 2), and
then iterate through each synset s E S to collect the
translations of each of its senses in the languages of
interest (lines 3–4). For instance, given the English
word bankENn , we collect its sense-specific German,
Italian and Spanish translations and obtain a set of
</bodyText>
<equation confidence="0.86186275">
multilingual terms T = { bankENn , ... , BankDE
n ,
Sparb¨uchseDE
n , Bankgeb¨audeDE
</equation>
<bodyText confidence="0.995180902439024">
n , ..., bancaITn ,
salvadanaioITn , ... , bancoESn , huchaES n }. Finally,
we create a disambiguation context ctx by taking the
word sequence Q and removing w from it (line 5, as
a result, e.g., ctx = { bonus
Collecting sense distributions. In the next phase
(lines 6–12), we collect a scoring distribution over
the different synsets S of w for each term ti E T.
Each distribution quantifies the empirical support for
the different senses of the target word, obtained us-
ing ti and the context ctx: we store this informa-
tion in a |T |x |S |matrix LScore, where each cell
lScorei,j quantifies the support for synset sj E S,
computed using the term in ti E T. We calculate the
scores as follows:
- We select at each step an element ti from T (line
7), for instance bancoESn .
- Next, we create a multilingual context Q&apos; by com-
bining ti with the words in ctx (line 8, e.g., we set
Q&apos; = { banco
- We use Q&apos; to build a graph Gi = (U, Ei) by
computing the paths in BabelNet which connect
the synsets of ti with those of the other words
in Q&apos; (line 10, see Section 3.3 for details on the
createGraph function). Note that by selecting at
each step a different element from T we create a
new graph where different sets of Babel synsets
get activated by the context words in ctx. In our
example, Figures 1(a)–(c) show the graphs ob-
tained by setting at different steps ti to bankENn ,
bancoES n and BankDE
n , respectively (we show ex-
cerpts by using only stockENn as context word for
ease of readability).
- Finally, we compute the support from term ti for
each synset sj E S of the target word by applying
a graph connectivity measure to Gi and store the
result in lScorei,j (lines 11–12). For instance, us-
ing degree as graph measure, we can compute the
following scores from the graph in Figure 1(b):
bankn bank nbankn
</bodyText>
<equation confidence="0.960095">
bancoES 2 0 1
n
</equation>
<bodyText confidence="0.903480228571429">
By repeating the process for each term in T (lines 7–
12) we compute all values in the matrix LScore. For
instance, given T = {bankENn , bancoESn , BankDE
n },
we create the set of graphs in Figures 1(a)–(c), and
compute from each of them the following scores
(again, using degree as scoring measure):
LScore =
bankENn � bankn bank nbankn 1 �
bancoES � 2 2 1 �
n 2 0 0
BankDE 2 0
n
Combining sense distributions. In the last step
(line 14) we aggregate the scores associated with
each term of T using an ensemble method M (see
Section 3.4 for details). For instance, M could sim-
ply consist of summing the scores associated with
each sense over all distributions and thus return a
score of 6, 2, and 2 for bankn, bank nand bankn,
respectively. As a result of the execution of Al-
gorithm 1, the combined scoring distribution is re-
turned (line 15). This sense distribution in turn can
be used to select the best sense using Equation 1.
The main hunch behind our approach is that using
information from different languages improves dis-
ambiguation performance, as in the example of Fig-
ure 1 where more accurate disambiguation is per-
formed by combining scores computed from trans-
lations in different languages, as opposed to using
n , payEN
EN v , stockENn }).
n , bonusEN
ES n , payEN
v , stockENn }.
</bodyText>
<page confidence="0.78902">
1402
</page>
<figure confidence="0.994164440677966">
(a) Disambiguation graph using the target word bankEN� .
(c) Disambiguation graph using BankDE� as translation.
(b) Disambiguation graph using bancoES� as translation.
(d) List of corresponding WordNet senses and their glosses
bank� financial institution that accepts deposits and channels
�
the money into lending activities
bank� a container (usually with a slot in the top) for keeping
�
money at home
bank� a building in which the business of banking transacted
�
stocks the capital raised by a corporation through the issue
of shares entitling holders to an ownership interest
stocks a certificate documenting the shareholder’s
ownership in the corporation
stocka7 any animals kept for use or profit
bank8n
Sparb¨uchseDE
huchaES
salvadanaioIT
piggy pig
bank
stock4n
AktienzertifikatDE
accionesES azioniIT
bank2n
BankDE
bancoES
bancaIT
commercial
bank
investment
banking
stock trader
broker
stock1n
AktienDE
accionesES
azioniIT
building abattoir
stock17n
ViehDE
ganadoES
bestiameIT
bank9n
Bankgeb¨audeDE
bancoES bancaIT
commercial
bank
investment
banking
stock1n
AktienDE
accionesES
azioniIT
bank2n
BankDE
bancoES
bancaIT
bench1n BankDE
bancoES panchinaIT
stock trader
broker
bed4n BankDE
estratoES lettoIT
stock4n
AktienzertifikatDE
accionesES azioniIT
bank8n
Sparb¨uchseDE
huchaES
salvadanaioIT
piggy pig
bank
building abattoir
bank9n
Bankgeb¨audeDE
bancoES bancaIT
stock17n
ViehDE
ganadoES
bestiameIT
commercial
bank
investment
banking
stock1n
AktienDE
accionesES
azioniIT
bank2n
BankDE
bancoES
bancaIT
bench1n
BankDE
bancoES
panchinaIT
stock trader
broker
stock4n
AktienzertifikatDE
accionesES azioniIT
bank9n
Bankgeb¨audeDE
bancoES bancaIT
bank8n
Sparb¨uchseDE
huchaES
salvadanaioIT
piggy pig
bank
building abattoir
stock17n
ViehDE
ganadoES
bestiameIT
</figure>
<figureCaption confidence="0.993407">
Figure 1: Multilingual graph construction for the input sentence ‘bank bonuses are paid in stock’. We show excerpts
using only stockEN,, as context word for ease of readability.
</figureCaption>
<bodyText confidence="0.989348611111111">
monolingual sense evidence only. Figure 1(a) shows
the graph created to disambiguate the English target
word bankENn in our example sentence. In the graph,
some of the possible senses of this word are acti-
vated, including the correct one (bank2n) but also re-
lated, yet incorrect ones such as bank8 n and bank9n.
Figure 1(b) and 1(c) show instead the graphs ob-
tained from replacing the target word with its Span-
ish and German translations, respectively. In these
graphs, different subsets of the senses of bankENn
are activated, together with others pertaining to the
translations only (e.g., the meaning of bancoESn cor-
responding to the English bench1n). However, the
sense that is consistently activated across all graphs
is the correct one – i.e., bankENn as financial insti-
tution – which is in fact the sense selected by our
multilingual approach by means of combining the
scoring distributions from all these graphs.
</bodyText>
<subsectionHeader confidence="0.996746">
3.3 Graph-based WSD
</subsectionHeader>
<bodyText confidence="0.996482695652174">
We use graph-based algorithms to exploit multilin-
gual knowledge from BabelNet for WSD. These are
a natural choice for our approach, since BabelNet is
a semantic network, and such algorithms have been
shown to achieve high performance across domains
(Agirre et al., 2009; Navigli et al., 2011), as well
as to compete with supervised methods on a vari-
ety of lexical disambiguation tasks (Ponzetto and
Navigli, 2010). To this end, we use the method
of Navigli and Lapata (2010) and construct a di-
rected graph G = (V, E) for an input word sequence
Q = (w1, ... , wn)5 using the lexical and semantic
relations found in BabelNet. The result of this pro-
cedure is a subgraph of BabelNet containing (1) the
senses of the words in context, (2) all edges and in-
termediate senses found in BabelNet along all paths
that connect them. Given G, a target word w E Q
and its set of senses in BabelNet 5 C_ V , we com-
pute a score distribution (score1, ... , score|S|) over
5, where scored refers to the confidence score for
the j-th sense of w, e.g. bank2n, based on some con-
nectivity measure applied to G. In this paper, we
specifically focus on two such measures.
</bodyText>
<footnote confidence="0.9018705">
5In our experiments we always take or to be a single sen-
tence, thus disambiguating on a sentence-by-sentence basis.
</footnote>
<page confidence="0.96114">
1403
</page>
<bodyText confidence="0.981618666666667">
Degree Centrality (Degree): The first measure
ranks the senses of a given word in the graph based
on the number of their incident edges, namely:
</bodyText>
<equation confidence="0.573048">
scorej = |{{sj, v} E E : v E V I |.
</equation>
<bodyText confidence="0.9984696875">
proposed by Brody et al. (2006), which they show
to be the best performing for WSD. This method
takes the scores associated with each term, normal-
izes and combines them by summing across distri-
butions. Formally, it computes the score for the j-th
sense of w as follows:
This standard connectivity measure weights a sense
as more appropriate if it has a higher degree. We
chose context-based Degree since, albeit simple, it
had previously been shown to yield a highly com-
petitive performance on various WSD tasks (Navigli
and Lapata, 2010; Ponzetto and Navigli, 2010).
Inverse path length sum (PLength): We then de-
veloped a graph connectivity measure which scores
each sense by summing over the inverse length of all
paths which connect it to other senses in the graph:
</bodyText>
<equation confidence="0.9779815">
�scorej =
p E paths(sj)
</equation>
<bodyText confidence="0.9999816">
where paths(sj) is the set of simple paths con-
necting sj to the senses of other context words,
length(p) is the number of edges in the path p and
each path is scored with the exponential inverse de-
cay of the path length. This measure overcomes the
locality of Degree by aggregating over all paths be-
tween a sense of the target word and those of the
context words, thus being able to capture the rich-
ness of the BabelNet subgraph and the semantic den-
sity of the underlying knowledge base.
</bodyText>
<sectionHeader confidence="0.822507" genericHeader="method">
3.4 Ensemble methods for multilingual WSD
</sectionHeader>
<bodyText confidence="0.9999534375">
At the core of our algorithm lies the combination of
the scores generated using the different translations
of the target word w. For this purpose, we apply so-
called ensemble methods, which have been shown
to improve the performance of both supervised (Flo-
rian et al., 2002) and unsupervised WSD systems
(Brody et al., 2006). Given |T |lexicalizations and
|S |senses for w, the input to the combination com-
ponent consists of a |T|x|S |matrix LScore, where
each cell lScorei,j quantifies the empirical support
for sense sj from a term ti E T (see Section 3.2 for
an example). The ensemble method computes from
this translation-sense matrix a combined scoring, ex-
pressing the joint confidence across terms in differ-
ent languages over the set of senses S. In this work,
we use the ‘Probability Mixture’ (PMixture) method
</bodyText>
<equation confidence="0.82576925">
,
j
p( si,j ), p(si,j) = � l 1
Scorei
</equation>
<bodyText confidence="0.90079075">
Es=1 lScorei,s
For instance, using the (normalized) sense distribu-
tions from our example, the ensemble distribution
will be the following:
</bodyText>
<table confidence="0.921242428571429">
bankEN bank2 n bank�n bank&apos;
n 0.40 0.40 0.20
bancoES 0.67 0.00 0.33
n 1.00 0.00 0.00
BankDE
n
PMixture 2.07 0.40 0.53
</table>
<subsectionHeader confidence="0.967315">
3.5 Weighting multilingual sense distribution
</subsectionHeader>
<bodyText confidence="0.999729137931034">
Computing a sense distribution for each translation
using the same graph connectivity measure assumes
that all translations are equal. However, a leitmotif
of multilingual WSD research is that translations re-
strict the set of candidate senses of the target word
in the source language. In our example of Figure
1, for instance, BankDE
n provides structural support
only for the financial sense of English bank, since
this is the only sense it covers. Within our frame-
work this can potentially lead to skewed sense dis-
tributions when only some senses of the target word
have a translation. In such cases, in fact, scores tend
to be concentrated mostly on the senses covered by
the translations, with the result that sense evidence
for uncovered English senses is disregarded. In or-
der to cope with this issue, we weight the elements
of each sense distribution lScorei for the i-th trans-
lation ti E T by a factor of 1+lo92 cov(ti, w), where
cov(ti, w) is the number of Babel synsets where ti
co-occurs with the target word w – i.e., the number
of senses of w that it covers (we use the log func-
tion to dampen the effect of high coverage values).
This is to say, in order to level off the effects of un-
balanced sense coverage we assume that, all things
being equal, the more senses a translation covers, the
stronger the disambiguation evidence it provides in
context for specific senses. As a result, the contri-
butions of each translation are weighted differently
</bodyText>
<equation confidence="0.99755025">
1
elength(p)−1 ,
scorej = � �TJ
i=1
</equation>
<page confidence="0.953459">
1404
</page>
<bodyText confidence="0.999649">
and we are thus able to dampen the effects of a
highly skewed distribution like, for instance, that of
</bodyText>
<equation confidence="0.957263">
BankDE
n :
</equation>
<table confidence="0.994044428571429">
bankEN bank&apos; n bank�n bank&apos;
n 1.72 1.72 0.86
bancoES 1.34 0.00 0.66
n 1.00 0.00 0.00
BankDE
n
Weighted PMixture 4.04 1.70 1.52
</table>
<sectionHeader confidence="0.99773" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999555">
We evaluate our approach in two different settings,
namely a monolingual all-words WSD task in Sec-
tion 4.1, as well as two different cross-lingual dis-
ambiguation gold standards in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.988476">
4.1 Monolingual WSD
</subsectionHeader>
<bodyText confidence="0.999977548387097">
Experimental setting. We first evaluate the per-
formance of multilingual joint WSD on a standard
monolingual dataset, namely the SemEval-2010 do-
main WSD task 17 (Agirre et al., 2010), since it
provides the latest dataset for fine-grained WSD in
English. We opt for an English all-words task for
two main reasons: first, it is a well-established and
widely-participated task in the WSD community –
thus ensuring a comparison of our method with a
wide range of state-of-the-art approaches, includ-
ing other graph-based techniques (e.g., Personalized
PageRank), as well as weakly-supervised and super-
vised approaches (see Agirre et al. (2010) for de-
tails on the participating systems); second, we want
to assess whether a multilingual approach benefits
lexical disambiguation in all settings, namely even
in a standard monolingual one. We use in our ex-
periments the dataset’s nouns-only subset (1032 in-
stances), since BabelNet currently contains multi-
lingual lexicalizations for nouns only (and thus no
multilingual strategy can be applied to other parts
of speech). We perform graph-based WSD with
BabelNet in two different configurations, namely a
monolingual and multilingual setting. The multi-
lingual system performs WSD by means of the full
joint multilingual approach described in Algorithm
1. The monolingual approach, instead, simply uses
the English input sentence for disambiguation – that
is, we skip lines 3–4 of Algorithm 1. Knowledge-
based systems typically suffer from a low recall –
i.e., they cannot provide an answer if no information
</bodyText>
<table confidence="0.999874428571428">
Algorithm P R F1
Monolingual Degree 50.6 45.2 47.7
graph PLength 51.0 47.3 49.1
Multilingual Degree† 53.9 48.6 51.1
ensemble PLength† 54.3 50.2 52.2
SemCor MFS 51.9 51.2 51.5
Random 25.3 25.3 25.3
</table>
<tableCaption confidence="0.94062675">
Table 1: Performance on SemEval-2010 all-words do-
main WSD (nouns only subset). Best results for each
measure are bolded. † indicates statistically significant
differences with respect to the monolingual setting.
</tableCaption>
<bodyText confidence="0.9996">
can be found with senses of the context words. To
overcome this issue, in both settings we use a type-
based fallback strategy which assigns to the target
word the sense which has been most frequently as-
signed by the system to other instances of the word
in the dataset.
Results and discussion. We report our results in
terms of precision (P), recall (R) and F1 measure in
Table 1, where we compare the monolingual vari-
ant (rows 1–2 of the table) with our multilingual
approach (rows 3–4). Following standard practice,
(1) we benchmark our method against two baselines,
namely a random sense assignment and the most fre-
quent sense (MFS) from SemCor; (2) we test for sta-
tistical significance by computing a 95% confidence
interval on the recall score (i.e., the main evaluation
measure for the WSD task) using bootstrap resam-
pling (Noreen, 1989).
The results show that our multilingual approach
improves over the monolingual one by a substan-
tial (i.e., statistically significant) margin. Combining
multilingual information from different languages
yields a higher precision (+3.3 for both graph algo-
rithms) and recall (+3.4 and +2.9 for Degree and
PLength, respectively). Manual inspection of the
output reveals that these increases in precision are
due to translations in different languages constrain-
ing each other – e.g., an implausible English sense is
‘ruled out’ from the sense distributions of the other
languages (cf. the example in Figure 1). The in-
creases in recall, instead, indicate that using trans-
lations triggers responses in those cases where no
sense of the English target word can be connected
to the senses of the context words – i.e., some trans-
</bodyText>
<page confidence="0.977901">
1405
</page>
<table confidence="0.999920714285714">
Algorithm P R F1
Monolingual Degree 52.0 51.3 51.6
graph PLength 55.0 54.2 54.6
Multilingual Degree† 61.6 59.5 60.5
ensemble PLength† 62.5 60.4 61.4
CFILT 61.4 59.4 60.4
IIITH 56.4 55.3 55.8
</table>
<tableCaption confidence="0.938995">
Table 2: Performance on SemEval-2010 all-words do-
main WSD (nouns only subset) using the most frequent
</tableCaption>
<bodyText confidence="0.991852645833333">
sense assigned by the system as back-off strategy when
no sense assignment is attempted.
lations activate senses in the knowledge base which
are closer to the senses of the context words. The
result is an overall increase in F1 measure of 3.4
and 3.1 points for Degree and PLength, respectively,
which makes it possible for us to beat the MFS
baseline (notably a difficult competitor for WSD
systems). Among the different graph algorithms,
PLength consistently outperforms Degree: however,
the differences are not statistically significant.
In order to better understand the impact of our ap-
proach we follow previous work (e.g., Navigli and
Lapata (2010)) and explore a weakly-supervised set-
ting where the system attempts no sense assignment
if the highest score among those assigned to the
senses of a target word is below a certain threshold.
If this is the case, in order to provide an answer for
all items, we output the most frequent sense assigned
by the system to other instances of the target word,
and fall back to SemCor’s MFS if no assignment has
been attempted. We estimate the optimal value for
the threshold by maximizing F1 on a development
set obtained by combining the Senseval-2 (Palmer et
al., 2001) and Senseval-3 (Snyder and Palmer, 2004)
English all-words datasets. The results for this set-
ting are shown in Table 2, where we also compare
with the top-performing systems from the SemEval
competition, namely CFILT (Kulkarni et al., 2010)
and IIITH (Reddy et al., 2010).
By complementing our multilingual method with
the MFS heuristic we achieve a performance compa-
rable with the state of the art on this task. Again, the
multilingual ensemble approach consistently outper-
forms the monolingual one and enables us to achieve
the best overall results for this dataset: without mul-
tilingual information, in fact, we achieve only aver-
age performance above the MFS level, whereas by
effectively combining sense evidence from multilin-
gual translations we are able to boost the F1 measure
by a 6-8 point margin, and thus outperform the top-
ranking SemEval systems. While differences with
CFILT are not statistically significant, we still take
this to be good news, since our system is general
purpose in nature and, accordingly, does not use any
domain information such as manually-labeled exam-
ples for the most frequent domain words (CFILT) or
a domain-specific sense ranking (IIITH).
</bodyText>
<subsectionHeader confidence="0.999598">
4.2 Cross-lingual lexical disambiguation
</subsectionHeader>
<bodyText confidence="0.999955529411765">
Using a multilingual lexical resource makes it possi-
ble to perform WSD in any of its languages. Ac-
cordingly, we complement our evaluation on En-
glish texts with a second set of experiments where
we quantify the impact of our approach on a lex-
ical disambiguation task in a multilingual setting.
To this end, we use the SemEval-2010 cross-lingual
lexical substitution (Mihalcea et al., 2010, CL-LS,
henceforth) and WSD (Lefever et al., 2011, CL-
WSD) tasks and evaluate our methodology on per-
forming disambiguation across different languages.
Both cross-lingual WSD tasks cast disambiguation
as a word translation problem: given an English pol-
ysemous noun in context as input, the system dis-
ambiguates it by providing a translation into another
language (translations are deemed correct if they
preserve the meaning of the source word in the target
language). Their main difference, instead, lies in the
range of translations which are assumed to be valid:
that is, while CL-LS assumes no predefined sense in-
ventory (i.e., any translation can be potentially cor-
rect), CL-WSD makes use of a sense inventory built
on the basis of the Europarl corpus (Koehn, 2005).
Our approach to lexical disambiguation involves
two steps: first, given a target word in context, we
disambiguate it as usual to the highest-ranked Ba-
bel synset; next, given the translations in the se-
lected synset, we return the most suitable lexical-
ization in the language of interest. Since the se-
lected synset can contain multiple translations in a
target language for the input English word, we ex-
plore using an unsupervised strategy to select the
most reliable translation from multiple candidates.
To this end, we return for each test instance only the
</bodyText>
<page confidence="0.969935">
1406
</page>
<table confidence="0.999429142857143">
Algorithm P/R/F1
Baseline 23.80
Monolingual Degree 30.52
graph PLength 30.64
Multilingual Degree 32.21
ensemble PLength 32.47
UBA-T 32.17
</table>
<tableCaption confidence="0.996576">
Table 3: Performance on SemEval-2010 lexical substitu-
tion (best results are bolded).
</tableCaption>
<bodyText confidence="0.999805617647059">
most frequent translation found in the Babel synset.
Given that the two tasks make different assumptions
on the sense inventory (no fixed inventory for CL-
LS vs. Europarl-based for CL-WSD), the frequency
of a translation is calculated as either the number
of Babel synsets in which it occurs (CL-LS), or its
frequency of alignment with the target word, as ob-
tained by applying GIZA++ (Och and Ney, 2003) to
Europarl (CL-WSD). To provide an answer for all
instances, we return this most frequent translation
even when no sense assignment is attempted – i.e.,
no sense of the target word is connected to any other
sense of the context words – or a tie occurs.
Results and discussion. We report our results for
CL-LS and CL-WSD in Tables 3 and 4. We evalu-
ate using the nouns-only subset of the CL-LS dataset
and the full CL-WSD dataset, consisting of 300 and
1,000 instances of nouns in context, respectively.
The evaluation scheme is based on the SemEval-
2007 English lexical substitution task (McCarthy
and Navigli, 2009), and consists of an adaptation of
the metrics of precision and recall for the translation
setting. For each task, we compare our monolingual
and multilingual approaches against the best per-
forming SemEval systems for these tasks, namely
UBA-T (Basile and Semeraro, 2010) and UVT-v
(van Gompel, 2010) for CL-LS and CL-WSD, re-
spectively, as well as a recent supervised proposal
that exploits automatically generated multilingual
features from parallel text and translated contexts
(Lefever et al., 2011, Parasense). For each task
we also report its official baseline, namely the first
translation from an online-dictionary6 for CL-LS,
and the most frequent word alignment obtained by
</bodyText>
<footnote confidence="0.944317">
6www.spanishdict.com
</footnote>
<bodyText confidence="0.99924052">
applying GIZA++ to the Europarl data for CL-WSD.
Our cross-lingual results confirm all trends of the
English monolingual evaluation, namely that: a) our
joint multilingual approach substantially improves
over the simple monolingual graph-based approach;
b) it enables us to achieve state-of-the-art perfor-
mance for these tasks. In the case of both CL-
LS and CL-WSD, using a rich multilingual knowl-
edge base like BabelNet makes it possible to achieve
a respectable performance already with the simple
monolingual approach, thus indicating the viability
of a knowledge-rich approach to sense-driven word
translation. The use of multilingual ensembles al-
ways improves the monolingual setting for all lan-
guages, and allows us to achieve the best overall re-
sults for both CL-LS and CL-WSD. Similarly to the
case of monolingual WSD, manual inspection of the
output reveals that translations help us rule out in-
correct senses and let the disambiguation algorithm
focus on the more coherent set of senses for the in-
put context in a way similar to the one highlighted
by the example in Figure 1. As a result of this we
are able to improve the performance of both mono-
lingual Degree and PLength, and compete with the
state of the art on all disambiguation tasks.
</bodyText>
<sectionHeader confidence="0.999569" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9996919">
In this paper we presented a multilingual joint ap-
proach to WSD. Key to our methodology is the ef-
fective use of a wide-coverage multilingual knowl-
edge base, BabelNet, which we exploit to perform
graph-based WSD across languages and combine
complementary sense evidence from translations in
different languages using an ensemble method. This
is the first proposal to exploit structured multilingual
information within a joint, knowledge-rich frame-
work for WSD. The APIs to perform multilingual
WSD using BabelNet are freely available for re-
search purposes (Navigli and Ponzetto, 2012b).
Thanks to multilingual joint WSD we achieve
state-of-the-art performance on three different gold
standards. The good news about these results is that
not only can further advances be achieved by using
multilingual lexical knowledge, but, more impor-
tantly, that combining multilingual sense evidence
from different languages at the same time yields
consistent improvements over a monolingual ap-
</bodyText>
<page confidence="0.973614">
1407
</page>
<table confidence="0.999600111111111">
French German Italian Spanish
P/R/F1 P/R/F1 P/R/F1 P/R/F1
Baseline 21.25 13.16 15.18 19.74
UvT-v N/A N/A N/A 23.39
Parasense 24.54 16.88 18.03 22.80
Monolingual Degree 22.94 17.15 18.03 22.48
graph PLength 23.42 17.72 18.19 22.76
Multilingual Degree 24.02 18.07 18.93 23.51
ensemble PLength 24.61 18.26 19.05 23.65
</table>
<tableCaption confidence="0.999936">
Table 4: Results on the SemEval-2010 cross-lingual WSD dataset (best results are bolded).
</tableCaption>
<bodyText confidence="0.999927736842105">
proach in both monolingual and cross-lingual lexical
disambiguation tasks – that is, ‘joining forces pays
off’. Effectively leveraging multilingual knowledge
for WSD helps overcome the shortcomings of the
underlying resource (noise, coverage, etc.), thus in-
dicating that further performance boosts can come
in the future from even better multilingual lexical
resources. Moreover, our methodology is general-
purpose and can be adapted to tasks other than
WSD: in fact, we have already taken the first steps
in this direction by showing the beneficial effects of
a joint multilingual approach to computing semantic
relatedness (Navigli and Ponzetto, 2012a). In ad-
dition, we plan in the very near future to general-
ize our multilingual joint approach and apply it to
high-end tasks such as multilingual textual entail-
ment (Mehdad et al., 2011) and sentiment analysis
(Lu et al., 2011) – so as to provide a general frame-
work for knowledge-rich multilingual NLP.
</bodyText>
<sectionHeader confidence="0.997511" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9890794">
The authors gratefully acknowl-
edge the support of the ERC Start-
ing Grant MultiJEDI No. 259234.
BabelNet and its API are available for download at
http://lcl.uniroma1.it/babelnet.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997266844444444">
Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa.
2009. Knowledge-based WSD on specific domains:
performing better than generic supervised WSD. In
Proceedings of the 21st International Joint Confer-
ence on Artificial Intelligence (IJCAI-09), pages 1501–
1506.
Eneko Agirre, Oier L´opez de Lacalle, Christiane Fell-
baum, Shu-Kai Hsieh, Maurizio Tesconi, Monica
Monachini, Piek Vossen, and Roxanne Segers. 2010.
Semeval-2010 task 17: All-words Word Sense Disam-
biguation on a specific domain. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 75–80.
Carmen Banea and Rada Mihalcea. 2011. Word Sense
Disambiguation with multilingual features. In Pro-
ceedings of the 9th International Conference on Com-
putational Semantics (IWCS 2011), pages 25–34.
Pierpaolo Basile and Giovanni Semeraro. 2010. UBA:
Using automatic translation and Wikipedia for cross-
lingual lexical substitution. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 242–247.
Samuel Brody, Roberto Navigli, and Mirella Lapata.
2006. Ensemble methods for unsupervised WSD.
In Proceedings of the 21st International Conference
on Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguistics
(COLING-ACL-06), pages 97–104.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1991. Word-sense dis-
ambiguation using statistical methods. In Proceed-
ings of the 29th Annual Meeting of the Association for
Computational Linguistics (ACL-91), pages 264–270.
Marine Carpuat and Dekai Wu. 2007. Improving Sta-
tistical Machine Translation using Word Sense Dis-
ambiguation. In Proceedings of the 2007 Joint Con-
ference on Empirical Methods in Natural Language
Processing and Computational Language Learning
(EMNLP-CoNLL-07), pages 61–72.
Yee Seng Chan and Hwee Tou Ng. 2005. Scaling up
Word Sense Disambiguation via parallel texts. In Pro-
ceedings of the 20th National Conference on Artificial
Intelligence (AAAI-05), pages 1037–1042.
Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007.
Word Sense Disambiguation improves Statistical Ma-
</reference>
<page confidence="0.934499">
1408
</page>
<reference confidence="0.996304839622642">
chine Translation. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics (ACL-07), pages 33–40.
Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two
languages are more informative than one. In Proceed-
ings of the 29th Annual Meeting of the Association for
Computational Linguistics (ACL-91), pages 130–137.
Gerard de Melo and Gerhard Weikum. 2010. MENTA:
Inducing multilingual taxonomies from Wikipedia. In
Proceedings of the 19th ACM Conference on Informa-
tion and Knowledge Management (CIKM-10), pages
1099–1108.
Mona Diab. 2003. Word Sense Disambiguation within a
Multilingual Framework. Ph.D. thesis, University of
Maryland, College Park, Maryland.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Database. MIT Press, Cambridge, MA.
Radu Florian, Silviu Cucerzan, Charles Schafer, and
David Yarowsky. 2002. Combining classifiers for
Word Sense Disambiguation. Natural Language En-
gineering, 8(4):1–14.
William A. Gale, Kenneth Church, and David Yarowsky.
1992. Using bilingual materials to develop Word
Sense Disambiguation methods. In Proceedings of the
Fourth International Conference on Theoretical and
Methodological Issues in Machine Translation, pages
101–112.
Nancy Ide, Tomaz Erjavec, and Dan Tufis¸. 2002. Sense
discrimination with parallel corpora. In Proceedings
of the ACL-02 Workshop on WSD: Recent Successes
and Future Directions, pages 54–60.
Nancy Ide. 2000. Cross-lingual sense determination:
Can it work? Computers and the Humanities, 34:223–
234.
Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, and
Pushpak Bhattacharyya. 2011. Together we can:
Bilingual bootstrapping for WSD. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics, (ACL-11), pages 561–569.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of Ma-
chine Translation Summit X.
Anup Kulkarni, Mitesh Khapra, Saurabh Sohoney, and
Pushpak Bhattacharyya. 2010. CFILT: Resource
conscious approaches for all-words domain specific
WSD. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
421–426.
Els Lefever and Veronique Hoste. 2010. SemEval-2010
task 3: Cross-lingual Word Sense Disambiguation. In
Proceedings of the 5th International Workshop on Se-
mantic Evaluations (SemEval-2010), pages 15–20.
Els Lefever, V´eronique Hoste, and Martine De Cock.
2011. Parasense or how to use parallel corpora for
Word Sense Disambiguation. In Proceedings of the
49th Annual Meeting of the Association for Computa-
tional Linguistics, (ACL-11), pages 317–322.
Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin
K. Tsou. 2011. Joint bilingual sentiment classification
with unlabeled parallel corpora. In Proceedings of the
49th Annual Meeting of the Association for Computa-
tional Linguistics, (ACL-11), pages 320–330.
Bernardo Magnini, Danilo Giampiccolo, and Alessan-
dro Vallin. 2004. The Italian lexical sample task at
Senseval-3. In Proceedings of the 3rd International
Workshop on the Evaluation of Systems for the Seman-
tic Analysis of Text (SENSEVAL-3), pages 17–20.
Lluis M`arquez, Mariona Taul´e, Antonia Mart´ı, N´uria
Artigas, Mar Garc´ıa, Francis Real, and Dani Ferr´es.
2004. Senseval-3: The Spanish lexical sample task.
In Proceedings of the 3rd International Workshop on
the Evaluation of Systems for the Semantic Analysis of
Text (SENSEVAL-3), pages 21–24.
Diana McCarthy and Roberto Navigli. 2009. The En-
glish lexical substitution task. Language Resources
and Evaluation, 43(2):139–159.
Yashar Mehdad, Matteo Negri, and Marcello Federico.
2011. Using bilingual parallel corpora for cross-
lingual textual entailment. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics, (ACL-11), pages 1336–1345.
Christian M. Meyer and Iryna Gurevych. 2012.
Ontowiktionary – Constructing an ontology from
the collaborative online dictionary Wiktionary. In
Maria Teresa Pazienza and Armando Stellato, edi-
tors, Semi-Automatic Ontology Development: Pro-
cesses and Resources. IGI Global, Hershey, Penn.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010.
Semeval-2010 task 2: Cross-lingual lexical substitu-
tion. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
9–14.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross Bunker. 1993. A semantic concordance. In Pro-
ceedings of the 3rd DARPA Workshop on Human Lan-
guage Technology, pages 303–308.
Vivi Nastase, Michael Strube, Benjamin B¨orschinger,
Caecilia Zirn, and Anas Elghafari. 2010. WikiNet:
A very large scale multi-lingual concept network. In
Proceedings of the 7th International Conference on
Language Resources and Evaluation, (LREC ’10).
Roberto Navigli and Mirella Lapata. 2010. An exper-
imental study on graph connectivity for unsupervised
Word Sense Disambiguation. IEEE Transactions on
Pattern Anaylsis and Machine Intelligence, 32(4):678–
692.
</reference>
<page confidence="0.903704">
1409
</page>
<reference confidence="0.99954197368421">
Roberto Navigli and Simone Paolo Ponzetto. 2010. Ba-
belNet: Building a very large multilingual semantic
network. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics,
(ACL-10), pages 216–225.
Roberto Navigli and Simone Paolo Ponzetto. 2012a. Ba-
belRelate! A joint multilingual approach to computing
semantic relatedness. In Proceedings of the 26th Con-
ference on Artificial Intelligence (AAAI-12).
Roberto Navigli and Simone Paolo Ponzetto. 2012b.
Multilingual WSD with just a few lines of code: The
BabelNet API. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics, (ACL-12). System Demonstrations.
Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopez
de Lacalle, and Eneko Agirre. 2011. Two birds with
one stone: Learning semantic models for Text Cate-
gorization and Word Sense Disambiguation. In Pro-
ceedings of the 20th ACM Conference on Informa-
tion and Knowledge Management (CIKM-11), pages
2317–2320.
Roberto Navigli. 2009. Word Sense Disambiguation: A
survey. ACM Computing Surveys, 41(2):1–69.
Eric W. Noreen, editor. 1989. Computer-intensive meth-
ods for testing hypotheses: an introduction. New
York, N.Y.: John Wiley.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Manabu Okumura, Kiyoaki Shirai, Kanako Komiya, and
Hikaru Yokono. 2010. SemEval-2010 task: Japanese
WSD. In Proceedings of the 5th International Work-
shop on Semantic Evaluations (SemEval-2010), pages
69–74.
Zeynep Orhan, Emine C¸elik, and Demirg¨uc¸ Neslihan.
2007. SemEval-2007 task 12: Turkish lexical sample
task. In Proceedings of the 4th International Work-
shop on Semantic Evaluations (SemEval-2007), pages
59–63.
Martha Palmer, Christiane Fellbaum, Scott Cotton, Lau-
ren Delfs, and Hoa Trang Dang. 2001. English tasks:
All-words and verb lexical sample. In Proceedings of
the 2nd International Workshop on Evaluating Word
Sense Disambiguation Systems (SENSEVAL-2), pages
21–24.
Simone Paolo Ponzetto and Roberto Navigli. 2010.
Knowledge-rich Word Sense Disambiguation rivaling
supervised system. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, (ACL-10), pages 1522–1531.
Siva Reddy, Abhilash Inumella, Diana McCarthy, and
Mark Stevenson. 2010. IIITH: Domain specific
Word Sense Disambiguation. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 387–391.
Philip Resnik and David Yarowsky. 1999. Distinguish-
ing systems and distinguishing senses: new evaluation
methods for Word Sense Disambiguation. Journal of
Natural Language Engineering, 5(2):113–133.
Carina Silberer and Simone Paolo Ponzetto. 2010. UHD:
Cross-lingual Word Sense Disambiguation using mul-
tilingual co-occurrence graphs. In Proceedings of the
5th International Workshop on Semantic Evaluations
(SemEval-2010), pages 134–137.
Benjamin Snyder and Martha Palmer. 2004. The English
all-words task. In Proceedings of the 3rd International
Workshop on the Evaluation of Systems for the Seman-
tic Analysis of Text (SENSEVAL-3), pages 41–43.
Maarten van Gompel. 2010. UvT-WSD1: A cross-
lingual word sense disambiguation system. In Pro-
ceedings of the 5th International Workshop on Seman-
tic Evaluations (SemEval-2010), pages 238–241.
Zhi Zhong and Hwee Tou Ng. 2009. Word Sense Dis-
ambiguation for all words without hard labor. In Pro-
ceedings of the 21st International Joint Conference on
Artificial Intelligence (IJCAI-09), pages 1616–1622.
</reference>
<page confidence="0.989837">
1410
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.273155">
<title confidence="0.999927">Joining Forces Pays Off: Multilingual Joint Word Sense Disambiguation</title>
<author confidence="0.72075">Navigli Paolo Ponzetto</author>
<affiliation confidence="0.51961">Dipartimento di Informatica Sapienza Universit`a di Roma</affiliation>
<abstract confidence="0.988706214285714">We present a multilingual joint approach to Word Sense Disambiguation (WSD). Our method exploits BabelNet, a very large multilingual knowledge base, to perform graphbased WSD across different languages, and brings together empirical evidence from these languages using ensemble methods. The results show that, thanks to complementing wide-coverage multilingual lexical knowledge with robust graph-based algorithms and combination methods, we are able to achieve the state of the art in both monolingual and multilingual WSD settings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez de Lacalle</author>
<author>Aitor Soroa</author>
</authors>
<title>Knowledge-based WSD on specific domains: performing better than generic supervised WSD.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-09),</booktitle>
<pages>1501--1506</pages>
<marker>Agirre, de Lacalle, Soroa, 2009</marker>
<rawString>Eneko Agirre, Oier Lopez de Lacalle, and Aitor Soroa. 2009. Knowledge-based WSD on specific domains: performing better than generic supervised WSD. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-09), pages 1501– 1506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier L´opez de Lacalle</author>
<author>Christiane Fellbaum</author>
<author>Shu-Kai Hsieh</author>
<author>Maurizio Tesconi</author>
<author>Monica Monachini</author>
<author>Piek Vossen</author>
<author>Roxanne Segers</author>
</authors>
<title>Semeval-2010 task 17: All-words Word Sense Disambiguation on a specific domain.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>75--80</pages>
<marker>Agirre, de Lacalle, Fellbaum, Hsieh, Tesconi, Monachini, Vossen, Segers, 2010</marker>
<rawString>Eneko Agirre, Oier L´opez de Lacalle, Christiane Fellbaum, Shu-Kai Hsieh, Maurizio Tesconi, Monica Monachini, Piek Vossen, and Roxanne Segers. 2010. Semeval-2010 task 17: All-words Word Sense Disambiguation on a specific domain. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 75–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Banea</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word Sense Disambiguation with multilingual features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 9th International Conference on Computational Semantics (IWCS</booktitle>
<pages>25--34</pages>
<contexts>
<context position="3901" citStr="Banea and Mihalcea, 2011" startWordPosition="597" endWordPosition="600">ea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics search on the topic has been done, including the use of statistical translations of sentences into many languages as features for supervised models (Banea and Mihalcea, 2011; Lefever et al., 2011), and the projection of monolingual knowledge onto another language (Khapra et al., 2011). Yet the above two goals, i.e., disambiguating in an arbitrary language and using lexical and semantic knowledge from many languages in a joint way to improve the WSD task, have not hitherto been attained. In this paper, we address both objectives and propose a graph-based approach to multilingual joint Word Sense Disambiguation. Our proposal brings together the lexical knowledge from different languages by exploiting empirical evidence for disambiguation from each of them, and then</context>
</contexts>
<marker>Banea, Mihalcea, 2011</marker>
<rawString>Carmen Banea and Rada Mihalcea. 2011. Word Sense Disambiguation with multilingual features. In Proceedings of the 9th International Conference on Computational Semantics (IWCS 2011), pages 25–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierpaolo Basile</author>
<author>Giovanni Semeraro</author>
</authors>
<title>UBA: Using automatic translation and Wikipedia for crosslingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>242--247</pages>
<contexts>
<context position="34552" citStr="Basile and Semeraro, 2010" startWordPosition="5679" endWordPosition="5682">s and discussion. We report our results for CL-LS and CL-WSD in Tables 3 and 4. We evaluate using the nouns-only subset of the CL-LS dataset and the full CL-WSD dataset, consisting of 300 and 1,000 instances of nouns in context, respectively. The evaluation scheme is based on the SemEval2007 English lexical substitution task (McCarthy and Navigli, 2009), and consists of an adaptation of the metrics of precision and recall for the translation setting. For each task, we compare our monolingual and multilingual approaches against the best performing SemEval systems for these tasks, namely UBA-T (Basile and Semeraro, 2010) and UVT-v (van Gompel, 2010) for CL-LS and CL-WSD, respectively, as well as a recent supervised proposal that exploits automatically generated multilingual features from parallel text and translated contexts (Lefever et al., 2011, Parasense). For each task we also report its official baseline, namely the first translation from an online-dictionary6 for CL-LS, and the most frequent word alignment obtained by 6www.spanishdict.com applying GIZA++ to the Europarl data for CL-WSD. Our cross-lingual results confirm all trends of the English monolingual evaluation, namely that: a) our joint multilin</context>
</contexts>
<marker>Basile, Semeraro, 2010</marker>
<rawString>Pierpaolo Basile and Giovanni Semeraro. 2010. UBA: Using automatic translation and Wikipedia for crosslingual lexical substitution. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 242–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>Ensemble methods for unsupervised WSD.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-06),</booktitle>
<pages>97--104</pages>
<contexts>
<context position="20541" citStr="Brody et al. (2006)" startWordPosition="3365" endWordPosition="3368">of senses in BabelNet 5 C_ V , we compute a score distribution (score1, ... , score|S|) over 5, where scored refers to the confidence score for the j-th sense of w, e.g. bank2n, based on some connectivity measure applied to G. In this paper, we specifically focus on two such measures. 5In our experiments we always take or to be a single sentence, thus disambiguating on a sentence-by-sentence basis. 1403 Degree Centrality (Degree): The first measure ranks the senses of a given word in the graph based on the number of their incident edges, namely: scorej = |{{sj, v} E E : v E V I |. proposed by Brody et al. (2006), which they show to be the best performing for WSD. This method takes the scores associated with each term, normalizes and combines them by summing across distributions. Formally, it computes the score for the j-th sense of w as follows: This standard connectivity measure weights a sense as more appropriate if it has a higher degree. We chose context-based Degree since, albeit simple, it had previously been shown to yield a highly competitive performance on various WSD tasks (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010). Inverse path length sum (PLength): We then developed a graph co</context>
<context position="22156" citStr="Brody et al., 2006" startWordPosition="3646" endWordPosition="3649">overcomes the locality of Degree by aggregating over all paths between a sense of the target word and those of the context words, thus being able to capture the richness of the BabelNet subgraph and the semantic density of the underlying knowledge base. 3.4 Ensemble methods for multilingual WSD At the core of our algorithm lies the combination of the scores generated using the different translations of the target word w. For this purpose, we apply socalled ensemble methods, which have been shown to improve the performance of both supervised (Florian et al., 2002) and unsupervised WSD systems (Brody et al., 2006). Given |T |lexicalizations and |S |senses for w, the input to the combination component consists of a |T|x|S |matrix LScore, where each cell lScorei,j quantifies the empirical support for sense sj from a term ti E T (see Section 3.2 for an example). The ensemble method computes from this translation-sense matrix a combined scoring, expressing the joint confidence across terms in different languages over the set of senses S. In this work, we use the ‘Probability Mixture’ (PMixture) method , j p( si,j ), p(si,j) = � l 1 Scorei Es=1 lScorei,s For instance, using the (normalized) sense distributi</context>
</contexts>
<marker>Brody, Navigli, Lapata, 2006</marker>
<rawString>Samuel Brody, Roberto Navigli, and Mirella Lapata. 2006. Ensemble methods for unsupervised WSD. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL-06), pages 97–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Word-sense disambiguation using statistical methods.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL-91),</booktitle>
<pages>264--270</pages>
<contexts>
<context position="5556" citStr="Brown et al., 1991" startWordPosition="865" endWordPosition="868">al effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silberer and Ponzetto, 2010). However, this requirement is often very hard to satisfy, especially if we need wide coverage. To overcome this limitation, in this work we make use of BabelNet (</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1991</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1991. Word-sense disambiguation using statistical methods. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL-91), pages 264–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving Statistical Machine Translation using Word Sense Disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning (EMNLP-CoNLL-07),</booktitle>
<pages>61--72</pages>
<contexts>
<context position="6760" citStr="Carpuat and Wu (2007)" startWordPosition="1050" endWordPosition="1053">use of BabelNet (Navigli and Ponzetto, 2010), a very large multilingual lexical knowledge base. This resource – complementary in nature to other recent efforts presented by de Melo and Weikum (2010), Nastase et al. (2010) and Meyer and Gurevych (2012), inter alia – provides a truly multilingual semantic network by combining Wikipedia’s multilinguality with the output of a state-of-the-art machine translation system to achieve high coverage for all languages. The key insight here is that Word Sense Disambiguation and Machine Translation (MT) are highly intertwined tasks, as previously shown by Carpuat and Wu (2007) and Chan et al. (2007), who successfully used sense information to boost state-of-the-art statistical MT. In this work we focus instead on the benefits of using multilingual information for WSD by exploiting the structure of a multilingual semantic network. 3 Multilingual Joint WSD We present our methodology for multilingual WSD: we first introduce BabelNet, the resource used in our work (Section 3.1) and then present our algorithm for multilingual joint WSD (Section 3.2), including its main components, namely graph-based WSD, ensemble methods and translation weighting (sections 3.3, 3.4 and </context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving Statistical Machine Translation using Word Sense Disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Language Learning (EMNLP-CoNLL-07), pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Scaling up Word Sense Disambiguation via parallel texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05),</booktitle>
<pages>1037--1042</pages>
<contexts>
<context position="5202" citStr="Chan and Ng, 2005" startWordPosition="807" endWordPosition="810">sense evidence for the meaning of a target word in context, and subsequent integration of these various pieces enables them to (soft) constrain each other. The results show that this way we are able to improve over previous, highperforming graph-based methods in both a monolingual and multilingual setting, thus showing for the first time the beneficial effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corp</context>
</contexts>
<marker>Chan, Ng, 2005</marker>
<rawString>Yee Seng Chan and Hwee Tou Ng. 2005. Scaling up Word Sense Disambiguation via parallel texts. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI-05), pages 1037–1042.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
<author>David Chiang</author>
</authors>
<title>Word Sense Disambiguation improves Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07),</booktitle>
<pages>33--40</pages>
<contexts>
<context position="6783" citStr="Chan et al. (2007)" startWordPosition="1055" endWordPosition="1058">nd Ponzetto, 2010), a very large multilingual lexical knowledge base. This resource – complementary in nature to other recent efforts presented by de Melo and Weikum (2010), Nastase et al. (2010) and Meyer and Gurevych (2012), inter alia – provides a truly multilingual semantic network by combining Wikipedia’s multilinguality with the output of a state-of-the-art machine translation system to achieve high coverage for all languages. The key insight here is that Word Sense Disambiguation and Machine Translation (MT) are highly intertwined tasks, as previously shown by Carpuat and Wu (2007) and Chan et al. (2007), who successfully used sense information to boost state-of-the-art statistical MT. In this work we focus instead on the benefits of using multilingual information for WSD by exploiting the structure of a multilingual semantic network. 3 Multilingual Joint WSD We present our methodology for multilingual WSD: we first introduce BabelNet, the resource used in our work (Section 3.1) and then present our algorithm for multilingual joint WSD (Section 3.2), including its main components, namely graph-based WSD, ensemble methods and translation weighting (sections 3.3, 3.4 and 3.5). 3.1 BabelNet Babe</context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng, and David Chiang. 2007. Word Sense Disambiguation improves Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
<author>Ulrike Schwall</author>
</authors>
<title>Two languages are more informative than one.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL-91),</booktitle>
<pages>130--137</pages>
<contexts>
<context position="3101" citStr="Dagan et al., 1991" startWordPosition="477" endWordPosition="480">sensetagged corpora like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for</context>
</contexts>
<marker>Dagan, Itai, Schwall, 1991</marker>
<rawString>Ido Dagan, Alon Itai, and Ulrike Schwall. 1991. Two languages are more informative than one. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics (ACL-91), pages 130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>MENTA: Inducing multilingual taxonomies from Wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM Conference on Information and Knowledge Management (CIKM-10),</booktitle>
<pages>1099--1108</pages>
<marker>de Melo, Weikum, 2010</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2010. MENTA: Inducing multilingual taxonomies from Wikipedia. In Proceedings of the 19th ACM Conference on Information and Knowledge Management (CIKM-10), pages 1099–1108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Word Sense Disambiguation within a Multilingual Framework.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Maryland, College Park,</institution>
<location>Maryland.</location>
<contexts>
<context position="5512" citStr="Diab, 2003" startWordPosition="859" endWordPosition="860">wing for the first time the beneficial effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silberer and Ponzetto, 2010). However, this requirement is often very hard to satisfy, especially if we need wide coverage. To overcome this limita</context>
</contexts>
<marker>Diab, 2003</marker>
<rawString>Mona Diab. 2003. Word Sense Disambiguation within a Multilingual Framework. Ph.D. thesis, University of Maryland, College Park, Maryland.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Florian</author>
<author>Silviu Cucerzan</author>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Combining classifiers for Word Sense Disambiguation.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="22106" citStr="Florian et al., 2002" startWordPosition="3637" endWordPosition="3641">tial inverse decay of the path length. This measure overcomes the locality of Degree by aggregating over all paths between a sense of the target word and those of the context words, thus being able to capture the richness of the BabelNet subgraph and the semantic density of the underlying knowledge base. 3.4 Ensemble methods for multilingual WSD At the core of our algorithm lies the combination of the scores generated using the different translations of the target word w. For this purpose, we apply socalled ensemble methods, which have been shown to improve the performance of both supervised (Florian et al., 2002) and unsupervised WSD systems (Brody et al., 2006). Given |T |lexicalizations and |S |senses for w, the input to the combination component consists of a |T|x|S |matrix LScore, where each cell lScorei,j quantifies the empirical support for sense sj from a term ti E T (see Section 3.2 for an example). The ensemble method computes from this translation-sense matrix a combined scoring, expressing the joint confidence across terms in different languages over the set of senses S. In this work, we use the ‘Probability Mixture’ (PMixture) method , j p( si,j ), p(si,j) = � l 1 Scorei Es=1 lScorei,s For</context>
</contexts>
<marker>Florian, Cucerzan, Schafer, Yarowsky, 2002</marker>
<rawString>Radu Florian, Silviu Cucerzan, Charles Schafer, and David Yarowsky. 2002. Combining classifiers for Word Sense Disambiguation. Natural Language Engineering, 8(4):1–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth Church</author>
<author>David Yarowsky</author>
</authors>
<title>Using bilingual materials to develop Word Sense Disambiguation methods.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>101--112</pages>
<contexts>
<context position="3120" citStr="Gale et al., 1992" startWordPosition="481" endWordPosition="484">like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Ling</context>
<context position="5183" citStr="Gale et al., 1992" startWordPosition="803" endWordPosition="806">rovides a piece of sense evidence for the meaning of a target word in context, and subsequent integration of these various pieces enables them to (soft) constrain each other. The results show that this way we are able to improve over previous, highperforming graph-based methods in both a monolingual and multilingual setting, thus showing for the first time the beneficial effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rel</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth Church, and David Yarowsky. 1992. Using bilingual materials to develop Word Sense Disambiguation methods. In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation, pages 101–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Tomaz Erjavec</author>
<author>Dan Tufis¸</author>
</authors>
<title>Sense discrimination with parallel corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on WSD: Recent Successes and Future Directions,</booktitle>
<pages>54--60</pages>
<marker>Ide, Erjavec, Tufis¸, 2002</marker>
<rawString>Nancy Ide, Tomaz Erjavec, and Dan Tufis¸. 2002. Sense discrimination with parallel corpora. In Proceedings of the ACL-02 Workshop on WSD: Recent Successes and Future Directions, pages 54–60.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
</authors>
<title>Cross-lingual sense determination: Can it work? Computers and the Humanities,</title>
<date>2000</date>
<pages>34--223</pages>
<contexts>
<context position="5369" citStr="Ide, 2000" startWordPosition="835" endWordPosition="836">hat this way we are able to improve over previous, highperforming graph-based methods in both a monolingual and multilingual setting, thus showing for the first time the beneficial effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silb</context>
</contexts>
<marker>Ide, 2000</marker>
<rawString>Nancy Ide. 2000. Cross-lingual sense determination: Can it work? Computers and the Humanities, 34:223– 234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitesh M Khapra</author>
<author>Salil Joshi</author>
<author>Arindam Chatterjee</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Together we can: Bilingual bootstrapping for WSD.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11),</booktitle>
<pages>561--569</pages>
<contexts>
<context position="4013" citStr="Khapra et al., 2011" startWordPosition="616" endWordPosition="619"> and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics search on the topic has been done, including the use of statistical translations of sentences into many languages as features for supervised models (Banea and Mihalcea, 2011; Lefever et al., 2011), and the projection of monolingual knowledge onto another language (Khapra et al., 2011). Yet the above two goals, i.e., disambiguating in an arbitrary language and using lexical and semantic knowledge from many languages in a joint way to improve the WSD task, have not hitherto been attained. In this paper, we address both objectives and propose a graph-based approach to multilingual joint Word Sense Disambiguation. Our proposal brings together the lexical knowledge from different languages by exploiting empirical evidence for disambiguation from each of them, and then combining this information in a synergistic way: each language provides a piece of sense evidence for the meani</context>
</contexts>
<marker>Khapra, Joshi, Chatterjee, Bhattacharyya, 2011</marker>
<rawString>Mitesh M. Khapra, Salil Joshi, Arindam Chatterjee, and Pushpak Bhattacharyya. 2011. Together we can: Bilingual bootstrapping for WSD. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11), pages 561–569.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of Machine Translation Summit X.</booktitle>
<contexts>
<context position="32474" citStr="Koehn, 2005" startWordPosition="5342" endWordPosition="5343">ross-lingual WSD tasks cast disambiguation as a word translation problem: given an English polysemous noun in context as input, the system disambiguates it by providing a translation into another language (translations are deemed correct if they preserve the meaning of the source word in the target language). Their main difference, instead, lies in the range of translations which are assumed to be valid: that is, while CL-LS assumes no predefined sense inventory (i.e., any translation can be potentially correct), CL-WSD makes use of a sense inventory built on the basis of the Europarl corpus (Koehn, 2005). Our approach to lexical disambiguation involves two steps: first, given a target word in context, we disambiguate it as usual to the highest-ranked Babel synset; next, given the translations in the selected synset, we return the most suitable lexicalization in the language of interest. Since the selected synset can contain multiple translations in a target language for the input English word, we explore using an unsupervised strategy to select the most reliable translation from multiple candidates. To this end, we return for each test instance only the 1406 Algorithm P/R/F1 Baseline 23.80 Mo</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of Machine Translation Summit X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anup Kulkarni</author>
<author>Mitesh Khapra</author>
<author>Saurabh Sohoney</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>CFILT: Resource conscious approaches for all-words domain specific WSD.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>421--426</pages>
<contexts>
<context position="30337" citStr="Kulkarni et al., 2010" startWordPosition="4998" endWordPosition="5001">eshold. If this is the case, in order to provide an answer for all items, we output the most frequent sense assigned by the system to other instances of the target word, and fall back to SemCor’s MFS if no assignment has been attempted. We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004) English all-words datasets. The results for this setting are shown in Table 2, where we also compare with the top-performing systems from the SemEval competition, namely CFILT (Kulkarni et al., 2010) and IIITH (Reddy et al., 2010). By complementing our multilingual method with the MFS heuristic we achieve a performance comparable with the state of the art on this task. Again, the multilingual ensemble approach consistently outperforms the monolingual one and enables us to achieve the best overall results for this dataset: without multilingual information, in fact, we achieve only average performance above the MFS level, whereas by effectively combining sense evidence from multilingual translations we are able to boost the F1 measure by a 6-8 point margin, and thus outperform the toprankin</context>
</contexts>
<marker>Kulkarni, Khapra, Sohoney, Bhattacharyya, 2010</marker>
<rawString>Anup Kulkarni, Mitesh Khapra, Saurabh Sohoney, and Pushpak Bhattacharyya. 2010. CFILT: Resource conscious approaches for all-words domain specific WSD. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 421–426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval-2010 task 3: Cross-lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>15--20</pages>
<contexts>
<context position="3393" citStr="Lefever and Hoste, 2010" startWordPosition="523" endWordPosition="526">umura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics search on the topic has been done, including the use of statistical translations of sentences into many languages as features for supervised models (Banea and Mihalcea, 2011; Lefever et al., 2011), and the projection of monolingual knowledge onto another language (</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. SemEval-2010 task 3: Cross-lingual Word Sense Disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 15–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>V´eronique Hoste</author>
<author>Martine De Cock</author>
</authors>
<title>Parasense or how to use parallel corpora for Word Sense Disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11),</booktitle>
<pages>317--322</pages>
<marker>Lefever, Hoste, De Cock, 2011</marker>
<rawString>Els Lefever, V´eronique Hoste, and Martine De Cock. 2011. Parasense or how to use parallel corpora for Word Sense Disambiguation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11), pages 317–322.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Chenhao Tan</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Joint bilingual sentiment classification with unlabeled parallel corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11),</booktitle>
<pages>320--330</pages>
<marker>Lu, Tan, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Chenhao Tan, Claire Cardie, and Benjamin K. Tsou. 2011. Joint bilingual sentiment classification with unlabeled parallel corpora. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11), pages 320–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Danilo Giampiccolo</author>
<author>Alessandro Vallin</author>
</authors>
<title>The Italian lexical sample task at Senseval-3.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),</booktitle>
<pages>17--20</pages>
<contexts>
<context position="2722" citStr="Magnini et al., 2004" startWordPosition="412" endWordPosition="415">rch in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) has always been focused mostly on English. Historically, English became established as the language used and understood by the scientific community and, consequently, most resources were developed for it, including large-scale computational lexicons like WordNet (Fellbaum, 1998) and sensetagged corpora like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of</context>
</contexts>
<marker>Magnini, Giampiccolo, Vallin, 2004</marker>
<rawString>Bernardo Magnini, Danilo Giampiccolo, and Alessandro Vallin. 2004. The Italian lexical sample task at Senseval-3. In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), pages 17–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lluis M`arquez</author>
<author>Mariona Taul´e</author>
<author>Antonia Mart´ı</author>
<author>N´uria Artigas</author>
<author>Mar Garc´ıa</author>
<author>Francis Real</author>
<author>Dani Ferr´es</author>
</authors>
<title>Senseval-3: The Spanish lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),</booktitle>
<pages>21--24</pages>
<marker>M`arquez, Taul´e, Mart´ı, Artigas, Garc´ıa, Real, Ferr´es, 2004</marker>
<rawString>Lluis M`arquez, Mariona Taul´e, Antonia Mart´ı, N´uria Artigas, Mar Garc´ıa, Francis Real, and Dani Ferr´es. 2004. Senseval-3: The Spanish lexical sample task. In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), pages 21–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>The English lexical substitution task.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="34281" citStr="McCarthy and Navigli, 2009" startWordPosition="5637" endWordPosition="5640"> Ney, 2003) to Europarl (CL-WSD). To provide an answer for all instances, we return this most frequent translation even when no sense assignment is attempted – i.e., no sense of the target word is connected to any other sense of the context words – or a tie occurs. Results and discussion. We report our results for CL-LS and CL-WSD in Tables 3 and 4. We evaluate using the nouns-only subset of the CL-LS dataset and the full CL-WSD dataset, consisting of 300 and 1,000 instances of nouns in context, respectively. The evaluation scheme is based on the SemEval2007 English lexical substitution task (McCarthy and Navigli, 2009), and consists of an adaptation of the metrics of precision and recall for the translation setting. For each task, we compare our monolingual and multilingual approaches against the best performing SemEval systems for these tasks, namely UBA-T (Basile and Semeraro, 2010) and UVT-v (van Gompel, 2010) for CL-LS and CL-WSD, respectively, as well as a recent supervised proposal that exploits automatically generated multilingual features from parallel text and translated contexts (Lefever et al., 2011, Parasense). For each task we also report its official baseline, namely the first translation from</context>
</contexts>
<marker>McCarthy, Navigli, 2009</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2009. The English lexical substitution task. Language Resources and Evaluation, 43(2):139–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yashar Mehdad</author>
<author>Matteo Negri</author>
<author>Marcello Federico</author>
</authors>
<title>Using bilingual parallel corpora for crosslingual textual entailment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11),</booktitle>
<pages>1336--1345</pages>
<marker>Mehdad, Negri, Federico, 2011</marker>
<rawString>Yashar Mehdad, Matteo Negri, and Marcello Federico. 2011. Using bilingual parallel corpora for crosslingual textual entailment. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, (ACL-11), pages 1336–1345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M Meyer</author>
<author>Iryna Gurevych</author>
</authors>
<title>Ontowiktionary – Constructing an ontology from the collaborative online dictionary Wiktionary.</title>
<date>2012</date>
<booktitle>In Maria Teresa Pazienza and Armando Stellato, editors, Semi-Automatic Ontology Development: Processes and Resources. IGI Global,</booktitle>
<location>Hershey, Penn.</location>
<contexts>
<context position="6390" citStr="Meyer and Gurevych (2012)" startWordPosition="993" endWordPosition="996">osslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silberer and Ponzetto, 2010). However, this requirement is often very hard to satisfy, especially if we need wide coverage. To overcome this limitation, in this work we make use of BabelNet (Navigli and Ponzetto, 2010), a very large multilingual lexical knowledge base. This resource – complementary in nature to other recent efforts presented by de Melo and Weikum (2010), Nastase et al. (2010) and Meyer and Gurevych (2012), inter alia – provides a truly multilingual semantic network by combining Wikipedia’s multilinguality with the output of a state-of-the-art machine translation system to achieve high coverage for all languages. The key insight here is that Word Sense Disambiguation and Machine Translation (MT) are highly intertwined tasks, as previously shown by Carpuat and Wu (2007) and Chan et al. (2007), who successfully used sense information to boost state-of-the-art statistical MT. In this work we focus instead on the benefits of using multilingual information for WSD by exploiting the structure of a mu</context>
</contexts>
<marker>Meyer, Gurevych, 2012</marker>
<rawString>Christian M. Meyer and Iryna Gurevych. 2012. Ontowiktionary – Constructing an ontology from the collaborative online dictionary Wiktionary. In Maria Teresa Pazienza and Armando Stellato, editors, Semi-Automatic Ontology Development: Processes and Resources. IGI Global, Hershey, Penn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Ravi Sinha</author>
<author>Diana McCarthy</author>
</authors>
<title>Semeval-2010 task 2: Cross-lingual lexical substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>9--14</pages>
<contexts>
<context position="3456" citStr="Mihalcea et al., 2010" startWordPosition="531" endWordPosition="534">n remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics search on the topic has been done, including the use of statistical translations of sentences into many languages as features for supervised models (Banea and Mihalcea, 2011; Lefever et al., 2011), and the projection of monolingual knowledge onto another language (Khapra et al., 2011). Yet the above two goals, i.e., disambigua</context>
<context position="31705" citStr="Mihalcea et al., 2010" startWordPosition="5217" endWordPosition="5220">purpose in nature and, accordingly, does not use any domain information such as manually-labeled examples for the most frequent domain words (CFILT) or a domain-specific sense ranking (IIITH). 4.2 Cross-lingual lexical disambiguation Using a multilingual lexical resource makes it possible to perform WSD in any of its languages. Accordingly, we complement our evaluation on English texts with a second set of experiments where we quantify the impact of our approach on a lexical disambiguation task in a multilingual setting. To this end, we use the SemEval-2010 cross-lingual lexical substitution (Mihalcea et al., 2010, CL-LS, henceforth) and WSD (Lefever et al., 2011, CLWSD) tasks and evaluate our methodology on performing disambiguation across different languages. Both cross-lingual WSD tasks cast disambiguation as a word translation problem: given an English polysemous noun in context as input, the system disambiguates it by providing a translation into another language (translations are deemed correct if they preserve the meaning of the source word in the target language). Their main difference, instead, lies in the range of translations which are assumed to be valid: that is, while CL-LS assumes no pre</context>
</contexts>
<marker>Mihalcea, Sinha, McCarthy, 2010</marker>
<rawString>Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. Semeval-2010 task 2: Cross-lingual lexical substitution. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 9–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross Bunker</author>
</authors>
<title>A semantic concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the 3rd DARPA Workshop on Human Language Technology,</booktitle>
<pages>303--308</pages>
<contexts>
<context position="2536" citStr="Miller et al., 1993" startWordPosition="376" endWordPosition="379">ent languages would improve the quality of text understanding in arbitrary languages. However, these two goals have hitherto never been achieved, as is attested to by the fact that research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) has always been focused mostly on English. Historically, English became established as the language used and understood by the scientific community and, consequently, most resources were developed for it, including large-scale computational lexicons like WordNet (Fellbaum, 1998) and sensetagged corpora like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yar</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross Bunker. 1993. A semantic concordance. In Proceedings of the 3rd DARPA Workshop on Human Language Technology, pages 303–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
<author>Benjamin B¨orschinger</author>
<author>Caecilia Zirn</author>
<author>Anas Elghafari</author>
</authors>
<title>WikiNet: A very large scale multi-lingual concept network.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation, (LREC ’10).</booktitle>
<marker>Nastase, Strube, B¨orschinger, Zirn, Elghafari, 2010</marker>
<rawString>Vivi Nastase, Michael Strube, Benjamin B¨orschinger, Caecilia Zirn, and Anas Elghafari. 2010. WikiNet: A very large scale multi-lingual concept network. In Proceedings of the 7th International Conference on Language Resources and Evaluation, (LREC ’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Mirella Lapata</author>
</authors>
<title>An experimental study on graph connectivity for unsupervised Word Sense Disambiguation.</title>
<date>2010</date>
<journal>IEEE Transactions on Pattern Anaylsis and Machine Intelligence,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>692</pages>
<contexts>
<context position="9524" citStr="Navigli and Lapata, 2010" startWordPosition="1461" endWordPosition="1464"> automatically generated ones from sense-labeled data, BabelNet is able to achieve wide coverage for all its languages (Catalan, English, French, German, Italian and Spanish): accordingly, we chose it to perform graph-based WSD in a multilingual setting since it is specifically focused on lexical knowledge. In addition, BabelNet is available for any language required to perform standard SemEval cross-lingual disambiguation tasks (e.g., Spanish, in order to perform cross-lingual lexical substitution). Since previous work in knowledgebased WSD shows the benefits of using rich lexical resources (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010), BabelNet is a suitable choice for performing graph-based multilingual WSD. 3.2 Exploiting multilingual information in a knowledge-based WSD framework We present a multilingual approach to WSD which exploits three main factors: i) the fact that translations of a target word provide complementary information on the range of its candidate senses in context; Algorithm 1 Multilingual joint WSD Input: a word sequence Q = (w1, ... , w,,,) a target word w E Q BabelNet BN an ensemble method M Output: a distribution of scores for the senses of w (D indicates a comment) 1: </context>
<context position="19534" citStr="Navigli and Lapata (2010)" startWordPosition="3171" endWordPosition="3174"> is in fact the sense selected by our multilingual approach by means of combining the scoring distributions from all these graphs. 3.3 Graph-based WSD We use graph-based algorithms to exploit multilingual knowledge from BabelNet for WSD. These are a natural choice for our approach, since BabelNet is a semantic network, and such algorithms have been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011), as well as to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). To this end, we use the method of Navigli and Lapata (2010) and construct a directed graph G = (V, E) for an input word sequence Q = (w1, ... , wn)5 using the lexical and semantic relations found in BabelNet. The result of this procedure is a subgraph of BabelNet containing (1) the senses of the words in context, (2) all edges and intermediate senses found in BabelNet along all paths that connect them. Given G, a target word w E Q and its set of senses in BabelNet 5 C_ V , we compute a score distribution (score1, ... , score|S|) over 5, where scored refers to the confidence score for the j-th sense of w, e.g. bank2n, based on some connectivity measure</context>
<context position="21047" citStr="Navigli and Lapata, 2010" startWordPosition="3450" endWordPosition="3453">sed on the number of their incident edges, namely: scorej = |{{sj, v} E E : v E V I |. proposed by Brody et al. (2006), which they show to be the best performing for WSD. This method takes the scores associated with each term, normalizes and combines them by summing across distributions. Formally, it computes the score for the j-th sense of w as follows: This standard connectivity measure weights a sense as more appropriate if it has a higher degree. We chose context-based Degree since, albeit simple, it had previously been shown to yield a highly competitive performance on various WSD tasks (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010). Inverse path length sum (PLength): We then developed a graph connectivity measure which scores each sense by summing over the inverse length of all paths which connect it to other senses in the graph: �scorej = p E paths(sj) where paths(sj) is the set of simple paths connecting sj to the senses of other context words, length(p) is the number of edges in the path p and each path is scored with the exponential inverse decay of the path length. This measure overcomes the locality of Degree by aggregating over all paths between a sense of the target word and those of</context>
<context position="29532" citStr="Navigli and Lapata (2010)" startWordPosition="4861" endWordPosition="4864">as back-off strategy when no sense assignment is attempted. lations activate senses in the knowledge base which are closer to the senses of the context words. The result is an overall increase in F1 measure of 3.4 and 3.1 points for Degree and PLength, respectively, which makes it possible for us to beat the MFS baseline (notably a difficult competitor for WSD systems). Among the different graph algorithms, PLength consistently outperforms Degree: however, the differences are not statistically significant. In order to better understand the impact of our approach we follow previous work (e.g., Navigli and Lapata (2010)) and explore a weakly-supervised setting where the system attempts no sense assignment if the highest score among those assigned to the senses of a target word is below a certain threshold. If this is the case, in order to provide an answer for all items, we output the most frequent sense assigned by the system to other instances of the target word, and fall back to SemCor’s MFS if no assignment has been attempted. We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, </context>
</contexts>
<marker>Navigli, Lapata, 2010</marker>
<rawString>Roberto Navigli and Mirella Lapata. 2010. An experimental study on graph connectivity for unsupervised Word Sense Disambiguation. IEEE Transactions on Pattern Anaylsis and Machine Intelligence, 32(4):678– 692.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: Building a very large multilingual semantic network.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, (ACL-10),</booktitle>
<pages>216--225</pages>
<contexts>
<context position="6183" citStr="Navigli and Ponzetto, 2010" startWordPosition="960" endWordPosition="963"> uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silberer and Ponzetto, 2010). However, this requirement is often very hard to satisfy, especially if we need wide coverage. To overcome this limitation, in this work we make use of BabelNet (Navigli and Ponzetto, 2010), a very large multilingual lexical knowledge base. This resource – complementary in nature to other recent efforts presented by de Melo and Weikum (2010), Nastase et al. (2010) and Meyer and Gurevych (2012), inter alia – provides a truly multilingual semantic network by combining Wikipedia’s multilinguality with the output of a state-of-the-art machine translation system to achieve high coverage for all languages. The key insight here is that Word Sense Disambiguation and Machine Translation (MT) are highly intertwined tasks, as previously shown by Carpuat and Wu (2007) and Chan et al. (2007)</context>
<context position="7416" citStr="Navigli and Ponzetto, 2010" startWordPosition="1148" endWordPosition="1151">successfully used sense information to boost state-of-the-art statistical MT. In this work we focus instead on the benefits of using multilingual information for WSD by exploiting the structure of a multilingual semantic network. 3 Multilingual Joint WSD We present our methodology for multilingual WSD: we first introduce BabelNet, the resource used in our work (Section 3.1) and then present our algorithm for multilingual joint WSD (Section 3.2), including its main components, namely graph-based WSD, ensemble methods and translation weighting (sections 3.3, 3.4 and 3.5). 3.1 BabelNet BabelNet (Navigli and Ponzetto, 2010) follows the structure of a traditional lexical knowledge base and, accordingly, consists of a labeled directed graph whose nodes represent concepts and named entities, and whose edges express semantic relations between them. Concepts and relations are harvested from the largest available semantic lexicon of English, i.e., WordNet, and a wide-coverage collaborativelyedited encyclopedia, i.e., Wikipedia1, thus making BabelNet a multilingual ‘encyclopedic dictionary’ which combines lexicographic information with encyclopedic knowledge on the basis of an unsupervised mapping framework. In additio</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2010. BabelNet: Building a very large multilingual semantic network. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, (ACL-10), pages 216–225.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2012a BabelRelate</author>
</authors>
<title>A joint multilingual approach to computing semantic relatedness.</title>
<booktitle>In Proceedings of the 26th Conference on Artificial Intelligence (AAAI-12).</booktitle>
<marker>BabelRelate, </marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012a. BabelRelate! A joint multilingual approach to computing semantic relatedness. In Proceedings of the 26th Conference on Artificial Intelligence (AAAI-12).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Multilingual WSD with just a few lines of code: The BabelNet API.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, (ACL-12). System Demonstrations.</booktitle>
<contexts>
<context position="36833" citStr="Navigli and Ponzetto, 2012" startWordPosition="6037" endWordPosition="6040"> on all disambiguation tasks. 5 Conclusions In this paper we presented a multilingual joint approach to WSD. Key to our methodology is the effective use of a wide-coverage multilingual knowledge base, BabelNet, which we exploit to perform graph-based WSD across languages and combine complementary sense evidence from translations in different languages using an ensemble method. This is the first proposal to exploit structured multilingual information within a joint, knowledge-rich framework for WSD. The APIs to perform multilingual WSD using BabelNet are freely available for research purposes (Navigli and Ponzetto, 2012b). Thanks to multilingual joint WSD we achieve state-of-the-art performance on three different gold standards. The good news about these results is that not only can further advances be achieved by using multilingual lexical knowledge, but, more importantly, that combining multilingual sense evidence from different languages at the same time yields consistent improvements over a monolingual ap1407 French German Italian Spanish P/R/F1 P/R/F1 P/R/F1 P/R/F1 Baseline 21.25 13.16 15.18 19.74 UvT-v N/A N/A N/A 23.39 Parasense 24.54 16.88 18.03 22.80 Monolingual Degree 22.94 17.15 18.03 22.48 graph </context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012b. Multilingual WSD with just a few lines of code: The BabelNet API. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, (ACL-12). System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Stefano Faralli</author>
</authors>
<title>Aitor Soroa, Oier Lopez de Lacalle, and Eneko Agirre.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM-11),</booktitle>
<pages>2317--2320</pages>
<marker>Navigli, Faralli, 2011</marker>
<rawString>Roberto Navigli, Stefano Faralli, Aitor Soroa, Oier Lopez de Lacalle, and Eneko Agirre. 2011. Two birds with one stone: Learning semantic models for Text Categorization and Word Sense Disambiguation. In Proceedings of the 20th ACM Conference on Information and Knowledge Management (CIKM-11), pages 2317–2320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word Sense Disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="2192" citStr="Navigli, 2009" startWordPosition="326" endWordPosition="327">he different languages to improve text understanding. These two aspects are strongly intertwined: on the one hand, enabling language-independent text understanding would allow for the harvesting of more knowledge in arbitrary languages, while, on the other hand, bringing together the lexical and semantic information available in different languages would improve the quality of text understanding in arbitrary languages. However, these two goals have hitherto never been achieved, as is attested to by the fact that research in a core language understanding task such as Word Sense Disambiguation (Navigli, 2009, WSD) has always been focused mostly on English. Historically, English became established as the language used and understood by the scientific community and, consequently, most resources were developed for it, including large-scale computational lexicons like WordNet (Fellbaum, 1998) and sensetagged corpora like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). No</context>
<context position="34281" citStr="Navigli, 2009" startWordPosition="5639" endWordPosition="5640">o Europarl (CL-WSD). To provide an answer for all instances, we return this most frequent translation even when no sense assignment is attempted – i.e., no sense of the target word is connected to any other sense of the context words – or a tie occurs. Results and discussion. We report our results for CL-LS and CL-WSD in Tables 3 and 4. We evaluate using the nouns-only subset of the CL-LS dataset and the full CL-WSD dataset, consisting of 300 and 1,000 instances of nouns in context, respectively. The evaluation scheme is based on the SemEval2007 English lexical substitution task (McCarthy and Navigli, 2009), and consists of an adaptation of the metrics of precision and recall for the translation setting. For each task, we compare our monolingual and multilingual approaches against the best performing SemEval systems for these tasks, namely UBA-T (Basile and Semeraro, 2010) and UVT-v (van Gompel, 2010) for CL-LS and CL-WSD, respectively, as well as a recent supervised proposal that exploits automatically generated multilingual features from parallel text and translated contexts (Lefever et al., 2011, Parasense). For each task we also report its official baseline, namely the first translation from</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word Sense Disambiguation: A survey. ACM Computing Surveys, 41(2):1–69.</rawString>
</citation>
<citation valid="true">
<title>Computer-intensive methods for testing hypotheses: an introduction.</title>
<date>1989</date>
<editor>Eric W. Noreen, editor.</editor>
<publisher>John Wiley.</publisher>
<location>New York, N.Y.:</location>
<marker>1989</marker>
<rawString>Eric W. Noreen, editor. 1989. Computer-intensive methods for testing hypotheses: an introduction. New York, N.Y.: John Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="33665" citStr="Och and Ney, 2003" startWordPosition="5531" endWordPosition="5534">hm P/R/F1 Baseline 23.80 Monolingual Degree 30.52 graph PLength 30.64 Multilingual Degree 32.21 ensemble PLength 32.47 UBA-T 32.17 Table 3: Performance on SemEval-2010 lexical substitution (best results are bolded). most frequent translation found in the Babel synset. Given that the two tasks make different assumptions on the sense inventory (no fixed inventory for CLLS vs. Europarl-based for CL-WSD), the frequency of a translation is calculated as either the number of Babel synsets in which it occurs (CL-LS), or its frequency of alignment with the target word, as obtained by applying GIZA++ (Och and Ney, 2003) to Europarl (CL-WSD). To provide an answer for all instances, we return this most frequent translation even when no sense assignment is attempted – i.e., no sense of the target word is connected to any other sense of the context words – or a tie occurs. Results and discussion. We report our results for CL-LS and CL-WSD in Tables 3 and 4. We evaluate using the nouns-only subset of the CL-LS dataset and the full CL-WSD dataset, consisting of 300 and 1,000 instances of nouns in context, respectively. The evaluation scheme is based on the SemEval2007 English lexical substitution task (McCarthy an</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Okumura</author>
<author>Kiyoaki Shirai</author>
<author>Kanako Komiya</author>
<author>Hikaru Yokono</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 task: Japanese WSD. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>69--74</pages>
<contexts>
<context position="2788" citStr="Okumura et al., 2010" startWordPosition="424" endWordPosition="427">mbiguation (Navigli, 2009, WSD) has always been focused mostly on English. Historically, English became established as the language used and understood by the scientific community and, consequently, most resources were developed for it, including large-scale computational lexicons like WordNet (Fellbaum, 1998) and sensetagged corpora like SemCor (Miller et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, </context>
</contexts>
<marker>Okumura, Shirai, Komiya, Yokono, 2010</marker>
<rawString>Manabu Okumura, Kiyoaki Shirai, Kanako Komiya, and Hikaru Yokono. 2010. SemEval-2010 task: Japanese WSD. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 69–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeynep Orhan</author>
<author>Emine C¸elik</author>
<author>Demirg¨uc¸ Neslihan</author>
</authors>
<title>SemEval-2007 task 12: Turkish lexical sample task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>59--63</pages>
<marker>Orhan, C¸elik, Neslihan, 2007</marker>
<rawString>Zeynep Orhan, Emine C¸elik, and Demirg¨uc¸ Neslihan. 2007. SemEval-2007 task 12: Turkish lexical sample task. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 59–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Christiane Fellbaum</author>
<author>Scott Cotton</author>
<author>Lauren Delfs</author>
<author>Hoa Trang Dang</author>
</authors>
<title>English tasks: All-words and verb lexical sample.</title>
<date>2001</date>
<booktitle>In Proceedings of the 2nd International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2),</booktitle>
<pages>21--24</pages>
<contexts>
<context position="30096" citStr="Palmer et al., 2001" startWordPosition="4960" endWordPosition="4963">we follow previous work (e.g., Navigli and Lapata (2010)) and explore a weakly-supervised setting where the system attempts no sense assignment if the highest score among those assigned to the senses of a target word is below a certain threshold. If this is the case, in order to provide an answer for all items, we output the most frequent sense assigned by the system to other instances of the target word, and fall back to SemCor’s MFS if no assignment has been attempted. We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004) English all-words datasets. The results for this setting are shown in Table 2, where we also compare with the top-performing systems from the SemEval competition, namely CFILT (Kulkarni et al., 2010) and IIITH (Reddy et al., 2010). By complementing our multilingual method with the MFS heuristic we achieve a performance comparable with the state of the art on this task. Again, the multilingual ensemble approach consistently outperforms the monolingual one and enables us to achieve the best overall results for this dataset: without multilingual informati</context>
</contexts>
<marker>Palmer, Fellbaum, Cotton, Delfs, Dang, 2001</marker>
<rawString>Martha Palmer, Christiane Fellbaum, Scott Cotton, Lauren Delfs, and Hoa Trang Dang. 2001. English tasks: All-words and verb lexical sample. In Proceedings of the 2nd International Workshop on Evaluating Word Sense Disambiguation Systems (SENSEVAL-2), pages 21–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Paolo Ponzetto</author>
<author>Roberto Navigli</author>
</authors>
<title>Knowledge-rich Word Sense Disambiguation rivaling supervised system.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, (ACL-10),</booktitle>
<pages>1522--1531</pages>
<contexts>
<context position="9553" citStr="Ponzetto and Navigli, 2010" startWordPosition="1465" endWordPosition="1468">nes from sense-labeled data, BabelNet is able to achieve wide coverage for all its languages (Catalan, English, French, German, Italian and Spanish): accordingly, we chose it to perform graph-based WSD in a multilingual setting since it is specifically focused on lexical knowledge. In addition, BabelNet is available for any language required to perform standard SemEval cross-lingual disambiguation tasks (e.g., Spanish, in order to perform cross-lingual lexical substitution). Since previous work in knowledgebased WSD shows the benefits of using rich lexical resources (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010), BabelNet is a suitable choice for performing graph-based multilingual WSD. 3.2 Exploiting multilingual information in a knowledge-based WSD framework We present a multilingual approach to WSD which exploits three main factors: i) the fact that translations of a target word provide complementary information on the range of its candidate senses in context; Algorithm 1 Multilingual joint WSD Input: a word sequence Q = (w1, ... , w,,,) a target word w E Q BabelNet BN an ensemble method M Output: a distribution of scores for the senses of w (D indicates a comment) 1: S +— SynsetsBN(w) 2: T +— fw}</context>
<context position="19473" citStr="Ponzetto and Navigli, 2010" startWordPosition="3159" endWordPosition="3162">he correct one – i.e., bankENn as financial institution – which is in fact the sense selected by our multilingual approach by means of combining the scoring distributions from all these graphs. 3.3 Graph-based WSD We use graph-based algorithms to exploit multilingual knowledge from BabelNet for WSD. These are a natural choice for our approach, since BabelNet is a semantic network, and such algorithms have been shown to achieve high performance across domains (Agirre et al., 2009; Navigli et al., 2011), as well as to compete with supervised methods on a variety of lexical disambiguation tasks (Ponzetto and Navigli, 2010). To this end, we use the method of Navigli and Lapata (2010) and construct a directed graph G = (V, E) for an input word sequence Q = (w1, ... , wn)5 using the lexical and semantic relations found in BabelNet. The result of this procedure is a subgraph of BabelNet containing (1) the senses of the words in context, (2) all edges and intermediate senses found in BabelNet along all paths that connect them. Given G, a target word w E Q and its set of senses in BabelNet 5 C_ V , we compute a score distribution (score1, ... , score|S|) over 5, where scored refers to the confidence score for the j-t</context>
<context position="21076" citStr="Ponzetto and Navigli, 2010" startWordPosition="3454" endWordPosition="3457"> incident edges, namely: scorej = |{{sj, v} E E : v E V I |. proposed by Brody et al. (2006), which they show to be the best performing for WSD. This method takes the scores associated with each term, normalizes and combines them by summing across distributions. Formally, it computes the score for the j-th sense of w as follows: This standard connectivity measure weights a sense as more appropriate if it has a higher degree. We chose context-based Degree since, albeit simple, it had previously been shown to yield a highly competitive performance on various WSD tasks (Navigli and Lapata, 2010; Ponzetto and Navigli, 2010). Inverse path length sum (PLength): We then developed a graph connectivity measure which scores each sense by summing over the inverse length of all paths which connect it to other senses in the graph: �scorej = p E paths(sj) where paths(sj) is the set of simple paths connecting sj to the senses of other context words, length(p) is the number of edges in the path p and each path is scored with the exponential inverse decay of the path length. This measure overcomes the locality of Degree by aggregating over all paths between a sense of the target word and those of the context words, thus bein</context>
</contexts>
<marker>Ponzetto, Navigli, 2010</marker>
<rawString>Simone Paolo Ponzetto and Roberto Navigli. 2010. Knowledge-rich Word Sense Disambiguation rivaling supervised system. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, (ACL-10), pages 1522–1531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siva Reddy</author>
<author>Abhilash Inumella</author>
<author>Diana McCarthy</author>
<author>Mark Stevenson</author>
</authors>
<title>IIITH: Domain specific Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>387--391</pages>
<contexts>
<context position="30368" citStr="Reddy et al., 2010" startWordPosition="5004" endWordPosition="5007">der to provide an answer for all items, we output the most frequent sense assigned by the system to other instances of the target word, and fall back to SemCor’s MFS if no assignment has been attempted. We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004) English all-words datasets. The results for this setting are shown in Table 2, where we also compare with the top-performing systems from the SemEval competition, namely CFILT (Kulkarni et al., 2010) and IIITH (Reddy et al., 2010). By complementing our multilingual method with the MFS heuristic we achieve a performance comparable with the state of the art on this task. Again, the multilingual ensemble approach consistently outperforms the monolingual one and enables us to achieve the best overall results for this dataset: without multilingual information, in fact, we achieve only average performance above the MFS level, whereas by effectively combining sense evidence from multilingual translations we are able to boost the F1 measure by a 6-8 point margin, and thus outperform the topranking SemEval systems. While differ</context>
</contexts>
<marker>Reddy, Inumella, McCarthy, Stevenson, 2010</marker>
<rawString>Siva Reddy, Abhilash Inumella, Diana McCarthy, and Mark Stevenson. 2010. IIITH: Domain specific Word Sense Disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 387–391.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>Distinguishing systems and distinguishing senses: new evaluation methods for Word Sense Disambiguation.</title>
<date>1999</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="3148" citStr="Resnik and Yarowsky, 1999" startWordPosition="485" endWordPosition="488"> et al., 1993). As a result WSD in other languages was hindered by a lack of resources, which in turn led to poor results or low involvement on the part of the research community (Magnini et al., 2004; M`arquez et al., 2004; Orhan et al., 2007; Okumura et al., 2010). Nonetheless, already in the 1990s it had been remarked that WSD could be improved by means of multilingual information: a recurring idea proposed by several researchers was that plausible translations of a word in context would restrict its possible senses to a manageable subset of meanings (Dagan et al., 1991; Gale et al., 1992; Resnik and Yarowsky, 1999). While the lack of resources at that time hampered the development of effective multilingual approaches to WSD, recently this idea has been revamped with the organization of SemEval tasks dealing with cross-lingual WSD (Lefever and Hoste, 2010) and cross-lingual lexical substitution (Mihalcea et al., 2010). At the same time, new re1399 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1399–1410, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics search on the topic </context>
</contexts>
<marker>Resnik, Yarowsky, 1999</marker>
<rawString>Philip Resnik and David Yarowsky. 1999. Distinguishing systems and distinguishing senses: new evaluation methods for Word Sense Disambiguation. Journal of Natural Language Engineering, 5(2):113–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carina Silberer</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>UHD: Cross-lingual Word Sense Disambiguation using multilingual co-occurrence graphs.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>134--137</pages>
<contexts>
<context position="5993" citStr="Silberer and Ponzetto, 2010" startWordPosition="929" endWordPosition="932">000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those which exploit existing multilingual WordNetlike resources (Ide et al., 2002), or use automatically induced multilingual co-occurrence graphs (Silberer and Ponzetto, 2010). However, this requirement is often very hard to satisfy, especially if we need wide coverage. To overcome this limitation, in this work we make use of BabelNet (Navigli and Ponzetto, 2010), a very large multilingual lexical knowledge base. This resource – complementary in nature to other recent efforts presented by de Melo and Weikum (2010), Nastase et al. (2010) and Meyer and Gurevych (2012), inter alia – provides a truly multilingual semantic network by combining Wikipedia’s multilinguality with the output of a state-of-the-art machine translation system to achieve high coverage for all la</context>
</contexts>
<marker>Silberer, Ponzetto, 2010</marker>
<rawString>Carina Silberer and Simone Paolo Ponzetto. 2010. UHD: Cross-lingual Word Sense Disambiguation using multilingual co-occurrence graphs. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 134–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The English all-words task.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),</booktitle>
<pages>41--43</pages>
<contexts>
<context position="30137" citStr="Snyder and Palmer, 2004" startWordPosition="4966" endWordPosition="4969">i and Lapata (2010)) and explore a weakly-supervised setting where the system attempts no sense assignment if the highest score among those assigned to the senses of a target word is below a certain threshold. If this is the case, in order to provide an answer for all items, we output the most frequent sense assigned by the system to other instances of the target word, and fall back to SemCor’s MFS if no assignment has been attempted. We estimate the optimal value for the threshold by maximizing F1 on a development set obtained by combining the Senseval-2 (Palmer et al., 2001) and Senseval-3 (Snyder and Palmer, 2004) English all-words datasets. The results for this setting are shown in Table 2, where we also compare with the top-performing systems from the SemEval competition, namely CFILT (Kulkarni et al., 2010) and IIITH (Reddy et al., 2010). By complementing our multilingual method with the MFS heuristic we achieve a performance comparable with the state of the art on this task. Again, the multilingual ensemble approach consistently outperforms the monolingual one and enables us to achieve the best overall results for this dataset: without multilingual information, in fact, we achieve only average perf</context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The English all-words task. In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), pages 41–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarten van Gompel</author>
</authors>
<title>UvT-WSD1: A crosslingual word sense disambiguation system.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010),</booktitle>
<pages>238--241</pages>
<marker>van Gompel, 2010</marker>
<rawString>Maarten van Gompel. 2010. UvT-WSD1: A crosslingual word sense disambiguation system. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2010), pages 238–241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Word Sense Disambiguation for all words without hard labor.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-09),</booktitle>
<pages>1616--1622</pages>
<contexts>
<context position="5223" citStr="Zhong and Ng, 2009" startWordPosition="811" endWordPosition="814">the meaning of a target word in context, and subsequent integration of these various pieces enables them to (soft) constrain each other. The results show that this way we are able to improve over previous, highperforming graph-based methods in both a monolingual and multilingual setting, thus showing for the first time the beneficial effects of exploiting multilingual knowledge in a joint fashion. 2 Related Work Parallel corpora have been used in the literature for the automatic creation of a sense-tagged dataset for supervised WSD in different languages (Gale et al., 1992; Chan and Ng, 2005; Zhong and Ng, 2009). Other approaches include the use of a coherence index for identifying the tendency to lexicalize senses differently across languages (Ide, 2000) and the clustering of source words which translate into the same target word, then used to perform WSD using a similarity measure (Diab, 2003). A historical approach (Brown et al., 1991) uses bilingual corpora to perform unsupervised word alignment and determine the most appropriate translation for a target word from a set of contextual features. All the above approaches to multilingual or crosslingual WSD rely on bilingual corpora, including those </context>
</contexts>
<marker>Zhong, Ng, 2009</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2009. Word Sense Disambiguation for all words without hard labor. In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI-09), pages 1616–1622.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>