<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000843">
<title confidence="0.997857">
Learning Constraints for Consistent Timeline Extraction
</title>
<author confidence="0.992">
David McClosky and Christopher D. Manning
</author>
<affiliation confidence="0.875934333333333">
Natural Language Processing Group
Computer Science Department
Stanford University, Stanford, CA, USA
</affiliation>
<email confidence="0.998826">
{mcclosky,manning}@stanford.edu
</email>
<sectionHeader confidence="0.995639" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994225">
We present a distantly supervised system for
extracting the temporal bounds offluents (re-
lations which only hold during certain times,
such as attends school). Unlike previous
pipelined approaches, our model does not as-
sume independence between each fluent or
even between named entities with known con-
nections (parent, spouse, employer, etc.). In-
stead, we model what makes timelines of flu-
ents consistent by learning cross-fluent con-
straints, potentially spanning entities as well.
For example, our model learns that someone
is unlikely to start a job at age two or to marry
someone who hasn’t been born yet. Our sys-
tem achieves a 36% error reduction over a
pipelined baseline.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993081733333333">
Many information extraction (IE) systems tradition-
ally extracted just relations, but a great many real
world relations such as attends school or has spouse
vary over time. To capture this, some recent IE
systems have extended their focus from relations to
fluents (relations combined with temporal bounds).
This can be seen in the temporal slot filling track in
the TAC-KBP 2011 shared task (Ji et al., 2011). A
direct application of this work is the automatic im-
provement of online resources such as Freebase and
Wikipedia infoboxes. Indirect applications include
question answering systems.
Fluents can be grouped together to form time-
lines (see Figure 1 for an example) and provide eas-
ily capturable consistency constraints. Our goal is
</bodyText>
<figureCaption confidence="0.99744475">
Figure 1: A timeline of two named entities. Each time
span represents afluent (a relation with temporal bounds).
Temporal bounds are denoted by spans on the timeline.
Fluents can create links between entities (e.g., marriage).
</figureCaption>
<bodyText confidence="0.999975833333333">
to learn these constraints and use them to produce
more accurate timelines of significant events for
people and organizations. For example, it is com-
mon knowledge that someone cannot attend a school
if they haven’t been born yet. Constraints on con-
sistent timelines do not need to be hard constraints,
though: it is rare, although possible, to become the
CEO of a company at the age of 21.
Despite the rich constraints on valid timelines,
there is relatively little work on exploiting these con-
straints for mutual disambiguation. Many existing
systems extract different parts of a timeline sepa-
rately and use heuristics to combine them. These
heuristics tend to optimize only local consistency
(within a single fluent) but ignore more global con-
straints across fluents (e.g., attending a school be-
fore being born) or across fluents of two linked
entities (e.g., attending a school before the school
was founded). In this work, we explore using joint
inference to enforce these constraints. We show
that these techniques can yield substantial improve-
ments. Additionally, our general approach is not
specific to extracting temporal boundaries of fluents.
It could easily be applied to other IE systems which
</bodyText>
<page confidence="0.983795">
873
</page>
<bodyText confidence="0.920372">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 873–882, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
employ independent extractions followed by heuris-
tics to improve consistency.
people and organizations, we add a special fluent,
lifespan, which doesn’t take a slot value.3 A list of
fluents we use are listed in Table 3.
</bodyText>
<sectionHeader confidence="0.598927" genericHeader="introduction">
2 The timelining task
</sectionHeader>
<bodyText confidence="0.999956902439024">
As a basis for our task, we first describe the Tempo-
ral KBP task (Ji et al., 2011). As input, one is given
a list of queries, a database of example fluents, and
source documents. Queries are named entities (peo-
ple or organizations) with their gold relations but no
temporal bounds. The database consists of training
entities with their fluents, including known tempo-
ral bounds for each fluent. Example fluents can be
seen in Table 1. Note that the database may be in-
complete. In addition to missing fluents for an en-
tity, some temporal bounds may be missing from
the database; missing bounds are unfortunately in-
distinguishable from unbounded ranges. As a result,
we can only trust concrete temporal boundaries in
the database. Source documents consist of raw text
from news, blogs, and Wikipedia articles. For each
fluent, systems must output their predicted temporal
bounds, along with references to source documents
to provide provenance.
Our task is a variation of the Temporal KBP task.
In our case, the database is a collection of Freebase1
entities and their fluents, merged with Wikipedia in-
foboxes. Each entity has a unique ID, allowing us
to avoid some coreference issues (though there can
still be issues in document retrieval). In Temporal
KBP, the temporal representation allows for upper
and lower bounds on both the event start and end:
(sl, su, el, eu) where sl &lt; start &lt; su, el &lt; end &lt;
eu. However, it is difficult to obtain these bounds
without manual annotation. As a result, we opted for
the simpler representation which can be easily found
in databases like Freebase. Our temporal represen-
tation is limited to bounds of the form (start, end)
where either can be unbounded or unknown (both
represented as foo).
Our set of fluents is closely related to those in
the Temporal KBP task. Our goal was to use
as much temporal information as possible, with
the hope of each fluent providing additional poten-
tial constraints. While we omit the resides in and
member of fluents,2 we add several others. For
</bodyText>
<footnote confidence="0.999202">
1http://freebase.org
2This is because these fluents are rarely present in Freebase
</footnote>
<sectionHeader confidence="0.978732" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.99347941025641">
To operate on a set of queries, we first collect can-
didate temporal expression mentions for each fluent
from our source documents. This limits us to us-
ing temporal expression mentions which appear near
fluent mentions in text. It also ensures that we can
provide provenance for each temporal boundary as-
sertion. This process is described in §3.1.
Our model contains two components, both of
which assign probabilities to timelines. The clas-
sifier component determines how each candidate
temporal expression mention connects to its fluent
(§3.2). For example, the mention may indicate the
START of the fluent, the END, both its START AND
END (for instantaneous events), or be UNRELATED.
These connections involve relations between tempo-
ral expression mentions and relations and we refer to
them as metarelations.4 For features, the classifier
uses the surrounding textual and syntactic context of
temporal expression and fluent mentions. Each clas-
sification decision is made independently, allowing
for inconsistency at multiple levels (within a fluent,
across fluents, or across entities). However, using
joint inference, the classifier component can deter-
mine the best overall span for each fluent.
The consistency component learns what makes
timelines consistent (§3.3). It is similar in nature to
a language model for timelines instead of sentences.
Given a candidate timeline, the consistency compo-
nent estimates its probability of occurring. This is
done by decomposing timelines into a series of ques-
tions (such as “did the entity go to school before
starting a job?”) and learning the probabilities of
different answers from training data.
Unlike the classifier component, the consistency
component is blind to the underlying text in the
source documents. The two components work to-
gether to find a global timeline that is both based on
textual evidence and coherent across entities using
with temporal bounds.
</bodyText>
<footnote confidence="0.99685725">
3Note that this is a relation in the non-temporal KBP task.
4Other metarelations are possible under more complex tem-
poral representations. For example, Artiles et al. (2011) uses
the HOLDS metarelation.
</footnote>
<page confidence="0.995241">
874
</page>
<table confidence="0.999153">
Entity Relation Slot value Temporal bounds
Jon Stewart lifespan — [1962-11-28, +oo)
/en/jon stewart
Jon Stewart has parent [1962-11-28, +oo)
/en/jon stewart Donald Leibowitz
/en/donald leibowitz
Jon Stewart attends school College of William and Mary (_oo, 1984]
/en/jon stewart /en/college of william and mary
Jon Stewart has spouse [2000-11, +oo)
/en/jon stewart Tracey McShane
/en/tracy mcshane
</table>
<tableCaption confidence="0.832278">
Table 1: Example relations with their temporal bounds. Freebase IDs are shown in monospace. Note that temporal
bounds differ in their resolution (some are days of the year, others are only years). Some bounds are unknown (e.g.,
the start of the attends school fluent) and indistinguishable from unbounded. The lifespan fluent is a unary relation.
</tableCaption>
<bodyText confidence="0.9937455">
joint inference (note that they are trained indepen-
dently). The inference process is described in §3.4.
</bodyText>
<subsectionHeader confidence="0.995429">
3.1 Temporal expression retrieval
</subsectionHeader>
<bodyText confidence="0.999938227272727">
Given a fluent, we search for all textual mentions
of the fluent and collect nearby temporal expression
mentions. These temporal expressions are used as
candidate boundaries for the fluent in later steps.
The search process assumes that if a fluent’s entity
and slot value co-occur in a sentence,5 that sentence
is typically a positive example of the fluent.6 This
is sometimes known as distant supervision (Craven
and Kumlien, 1999; Mintz et al., 2009). We use
the Stanford Core NLP suite (Toutanova et al., 2003;
Finkel et al., 2005; Klein and Manning, 2003; Lee et
al., 2011) to annotate each document with POS and
NER tags, parse trees, and coreference chains. On
top of this, we apply a rule-based temporal expres-
sion extractor (Chang and Manning, 2012). Since
we have coreference links, we also search docu-
ments for anything coreferent with the fluent’s en-
tity.
The temporal expression extractor handles most
standard date and time formats. For each document,
one can provide an optional reference time. For
underspecified dates, the reference time is used to
</bodyText>
<footnote confidence="0.998868222222222">
5While we limit our scope to sentences in this work, it is
trivial to extend this to larger regions such as paragraphs.
6The lifespan fluent requires special handling. Ideally, its
candidates would be provided by a relation extraction mention
detector (e.g., a KBP system). For this work, we use the gold
lifespan bounds as slot values for the purpose of document re-
trieval. While this does heavily bias the system towards using
gold bounds, the system still must predict the correct associa-
tions (START, END, etc.) making the lifespan fluent non-trivial.
</footnote>
<bodyText confidence="0.999952315789474">
resolve these dates to full expressions if possible.
Some of our documents are news articles, where we
use the publication date as the reference time. Other
documents, e.g., Wikipedia articles, are undated and
we typically omit a reference time for these. We ex-
clude dates which are not uniquely resolvable (e.g.,
“September 15th,” when the reference date is un-
known) since our task requires us to output unam-
biguous dates.
We create training datums by computing the
metarelation between each temporal expression and
its gold fluent. For example, for the temporal
expression mention “September 15th, 1981” and
gold lifespan relation that spans [1981-09-15,
+oo), we would assign the START metarelation. As
a heuristic, we allow for underspecified matches.
Thus, both “1981” and “September 1981” would
have the START metarelation but “September 2nd,
1981” would be assigned UNRELATED.
</bodyText>
<subsectionHeader confidence="0.999441">
3.2 Classifier component
</subsectionHeader>
<bodyText confidence="0.999618">
We use a classifier to determine the nature of the
link between fluents and candidate temporal expres-
sion mentions. Our classifier (a standard multi-
class maximum entropy classifier) learns a function
C : (t, f) M where t is a temporal expression
mention, f = (entity, relation name, slot value) is
a fluent from the database, and M is the set of the
four possible metarelations.
Features for the classifier include many of those
in Artiles et al. (2011). These include standard re-
lation extraction features such as the dependency
paths between the temporal expression and the en-
tity or slot value. We use both the original depen-
</bodyText>
<page confidence="0.991769">
875
</page>
<bodyText confidence="0.999972964285714">
dency paths and their collapsed Stanford Dependen-
cies forms (de Marneffe and Manning, 2008). We
include the lengths of each path and, if the path is
shorter than four edges, the grammatical relations,
words, POS tags, and NER labels along the path.
We extract the same sorts of features from surface
paths (i.e., the words and tags between the entity and
the temporal expression) if the path is five tokens or
shorter. For temporal expressions, we include their
century and decade as features. These features act as
a crude prior over when valid temporal expressions
occur. There are also features for the precision of
the temporal expression (year only, has month, and
has day). Lastly, we include the relation name itself
as a feature.
Previous work (Artiles et al., 2011) heuristically
aggregates the hard decisions from their classifier to
create a locally consistent span. The basic aggre-
gation model (described in §4.2) is similar to their
method. In contrast, our method uses the likeli-
hood of complete spans to ensure both boundaries
are consistent with the text.
To calculate the likelihood of a specific temporal
span for a fluent f, we represent the span as a
series of metarelations and take the product of their
probabilities. For example, if the candidate span is
[1981-09-15, +o0) and we have two temporal
expressions, “September 15th, 1981” and “2012”:
</bodyText>
<equation confidence="0.999221666666667">
P(span(f) = [1981-09-15, +o0)  |f) =
P(C(“September 15th, 1981”, f) = START)x
P(C(“2012”, f) =UNRELATED)
</equation>
<bodyText confidence="0.998908333333333">
This can easily be extended to calculating the joint
probability of an entire timeline, represented as a list
of (fluent, span) pairs:
</bodyText>
<equation confidence="0.7382485">
PCC ((f1, s1), . . . ) = 11 P(span(fi) = si  |fi)
i
</equation>
<bodyText confidence="0.9998425">
We refer to this model as the Combined Classifier
(CC) since it uses the probabilities of all timelines
boundaries rather than aggregating hard local deci-
sions.
</bodyText>
<subsectionHeader confidence="0.999351">
3.3 Consistency component
</subsectionHeader>
<bodyText confidence="0.999931479166667">
While distant supervision can be used to create im-
plicit negative examples for the classifier component
(time expressions marked as UNRELATED), we do
not have an equivalent technique to reliably create
negative examples for the consistency component
(examples of inconsistent timelines). Instead, we
only have positive examples of consistent timelines
from the database. As a result, we must treat predict-
ing consistency as a density estimation rather than a
classification problem.
Our consistency component is designed to be as
general as possible – it does not even include basic
constraints about timelines such as “starts are before
ends.” Instead, we provide several simple templates
for temporal constraints to allow it to learn these ba-
sic tendencies as well as more complex ones. Ex-
amples include whether one typically goes to school
first or starts their first job, how many jobs people
typically have at one time, or if it is possible to marry
someone who hasn’t been born yet.
We achieve this by decomposing timelines
into a series of probabilistic events, or ques-
tions. As an example, one question about
the timeline shown in Table 1 is whether Jon
Stewart graduated from the College of William
and Mary BEFORE marrying Tracey McShane,
i.e., end(attends school) &lt; start(has spouse). In this
case, the answer is “yes.” More generally, we
can apply the BEFORE template to all bound-
aries of all fluents: boundary1(fluent1) &lt;
boundary2(fluent2). We use templates like these
(denoted by SMALL CAPS) to generate all possible
questions to ask about a specific entity.
Other questions can be asked at the fluent level
rather than the boundary level (Allen, 1983). One
set of fluent level questions asks whether two flu-
ents’ spans OVERLAP. For example, in Table 1, Jon
Stewart’s lifespan OVERLAPs with the span of his
has spouse fluent. Other sets of fluent level ques-
tions ask whether the span of a fluent completely
CONTAINS the span of another one, whether a flu-
ent is COMPLETELY BEFORE another fluent, and
whether two fluents TOUCH (the start of one fluent
is the same as the end of another).
Since all of these questions involve ordering but
ignore the actual differences in time, we create one
more set of questions asking whether two bound-
aries are WITHIN a certain number of years:
</bodyText>
<equation confidence="0.801587">
|boundary1(fluent1) − boundary2(fluent2) |&lt; K
</equation>
<page confidence="0.972791">
876
</page>
<bodyText confidence="0.9994534">
for K E 11, 2, 4, 8,16}. The aim is to approxi-
mate the typical lengths of a single fluent or amount
of time between boundaries from different fluents.
There is nothing which requires that the flu-
ents in question come from a single entity. Thus,
we can trivially ask questions about two entities
which are linked by a fluent. For example, since
Jon Stewart is linked to Tracey McShane by the
has spouse fluent (Table 1), we could ask the ques-
tion of whether Jon Stewart’s lifespan OVERLAPS
Tracey McShane’s lifespan. We can ask any type
of question about two linked entities and distinguish
the questions by prefixing them with the nature of
the link (has spouse in this case).
Note that not all questions can be answered since
they may rely on comparing unknown values. This
is because (for our setup) infinite values are indistin-
guishable from unknown values. For example, the
start of the Jon Stewart’s attends school fluent is un-
defined in the database, but clearly not actually −00.
Thus, we add a third possible answer to each ques-
tion: unknown. The answers to boundary level ques-
tions are defined only if both boundaries are finite.
Fluent level questions have known answers as long
as both fluents have at least one finite value.
To train our model, we gather the answers to ques-
tions over all the fluents from training entities. Each
question forms a multinomial over the three possible
values (yes, no, unknown). To determine the proba-
bility of a complete timeline:
</bodyText>
<equation confidence="0.9985112">
Pc�nsistency(timeline) =
�
H (1 − c)PB(a  |q) q is old
c q is new
(q,a)∈Q(timeline)
</equation>
<bodyText confidence="0.999962925925926">
where Q(·) generates all possible
(question, answer) pairs which are consistent
with the fluents in the timeline, 0 is a vector of the
model parameters, and c is a smoothing parameter
(described below).
To learn the model parameters, we start by us-
ing maximum-likelihood estimation for these multi-
nomials from training entities. However, some
smoothing is required since new entities may con-
tain previously unseen answers to existing ques-
tions. To address this, we apply add-A smoothing
to each multinomial, PB(a  |q). Additionally, it is
possible to see entirely new questions when we see
a new combination of fluent types. We reserve an
amount of probability mass for new questions, c. c
and A are estimated in turn by picking the value that
maximizes the likelihood of the timeline made by
the development entities.
To adjust the weight of the consistency compo-
nent relative to the classifier component, we take
the geometric mean of the likelihood using the to-
tal number of questions, |Q(t)|, as the exponent and
raise the resulting mean to an exponent, Q. This is
necessary since the two components essentially op-
erate on different scales. The Joint Classifier with
Consistency (JCC) model calculates the score of a
timeline, t, according to both components:
</bodyText>
<equation confidence="0.37675">
a
score JCC (t) = PCC (t) 1P.nsistency (t) |Q(t)|
</equation>
<sectionHeader confidence="0.858693" genericHeader="method">
3.4 Inference
</sectionHeader>
<bodyText confidence="0.99963825">
Inference for the CC model is relatively simple:
Simply pick the most likely span for each fluent.
Since it assumes all fluents are independent, the
bounds for each fluent can be inferred separately.
To perform inference on a specific fluent, we con-
sider all of its possible temporal spans, limited by
the temporal expression mentions found by the re-
trieval system (§3.1). Each possible span assigns one
of the four metarelations to each candidate temporal
expression for the fluent. For example, if we found
only the temporal expression mention “1981” for a
specific fluent, there are four possible spans:
</bodyText>
<table confidence="0.8776695">
UNRELATED: (−00, +00)
START: [1981-01-01, +00)
END: (−00, 1981-12-31]
START AND END: [1981-01-01, 1981-12-31]
</table>
<bodyText confidence="0.998579153846154">
Note that when we assign “1981” as a start, we
use the earliest possible time (January 1st) while
when we assign it as an end, we use the latest pos-
sible time (December 31st). Of course, we typi-
cally have multiple candidate temporal expressions
and thus potentially many more than four possible
spans. All temporal expression mentions that re-
solve to the same time are grouped together, since it
wouldn’t make sense to assign “August 28th, 2010”
one metarelation and a different one to “8/28/2010.”
Joint inference for the JCC model is a little more
involved since the consistency model does not as-
sume independence across fluents. Thus, we need
</bodyText>
<page confidence="0.987463">
877
</page>
<bodyText confidence="0.999969818181818">
to apply techniques like Gibbs sampling or random-
restart hillclimbing (RRHC) to determine the opti-
mal temporal spans for each fluent. For our task,
the two methods obtain similar performance while
RRHC requires many fewer iterations so our discus-
sion focuses on the latter. RRHC involves looping
over all fluents in our testing entities, shuffling the
order of the fluents at the beginning of each pass.
We maintain a working timeline, t, with our current
guesses of the spans for each fluent. For each fluent
and span (f, s) E t, we pick the optimal span for f:
</bodyText>
<equation confidence="0.996807">
s* = arg max scoreJCC (ts′)
s′ES(f)
</equation>
<bodyText confidence="0.999994411764706">
where S(f) determines all possible temporal
spans for the fluent f and ts′ = (t U (f, s′)) − (f, s)
is a copy of t where s′ is the span for f instead
of s. After selecting s*, we add it to our timeline:
tnew = (t U (f, s*)) − (f, s). Rather than calculat-
ing the score of the full timeline, we can save time by
using only the relevant fluents in ts′. For example,
if our fluent is the has spouse fluent for Jon Stew-
art, we include all the fluents involving Jon Stewart
and any relevant linked entities. In this case, we also
include all the fluents for Tracey McShane.
Each round of RRHC consists of two passes
through the fluents we are inferring: An arg max
pass followed by a randomization pass where we
randomly choose spans for a random fraction of the
fluents. When finished, we return the highest scor-
ing timeline seen during either of these passes.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999986909090909">
We evaluate our models (CC and JCC) according to
their ability to predict the temporal bounds of flu-
ents from Freebase. This is similar to the Diagnostic
Track in the Temporal KBP task, where gold rela-
tions are provided as inputs. We provide three base-
lines for comparison, discussed further in §4.2. To
form our database, we scraped a random sample of
people and organization entities from Freebase us-
ing their API. Since our consistency model has lim-
ited effect if entities do not have any links to other
entities, we restrict our attention to entities linked
to at least one other entity – this eliminates a large
portion of possible entities. Our corpus7 consists of
8,450 entities for training, 1,072 for development,
and 1,067 for test. Entities have approximately 2.0
fluents on average.
From experiments on the development set, we set
the relative strength of the consistency component
Q = 10. For the JCC model, we perform three runs
for each experiment with different random seeds.
Each experiment performs 10 rounds of RRHC,8 ini-
tializing from an empty timeline.
</bodyText>
<subsectionHeader confidence="0.988201">
4.1 Evaluation metric
</subsectionHeader>
<bodyText confidence="0.9999385">
Our evaluation metric is adapted from the Temporal
KBP metric (Ji et al., 2011) to work with 2-tuples
for temporal representations rather than the 4-tuples
in Temporal KBP. The metric favors tighter bounds
on fluents while giving partial credit. All dates need
to be given at day resolution. Thus, for gold fluents
with only year- or month-level resolution, we treat
them as their earliest (for starts) or latest (for ends)
possible day. To score a boundary, we take the dif-
ference between the predicted and gold values: If
they’re both unbounded (foo), the boundary’s score
is 1. If only one is unbounded, the score is 0. If
both are finite, the score is 1/(1 + |d|) where d is
the difference between the values in years. To score
a fluent, we average the scores of its start and end
boundaries. In rare cases, we have multiple spans
for the same relation (e.g., Elizabeth Taylor married
Richard Burton twice). In these cases, we give sys-
tems the benefit of the doubt and greedily align flu-
ents in such a way as to maximize the metric. The
total metric computes the score of each fluent di-
vided by the number of fluents. The official metric
includes precision and recall components, but since
our setup provides gold relations, our precision and
recall are be equal. This allows us to report a single
number.
</bodyText>
<subsectionHeader confidence="0.99375">
4.2 Baselines and oracle
</subsectionHeader>
<bodyText confidence="0.999742666666667">
The simplest baseline is the null baseline, proposed
in Surdeanu et al. (2011). This baseline assumes that
all fluents are unbounded in their spans. The purpose
</bodyText>
<footnote confidence="0.9944845">
7http://nlp.stanford.edu/˜mcclosky/data/
freebase-temporal-relations.tar.gz
8There was no significant difference in accuracy between
running 10 and 200 rounds of RRHC.
</footnote>
<page confidence="0.993669">
878
</page>
<figure confidence="0.870212636363636">
Model Dev Test
Oracle 78.1 75.2
Joint Classifier with Consistency 76.1 72.2
Combined Classifier 75.8 71.5
Basic aggregation (modes) 75.3 71.2
Basic aggregation 74.7 70.5
null baseline 58.8 55.6
Table 2: Performance of systems on development and test
divisions. The Joint classifier with Consistency is the av-
erage of three runs with negligible variance (u ≈ 0.02).
4.3 Results
</figure>
<figureCaption confidence="0.995807">
Figure 2: Performance of models and baselines on devel-
opment data while varying amount of training data. Not
pictured: The null baseline at 58.8%.
</figureCaption>
<bodyText confidence="0.999966901960784">
of this baseline is primarily to show the approximate
minimal value for the temporal metric.
We provide two other baselines to describe heuris-
tic methods of aggregating the hard decisions from
the classifier function C learned in §3.2. These are
unlike the CC model which uses the soft decisions
of C. Both of these baselines maintain lists of pos-
sible starts and ends for each fluent. If the classifier
assigns START AND END, we add the candidate tem-
poral expression to both. The first baseline, basic
aggregation, is along the same lines as the aggrega-
tion method used in Artiles et al. (2011), a state-of-
the-art system. Our baseline assigns the earliest start
and the latest end as the bounds for each fluent, as-
signing foo for empty lists. The second baseline,
basic aggregation (modes), is the same except that it
uses the mode from each list.
To determine the best possible score given our
temporal expression retrieval system, we calculate
the oracle score by assigning each fluent the span
which maximizes the temporal metric. The oracle
score can differ from a perfect score since we can
only use candidate temporal expressions as values
for a fluent if (a) mentions of the fluent are retriev-
able in our source documents, (b) the temporal ex-
pression mention appears nearby, and (c) our tem-
poral expression extractor is able to recognize it cor-
rectly. Nevertheless, it is still a reasonable upper
bound in our setting.
We present the performance of our models, base-
lines, and the oracle in Figure 2 while varying the
percentage of training entities. The JCC model
(76.1% on development with 100% training enti-
ties) is consistently the best non-oracle system. Its
gains are larger when the amount of training data is
low. This is presumably because the classifier suf-
fers from insufficient data and the consistency com-
ponent is able to learn consistency rules to recover
from this. Both the CC and JCC models outperform
the basic aggregation models. This shows the value
of incorporating all marginal probabilities. On the
test set (Table 2), the JCC model performs even bet-
ter in comparison to the simple models, despite the
test set being clearly more difficult than the develop-
ment set. In this case, the JCC achieves a 36% error
reduction over the basic aggregation model.9 On the
official KBP entities, the oracle score is 92%. Since
we use a different set of entities, there is a mismatch
between our entities and the source documents re-
sulting in a lower oracle score. Addressing this is
future work.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999883125">
Table 3 shows the performance of four systems
and baselines on individual fluent types. The JCC
model derives most of its improvement from the
two lifespan fluents and other high frequency flu-
ents. The lifespan fluents provide the most room
for improvement since they tend to contain non-null
values a reasonable amount of the time (note how
these relations have a large gap between their ora-
</bodyText>
<footnote confidence="0.889749">
9This counts errors relative to the oracle score since we treat
the retrieval system as fixed in this work.
</footnote>
<page confidence="0.992369">
879
</page>
<table confidence="0.999042">
Model
Fluent Count null Basic Basic (modes) CC JCC Oracle
organization: lifespan 266 49.2 71.0 70.7 71.1 71.7 73.4
organization: top employees 150 88.0 88.0 88.0 88.0 88.0 88.3
organization: founders 31 0.0 5.4 5.4 10.8 11.1 16.3
organization: acquires company 14 21.4 21.4 21.4 21.4 21.4 38.5
person: lifespan 806 28.6 63.1 64.6 65.6 66.1 69.1
person: has spouse 582 92.2 92.1 92.1 92.2 92.3 93.1
person: attends school 107 97.7 97.7 97.7 97.7 98.1 98.1
person: has job 85 78.8 79.4 79.4 78.8 78.8 80.3
person: holds government position 45 16.7 19.7 19.7 19.7 19.7 25.1
person: romantic partner 5 50.0 52.9 52.9 52.9 52.9 71.2
</table>
<tableCaption confidence="0.714475833333333">
Table 3: Fluent-level performance of models and baselines on development data. Scores are calculated with the
temporal metric. CC stands for Combined Classifier and JCC for Joint Classifier with Consistency. The JCC model
obtains most of its benefits on the two lifespan relations. For attends school, it is the only system able to achieve
oracle-level performance. The null baseline is especially strong for several fluents since these tend to be unbounded or
(more likely) missing their values in Freebase. The two basic aggregation models differ primarily on their predictions
for the lifespan fluents.
</tableCaption>
<bodyText confidence="0.9999824">
cle and null scores). Additionally, the lifespan fluent
is always present for entities while other fluents are
sparser. For attends school, JCC is the only system
able to achieve oracle-level performance. No system
improves on the null baseline for acquires company.
This is likely due to its sparsity.
Inspecting the multinomials in the consistency
component, we can see that the model learns reason-
able answers to questions such as whether an entity
“was born before getting married?” (yes: 14.8%,
no: 0.04%),10 “died before their parents were born?”
(yes: 0.3%, no: 53.7%) and “finished a job before
starting a job (not necessarily the same one)?” (yes:
72.5%, no: 20.5%). Despite some unavoidable noise
in the data, it is clear these constraints are useful.
</bodyText>
<sectionHeader confidence="0.999915" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.98825047368421">
There is a large body of related work that focuses
on ordering events or classifying temporal relations
between them (Ling and Weld, 2010; Yoshikawa et
al., 2009; Chambers and Jurafsky, 2008; Mani et
al., 2006, inter alia). Much of this work uses the
Allen interval relations (Allen, 1983) which richly
describe partial orderings of fluents. We use several
of these as fluent-level question templates.
Joint inference has been applied successfully
10Percentages for “unknown” are omitted here.
to other NLP problems (Roth and Yih, 2004;
Toutanova et al., 2008; Martins et al., 2009; Chang
et al., 2010; Koo et al., 2010; Berant et al.,
2011). Two recent examples in information ex-
traction include using Markov Logic for temporal
ordering (Ling and Weld, 2010) and using dual-
decomposition for event extraction (Riedel and Mc-
Callum, 2011).
Our work is closest to Temporal KBP slot filling
systems. The CUNY and UNED systems (Artiles
et al., 2011; Garrido et al., 2011) for this task used
classifiers to determine the relation between tempo-
ral expressions and fluents. These systems use the
hard decisions from the classifier and combine the
decisions by finding a span that includes all temporal
expressions. In contrast, our system uses the classi-
fier’s marginal probabilities along with the consis-
tency component to incorporate global consistency
constraints. Other participants used rule-based and
pattern matching approaches (Byrne and Dunnion,
2011; Surdeanu et al., 2011; Burman et al., 2011).
Outside of Temporal KBP, there are several works
on the task of extracting fluents from text. Wang
et al. (2011) which uses label propagation, a graph-
based semi-supervised method to extend positive
and negative seed examples over the graph. Taluk-
dar et al. (2012) apply a similar approach by ag-
gregating local classification decisions using tempo-
</bodyText>
<page confidence="0.984729">
880
</page>
<bodyText confidence="0.998612333333333">
necessarily reflect the view of the DARPA, AFRL,
or the US government.
ral constraints (e.g., mutual exclusion, containment,
and succession) and joint inference. One key dif-
ference is that their constraints are included as input
rather than learned by the system.
</bodyText>
<sectionHeader confidence="0.6843545" genericHeader="evaluation">
References
7 Conclusion and future Work
</sectionHeader>
<bodyText confidence="0.999980925925926">
Joint inference can be effectively applied to the task
of inferring timelines about named entities. Rather
than using hard coded heuristics, our model learns
and applies consistency constraints which capture
inter-entity and cross-entity rules. Simple inference
techniques such as random-restart hillclimbing score
well and run efficiently. Both of our models (CC and
JCC) obtain a substantial error reductions over sim-
pler heuristics-based consistency approaches.
The overall framework can easily be applied to
other information extraction tasks. Rather than list-
ing rules for consistency, these can be learned and
enforced via joint inference. While simple joint in-
ference methods such as random-restart hillclimb-
ing and Gibbs sampling worked well in our case,
more complex inference methods may be required
with more elaborate constraints.
A prime direction for future work is combining
our model with a probabilistic relation extraction
system. This could be accomplished by using the
marginal probabilities on the extracted relations and
multiplying them with the probabilities from the
classifier and consistency components. Inference
would require an additional step which could add or
drop candidate fluents. Furthermore, the consistency
component can be extended with new question types
to incorporate non-temporal constraints as well.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999609833333333">
The authors would like to thank the Stanford NLP
group (with special thanks to Gabor Angeli and
Mihai Surdeanu), William Headden, Micha Elsner,
Pontus Stenetorp, and our anonymous reviewers for
their helpful comments and feedback.
We gratefully acknowledge the support of
Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air
Force Research Laboratory (AFRL) prime contract
no. FA8750-09-C-0181. Any opinions, findings,
and conclusion or recommendations expressed in
this material are those of the author(s) and do not
</bodyText>
<reference confidence="0.998898">
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the ACM,
26(11):832–843.
Javier Artiles, Qi Li, Taylor Cassidy, Suzanne Tamang,
and Heng Ji. 2011. CUNY BLENDER TAC-
KBP2011 Temporal Slot Filling System Description.
In Proceedings of Text Analysis Conference (TAC),
November.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 610–619, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Amev Burman, Arun Jayapal, Sathish Kannan, Madhu
Kavilikatta, Ayman Alhelbawy, Leon Derczynski, and
Robert Gaizauskas. 2011. USFD at KBP 2011: Entity
Linking, Slot Filling and Temporal Bounding. In Pro-
ceedings of Text Analysis Conference (TAC), Novem-
ber.
Lorna Byrne and John Dunnion. 2011. UCD IIRG at
TAC 2011. In Proceedings of Text Analysis Confer-
ence (TAC), November.
Nathanael Chambers and Dan Jurafsky. 2008. Jointly
combining implicit constraints improves temporal or-
dering. In Proceedings of the Conference on Empir-
ical Methods in Natural Language Processing, pages
698–706. Association for Computational Linguistics.
Angel X. Chang and Christopher D. Manning. 2012.
SUTIME: A library for recognizing and normalizing
time expressions. In 8th International Conference on
Language Resources and Evaluation (LREC 2012),
May.
Ming-Wei Chang, Dan Goldwasser, Dan Roth, and Vivek
Srikumar. 2010. Discriminative learning over con-
strained latent representations. In Human Language
Technologies: The 2010 Annual Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 429–437. Association for
Computational Linguistics.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting information
from text sources. In Proceedings of the Seventh Inter-
national Conference on Intelligent Systems for Molec-
ular Biology, pages 77–86. Heidelberg, Germany.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The Stanford typed dependencies repre-
sentation. In Proceedings of the COLING Workshop
</reference>
<page confidence="0.979931">
881
</page>
<reference confidence="0.999719326923077">
on Cross-framework and Cross-domain Parser Evalu-
ation.
Jenny R. Finkel, Teg Grenager, and Christopher D. Man-
ning. 2005. Incorporating non-local information into
information extraction systems by Gibbs sampling. In
Proceedings of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, pages 363–370.
Association for Computational Linguistics.
Guillermo Garrido, Bernardo Cabaleiro, Anselmo Pe nas,
Alvaro Rodrigo, and Damiano Spina. 2011. A distant
supervised learning system for the TAC-KBP Slot Fill-
ing and Temporal Slot Filling Tasks. In Proceedings of
Text Analysis Conference (TAC), November.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the TAC 2011 Knowledge Base Popula-
tion track. In Proceedings of Text Analysis Conference
(TAC), November.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of the 41st An-
nual Meeting on Association for Computational Lin-
guistics, pages 423–430. Association for Computa-
tional Linguistics.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decompo-
sition for parsing with non-projective head automata.
In Proceedings of the 2010 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1288–1298. Association for Computational Linguis-
tics.
Heeyoung Lee, Yves Peirsman, Angel X. Chang,
Nathanael Chambers, Mihai Surdeanu, and Dan Juraf-
sky. 2011. Stanford’s Multi-Pass Sieve Coreference
Resolution System at the CoNLL-2011 Shared Task.
In CoNLL 2011, page 28.
Xiao Ling and Daniel S. Weld. 2010. Temporal infor-
mation extraction. In Proceedings of the Twenty Fifth
National Conference on Artificial Intelligence.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and the 44th Annual Meeting of the Association for
Computational Linguistics, pages 753–760. Associa-
tion for Computational Linguistics.
Andr´e F. T. Martins, Noah A. Smith, and Eric P. Xing.
2009. Concise integer linear programming formula-
tions for dependency parsing. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages
342–350. Association for Computational Linguistics.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP, pages 1003–1011. Associa-
tion for Computational Linguistics.
Sebastian Riedel and Andrew McCallum. 2011. Fast and
robust joint models for biomedical event extraction. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing (EMNLP ’11), July.
Dan Roth and Wen-tau Yih. 2004. A linear program-
ming formulation for global inference in natural lan-
guage tasks. In Hwee Tou Ng and Ellen Riloff, editors,
HLT-NAACL 2004 Workshop: Eighth Conference on
Computational Natural Language Learning (CoNLL-
2004), pages 1–8, Boston, Massachusetts, USA, May
6 - May 7. Association for Computational Linguistics.
Mihai Surdeanu, Sonal Gupta, John Bauer, David Mc-
Closky, Angel X. Chang, Valentin I. Spitkovsky, and
Christopher D. Manning. 2011. Stanford’s Distantly-
Supervised Slot-Filling System. In Proceedings of
Text Analysis Conference (TAC), November.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts. In
Proceedings of the Fifth ACM International Confer-
ence on Web Search and Data Mining, pages 73–82.
ACM.
Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of the 2003 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics on Human Language Technology, pages 173–
180. Association for Computational Linguistics.
Kristina Toutanova, Aria Haghighi, and Christopher D.
Manning. 2008. A global joint model for semantic
role labeling. Computational Linguistics, 34(2):161–
191.
Yafang Wang, Bing Yang, Lizhen Qu, Marc Spaniol, and
Gerhard Weikum. 2011. Harvesting facts from textual
web sources by constrained label propagation. In Pro-
ceedings of the 20th ACM International Conference on
Information and Knowledge Management, pages 837–
846. ACM.
Katsumasa Yoshikawa, Sebastian Riedel, Yuji Mat-
sumoto, and Masayuki Asahara. 2009. Jointly iden-
tifying temporal relations with Markov Logic. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP, pages 405–413. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.998072">
882
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.840420">
<title confidence="0.999995">Learning Constraints for Consistent Timeline Extraction</title>
<author confidence="0.986715">David McClosky</author>
<author confidence="0.986715">D Christopher</author>
<affiliation confidence="0.954488333333333">Natural Language Processing Computer Science Stanford University, Stanford, CA,</affiliation>
<abstract confidence="0.997880588235294">We present a distantly supervised system for the temporal bounds (relations which only hold during certain times, as Unlike previous pipelined approaches, our model does not assume independence between each fluent or even between named entities with known connections (parent, spouse, employer, etc.). Instead, we model what makes timelines of fluents consistent by learning cross-fluent constraints, potentially spanning entities as well. For example, our model learns that someone is unlikely to start a job at age two or to marry someone who hasn’t been born yet. Our system achieves a 36% error reduction over a pipelined baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Communications of the ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<contexts>
<context position="15385" citStr="Allen, 1983" startWordPosition="2459" endWordPosition="2460">istic events, or questions. As an example, one question about the timeline shown in Table 1 is whether Jon Stewart graduated from the College of William and Mary BEFORE marrying Tracey McShane, i.e., end(attends school) &lt; start(has spouse). In this case, the answer is “yes.” More generally, we can apply the BEFORE template to all boundaries of all fluents: boundary1(fluent1) &lt; boundary2(fluent2). We use templates like these (denoted by SMALL CAPS) to generate all possible questions to ask about a specific entity. Other questions can be asked at the fluent level rather than the boundary level (Allen, 1983). One set of fluent level questions asks whether two fluents’ spans OVERLAP. For example, in Table 1, Jon Stewart’s lifespan OVERLAPs with the span of his has spouse fluent. Other sets of fluent level questions ask whether the span of a fluent completely CONTAINS the span of another one, whether a fluent is COMPLETELY BEFORE another fluent, and whether two fluents TOUCH (the start of one fluent is the same as the end of another). Since all of these questions involve ordering but ignore the actual differences in time, we create one more set of questions asking whether two boundaries are WITHIN </context>
<context position="30403" citStr="Allen, 1983" startWordPosition="4998" endWordPosition="4999">as born before getting married?” (yes: 14.8%, no: 0.04%),10 “died before their parents were born?” (yes: 0.3%, no: 53.7%) and “finished a job before starting a job (not necessarily the same one)?” (yes: 72.5%, no: 20.5%). Despite some unavoidable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling sy</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM, 26(11):832–843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier Artiles</author>
<author>Qi Li</author>
<author>Taylor Cassidy</author>
<author>Suzanne Tamang</author>
<author>Heng Ji</author>
</authors>
<title>CUNY BLENDER TACKBP2011 Temporal Slot Filling System Description.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="7793" citStr="Artiles et al. (2011)" startWordPosition="1232" endWordPosition="1235">sing timelines into a series of questions (such as “did the entity go to school before starting a job?”) and learning the probabilities of different answers from training data. Unlike the classifier component, the consistency component is blind to the underlying text in the source documents. The two components work together to find a global timeline that is both based on textual evidence and coherent across entities using with temporal bounds. 3Note that this is a relation in the non-temporal KBP task. 4Other metarelations are possible under more complex temporal representations. For example, Artiles et al. (2011) uses the HOLDS metarelation. 874 Entity Relation Slot value Temporal bounds Jon Stewart lifespan — [1962-11-28, +oo) /en/jon stewart Jon Stewart has parent [1962-11-28, +oo) /en/jon stewart Donald Leibowitz /en/donald leibowitz Jon Stewart attends school College of William and Mary (_oo, 1984] /en/jon stewart /en/college of william and mary Jon Stewart has spouse [2000-11, +oo) /en/jon stewart Tracey McShane /en/tracy mcshane Table 1: Example relations with their temporal bounds. Freebase IDs are shown in monospace. Note that temporal bounds differ in their resolution (some are days of the ye</context>
<context position="11693" citStr="Artiles et al. (2011)" startWordPosition="1852" endWordPosition="1855">ified matches. Thus, both “1981” and “September 1981” would have the START metarelation but “September 2nd, 1981” would be assigned UNRELATED. 3.2 Classifier component We use a classifier to determine the nature of the link between fluents and candidate temporal expression mentions. Our classifier (a standard multiclass maximum entropy classifier) learns a function C : (t, f) M where t is a temporal expression mention, f = (entity, relation name, slot value) is a fluent from the database, and M is the set of the four possible metarelations. Features for the classifier include many of those in Artiles et al. (2011). These include standard relation extraction features such as the dependency paths between the temporal expression and the entity or slot value. We use both the original depen875 dency paths and their collapsed Stanford Dependencies forms (de Marneffe and Manning, 2008). We include the lengths of each path and, if the path is shorter than four edges, the grammatical relations, words, POS tags, and NER labels along the path. We extract the same sorts of features from surface paths (i.e., the words and tags between the entity and the temporal expression) if the path is five tokens or shorter. Fo</context>
<context position="25666" citStr="Artiles et al. (2011)" startWordPosition="4209" endWordPosition="4212">e null baseline at 58.8%. of this baseline is primarily to show the approximate minimal value for the temporal metric. We provide two other baselines to describe heuristic methods of aggregating the hard decisions from the classifier function C learned in §3.2. These are unlike the CC model which uses the soft decisions of C. Both of these baselines maintain lists of possible starts and ends for each fluent. If the classifier assigns START AND END, we add the candidate temporal expression to both. The first baseline, basic aggregation, is along the same lines as the aggregation method used in Artiles et al. (2011), a state-ofthe-art system. Our baseline assigns the earliest start and the latest end as the bounds for each fluent, assigning foo for empty lists. The second baseline, basic aggregation (modes), is the same except that it uses the mode from each list. To determine the best possible score given our temporal expression retrieval system, we calculate the oracle score by assigning each fluent the span which maximizes the temporal metric. The oracle score can differ from a perfect score since we can only use candidate temporal expressions as values for a fluent if (a) mentions of the fluent are r</context>
<context position="31057" citStr="Artiles et al., 2011" startWordPosition="5101" endWordPosition="5104">erings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several wo</context>
</contexts>
<marker>Artiles, Li, Cassidy, Tamang, Ji, 2011</marker>
<rawString>Javier Artiles, Qi Li, Taylor Cassidy, Suzanne Tamang, and Heng Ji. 2011. CUNY BLENDER TACKBP2011 Temporal Slot Filling System Description. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>610--619</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="30755" citStr="Berant et al., 2011" startWordPosition="5052" endWordPosition="5055"> of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the c</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 610–619, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amev Burman</author>
<author>Arun Jayapal</author>
<author>Sathish Kannan</author>
<author>Madhu Kavilikatta</author>
<author>Ayman Alhelbawy</author>
<author>Leon Derczynski</author>
<author>Robert Gaizauskas</author>
</authors>
<title>USFD at KBP 2011: Entity Linking, Slot Filling and Temporal Bounding.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="31610" citStr="Burman et al., 2011" startWordPosition="5183" endWordPosition="5186">ot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extracting fluents from text. Wang et al. (2011) which uses label propagation, a graphbased semi-supervised method to extend positive and negative seed examples over the graph. Talukdar et al. (2012) apply a similar approach by aggregating local classification decisions using tempo880 necessarily reflect the view of the DARPA, AFRL, or the US government. ral constraints (e.g., mutual exclusion, containment, and succession) and joint inference. One key difference is that their constraints are included as input rather than learned</context>
</contexts>
<marker>Burman, Jayapal, Kannan, Kavilikatta, Alhelbawy, Derczynski, Gaizauskas, 2011</marker>
<rawString>Amev Burman, Arun Jayapal, Sathish Kannan, Madhu Kavilikatta, Ayman Alhelbawy, Leon Derczynski, and Robert Gaizauskas. 2011. USFD at KBP 2011: Entity Linking, Slot Filling and Temporal Bounding. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lorna Byrne</author>
<author>John Dunnion</author>
</authors>
<title>UCD IIRG at TAC</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="31565" citStr="Byrne and Dunnion, 2011" startWordPosition="5175" endWordPosition="5178">m, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extracting fluents from text. Wang et al. (2011) which uses label propagation, a graphbased semi-supervised method to extend positive and negative seed examples over the graph. Talukdar et al. (2012) apply a similar approach by aggregating local classification decisions using tempo880 necessarily reflect the view of the DARPA, AFRL, or the US government. ral constraints (e.g., mutual exclusion, containment, and succession) and joint inference. One key difference is that their constrai</context>
</contexts>
<marker>Byrne, Dunnion, 2011</marker>
<rawString>Lorna Byrne and John Dunnion. 2011. UCD IIRG at TAC 2011. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Jointly combining implicit constraints improves temporal ordering.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>698--706</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30304" citStr="Chambers and Jurafsky, 2008" startWordPosition="4979" endWordPosition="4982">nsistency component, we can see that the model learns reasonable answers to questions such as whether an entity “was born before getting married?” (yes: 14.8%, no: 0.04%),10 “died before their parents were born?” (yes: 0.3%, no: 53.7%) and “finished a job before starting a job (not necessarily the same one)?” (yes: 72.5%, no: 20.5%). Despite some unavoidable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition fo</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 698–706. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>SUTIME: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In 8th International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="9467" citStr="Chang and Manning, 2012" startWordPosition="1494" endWordPosition="1497">ssions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference time is used to 5While we limit our scope to sentences in this work, it is trivial to extend this to larger regions such as paragraphs. 6The lifespan fluent requires special handling. Ideally, its candidates would be provided by a relation extraction mention detector (e.g., a KBP system). For this work, we </context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel X. Chang and Christopher D. Manning. 2012. SUTIME: A library for recognizing and normalizing time expressions. In 8th International Conference on Language Resources and Evaluation (LREC 2012), May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
<author>Vivek Srikumar</author>
</authors>
<title>Discriminative learning over constrained latent representations.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>429--437</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30715" citStr="Chang et al., 2010" startWordPosition="5044" endWordPosition="5047">. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal express</context>
</contexts>
<marker>Chang, Goldwasser, Roth, Srikumar, 2010</marker>
<rawString>Ming-Wei Chang, Dan Goldwasser, Dan Roth, and Vivek Srikumar. 2010. Discriminative learning over constrained latent representations. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 429–437. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology,</booktitle>
<pages>77--86</pages>
<location>Heidelberg, Germany.</location>
<contexts>
<context position="9141" citStr="Craven and Kumlien, 1999" startWordPosition="1437" endWordPosition="1440">m unbounded. The lifespan fluent is a unary relation. joint inference (note that they are trained independently). The inference process is described in §3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dat</context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology, pages 77–86. Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Proceedings of the COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Teg Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by Gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9243" citStr="Finkel et al., 2005" startWordPosition="1456" endWordPosition="1459">ntly). The inference process is described in §3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference time is used to 5While we limit our scope to sentences in this work, it is trivial t</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny R. Finkel, Teg Grenager, and Christopher D. Manning. 2005. Incorporating non-local information into information extraction systems by Gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillermo Garrido</author>
<author>Bernardo Cabaleiro</author>
<author>Anselmo Pe nas</author>
<author>Alvaro Rodrigo</author>
<author>Damiano Spina</author>
</authors>
<title>A distant supervised learning system for the TAC-KBP Slot Filling and Temporal Slot Filling Tasks.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="31080" citStr="Garrido et al., 2011" startWordPosition="5105" endWordPosition="5108">use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extr</context>
</contexts>
<marker>Garrido, Cabaleiro, nas, Rodrigo, Spina, 2011</marker>
<rawString>Guillermo Garrido, Bernardo Cabaleiro, Anselmo Pe nas, Alvaro Rodrigo, and Damiano Spina. 2011. A distant supervised learning system for the TAC-KBP Slot Filling and Temporal Slot Filling Tasks. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Knowledge Base Population track.</title>
<date>2011</date>
<journal>Overview of the TAC</journal>
<booktitle>In Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="1342" citStr="Ji et al., 2011" startWordPosition="200" endWordPosition="203"> example, our model learns that someone is unlikely to start a job at age two or to marry someone who hasn’t been born yet. Our system achieves a 36% error reduction over a pipelined baseline. 1 Introduction Many information extraction (IE) systems traditionally extracted just relations, but a great many real world relations such as attends school or has spouse vary over time. To capture this, some recent IE systems have extended their focus from relations to fluents (relations combined with temporal bounds). This can be seen in the temporal slot filling track in the TAC-KBP 2011 shared task (Ji et al., 2011). A direct application of this work is the automatic improvement of online resources such as Freebase and Wikipedia infoboxes. Indirect applications include question answering systems. Fluents can be grouped together to form timelines (see Figure 1 for an example) and provide easily capturable consistency constraints. Our goal is Figure 1: A timeline of two named entities. Each time span represents afluent (a relation with temporal bounds). Temporal bounds are denoted by spans on the timeline. Fluents can create links between entities (e.g., marriage). to learn these constraints and use them t</context>
<context position="3675" citStr="Ji et al., 2011" startWordPosition="570" endWordPosition="573">uld easily be applied to other IE systems which 873 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 873–882, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics employ independent extractions followed by heuristics to improve consistency. people and organizations, we add a special fluent, lifespan, which doesn’t take a slot value.3 A list of fluents we use are listed in Table 3. 2 The timelining task As a basis for our task, we first describe the Temporal KBP task (Ji et al., 2011). As input, one is given a list of queries, a database of example fluents, and source documents. Queries are named entities (people or organizations) with their gold relations but no temporal bounds. The database consists of training entities with their fluents, including known temporal bounds for each fluent. Example fluents can be seen in Table 1. Note that the database may be incomplete. In addition to missing fluents for an entity, some temporal bounds may be missing from the database; missing bounds are unfortunately indistinguishable from unbounded ranges. As a result, we can only trust </context>
<context position="22958" citStr="Ji et al., 2011" startWordPosition="3759" endWordPosition="3762">ed to at least one other entity – this eliminates a large portion of possible entities. Our corpus7 consists of 8,450 entities for training, 1,072 for development, and 1,067 for test. Entities have approximately 2.0 fluents on average. From experiments on the development set, we set the relative strength of the consistency component Q = 10. For the JCC model, we perform three runs for each experiment with different random seeds. Each experiment performs 10 rounds of RRHC,8 initializing from an empty timeline. 4.1 Evaluation metric Our evaluation metric is adapted from the Temporal KBP metric (Ji et al., 2011) to work with 2-tuples for temporal representations rather than the 4-tuples in Temporal KBP. The metric favors tighter bounds on fluents while giving partial credit. All dates need to be given at day resolution. Thus, for gold fluents with only year- or month-level resolution, we treat them as their earliest (for starts) or latest (for ends) possible day. To score a boundary, we take the difference between the predicted and gold values: If they’re both unbounded (foo), the boundary’s score is 1. If only one is unbounded, the score is 0. If both are finite, the score is 1/(1 + |d|) where d is </context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the TAC 2011 Knowledge Base Population track. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9268" citStr="Klein and Manning, 2003" startWordPosition="1460" endWordPosition="1463">process is described in §3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference time is used to 5While we limit our scope to sentences in this work, it is trivial to extend this to larger r</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 423–430. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1288--1298</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30733" citStr="Koo et al., 2010" startWordPosition="5048" endWordPosition="5051">re is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast,</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1288–1298. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel X Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<date>2011</date>
<booktitle>Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task. In CoNLL 2011,</booktitle>
<pages>28</pages>
<contexts>
<context position="9287" citStr="Lee et al., 2011" startWordPosition="1464" endWordPosition="1467">3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference time is used to 5While we limit our scope to sentences in this work, it is trivial to extend this to larger regions such as para</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel X. Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task. In CoNLL 2011, page 28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Temporal information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Twenty Fifth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="30251" citStr="Ling and Weld, 2010" startWordPosition="4971" endWordPosition="4974">arsity. Inspecting the multinomials in the consistency component, we can see that the model learns reasonable answers to questions such as whether an entity “was born before getting married?” (yes: 14.8%, no: 0.04%),10 “died before their parents were born?” (yes: 0.3%, no: 53.7%) and “finished a job before starting a job (not necessarily the same one)?” (yes: 72.5%, no: 20.5%). Despite some unavoidable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering</context>
</contexts>
<marker>Ling, Weld, 2010</marker>
<rawString>Xiao Ling and Daniel S. Weld. 2010. Temporal information extraction. In Proceedings of the Twenty Fifth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>753--760</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30323" citStr="Mani et al., 2006" startWordPosition="4983" endWordPosition="4986">ee that the model learns reasonable answers to questions such as whether an entity “was born before getting married?” (yes: 14.8%, no: 0.04%),10 “died before their parents were born?” (yes: 0.3%, no: 53.7%) and “finished a job before starting a job (not necessarily the same one)?” (yes: 72.5%, no: 20.5%). Despite some unavoidable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction </context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th Annual Meeting of the Association for Computational Linguistics, pages 753–760. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e F T Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>342--350</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30695" citStr="Martins et al., 2009" startWordPosition="5040" endWordPosition="5043">constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes </context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andr´e F. T. Martins, Noah A. Smith, and Eric P. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 342–350. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9162" citStr="Mintz et al., 2009" startWordPosition="1441" endWordPosition="1444">fluent is a unary relation. joint inference (note that they are trained independently). The inference process is described in §3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference tim</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Fast and robust joint models for biomedical event extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP ’11),</booktitle>
<contexts>
<context position="30950" citStr="Riedel and McCallum, 2011" startWordPosition="5081" endWordPosition="5085"> inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne an</context>
</contexts>
<marker>Riedel, McCallum, 2011</marker>
<rawString>Sebastian Riedel and Andrew McCallum. 2011. Fast and robust joint models for biomedical event extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP ’11), July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng and Ellen Riloff, editors, HLT-NAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL2004),</booktitle>
<volume>6</volume>
<pages>1--8</pages>
<location>Boston, Massachusetts, USA,</location>
<contexts>
<context position="30649" citStr="Roth and Yih, 2004" startWordPosition="5032" endWordPosition="5035">idable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine </context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>Dan Roth and Wen-tau Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Hwee Tou Ng and Ellen Riloff, editors, HLT-NAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL2004), pages 1–8, Boston, Massachusetts, USA, May 6 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sonal Gupta</author>
<author>John Bauer</author>
<author>David McClosky</author>
<author>Angel X Chang</author>
<author>Valentin I Spitkovsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Stanford’s DistantlySupervised Slot-Filling System. In</title>
<date>2011</date>
<booktitle>Proceedings of Text Analysis Conference (TAC),</booktitle>
<contexts>
<context position="24292" citStr="Surdeanu et al. (2011)" startWordPosition="3992" endWordPosition="3995">ries. In rare cases, we have multiple spans for the same relation (e.g., Elizabeth Taylor married Richard Burton twice). In these cases, we give systems the benefit of the doubt and greedily align fluents in such a way as to maximize the metric. The total metric computes the score of each fluent divided by the number of fluents. The official metric includes precision and recall components, but since our setup provides gold relations, our precision and recall are be equal. This allows us to report a single number. 4.2 Baselines and oracle The simplest baseline is the null baseline, proposed in Surdeanu et al. (2011). This baseline assumes that all fluents are unbounded in their spans. The purpose 7http://nlp.stanford.edu/˜mcclosky/data/ freebase-temporal-relations.tar.gz 8There was no significant difference in accuracy between running 10 and 200 rounds of RRHC. 878 Model Dev Test Oracle 78.1 75.2 Joint Classifier with Consistency 76.1 72.2 Combined Classifier 75.8 71.5 Basic aggregation (modes) 75.3 71.2 Basic aggregation 74.7 70.5 null baseline 58.8 55.6 Table 2: Performance of systems on development and test divisions. The Joint classifier with Consistency is the average of three runs with negligible v</context>
<context position="31588" citStr="Surdeanu et al., 2011" startWordPosition="5179" endWordPosition="5182">sest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extracting fluents from text. Wang et al. (2011) which uses label propagation, a graphbased semi-supervised method to extend positive and negative seed examples over the graph. Talukdar et al. (2012) apply a similar approach by aggregating local classification decisions using tempo880 necessarily reflect the view of the DARPA, AFRL, or the US government. ral constraints (e.g., mutual exclusion, containment, and succession) and joint inference. One key difference is that their constraints are included as inp</context>
</contexts>
<marker>Surdeanu, Gupta, Bauer, McClosky, Chang, Spitkovsky, Manning, 2011</marker>
<rawString>Mihai Surdeanu, Sonal Gupta, John Bauer, David McClosky, Angel X. Chang, Valentin I. Spitkovsky, and Christopher D. Manning. 2011. Stanford’s DistantlySupervised Slot-Filling System. In Proceedings of Text Analysis Conference (TAC), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Derry Wijaya</author>
<author>Tom Mitchell</author>
</authors>
<title>Coupled temporal scoping of relational facts.</title>
<date>2012</date>
<booktitle>In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining,</booktitle>
<pages>73--82</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="31875" citStr="Talukdar et al. (2012)" startWordPosition="5226" endWordPosition="5230">decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extracting fluents from text. Wang et al. (2011) which uses label propagation, a graphbased semi-supervised method to extend positive and negative seed examples over the graph. Talukdar et al. (2012) apply a similar approach by aggregating local classification decisions using tempo880 necessarily reflect the view of the DARPA, AFRL, or the US government. ral constraints (e.g., mutual exclusion, containment, and succession) and joint inference. One key difference is that their constraints are included as input rather than learned by the system. References 7 Conclusion and future Work Joint inference can be effectively applied to the task of inferring timelines about named entities. Rather than using hard coded heuristics, our model learns and applies consistency constraints which capture i</context>
</contexts>
<marker>Talukdar, Wijaya, Mitchell, 2012</marker>
<rawString>Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell. 2012. Coupled temporal scoping of relational facts. In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, pages 73–82. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9222" citStr="Toutanova et al., 2003" startWordPosition="1452" endWordPosition="1455">ey are trained independently). The inference process is described in §3.4. 3.1 Temporal expression retrieval Given a fluent, we search for all textual mentions of the fluent and collect nearby temporal expression mentions. These temporal expressions are used as candidate boundaries for the fluent in later steps. The search process assumes that if a fluent’s entity and slot value co-occur in a sentence,5 that sentence is typically a positive example of the fluent.6 This is sometimes known as distant supervision (Craven and Kumlien, 1999; Mintz et al., 2009). We use the Stanford Core NLP suite (Toutanova et al., 2003; Finkel et al., 2005; Klein and Manning, 2003; Lee et al., 2011) to annotate each document with POS and NER tags, parse trees, and coreference chains. On top of this, we apply a rule-based temporal expression extractor (Chang and Manning, 2012). Since we have coreference links, we also search documents for anything coreferent with the fluent’s entity. The temporal expression extractor handles most standard date and time formats. For each document, one can provide an optional reference time. For underspecified dates, the reference time is used to 5While we limit our scope to sentences in this </context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 173– 180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>A global joint model for semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<pages>191</pages>
<contexts>
<context position="30673" citStr="Toutanova et al., 2008" startWordPosition="5036" endWordPosition="5039">data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) and using dualdecomposition for event extraction (Riedel and McCallum, 2011). Our work is closest to Temporal KBP slot filling systems. The CUNY and UNED systems (Artiles et al., 2011; Garrido et al., 2011) for this task used classifiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding</context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2008</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2008. A global joint model for semantic role labeling. Computational Linguistics, 34(2):161– 191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yafang Wang</author>
<author>Bing Yang</author>
<author>Lizhen Qu</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>Harvesting facts from textual web sources by constrained label propagation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>837--846</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="31724" citStr="Wang et al. (2011)" startWordPosition="5203" endWordPosition="5206">fiers to determine the relation between temporal expressions and fluents. These systems use the hard decisions from the classifier and combine the decisions by finding a span that includes all temporal expressions. In contrast, our system uses the classifier’s marginal probabilities along with the consistency component to incorporate global consistency constraints. Other participants used rule-based and pattern matching approaches (Byrne and Dunnion, 2011; Surdeanu et al., 2011; Burman et al., 2011). Outside of Temporal KBP, there are several works on the task of extracting fluents from text. Wang et al. (2011) which uses label propagation, a graphbased semi-supervised method to extend positive and negative seed examples over the graph. Talukdar et al. (2012) apply a similar approach by aggregating local classification decisions using tempo880 necessarily reflect the view of the DARPA, AFRL, or the US government. ral constraints (e.g., mutual exclusion, containment, and succession) and joint inference. One key difference is that their constraints are included as input rather than learned by the system. References 7 Conclusion and future Work Joint inference can be effectively applied to the task of </context>
</contexts>
<marker>Wang, Yang, Qu, Spaniol, Weikum, 2011</marker>
<rawString>Yafang Wang, Bing Yang, Lizhen Qu, Marc Spaniol, and Gerhard Weikum. 2011. Harvesting facts from textual web sources by constrained label propagation. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, pages 837– 846. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Yuji Matsumoto</author>
<author>Masayuki Asahara</author>
</authors>
<title>Jointly identifying temporal relations with Markov Logic.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>405--413</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30275" citStr="Yoshikawa et al., 2009" startWordPosition="4975" endWordPosition="4978">e multinomials in the consistency component, we can see that the model learns reasonable answers to questions such as whether an entity “was born before getting married?” (yes: 14.8%, no: 0.04%),10 “died before their parents were born?” (yes: 0.3%, no: 53.7%) and “finished a job before starting a job (not necessarily the same one)?” (yes: 72.5%, no: 20.5%). Despite some unavoidable noise in the data, it is clear these constraints are useful. 6 Related work There is a large body of related work that focuses on ordering events or classifying temporal relations between them (Ling and Weld, 2010; Yoshikawa et al., 2009; Chambers and Jurafsky, 2008; Mani et al., 2006, inter alia). Much of this work uses the Allen interval relations (Allen, 1983) which richly describe partial orderings of fluents. We use several of these as fluent-level question templates. Joint inference has been applied successfully 10Percentages for “unknown” are omitted here. to other NLP problems (Roth and Yih, 2004; Toutanova et al., 2008; Martins et al., 2009; Chang et al., 2010; Koo et al., 2010; Berant et al., 2011). Two recent examples in information extraction include using Markov Logic for temporal ordering (Ling and Weld, 2010) a</context>
</contexts>
<marker>Yoshikawa, Riedel, Matsumoto, Asahara, 2009</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Yuji Matsumoto, and Masayuki Asahara. 2009. Jointly identifying temporal relations with Markov Logic. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 405–413. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>