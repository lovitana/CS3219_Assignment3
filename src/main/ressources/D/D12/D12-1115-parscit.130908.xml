<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.96842">
Resolving “This-issue” Anaphora
</title>
<author confidence="0.994055">
Varada Kolhatkar
</author>
<affiliation confidence="0.998451">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.98484">
Toronto, ON, M5S 3G4, Canada
</address>
<email confidence="0.999378">
varada@cs.toronto.edu
</email>
<author confidence="0.995539">
Graeme Hirst
</author>
<affiliation confidence="0.9984655">
Department of Computer Science
University of Toronto
</affiliation>
<address confidence="0.984741">
Toronto, ON, M5S 3G4, Canada
</address>
<email confidence="0.999396">
gh@cs.toronto.edu
</email>
<sectionHeader confidence="0.995646" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99985585">
We annotate and resolve a particular
case of abstract anaphora, namely, this-
issue anaphora. We propose a candidate
ranking model for this-issue anaphora
resolution that explores different issue-
specific and general abstract-anaphora
features. The model is not restricted
to nominal or verbal antecedents; rather,
it is able to identify antecedents that
are arbitrary spans of text. Our re-
sults show that (a) the model outperforms
the strong adjacent-sentence baseline;
(b) general abstract-anaphora features,
as distinguished from issue-specific fea-
tures, play a crucial role in this-issue
anaphora resolution, suggesting that our
approach can be generalized for other
NPs such as this problem and this debate;
and (c) it is possible to reduce the search
space in order to improve performance.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993925">
Anaphora in which the anaphoric expression refers
to an abstract object such as a proposition, a prop-
erty, or a fact is known as abstract object anaphora.
This is seen in the following examples.
</bodyText>
<listItem confidence="0.9881125">
(1) [Be careful what you wish... because wishes
sometimes come true.]i [That]i is what the
Semiconductor Industry Association, which rep-
resents U.S. manufacturers, has been learning.
(from Asher (1993))
(2) This prospective study suggested [that oral
</listItem>
<bodyText confidence="0.924749">
carvedilol is more effective than oral meto-
prolol in the prevention of AF after on-pump
CABG]i. It is well tolerated when started before
and continued after the surgery. However, further
prospective studies are needed to clarify [this is-
sue]i.
</bodyText>
<listItem confidence="0.99180025">
(3) In principle, he said, airlines should be allowed
[to sell standing-room-only tickets for adults]i
— as long as [this decision]i was approved by
their marketing departments.
</listItem>
<bodyText confidence="0.999799125">
These examples highlight a difficulty not found with
nominal anaphora. First, the anaphors refer to ab-
stract concepts that can be expressed with differ-
ent syntactic shapes which are usually not nominals.
The anaphor That in (1) refers to the proposition in
the previous utterance, whereas the anaphor this is-
sue in (2) refers to a clause from the previous text.
In (3), the anaphoric expression this decision refers
to a verb phrase from the same sentence. Second,
the antecedents do not always have precisely defined
boundaries. In (2), for example, the whole sentence
containing the marked clause could also be thought
to be the correct antecedent. Third, the actual refer-
ents are not always the precise textual antecedents.
The actual referent in (2), the issue to be clarified,
is whether oral carvedilol is more effective than oral
metoprolol in the prevention of AF after on-pump
CABG or not, a variant of the antecedent text.
Generally, abstract anaphora, as distinguished
from nominal anaphora, is signalled in English by
pronouns this, that, and it (M¨uller, 2008). But in
abstract anaphora, English prefers demonstratives
to personal pronouns and definite articles (Pas-
sonneau, 1989; Navarretta, 2011).1 Demonstra-
</bodyText>
<footnote confidence="0.9961635">
1This is not to say that personal pronouns and definite arti-
cles do not occur in abstract anaphora, but they are not common.
</footnote>
<page confidence="0.853088">
1255
</page>
<note confidence="0.810615">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1255–1265, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998918311111111">
tives can be used in isolation (That in (1)) or with
nouns (e.g., this issue in (2)). The latter follows
the pattern demonstrative {modifier}* noun. The
demonstrative acts as a determiner and the noun fol-
lowing the demonstrative imposes selectional con-
straints for the antecedent, as in examples (2) and
(3). Francis (1994) calls such nouns label nouns,
which “serve to encapsulate or package a stretch
of discourse”. Schmid (2000) refers to them as
shell nouns, a metaphoric term which reflects differ-
ent functions of these nouns such as encapsulation,
pointing, and signalling.
Demonstrative nouns, along with pronouns like
both and either, are referred to as sortal anaphors
(Casta˜no et al., 2002; Lin and Liang, 2004; Torii
and Vijay-Shanker, 2007). Casta˜no et al. observed
that sortal anaphors are prevalent in the biomedi-
cal literature. They noted that among 100 distinct
anaphors derived from a corpus of 70 Medline ab-
stracts, 60% were sortal anaphors. But how often
do demonstrative nouns refer to abstract objects?
We observed that from a corpus of 74,000 randomly
chosen Medline2 abstracts, of the first 150 most fre-
quently occurring distinct demonstrative nouns (fre-
quency &gt; 30), 51.3% were abstract, 41.3% were
concrete, and 7.3% were discourse deictic. This
shows that abstract anaphora resolution is an impor-
tant component of general anaphora resolution in the
biomedical domain. However, automatic resolution
of this type of anaphora has not attracted much atten-
tion and the previous work for this task is limited.
The present work is a step towards resolving ab-
stract anaphora in written text. In particular, we
choose the interesting abstract concept issue and
demonstrate the complexities of resolving this-issue
anaphora manually as well as automatically in the
Medline domain. We present our algorithm, results,
and error analysis for this-issue anaphora resolution.
The abstract concept issue was chosen for the fol-
lowing reasons. First, it occurs frequently in all
kinds of text from newspaper articles to novels to
scientific articles. There are 13,489 issue anaphora
instances in the New York Times corpus and 1,116
instances in 65,000 Medline abstracts. Second, it is
abstract enough that it can take several syntactic and
</bodyText>
<footnote confidence="0.903201">
2http://www.nlm.nih.gov/bsd/pmresources.
html
</footnote>
<bodyText confidence="0.9996114">
semantic forms, which makes the problem interest-
ing and non-trivial. Third, issue referents in scien-
tific literature generally lie in the previous sentence
or two, which makes the problem tractable. Fourth,
issues in Medline abstracts are generally associated
with clinical problems in the medical domain and
spell out the motivation of the research presented in
the article. So extraction of this information would
be useful in any biomedical information retrieval
system.
</bodyText>
<sectionHeader confidence="0.999724" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.995294542857143">
Anaphora resolution has been extensively studied
in computational linguistics (Hirst, 1981; Mitkov,
2002; Poesio et al., 2011). But CL research has
mostly focused on nominal anaphora resolution
(e.g., resolving multiple ambiguous mentions of a
single entity representing a person, a location, or an
organization) mainly for two reasons. First, nominal
anaphora is the most frequently occurring anaphora
in most domains, and second, there is a substantial
amount of annotated data available for this kind of
anaphora.
Besides pronominal anaphora, some work has
been done on complement anaphora (Modjeska,
2003) (e.g., British and other European steelmak-
ers). There is also some research on resolving sor-
tal anaphora in the medical domain using domain
knowledge (Casta˜no et al., 2002; Lin and Liang,
2004; Torii and Vijay-Shanker, 2007). But all these
approaches focus only on the anaphors with nominal
antecedents.
By contrast, the area of abstract object anaphora
remains relatively unexplored mainly because the
standard anaphora resolution features such as agree-
ment and apposition cannot be applied to abstract
anaphora resolution. Asher (1993) built a theoreti-
cal framework to resolve abstract anaphora. He di-
vided discourse abstract anaphora into three broad
categories: event anaphora, proposition anaphora,
and fact anaphora, and discussed how abstract en-
tities can be resolved using discourse representa-
tion theory. Chen et al. (2011) focused on a sub-
set of event anaphora and resolved event corefer-
ence chains in terms of the representative verbs of
the events from the OntoNotes corpus. Our task dif-
fers from their work as follows. Chen et al. mainly
</bodyText>
<page confidence="0.984604">
1256
</page>
<bodyText confidence="0.999769142857143">
focus on events and actions and use verbs as a proxy
for the non-nominal antecedents. But this-issue an-
tecedents cannot usually be represented by a verb.
Our work is not restricted to a particular syntactic
type of the antecedent; rather we provide the flexibil-
ity of marking arbitrary spans of text as antecedents.
There are also some prominent approaches to ab-
stract anaphora resolution in the spoken dialogue
domain (Eckert and Strube, 2000; Byron, 2004;
M¨uller, 2008). These approaches go beyond nom-
inal antecedents; however, they are restricted to spo-
ken dialogues in specific domains and need serious
adaptation if one wants to apply them to arbitrary
text.
In addition to research on resolution, there is
also some work on effective annotation of abstract
anaphora (Strube and M¨uller, 2003; Botley, 2006;
Poesio and Artstein, 2008; Dipper and Zinsmeister,
2011). However, to the best of our knowledge, there
is currently no English corpus annotated for issue
anaphora antecedents.
</bodyText>
<sectionHeader confidence="0.971911" genericHeader="method">
3 Data and Annotation
</sectionHeader>
<bodyText confidence="0.994110833333333">
To create an initial annotated dataset, we collected
188 this {modifier}* issue instances along with the
surrounding context from Medline abstracts.3 Five
instances were discarded as they had an unrelated
(publication related) sense. Among the remaining
183 instances, 132 instances were independently an-
notated by two annotators, a domain expert and a
non-expert, and the remaining 51 instances were an-
notated only by the domain expert. We use the for-
mer instances for training and the latter instances
(unseen by the developer) for testing. The anno-
tator’s task was to mark arbitrary text segments
as antecedents (without concern for their linguistic
types). To make the task tractable, we assumed that
an antecedent does not span multiple sentences but
lies in a single sentence (since we are dealing with
singular this-issue anaphors) and that it is a continu-
ous span of text.
3Although our dataset is rather small, its size is similar to
other available abstract anaphora corpora in English: 154 in-
stances in Eckert and Strube (2000), 69 instances in Byron
(2003), 462 instances annotated by only one annotator in Botley
(2006), and 455 instances restricted to those which have only
nominal or clausal antecedents in Poesio and Artstein (2008).
</bodyText>
<table confidence="0.9818185">
r11 r12 r13
Annotator 1 id2
r21 r22 r23 r24
Annotator 2 id1
id2
Intersections 1 2 3 4 5 6
</table>
<figureCaption confidence="0.994723">
Figure 1: Example of annotated data. Bold segments
denote the marked antecedents for the corresponding
anaphor ids. rhj is the jth section identified by the an-
notator h.
</figureCaption>
<subsectionHeader confidence="0.974682">
3.1 Inter-annotator Agreement
</subsectionHeader>
<bodyText confidence="0.999937692307692">
This kind of annotation — identifying and marking
arbitrary units of text that are not necessarily con-
stituents — requires a non-trivial variant of the usual
inter-annotator agreement measures. We use Krip-
pendorff’s reliability coefficient for unitizing (au)
(Krippendorff, 1995) which has not often been used
or described in CL. In our context, unitizing means
marking the spans of the text that serve as the an-
tecedent for the given anaphors within the given text.
The coefficient au assumes that the annotated sec-
tions do not overlap in a single annotator’s output
and our data satisfies this criterion.4 The general
form of coefficient au is:
</bodyText>
<equation confidence="0.8590515">
au = 1− uDo (1)
uDe
</equation>
<bodyText confidence="0.99578445">
where uDo and uDe are observed and expected dis-
agreements respectively. Both disagreement quanti-
ties express the average squared differences between
the mismatching pairs of values assigned by anno-
tators to given units of analysis. au = 1 indicates
perfect reliability and au = 0 indicates the absence
of reliability. When au &lt; 0, the disagreement is sys-
tematic. Annotated data with reliability of au &gt; 0.80
is considered reliable (Krippendorff, 2004).
Krippendorff’s au is non-trivial, and explaining it
in detail would take too much space, but the general
idea, in our context, is as follows. The annotators
mark the antecedents corresponding to each anaphor
in their respective copies of the text, as shown in Fig-
ure 1. The marked antecedents are mutually exclu-
sive sections r; we denote the jth section identified
4If antecedents overlap with each other in a single annota-
tor’s output (which is a rare event) we construct data that satis-
fies the non-overlap criterion by creating different copies of the
same text corresponding to each anaphor instance.
</bodyText>
<equation confidence="0.9981588">
r14 r15 r16 r17 r18 r19
id3 id4 id5
r25 r26 r27 r28 r29 r2,10
id3 id4 id5
7 8 9 10 11 12 13 14
</equation>
<page confidence="0.953746">
1257
</page>
<subsectionHeader confidence="0.872587">
Antecedent type Distribution Example
</subsectionHeader>
<bodyText confidence="0.7782968">
clause 37.9% There is a controversial debate (SBAR whether back school program might improve
quality of life in back pain patients). This study aimed to address this issue.
sentence 26.5% (S Reduced serotonin function and abnormalities in the hypothalamic-pituitary-adrenal
axis are thought to play a role in the aetiology of major depression.) We sought to
examine this issue in the elderly ...
mixed 18.2% (S (PP Given these data) (, ,) (NP decreasing HTD to &lt; or = 5 years) (VP may have
a detrimental effect on patients with locally advanced prostate cancer) (. .)) Only a
randomized trial will conclusively clarify this issue.
nominalization 17.4% As (NP the influence of estrogen alone on breast cancer detection) is not established,
we examined this issue in the Women’s Health Initiative trial...
</bodyText>
<tableCaption confidence="0.99865">
Table 1: Antecedent types. In examples, the antecedent type is in bold and the marked antecedent is in italics.
</tableCaption>
<bodyText confidence="0.999951766666667">
by the annotator h by rh j. In Figure 1, annotators 1
and 2 have reached different conclusions by identi-
fying 9 and 10 sections respectively in their copies
of the text. Annotator 1 has not marked any an-
tecedent for the anaphor with id = 1, while annotator
2 has marked r21 for the same anaphor. Both anno-
tators have marked exactly the same antecedent for
the anaphor with id = 4. The difference between two
annotated sections is defined in terms of the square
of the distance between the non-overlapping parts of
the sections. The distance is 0 when the sections are
unmarked by both annotators or are marked and ex-
actly same, and is the summation of the squares of
the unmatched parts if they are different. The coeffi-
cient is computed using intersections of the marked
sections. In Figure 1, annotators 1 and 2 have a to-
tal of 14 intersections. The observed disagreement
uDo is the weighted sum of the differences between
all mismatching intersections of sections marked by
the annotators, and the expected disagreement is the
summation of all possible differences of pairwise
combinations of all sections of all annotators nor-
malized by the length of the text (in terms of the
number of tokens) and the number of pairwise com-
binations of annotators.
For our data, the inter-annotator agreement was
ctu = 0.86 (uDo = 0.81 and uDe = 5.81) despite the
fact that the annotators differed in their domain ex-
pertise, which suggests that abstract concepts such
as issue can be annotated reliably.
</bodyText>
<subsectionHeader confidence="0.999912">
3.2 Corpus Statistics
</subsectionHeader>
<bodyText confidence="0.999499393939394">
A gold standard corpus was created by resolving the
cases where the annotators disagreed. Among 132
training instances, the annotators could not resolve
6 instances and we broke the tie by writing to the
authors of the articles and using their response to
resolve the disagreement. In the gold standard cor-
pus, 95.5% of the antecedents were in the current or
previous sentence and 99.2% were in the current or
previous two sentences. Only one antecedent was
found more than two sentences back and it was six
sentences back. One instance was a cataphor, but
the antecedent occurred in the same sentence as the
anaphor. This suggests that for an automatic this-
issue resolution system, it would be reasonable to
consider only the previous two sentences along with
the sentence containing the anaphor.
The distribution of the different linguistic forms
that an antecedent of this-issue can take in our data
set is shown in Table 1. The majority of antecedents
are clauses or whole sentences. A number of an-
tecedents are noun phrases, but these are gener-
ally nominalizations that refer to abstract concepts
(e.g., the influence of estrogen alone on breast can-
cer detection). Some antecedents are not even well-
defined syntactic constituents5 but are combinations
of several well-defined constituents. We denote the
type of such antecedents as mixed. In the corpus,
18.2% of the antecedents are of this type, suggest-
ing that it is not sufficient to restrict the antecedent
search space to well-defined syntactic constituents.6
In our data, we did not find anaphoric chains for
any of the this-issue anaphor instances, which indi-
cates that the antecedents of this-issue anaphors are
</bodyText>
<footnote confidence="0.600917">
5We refer to every syntactic constituent identified by the
parser as a well-defined syntactic constituent.
6Indeed, many of mixed type antecedents (nearly three-
quarters of them) are the result of parser attachment errors, but
many are not.
</footnote>
<page confidence="0.982302">
1258
</page>
<bodyText confidence="0.999876">
in the reader’s local memory and not in the global
memory. This observation supports the THIS-NPs
hypothesis (Gundel et al., 1993; Poesio and Mod-
jeska, 2002) that this-NPs are used to refer to enti-
ties which are active albeit not in focus, i.e., they are
not the center of the previous utterance.
</bodyText>
<sectionHeader confidence="0.996691" genericHeader="method">
4 Resolution Algorithm
</sectionHeader>
<subsectionHeader confidence="0.992412">
4.1 Candidate Extraction
</subsectionHeader>
<bodyText confidence="0.99998292">
For correct resolution, the set of extracted candidates
must contain the correct antecedent in the first place.
The problem of candidate extraction is non-trivial in
abstract anaphora resolution because the antecedents
are of many different types of syntactic constituents
such as clauses, sentences, and nominalizations.
Drawing on our observation that the mixed type an-
tecedents are generally a combination of different
well-defined syntactic constituents, we extract the
set of candidate antecedents as follows. First, we
create a set of candidate sentences which contains
the sentence containing the this-issue anaphor and
the two preceding sentences. Then, we parse every
candidate sentence with the Stanford Parser7. Ini-
tially, the set of candidate constituents contains a
list of well-defined syntactic constituents. We re-
quire that the node type of these constituents be in
the set {S, SBAR, NP, SQ, SBARQ, S+V}. This
set was empirically derived from our data. To each
constituent, there is associated a set of mixed type
constituents. These are created by concatenating the
original constituent with its sister constituents. For
example, in (4), the set of well-defined eligible can-
didate constituents is {NP, NP1} and so NP1 PP1 is
a mixed type candidate.
</bodyText>
<equation confidence="0.907383">
(4) NP
NP1 PP1 PP2
</equation>
<bodyText confidence="0.999957666666667">
The set of candidate constituents is updated with
the extracted mixed type constituents. Extracting
mixed type candidate constituents not only deals
with mixed type instances as shown in Table 1, but
as a side effect it also corrects some attachment er-
rors made by the parser. Finally, the constituents
</bodyText>
<footnote confidence="0.8393565">
7http://nlp.stanford.edu/software/
lex-parser.shtml
</footnote>
<bodyText confidence="0.995193666666667">
having a number of leaves (words) less than a thresh-
old8 are discarded to give the final set of candidate
constituents.
</bodyText>
<subsectionHeader confidence="0.774482">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.99995558974359">
We explored the effect of including 43 automati-
cally extracted features (12 feature classes), which
are summarized in Table 2. The features can also be
broadly divided into two groups: issue-specific fea-
tures and general abstract-anaphora features. Issue-
specific features are based on our common-sense
knowledge of the concept of issue and the different
semantic forms it can take; e.g., controversy (X is
controversial), hypothesis (It has been hypothesized
X), or lack of knowledge (X is unknown), where X
is the issue. In our data, we observed certain syn-
tactic patterns of issues such as whether X or not
and that X and the IP feature class encodes this in-
formation. Other issue-specific features are IVERB
and IHEAD. The feature IVERB checks whether
the governing verb of the candidate is an issue
verb (e.g., speculate, hypothesize, argue, debate),
whereas IHEAD checks whether the candidate head
in the dependency tree is an issue word (e.g., contro-
versy, uncertain, unknown). The general abstract-
anaphora resolution features do not make use of
the semantic properties of the word issue. Some
of these features are derived empirically from the
training data (e.g., ST, L, D). The EL feature is bor-
rowed from M¨uller (2008) and encodes the embed-
ding level of the candidate within the candidate sen-
tence. The MC feature tries to capture the idea of the
THIS-NPs hypothesis (Gundel et al., 1993; Poesio
and Modjeska, 2002) that the antecedents of this-
NP anaphors are not the center of the previous utter-
ance. The general abstract-anaphora features in the
SR feature class capture the semantic role of the can-
didate in the candidate sentence. We used the Illinois
Semantic Role Labeler9 for SR features. The gen-
eral abstract-anaphora features also contain a few
lexical features (e.g., M, SC). But these features are
independent of the semantic properties of the word
issue. The general abstract-anaphora resolution fea-
tures also contain dependency-tree features, lexical-
</bodyText>
<footnote confidence="0.99306575">
8The threshold 5 was empirically derived. Antecedents in
our training data had on average 17 words.
9http://cogcomp.cs.illinois.edu/page/
software_view/SRL
</footnote>
<page confidence="0.980494">
1259
</page>
<figure confidence="0.77304775862069">
ISSUE PATTERN (IP)
ISWHETHER 1 iff the candidate follows the pattern SBAR — (IN whether) (S ...)
ISTHAT 1 iff the candidate follows the pattern SBAR — (IN that) (S ...)
ISIF 1 iff the candidate follows the pattern SBAR — (IN iff) (S ...)
ISQUESTION 1 iff the candidate node is SBARQ or SQ
SYNTACTIC TYPE (ST)
ISNP 1 iff the candidate node is of type NP
ISS 1 iff the candidate node is a sentence node
ISSBAR 1 iff the candidate node is an SBAR node
ISSQ 1 iff the candidate node is an SQ or SBARQ node
MIXED 1 iff the candidate node is of type mixed
EMBEDDING LEVEL (EL) (M¨uller, 2008)
TLEMBEDDING level of embedding of the given candidate in its top clause (the root node of the syntactic tree)
ILEMBEDDING level of embedding of the given candidate in its immediate clause (the closest parent of type S or SBAR)
MAIN CLAUSE (MC)
MCLAUSE 1 iff the candidate is in the main clause
DISTANCE (D)
ISSAME 1 iff the candidate is in the same sentence as anaphor
SADJA 1 iff the candidate is in the adjacent sentence
ISREM 1 iff the candidate occurs 2 or more sentences before the anaphor
POSITION 1 iff the antecedent occurs before anaphor
SEMANTIC ROLE LABELLING (SR)
IVERB 1 iff the governing verb of the given candidate is an issue verb
ISA0 1 iff the candidate is the agent of the governing verb
ISA1 1 iff the candidate is the patient of the governing verb
ISA2 1 iff the candidate is the instrument of the governing verb
ISAM 1 iff the candidate plays the role of modiffication
ISNOR 1 iff the candidate plays no well-defined semantic role in the sentence
DEPENDENCY TREE (DT)
</figure>
<figureCaption confidence="0.779386666666667">
IHEAD 1 iff the candidate head in the dependency tree is an issue word (e.g., controversial, unknown)
ISSUBJ 1 iff the dependency relation of the candidate to its head is of type nominal, controlling or clausal subject
ISOBJ 1 iff the dependency relation of the candidate to its head is of type direct object or preposition obj
ISDEP 1 iff the dependency relation of the candidate to its head is of type dependent
ISROOT 1 iff the candidate is the root of the dependency tree
ISPREP 1 iff the dependency relation of the candidate to its head is of type preposition
ISCONT 1 iff the dependency relation of the candidate to its head is of type continuation
ISCOMP 1 iff the dependency relation of the candidate to its head is of type clausal or adjectival complement
ISSENT 1 iff candidate’s head is the root node
</figureCaption>
<figure confidence="0.278405">
PRESENCE OF MODALS (M)
MODAL 1 iff the given candidate contains a modal verb
PRESENCE OF SUBORDINATING CONJUNCTION (SC)
ISCONT 1 iff the candidate starts with a contrastive subordinating conjunction (e.g., however, but, yet)
ISCAUSE 1 iff the candidate starts with a causal subordinating conjunction (e.g., because, as, since)
ISCOND 1 iff the candidate starts with a conditional subordinating conjunction (e.g., if, that, whether or not)
LEXICAL OVERLAP (LO)
TOS normalized ratio of the overlapping words in candidate and the title of the article
AOS normalized ratio of the overlapping words in candidate and the anaphor sentence
DWS proportion of domain-specific words in the candidate
CONTEXT (C)
ISPPREP 1 iff the preceding word of the candidate is a preposition
ISFPREP 1 iff the following word of the candidate is a preposition
ISPPUNCT 1 iff the preceding word of the candidate is a punctuation
ISFPUNCT 1 iff the following word of the candidate is a punctuation
LENGTH (L)
LEN length of the candidate in words
</figure>
<tableCaption confidence="0.986729">
Table 2: Feature sets for this-issue resolution. All features are extracted automatically.
</tableCaption>
<page confidence="0.98861">
1260
</page>
<bodyText confidence="0.866043">
overlap features, and context features.
</bodyText>
<subsectionHeader confidence="0.985798">
4.3 Candidate Ranking Model
</subsectionHeader>
<bodyText confidence="0.998905482758621">
Given an anaphor ai and a set of candidate
antecedents C = {C1,C2,...,Ck}, the problem of
anaphora resolution is to choose the best candidate
antecedent for ai. We follow the candidate-ranking
model proposed by Denis and Baldridge (2008).
The advantage of the candidate-ranking model over
the mention-pair model is that it overcomes the
strong independence assumption made in mention-
pair models and evaluates how good a candidate is
relative to all other candidates.
We train our model as follows. If the anaphor
is a this-issue anaphor, the set C is extracted us-
ing the candidate extraction algorithm from Section
4.1. Then a corresponding set of feature vectors,
Cf = {Cf1,Cf2,...,Cfk}, is created using the features
in Table 2. The training instances are created as de-
scribed by Soon et al. (2001). Note that the instance
creation is simpler than for general coreference res-
olution because of the absence of anaphoric chains
in our data. For every anaphor ai and eligible can-
didates Cf = {Cf1,Cf2,...,Cfk}, we create training
examples (ai,Cfi,label),VCfi E Cf. The label is 1
if Ci is the true antecedent of the anaphor ai, oth-
erwise the label is −1. The examples with label 1
get the rank of 1, while other examples get the rank
of 2. We use SVMrank (Joachims, 2002) for train-
ing the candidate-ranking model. During testing, the
trained model is used to rank the candidates of each
test instance of this-issue anaphor.
</bodyText>
<sectionHeader confidence="0.998114" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9999045">
In this section we present the evaluation of each
component of our resolution system.
</bodyText>
<subsectionHeader confidence="0.998667">
5.1 Evaluation of Candidate Extraction
</subsectionHeader>
<bodyText confidence="0.998684541666667">
The set of candidate antecedents extracted by the
method from Section 4.1 contained the correct an-
tecedent 92% of the time. Each anaphor had, on
average, 23.80 candidates, of which only 5.19 can-
didates were nominal type. The accuracy dropped
to 84% when we did not extract mixed type candi-
dates. The error analysis of the 8% of the instances
where we failed to extract the correct antecedent re-
vealed that most of these errors were parsing errors
which could not be corrected by our candidate ex-
traction method.10 In these cases, the parts of the
antecedent had been placed in completely different
branches of the parse tree. For example, in (5), the
correct antecedent is a combination of the NP from
the S —* VP —* NP —* PP —* NP branch and the PP
from S —* VP —* PP branch. In such a case, concate-
nating sister constituents does not help.
(5) The data from this pilot study (VP (VBP provide)
(NP (NP no evidence) (PP (IN for) (NP a dif-
ference in hemodynamic effects between pulse
HVHF and CPFA))) (PP in patients with sep-
tic shock already receiving CRRT)). A larger
sample size is needed to adequately explore this
issue.
</bodyText>
<subsectionHeader confidence="0.998969">
5.2 Evaluation of this-issue Resolution
</subsectionHeader>
<bodyText confidence="0.999718862068966">
We propose two metrics for abstract anaphora eval-
uation. The simplest metric is the percentage of an-
tecedents on which the system and the annotated
gold data agree. We denote this metric as EXACT-
M (Exact Match) and compute it as the ratio of
number of correctly identified antecedents to the to-
tal number of marked antecedents. This metric is
a good indicator of a system’s performance; how-
ever, it is a rather strict evaluation because, as we
noted in section 1, issues generally have no precise
boundaries in the text. So we propose another met-
ric called RLL, which is similar to the ROUGE-L
metric (Lin, 2004) used for the evaluation of auto-
matic summarization. Let the marked antecedents
of the gold corpus for k anaphor instances be G =
(g1,g2,...,gk) and the system-annotated antecedents
be A = (a1,a2,...,ak). Let the number of words in
G and A be m and n respectively. Let LCS(gi,ai)
be the the number of words in the longest common
subsequence of gi and ai. Then the precision (PRLL)
and recall (RRLL) over the whole data set are com-
puted as shown in equations (2) and (3). PRLL is
the total number of word overlaps between the gold
and system-annotated antecedents normalized by the
number of words in system-annotated antecedents
and RRLL is the total number of such word overlaps
normalized by the number of words in the gold an-
tecedents. If the system picks too much text for an-
tecedents, RRLL is high but PRLL is low. The F-score,
</bodyText>
<footnote confidence="0.760749">
10Extracting candidate constituents from the dependency
trees did not add any new candidates to the set of candidates.
</footnote>
<page confidence="0.909839">
1261
</page>
<table confidence="0.999202266666667">
5-fold Cross-Validation PRLL Test EX-M
PRLL RRLL FRLL EX-M RRLL FRLL
1 Adjacent sentence 66.47 86.16 74.93 22.93 61.73 87.69 72.46 24.00
2 Random 50.71 32.84 39.63 8.40 43.75 35.00 38.89 15.69
3 {IP, D, C, LO, EL, M, MC, L, SC, SR, DT} 79.37 83.66 81.11 59.80 71.89 85.74 78.20 58.82
4 {IP, D, C, LO, M, MC, L, SC, DT} 78.71 83.86 81.14 59.89 70.64 88.09 78.40 54.90
5 {IP, D, C, EL, L, SC, SR, DT} 77.95 83.06 80.33 57.41 72.03 84.85 77.92 60.78
6 {IP, D, EL, MC, L, SR, DT} 80.00 84.75 82.24 59.91 68.88 85.29 76.22 56.86
7 {IP, D, M, L, SR} 73.42 83.16 77.90 52.31 70.74 91.03 79.61 50.98
8 {D, C, LO, L, SC, SR, DT} 79.15 85.28 82.04 56.07 67.39 86.32 75.69 52.94
9 issue-specific features 74.66 45.70 56.57 41.42 64.20 45.88 53.52 41.38
10 non-issue features 76.39 79.39 77.82 51.48 71.19 83.24 76.75 58.82
11 All 78.22 82.92 80.41 56.75 71.28 83.24 76.80 56.86
12 Oracle candidate extractor + row 3 79.63 82.26 80.70 58.32 74.65 87.06 80.38 64.71
13 Oracle candidate sentence extractor + row 3 86.67 92.12 89.25 63.72 79.71 91.49 85.20 62.00
</table>
<tableCaption confidence="0.9902295">
Table 3: this-issue resolution results with SVMrank. All means evaluation using all features. Issue-specific features =
{IP, IVERB, IHEAD}. EX-M is EXACT-M.
</tableCaption>
<bodyText confidence="0.966987">
FRLL, combines these two scores.
</bodyText>
<equation confidence="0.9668198">
LCS(gi,ai) (2)
LCS(gi,ai) (3)
FRLL = 2 x PRLL x RRLL
(4)
PRLL +RRLL
</equation>
<bodyText confidence="0.99900352">
The lower bound of FRLL is 0, where no true an-
tecedent has any common substring with the pre-
dicted antecedents and the upper bound is 1, where
all the predicted and true antecedents are exactly the
same. In our results we represent these scores in
terms of percentage.
There are no implemented systems that resolve is-
sue anaphora or abstract anaphora signalled by label
nouns in arbitrary text to use as a comparison. So
we compare our results against two baselines: ad-
jacent sentence and random. The adjacent sentence
baseline chooses the previous sentence as the correct
antecedent. This is a high baseline because in our
data 84.1% of the antecedents lie within the adjacent
sentence. The random baseline chooses a candidate
drawn from a uniform random distribution over the
set of candidates.11
11Note that our FRLL scores for both baselines are rather high
because candidates often have considerable overlap with one
another; hence a wrong choice may still have a high FRLL score.
We carried out two sets of systematic experi-
ments in which we considered all combinations of
our twelve feature classes. The first set consists of
5-fold cross-validation experiments on our training
data. The second set evaluates how well the model
built on the training data works on the unseen test
data.
Table 3 gives results of our system. The first two
rows are the baseline results. Rows 3 to 8 give re-
sults for some of the best performing feature sets.
All systems based on our features beat both base-
lines on F-scores and EXACT-M. The empirically
derived feature sets IP (issue patterns) and D (dis-
tance) appeared in almost all best feature set com-
binations. Removing D resulted in a 6 percentage
points drop in FRLL and a 4 percentage points drop
in EXACT-M scores. Surprisingly, feature set ST
(syntactic type) was not included in most of the best
performing set of feature sets. The combination of
syntactic and semantic feature sets {IP, D, EL, MC,
L, SR, DT} gave the best FRLL and EXACT-M scores
for the cross-validation experiments. For the test-
data experiments, the combination of semantic and
lexical features {D, C, LO, L, SC, SR, DT} gave
the best FRLL results, whereas syntactic, discourse,
and semantic features {IP, D, C, EL, L, SC, SR,
DT} gave the best EXACT-M results. Overall, row
3 of the table gives reasonable results for both cross-
validation and test-data experiments with no statisti-
cally significant difference to the corresponding best
</bodyText>
<equation confidence="0.996948166666667">
1
n
PRLL =
k
�
i=1
1
m
RRLL =
k
�
i=1
</equation>
<page confidence="0.86885">
1262
</page>
<bodyText confidence="0.995846735294117">
EXACT-M scores in rows 6 and 5 respectively.12
To pinpoint the errors made by our system, we
carried out three experiments. In the first experi-
ment, we examined the contribution of issue-specific
features versus non-issue features (rows 9 and 10).
Interestingly, when we used only non-issue features,
the performance dropped only slightly. The FRLL re-
sults from using only issue-specific features were
below baseline, suggesting that the more general
features associated with abstract anaphora play a
crucial role in resolving this-issue anaphora.
In the second experiment, we determined the er-
ror caused by the candidate extractor component of
our system. Row 12 of the table gives the result
when an oracle candidate extractor was used to add
the correct antecedent in the set of candidates when-
ever our candidate extractor failed. This did not
affect cross-validation results by much because of
the rarity of such instances. However, in the test-
data experiment, the EXACT-M improvements that
resulted were statistically significant. This shows
that our resolution algorithm was able to identify an-
tecedents that were arbitrary spans of text.
In the last experiment, we examined the effect of
the reduction of the candidate search space. We as-
sumed an oracle candidate sentence extractor (Row
13) which knows the exact candidate sentence in
which the antecedent lies. We can see that both
RLL and EXACT-M scores markedly improved in
this setting. In response to these results, we trained
a decision-tree classifier to identify the correct an-
tecedent sentence with simple location and length
features and achieved 95% accuracy in identifying
the correct candidate sentence.
</bodyText>
<sectionHeader confidence="0.998483" genericHeader="conclusions">
6 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.99966425">
We have demonstrated the possibility of resolv-
ing complex abstract anaphora, namely, this-issue
anaphora having arbitrary antecedents. The work
takes the annotation work of Botley (2006) and Dip-
per and Zinsmeister (2011) to the next level by re-
solving this-issue anaphora automatically. We pro-
posed a set of 43 automatically extracted features
that can be used for resolving abstract anaphora.
</bodyText>
<footnote confidence="0.50645125">
12We performed a simple one-tailed, k-fold cross-validated
paired t-test at significance level p = 0.05 to determine whether
the difference between the EXACT-M scores of two feature
classes is statistically significant.
</footnote>
<bodyText confidence="0.976210395833333">
Our results show that general abstract-anaphora
resolution features (i.e., other than issue-specific
features) play a crucial role in resolving this-issue
anaphora. This is encouraging, as it suggests that
the approach could be generalized for other NPs —
especially NPs having similar semantic constraints
such as this problem, this decision, and this conflict.
The results also show that reduction of search
space markedly improves the resolution perfor-
mance, suggesting that a two-stage process that first
identifies the broad region of the antecedent and then
pinpoints the exact antecedent might work better
than the current single-stage approach. The rationale
behind this two-stage process is twofold. First, the
search space of abstract anaphora is large and noisy
compared to nominal anaphora.13 And second, it is
possible to reduce the search space and accurately
identify the broad region of the antecedents using
simple features such as the location of the anaphor
in the anaphor sentence (e.g., if the anaphor occurs
at the beginning of the sentence, the antecedent is
most likely present in the previous sentence).
We chose scientific articles over general text be-
cause in the former domain the actual referents are
seldom discourse deictic (i.e., not present in the
text). In the news domain, for instance, which we
have also examined and are presently annotating, a
large percentage of this-issue antecedents lie out-
side the text. For example, newspaper articles often
quote sentences of others who talk about the issues
in their own world, as shown in example (6).
(6) As surprising and encouraging to organizers of
the movement are the Wall Street names added
to their roster. Prominent among them is Paul
Singer, a hedge fund manager who is straight
and chairman of the conservative Manhattan
Institute. He has donated more than $8 million
to various same-sex marriage efforts, in states
including California, Maine, New Hampshire,
New Jersey, New York and Oregon, much of it
since 2007.
“It’s become something that gradually peo-
13If we consider all well-defined syntactic constituents of a
sentence as issue candidates, in our data, a sentence has on av-
erage 43.61 candidates. Combinations of several well-defined
syntactic constituents only add to this number. Hence if we
consider the antecedent candidates from the previous 2 or 3 sen-
tences, the search space can become quite large and noisy.
</bodyText>
<page confidence="0.898375">
1263
</page>
<bodyText confidence="0.999370770833333">
ple like myself weren’t afraid to fund, weren’t
afraid to speak out on,” Mr. Singer said in an in-
terview. “I’m somebody who is philosophically
very conservative, and on this issue I thought
that this really was important on the basis of
liberty and actual family stability.”
In such a case, the antecedent of this issue is not
always in the text of the newspaper article itself, but
must be inferred from the context of the quotation
and the world of the speaker quoted. That said, we
do not use any domain-specific information in our
this-issue resolution model. Our features are solely
based on distance, syntactic structure, and semantic
and lexical properties of the candidate antecedents
which could be extracted for text in any domain.
Issue anaphora can also be signalled by demon-
stratives other than this. However, for our initial
study, we chose this issue for two reasons. First, in
our corpus as well as in other general corpora such
as the New York Times corpus, issue occurs much
more frequently with this than other demonstratives.
Second, we did not want to increase the complexity
of the problem by including the plural issues.
Our approach needs further development to make
it useful. Our broad goal is to resolve abstract
anaphora signalled by label nouns in all kinds of
text. At present, the major obstacle is that there
is very little annotated data available that could be
used to train an abstract anaphora resolution sys-
tem. And the understanding of abstract anaphora
itself is still at an early stage; it would be prema-
ture to think about unsupervised approaches. In this
work, we studied the narrow problem of resolution
of this-issue anaphora in the medical domain to get
a good grasp of the general abstract-anaphora reso-
lution problem.
A number of extensions are planned for this work.
First, we will extend the work to resolve other ab-
stract anaphors (e.g., this decision, this problem).
Second, we will experiment with a two-stage reso-
lution approach. Third, we would like to explore the
effect of including serious discourse structure fea-
tures in our model. (The feature sets SC and C en-
code only shallow discourse information.) Finally,
during annotation, we noted a number of issue pat-
terns (e.g., An open question is X, X is under debate);
a possible extension is extracting issues and prob-
lems from text using these patterns as seed patterns.
</bodyText>
<sectionHeader confidence="0.9971" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9996025">
We thank Dr. Brian Budgell from the Canadian
Memorial Chiropractic College for annotating our
data and for helpful discussions. We also thank
the anonymous reviewers for their detailed and con-
structive comments. This research was financially
supported by the Natural Sciences and Engineering
Research Council of Canada and by the University
of Toronto.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999783615384615">
Nicholas Asher. 1993. Reference to Abstract Objects in
Discourse. Kluwer Academic Publishers, Dordrecht,
Netherlands.
Philip Simon Botley. 2006. Indirect anaphora: Testing
the limits of corpus-based linguistics. International
Journal of Corpus Linguistics, 11(1):73–112.
Donna K. Byron. 2003. Annotation of pronouns and
their antecedents: A comparison of two domains.
Technical Report, University of Rochester.
Donna K. Byron. 2004. Resolving pronominal refer-
ence to abstract entities. Ph.D. thesis, Rochester, New
York: University of Rochester.
Jos´e Casta˜no, Jason Zhang, and James Pustejovsky.
2002. Anaphora resolution in biomedical literature. In
Proceedings of the International Symposium on Refer-
ence Resolution for NLP, Alicante, Spain, June.
Bin Chen, Jian Su, Sinno Jialin Pan, and Chew Lim Tan.
2011. A unified event coreference resolution by inte-
grating multiple resolvers. In Proceedings of 5th Inter-
national Joint Conference on Natural Language Pro-
cessing, Chiang Mai, Thailand, November.
Pascal Denis and Jason Baldridge. 2008. Specialized
models and ranking for coreference resolution. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 660–669,
Honolulu, Hawaii, October. Association for Computa-
tional Linguistics.
Stefanie Dipper and Heike Zinsmeister. 2011. Annotat-
ing abstract anaphora. Language Resources and Eval-
uation, 69:1–16.
Miriam Eckert and Michael Strube. 2000. Dialogue acts,
synchronizing units, and anaphora resolution. Journal
of Semantics, 17:51–89.
Gill Francis. 1994. Labelling discourse: an aspect
of nominal group lexical cohesion. In Malcolm
Coulthard, editor, Advances in written text analysis,
pages 83–101, London. Routledge.
Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski.
1993. Cognitive status and the form of referring ex-
</reference>
<page confidence="0.854136">
1264
</page>
<reference confidence="0.999833098591549">
pressions in discourse. Language, 69(2):274–307,
June.
Graeme Hirst. 1981. Anaphora in Natural Language Un-
derstanding: A Survey, volume 119 of Lecture Notes
in Computer Science. Springer.
Thorsten Joachims. 2002. Optimizing search engines us-
ing clickthrough data. In ACM SIGKDD Conference
on Knowledge Discovery and Data Mining (KDD),
pages 133–142.
Klaus Krippendorff. 1995. On the reliability of unitizing
contiguous data. Sociological Methodology, 25:47–
76.
Klaus Krippendorff. 2004. Content Analysis: An In-
troduction to Its Methodology. Sage, Thousand Oaks,
CA, second edition.
Yu-Hsiang Lin and Tyne Liang. 2004. Pronominal and
sortal anaphora resolution for biomedical literature. In
Proceedings of ROCLING XVI: Conference on Com-
putational Linguistics and Speech Processing, Taiwan,
September.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summarization
Branches Out: Proceedings of the ACL-04 Workshop,
pages 74–81, Barcelona, Spain, July. Association for
Computational Linguistics.
Ruslan Mitkov. 2002. Anaphora Resolution. Longman.
Natalia N. Modjeska. 2003. Resolving Other-Anaphora.
Ph.D. thesis, School of Informatics, University of Ed-
inburgh.
Christoph M¨uller. 2008. Fully Automatic Resolution of
It, This and That in Unrestricted Multi-Party Dialog.
Ph.D. thesis, Universit¨at T¨ubingen.
Costanza Navarretta. 2011. Antecedent and referent
types of abstract pronominal anaphora. In Proceed-
ings of the Workshop Beyond Semantics: Corpus-
based investigations of pragmatic and discourse phe-
nomena, G¨ottingen, Germany, February.
Rebecca Passonneau. 1989. Getting at discourse refer-
ents. In Proceedings of the 27th Annual Meeting of
the Association for Computational Linguistics, pages
51–59, Vancouver, British Columbia, Canada, June.
Association for Computational Linguistics.
Massimo Poesio and Ron Artstein. 2008. Anaphoric
annotation in the ARRAU corpus. In Proceedings of
the Sixth International Conference on Language Re-
sources and Evaluation (LREC’08), Marrakech, Mo-
rocco, May.
Massimo Poesio and Natalia N. Modjeska. 2002.
The THIS-NPs hypothesis: A corpus-based investiga-
tion. In Proceedings of the 4th Discourse Anaphora
and Anaphor Resolution Conference (DAARC 2002),
pages 157–162, Lisbon, Portugal, September.
Massimo Poesio, Simone Ponzetto, and Yannick Versley.
2011. Computational models of anaphora resolution:
A survey. Unpublished.
Hans-J¨org Schmid. 2000. English Abstract Nouns As
Conceptual Shells: From Corpus to Cognition. Topics
in English Linguistics. De Gruyter Mouton, Berlin.
Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim.
2001. A machine learning approach to coreference
resolution of noun phrases. Computational Linguis-
tics, 27(4):521–544.
Michael Strube and Christoph M¨uller. 2003. A machine
learning approach to pronoun resolution in spoken di-
alogue. In Proceedings of the 41st Annual Meeting of
the Association for Computational Linguistics, pages
168–175, Sapporo, Japan, July. Association for Com-
putational Linguistics.
Manabu Torii and K. Vijay-Shanker. 2007. Sortal
anaphora resolution in Medline abstracts. Computa-
tionalIntelligence, 23(1):15–27.
</reference>
<page confidence="0.991149">
1265
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.790264">
<title confidence="0.997013">Resolving “This-issue” Anaphora</title>
<author confidence="0.923154">Varada</author>
<affiliation confidence="0.999825">Department of Computer University of</affiliation>
<address confidence="0.95391">Toronto, ON, M5S 3G4,</address>
<email confidence="0.999638">varada@cs.toronto.edu</email>
<author confidence="0.943867">Graeme</author>
<affiliation confidence="0.9998425">Department of Computer University of</affiliation>
<address confidence="0.961245">Toronto, ON, M5S 3G4,</address>
<email confidence="0.999881">gh@cs.toronto.edu</email>
<abstract confidence="0.999571095238095">We annotate and resolve a particular of abstract anaphora, namely, this- We propose a candidate model for that explores different specific and general abstract-anaphora features. The model is not restricted to nominal or verbal antecedents; rather, it is able to identify antecedents that are arbitrary spans of text. Our results show that (a) the model outperforms the strong adjacent-sentence baseline; (b) general abstract-anaphora features, distinguished from feaplay a crucial role in anaphora resolution, suggesting that our approach can be generalized for other such as problem and (c) it is possible to reduce the search space in order to improve performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
</authors>
<title>Reference to Abstract Objects in Discourse.</title>
<date>1993</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht, Netherlands.</location>
<contexts>
<context position="1479" citStr="Asher (1993)" startWordPosition="216" endWordPosition="217">phora resolution, suggesting that our approach can be generalized for other NPs such as this problem and this debate; and (c) it is possible to reduce the search space in order to improve performance. 1 Introduction Anaphora in which the anaphoric expression refers to an abstract object such as a proposition, a property, or a fact is known as abstract object anaphora. This is seen in the following examples. (1) [Be careful what you wish... because wishes sometimes come true.]i [That]i is what the Semiconductor Industry Association, which represents U.S. manufacturers, has been learning. (from Asher (1993)) (2) This prospective study suggested [that oral carvedilol is more effective than oral metoprolol in the prevention of AF after on-pump CABG]i. It is well tolerated when started before and continued after the surgery. However, further prospective studies are needed to clarify [this issue]i. (3) In principle, he said, airlines should be allowed [to sell standing-room-only tickets for adults]i — as long as [this decision]i was approved by their marketing departments. These examples highlight a difficulty not found with nominal anaphora. First, the anaphors refer to abstract concepts that can b</context>
<context position="7478" citStr="Asher (1993)" startWordPosition="1139" endWordPosition="1140">anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sortal anaphora in the medical domain using domain knowledge (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). But all these approaches focus only on the anaphors with nominal antecedents. By contrast, the area of abstract object anaphora remains relatively unexplored mainly because the standard anaphora resolution features such as agreement and apposition cannot be applied to abstract anaphora resolution. Asher (1993) built a theoretical framework to resolve abstract anaphora. He divided discourse abstract anaphora into three broad categories: event anaphora, proposition anaphora, and fact anaphora, and discussed how abstract entities can be resolved using discourse representation theory. Chen et al. (2011) focused on a subset of event anaphora and resolved event coreference chains in terms of the representative verbs of the events from the OntoNotes corpus. Our task differs from their work as follows. Chen et al. mainly 1256 focus on events and actions and use verbs as a proxy for the non-nominal antecede</context>
</contexts>
<marker>Asher, 1993</marker>
<rawString>Nicholas Asher. 1993. Reference to Abstract Objects in Discourse. Kluwer Academic Publishers, Dordrecht, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Simon Botley</author>
</authors>
<title>Indirect anaphora: Testing the limits of corpus-based linguistics.</title>
<date>2006</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="8809" citStr="Botley, 2006" startWordPosition="1355" endWordPosition="1356">tactic type of the antecedent; rather we provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphora resolution in the spoken dialogue domain (Eckert and Strube, 2000; Byron, 2004; M¨uller, 2008). These approaches go beyond nominal antecedents; however, they are restricted to spoken dialogues in specific domains and need serious adaptation if one wants to apply them to arbitrary text. In addition to research on resolution, there is also some work on effective annotation of abstract anaphora (Strube and M¨uller, 2003; Botley, 2006; Poesio and Artstein, 2008; Dipper and Zinsmeister, 2011). However, to the best of our knowledge, there is currently no English corpus annotated for issue anaphora antecedents. 3 Data and Annotation To create an initial annotated dataset, we collected 188 this {modifier}* issue instances along with the surrounding context from Medline abstracts.3 Five instances were discarded as they had an unrelated (publication related) sense. Among the remaining 183 instances, 132 instances were independently annotated by two annotators, a domain expert and a non-expert, and the remaining 51 instances were</context>
<context position="10141" citStr="Botley (2006)" startWordPosition="1567" endWordPosition="1568">developer) for testing. The annotator’s task was to mark arbitrary text segments as antecedents (without concern for their linguistic types). To make the task tractable, we assumed that an antecedent does not span multiple sentences but lies in a single sentence (since we are dealing with singular this-issue anaphors) and that it is a continuous span of text. 3Although our dataset is rather small, its size is similar to other available abstract anaphora corpora in English: 154 instances in Eckert and Strube (2000), 69 instances in Byron (2003), 462 instances annotated by only one annotator in Botley (2006), and 455 instances restricted to those which have only nominal or clausal antecedents in Poesio and Artstein (2008). r11 r12 r13 Annotator 1 id2 r21 r22 r23 r24 Annotator 2 id1 id2 Intersections 1 2 3 4 5 6 Figure 1: Example of annotated data. Bold segments denote the marked antecedents for the corresponding anaphor ids. rhj is the jth section identified by the annotator h. 3.1 Inter-annotator Agreement This kind of annotation — identifying and marking arbitrary units of text that are not necessarily constituents — requires a non-trivial variant of the usual inter-annotator agreement measures</context>
<context position="34576" citStr="Botley (2006)" startWordPosition="5671" endWordPosition="5672">ce extractor (Row 13) which knows the exact candidate sentence in which the antecedent lies. We can see that both RLL and EXACT-M scores markedly improved in this setting. In response to these results, we trained a decision-tree classifier to identify the correct antecedent sentence with simple location and length features and achieved 95% accuracy in identifying the correct candidate sentence. 6 Discussion and Conclusions We have demonstrated the possibility of resolving complex abstract anaphora, namely, this-issue anaphora having arbitrary antecedents. The work takes the annotation work of Botley (2006) and Dipper and Zinsmeister (2011) to the next level by resolving this-issue anaphora automatically. We proposed a set of 43 automatically extracted features that can be used for resolving abstract anaphora. 12We performed a simple one-tailed, k-fold cross-validated paired t-test at significance level p = 0.05 to determine whether the difference between the EXACT-M scores of two feature classes is statistically significant. Our results show that general abstract-anaphora resolution features (i.e., other than issue-specific features) play a crucial role in resolving this-issue anaphora. This is</context>
</contexts>
<marker>Botley, 2006</marker>
<rawString>Philip Simon Botley. 2006. Indirect anaphora: Testing the limits of corpus-based linguistics. International Journal of Corpus Linguistics, 11(1):73–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
</authors>
<title>Annotation of pronouns and their antecedents: A comparison of two domains.</title>
<date>2003</date>
<tech>Technical Report,</tech>
<institution>University of Rochester.</institution>
<contexts>
<context position="10077" citStr="Byron (2003)" startWordPosition="1557" endWordPosition="1558">instances for training and the latter instances (unseen by the developer) for testing. The annotator’s task was to mark arbitrary text segments as antecedents (without concern for their linguistic types). To make the task tractable, we assumed that an antecedent does not span multiple sentences but lies in a single sentence (since we are dealing with singular this-issue anaphors) and that it is a continuous span of text. 3Although our dataset is rather small, its size is similar to other available abstract anaphora corpora in English: 154 instances in Eckert and Strube (2000), 69 instances in Byron (2003), 462 instances annotated by only one annotator in Botley (2006), and 455 instances restricted to those which have only nominal or clausal antecedents in Poesio and Artstein (2008). r11 r12 r13 Annotator 1 id2 r21 r22 r23 r24 Annotator 2 id1 id2 Intersections 1 2 3 4 5 6 Figure 1: Example of annotated data. Bold segments denote the marked antecedents for the corresponding anaphor ids. rhj is the jth section identified by the annotator h. 3.1 Inter-annotator Agreement This kind of annotation — identifying and marking arbitrary units of text that are not necessarily constituents — requires a non</context>
</contexts>
<marker>Byron, 2003</marker>
<rawString>Donna K. Byron. 2003. Annotation of pronouns and their antecedents: A comparison of two domains. Technical Report, University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donna K Byron</author>
</authors>
<title>Resolving pronominal reference to abstract entities.</title>
<date>2004</date>
<booktitle>Ph.D. thesis,</booktitle>
<location>Rochester, New York: University of Rochester.</location>
<contexts>
<context position="8453" citStr="Byron, 2004" startWordPosition="1299" endWordPosition="1300"> chains in terms of the representative verbs of the events from the OntoNotes corpus. Our task differs from their work as follows. Chen et al. mainly 1256 focus on events and actions and use verbs as a proxy for the non-nominal antecedents. But this-issue antecedents cannot usually be represented by a verb. Our work is not restricted to a particular syntactic type of the antecedent; rather we provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphora resolution in the spoken dialogue domain (Eckert and Strube, 2000; Byron, 2004; M¨uller, 2008). These approaches go beyond nominal antecedents; however, they are restricted to spoken dialogues in specific domains and need serious adaptation if one wants to apply them to arbitrary text. In addition to research on resolution, there is also some work on effective annotation of abstract anaphora (Strube and M¨uller, 2003; Botley, 2006; Poesio and Artstein, 2008; Dipper and Zinsmeister, 2011). However, to the best of our knowledge, there is currently no English corpus annotated for issue anaphora antecedents. 3 Data and Annotation To create an initial annotated dataset, we c</context>
</contexts>
<marker>Byron, 2004</marker>
<rawString>Donna K. Byron. 2004. Resolving pronominal reference to abstract entities. Ph.D. thesis, Rochester, New York: University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Casta˜no</author>
<author>Jason Zhang</author>
<author>James Pustejovsky</author>
</authors>
<title>Anaphora resolution in biomedical literature.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Symposium on Reference Resolution for NLP,</booktitle>
<location>Alicante, Spain,</location>
<marker>Casta˜no, Zhang, Pustejovsky, 2002</marker>
<rawString>Jos´e Casta˜no, Jason Zhang, and James Pustejovsky. 2002. Anaphora resolution in biomedical literature. In Proceedings of the International Symposium on Reference Resolution for NLP, Alicante, Spain, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Chen</author>
<author>Jian Su</author>
<author>Sinno Jialin Pan</author>
<author>Chew Lim Tan</author>
</authors>
<title>A unified event coreference resolution by integrating multiple resolvers.</title>
<date>2011</date>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="7773" citStr="Chen et al. (2011)" startWordPosition="1181" endWordPosition="1184">ker, 2007). But all these approaches focus only on the anaphors with nominal antecedents. By contrast, the area of abstract object anaphora remains relatively unexplored mainly because the standard anaphora resolution features such as agreement and apposition cannot be applied to abstract anaphora resolution. Asher (1993) built a theoretical framework to resolve abstract anaphora. He divided discourse abstract anaphora into three broad categories: event anaphora, proposition anaphora, and fact anaphora, and discussed how abstract entities can be resolved using discourse representation theory. Chen et al. (2011) focused on a subset of event anaphora and resolved event coreference chains in terms of the representative verbs of the events from the OntoNotes corpus. Our task differs from their work as follows. Chen et al. mainly 1256 focus on events and actions and use verbs as a proxy for the non-nominal antecedents. But this-issue antecedents cannot usually be represented by a verb. Our work is not restricted to a particular syntactic type of the antecedent; rather we provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphor</context>
</contexts>
<marker>Chen, Su, Pan, Tan, 2011</marker>
<rawString>Bin Chen, Jian Su, Sinno Jialin Pan, and Chew Lim Tan. 2011. A unified event coreference resolution by integrating multiple resolvers. In Proceedings of 5th International Joint Conference on Natural Language Processing, Chiang Mai, Thailand, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Jason Baldridge</author>
</authors>
<title>Specialized models and ranking for coreference resolution.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>660--669</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="24824" citStr="Denis and Baldridge (2008)" startWordPosition="4004" endWordPosition="4007">g word of the candidate is a preposition ISPPUNCT 1 iff the preceding word of the candidate is a punctuation ISFPUNCT 1 iff the following word of the candidate is a punctuation LENGTH (L) LEN length of the candidate in words Table 2: Feature sets for this-issue resolution. All features are extracted automatically. 1260 overlap features, and context features. 4.3 Candidate Ranking Model Given an anaphor ai and a set of candidate antecedents C = {C1,C2,...,Ck}, the problem of anaphora resolution is to choose the best candidate antecedent for ai. We follow the candidate-ranking model proposed by Denis and Baldridge (2008). The advantage of the candidate-ranking model over the mention-pair model is that it overcomes the strong independence assumption made in mentionpair models and evaluates how good a candidate is relative to all other candidates. We train our model as follows. If the anaphor is a this-issue anaphor, the set C is extracted using the candidate extraction algorithm from Section 4.1. Then a corresponding set of feature vectors, Cf = {Cf1,Cf2,...,Cfk}, is created using the features in Table 2. The training instances are created as described by Soon et al. (2001). Note that the instance creation is </context>
</contexts>
<marker>Denis, Baldridge, 2008</marker>
<rawString>Pascal Denis and Jason Baldridge. 2008. Specialized models and ranking for coreference resolution. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 660–669, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefanie Dipper</author>
<author>Heike Zinsmeister</author>
</authors>
<title>Annotating abstract anaphora. Language Resources and Evaluation,</title>
<date>2011</date>
<pages>69--1</pages>
<contexts>
<context position="8867" citStr="Dipper and Zinsmeister, 2011" startWordPosition="1361" endWordPosition="1364">provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphora resolution in the spoken dialogue domain (Eckert and Strube, 2000; Byron, 2004; M¨uller, 2008). These approaches go beyond nominal antecedents; however, they are restricted to spoken dialogues in specific domains and need serious adaptation if one wants to apply them to arbitrary text. In addition to research on resolution, there is also some work on effective annotation of abstract anaphora (Strube and M¨uller, 2003; Botley, 2006; Poesio and Artstein, 2008; Dipper and Zinsmeister, 2011). However, to the best of our knowledge, there is currently no English corpus annotated for issue anaphora antecedents. 3 Data and Annotation To create an initial annotated dataset, we collected 188 this {modifier}* issue instances along with the surrounding context from Medline abstracts.3 Five instances were discarded as they had an unrelated (publication related) sense. Among the remaining 183 instances, 132 instances were independently annotated by two annotators, a domain expert and a non-expert, and the remaining 51 instances were annotated only by the domain expert. We use the former in</context>
<context position="34610" citStr="Dipper and Zinsmeister (2011)" startWordPosition="5674" endWordPosition="5678">13) which knows the exact candidate sentence in which the antecedent lies. We can see that both RLL and EXACT-M scores markedly improved in this setting. In response to these results, we trained a decision-tree classifier to identify the correct antecedent sentence with simple location and length features and achieved 95% accuracy in identifying the correct candidate sentence. 6 Discussion and Conclusions We have demonstrated the possibility of resolving complex abstract anaphora, namely, this-issue anaphora having arbitrary antecedents. The work takes the annotation work of Botley (2006) and Dipper and Zinsmeister (2011) to the next level by resolving this-issue anaphora automatically. We proposed a set of 43 automatically extracted features that can be used for resolving abstract anaphora. 12We performed a simple one-tailed, k-fold cross-validated paired t-test at significance level p = 0.05 to determine whether the difference between the EXACT-M scores of two feature classes is statistically significant. Our results show that general abstract-anaphora resolution features (i.e., other than issue-specific features) play a crucial role in resolving this-issue anaphora. This is encouraging, as it suggests that </context>
</contexts>
<marker>Dipper, Zinsmeister, 2011</marker>
<rawString>Stefanie Dipper and Heike Zinsmeister. 2011. Annotating abstract anaphora. Language Resources and Evaluation, 69:1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Eckert</author>
<author>Michael Strube</author>
</authors>
<title>Dialogue acts, synchronizing units, and anaphora resolution.</title>
<date>2000</date>
<journal>Journal of Semantics,</journal>
<pages>17--51</pages>
<contexts>
<context position="8440" citStr="Eckert and Strube, 2000" startWordPosition="1295" endWordPosition="1298">esolved event coreference chains in terms of the representative verbs of the events from the OntoNotes corpus. Our task differs from their work as follows. Chen et al. mainly 1256 focus on events and actions and use verbs as a proxy for the non-nominal antecedents. But this-issue antecedents cannot usually be represented by a verb. Our work is not restricted to a particular syntactic type of the antecedent; rather we provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphora resolution in the spoken dialogue domain (Eckert and Strube, 2000; Byron, 2004; M¨uller, 2008). These approaches go beyond nominal antecedents; however, they are restricted to spoken dialogues in specific domains and need serious adaptation if one wants to apply them to arbitrary text. In addition to research on resolution, there is also some work on effective annotation of abstract anaphora (Strube and M¨uller, 2003; Botley, 2006; Poesio and Artstein, 2008; Dipper and Zinsmeister, 2011). However, to the best of our knowledge, there is currently no English corpus annotated for issue anaphora antecedents. 3 Data and Annotation To create an initial annotated </context>
<context position="10047" citStr="Eckert and Strube (2000)" startWordPosition="1550" endWordPosition="1553">y by the domain expert. We use the former instances for training and the latter instances (unseen by the developer) for testing. The annotator’s task was to mark arbitrary text segments as antecedents (without concern for their linguistic types). To make the task tractable, we assumed that an antecedent does not span multiple sentences but lies in a single sentence (since we are dealing with singular this-issue anaphors) and that it is a continuous span of text. 3Although our dataset is rather small, its size is similar to other available abstract anaphora corpora in English: 154 instances in Eckert and Strube (2000), 69 instances in Byron (2003), 462 instances annotated by only one annotator in Botley (2006), and 455 instances restricted to those which have only nominal or clausal antecedents in Poesio and Artstein (2008). r11 r12 r13 Annotator 1 id2 r21 r22 r23 r24 Annotator 2 id1 id2 Intersections 1 2 3 4 5 6 Figure 1: Example of annotated data. Bold segments denote the marked antecedents for the corresponding anaphor ids. rhj is the jth section identified by the annotator h. 3.1 Inter-annotator Agreement This kind of annotation — identifying and marking arbitrary units of text that are not necessarily</context>
</contexts>
<marker>Eckert, Strube, 2000</marker>
<rawString>Miriam Eckert and Michael Strube. 2000. Dialogue acts, synchronizing units, and anaphora resolution. Journal of Semantics, 17:51–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gill Francis</author>
</authors>
<title>Labelling discourse: an aspect of nominal group lexical cohesion.</title>
<date>1994</date>
<booktitle>Advances in written text analysis,</booktitle>
<pages>83--101</pages>
<editor>In Malcolm Coulthard, editor,</editor>
<location>London. Routledge.</location>
<contexts>
<context position="3868" citStr="Francis (1994)" startWordPosition="591" endWordPosition="592"> abstract anaphora, but they are not common. 1255 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1255–1265, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics tives can be used in isolation (That in (1)) or with nouns (e.g., this issue in (2)). The latter follows the pattern demonstrative {modifier}* noun. The demonstrative acts as a determiner and the noun following the demonstrative imposes selectional constraints for the antecedent, as in examples (2) and (3). Francis (1994) calls such nouns label nouns, which “serve to encapsulate or package a stretch of discourse”. Schmid (2000) refers to them as shell nouns, a metaphoric term which reflects different functions of these nouns such as encapsulation, pointing, and signalling. Demonstrative nouns, along with pronouns like both and either, are referred to as sortal anaphors (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). Casta˜no et al. observed that sortal anaphors are prevalent in the biomedical literature. They noted that among 100 distinct anaphors derived from a corpus of 70 Medlin</context>
</contexts>
<marker>Francis, 1994</marker>
<rawString>Gill Francis. 1994. Labelling discourse: an aspect of nominal group lexical cohesion. In Malcolm Coulthard, editor, Advances in written text analysis, pages 83–101, London. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeanette K Gundel</author>
<author>Nancy Hedberg</author>
<author>Ron Zacharski</author>
</authors>
<title>Cognitive status and the form of referring expressions in discourse.</title>
<date>1993</date>
<journal>Language,</journal>
<volume>69</volume>
<issue>2</issue>
<contexts>
<context position="16891" citStr="Gundel et al., 1993" startWordPosition="2695" endWordPosition="2698">fficient to restrict the antecedent search space to well-defined syntactic constituents.6 In our data, we did not find anaphoric chains for any of the this-issue anaphor instances, which indicates that the antecedents of this-issue anaphors are 5We refer to every syntactic constituent identified by the parser as a well-defined syntactic constituent. 6Indeed, many of mixed type antecedents (nearly threequarters of them) are the result of parser attachment errors, but many are not. 1258 in the reader’s local memory and not in the global memory. This observation supports the THIS-NPs hypothesis (Gundel et al., 1993; Poesio and Modjeska, 2002) that this-NPs are used to refer to entities which are active albeit not in focus, i.e., they are not the center of the previous utterance. 4 Resolution Algorithm 4.1 Candidate Extraction For correct resolution, the set of extracted candidates must contain the correct antecedent in the first place. The problem of candidate extraction is non-trivial in abstract anaphora resolution because the antecedents are of many different types of syntactic constituents such as clauses, sentences, and nominalizations. Drawing on our observation that the mixed type antecedents are</context>
<context position="20278" citStr="Gundel et al., 1993" startWordPosition="3235" endWordPosition="3238">e candidate is an issue verb (e.g., speculate, hypothesize, argue, debate), whereas IHEAD checks whether the candidate head in the dependency tree is an issue word (e.g., controversy, uncertain, unknown). The general abstractanaphora resolution features do not make use of the semantic properties of the word issue. Some of these features are derived empirically from the training data (e.g., ST, L, D). The EL feature is borrowed from M¨uller (2008) and encodes the embedding level of the candidate within the candidate sentence. The MC feature tries to capture the idea of the THIS-NPs hypothesis (Gundel et al., 1993; Poesio and Modjeska, 2002) that the antecedents of thisNP anaphors are not the center of the previous utterance. The general abstract-anaphora features in the SR feature class capture the semantic role of the candidate in the candidate sentence. We used the Illinois Semantic Role Labeler9 for SR features. The general abstract-anaphora features also contain a few lexical features (e.g., M, SC). But these features are independent of the semantic properties of the word issue. The general abstract-anaphora resolution features also contain dependency-tree features, lexical8The threshold 5 was emp</context>
</contexts>
<marker>Gundel, Hedberg, Zacharski, 1993</marker>
<rawString>Jeanette K. Gundel, Nancy Hedberg, and Ron Zacharski. 1993. Cognitive status and the form of referring expressions in discourse. Language, 69(2):274–307, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Anaphora in Natural Language Understanding: A Survey,</title>
<date>1981</date>
<booktitle>of Lecture Notes in Computer Science.</booktitle>
<volume>119</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="6420" citStr="Hirst, 1981" startWordPosition="980" endWordPosition="981">m.nih.gov/bsd/pmresources. html semantic forms, which makes the problem interesting and non-trivial. Third, issue referents in scientific literature generally lie in the previous sentence or two, which makes the problem tractable. Fourth, issues in Medline abstracts are generally associated with clinical problems in the medical domain and spell out the motivation of the research presented in the article. So extraction of this information would be useful in any biomedical information retrieval system. 2 Related Work Anaphora resolution has been extensively studied in computational linguistics (Hirst, 1981; Mitkov, 2002; Poesio et al., 2011). But CL research has mostly focused on nominal anaphora resolution (e.g., resolving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on r</context>
</contexts>
<marker>Hirst, 1981</marker>
<rawString>Graeme Hirst. 1981. Anaphora in Natural Language Understanding: A Survey, volume 119 of Lecture Notes in Computer Science. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<pages>133--142</pages>
<contexts>
<context position="25857" citStr="Joachims, 2002" startWordPosition="4183" endWordPosition="4184"> vectors, Cf = {Cf1,Cf2,...,Cfk}, is created using the features in Table 2. The training instances are created as described by Soon et al. (2001). Note that the instance creation is simpler than for general coreference resolution because of the absence of anaphoric chains in our data. For every anaphor ai and eligible candidates Cf = {Cf1,Cf2,...,Cfk}, we create training examples (ai,Cfi,label),VCfi E Cf. The label is 1 if Ci is the true antecedent of the anaphor ai, otherwise the label is −1. The examples with label 1 get the rank of 1, while other examples get the rank of 2. We use SVMrank (Joachims, 2002) for training the candidate-ranking model. During testing, the trained model is used to rank the candidates of each test instance of this-issue anaphor. 5 Evaluation In this section we present the evaluation of each component of our resolution system. 5.1 Evaluation of Candidate Extraction The set of candidate antecedents extracted by the method from Section 4.1 contained the correct antecedent 92% of the time. Each anaphor had, on average, 23.80 candidates, of which only 5.19 candidates were nominal type. The accuracy dropped to 84% when we did not extract mixed type candidates. The error ana</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>On the reliability of unitizing contiguous data. Sociological Methodology,</title>
<date>1995</date>
<pages>25--47</pages>
<contexts>
<context position="10828" citStr="Krippendorff, 1995" startWordPosition="1677" endWordPosition="1678">lausal antecedents in Poesio and Artstein (2008). r11 r12 r13 Annotator 1 id2 r21 r22 r23 r24 Annotator 2 id1 id2 Intersections 1 2 3 4 5 6 Figure 1: Example of annotated data. Bold segments denote the marked antecedents for the corresponding anaphor ids. rhj is the jth section identified by the annotator h. 3.1 Inter-annotator Agreement This kind of annotation — identifying and marking arbitrary units of text that are not necessarily constituents — requires a non-trivial variant of the usual inter-annotator agreement measures. We use Krippendorff’s reliability coefficient for unitizing (au) (Krippendorff, 1995) which has not often been used or described in CL. In our context, unitizing means marking the spans of the text that serve as the antecedent for the given anaphors within the given text. The coefficient au assumes that the annotated sections do not overlap in a single annotator’s output and our data satisfies this criterion.4 The general form of coefficient au is: au = 1− uDo (1) uDe where uDo and uDe are observed and expected disagreements respectively. Both disagreement quantities express the average squared differences between the mismatching pairs of values assigned by annotators to given</context>
</contexts>
<marker>Krippendorff, 1995</marker>
<rawString>Klaus Krippendorff. 1995. On the reliability of unitizing contiguous data. Sociological Methodology, 25:47– 76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Content Analysis: An Introduction to Its Methodology. Sage,</title>
<date>2004</date>
<location>Thousand Oaks, CA,</location>
<note>second edition.</note>
<contexts>
<context position="11667" citStr="Krippendorff, 2004" startWordPosition="1820" endWordPosition="1821">the annotated sections do not overlap in a single annotator’s output and our data satisfies this criterion.4 The general form of coefficient au is: au = 1− uDo (1) uDe where uDo and uDe are observed and expected disagreements respectively. Both disagreement quantities express the average squared differences between the mismatching pairs of values assigned by annotators to given units of analysis. au = 1 indicates perfect reliability and au = 0 indicates the absence of reliability. When au &lt; 0, the disagreement is systematic. Annotated data with reliability of au &gt; 0.80 is considered reliable (Krippendorff, 2004). Krippendorff’s au is non-trivial, and explaining it in detail would take too much space, but the general idea, in our context, is as follows. The annotators mark the antecedents corresponding to each anaphor in their respective copies of the text, as shown in Figure 1. The marked antecedents are mutually exclusive sections r; we denote the jth section identified 4If antecedents overlap with each other in a single annotator’s output (which is a rare event) we construct data that satisfies the non-overlap criterion by creating different copies of the same text corresponding to each anaphor ins</context>
</contexts>
<marker>Krippendorff, 2004</marker>
<rawString>Klaus Krippendorff. 2004. Content Analysis: An Introduction to Its Methodology. Sage, Thousand Oaks, CA, second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu-Hsiang Lin</author>
<author>Tyne Liang</author>
</authors>
<title>Pronominal and sortal anaphora resolution for biomedical literature.</title>
<date>2004</date>
<booktitle>In Proceedings of ROCLING XVI: Conference on Computational Linguistics and Speech Processing,</booktitle>
<location>Taiwan,</location>
<contexts>
<context position="4266" citStr="Lin and Liang, 2004" startWordPosition="652" endWordPosition="655">ws the pattern demonstrative {modifier}* noun. The demonstrative acts as a determiner and the noun following the demonstrative imposes selectional constraints for the antecedent, as in examples (2) and (3). Francis (1994) calls such nouns label nouns, which “serve to encapsulate or package a stretch of discourse”. Schmid (2000) refers to them as shell nouns, a metaphoric term which reflects different functions of these nouns such as encapsulation, pointing, and signalling. Demonstrative nouns, along with pronouns like both and either, are referred to as sortal anaphors (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). Casta˜no et al. observed that sortal anaphors are prevalent in the biomedical literature. They noted that among 100 distinct anaphors derived from a corpus of 70 Medline abstracts, 60% were sortal anaphors. But how often do demonstrative nouns refer to abstract objects? We observed that from a corpus of 74,000 randomly chosen Medline2 abstracts, of the first 150 most frequently occurring distinct demonstrative nouns (frequency &gt; 30), 51.3% were abstract, 41.3% were concrete, and 7.3% were discourse deictic. This shows that abstract anaphora resolution is an im</context>
<context position="7133" citStr="Lin and Liang, 2004" startWordPosition="1088" endWordPosition="1091">esolution (e.g., resolving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sortal anaphora in the medical domain using domain knowledge (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). But all these approaches focus only on the anaphors with nominal antecedents. By contrast, the area of abstract object anaphora remains relatively unexplored mainly because the standard anaphora resolution features such as agreement and apposition cannot be applied to abstract anaphora resolution. Asher (1993) built a theoretical framework to resolve abstract anaphora. He divided discourse abstract anaphora into three broad categories: event anaphora, proposition anaphora, and fact anaphora, and discussed how abstract entities can be resolved using discourse r</context>
</contexts>
<marker>Lin, Liang, 2004</marker>
<rawString>Yu-Hsiang Lin and Tyne Liang. 2004. Pronominal and sortal anaphora resolution for biomedical literature. In Proceedings of ROCLING XVI: Conference on Computational Linguistics and Speech Processing, Taiwan, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,</booktitle>
<pages>74--81</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Barcelona, Spain,</location>
<contexts>
<context position="27925" citStr="Lin, 2004" startWordPosition="4545" endWordPosition="4546"> propose two metrics for abstract anaphora evaluation. The simplest metric is the percentage of antecedents on which the system and the annotated gold data agree. We denote this metric as EXACTM (Exact Match) and compute it as the ratio of number of correctly identified antecedents to the total number of marked antecedents. This metric is a good indicator of a system’s performance; however, it is a rather strict evaluation because, as we noted in section 1, issues generally have no precise boundaries in the text. So we propose another metric called RLL, which is similar to the ROUGE-L metric (Lin, 2004) used for the evaluation of automatic summarization. Let the marked antecedents of the gold corpus for k anaphor instances be G = (g1,g2,...,gk) and the system-annotated antecedents be A = (a1,a2,...,ak). Let the number of words in G and A be m and n respectively. Let LCS(gi,ai) be the the number of words in the longest common subsequence of gi and ai. Then the precision (PRLL) and recall (RRLL) over the whole data set are computed as shown in equations (2) and (3). PRLL is the total number of word overlaps between the gold and system-annotated antecedents normalized by the number of words in </context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74–81, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
</authors>
<title>Anaphora Resolution.</title>
<date>2002</date>
<publisher>Longman.</publisher>
<contexts>
<context position="6434" citStr="Mitkov, 2002" startWordPosition="982" endWordPosition="983">/pmresources. html semantic forms, which makes the problem interesting and non-trivial. Third, issue referents in scientific literature generally lie in the previous sentence or two, which makes the problem tractable. Fourth, issues in Medline abstracts are generally associated with clinical problems in the medical domain and spell out the motivation of the research presented in the article. So extraction of this information would be useful in any biomedical information retrieval system. 2 Related Work Anaphora resolution has been extensively studied in computational linguistics (Hirst, 1981; Mitkov, 2002; Poesio et al., 2011). But CL research has mostly focused on nominal anaphora resolution (e.g., resolving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sorta</context>
</contexts>
<marker>Mitkov, 2002</marker>
<rawString>Ruslan Mitkov. 2002. Anaphora Resolution. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natalia N Modjeska</author>
</authors>
<title>Resolving Other-Anaphora.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>School of Informatics, University of Edinburgh.</institution>
<contexts>
<context position="6939" citStr="Modjeska, 2003" startWordPosition="1058" endWordPosition="1059"> Work Anaphora resolution has been extensively studied in computational linguistics (Hirst, 1981; Mitkov, 2002; Poesio et al., 2011). But CL research has mostly focused on nominal anaphora resolution (e.g., resolving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sortal anaphora in the medical domain using domain knowledge (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). But all these approaches focus only on the anaphors with nominal antecedents. By contrast, the area of abstract object anaphora remains relatively unexplored mainly because the standard anaphora resolution features such as agreement and apposition cannot be applied to abstract anaphora resolution. Asher (1993) built a theoretical framework to resolve abstract anaphora. </context>
</contexts>
<marker>Modjeska, 2003</marker>
<rawString>Natalia N. Modjeska. 2003. Resolving Other-Anaphora. Ph.D. thesis, School of Informatics, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph M¨uller</author>
</authors>
<title>Fully Automatic Resolution of It, This and That in Unrestricted Multi-Party Dialog.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit¨at T¨ubingen.</institution>
<marker>M¨uller, 2008</marker>
<rawString>Christoph M¨uller. 2008. Fully Automatic Resolution of It, This and That in Unrestricted Multi-Party Dialog. Ph.D. thesis, Universit¨at T¨ubingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Costanza Navarretta</author>
</authors>
<title>Antecedent and referent types of abstract pronominal anaphora.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop Beyond Semantics: Corpusbased investigations of pragmatic and discourse phenomena,</booktitle>
<location>G¨ottingen, Germany,</location>
<contexts>
<context position="3162" citStr="Navarretta, 2011" startWordPosition="482" endWordPosition="483">ause could also be thought to be the correct antecedent. Third, the actual referents are not always the precise textual antecedents. The actual referent in (2), the issue to be clarified, is whether oral carvedilol is more effective than oral metoprolol in the prevention of AF after on-pump CABG or not, a variant of the antecedent text. Generally, abstract anaphora, as distinguished from nominal anaphora, is signalled in English by pronouns this, that, and it (M¨uller, 2008). But in abstract anaphora, English prefers demonstratives to personal pronouns and definite articles (Passonneau, 1989; Navarretta, 2011).1 Demonstra1This is not to say that personal pronouns and definite articles do not occur in abstract anaphora, but they are not common. 1255 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1255–1265, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics tives can be used in isolation (That in (1)) or with nouns (e.g., this issue in (2)). The latter follows the pattern demonstrative {modifier}* noun. The demonstrative acts as a determiner and the noun following the de</context>
</contexts>
<marker>Navarretta, 2011</marker>
<rawString>Costanza Navarretta. 2011. Antecedent and referent types of abstract pronominal anaphora. In Proceedings of the Workshop Beyond Semantics: Corpusbased investigations of pragmatic and discourse phenomena, G¨ottingen, Germany, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Passonneau</author>
</authors>
<title>Getting at discourse referents.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>51--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="3143" citStr="Passonneau, 1989" startWordPosition="479" endWordPosition="481">ning the marked clause could also be thought to be the correct antecedent. Third, the actual referents are not always the precise textual antecedents. The actual referent in (2), the issue to be clarified, is whether oral carvedilol is more effective than oral metoprolol in the prevention of AF after on-pump CABG or not, a variant of the antecedent text. Generally, abstract anaphora, as distinguished from nominal anaphora, is signalled in English by pronouns this, that, and it (M¨uller, 2008). But in abstract anaphora, English prefers demonstratives to personal pronouns and definite articles (Passonneau, 1989; Navarretta, 2011).1 Demonstra1This is not to say that personal pronouns and definite articles do not occur in abstract anaphora, but they are not common. 1255 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1255–1265, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics tives can be used in isolation (That in (1)) or with nouns (e.g., this issue in (2)). The latter follows the pattern demonstrative {modifier}* noun. The demonstrative acts as a determiner and the no</context>
</contexts>
<marker>Passonneau, 1989</marker>
<rawString>Rebecca Passonneau. 1989. Getting at discourse referents. In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics, pages 51–59, Vancouver, British Columbia, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Ron Artstein</author>
</authors>
<title>Anaphoric annotation in the ARRAU corpus.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="8836" citStr="Poesio and Artstein, 2008" startWordPosition="1357" endWordPosition="1360"> the antecedent; rather we provide the flexibility of marking arbitrary spans of text as antecedents. There are also some prominent approaches to abstract anaphora resolution in the spoken dialogue domain (Eckert and Strube, 2000; Byron, 2004; M¨uller, 2008). These approaches go beyond nominal antecedents; however, they are restricted to spoken dialogues in specific domains and need serious adaptation if one wants to apply them to arbitrary text. In addition to research on resolution, there is also some work on effective annotation of abstract anaphora (Strube and M¨uller, 2003; Botley, 2006; Poesio and Artstein, 2008; Dipper and Zinsmeister, 2011). However, to the best of our knowledge, there is currently no English corpus annotated for issue anaphora antecedents. 3 Data and Annotation To create an initial annotated dataset, we collected 188 this {modifier}* issue instances along with the surrounding context from Medline abstracts.3 Five instances were discarded as they had an unrelated (publication related) sense. Among the remaining 183 instances, 132 instances were independently annotated by two annotators, a domain expert and a non-expert, and the remaining 51 instances were annotated only by the doma</context>
<context position="10257" citStr="Poesio and Artstein (2008)" startWordPosition="1583" endWordPosition="1586">t concern for their linguistic types). To make the task tractable, we assumed that an antecedent does not span multiple sentences but lies in a single sentence (since we are dealing with singular this-issue anaphors) and that it is a continuous span of text. 3Although our dataset is rather small, its size is similar to other available abstract anaphora corpora in English: 154 instances in Eckert and Strube (2000), 69 instances in Byron (2003), 462 instances annotated by only one annotator in Botley (2006), and 455 instances restricted to those which have only nominal or clausal antecedents in Poesio and Artstein (2008). r11 r12 r13 Annotator 1 id2 r21 r22 r23 r24 Annotator 2 id1 id2 Intersections 1 2 3 4 5 6 Figure 1: Example of annotated data. Bold segments denote the marked antecedents for the corresponding anaphor ids. rhj is the jth section identified by the annotator h. 3.1 Inter-annotator Agreement This kind of annotation — identifying and marking arbitrary units of text that are not necessarily constituents — requires a non-trivial variant of the usual inter-annotator agreement measures. We use Krippendorff’s reliability coefficient for unitizing (au) (Krippendorff, 1995) which has not often been use</context>
</contexts>
<marker>Poesio, Artstein, 2008</marker>
<rawString>Massimo Poesio and Ron Artstein. 2008. Anaphoric annotation in the ARRAU corpus. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Natalia N Modjeska</author>
</authors>
<title>The THIS-NPs hypothesis: A corpus-based investigation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 4th Discourse Anaphora and Anaphor Resolution Conference (DAARC</booktitle>
<pages>157--162</pages>
<location>Lisbon, Portugal,</location>
<contexts>
<context position="16919" citStr="Poesio and Modjeska, 2002" startWordPosition="2699" endWordPosition="2703">the antecedent search space to well-defined syntactic constituents.6 In our data, we did not find anaphoric chains for any of the this-issue anaphor instances, which indicates that the antecedents of this-issue anaphors are 5We refer to every syntactic constituent identified by the parser as a well-defined syntactic constituent. 6Indeed, many of mixed type antecedents (nearly threequarters of them) are the result of parser attachment errors, but many are not. 1258 in the reader’s local memory and not in the global memory. This observation supports the THIS-NPs hypothesis (Gundel et al., 1993; Poesio and Modjeska, 2002) that this-NPs are used to refer to entities which are active albeit not in focus, i.e., they are not the center of the previous utterance. 4 Resolution Algorithm 4.1 Candidate Extraction For correct resolution, the set of extracted candidates must contain the correct antecedent in the first place. The problem of candidate extraction is non-trivial in abstract anaphora resolution because the antecedents are of many different types of syntactic constituents such as clauses, sentences, and nominalizations. Drawing on our observation that the mixed type antecedents are generally a combination of </context>
<context position="20306" citStr="Poesio and Modjeska, 2002" startWordPosition="3239" endWordPosition="3242">ue verb (e.g., speculate, hypothesize, argue, debate), whereas IHEAD checks whether the candidate head in the dependency tree is an issue word (e.g., controversy, uncertain, unknown). The general abstractanaphora resolution features do not make use of the semantic properties of the word issue. Some of these features are derived empirically from the training data (e.g., ST, L, D). The EL feature is borrowed from M¨uller (2008) and encodes the embedding level of the candidate within the candidate sentence. The MC feature tries to capture the idea of the THIS-NPs hypothesis (Gundel et al., 1993; Poesio and Modjeska, 2002) that the antecedents of thisNP anaphors are not the center of the previous utterance. The general abstract-anaphora features in the SR feature class capture the semantic role of the candidate in the candidate sentence. We used the Illinois Semantic Role Labeler9 for SR features. The general abstract-anaphora features also contain a few lexical features (e.g., M, SC). But these features are independent of the semantic properties of the word issue. The general abstract-anaphora resolution features also contain dependency-tree features, lexical8The threshold 5 was empirically derived. Antecedent</context>
</contexts>
<marker>Poesio, Modjeska, 2002</marker>
<rawString>Massimo Poesio and Natalia N. Modjeska. 2002. The THIS-NPs hypothesis: A corpus-based investigation. In Proceedings of the 4th Discourse Anaphora and Anaphor Resolution Conference (DAARC 2002), pages 157–162, Lisbon, Portugal, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>Simone Ponzetto</author>
<author>Yannick Versley</author>
</authors>
<title>Computational models of anaphora resolution: A survey.</title>
<date>2011</date>
<publisher>Unpublished.</publisher>
<contexts>
<context position="6456" citStr="Poesio et al., 2011" startWordPosition="984" endWordPosition="987">html semantic forms, which makes the problem interesting and non-trivial. Third, issue referents in scientific literature generally lie in the previous sentence or two, which makes the problem tractable. Fourth, issues in Medline abstracts are generally associated with clinical problems in the medical domain and spell out the motivation of the research presented in the article. So extraction of this information would be useful in any biomedical information retrieval system. 2 Related Work Anaphora resolution has been extensively studied in computational linguistics (Hirst, 1981; Mitkov, 2002; Poesio et al., 2011). But CL research has mostly focused on nominal anaphora resolution (e.g., resolving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sortal anaphora in the medi</context>
</contexts>
<marker>Poesio, Ponzetto, Versley, 2011</marker>
<rawString>Massimo Poesio, Simone Ponzetto, and Yannick Versley. 2011. Computational models of anaphora resolution: A survey. Unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-J¨org Schmid</author>
</authors>
<title>English Abstract Nouns As Conceptual Shells: From Corpus to Cognition. Topics in English Linguistics. De Gruyter Mouton,</title>
<date>2000</date>
<location>Berlin.</location>
<contexts>
<context position="3976" citStr="Schmid (2000)" startWordPosition="608" endWordPosition="609">ds in Natural Language Processing and Computational Natural Language Learning, pages 1255–1265, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics tives can be used in isolation (That in (1)) or with nouns (e.g., this issue in (2)). The latter follows the pattern demonstrative {modifier}* noun. The demonstrative acts as a determiner and the noun following the demonstrative imposes selectional constraints for the antecedent, as in examples (2) and (3). Francis (1994) calls such nouns label nouns, which “serve to encapsulate or package a stretch of discourse”. Schmid (2000) refers to them as shell nouns, a metaphoric term which reflects different functions of these nouns such as encapsulation, pointing, and signalling. Demonstrative nouns, along with pronouns like both and either, are referred to as sortal anaphors (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). Casta˜no et al. observed that sortal anaphors are prevalent in the biomedical literature. They noted that among 100 distinct anaphors derived from a corpus of 70 Medline abstracts, 60% were sortal anaphors. But how often do demonstrative nouns refer to abstract objects? We ob</context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Hans-J¨org Schmid. 2000. English Abstract Nouns As Conceptual Shells: From Corpus to Cognition. Topics in English Linguistics. De Gruyter Mouton, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wee Meng Soon</author>
<author>Hwee Tou Ng</author>
<author>Chung Yong Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="25387" citStr="Soon et al. (2001)" startWordPosition="4097" endWordPosition="4100">te-ranking model proposed by Denis and Baldridge (2008). The advantage of the candidate-ranking model over the mention-pair model is that it overcomes the strong independence assumption made in mentionpair models and evaluates how good a candidate is relative to all other candidates. We train our model as follows. If the anaphor is a this-issue anaphor, the set C is extracted using the candidate extraction algorithm from Section 4.1. Then a corresponding set of feature vectors, Cf = {Cf1,Cf2,...,Cfk}, is created using the features in Table 2. The training instances are created as described by Soon et al. (2001). Note that the instance creation is simpler than for general coreference resolution because of the absence of anaphoric chains in our data. For every anaphor ai and eligible candidates Cf = {Cf1,Cf2,...,Cfk}, we create training examples (ai,Cfi,label),VCfi E Cf. The label is 1 if Ci is the true antecedent of the anaphor ai, otherwise the label is −1. The examples with label 1 get the rank of 1, while other examples get the rank of 2. We use SVMrank (Joachims, 2002) for training the candidate-ranking model. During testing, the trained model is used to rank the candidates of each test instance </context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Wee Meng Soon, Hwee Tou Ng, and Chung Yong Lim. 2001. A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Christoph M¨uller</author>
</authors>
<title>A machine learning approach to pronoun resolution in spoken dialogue.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>168--175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<marker>Strube, M¨uller, 2003</marker>
<rawString>Michael Strube and Christoph M¨uller. 2003. A machine learning approach to pronoun resolution in spoken dialogue. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 168–175, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manabu Torii</author>
<author>K Vijay-Shanker</author>
</authors>
<title>Sortal anaphora resolution in Medline abstracts.</title>
<date>2007</date>
<journal>ComputationalIntelligence,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="4298" citStr="Torii and Vijay-Shanker, 2007" startWordPosition="656" endWordPosition="659">trative {modifier}* noun. The demonstrative acts as a determiner and the noun following the demonstrative imposes selectional constraints for the antecedent, as in examples (2) and (3). Francis (1994) calls such nouns label nouns, which “serve to encapsulate or package a stretch of discourse”. Schmid (2000) refers to them as shell nouns, a metaphoric term which reflects different functions of these nouns such as encapsulation, pointing, and signalling. Demonstrative nouns, along with pronouns like both and either, are referred to as sortal anaphors (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). Casta˜no et al. observed that sortal anaphors are prevalent in the biomedical literature. They noted that among 100 distinct anaphors derived from a corpus of 70 Medline abstracts, 60% were sortal anaphors. But how often do demonstrative nouns refer to abstract objects? We observed that from a corpus of 74,000 randomly chosen Medline2 abstracts, of the first 150 most frequently occurring distinct demonstrative nouns (frequency &gt; 30), 51.3% were abstract, 41.3% were concrete, and 7.3% were discourse deictic. This shows that abstract anaphora resolution is an important component of general ana</context>
<context position="7165" citStr="Torii and Vijay-Shanker, 2007" startWordPosition="1092" endWordPosition="1095">lving multiple ambiguous mentions of a single entity representing a person, a location, or an organization) mainly for two reasons. First, nominal anaphora is the most frequently occurring anaphora in most domains, and second, there is a substantial amount of annotated data available for this kind of anaphora. Besides pronominal anaphora, some work has been done on complement anaphora (Modjeska, 2003) (e.g., British and other European steelmakers). There is also some research on resolving sortal anaphora in the medical domain using domain knowledge (Casta˜no et al., 2002; Lin and Liang, 2004; Torii and Vijay-Shanker, 2007). But all these approaches focus only on the anaphors with nominal antecedents. By contrast, the area of abstract object anaphora remains relatively unexplored mainly because the standard anaphora resolution features such as agreement and apposition cannot be applied to abstract anaphora resolution. Asher (1993) built a theoretical framework to resolve abstract anaphora. He divided discourse abstract anaphora into three broad categories: event anaphora, proposition anaphora, and fact anaphora, and discussed how abstract entities can be resolved using discourse representation theory. Chen et al</context>
</contexts>
<marker>Torii, Vijay-Shanker, 2007</marker>
<rawString>Manabu Torii and K. Vijay-Shanker. 2007. Sortal anaphora resolution in Medline abstracts. ComputationalIntelligence, 23(1):15–27.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>