<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000308">
<title confidence="0.929784">
Joint Inference for Event Timeline Construction
</title>
<author confidence="0.998465">
Quang Xuan Do Wei Lu Dan Roth
</author>
<affiliation confidence="0.847849666666667">
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA
</affiliation>
<email confidence="0.998926">
{quangdo2,luwei,danr}@illinois.edu
</email>
<sectionHeader confidence="0.996658" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999771157894737">
This paper addresses the task of construct-
ing a timeline of events mentioned in a given
text. To accomplish that, we present a novel
representation of the temporal structure of a
news article based on time intervals. We then
present an algorithmic approach that jointly
optimizes the temporal structure by coupling
local classifiers that predict associations and
temporal relations between pairs of tempo-
ral entities with global constraints. Moreover,
we present ways to leverage knowledge pro-
vided by event coreference to further improve
the system performance. Overall, our experi-
ments show that the joint inference model sig-
nificantly outperformed the local classifiers by
9.2% of relative improvement in Fl. The ex-
periments also suggest that good event coref-
erence could make remarkable contribution to
a robust event timeline construction system.
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999837615384615">
Inferring temporal relations amongst a collection of
events in a text is a significant step towards vari-
ous important tasks such as automatic information
extraction and document comprehension. Over the
past few years, with the development of the Time-
Bank corpus (Pustejovsky et al., 2003) , there have
been several works on building automatic systems
for such a task (Mani et al., 2006; Chambers and
Jurafsky, 2008; Yoshikawa et al., 2009; Denis and
Muller, 2011).
Most previous works devoted much efforts to the
task of identifying relative temporal relations (such
as before, or overlap) amongst events (Chambers
</bodyText>
<figureCaption confidence="0.911477333333333">
Figure 1: A graphical illustration of our timeline representation.
The e’s, t’s and I’s are events, time points and time intervals,
respectively.
</figureCaption>
<bodyText confidence="0.999905666666667">
and Jurafsky, 2008; Denis and Muller, 2011), with-
out addressing the task of identifying correct asso-
ciations between events and their absolute time of
occurrence. Even if this issue is addressed, certain
restrictions are often imposed for efficiency reasons
(Yoshikawa et al., 2009; Verhagen et al., 2010). In
practice, however, being able to automatically infer
the correct time of occurrence associated with each
event is crucial. Such information not only leads to
better text comprehension, but also enables fusion
of event structures extracted from multiple articles
or domains.
In this work, we are specifically interested in map-
ping events into an universal timeline representa-
tion. Besides inferring the relative temporal rela-
tions amongst the events, we would also like to au-
tomatically infer a specific absolute time of occur-
rence for each event mentioned in the text. Unlike
previous work, we associate each event with a spe-
cific absolute time interval inferred from the text. An
example timeline representation is illustrated in Fig.
</bodyText>
<figure confidence="0.997024642857143">
|
|
I2
e4
Time
−→
•
•
•
•
•
−∞
e2
e7 − e6
I3
I1
•
+∞
|
|
|
|
e3/e5
t1
e1
t2
t3
t4
</figure>
<page confidence="0.971058">
677
</page>
<note confidence="0.8215335">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 677–687, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<listItem confidence="0.5294575">
1. Further details of our timeline representation are
given in Sec. 2.3.
</listItem>
<bodyText confidence="0.999961483870968">
We perform global inference by combining a col-
lection of local pairwise classifiers through the use
of an Integer Linear Programming (ILP) formula-
tion that promotes global coherence among local de-
cisions. The formulation allows our model to pre-
dict both event-event relations and event-time inter-
val associations simultaneously. We show that, with
the use of time intervals instead of time points, our
approach leads to a more concise ILP formulation
with reduced number of variables and constraints.
Moreover, we observed that event coreference can
reveal important information for such a task. We
propose that different event mentions that refer to
the same event can be grouped together before clas-
sification and performing global inference. This can
reduce the amount of efforts in both classification
and inference stages and can potentially eliminate
mistakes that would be made otherwise without such
coreference information. To the best of our knowl-
edge, our proposal of leveraging event coreference
to support event timeline construction is novel.
Our experiments on a collection of annotated
news articles from the standard ACE dataset demon-
strate that our approach produces robust timelines of
events. We show that our algorithmic approach is
able to combine various local evidences to produce
a global coherent temporal structure, with improved
overall performance. Furthermore, the experiments
show that the overall performance can be further im-
proved by exploiting knowledge from event corefer-
ence.
</bodyText>
<sectionHeader confidence="0.977081" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999988666666667">
We focus on the task of mapping event mentions in
a news article to a timeline. We first briefly describe
and define several basic concepts.
</bodyText>
<subsectionHeader confidence="0.910556">
2.1 Events
</subsectionHeader>
<bodyText confidence="0.999945357142857">
Following the annotation guidelines of the ACE
project, we define an event as an action or occur-
rence that happens with associated participants or
arguments. We also distinguish between events and
event mentions, where a unique event can be core-
ferred to by a set of explicit event mentions in an
article. Formally, an event P is co-referred to by
a set of event mentions (e�1, e�2, ... , ek). Each event
mention e can be written as p(a1, a2, ... , al), where
the predicate p is the word that triggers the presence
of e in text, and a1, a2,... al are the arguments asso-
ciated with e. In this work we focus on four tempo-
ral relations between two event mentions including
before, after, overlap and no relation.
</bodyText>
<subsectionHeader confidence="0.998115">
2.2 Time Intervals
</subsectionHeader>
<bodyText confidence="0.998291230769231">
Similar to Denis and Muller (2011), we define time
intervals as pairs of time endpoints. Each time in-
terval I is denoted by [t−, t+], where t− and t+ are
two time endpoints representing the lower and upper
bound of the interval I, respectively, with t− &lt; t+.
The general form of a time endpoint is written as
“YYYY-MM-DD hh:mm:ss”. An endpoint can be un-
defined, in which case it is set to an infinity value:
−oc, or +oc. There are two types of time intervals:
Explicit intervals are time intervals that can be
extracted directly from a given text. For example,
consider the following snippet of an article in our
data set: The litigation covers buyers in auctions
outside the United States between January 1, 1993
and February 7, 2000. In this example, we can ex-
tract and normalize two time intervals which are ex-
plicitly written, including January 1, 1993 —* [1993-
01-01 00:00:00, 1993-01-01 23:59:59] and Febru-
ary 7, 2000 —* [2000-02-07 00:00:00, 2000-02-07
23:59:59]. Moreover, an explicit interval can also
be formed by one or more separate explicit temporal
expressions. In the example above, the connective
term between relates the two expressions to form a
single time interval: between January 1, 1993 and
February 7, 2000 —* [1993-01-01 00:00:00, 2000-
02-07 23:59:59]. To extract explicit time intervals
from text, we use the time interval extractor de-
scribed in Zhao et al. (2012).
Implicit intervals are time intervals that are not
explicitly mentioned in the text. We observed that
there are events that cannot be assigned to any pre-
cise time interval but are roughly known to occur
in the past or in the future relative to the Doc-
ument Creation Time (DCT) of the article. We
introduce two implicit time intervals to represent
the past and the future events as (−oc, t−DCT] and
[t+DCT , +oc), respectively. In addition, we also al-
low an event mention to be assigned into the entire
timeline, which is denoted by (−oc, +oc) if we can-
</bodyText>
<page confidence="0.998106">
678
</page>
<bodyText confidence="0.999814">
not identify its time of occurrence. We also consider
DCT as an implicit interval.
We say that the time interval Ii precedes the time
interval Ij on a timeline if and only if tz &lt; t−j ,
which also implies that Ii succeeds Ij if and only if
t−i &gt; t� . The two intervals overlap, otherwise.
</bodyText>
<subsectionHeader confidence="0.977343">
2.3 Timeline
</subsectionHeader>
<bodyText confidence="0.999984838709677">
We define a timeline as a partially ordered set of time
intervals. Fig. 1 gives a graphical illustration of an
example timeline, where events are annotated and
associated with time intervals. Relations amongst
events can be properly reflected in the timeline rep-
resentation. For example, in the figure, the events e1
and e2 are both associated with the interval I1. The
relation between them is no relation, since it is un-
clear which occurs first. On the other hand, e5 and
e3 both happen in the interval I2 but they form an
overlap relation. The events e6 and e7 occur within
the same interval I3, but e7 precedes (i.e. before) e6
on the timeline. The event e4 is associated with the
interval (−oo, +oo), indicating there is no knowl-
edge about its time of occurrence.
We believe that such a timeline representation
for temporally ordering events has several advan-
tages over the temporal graph representations used
in previous works (Chambers and Jurafsky, 2008;
Yoshikawa et al., 2009; Denis and Muller, 2011).
Unlike previous works, in our model the events are
partially ordered in a single timeline, where each
event is associated with a precise time interval. This
improves human interpretability of the temporal re-
lations amongst events and time. This property of
our timeline representation, thus, facilitates merg-
ing multiple timelines induced from different arti-
cles. Furthermore, as we will show later, the use
of time intervals within the timeline representation
simplifies the global inference formulation and thus
the inference process.
</bodyText>
<sectionHeader confidence="0.986583" genericHeader="method">
3 A Joint Timeline Model
</sectionHeader>
<bodyText confidence="0.999975739130434">
Our task is to induce a globally coherent timeline
for a given article. We thus adopt a global infer-
ence model for performing the task. The model
consists of two components: (1) two local pairwise
classifiers, one between event mentions and time in-
tervals (the E–T classifier) and one between event
mentions themselves (the E–E classifier), and (2)
a joint inference module that enforces global co-
herency constraints on the final outputs of the two
local classifiers. Fig. 2 shows a simplified temporal
structure of event mentions and time intervals of an
article in our model.
Our E–T classifier is different from previous
work (Chambers and Jurafsky, 2008; Yoshikawa et
al., 2009; Denis and Muller, 2011), where such clas-
sifiers were trained to identify temporal relations be-
tween event mentions and a temporal expression. In
our work, in order to construct absolute timeline of
event mentions, temporal expressions are captured
and normalized as absolute time intervals. The E–T
classifiers are then used to assign event mentions to
their contextually corresponding time intervals.
We also lifted several restrictions imposed in pre-
vious work (Bethard et al., 2007; Yoshikawa et al.,
2009; Verhagen et al., 2010). Specifically, we do
not require that event mentions and time expressions
have to appear in the same sentence, and we do not
require two event mentions have to appear very close
to each other (e.g., main event mentions in adjacent
sentences) in order to be considered as candidate
pairs for classification. Instead, we performed clas-
sifications over all pairs of event mentions and time
intervals as well as over all pairs of event mentions.
We show through experiments that lifting these re-
strictions is indeed important (see Sec. 5).
Another important improvement over previous
work is our global inference model We would like
to highlight that our work is also distinct from most
previous works in the global inference component.
Specifically, our global inference model jointly op-
timizes the E-E relations amongst event mentions
and their associations, E-T, with temporal informa-
tion (intervals in our case). Previous work (Cham-
bers and Jurafsky, 2008; Denis and Muller, 2011),
on the other hand, assumed that the E-T information
is given and only tried to improve E-E.
</bodyText>
<subsectionHeader confidence="0.999417">
3.1 The Pairwise Classifiers
</subsectionHeader>
<bodyText confidence="0.999703666666667">
We first describe our local classifiers that associate
event mention with time interval and classify tempo-
ral relations between event mentions, respectively.
CE−T: is the E–T classifier that associates an
event mention with a time interval. Given an event
mention and a time interval, the classifier predicts
</bodyText>
<page confidence="0.998146">
679
</page>
<figureCaption confidence="0.995096">
Figure 2: A simplified temporal structure of an article. There
</figureCaption>
<bodyText confidence="0.8413288">
are m time intervals Il · · · Im and n event mentions el · · · en.
A solid edge indicates an association between an interval and
an event mention, whereas a dash edge illustrates a temporal
relation between two event mentions.
whether the former associates with the latter.
</bodyText>
<equation confidence="0.9994035">
CE−T(ei,Ij) → {0, 1},
∀i,j,1 ≤ i ≤ n,1 ≤ j ≤ m, (1)
</equation>
<bodyText confidence="0.999934">
where n and m are the number of event mentions
and time intervals in an article, respectively.
CE−E: is the E–E classifier that identifies
the temporal relation between two event mentions.
Given a pair of event mentions, the classifier predicts
one of the four temporal relations between them:
before, after, overlap and no relation. Specifically:
</bodyText>
<equation confidence="0.995716">
CE−E(ei, ej) → { b, a, o, n},
∀i, j,1 ≤ i, j ≤ n, i _6 j, (2)
</equation>
<bodyText confidence="0.986690590163935">
For training of the classifiers, we define a set of
features following some previous work (Bethard et
al., 2007; Chambers and Jurafsky, 2008; Yoshikawa
et al., 2009), together with some additional features
that we believe to be helpful for the interval-based
representation. We describe the base features below
and use † and ‡ to denote the features used for CE−T
and CE−E, respectively. We use the term temporal
entity (or entity, for short) to refer to either an event
mention or a time interval.
Lexical Features: A set of lexical features related
to the temporal entities: (i)†‡ the word, lemma and
part-of-speech of the input event mentions and the
context surrounding them, where the context is de-
fined as a window of 2 words before and after the
mention; (ii)† the modal verbs to the left and to the
right of the event mention; (iii)‡ the temporal con-
nectives between the event mentions1.
1We define a list of temporal connectives including before,
after, since, when, meanwhile, lately, etc.
Syntactic Features: (i)†‡ which entity appears
first in the text; (ii)†‡ whether the two entities appear
in the same sentence; (iii)†‡ the quantized number of
sentences between the two entities2; (iv)†‡ whether
the input event mentions are covered by preposi-
tional phrases and what are the heads of the phrases;
(v)†‡ if the entities are in the same sentence, what is
their least common constituent on the syntactic parse
tree; (vi)† whether there is any other temporal entity
that is closer to one of the two entities.
Semantic Features‡: A set of semantic features,
mostly related to the input event mentions: (i)
whether the input event mentions have a common
synonym from their synsets in WordNet (Fellbaum,
1998); (ii) whether the input event mentions have a
common derivational form derived from WordNet.
Linguistic Features†‡: The tense and the aspect
of the input event mentions. We use an in-house
rule-based recognizer to extract these features.
Time Interval Features†: A set of features re-
lated to the input time interval: (i) whether the
interval is implicit; (ii) if it is implicit, identify
its interval type: “dct” _ [t−DCT, t�DCT1, “past” _
(−∞, t−DCT1, “feature” _ [tDCT, +∞), and “en-
tire” _ (−∞, +∞); (iii) the interval is before, after
or overlapping with the DCT.
We note that unlike many previous work (Mani et
al., 2006; Chambers and Jurafsky, 2008; Denis and
Muller, 2011), our classifiers do not use any gold
annotations of event attributes (event class, tense, as-
pect, modal and polarity) provided in the TimeBank
corpus as features.
In our work, we use a regularized averaged Per-
ceptron (Freund and Schapire, 1999) as our classifi-
cation algorithm3. We used the one-vs.-all scheme
to transform a set of binary classifiers into a multi-
class classifier (for CE−E). The raw prediction
scores were converted into probability distribution
using the Softmax function (Bishop 1996). If there
are n classes and the raw score of class i is acti, the
posterior estimation for class i is:
</bodyText>
<footnote confidence="0.796197166666667">
eacti
E1≤j≤n eact.,
2We quantize the number of sentences between two entities
to 0, 1, 2, less than 5 and greater than or equal to 5
3Other algorithm (e.g. SVM) gave comparable or worse re-
sults, so we only show the results from Averaged Perceptron.
</footnote>
<figure confidence="0.800218857142857">
I1
• • •
I2
I3
Im
e1 e2 e3 e4 e5 • • • en-1 en
P(i) _
</figure>
<page confidence="0.937819">
680
</page>
<subsectionHeader confidence="0.987043">
3.2 Joint Inference for Event Timeline
</subsectionHeader>
<bodyText confidence="0.999705193548387">
To exploit the interaction among the temporal enti-
ties in an article, we optimize the predicted tempo-
ral structure, formed by predictions from CE−T and
CE−E, w.r.t. a set of global constraints that enforce
coherency on the final structure. We perform exact
inference using Integer Linear Programming (ILP)
as in (Roth and Yih, 2007; Clarke and Lapata, 2008).
We use the Gurobi Optimizer4 as a solver.
Let I = {I1, I2, ... , Im} denote the set of time
intervals extracted from an article, and let E =
{e1, e2, ... , en} denote all event mentions in the
same article. Let EI = {(ei, Ij) ∈ E × I|ei ∈
E, Ij ∈ I} denote the set of all pairs of event
mentions and time intervals. We also denote the
set of event mention pairs by EE = {(ei, ej) ∈
E × E|ei ∈ E, ej ∈ E, i =6 j}. The prediction prob-
ability of an association of a pair eI ∈ EI, given
by classifier CE−T, is denoted by p(eI,1)5. Now, let
R = {b, d, o, n} be the set of temporal relations be-
tween two event mentions. The prediction proba-
bility of an event mention pair ee ∈ EE that takes
temporal relation r, given by CE−E, is denoted by
p(ee,r). Furthermore, we define x(eI,1) to be a binary
indicator variable that takes on the value 1 iff an as-
sociation is predicted between e and I. Similarly,
we define a binary indicator variable y(ee,r) of a pair
of event mentions ee that takes on the value 1 iff ee
is predicted to hold the relation r.
The objective function is then defined as a linear
combination of the prediction probabilities from the
two local classifiers as follows:
</bodyText>
<equation confidence="0.991350666666667">
p(eI,1) · x(eI,1)
+ (1 − A) � � �p(ee,r) · y(ee,r) (3)
eeE££ rEIZ
</equation>
<bodyText confidence="0.714329">
subject to the following constraints:
</bodyText>
<equation confidence="0.987848">
x(eI,1) ∈ {0, 1}, ∀eI ∈ EI (4)
y(ee,r) ∈ {0, 1}, ∀ee ∈ EE,r ∈ R (5)
� y(ee,r) = 1, ∀ee ∈ EE (6)
rEIZ
</equation>
<footnote confidence="0.831566">
4http://gurobi.com/
5This value is complementary to the non-association proba-
bility, denoted by P(eI,0) = 1 − P(eI,1)
</footnote>
<bodyText confidence="0.9998611">
We use the single parameter A to balance the over-
all contribution of two components E-T and E-E.
A is determined through cross validation tuning on
a development set. We use (4) and (5) to make sure
x(eI,1) and y(ee,r) are binary values. The equality
constraint (6) ensures that exactly one particular re-
lation can be assigned to each event mention pair.
In addition, we also require that each event is as-
sociated with only one time interval. These con-
straints are encoded as follows:
</bodyText>
<equation confidence="0.92658">
� x(eI,1) = 1, ∀e ∈ E (7)
IEZ
</equation>
<bodyText confidence="0.987876333333333">
Our model also enforces reflexivity and transitiv-
ity constraints on the relations among event men-
tions as follows:
</bodyText>
<equation confidence="0.99638725">
y(eiej,r) − y(ejei,r) = 0,
∀eiej = (ei, ej) ∈ EE, i =6 j (8)
y(eiej,r1) + y(ejek,r2) − y(eiek,r3) ≤ 1,
∀eiej, ejek, eiek ∈ EE, i =6 j =6 k (9)
</equation>
<bodyText confidence="0.9996988125">
The equality constraints in (8) encode reflexive
property of event-event relations, where the rela-
tion r� denotes the inversion of the relation r. The
set of possible (r, r) pairs is defined as follows:
{(�b, d), (d,�b), (o, o), (n, n)}. Following the work
of (Bramsen et al., 2006; Chambers and Jurafsky,
2008), we encode transitive closure of relations be-
tween event mentions with inequality constraints in
(9), which states that if the pair (ei, ej) has a certain
relation r1, and the pair (ej, ek) has the relation r2,
then the relation r3 must be satisfied between ei and
ek. Examples of such triple (r1, r2, r3) include (b, b,
b) and (d, d, d).
Finally, to capture the interactions between our
local pairwise classifiers we add the following con-
straints:
</bodyText>
<equation confidence="0.959084333333333">
x(eiIk,1) + x(ejIl,1) − yheiej,bi ≤ 1,
∀eiIk, ejIl ∈ EI, ∀eiej ∈ EE,
Ik precedes Il, i =6 j, k =6 l (10)
</equation>
<bodyText confidence="0.998930333333333">
Intuitively, the inequality constraints in (10) spec-
ify that a temporal relation between two event men-
tions can be inferred from their respective associated
</bodyText>
<figure confidence="0.85290925">
arg max
x,y
[A
eIE£Z
</figure>
<page confidence="0.983533">
681
</page>
<bodyText confidence="0.999756076923077">
time intervals. Specifically, if two event mentions ei
and ej are associated with two time intervals Ik and
Ii respectively, and Ik precedes Ii in the timeline,
then ei must happen before ej.
It is important to note that our interval-based for-
mulation is more concise in terms of the number of
variables and constraints needed in the ILP relative
to time expression-based (or timepoint-based) for-
mulations used in previous work (Chambers and Ju-
rafsky, 2008). Specifically, in such timepoint-based
formulations, the relation between each event men-
tion and each time expression needs to be inferred,
resulting in |E||T ||RT  |variables, where |E|, |T |,
and |RT  |are the numbers of event mentions, time
points, and temporal relations respectively. In con-
trast, only |E||I |variables are required in our for-
mulation, where |I |is the number of intervals (since
we extract intervals explicitly, |I |is roughly equal
to |T |). Furthermore, performing inference with the
timepoint-based formulation would require |E||T |
equality constraints to enforce that each event men-
tion can take only one relation in RT for a particular
time point, whereas our interval-based model only
requires |E |constraints, since each event is strictly
associated with one interval (see Eqn. (7)). We jus-
tify the benefits of our formulation later in Sec. 5.4.
</bodyText>
<sectionHeader confidence="0.990734" genericHeader="method">
4 Incorporating Knowledge from Event
Coreference
</sectionHeader>
<bodyText confidence="0.99983775">
One of the key contributions of our work is using
event coreference information to enhance the time-
line construction performance. This is motivated by
the following two principles:
</bodyText>
<listItem confidence="0.9962756">
(P1) All mentions of a unique event are associ-
ated with the same time interval, and overlap with
each other.
(P2) All mentions of an event have the same tem-
poral relation with all mentions of another event.
</listItem>
<bodyText confidence="0.99971925">
The example below, extracted from an article pub-
lished on 03/11/2003 in the Automatic Content Ex-
traction (ACE), 2005, corpus6 serves to illustrate the
significance of event coreference to our task.
</bodyText>
<footnote confidence="0.915326">
6http://www.itl.nist.gov/iad/mig/tests/ace/2005/
</footnote>
<bodyText confidence="0.9466523125">
The world’s most powerful fine art auction houses,
Sotheby’s and Christie’s, have agreed to [el =
pay] 40 million dollars to settle an international
price-fixing scam, Sotheby’s said. The [e2 = pay-
ment], if approved by the courts, would settle a
slew of [el = suits] by clients over auctions held
between 1993 and 2000 outside the US.... Sotheby’s
and Christie’s will each [e3 = pay] 20 million dol-
lars,” said Sotheby’s, which operates in 34 countries.
In this example, there are 4 event mentions, whose
trigger words are highlighted in bold face. The un-
derlined text gives an explicit time interval: I1 =
[1993-01-01 00:00:00, 2000-12-31 23:59:59] (we
ignore 2 other intervals given by 1993 and 2000
to simplify the illustration). Now if we consider
the event mention e12, it actually belongs to the im-
plicit future interval I2 = [2003-03-11 23:59:59,
+∞). Nevertheless, there is a reasonable chance
that CE−T associates it with I1, given that they both
appear in the same sentence, and there is no di-
rect evident feature indicating the event will actu-
ally happen in the future. In such a situation, using
a local classifier to identify the correct temporal as-
sociation could be challenging.
Fortunately, precise knowledge from event coref-
erence may help alleviate such a problem. The
knowledge reveals that the 4 event mentions can be
grouped into 2 distinct events: E1 = {e11, e12, e1�},
E2 = {e21}. If CE−T can make a strong prediction
in associating the event mention e11 (or e1�) to I2, in-
stead of I1, the system will have a high chance to
re-assign e12 to I2 based on principle (P1). Similarly,
if CE−E is effective in figuring out that some men-
tion of event E1 occurs after some mention of E2,
then all the mentions of E1 would be predicted to
occur after all mentions in E2 according to (P2).
To incorporate knowledge from event coreference
into our classifiers and the joint inference model, we
use the following procedure: (1) performing classi-
fication with CE−T and CE−E on the data, (2) using
the knowledge from event coreference to overwrite
the prediction probabilities obtained by the two lo-
cal classifiers in step (1), and (3) applying the joint
inference model on the new prediction probabilities
obtained from (2). We note that if we stop at step (2),
we get the outputs of the local classifiers enhanced
by event coreference knowledge.
To overwrite the classification probabilities using
</bodyText>
<page confidence="0.997013">
682
</page>
<sectionHeader confidence="0.87006" genericHeader="method">
5 Experimental Study
</sectionHeader>
<bodyText confidence="0.999758833333333">
We first describe the experimental data and then
present and discuss the experimental results.
event coreference knowledge, we propose two ap-
proaches as follows:
MaxScore: We define the probability between
any mention e E Ei and an interval I as follows:
</bodyText>
<equation confidence="0.982721">
P(e&apos;, I) (11)
</equation>
<bodyText confidence="0.9989752">
where P(e&apos;, I) is the classifier (CE_T) probability
for associating event mention e&apos; to the time interval.
On the other hand, the probabilities for associat-
ing the set of temporal relations, R, to each pair of
mentions in Ei x Ej, is given by the following pair:
</bodyText>
<equation confidence="0.899787">
arg max P�((ei0, ej0), r))
(ei0,ej0)EEixEj,rEIZ
P�((ei, ej)*, r), br E R (12)
</equation>
<bodyText confidence="0.99814525">
In other words, over all possible event mention
pairs and relations, we first pick the pair who glob-
ally obtains the highest probability for some rela-
tion. Next, we simply take the probability distri-
bution of that event mention pair as the distribution
over the relations, for the event pair.
SumScore: The probability between any mention
e E Ei and an interval I is obtained by:
</bodyText>
<equation confidence="0.990591">
1 X
|Ei |e0EEi
</equation>
<bodyText confidence="0.988002333333333">
To obtain the probability distribution over the set
of temporal relations, R, for any pair of mentions in
Ei x Ej, we used the following procedure:
</bodyText>
<equation confidence="0.9991564">
Xr* = arg max
rEIZ eiEEi
(ei, ej)* = arg max P��(ei0, ej0), r*)
(ei0,ej0)EEixEj
p(ee,r) = P�((ei, ej)*, r), br E R (14)
</equation>
<bodyText confidence="0.999905916666667">
In other words, given two groups of event men-
tions, we first compute the total score of each rela-
tion, and select the relation which has the highest
score. Next from the list of pairs of event mentions
from the two groups, we select the pair which has the
relation r* with highest score compared to all other
pairs. The probability distribution of this pair will
be used as the probability distribution of all event
mention pairs between the two events.
In both approaches, we assign the overlap rela-
tions to all pairs of event mentions in the same event
with probability 1.0.
</bodyText>
<subsectionHeader confidence="0.991585">
5.1 Data and Setup
</subsectionHeader>
<bodyText confidence="0.999996666666667">
Most previous works in temporal reasoning used
the TimeBank corpus as a benchmark. The cor-
pus contains a fairly diverse collection of anno-
tated event mentions, without any specific focus on
certain event types. According to the annotation
guideline of the corpus, most of verbs, nominal-
izations, adjectives, predicative clauses and preposi-
tional phrases can be tagged as events. However, in
practice, when performing temporal reasoning about
events in a given text, one is typically interested in
significant and typed events, such as Killing, Leg-
islation, Election. Furthermore, event mentions in
TimeBank are annotated with neither event argu-
ments nor event coreference information.
We noticed that the ACE 2005 corpus contains the
annotation that we are interested in. The corpus con-
sists of articles annotated with event mentions (with
event triggers and arguments) and event coreference
information. To create an experimental data set for
our work, we selected from the corpus 20 newswire
articles published in March 2003. To extract time
intervals from the articles, we used the time inter-
val extractor described in (Zhao et al., 2012) with
minimal post-processing. Implicit intervals are also
added according to Sec. 2.2. We then hired an anno-
tator with expertise in the field to annotate the data
with the following information: (i) event mention
and time interval association, and (ii) the temporal
relations between event mentions, including {b, d,
o}. The annotator was not required to annotate all
pairs of event mentions, but as many as possible.
Next, we saturated the relations based on the ini-
tial annotations as follows: (i) event mentions that
had not been associated with any time intervals were
assigned to the entire timeline interval (−oo, +oo),
and (ii) added inferred temporal relations between
event mentions with reflectivity and transitivity. Ta-
ble 1 shows the data statistics before and after sat-
uration. There are totally 8312 event pairs from 20
documents, including no relation pairs. We note that
in a separate experiment, we still evaluated CE_E
on the TimeBank corpus and got better performance
</bodyText>
<equation confidence="0.993209125">
p(eI,�) = max
e0EEi
(ei,ej)* =
p(ee,r) =
p(eI,�) =
P�(e&apos;, I) (13)
X P�((ei, ej), r)
ejEEj
</equation>
<page confidence="0.989601">
683
</page>
<table confidence="0.998163333333333">
Data #Intervals #E-mentions #E-T #E-E
Initial 232 324 305 376
Saturated 232 324 324 5940
</table>
<tableCaption confidence="0.999973">
Table 1: The statistics of our experimental data set.
</tableCaption>
<bodyText confidence="0.995164583333333">
than a corresponding classifier in an existing work
(see Sec. 5.4).
We conducted all experiments with 5-fold cross
validation at the instance level on our data set after
saturation. The global inference model was applied
on a whole document. The results of the systems are
reported in averaged precision, recall and F1 score
on the association performance, for CE−T, and the
temporal relations (we excluded the n relation, for
CE−E). We also measured the overall performance
of the systems by computing the average of the per-
formance of the classifiers.
</bodyText>
<subsectionHeader confidence="0.99973">
5.2 A Baseline
</subsectionHeader>
<bodyText confidence="0.999989">
We developed a baseline system that works as fol-
lows. It associates an event mention with the closest
time interval found in the same sentence. If such
an interval is not found, the baseline associates the
mention with the closest time interval to the left.
If the interval is again not found, the mention will
be associated with the DCT interval. The baseline
is based on the intuition of natural reading order:
events that are mentioned earlier are likely to pre-
cede those mentioned later. For the temporal rela-
tion between a pair of event mentions, the baseline
treats the event mention that appears earlier in the
text as temporally happening before the other men-
tion. The baseline performance is shown in the first
group of results in Table 2.
</bodyText>
<subsectionHeader confidence="0.999709">
5.3 Our Systems
</subsectionHeader>
<bodyText confidence="0.999959362068966">
For our systems, we first evaluated the performance
of our local pairwise classifiers and the global in-
ference model. The second group of results in Ta-
ble 2 shows the systems’ performance. Overall,
the results show that our global inference model
relatively outperformed the baseline and the local
classifiers by 57.8% and 9.2% in F1, respectively.
We perform a bootstrap resampling significance test
(Koehn, 2004) on the output predictions of the lo-
cal classifiers with and without the inference model.
The test shows that the overall improvement with
the inference model is statistically significant (p &lt;
0.01). This indicates the effectiveness of our joint
inference model with global coherence constraints.
Next, we integrated event coreference knowledge
into our systems (as described in Sec. 4) and eval-
uated their performance. Our experiments showed
that the SumScore approach works better for CE−T,
while MaxScore is more suitable for CE−E. Our ob-
servations showed that event mentions of an event
may appear in close proximity with multiple time
intervals in the text, making CE−T produce high
prediction scores for many event mention-interval
pairs. This, consequently, confuses MaxScore on
the best association of the event and the time inter-
vals, whereas SumScore overcomes the problem by
averaging out the association scores. On the other
hand, CE−E gets more benefit from MaxScore be-
cause CE−E works better on pairs of event mentions
that appear closely in the text, which activate more
valuable learning features. We will report the results
using the best approach of each classifier.
To evaluate our systems with event coreference
knowledge, we first experimented our systems with
gold event coreference as given by the ACE 2005
corpus. Table 2 shows the contribution of event
coreference to our systems in the third group of the
results. The results show that injecting knowledge
from event coreference remarkably improved both
the local classifiers and the joint inference model.
Overall, the system that combined event corefer-
ence and the global inference model achieved the
best performance, which significantly overtook all
other compared systems. Specifically, it outper-
formed the baseline system, the local classifiers, and
the joint inference model without event coreference
with 80%, 25%, and 14% of relative improvement in
F1, respectively. It also consistently outperformed
the local classifiers enhanced with event corefer-
ence. We note that the precision and recall of CE−T
in the joint inference model are the same because
the inference model enforced each event mention to
be associated with exactly one time interval. This
is also true for the systems integrated with event
coreference because our integration approaches as-
sign only one time interval to an event mention.
We next move to experimenting with automati-
cally learned event coreference systems. In this ex-
</bodyText>
<page confidence="0.996138">
684
</page>
<table confidence="0.999682666666667">
Model CE−T CE−E Overall
Prec. Rec. Fl Prec. Rec. Fl Prec. Rec. Fl
1 Baseline 33.29 33.29 33.29 20.86 32.81 25.03 27.06 33.05 29.16
2 No Event Coref.
Local classifiers 62.70 34.50 43.29 40.46 42.42 40.96 51.58 38.46 42.13
Global inference 47.88 47.88 47.88 41.42 48.04 44.14 44.65 47.96 46.01
3 With Gold Event Coref.
Local classifiers 50.88 50.88 50.88 43.86 52.65 47.46 47.37 51.77 49.17
Global inference 50.88 50.88 50.88 48.04 62.45 54.05 49.46 56.67 52.47
4 With Learned Event Coref.
Local classifiers 46.37 46.37 46.37 40.83 45.28 42.60 43.60 45.83 44.49
Global inference 46.37 46.37 46.37 42.09 52.50 46.47 44.23 49.44 46.42
</table>
<tableCaption confidence="0.999536">
Table 2: Performance under various evaluation settings. All figures are averaged scores from 5-fold cross-validation experiments.
</tableCaption>
<bodyText confidence="0.999993368421053">
periment, we re-trained the event coreference sys-
tem described in Chen et al. (2009) on all arti-
cles in the ACE 2005 corpus, excluding the 20 ar-
ticles used in our data set. The performance of these
systems are shown in the fourth group of the re-
sults in Table 2. The results show that by using a
learned event coreference system, we achieved the
same improvement trends as with gold event coref-
erence. However, we did not obtain significant im-
provement when comparing with global inference
without event coreference information. This result
shows that the performance of an event coreference
system can have a significant impact on the over-
all performance. While this suggests that a better
event coreference system could potentially help the
task more, it also opens the question whether event
coreference can be benefited from our local classi-
fiers through the use of a joint inference framework.
We would like to leave this for future investigations.
</bodyText>
<subsectionHeader confidence="0.995141">
5.4 Previous Work-Related Experiments
</subsectionHeader>
<bodyText confidence="0.999972653061225">
We also performed experiments using the same set-
ting as in (Yoshikawa et al., 2009), which followed
the guidelines of the TempEval challenges (Verha-
gen et al., 2007; Verhagen et al., 2010), on our sat-
urated data. Several assumptions were made to sim-
plify the task. For example, only main events in
adjacent sentences are considered when identifying
event-event relations. See (Yoshikawa et al., 2009)
for more details. We performed 5-fold cross valida-
tion without event coreference. Overall, the system
achieved 29.99 F1 for the local classifiers and 34.69
when the global inference is used. These results are
better than the baseline but underperform our full
models where those simplification assumptions are
not imposed, as shown in Table 2, indicating the im-
portance of relaxing their assumptions in practice.
We also evaluated our CE−E on the TimeBank
corpus. We followed the settings of Chambers and
Jurafsky (2008) to extract all event mention pairs
that were annotated with before (or ibefore, “imme-
diately before”) and after (or iafter) relations in 183
news articles in the corpus. We trained and evalu-
ated our CE−E on these examples with the same fea-
ture set that we evaluated in our experiments above,
with gold tense and aspect features but without event
type. Following their work, we performed 10-fold
cross validation. Our classifier achieved a micro-
averaged accuracy of 73.45%, whereas Chambers
and Jurafsky (2008) reported 66.8%. We next in-
jected the knowledge of an event coreference sys-
tem trained on the ACE2005 corpus into our CE−E,
and obtained a micro-averaged accuracy of 73.39%.
It was not surprising that event coreference did not
help in this dataset because: (i) different domains
– the event coreference was trained on ACE 05 but
applied on TimeBank, and (ii) different annotation
guidelines on events in ACE 2005 and TimeBank.
Finally, we conducted an experiment that justi-
fies the advantages of our interval-based inference
model over a time point-based inference. To do this,
we first converted our data in Table 1 from inter-
vals to time points and infer the temporal relations
between the annotated event mentions and the time
points: before, after, overlap, and unknown. We
modified the first component in the objective func-
tion in (3) to accommodate these temporal relations.
We also made several changes to the constraints,
including removing those in (7) since they are no
longer required, and adding constraints that ensure
</bodyText>
<page confidence="0.997202">
685
</page>
<bodyText confidence="0.999992555555556">
the relation between a time point and an event men-
tion takes exactly one value. Proper changes were
also made to other constraints in (10) to reflect the
fact that time points are considered rather than inter-
vals. We observed that experiment with such a for-
mulation was unable to finish within 5 hours (we ter-
minated the ILP inference after waiting for 5 hours),
whereas our interval-based model finished the ex-
periment with an average of 21 seconds per article.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999968468085106">
Research in temporal reasoning recently received
much attention. Allen (1983) introduced an interval
based temporal logic which has been used widely
in the field. Recent efforts in building an annotated
temporal corpus (Pustejovsky et al., 2003) has pop-
ularized the use of machine learning techniques for
the task (Mani et al., 2006; Bethard et al., 2007).
This corpus was later used (with simplifications) in
two TempEval challenges (Verhagen et al., 2007;
Verhagen et al., 2010). In these challenges, several
temporal-related tasks were defined including the
tasks of identifying the temporal relation between an
event mention and a temporal expression in the same
sentence, and recognizing temporal relations of pairs
of event mentions in adjacent sentences. However,
with several restrictions imposed to these tasks, the
developed systems were not practical.
Recently, there has been much work attempting
to leverage Allen’s interval algebra of temporal re-
lations to enforce global constraints on local pre-
dictions. The work of Tatu and Srikanth (2008)
used global relational constraints to not only expand
the training data but also identifies temporal incon-
sistencies to improve local classifiers. They used
greedy search to select the most appropriate config-
uration of temporal relations among events and tem-
poral expressions. For exact inferences, Bramsen et
al. (2006), Chambers and Jurafsky (2008), Denis
and Muller (2011), and Talukdar et al. (2012) for-
mulated the temporal reasoning problem in an ILP.
However, the inference models in their work were
not a joint model involving multiple local classifiers
but only one local classifier was involved in their ob-
jective functions.
The work of Yoshikawa et al. (2009) did formu-
late a joint inference model with Markov Logic Net-
work (MLN). They, however, used the same setting
as the TempEval challenges, thus only pairs of tem-
poral entities in the same or adjacent sentences are
considered. Our work, on the other hand, focuses on
constructing an event timeline with time intervals,
taking multiple local pairwise predictions into a joint
inference model and removing the restrictions on the
positions of the temporal entities. Furthermore, we
propose for the first time to use event coreference
and evaluate the importance of its role in the task of
event timeline construction.
</bodyText>
<sectionHeader confidence="0.997632" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99999275">
We proposed an interval-based representation of the
timeline of event mentions in an article. Our rep-
resentation allowed us to formalize the joint infer-
ence model that can be solved efficiently, compared
to a time point-based inference model, thus open-
ing up the possibility of building more practical
event temporal inference systems. Our inference
model achieved significant improvement over the lo-
cal classifiers. We also showed that event coref-
erence can naturally support timeline construction,
and good event coreference led to significant im-
provement in the system performance. Specifically,
when such gold event coreference knowledge was
injected into the model, a significant improvement
in the overall performance could be obtained. While
our experiments suggest that the temporal classi-
fiers can potentially help enhance the performance
of event coreference, in future work we would like
to investigate into coupling event coreference with
other components in a global inference framework.
</bodyText>
<sectionHeader confidence="0.998238" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99849775">
The authors gratefully acknowledge the support
of Defense Advanced Research Projects Agency
(DARPA) Machine Reading Program under Air
Force Research Laboratory (AFRL) prime contract
No. FA8750-09-C-0181, and the Army Research
Laboratory (ARL) under agreement W911NF-09-2-
0053. The first author also thanks the Vietnam Ed-
ucation Foundation (VEF) for its sponsorship. Any
opinions, findings, and conclusion or recommenda-
tions expressed in this material are those of the au-
thors and do not necessarily reflect the view of the
VEF, DARPA, AFRL, ARL, or the US government.
</bodyText>
<page confidence="0.998626">
686
</page>
<sectionHeader confidence="0.993885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999921847457627">
James F. Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the ACM.
Steven Bethard, James H. Martin, and Sara Klingenstein.
2007. Timelines from text: Identification of syntactic
temporal relations. In ICSC.
P. Bramsen, P. Deshpande, Y. K. Lee, and R. Barzilay.
2006. Inducing temporal graphs. In EMNLP.
N. Chambers and D. Jurafsky. 2008. Jointly combin-
ing implicit constraints improves temporal ordering.
In EMNLP.
Zheng Chen, Heng Ji, and Robert Haralick. 2009. A
pairwise event coreference model, feature impact and
evaluation for event coreference resolution. In Work-
shop on Events in Emerging Text Types.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear programming
approach. Journal of Artificial Intelligence Research.
Pascal Denis and Philippe Muller. 2011. Predicting
globally-coherent temporal structures from texts via
endpoint inference and graph decomposition. In IJ-
CAI.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
Yoav Freund and Robert E. Schapire. 1999. Large mar-
gin classification using the perceptron algorithm. Ma-
chine Learning.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In EMNLP.
Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min
Lee, and James Pustejovsky. 2006. Machine learning
of temporal relations. In ACL.
J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas,
A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro,
and M. Lazo. 2003. The TIMEBANK corpus. In
Corpus Linguistics.
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In Introduction to Statistical Relational
Learning.
Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell.
2012. Coupled temporal scoping of relational facts. In
WSDM.
Marta Tatu and Munirathnam Srikanth. 2008. Experi-
ments with reasoning for temporal relations between
events. In COLING.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. Semeval-2007 task 15: Tempeval temporal re-
lation identification. In SemEval-2007.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. Semeval-2010 task 13:
Tempeval-2. In SemEval-2010.
Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asa-
hara, and Yuji Matsumoto. 2009. Jointly identify-
ing temporal relations with markov logic. In ACL-
IJCNLP.
Ran Zhao, Quang Do, and Dan Roth. 2012. A robust
shallow temporal reasoning system. In NAACL-HLT
Demo.
</reference>
<page confidence="0.997834">
687
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.952759">
<title confidence="0.998487">Joint Inference for Event Timeline Construction</title>
<author confidence="0.999945">Quang Xuan Do Wei Lu Dan Roth</author>
<affiliation confidence="0.998361">Department of Computer University of Illinois at</affiliation>
<address confidence="0.965222">Urbana, IL 61801,</address>
<abstract confidence="0.99950485">This paper addresses the task of constructing a timeline of events mentioned in a given text. To accomplish that, we present a novel representation of the temporal structure of a news article based on time intervals. We then present an algorithmic approach that jointly optimizes the temporal structure by coupling local classifiers that predict associations and temporal relations between pairs of temporal entities with global constraints. Moreover, we present ways to leverage knowledge provided by event coreference to further improve the system performance. Overall, our experiments show that the joint inference model significantly outperformed the local classifiers by relative improvement in The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Communications of the ACM.</journal>
<contexts>
<context position="37680" citStr="Allen (1983)" startWordPosition="6281" endWordPosition="6282"> longer required, and adding constraints that ensure 685 the relation between a time point and an event mention takes exactly one value. Proper changes were also made to other constraints in (10) to reflect the fact that time points are considered rather than intervals. We observed that experiment with such a formulation was unable to finish within 5 hours (we terminated the ILP inference after waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, </context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F. Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>James H Martin</author>
<author>Sara Klingenstein</author>
</authors>
<title>Timelines from text: Identification of syntactic temporal relations.</title>
<date>2007</date>
<booktitle>In ICSC.</booktitle>
<contexts>
<context position="10690" citStr="Bethard et al., 2007" startWordPosition="1742" endWordPosition="1745">ls of an article in our model. Our E–T classifier is different from previous work (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011), where such classifiers were trained to identify temporal relations between event mentions and a temporal expression. In our work, in order to construct absolute timeline of event mentions, temporal expressions are captured and normalized as absolute time intervals. The E–T classifiers are then used to assign event mentions to their contextually corresponding time intervals. We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al., 2009; Verhagen et al., 2010). Specifically, we do not require that event mentions and time expressions have to appear in the same sentence, and we do not require two event mentions have to appear very close to each other (e.g., main event mentions in adjacent sentences) in order to be considered as candidate pairs for classification. Instead, we performed classifications over all pairs of event mentions and time intervals as well as over all pairs of event mentions. We show through experiments that lifting these restrictions is indeed important (see Sec. 5). Another importa</context>
<context position="13065" citStr="Bethard et al., 2007" startWordPosition="2143" endWordPosition="2146">whether the former associates with the latter. CE−T(ei,Ij) → {0, 1}, ∀i,j,1 ≤ i ≤ n,1 ≤ j ≤ m, (1) where n and m are the number of event mentions and time intervals in an article, respectively. CE−E: is the E–E classifier that identifies the temporal relation between two event mentions. Given a pair of event mentions, the classifier predicts one of the four temporal relations between them: before, after, overlap and no relation. Specifically: CE−E(ei, ej) → { b, a, o, n}, ∀i, j,1 ≤ i, j ≤ n, i _6 j, (2) For training of the classifiers, we define a set of features following some previous work (Bethard et al., 2007; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009), together with some additional features that we believe to be helpful for the interval-based representation. We describe the base features below and use † and ‡ to denote the features used for CE−T and CE−E, respectively. We use the term temporal entity (or entity, for short) to refer to either an event mention or a time interval. Lexical Features: A set of lexical features related to the temporal entities: (i)†‡ the word, lemma and part-of-speech of the input event mentions and the context surrounding them, where the context is defined as</context>
<context position="37958" citStr="Bethard et al., 2007" startWordPosition="6325" endWordPosition="6328">. We observed that experiment with such a formulation was unable to finish within 5 hours (we terminated the ILP inference after waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of tempor</context>
</contexts>
<marker>Bethard, Martin, Klingenstein, 2007</marker>
<rawString>Steven Bethard, James H. Martin, and Sara Klingenstein. 2007. Timelines from text: Identification of syntactic temporal relations. In ICSC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bramsen</author>
<author>P Deshpande</author>
<author>Y K Lee</author>
<author>R Barzilay</author>
</authors>
<title>Inducing temporal graphs.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="19220" citStr="Bramsen et al., 2006" startWordPosition="3246" endWordPosition="3249">nterval. These constraints are encoded as follows: � x(eI,1) = 1, ∀e ∈ E (7) IEZ Our model also enforces reflexivity and transitivity constraints on the relations among event mentions as follows: y(eiej,r) − y(ejei,r) = 0, ∀eiej = (ei, ej) ∈ EE, i =6 j (8) y(eiej,r1) + y(ejek,r2) − y(eiek,r3) ≤ 1, ∀eiej, ejek, eiek ∈ EE, i =6 j =6 k (9) The equality constraints in (8) encode reflexive property of event-event relations, where the relation r� denotes the inversion of the relation r. The set of possible (r, r) pairs is defined as follows: {(�b, d), (d,�b), (o, o), (n, n)}. Following the work of (Bramsen et al., 2006; Chambers and Jurafsky, 2008), we encode transitive closure of relations between event mentions with inequality constraints in (9), which states that if the pair (ei, ej) has a certain relation r1, and the pair (ej, ek) has the relation r2, then the relation r3 must be satisfied between ei and ek. Examples of such triple (r1, r2, r3) include (b, b, b) and (d, d, d). Finally, to capture the interactions between our local pairwise classifiers we add the following constraints: x(eiIk,1) + x(ejIl,1) − yheiej,bi ≤ 1, ∀eiIk, ejIl ∈ EI, ∀eiej ∈ EE, Ik precedes Il, i =6 j, k =6 l (10) Intuitively, th</context>
<context position="38980" citStr="Bramsen et al. (2006)" startWordPosition="6477" endWordPosition="6480">nces. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational constraints to not only expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was involved in their objective functions. The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Network (MLN). They, however, used the same setting as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are considered. Our work, on the other hand</context>
</contexts>
<marker>Bramsen, Deshpande, Lee, Barzilay, 2006</marker>
<rawString>P. Bramsen, P. Deshpande, Y. K. Lee, and R. Barzilay. 2006. Inducing temporal graphs. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chambers</author>
<author>D Jurafsky</author>
</authors>
<title>Jointly combining implicit constraints improves temporal ordering.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1499" citStr="Chambers and Jurafsky, 2008" startWordPosition="223" endWordPosition="226"> local classifiers by 9.2% of relative improvement in Fl. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system. 1 Introduction Inferring temporal relations amongst a collection of events in a text is a significant step towards various important tasks such as automatic information extraction and document comprehension. Over the past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have been several works on building automatic systems for such a task (Mani et al., 2006; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of occurrence. Even if this issue is addressed, certain restrictions are often imposed for efficiency rea</context>
<context position="8910" citStr="Chambers and Jurafsky, 2008" startWordPosition="1463" endWordPosition="1466">ssociated with the interval I1. The relation between them is no relation, since it is unclear which occurs first. On the other hand, e5 and e3 both happen in the interval I2 but they form an overlap relation. The events e6 and e7 occur within the same interval I3, but e7 precedes (i.e. before) e6 on the timeline. The event e4 is associated with the interval (−oo, +oo), indicating there is no knowledge about its time of occurrence. We believe that such a timeline representation for temporally ordering events has several advantages over the temporal graph representations used in previous works (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Unlike previous works, in our model the events are partially ordered in a single timeline, where each event is associated with a precise time interval. This improves human interpretability of the temporal relations amongst events and time. This property of our timeline representation, thus, facilitates merging multiple timelines induced from different articles. Furthermore, as we will show later, the use of time intervals within the timeline representation simplifies the global inference formulation and thus the inference process. 3 A Joint Ti</context>
<context position="10180" citStr="Chambers and Jurafsky, 2008" startWordPosition="1664" endWordPosition="1667">ly coherent timeline for a given article. We thus adopt a global inference model for performing the task. The model consists of two components: (1) two local pairwise classifiers, one between event mentions and time intervals (the E–T classifier) and one between event mentions themselves (the E–E classifier), and (2) a joint inference module that enforces global coherency constraints on the final outputs of the two local classifiers. Fig. 2 shows a simplified temporal structure of event mentions and time intervals of an article in our model. Our E–T classifier is different from previous work (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011), where such classifiers were trained to identify temporal relations between event mentions and a temporal expression. In our work, in order to construct absolute timeline of event mentions, temporal expressions are captured and normalized as absolute time intervals. The E–T classifiers are then used to assign event mentions to their contextually corresponding time intervals. We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al., 2009; Verhagen et al., 2010). Specifically, we do not require that eve</context>
<context position="11694" citStr="Chambers and Jurafsky, 2008" startWordPosition="1902" endWordPosition="1906"> classifications over all pairs of event mentions and time intervals as well as over all pairs of event mentions. We show through experiments that lifting these restrictions is indeed important (see Sec. 5). Another important improvement over previous work is our global inference model We would like to highlight that our work is also distinct from most previous works in the global inference component. Specifically, our global inference model jointly optimizes the E-E relations amongst event mentions and their associations, E-T, with temporal information (intervals in our case). Previous work (Chambers and Jurafsky, 2008; Denis and Muller, 2011), on the other hand, assumed that the E-T information is given and only tried to improve E-E. 3.1 The Pairwise Classifiers We first describe our local classifiers that associate event mention with time interval and classify temporal relations between event mentions, respectively. CE−T: is the E–T classifier that associates an event mention with a time interval. Given an event mention and a time interval, the classifier predicts 679 Figure 2: A simplified temporal structure of an article. There are m time intervals Il · · · Im and n event mentions el · · · en. A solid e</context>
<context position="13094" citStr="Chambers and Jurafsky, 2008" startWordPosition="2147" endWordPosition="2150">ociates with the latter. CE−T(ei,Ij) → {0, 1}, ∀i,j,1 ≤ i ≤ n,1 ≤ j ≤ m, (1) where n and m are the number of event mentions and time intervals in an article, respectively. CE−E: is the E–E classifier that identifies the temporal relation between two event mentions. Given a pair of event mentions, the classifier predicts one of the four temporal relations between them: before, after, overlap and no relation. Specifically: CE−E(ei, ej) → { b, a, o, n}, ∀i, j,1 ≤ i, j ≤ n, i _6 j, (2) For training of the classifiers, we define a set of features following some previous work (Bethard et al., 2007; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009), together with some additional features that we believe to be helpful for the interval-based representation. We describe the base features below and use † and ‡ to denote the features used for CE−T and CE−E, respectively. We use the term temporal entity (or entity, for short) to refer to either an event mention or a time interval. Lexical Features: A set of lexical features related to the temporal entities: (i)†‡ the word, lemma and part-of-speech of the input event mentions and the context surrounding them, where the context is defined as a window of 2 words before a</context>
<context position="15325" citStr="Chambers and Jurafsky, 2008" startWordPosition="2519" endWordPosition="2522">ent mentions have a common derivational form derived from WordNet. Linguistic Features†‡: The tense and the aspect of the input event mentions. We use an in-house rule-based recognizer to extract these features. Time Interval Features†: A set of features related to the input time interval: (i) whether the interval is implicit; (ii) if it is implicit, identify its interval type: “dct” _ [t−DCT, t�DCT1, “past” _ (−∞, t−DCT1, “feature” _ [tDCT, +∞), and “entire” _ (−∞, +∞); (iii) the interval is before, after or overlapping with the DCT. We note that unlike many previous work (Mani et al., 2006; Chambers and Jurafsky, 2008; Denis and Muller, 2011), our classifiers do not use any gold annotations of event attributes (event class, tense, aspect, modal and polarity) provided in the TimeBank corpus as features. In our work, we use a regularized averaged Perceptron (Freund and Schapire, 1999) as our classification algorithm3. We used the one-vs.-all scheme to transform a set of binary classifiers into a multiclass classifier (for CE−E). The raw prediction scores were converted into probability distribution using the Softmax function (Bishop 1996). If there are n classes and the raw score of class i is acti, the post</context>
<context position="19250" citStr="Chambers and Jurafsky, 2008" startWordPosition="3250" endWordPosition="3253">ints are encoded as follows: � x(eI,1) = 1, ∀e ∈ E (7) IEZ Our model also enforces reflexivity and transitivity constraints on the relations among event mentions as follows: y(eiej,r) − y(ejei,r) = 0, ∀eiej = (ei, ej) ∈ EE, i =6 j (8) y(eiej,r1) + y(ejek,r2) − y(eiek,r3) ≤ 1, ∀eiej, ejek, eiek ∈ EE, i =6 j =6 k (9) The equality constraints in (8) encode reflexive property of event-event relations, where the relation r� denotes the inversion of the relation r. The set of possible (r, r) pairs is defined as follows: {(�b, d), (d,�b), (o, o), (n, n)}. Following the work of (Bramsen et al., 2006; Chambers and Jurafsky, 2008), we encode transitive closure of relations between event mentions with inequality constraints in (9), which states that if the pair (ei, ej) has a certain relation r1, and the pair (ej, ek) has the relation r2, then the relation r3 must be satisfied between ei and ek. Examples of such triple (r1, r2, r3) include (b, b, b) and (d, d, d). Finally, to capture the interactions between our local pairwise classifiers we add the following constraints: x(eiIk,1) + x(ejIl,1) − yheiej,bi ≤ 1, ∀eiIk, ejIl ∈ EI, ∀eiej ∈ EE, Ik precedes Il, i =6 j, k =6 l (10) Intuitively, the inequality constraints in (1</context>
<context position="35579" citStr="Chambers and Jurafsky (2008)" startWordPosition="5933" endWordPosition="5936">s in adjacent sentences are considered when identifying event-event relations. See (Yoshikawa et al., 2009) for more details. We performed 5-fold cross validation without event coreference. Overall, the system achieved 29.99 F1 for the local classifiers and 34.69 when the global inference is used. These results are better than the baseline but underperform our full models where those simplification assumptions are not imposed, as shown in Table 2, indicating the importance of relaxing their assumptions in practice. We also evaluated our CE−E on the TimeBank corpus. We followed the settings of Chambers and Jurafsky (2008) to extract all event mention pairs that were annotated with before (or ibefore, “immediately before”) and after (or iafter) relations in 183 news articles in the corpus. We trained and evaluated our CE−E on these examples with the same feature set that we evaluated in our experiments above, with gold tense and aspect features but without event type. Following their work, we performed 10-fold cross validation. Our classifier achieved a microaveraged accuracy of 73.45%, whereas Chambers and Jurafsky (2008) reported 66.8%. We next injected the knowledge of an event coreference system trained on </context>
<context position="39010" citStr="Chambers and Jurafsky (2008)" startWordPosition="6481" endWordPosition="6484">eral restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational constraints to not only expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was involved in their objective functions. The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Network (MLN). They, however, used the same setting as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are considered. Our work, on the other hand, focuses on constructing an e</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>N. Chambers and D. Jurafsky. 2008. Jointly combining implicit constraints improves temporal ordering. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
<author>Robert Haralick</author>
</authors>
<title>A pairwise event coreference model, feature impact and evaluation for event coreference resolution.</title>
<date>2009</date>
<booktitle>In Workshop on Events in Emerging Text Types.</booktitle>
<contexts>
<context position="33750" citStr="Chen et al. (2009)" startWordPosition="5636" endWordPosition="5639"> inference 47.88 47.88 47.88 41.42 48.04 44.14 44.65 47.96 46.01 3 With Gold Event Coref. Local classifiers 50.88 50.88 50.88 43.86 52.65 47.46 47.37 51.77 49.17 Global inference 50.88 50.88 50.88 48.04 62.45 54.05 49.46 56.67 52.47 4 With Learned Event Coref. Local classifiers 46.37 46.37 46.37 40.83 45.28 42.60 43.60 45.83 44.49 Global inference 46.37 46.37 46.37 42.09 52.50 46.47 44.23 49.44 46.42 Table 2: Performance under various evaluation settings. All figures are averaged scores from 5-fold cross-validation experiments. periment, we re-trained the event coreference system described in Chen et al. (2009) on all articles in the ACE 2005 corpus, excluding the 20 articles used in our data set. The performance of these systems are shown in the fourth group of the results in Table 2. The results show that by using a learned event coreference system, we achieved the same improvement trends as with gold event coreference. However, we did not obtain significant improvement when comparing with global inference without event coreference information. This result shows that the performance of an event coreference system can have a significant impact on the overall performance. While this suggests that a </context>
</contexts>
<marker>Chen, Ji, Haralick, 2009</marker>
<rawString>Zheng Chen, Heng Ji, and Robert Haralick. 2009. A pairwise event coreference model, feature impact and evaluation for event coreference resolution. In Workshop on Events in Emerging Text Types.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research.</journal>
<contexts>
<context position="16661" citStr="Clarke and Lapata, 2008" startWordPosition="2752" endWordPosition="2755">o 0, 1, 2, less than 5 and greater than or equal to 5 3Other algorithm (e.g. SVM) gave comparable or worse results, so we only show the results from Averaged Perceptron. I1 • • • I2 I3 Im e1 e2 e3 e4 e5 • • • en-1 en P(i) _ 680 3.2 Joint Inference for Event Timeline To exploit the interaction among the temporal entities in an article, we optimize the predicted temporal structure, formed by predictions from CE−T and CE−E, w.r.t. a set of global constraints that enforce coherency on the final structure. We perform exact inference using Integer Linear Programming (ILP) as in (Roth and Yih, 2007; Clarke and Lapata, 2008). We use the Gurobi Optimizer4 as a solver. Let I = {I1, I2, ... , Im} denote the set of time intervals extracted from an article, and let E = {e1, e2, ... , en} denote all event mentions in the same article. Let EI = {(ei, Ij) ∈ E × I|ei ∈ E, Ij ∈ I} denote the set of all pairs of event mentions and time intervals. We also denote the set of event mention pairs by EE = {(ei, ej) ∈ E × E|ei ∈ E, ej ∈ E, i =6 j}. The prediction probability of an association of a pair eI ∈ EI, given by classifier CE−T, is denoted by p(eI,1)5. Now, let R = {b, d, o, n} be the set of temporal relations between two </context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>J. Clarke and M. Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Philippe Muller</author>
</authors>
<title>Predicting globally-coherent temporal structures from texts via endpoint inference and graph decomposition.</title>
<date>2011</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="1548" citStr="Denis and Muller, 2011" startWordPosition="231" endWordPosition="234"> Fl. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system. 1 Introduction Inferring temporal relations amongst a collection of events in a text is a significant step towards various important tasks such as automatic information extraction and document comprehension. Over the past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have been several works on building automatic systems for such a task (Mani et al., 2006; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of occurrence. Even if this issue is addressed, certain restrictions are often imposed for efficiency reasons (Yoshikawa et al., 2009; Verhagen et al., 20</context>
<context position="5731" citStr="Denis and Muller (2011)" startWordPosition="910" endWordPosition="913">nts or arguments. We also distinguish between events and event mentions, where a unique event can be coreferred to by a set of explicit event mentions in an article. Formally, an event P is co-referred to by a set of event mentions (e�1, e�2, ... , ek). Each event mention e can be written as p(a1, a2, ... , al), where the predicate p is the word that triggers the presence of e in text, and a1, a2,... al are the arguments associated with e. In this work we focus on four temporal relations between two event mentions including before, after, overlap and no relation. 2.2 Time Intervals Similar to Denis and Muller (2011), we define time intervals as pairs of time endpoints. Each time interval I is denoted by [t−, t+], where t− and t+ are two time endpoints representing the lower and upper bound of the interval I, respectively, with t− &lt; t+. The general form of a time endpoint is written as “YYYY-MM-DD hh:mm:ss”. An endpoint can be undefined, in which case it is set to an infinity value: −oc, or +oc. There are two types of time intervals: Explicit intervals are time intervals that can be extracted directly from a given text. For example, consider the following snippet of an article in our data set: The litigat</context>
<context position="8959" citStr="Denis and Muller, 2011" startWordPosition="1471" endWordPosition="1474">them is no relation, since it is unclear which occurs first. On the other hand, e5 and e3 both happen in the interval I2 but they form an overlap relation. The events e6 and e7 occur within the same interval I3, but e7 precedes (i.e. before) e6 on the timeline. The event e4 is associated with the interval (−oo, +oo), indicating there is no knowledge about its time of occurrence. We believe that such a timeline representation for temporally ordering events has several advantages over the temporal graph representations used in previous works (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Unlike previous works, in our model the events are partially ordered in a single timeline, where each event is associated with a precise time interval. This improves human interpretability of the temporal relations amongst events and time. This property of our timeline representation, thus, facilitates merging multiple timelines induced from different articles. Furthermore, as we will show later, the use of time intervals within the timeline representation simplifies the global inference formulation and thus the inference process. 3 A Joint Timeline Model Our task is to induce a globally coh</context>
<context position="10229" citStr="Denis and Muller, 2011" startWordPosition="1672" endWordPosition="1675">pt a global inference model for performing the task. The model consists of two components: (1) two local pairwise classifiers, one between event mentions and time intervals (the E–T classifier) and one between event mentions themselves (the E–E classifier), and (2) a joint inference module that enforces global coherency constraints on the final outputs of the two local classifiers. Fig. 2 shows a simplified temporal structure of event mentions and time intervals of an article in our model. Our E–T classifier is different from previous work (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011), where such classifiers were trained to identify temporal relations between event mentions and a temporal expression. In our work, in order to construct absolute timeline of event mentions, temporal expressions are captured and normalized as absolute time intervals. The E–T classifiers are then used to assign event mentions to their contextually corresponding time intervals. We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al., 2009; Verhagen et al., 2010). Specifically, we do not require that event mentions and time expressions have to appear i</context>
<context position="11719" citStr="Denis and Muller, 2011" startWordPosition="1907" endWordPosition="1910">rs of event mentions and time intervals as well as over all pairs of event mentions. We show through experiments that lifting these restrictions is indeed important (see Sec. 5). Another important improvement over previous work is our global inference model We would like to highlight that our work is also distinct from most previous works in the global inference component. Specifically, our global inference model jointly optimizes the E-E relations amongst event mentions and their associations, E-T, with temporal information (intervals in our case). Previous work (Chambers and Jurafsky, 2008; Denis and Muller, 2011), on the other hand, assumed that the E-T information is given and only tried to improve E-E. 3.1 The Pairwise Classifiers We first describe our local classifiers that associate event mention with time interval and classify temporal relations between event mentions, respectively. CE−T: is the E–T classifier that associates an event mention with a time interval. Given an event mention and a time interval, the classifier predicts 679 Figure 2: A simplified temporal structure of an article. There are m time intervals Il · · · Im and n event mentions el · · · en. A solid edge indicates an associat</context>
<context position="15350" citStr="Denis and Muller, 2011" startWordPosition="2523" endWordPosition="2526">rivational form derived from WordNet. Linguistic Features†‡: The tense and the aspect of the input event mentions. We use an in-house rule-based recognizer to extract these features. Time Interval Features†: A set of features related to the input time interval: (i) whether the interval is implicit; (ii) if it is implicit, identify its interval type: “dct” _ [t−DCT, t�DCT1, “past” _ (−∞, t−DCT1, “feature” _ [tDCT, +∞), and “entire” _ (−∞, +∞); (iii) the interval is before, after or overlapping with the DCT. We note that unlike many previous work (Mani et al., 2006; Chambers and Jurafsky, 2008; Denis and Muller, 2011), our classifiers do not use any gold annotations of event attributes (event class, tense, aspect, modal and polarity) provided in the TimeBank corpus as features. In our work, we use a regularized averaged Perceptron (Freund and Schapire, 1999) as our classification algorithm3. We used the one-vs.-all scheme to transform a set of binary classifiers into a multiclass classifier (for CE−E). The raw prediction scores were converted into probability distribution using the Softmax function (Bishop 1996). If there are n classes and the raw score of class i is acti, the posterior estimation for clas</context>
<context position="39035" citStr="Denis and Muller (2011)" startWordPosition="6485" endWordPosition="6488">hese tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational constraints to not only expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was involved in their objective functions. The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Network (MLN). They, however, used the same setting as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are considered. Our work, on the other hand, focuses on constructing an event timeline with time i</context>
</contexts>
<marker>Denis, Muller, 2011</marker>
<rawString>Pascal Denis and Philippe Muller. 2011. Predicting globally-coherent temporal structures from texts via endpoint inference and graph decomposition. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="14671" citStr="Fellbaum, 1998" startWordPosition="2412" endWordPosition="2413">ar in the same sentence; (iii)†‡ the quantized number of sentences between the two entities2; (iv)†‡ whether the input event mentions are covered by prepositional phrases and what are the heads of the phrases; (v)†‡ if the entities are in the same sentence, what is their least common constituent on the syntactic parse tree; (vi)† whether there is any other temporal entity that is closer to one of the two entities. Semantic Features‡: A set of semantic features, mostly related to the input event mentions: (i) whether the input event mentions have a common synonym from their synsets in WordNet (Fellbaum, 1998); (ii) whether the input event mentions have a common derivational form derived from WordNet. Linguistic Features†‡: The tense and the aspect of the input event mentions. We use an in-house rule-based recognizer to extract these features. Time Interval Features†: A set of features related to the input time interval: (i) whether the interval is implicit; (ii) if it is implicit, identify its interval type: “dct” _ [t−DCT, t�DCT1, “past” _ (−∞, t−DCT1, “feature” _ [tDCT, +∞), and “entire” _ (−∞, +∞); (iii) the interval is before, after or overlapping with the DCT. We note that unlike many previou</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>Large margin classification using the perceptron algorithm.</title>
<date>1999</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="15595" citStr="Freund and Schapire, 1999" startWordPosition="2563" endWordPosition="2566">nput time interval: (i) whether the interval is implicit; (ii) if it is implicit, identify its interval type: “dct” _ [t−DCT, t�DCT1, “past” _ (−∞, t−DCT1, “feature” _ [tDCT, +∞), and “entire” _ (−∞, +∞); (iii) the interval is before, after or overlapping with the DCT. We note that unlike many previous work (Mani et al., 2006; Chambers and Jurafsky, 2008; Denis and Muller, 2011), our classifiers do not use any gold annotations of event attributes (event class, tense, aspect, modal and polarity) provided in the TimeBank corpus as features. In our work, we use a regularized averaged Perceptron (Freund and Schapire, 1999) as our classification algorithm3. We used the one-vs.-all scheme to transform a set of binary classifiers into a multiclass classifier (for CE−E). The raw prediction scores were converted into probability distribution using the Softmax function (Bishop 1996). If there are n classes and the raw score of class i is acti, the posterior estimation for class i is: eacti E1≤j≤n eact., 2We quantize the number of sentences between two entities to 0, 1, 2, less than 5 and greater than or equal to 5 3Other algorithm (e.g. SVM) gave comparable or worse results, so we only show the results from Averaged </context>
</contexts>
<marker>Freund, Schapire, 1999</marker>
<rawString>Yoav Freund and Robert E. Schapire. 1999. Large margin classification using the perceptron algorithm. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="30419" citStr="Koehn, 2004" startWordPosition="5117" endWordPosition="5118">eats the event mention that appears earlier in the text as temporally happening before the other mention. The baseline performance is shown in the first group of results in Table 2. 5.3 Our Systems For our systems, we first evaluated the performance of our local pairwise classifiers and the global inference model. The second group of results in Table 2 shows the systems’ performance. Overall, the results show that our global inference model relatively outperformed the baseline and the local classifiers by 57.8% and 9.2% in F1, respectively. We perform a bootstrap resampling significance test (Koehn, 2004) on the output predictions of the local classifiers with and without the inference model. The test shows that the overall improvement with the inference model is statistically significant (p &lt; 0.01). This indicates the effectiveness of our joint inference model with global coherence constraints. Next, we integrated event coreference knowledge into our systems (as described in Sec. 4) and evaluated their performance. Our experiments showed that the SumScore approach works better for CE−T, while MaxScore is more suitable for CE−E. Our observations showed that event mentions of an event may appea</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Marc Verhagen</author>
<author>Ben Wellner</author>
<author>Chong Min Lee</author>
<author>James Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1470" citStr="Mani et al., 2006" startWordPosition="219" endWordPosition="222">ly outperformed the local classifiers by 9.2% of relative improvement in Fl. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system. 1 Introduction Inferring temporal relations amongst a collection of events in a text is a significant step towards various important tasks such as automatic information extraction and document comprehension. Over the past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have been several works on building automatic systems for such a task (Mani et al., 2006; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of occurrence. Even if this issue is addressed, certain restrictions are oft</context>
<context position="15296" citStr="Mani et al., 2006" startWordPosition="2515" endWordPosition="2518">hether the input event mentions have a common derivational form derived from WordNet. Linguistic Features†‡: The tense and the aspect of the input event mentions. We use an in-house rule-based recognizer to extract these features. Time Interval Features†: A set of features related to the input time interval: (i) whether the interval is implicit; (ii) if it is implicit, identify its interval type: “dct” _ [t−DCT, t�DCT1, “past” _ (−∞, t−DCT1, “feature” _ [tDCT, +∞), and “entire” _ (−∞, +∞); (iii) the interval is before, after or overlapping with the DCT. We note that unlike many previous work (Mani et al., 2006; Chambers and Jurafsky, 2008; Denis and Muller, 2011), our classifiers do not use any gold annotations of event attributes (event class, tense, aspect, modal and polarity) provided in the TimeBank corpus as features. In our work, we use a regularized averaged Perceptron (Freund and Schapire, 1999) as our classification algorithm3. We used the one-vs.-all scheme to transform a set of binary classifiers into a multiclass classifier (for CE−E). The raw prediction scores were converted into probability distribution using the Softmax function (Bishop 1996). If there are n classes and the raw score</context>
<context position="37935" citStr="Mani et al., 2006" startWordPosition="6321" endWordPosition="6324">ther than intervals. We observed that experiment with such a formulation was unable to finish within 5 hours (we terminated the ILP inference after waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s int</context>
</contexts>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>Inderjeet Mani, Marc Verhagen, Ben Wellner, Chong Min Lee, and James Pustejovsky. 2006. Machine learning of temporal relations. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
<author>P Hanks</author>
<author>R Sauri</author>
<author>A See</author>
<author>R Gaizauskas</author>
<author>A Setzer</author>
<author>D Radev</author>
<author>B Sundheim</author>
<author>D Day</author>
<author>L Ferro</author>
<author>M Lazo</author>
</authors>
<title>The TIMEBANK corpus. In Corpus Linguistics.</title>
<date>2003</date>
<contexts>
<context position="1373" citStr="Pustejovsky et al., 2003" startWordPosition="201" endWordPosition="204"> improve the system performance. Overall, our experiments show that the joint inference model significantly outperformed the local classifiers by 9.2% of relative improvement in Fl. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system. 1 Introduction Inferring temporal relations amongst a collection of events in a text is a significant step towards various important tasks such as automatic information extraction and document comprehension. Over the past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have been several works on building automatic systems for such a task (Mani et al., 2006; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and</context>
<context position="37848" citStr="Pustejovsky et al., 2003" startWordPosition="6305" endWordPosition="6308">e also made to other constraints in (10) to reflect the fact that time points are considered rather than intervals. We observed that experiment with such a formulation was unable to finish within 5 hours (we terminated the ILP inference after waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems we</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, Lazo, 2003</marker>
<rawString>J. Pustejovsky, P. Hanks, R. Sauri, A. See, R. Gaizauskas, A. Setzer, D. Radev, B. Sundheim, D. Day, L. Ferro, and M. Lazo. 2003. The TIMEBANK corpus. In Corpus Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation. In Introduction to Statistical Relational Learning.</title>
<date>2007</date>
<contexts>
<context position="16635" citStr="Roth and Yih, 2007" startWordPosition="2748" endWordPosition="2751">tween two entities to 0, 1, 2, less than 5 and greater than or equal to 5 3Other algorithm (e.g. SVM) gave comparable or worse results, so we only show the results from Averaged Perceptron. I1 • • • I2 I3 Im e1 e2 e3 e4 e5 • • • en-1 en P(i) _ 680 3.2 Joint Inference for Event Timeline To exploit the interaction among the temporal entities in an article, we optimize the predicted temporal structure, formed by predictions from CE−T and CE−E, w.r.t. a set of global constraints that enforce coherency on the final structure. We perform exact inference using Integer Linear Programming (ILP) as in (Roth and Yih, 2007; Clarke and Lapata, 2008). We use the Gurobi Optimizer4 as a solver. Let I = {I1, I2, ... , Im} denote the set of time intervals extracted from an article, and let E = {e1, e2, ... , en} denote all event mentions in the same article. Let EI = {(ei, Ij) ∈ E × I|ei ∈ E, Ij ∈ I} denote the set of all pairs of event mentions and time intervals. We also denote the set of event mention pairs by EE = {(ei, ej) ∈ E × E|ei ∈ E, ej ∈ E, i =6 j}. The prediction probability of an association of a pair eI ∈ EI, given by classifier CE−T, is denoted by p(eI,1)5. Now, let R = {b, d, o, n} be the set of tempo</context>
</contexts>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. In Introduction to Statistical Relational Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Derry Wijaya</author>
<author>Tom Mitchell</author>
</authors>
<title>Coupled temporal scoping of relational facts.</title>
<date>2012</date>
<booktitle>In WSDM.</booktitle>
<contexts>
<context position="39063" citStr="Talukdar et al. (2012)" startWordPosition="6490" endWordPosition="6493">tems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational constraints to not only expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was involved in their objective functions. The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Network (MLN). They, however, used the same setting as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are considered. Our work, on the other hand, focuses on constructing an event timeline with time intervals, taking multiple lo</context>
</contexts>
<marker>Talukdar, Wijaya, Mitchell, 2012</marker>
<rawString>Partha Pratim Talukdar, Derry Wijaya, and Tom Mitchell. 2012. Coupled temporal scoping of relational facts. In WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Munirathnam Srikanth</author>
</authors>
<title>Experiments with reasoning for temporal relations between events.</title>
<date>2008</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="38659" citStr="Tatu and Srikanth (2008)" startWordPosition="6429" endWordPosition="6432">s (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational constraints to not only expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was invo</context>
</contexts>
<marker>Tatu, Srikanth, 2008</marker>
<rawString>Marta Tatu and Munirathnam Srikanth. 2008. Experiments with reasoning for temporal relations between events. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>Semeval-2007 task 15: Tempeval temporal relation identification.</title>
<date>2007</date>
<booktitle>In SemEval-2007.</booktitle>
<contexts>
<context position="34822" citStr="Verhagen et al., 2007" startWordPosition="5813" endWordPosition="5817">esult shows that the performance of an event coreference system can have a significant impact on the overall performance. While this suggests that a better event coreference system could potentially help the task more, it also opens the question whether event coreference can be benefited from our local classifiers through the use of a joint inference framework. We would like to leave this for future investigations. 5.4 Previous Work-Related Experiments We also performed experiments using the same setting as in (Yoshikawa et al., 2009), which followed the guidelines of the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010), on our saturated data. Several assumptions were made to simplify the task. For example, only main events in adjacent sentences are considered when identifying event-event relations. See (Yoshikawa et al., 2009) for more details. We performed 5-fold cross validation without event coreference. Overall, the system achieved 29.99 F1 for the local classifiers and 34.69 when the global inference is used. These results are better than the baseline but underperform our full models where those simplification assumptions are not imposed, as shown in Table 2, indicating the impo</context>
<context position="38059" citStr="Verhagen et al., 2007" startWordPosition="6340" endWordPosition="6343">ted the ILP inference after waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008)</context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. Semeval-2007 task 15: Tempeval temporal relation identification. In SemEval-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>Semeval-2010 task 13: Tempeval-2. In SemEval-2010.</booktitle>
<contexts>
<context position="2151" citStr="Verhagen et al., 2010" startWordPosition="322" endWordPosition="325">s and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of occurrence. Even if this issue is addressed, certain restrictions are often imposed for efficiency reasons (Yoshikawa et al., 2009; Verhagen et al., 2010). In practice, however, being able to automatically infer the correct time of occurrence associated with each event is crucial. Such information not only leads to better text comprehension, but also enables fusion of event structures extracted from multiple articles or domains. In this work, we are specifically interested in mapping events into an universal timeline representation. Besides inferring the relative temporal relations amongst the events, we would also like to automatically infer a specific absolute time of occurrence for each event mentioned in the text. Unlike previous work, we a</context>
<context position="10738" citStr="Verhagen et al., 2010" startWordPosition="1750" endWordPosition="1753">ier is different from previous work (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011), where such classifiers were trained to identify temporal relations between event mentions and a temporal expression. In our work, in order to construct absolute timeline of event mentions, temporal expressions are captured and normalized as absolute time intervals. The E–T classifiers are then used to assign event mentions to their contextually corresponding time intervals. We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al., 2009; Verhagen et al., 2010). Specifically, we do not require that event mentions and time expressions have to appear in the same sentence, and we do not require two event mentions have to appear very close to each other (e.g., main event mentions in adjacent sentences) in order to be considered as candidate pairs for classification. Instead, we performed classifications over all pairs of event mentions and time intervals as well as over all pairs of event mentions. We show through experiments that lifting these restrictions is indeed important (see Sec. 5). Another important improvement over previous work is our global </context>
<context position="34846" citStr="Verhagen et al., 2010" startWordPosition="5818" endWordPosition="5821">rformance of an event coreference system can have a significant impact on the overall performance. While this suggests that a better event coreference system could potentially help the task more, it also opens the question whether event coreference can be benefited from our local classifiers through the use of a joint inference framework. We would like to leave this for future investigations. 5.4 Previous Work-Related Experiments We also performed experiments using the same setting as in (Yoshikawa et al., 2009), which followed the guidelines of the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010), on our saturated data. Several assumptions were made to simplify the task. For example, only main events in adjacent sentences are considered when identifying event-event relations. See (Yoshikawa et al., 2009) for more details. We performed 5-fold cross validation without event coreference. Overall, the system achieved 29.99 F1 for the local classifiers and 34.69 when the global inference is used. These results are better than the baseline but underperform our full models where those simplification assumptions are not imposed, as shown in Table 2, indicating the importance of relaxing their</context>
<context position="38083" citStr="Verhagen et al., 2010" startWordPosition="6344" endWordPosition="6347">fter waiting for 5 hours), whereas our interval-based model finished the experiment with an average of 21 seconds per article. 6 Related Work Research in temporal reasoning recently received much attention. Allen (1983) introduced an interval based temporal logic which has been used widely in the field. Recent efforts in building an annotated temporal corpus (Pustejovsky et al., 2003) has popularized the use of machine learning techniques for the task (Mani et al., 2006; Bethard et al., 2007). This corpus was later used (with simplifications) in two TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010). In these challenges, several temporal-related tasks were defined including the tasks of identifying the temporal relation between an event mention and a temporal expression in the same sentence, and recognizing temporal relations of pairs of event mentions in adjacent sentences. However, with several restrictions imposed to these tasks, the developed systems were not practical. Recently, there has been much work attempting to leverage Allen’s interval algebra of temporal relations to enforce global constraints on local predictions. The work of Tatu and Srikanth (2008) used global relational </context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. Semeval-2010 task 13: Tempeval-2. In SemEval-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katsumasa Yoshikawa</author>
<author>Sebastian Riedel</author>
<author>Masayuki Asahara</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Jointly identifying temporal relations with markov logic.</title>
<date>2009</date>
<booktitle>In ACLIJCNLP.</booktitle>
<contexts>
<context position="1523" citStr="Yoshikawa et al., 2009" startWordPosition="227" endWordPosition="230"> relative improvement in Fl. The experiments also suggest that good event coreference could make remarkable contribution to a robust event timeline construction system. 1 Introduction Inferring temporal relations amongst a collection of events in a text is a significant step towards various important tasks such as automatic information extraction and document comprehension. Over the past few years, with the development of the TimeBank corpus (Pustejovsky et al., 2003) , there have been several works on building automatic systems for such a task (Mani et al., 2006; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Most previous works devoted much efforts to the task of identifying relative temporal relations (such as before, or overlap) amongst events (Chambers Figure 1: A graphical illustration of our timeline representation. The e’s, t’s and I’s are events, time points and time intervals, respectively. and Jurafsky, 2008; Denis and Muller, 2011), without addressing the task of identifying correct associations between events and their absolute time of occurrence. Even if this issue is addressed, certain restrictions are often imposed for efficiency reasons (Yoshikawa et al., </context>
<context position="8934" citStr="Yoshikawa et al., 2009" startWordPosition="1467" endWordPosition="1470">1. The relation between them is no relation, since it is unclear which occurs first. On the other hand, e5 and e3 both happen in the interval I2 but they form an overlap relation. The events e6 and e7 occur within the same interval I3, but e7 precedes (i.e. before) e6 on the timeline. The event e4 is associated with the interval (−oo, +oo), indicating there is no knowledge about its time of occurrence. We believe that such a timeline representation for temporally ordering events has several advantages over the temporal graph representations used in previous works (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011). Unlike previous works, in our model the events are partially ordered in a single timeline, where each event is associated with a precise time interval. This improves human interpretability of the temporal relations amongst events and time. This property of our timeline representation, thus, facilitates merging multiple timelines induced from different articles. Furthermore, as we will show later, the use of time intervals within the timeline representation simplifies the global inference formulation and thus the inference process. 3 A Joint Timeline Model Our task is</context>
<context position="10204" citStr="Yoshikawa et al., 2009" startWordPosition="1668" endWordPosition="1671">ven article. We thus adopt a global inference model for performing the task. The model consists of two components: (1) two local pairwise classifiers, one between event mentions and time intervals (the E–T classifier) and one between event mentions themselves (the E–E classifier), and (2) a joint inference module that enforces global coherency constraints on the final outputs of the two local classifiers. Fig. 2 shows a simplified temporal structure of event mentions and time intervals of an article in our model. Our E–T classifier is different from previous work (Chambers and Jurafsky, 2008; Yoshikawa et al., 2009; Denis and Muller, 2011), where such classifiers were trained to identify temporal relations between event mentions and a temporal expression. In our work, in order to construct absolute timeline of event mentions, temporal expressions are captured and normalized as absolute time intervals. The E–T classifiers are then used to assign event mentions to their contextually corresponding time intervals. We also lifted several restrictions imposed in previous work (Bethard et al., 2007; Yoshikawa et al., 2009; Verhagen et al., 2010). Specifically, we do not require that event mentions and time exp</context>
<context position="13119" citStr="Yoshikawa et al., 2009" startWordPosition="2151" endWordPosition="2154">(ei,Ij) → {0, 1}, ∀i,j,1 ≤ i ≤ n,1 ≤ j ≤ m, (1) where n and m are the number of event mentions and time intervals in an article, respectively. CE−E: is the E–E classifier that identifies the temporal relation between two event mentions. Given a pair of event mentions, the classifier predicts one of the four temporal relations between them: before, after, overlap and no relation. Specifically: CE−E(ei, ej) → { b, a, o, n}, ∀i, j,1 ≤ i, j ≤ n, i _6 j, (2) For training of the classifiers, we define a set of features following some previous work (Bethard et al., 2007; Chambers and Jurafsky, 2008; Yoshikawa et al., 2009), together with some additional features that we believe to be helpful for the interval-based representation. We describe the base features below and use † and ‡ to denote the features used for CE−T and CE−E, respectively. We use the term temporal entity (or entity, for short) to refer to either an event mention or a time interval. Lexical Features: A set of lexical features related to the temporal entities: (i)†‡ the word, lemma and part-of-speech of the input event mentions and the context surrounding them, where the context is defined as a window of 2 words before and after the mention; (ii</context>
<context position="34741" citStr="Yoshikawa et al., 2009" startWordPosition="5801" endWordPosition="5804"> when comparing with global inference without event coreference information. This result shows that the performance of an event coreference system can have a significant impact on the overall performance. While this suggests that a better event coreference system could potentially help the task more, it also opens the question whether event coreference can be benefited from our local classifiers through the use of a joint inference framework. We would like to leave this for future investigations. 5.4 Previous Work-Related Experiments We also performed experiments using the same setting as in (Yoshikawa et al., 2009), which followed the guidelines of the TempEval challenges (Verhagen et al., 2007; Verhagen et al., 2010), on our saturated data. Several assumptions were made to simplify the task. For example, only main events in adjacent sentences are considered when identifying event-event relations. See (Yoshikawa et al., 2009) for more details. We performed 5-fold cross validation without event coreference. Overall, the system achieved 29.99 F1 for the local classifiers and 34.69 when the global inference is used. These results are better than the baseline but underperform our full models where those sim</context>
<context position="39329" citStr="Yoshikawa et al. (2009)" startWordPosition="6534" endWordPosition="6537"> expand the training data but also identifies temporal inconsistencies to improve local classifiers. They used greedy search to select the most appropriate configuration of temporal relations among events and temporal expressions. For exact inferences, Bramsen et al. (2006), Chambers and Jurafsky (2008), Denis and Muller (2011), and Talukdar et al. (2012) formulated the temporal reasoning problem in an ILP. However, the inference models in their work were not a joint model involving multiple local classifiers but only one local classifier was involved in their objective functions. The work of Yoshikawa et al. (2009) did formulate a joint inference model with Markov Logic Network (MLN). They, however, used the same setting as the TempEval challenges, thus only pairs of temporal entities in the same or adjacent sentences are considered. Our work, on the other hand, focuses on constructing an event timeline with time intervals, taking multiple local pairwise predictions into a joint inference model and removing the restrictions on the positions of the temporal entities. Furthermore, we propose for the first time to use event coreference and evaluate the importance of its role in the task of event timeline c</context>
</contexts>
<marker>Yoshikawa, Riedel, Asahara, Matsumoto, 2009</marker>
<rawString>Katsumasa Yoshikawa, Sebastian Riedel, Masayuki Asahara, and Yuji Matsumoto. 2009. Jointly identifying temporal relations with markov logic. In ACLIJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ran Zhao</author>
<author>Quang Do</author>
<author>Dan Roth</author>
</authors>
<title>A robust shallow temporal reasoning system.</title>
<date>2012</date>
<booktitle>In NAACL-HLT Demo.</booktitle>
<contexts>
<context position="7089" citStr="Zhao et al. (2012)" startWordPosition="1140" endWordPosition="1143">rmalize two time intervals which are explicitly written, including January 1, 1993 —* [1993- 01-01 00:00:00, 1993-01-01 23:59:59] and February 7, 2000 —* [2000-02-07 00:00:00, 2000-02-07 23:59:59]. Moreover, an explicit interval can also be formed by one or more separate explicit temporal expressions. In the example above, the connective term between relates the two expressions to form a single time interval: between January 1, 1993 and February 7, 2000 —* [1993-01-01 00:00:00, 2000- 02-07 23:59:59]. To extract explicit time intervals from text, we use the time interval extractor described in Zhao et al. (2012). Implicit intervals are time intervals that are not explicitly mentioned in the text. We observed that there are events that cannot be assigned to any precise time interval but are roughly known to occur in the past or in the future relative to the Document Creation Time (DCT) of the article. We introduce two implicit time intervals to represent the past and the future events as (−oc, t−DCT] and [t+DCT , +oc), respectively. In addition, we also allow an event mention to be assigned into the entire timeline, which is denoted by (−oc, +oc) if we can678 not identify its time of occurrence. We al</context>
<context position="27446" citStr="Zhao et al., 2012" startWordPosition="4623" endWordPosition="4626">ts, such as Killing, Legislation, Election. Furthermore, event mentions in TimeBank are annotated with neither event arguments nor event coreference information. We noticed that the ACE 2005 corpus contains the annotation that we are interested in. The corpus consists of articles annotated with event mentions (with event triggers and arguments) and event coreference information. To create an experimental data set for our work, we selected from the corpus 20 newswire articles published in March 2003. To extract time intervals from the articles, we used the time interval extractor described in (Zhao et al., 2012) with minimal post-processing. Implicit intervals are also added according to Sec. 2.2. We then hired an annotator with expertise in the field to annotate the data with the following information: (i) event mention and time interval association, and (ii) the temporal relations between event mentions, including {b, d, o}. The annotator was not required to annotate all pairs of event mentions, but as many as possible. Next, we saturated the relations based on the initial annotations as follows: (i) event mentions that had not been associated with any time intervals were assigned to the entire tim</context>
</contexts>
<marker>Zhao, Do, Roth, 2012</marker>
<rawString>Ran Zhao, Quang Do, and Dan Roth. 2012. A robust shallow temporal reasoning system. In NAACL-HLT Demo.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>