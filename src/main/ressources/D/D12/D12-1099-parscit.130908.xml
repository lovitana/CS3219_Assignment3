<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.998502">
Building a Lightweight Semantic Model for Unsupervised Information
Extraction on Short Listings
</title>
<author confidence="0.949041">
Doo Soon Kim
</author>
<affiliation confidence="0.914548">
Accenture Technology Lab
</affiliation>
<address confidence="0.9548115">
50 W San Fernando St.,
San Jose, CA, 95113
</address>
<author confidence="0.585497">
Kunal Verma
</author>
<affiliation confidence="0.595123">
Accenture Technology Lab
</affiliation>
<address confidence="0.9149525">
50 W San Fernando St.,
San Jose, CA, 95113
</address>
<author confidence="0.844531">
Peter Z. Yeh
</author>
<affiliation confidence="0.826444">
Accenture Technology Lab
</affiliation>
<address confidence="0.979671">
50 W San Fernando St.,
San Jose, CA, 95113
</address>
<email confidence="0.999534">
{doo.soon.kim, k.verma, peter.z.yeh}@accenture.com
</email>
<sectionHeader confidence="0.995655" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999880473684211">
Short listings such as classified ads or product
listings abound on the web. If a computer can
reliably extract information from them, it will
greatly benefit a variety of applications. Short
listings are, however, challenging to process
due to their informal styles. In this paper, we
present an unsupervised information extrac-
tion system for short listings. Given a cor-
pus of listings, the system builds a seman-
tic model that represents typical objects and
their attributes in the domain of the corpus,
and then uses the model to extract informa-
tion. Two key features in the system are a se-
mantic parser that extracts objects and their at-
tributes and a listing-focused clustering mod-
ule that helps group together extracted tokens
of same type. Our evaluation shows that the
semantic model learned by these two modules
is effective across multiple domains.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997790673913044">
Short listings such as classified ads or product list-
ings are prevalent on the web. These texts are gen-
erally concise – around 10 words in length. Fig. 1
shows some example listings. Due to the recent ex-
plosive growth of such listings, extracting informa-
tion from them becomes crucial for tasks such as
faceted search and reasoning. For example, con-
sider an online shopping site on which information
about merchandises for sale is posted. Detecting
brands/styles/features that are frequently mentioned
in the postings would allow a company to design a
better marketing strategy.
Most Information Extraction (IE) techniques de-
veloped for formal texts, however, would be inap-
plicable to listings because of their informal and id-
iosyncratic styles. For example, typos, abbreviations
and synonyms often appear and should be resolved
(e.g., apartment/apt, bike/bicycle). Symbols could
have the special meanings (e.g., x in 2x2 in Fig. 1
indicates number of bedrooms and bathrooms). To-
kenization based only on space is insufficient (e.g.,
RawlingBaseball in Fig. 1). Multiwords such as
granite top should also be detected. Applying off-
the-shelf parsers is infeasible because of unusual
phrasal forms in most listings, such as a long se-
quence of nouns/adjectives (e.g., “New Paint Wood
Floors New Windows Gated Complex”)
To address these challenges, several approaches
have applied machine learning algorithms (Ghani et
al., 2006) (Putthividhya and Hu, 2011) or an external
knowledge base (Michelson and Knoblock, 2005).
These approaches, however, commonly require hu-
man supervision to produce training data or to build
a knowledge base. This is expensive, requiring re-
peated manual effort whenever a new domain or a
new set of information to be extracted is introduced.
In this paper, we present an unsupervised IE sys-
tem for listings. The system extracts tokens from
a corpus of listings and then clusters tokens of
the same types, where each resulting cluster cor-
responds to an information type (e.g., size, brand,
etc.). For formal texts, contexts (e.g., surrounding
words) have been a major feature for word cluster-
ing (Turney and Pantel, 2010). This feature alone,
however, is insufficient for short listings because of
lack of contextual clues in short listings.
</bodyText>
<page confidence="0.963164">
1081
</page>
<note confidence="0.9706785">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1081–1092, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
2x2 Charming Condo – 1515 Martin Av-
enue near Downtown (from Craigslist)
RawlingsBaseball Gloves Pro Preferred
Black 12” (from EBay)
HousingType: Condo, BedroomNum: 2, BathroomNum: 2, Lo-
cation: 1515 Martin Avenue, Neighborhood: Downtown
ProductType: Gloves, Brand: Rawlings, Sport: Baseball, Color:
Black, Size: 12”, SeriesName: Pro Preferred
LG 32” 1080p LCD TV – $329 @
BestBuy (from FatWallet)
Product Type: TV, Brand: Panasonic, Size: 32”, Resolution :
1080P, DisplayTechnology: LCD, Price 329$, Seller: Best Buy
</note>
<figureCaption confidence="0.999587">
Figure 1: Example short listings and the information extracted from them.
</figureCaption>
<bodyText confidence="0.999984681818182">
To address this limitation of context-based clus-
tering, we first identify common types of informa-
tion (main objects and their attributes) represented
in listings and apply customized clustering for these
types. Specifically, we define a semantic model
to explicitly represent these information types, and
based on the semantic model, develop two compo-
nents to improve clustering – a shallow semantic
parser and listing-focused clustering module. The
semantic parser specifically focuses on extracting
main objects and the listing-focused clustering mod-
ule helps group together extracted tokens of the
same type.
Our evaluation shows that our two main con-
tributions (shallow semantic parser and listing-
focused clustering) significantly improve perfor-
mance across three different domains – Craigslist,
EBay, and FatWallet. Our system achieves .50�.65
F1-score for the EBay and the FatWallet datasets
based on gold standards constructed by human an-
notators. For the Craigslist dataset, which is more
difficult than the other two, F1-score is .35.
</bodyText>
<sectionHeader confidence="0.999739" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.994487905660377">
IE on Listings. (Ghani et al., 2006) (Putthividhya
and Hu, 2011) propose semi-supervised approaches
to extract product types and their attributes from
product listings. (Ghani et al., 2006) applies the
EM (Expectation-Maximization) algorithm to incor-
porate unlabelled data. (Putthividhya and Hu, 2011)
uses unlabelled data to build dictionaries of values to
be extracted (e.g., brand or model names), which are
then used as a feature for a machine learning system.
(Michelson and Knoblock, 2005) uses a manually-
crafted knowledge base called reference set to de-
fine standard forms of values to be extracted. Using
a string edit function, the system then identifies to-
kens in listings that have a low distance score with
the values defined in the reference set. They also
propose a semi-supervised method to building ref-
erence sets (Michelson and Knoblock, 2009).Unlike
these systems, our approach is unsupervised.
Unsupervised Information Extraction. Most un-
supervised IE systems produce clusters for tokens
of same type extracted from a corpus of unlabelled
texts. (Chambers and Jurafsky, 2011) (Poon and
Domingos, 2010) (Chen et al., 2011) focus on ex-
tracting frame-like structures (Baker et al., 1998)
by defining two types of clusters, event clusters and
role clusters. Event clusters define an event (a sit-
uation or a frame) such as BOMBING by clustering
verbs/nominalized verbs such as {kill, explosion}.
Role clusters define the semantic roles of the event
(e.g., {terrorist, gunman} for the Perpetrator role in
BOMBING). Similarly, our system defines two types
of clusters – the main concept clusters (e.g., TV or
book) and the attribute clusters (e.g., size, color).
(Chambers and Jurafsky, 2011) is similar to our ap-
proach in that it learns a semantic model, called tem-
plate, from unlabelled news articles and then uses
the template to extract information.
Our system is different because it focuses on in-
formal listings, which the components (such as a
parser) used by these systems cannot handle.
Field Segmentation (Sequence Modelling). This
task focuses on segmenting a short text, such as
bibliographies or listings. (Grenager et al., 2005)
presents an unsupervised HMM based on the obser-
vation that the segmented fields tend to be of mul-
tiple words length. (Haghighi and Klein, 2006)
exploits prototype words (e.g., close, near, shop-
ing for the NEIGHBORHOOD attribute) in an un-
supervised setting. (Chang et al., 2007) incorpo-
rates domain specific constraints in semi-supervised
learning. Our task is different than these systems be-
cause we focus on extracting information to enable
a variety of automated applications such as business
</bodyText>
<page confidence="0.99501">
1082
</page>
<bodyText confidence="0.997249272727273">
intelligence reporting, faceted search or automated
reasoning, rather than segmenting the text. The seg-
mented fields are often a long unstructured text (e.g.,
2 bath 1 bed for size rather than 2 for BathroomNum
and 1 for BedroomNum).
IE on Informal Texts. IE on informal texts is get-
ting much attention because of the recent explosive
growth of these texts. The informal texts that are
attempted for IE include online forums (Gruhl et
al., 2009), SMS (Beaufort et al., 2010), twitter mes-
sages (Liu et al., 2011).
</bodyText>
<sectionHeader confidence="0.971378" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999961">
Given a corpus of listings for a domain of interest,
our system constructs a semantic model that repre-
sents the types of information and their values to be
extracted. Our system then uses the resulting model
to extract both the type and value from the corpus 1.
We first describe the semantic model and then the
two key steps for creating this model – shallow se-
mantic parsing and listing-focused clustering. Fig. 3
illustrates these two steps with example listings.
</bodyText>
<subsectionHeader confidence="0.988856">
3.1 Semantic Model
</subsectionHeader>
<bodyText confidence="0.9997895">
Our semantic model captures two important pieces
of information – the main concept and its attributes.
This representation is based on the observation that
most listings (e.g. rentals, products) describe the
attributes of a single object (i.e. the main concept
in our model). Our system takes advantage of this
observation by applying customized clustering for
each type of information in the model, which results
in better performance compared to a one-size-fits-all
algorithm. Moreover, this model is general enough
to be applicable across a wide range of domains. We
quantitatively show both benefits in our evaluation.
Fig. 2 illustrates our model along with an instanti-
ation for rental listings. The main concept is a clus-
ter containing tokens referencing the main object in
the listing. For example, in the rental listing, the
main concept cluster includes tokens such as house,
condo, and townhouse.
Each attribute of the main concept (e.g. Address,
BedroomNum, etc.) is also a cluster, and two types
</bodyText>
<footnote confidence="0.991174">
1To handle string variations (e.g., typos) during extraction,
our system uses a string edit distance function, Jaro-Winkler
distance (Winkler, 1990) with a threshold, 0.9.
</footnote>
<figureCaption confidence="0.999586">
Figure 2: Semantic model and its instantiation for rental
listings. + indicates multiple clusters can be created.
</figureCaption>
<bodyText confidence="0.999925428571429">
of attributes are defined in our model – quantita-
tive attributes and qualitative ones. Quantitative at-
tributes capture numeric values (e.g. 1 bedroom, 150
Hz, and 70 kg), and are generally a number followed
by a token indicating the attribute (e.g., unit of mea-
surement). Hence, clusters for quantitative attributes
include these indicator tokens (see Fig. 2).
Qualitative attributes capture descriptions about
the main concept (e.g., address, shipping informa-
tion, condition). The values of these attributes gen-
erally appear in listings without explicitly mention-
ing the names of these attributes. Hence, the clusters
for qualitative attributes include tokens correspond-
ing to the values themselves (e.g. washer hookup).
</bodyText>
<subsectionHeader confidence="0.99987">
3.2 Shallow Semantic Parser
</subsectionHeader>
<bodyText confidence="0.9996918">
Our Shallow Semantic Parser (SSP) analyzes an in-
put corpus to produce a partial semantic model. SSP
first performs preprocessing and multiword detec-
tion. SSP then identifies which resulting tokens are
the main concepts and which are their attributes.
</bodyText>
<subsectionHeader confidence="0.747195">
3.2.1 Preprocessing and Multiword Detection
</subsectionHeader>
<bodyText confidence="0.9980998">
SSP preprocesses the corpus through three steps.
(1) SSP cleans the corpus by removing duplicate
listings and HTML expressions/tags. (2) SSP tok-
enizes each listing based on spaces along with cus-
tom heuristics – e.g., handling alpha-numeric to-
kens starting with numbers (e.g., 3bedroom to 3 bed-
room) and mixed case tokens (e.g., NikeShoes to
Nike Shoes). (3) SSP performs POS tagging using an
off-the-shelf tagger (Tsuruoka and Tsujii, 2005). To
improve accuracy, SSP assigns to a token the most
frequent POS across all occurrences of that token.
This heuristic works well because most tokens in fo-
cused domains, like listings, have only one POS.
SSP then detects multiword tokens based on the
following rules:
</bodyText>
<table confidence="0.635728076923077">
* Main Concept
{house, condo, apt., apartment, townhouse, ...}
* Qualitative Attribute+
{washer, dryer, w/d, washer
hookup, d hookup,...}
* Quantitative Attribute+
{bedroom, bdrm, bd,
bed,...}
1083
A corpus of listings Semantically analyzed listings Semantic model
* Brentwood Apt. with 3 bedroom
* 2 BD/ 2 BA +Den – Open Sun 2/12
* Affordable Rental Apartments-
Come take a Look!
* [brentwood/ATTR] [apt./MC] with 3
[bedroom/ATTR]
* 2 [BD/ATTR]/ 2 [BA/ATTR] +[den/ATTR] – [open
sun 2/12/ATTR]
* [affordable rental/ATTR] [apartments/MC]-
come take a look!
* Main Concept
{apt., apartment}
* Location * BedroomNum
{brentwood} {bedroom, bd}
Shallow Semantic Listing-Focused
Parser Clustering
</table>
<figureCaption confidence="0.978557">
Figure 3: Steps of our system: The parser tokenizes listings (multiword detection) and then identifies main concepts
and attributes (marked as MC and ATTR). The clustering module then clusters tokens of the same type. The tags (such
as Location, BedroomNum) are included to help understand the figure. They are not produced by the system.
</figureCaption>
<bodyText confidence="0.823504826086957">
1. If a bigram (e.g., top loor) in a listing fre-
quently appears as either a single or dashed token
(e.g., TopFloor or top-loor) in other listings, then
the bigram is regarded as a multiword.
2. For each bigram, w1 w2 (excluding symbols
and numbers), if the conditional probability of the
bigram given either w1 or w2 (i.e., p(w1w2 �
w1(or w2)) is high (over 0.75 in our system)), the
bigram is considered as a candidate multiword. This
rule tests the tendency of two tokens appearing to-
gether when either one appears.
However, this test alone is insufficient, as it of-
ten generates coarse-grained results – e.g., baseball
glove, softball glove, and Hi-Def TV 2. To prevent
this problem, for each w2, we measure the entropy
over the distribution of the tokens in the w1 position.
Our intuition is that high variability in the w1 posi-
tion (i.e., high entropy) indicates that the multiword
is likely a breakable phrase. Hence, those candidates
with high entropy are removed.
SPP repeatedly applies the above rules to acquire
multiwords of arbitrary length. In our implementa-
tion, we limit multiword detection up to four-gram.
</bodyText>
<subsectionHeader confidence="0.917088">
3.2.2 Main Concept Identification
</subsectionHeader>
<bodyText confidence="0.996148295454545">
SSP then identifies the main concepts (mc words)
and their attributes (attrs) to produce a partial se-
mantic model. This process is guided by the ob-
servation that main concepts tend to appear as head
nouns in a listing and attributes as the modifiers of
these head nouns (see the examples in Fig. 3).
2Even though these examples are legitimate multiwords,
they overlook useful information such as baseball and softball
are types of gloves and Hi-Def is an attribute of TV.
Algorithm 1 describes the discovery process of
mc words and attrs. First, SSP initializes attrs with
tokens that are likely to be a modifier (line 2), by
choosing tokens that frequently appear as the object
of a preposition within the corpus – e.g., for rent,
with washer and dryer, for baseball.
SSP then iteratively performs two steps – PARSE
and EXPANDMODEL (lines 3 — 6) – in a boot-
strap manner (see Fig. 4). PARSE tags the noun to-
kens in each listing as either head nouns or modi-
fiers. Specifically, PARSE first assesses if a listing
is “hard” to parse (line 10) based on two criteria – (1)
the listing contains a long sequence of nouns (seven
words or longer in our system) without any prepo-
sitions (e.g., worth shutout series 12” womens fast-
pitch softball fielders glove s0120 lefty); and (2) the
majority of these nouns do not appear in mc words
and attrs (e.g., over 70% in our system). The listings
meeting these criteria are generally difficult to rec-
ognize the head noun without any semantic knowl-
edge. PARSE will revisit these listings in the next
round as more mc words and attrs are identified.
If a listing does not meet these criteria, PARSE
tags nouns appearing in mc words and attrs as
head nouns and modifiers respectively (line 11). If
this step fails to recognize a head noun, a heuris-
tic is used to identify the head noun – it identi-
fies the first noun phrase by finding a sequence of
nouns/adjectives/numbers, and then tags as the head
noun the last noun in the phrase that is not tagged as
a modifier (line 13). For example, in the first listing
of Fig. 3, brentwood apts. is the first noun phrase
that meets the condition above; and hence apt. is
tagged as the head noun. The remaining untagged
nouns in the listing are tagged as modifiers (line 15).
</bodyText>
<page confidence="0.985458">
1084
</page>
<bodyText confidence="0.34842">
Algorithm 1 Extracting main concepts
</bodyText>
<listItem confidence="0.989555291666666">
1: Input: POS-tagged corpus, corp
2: Initialize attrs
3: repeat
4: (hn,mod) = Parse(corp, mc words, attrs)
5: (mc words,attrs) = ExpandModel(hn,mod)
6: until mc words, attrs not changed
8: function PARSE(mc words, attrs)
9: for all each listing do
10: if parsible then
11: Parse with mc words, attrs
12: if headnoun is not tagged then
13: Tag the last noun in the first noun
phrase that are not a modifier as hn
14: end if
15: Tag the other nouns as mod
16: end if
17: end for
18: end function
20: function EXPANDMODEL(corp)
21: For each token, calculate a ratio of as a head
noun to as a modifier
22: Add tokens with high ratio to mc words
23: Add tokens with low ratio to attrs
24: end function
</listItem>
<bodyText confidence="0.999837571428571">
EXPANDMODEL assigns tokens to either
mc words or attrs based on the tags generated
by PARSE. For each token, EXPANDMODEL
counts the frequency of the token being tagged as a
head noun and as a modifier. If a token is predom-
inately tagged as a head noun (or a modifier), the
token is added to mc words (or attrs) 3.
This bootstrap method is advantageous 4 be-
cause SSP can initially focus on easy cases –
i.e., mc words and attrs that can be detected with
high confidence, such as condo(mc words) and bed-
room(attrs), which often appear as a head noun and
a modifier in the easy-to-parse listings. These re-
sults can help the system to parse more difficult
</bodyText>
<footnote confidence="0.9951184">
3In our system, if the ratio of the frequency of the head noun
to the frequency of the modifier is over .55, the token is added
to mc words. If less than .35, it is added to attrs.
4The bootstrapping cycle generally ends within 3∼4 itera-
tions.
</footnote>
<note confidence="0.581225">
ExpandModel
</note>
<figureCaption confidence="0.99964">
Figure 4: Bootstrapped PARSE and EXPANDMODEL
</figureCaption>
<bodyText confidence="0.999776">
listings. For example, identifying condo(mc words)
helps parsing the following more difficult listing,
“2 bedroom 1 bathroom condo large patio washer
dryer available” – condo would be tagged as a head
noun and the rest of the nouns as modifiers.
The result of this step is a partial semantic model
that contains a cluster for the main concept and a list
of candidate attribute tokens.
</bodyText>
<subsectionHeader confidence="0.975772">
3.3 Listing-Focused Clustering
</subsectionHeader>
<bodyText confidence="0.999693125">
Listing-Focused Clustering (LFC) further expands
the partial semantic model (constructed by SSP) by
grouping the remaining candidate attribute tokens
into attribute clusters – i.e. one cluster for each at-
tribute of the main concept. LFC may also add a
token to the main concept cluster if appropriate.
For formal texts, distributional similarity is
widely used for clustering words because the con-
textual clues in these texts are sufficiently discrimi-
native (Lin and Pantel, 2001). This feature alone,
however, is insufficient for listings because they
lack discriminative contexts due to the short length.
Hence, our approach augments context-based sim-
ilarity with the following rules (presented in order
of precedence), based on general properties we ob-
served from listing data across various domains.
</bodyText>
<listItem confidence="0.991042545454545">
• Two quantitative attribute tokens cannot be
placed into the same cluster if they frequently
appear together in a listing. For example, bed
and bath should not be clustered because they
frequently appear together (e.g. 2 bed/ 2bath).
This rule is based on the observation that a
quantitative attribute is likely to appear only
once in a listing. To enforce this restriction, for
all pairs of tokens, t1 and t2, LFC measures the
conditional probability of the pair appearing to-
gether in a listing given the appearance of either
</listItem>
<figure confidence="0.9270236">
• Listings with head noun
and modifiers detected
Parse
• mc_words
• attributes
</figure>
<page confidence="0.939255">
1085
</page>
<listItem confidence="0.943497928571429">
t1 and t2. If any of these conditional probabili-
ties are high, t1 and t2 are not clustered.
• Attribute types are strongly enforced by never
clustering together a quantitative attribute to-
ken and a qualitative attribute token. The type
of a token is determined by analyzing the im-
mediate preceding tokens throughout the cor-
pus. If the preceding tokens are generally num-
bers, then LFC regards the token as a quantita-
tive attribute. Otherwise, the token is regarded
as a qualitative attribute.
• Two tokens are similar if the characters in one
token appear in the other, preserving the order
(e.g., bdrm and bedroom)
</listItem>
<bodyText confidence="0.999922965517241">
If the above rules fail to determine the similarity
between two tokens, LFC reverts to context-based
similarity. For each token, LFC creates a context
vector containing frequencies of the context words
around the token with a window size of two. For
example, in the first sentence in Fig. 3, the context
words around apts. are l-start (beginning of the sen-
tence), l-brentwood, r-with, and r-3 5. The frequen-
cies in these vectors are also weighted using PMI
scores (pointwise mutual information) between a to-
ken and its context words, as suggested by (Turney
and Pantel, 2010). The intuition is that a high PMI
indicates a context word is strongly associated with a
token and hence has high discriminative power. We
also apply a smoothing function suggested in (Tur-
ney and Pantel, 2010) to mitigate PMI’s bias towards
infrequent events. The similarity score is based on a
cosine similarity between the two weighted vectors.
Based on this similarity function, LFC applies ag-
glomerative clustering (with average linkage) to pro-
duce attribute clusters (or to expand the main con-
cept cluster). However, calculating similarity scores
for all pairs of tokens is expensive. To address
this problem, LFC performs clustering in two steps.
First, LFC performs agglomerative clustering on all
pairs of tokens with high frequency 6. LFC then cal-
culates the similarity between each low-frequency
token and the clusters resulting from the previous
step. If the similarity score is over a user-specified
</bodyText>
<footnote confidence="0.966709">
5l and r indicates the left or right window.
6The threshold for stopping clustering is determined with
the development dataset.
</footnote>
<table confidence="0.99924375">
Dataset Dev Test Avg word
Rent Ad 8,950 9,400 9.44
Glove 8,600 9,500 10.56
TV Deal - 900 15.60
</table>
<tableCaption confidence="0.73837425">
Table 1: Dev/Test indicates the number of listings used
for development/testing. Avg word indicates the average
number of words in a listing. The development dataset is
used to tune the parameters.
</tableCaption>
<bodyText confidence="0.999579">
threshold, then LFC addes the token to the cluster.
If the score is less than the threshold but the token
still appears relatively frequently, then LFC creates
a new cluster for the token.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9999854">
We perform two evaluations to assess the perfor-
mance of our approach. First, we evaluate how
well our approach extracts the correct type (e.g.,
BedroomNum) and value (e.g., 2) across multiple
domains. Next, we evaluate the contribution of
each main component in our approach – i.e., shal-
low semantic parsing and listing-focused clustering
– through an ablation study. We also provide an
in-depth error analysis along with how our system’s
performance is affected by the corpus size.
</bodyText>
<subsectionHeader confidence="0.986447">
4.1 Evaluation Setup
</subsectionHeader>
<bodyText confidence="0.999967230769231">
We first assemble three different listing datasets for
our evaluation – housing rental advertisements from
Craigslist (Rent Ad), auction listings of baseball
gloves from EBay (Glove), and hot deal postings of
TV/Projector from FatWallet (TV Deal) 7. Table 1
shows the size of each dataset, and example listings
are shown in Fig. 1 8. We also include example ex-
tractions for each domain in Table. 3.
We then construct a gold standard by employing
two independent human annotators. To do this, we
first define the information types (i.e. main concept
and attribute) for each dataset (and hence the tar-
gets for extraction). We use attributes from EBay
</bodyText>
<footnote confidence="0.98465075">
7The datasets are available at https://sites.
google.com/site/2soonk/
8The parameters were tuned by the development set. Our
system is sensitive to the similarity score threshold in agglom-
erative clustering but less sensitive to the other parameters.
Hence, we tuned the similarity threshold for each domain while
fixing the values for the other parameters across different do-
mains.
</footnote>
<page confidence="0.982372">
1086
</page>
<table confidence="0.594958222222222">
Rent Ad
Glove
housing type (.70/.93), num bedroom (.94/.99), num bathroom (.97/1), location (-.64/.82),
neighborhood (.55/.79), others(14 types)
product type (.71/1.00), brand (.58/.98), sport (.71/1.00), size (.87/.99), series name
(.51/.77), others(10 types)
TV Deal
product type (.98/1.00), size (.85/1.00), display technology (.93/1.00), resolution (.89/.99),
seller (.73/1.00), others(14 types)
</table>
<tableCaption confidence="0.9946405">
Table 2: Information types for each domain. See Fig. 1 for the examples of each type. Due to space limitation, we
show only top five types in terms of the number of extractions made by the annotators. The parentheses indicate inter-
annotator agreement based on exact match between two annotators (first number) and partial match (second number).
Exact agreement for qualitative attributes (e.g., location, neighborhood, series name) is found to be difficult.
</tableCaption>
<table confidence="0.968146444444444">
Rent Ad housing type studio, townhome, condo, townhouse, cottage,
num bedroom bd, bed, br, bedroom, bdrm, bedrooms
neighborhood downtown, San Francisco, china town
Glove product type mitt, base mitt, glove, glove mitt
TV Deal size ”, inch, in
brand rawlings, louisville slugger, mizuno, wilson
product type hdtv, wall mount, monitor
size ”, inch
seller wallmart, amazon, newegg, best buy
</table>
<tableCaption confidence="0.98702">
Table 3: Examples of positive extractions for the main concept attributes (e.g., housing type, product type), the
qualitative attributes (e.g., num bedroom, size) and the quantitative attributes (e.g., neighborhood, brand, seller)
used in the experiment
</tableCaption>
<bodyText confidence="0.999957066666667">
as the starting point for Glove and TV Deal; and
attributes from Rent.com9 for Rent Ad. We review
these attributes with two independent Subject Mat-
ter Experts (SMEs) to identify (and include) addi-
tional, missing attributes that are useful for analyt-
ics and reporting. In total, 19 types (Rent Ad), 15
types (Glove) and 19 types (TV Deal) are defined.
For each dataset, we randomly select 100 listings
from the Test listings, and instruct each annotator
to extract values from these listings, based on the
information types for the dataset. Table 2 shows
the defined attributes of each data set and the inter-
annotator agreement across the attributes 10.
Finally, we apply our system to the Test listings
in each dataset; and evaluate the extraction results
</bodyText>
<equation confidence="0.353975333333333">
9http://www.rent.com
10We use Cohen’s kappa, P(�)�P (e)
1�P (e) . P(a), the agree-
</equation>
<bodyText confidence="0.928700266666667">
ment probability, is calculated by the number of list-
ings in which the two annotators agree divided by 100.
P(e), the chance agreement probability, is calculated by
E(T.,v.) P1((Ti, vi)) * P2((Ti, vi)) in which Pj((Ti, vi)) de-
notes a probability of extracting vi of the type Ti by the anno-
tator j. P((Ti, vi)) is calculated by the frequency of (Ti, vi)
extracted divided by the frequency of Ti extracted.
against the gold standards using the metrics of preci-
sion (P), recall (R), and F1-score (a harmonic mean
of precision and recall). Each extraction result is a
tuple (Ti, vi) where Ti is the information type (e.g.,
BedroomNum) and vi is the value (e.g. 2).
# correct extractions by our system
P=
Total # extractions by our system
# correct extractions by our system
Total # extractions by an annotator
We say that an extraction result is correct if vi
matches exactly the value extracted by the annotator
and Ti matches the information type assigned to vi
by the annotator. To enforce this criteria, we match
the attribute clusters produced by our system to the
information types. This matching step is needed be-
cause our approach is unsupervised and hence the
clusters are unlabelled. We use two methods for this
matching step – many-to-one mapping and one-to-
one mapping. For many-to-one mapping (as used
in (Chen et al., 2011)), we match an attribute cluster
to the information type whose values (as extracted
by the annotator) have the highest overlap with the
</bodyText>
<equation confidence="0.693468">
R=
</equation>
<page confidence="0.978188">
1087
</page>
<bodyText confidence="0.99997475">
values of the cluster. Hence, many attribute clusters
can map to the same information type. This method,
however, has one major disadvantage: high perfor-
mance can be easily achieved by creating small-
sized clusters – e.g., singleton clusters in the extreme
case. To mitigate this problem, we also use a one-
to-one mapping method – i.e. at most one attribute
cluster (i.e. the one with the best overlap) can be
mapped to one information type.
We report results for both methods. We also re-
port results for partial matches using the same met-
rics above. We say that an extraction result is par-
tially correct if vi partially matches the value ex-
tracted by the annotator (hardwood vs. hardwood
floors) and Ti matches the information type assigned
to vi by the annotator. 11
</bodyText>
<subsectionHeader confidence="0.989485">
4.2 Performance Across Multiple Domains
</subsectionHeader>
<bodyText confidence="0.99050846875">
Table 4 shows the system performance result across
the domains. Considering our approach is unsuper-
vised, the result is encouraging. For the baseball
glove and the TV dataset, F-score is .51 and .66 (in
one-to-one mapping). For the rent ad, which is more
difficult, F-score is .39. We hypothesize that the low
F1-score in the rent ad dataset is the result of poor
extraction due to spurious tokens (e.g., our commu-
nity, this weather). To test this hypothesis, we mea-
sure the performance of our system only on the ex-
traction task (i.e., excluding the information type as-
signment task). Table 5 shows that the performance
on extraction for the rent ad dataset is the lowest,
confirming our hypothesis.
We also measure the performance per each infor-
mation type. Fig. 5 shows the result, revealing sev-
eral facts. First, the main concept clusters (hous-
ing type and product type) achieve a high F1-score,
showing the benefit of our semantic parser. Sec-
11We could not compare our system to other systems for sev-
eral reasons. First, to the best of our knowledge, no unsuper-
vised IE system has been built specifically for short listings.
Second, semi-supervised systems such as (Putthividhya and
Hu, 2011) (Michelson and Knoblock, 2005) require domain-
specific dictionaries, which are expensive to build and scale.
Third, even developing a supervised IE system is non-trivial. In
our preliminary evaluation with the (linear chain) conditional
random field (170/30 training/testing listings) using basic fea-
tures (the lexemes and POS of the current word and words in the
two left/right windows), precision/recall/F1-score are .5/.33/.4.
This result is no better than our system. More training data
and/or better features seem to be required.
</bodyText>
<table confidence="0.99990525">
P Full F P Full(Par) F
R R
Rent Ad 0.3 0.41 0.35 0.43 0.55 0.48
(302/219) 0.34 0.46 0.39 0.65 0.69 0.67
Glove 0.54 0.48 0.51 0.72 0.58 0.64
(563/631) 0.57 0.51 0.54 0.81 0.65 0.72
TV Deal 0.7 0.63 0.66 0.81 0.7 0.75
(765/851) 0.74 0.67 0.7 0.86 0.74 0.79
</table>
<tableCaption confidence="0.960954571428571">
Table 4: Performance based on one-to-one (first row) and
many-to-one mappings (second row) combined across
both annotators. Full indicates exact match between sys-
tem’s extraction and annotators’ extraction. (Par) indi-
cates partial match. The parentheses indicate the total
number of extraction made by our system and the anno-
tators (averaged) respectively.
</tableCaption>
<table confidence="0.99993775">
Full Full(Par) Ext Ext(Par)
Rent Ad 0.35 0.48 0.42 0.58
Glove 0.51 0.64 0.62 0.69
TV Deal 0.66 0.75 0.75 0.77
</table>
<tableCaption confidence="0.9754085">
Table 5: F1-score when considering only extraction task
(Ext and Ext(Par)). Ext(Par) is based on partial match.
</tableCaption>
<bodyText confidence="0.999949916666667">
ond, the quantitative attributes (e.g., num bedroom,
glove size, screen size) generally have a higher F1
than the qualitative attributes (e.g., location, neigh-
borhood, series name). These qualitative attributes,
in fact, have a low inter-annotator agreement (e.g., -
.64, .55 for location and neighborhood in Rent Ad
and .51 for series name in Glove), indicating the
difficulty of exactly predicting the extractions made
by the annotators. If we consider the partial match or
the extraction only match (Ext) for those qualitative
attributes, their F1-scores are significantly higher
than the exact match in the Full task.
</bodyText>
<subsectionHeader confidence="0.999947">
4.3 Ablation Study
</subsectionHeader>
<bodyText confidence="0.9999154">
To evaluate our semantic parser and listing-focused
clustering module, we ablate these two components
to create four versions of our system for compari-
son – Baseline, Baseline+LFC, Baseline+SSP and
Full System. Baseline performs a space-based tok-
enization followed by clustering based only on the
context feature. Baseline+LFC and Baseline+SSP
add listing-focused clustering and shallow semantic
parser features respectively. The Full system uses
both features.
</bodyText>
<page confidence="0.983057">
1088
</page>
<figure confidence="0.997944333333333">
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Full Full(Par) Ext Ext(Par)
</figure>
<figureCaption confidence="0.9912335">
Figure 5: F1-score across the attribute types shown in Table 2. The parentheses indicate the number of extractions
made by our system and the annotators respectively.
</figureCaption>
<table confidence="0.9997444">
P Rent Ad F P Glove F P TV Deal F
R R R
Full Baseline 0.10 0.27 0.14 0.26 0.34 0.29 0.42 0.51 0.46
Baseline+LFC 0.11 0.30 0.16 0.301 0.391 0.34 0.42 0.51 0.46
Baseline+SSP 0.21* 0.37* 0.26 0.46* 0.47* 0.46 0.65* 0.59* 0.62
Full System 0.30 * 0.41 * 0.35 0.54 * 0.48 * 0.51 0.70 * 0.63 * 0.66
Full(Par) Baseline 0.15 0.40 0.22 0.37 0.50 0.42 0.59 0.69 0.63
Baseline+SSP 0.15 0.43 0.22 0.44* 0.56* 0.49 0.59 0.69 0.63
Baseline+LFC 0.39* 0.55* 0.46 0.37 0.34 0.35 0.79* 0.69 0.73
Full System 0.43 * 0.55 * 0.48 0.72 * 0.58 * 0.64 0.81 * 0.70 0.75
</table>
<tableCaption confidence="0.9732555">
Table 6: Based on one-to-one mapping. * indicates two-tail statistically significant difference (p &lt; 0.05) against
Baseline in Fisher’s test. † indicates one-tail difference. The Fisher’s test is inapplicable to F1-scores.
</tableCaption>
<table confidence="0.9857435">
Rent Ad Glove TV Deal
NOT IN MAPPING 0.42 NOT IN MAPPING 0.27 NOT IN MAPPING 0.33
WRONG EXT 0.25 WRONG EXT 0.16 WRONG EXT 0.20
TK-neighborhood 0.05 WRONG TYPE 0.15 TK-display technology 0.13
TK-housing type 0.05 TK-series name 0.13 TK-shipping info 0.07
TK-location 0.03 TK-dexterity 0.12 WRONG TYPE 0.07
</table>
<tableCaption confidence="0.999875">
Table 7: The top five errors based on the one-to-one mapping.
</tableCaption>
<page confidence="0.996789">
1089
</page>
<bodyText confidence="0.999979090909091">
The results shown in Table 6 lead to the fol-
lowing observations. First, the use of SSP (Base-
line+SSP) makes an improvement for all categories
except Full(Par) in the glove dataset. This is because
SSP identifies main concepts accurately. Second,
while LFC by itself (Bseline+LFC) is effective only
in the glove dataset, it has the best F1-score in all
three domains when combined with SSP (Full Sys-
tem). The result also shows that the simple space-
based tokenization and the context-based clustering
(Baseline) is insufficient for handling short listings.
</bodyText>
<subsectionHeader confidence="0.995348">
4.4 Error Analysis and Corpus Size Effect
</subsectionHeader>
<bodyText confidence="0.999967964285714">
We analyze the error types for the wrong extraction
made by our system. Specifically, for each error, we
assign it to one (or more) of the following causes:
(1) a cluster (and hence attribute type) was excluded
due to the 1-to-1 mapping methodology described
above (NOT IN MAPPING); (2) the value extracted
by the system was not extracted by any of the anno-
tators (WRONG EXT); (3) wrong information type –
i.e., the token belonged to a wrong cluster (WRONG
TYPE); (4) incorrect tokenization for an information
type (TK-&lt;type name&gt;).
Table 7 shows the result. In all three domains,
NOT IN MAPPING is a major source of error, indi-
cating the system’s clusters are too fine-grained as
compared to the gold standard. WRONG EXT is
another source of error (especially in the housing
rental), indicating the system should extract more
informative tokens. Tokenization on the qualitative
attributes (neighborhood, series name, display tech-
nology in Table 7) should be improved also.
Finally, we measure the effect of the corpus size
on the system performance. Fig. 6 shows how the
F1-score varies with the corpus size 12. It shows that
a small corpus size is sufficient for achieving good
performance. We hypothesize that, for focused do-
mains such as our dataset, only a couple of hundred
listings are sufficient to acquire meaningful statis-
tics.
</bodyText>
<sectionHeader confidence="0.994852" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.73744125">
We presented an unsupervised IE system on short
listings. The key features in our system are a shal-
12Due to the space limitation, we include only the rent do-
main result. However, all three datasets follow a similar pattern.
</bodyText>
<figure confidence="0.961195583333333">
F1
0.8 Full
0.7 Full(P)
0.6 Ext
0.5 Ext(P)
0.4
0.3
0.2
0.1
0
0 2000 4000 6000 8000 10000
number of listings
</figure>
<figureCaption confidence="0.996207">
Figure 6: F1-score of our system over varying corpus size
for the rent domain
</figureCaption>
<bodyText confidence="0.999518933333333">
low semantic parser and a listing-focused clustering
module. Our evaluation shows the benefits of the
two features across multiple domains. To improve
our system further, we plan the following works.
First, we plan to compare our system with super-
vised systems to identify the gap between the two
systems. Second, as in (Poon and Domingos, 2010),
we plan to explore a joint learning method to com-
bine the tasks of tokenization, forming the main con-
cept cluster and forming the attribute clusters; these
tasks depend on the outputs of one another. Fi-
nally, we plan to explore that external knowledge
resources such as DBPedia (Auer et al., 2007) and
FreeBase (Bollacker et al., 2008) can be used to fur-
ther improve performance.
</bodyText>
<sectionHeader confidence="0.999252" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.99998425">
We would like to thank Colin Puri and Rey Vasquez
for their contribution to this work. We also thank
the anonymous reviewers for their helpful comments
and suggestions for improving the paper.
</bodyText>
<sectionHeader confidence="0.998557" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994975833333333">
S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens
Lehmann, Richard Cyganiak, and Zachary Ives. 2007.
Dbpedia: a nucleus for a web of open data. In Pro-
ceedings of the 6th international The semantic web
and 2nd Asian conference on Asian semantic web con-
ference, ISWC’07/ASWC’07, pages 722–735, Berlin,
Heidelberg. Springer-Verlag.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The berkeley framenet project. In Proceed-
ings of the 36th Annual Meeting of the Association
for Computational Linguistics and 17th International
Conference on Computational Linguistics - Volume 1,
</reference>
<page confidence="0.871502">
1090
</page>
<reference confidence="0.999058971962617">
ACL ’98, pages 86–90, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Richard Beaufort, Sophie Roekhaut, Louise-Am´elie
Cougnon, and C´edrick Fairon. 2010. A hybrid
rule/model-based finite-state framework for normaliz-
ing sms messages. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, ACL ’10, pages 770–779, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring hu-
man knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management of
data, SIGMOD ’08, pages 1247–1250, New York, NY,
USA. ACM.
Nathanael Chambers and Dan Jurafsky. 2011. Template-
based information extraction without the templates. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages 976–
986, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Ming-Wei Chang, Lev Ratinov, and Dan Roth.
2007. Guiding semi-supervision with constraint-
driven learning. In Proceedings of the 45th Annual
Meeting of the Association of Computational Linguis-
tics, pages 280–287, Prague, Czech Republic, June.
Association for Computational Linguistics.
Harr Chen, Edward Benson, Tahira Naseem, and Regina
Barzilay. 2011. In-domain relation discovery with
meta-constraints via posterior regularization. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies - Volume 1, HLT ’11, pages 530–540,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Rayid Ghani, Katharina Probst, Yan Liu, Marko Krema,
and Andrew Fano. 2006. Text mining for product at-
tribute extraction. SIGKDD Explor. Newsl., 8(1):41–
48, June.
Trond Grenager, Dan Klein, and Christopher D. Man-
ning. 2005. Unsupervised learning of field segmen-
tation models for information extraction. In Proceed-
ings of the 43rd Annual Meeting on Association for
Computational Linguistics, ACL ’05, pages 371–378,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Daniel Gruhl, Meena Nagarajan, Jan Pieper, Christine
Robson, and Amit Sheth. 2009. Context and domain
knowledge enhanced entity spotting in informal text.
In Proceedings of the 8th International Semantic Web
Conference, ISWC ’09, pages 260–276, Berlin, Hei-
delberg. Springer-Verlag.
Aria Haghighi and Dan Klein. 2006. Prototype-driven
learning for sequence models. In Proceedings of
the main conference on Human Language Technology
Conference of the North American Chapter of the As-
sociation of Computational Linguistics, HLT-NAACL
’06, pages 320–327, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Dekang Lin and Patrick Pantel. 2001. Dirt
@sbt@discovery of inference rules from text. In Pro-
ceedings of the seventh ACM SIGKDD international
conference on Knowledge discovery and data min-
ing, KDD ’01, pages 323–328, New York, NY, USA.
ACM.
Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming
Zhou. 2011. Recognizing named entities in tweets.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages 359–
367, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Matthew Michelson and Craig A. Knoblock. 2005. Se-
mantic annotation of unstructured and ungrammatical
text. In Proceedings of the 19th international joint
conference on Artificial intelligence, IJCAI’05, pages
1091–1098, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Matthew Michelson and Craig A. Knoblock. 2009. Ex-
ploiting background knowledge to build reference sets
for information extraction. In Proceedings of the
21st international jont conference on Artifical intel-
ligence, IJCAI’09, pages 2076–2082, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Hoifung Poon and Pedro Domingos. 2007. Joint in-
ference in information extraction. In Proceedings of
the 22nd national conference on Artificial intelligence
- Volume 1, AAAI’07, pages 913–918. AAAI Press.
Hoifung Poon and Pedro Domingos. 2010. Unsuper-
vised ontology induction from text. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, ACL ’10, pages 296–305,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Duangmanee (Pew) Putthividhya and Junling Hu. 2011.
Bootstrapped named entity recognition for product at-
tribute extraction. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 1557–1567, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Joseph Reisinger and Marius Pas¸ca. 2011. Fine-grained
class label markup of search queries. In Proceed-
ings of the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language Tech-
nologies - Volume 1, HLT ’11, pages 1200–1209,
</reference>
<page confidence="0.776692">
1091
</page>
<reference confidence="0.99896668">
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information ex-
traction. In In Advances in Neural Information Pro-
cessing Systems 17, pages 1185–1192.
Satoshi Sekine. 2006. On-demand information ex-
traction. In Proceedings of the COLING/ACL on
Main conference poster sessions, COLING-ACL ’06,
pages 731–738, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidi-
rectional inference with the easiest-first strategy for
tagging sequence data. In Proceedings of the confer-
ence on Human Language Technology and Empirical
Methods in Natural Language Processing, HLT ’05,
pages 467–474, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: vector space models of semantics.
J. Artif. Int. Res., 37(1):141–188, January.
William E. Winkler. 1990. String comparator metrics
and enhanced decision rules in the fellegi-sunter model
of record linkage. In Proceedings of the Section on
Survey Research, pages 354–359.
</reference>
<page confidence="0.994034">
1092
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.558536">
<title confidence="0.9987455">Building a Lightweight Semantic Model for Unsupervised Extraction on Short Listings</title>
<author confidence="0.944029">Doo Soon</author>
<affiliation confidence="0.975325">Accenture Technology</affiliation>
<address confidence="0.956424">50 W San Fernando San Jose, CA, 95113</address>
<email confidence="0.810835">Kunal</email>
<affiliation confidence="0.986662">Accenture Technology</affiliation>
<address confidence="0.9576815">50 W San Fernando San Jose, CA, 95113</address>
<author confidence="0.993985">Z Peter</author>
<affiliation confidence="0.992882">Accenture Technology</affiliation>
<address confidence="0.9576915">50 W San Fernando San Jose, CA, 95113</address>
<email confidence="0.984723">k.verma,</email>
<abstract confidence="0.9997469">Short listings such as classified ads or product listings abound on the web. If a computer can reliably extract information from them, it will greatly benefit a variety of applications. Short listings are, however, challenging to process due to their informal styles. In this paper, we present an unsupervised information extraction system for short listings. Given a corpus of listings, the system builds a semantic model that represents typical objects and their attributes in the domain of the corpus, and then uses the model to extract information. Two key features in the system are a semantic parser that extracts objects and their attributes and a listing-focused clustering module that helps group together extracted tokens of same type. Our evaluation shows that the semantic model learned by these two modules is effective across multiple domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S¨oren Auer</author>
<author>Christian Bizer</author>
<author>Georgi Kobilarov</author>
<author>Jens Lehmann</author>
<author>Richard Cyganiak</author>
<author>Zachary Ives</author>
</authors>
<title>Dbpedia: a nucleus for a web of open data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07,</booktitle>
<pages>722--735</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>Auer, Bizer, Kobilarov, Lehmann, Cyganiak, Ives, 2007</marker>
<rawString>S¨oren Auer, Christian Bizer, Georgi Kobilarov, Jens Lehmann, Richard Cyganiak, and Zachary Ives. 2007. Dbpedia: a nucleus for a web of open data. In Proceedings of the 6th international The semantic web and 2nd Asian conference on Asian semantic web conference, ISWC’07/ASWC’07, pages 722–735, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1, ACL ’98,</booktitle>
<pages>86--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6632" citStr="Baker et al., 1998" startWordPosition="1014" endWordPosition="1017">alues to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al., 2011) focus on extracting frame-like structures (Baker et al., 1998) by defining two types of clusters, event clusters and role clusters. Event clusters define an event (a situation or a frame) such as BOMBING by clustering verbs/nominalized verbs such as {kill, explosion}. Role clusters define the semantic roles of the event (e.g., {terrorist, gunman} for the Perpetrator role in BOMBING). Similarly, our system defines two types of clusters – the main concept clusters (e.g., TV or book) and the attribute clusters (e.g., size, color). (Chambers and Jurafsky, 2011) is similar to our approach in that it learns a semantic model, called template, from unlabelled ne</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1, ACL ’98, pages 86–90, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Beaufort</author>
<author>Sophie Roekhaut</author>
<author>Louise-Am´elie Cougnon</author>
<author>C´edrick Fairon</author>
</authors>
<title>A hybrid rule/model-based finite-state framework for normalizing sms messages.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>770--779</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8558" citStr="Beaufort et al., 2010" startWordPosition="1325" endWordPosition="1328">task is different than these systems because we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The segmented fields are often a long unstructured text (e.g., 2 bath 1 bed for size rather than 2 for BathroomNum and 1 for BedroomNum). IE on Informal Texts. IE on informal texts is getting much attention because of the recent explosive growth of these texts. The informal texts that are attempted for IE include online forums (Gruhl et al., 2009), SMS (Beaufort et al., 2010), twitter messages (Liu et al., 2011). 3 Our Approach Given a corpus of listings for a domain of interest, our system constructs a semantic model that represents the types of information and their values to be extracted. Our system then uses the resulting model to extract both the type and value from the corpus 1. We first describe the semantic model and then the two key steps for creating this model – shallow semantic parsing and listing-focused clustering. Fig. 3 illustrates these two steps with example listings. 3.1 Semantic Model Our semantic model captures two important pieces of informat</context>
</contexts>
<marker>Beaufort, Roekhaut, Cougnon, Fairon, 2010</marker>
<rawString>Richard Beaufort, Sophie Roekhaut, Louise-Am´elie Cougnon, and C´edrick Fairon. 2010. A hybrid rule/model-based finite-state framework for normalizing sms messages. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 770–779, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, SIGMOD ’08,</booktitle>
<pages>1247--1250</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, SIGMOD ’08, pages 1247–1250, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Templatebased information extraction without the templates.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>976--986</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6523" citStr="Chambers and Jurafsky, 2011" startWordPosition="996" endWordPosition="999">Michelson and Knoblock, 2005) uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al., 2011) focus on extracting frame-like structures (Baker et al., 1998) by defining two types of clusters, event clusters and role clusters. Event clusters define an event (a situation or a frame) such as BOMBING by clustering verbs/nominalized verbs such as {kill, explosion}. Role clusters define the semantic roles of the event (e.g., {terrorist, gunman} for the Perpetrator role in BOMBING). Similarly, our system defines two types of clusters – the main concept clusters (e.g., TV or book) and the attribute clusters (e.g., size, color). (Chambers and Juraf</context>
</contexts>
<marker>Chambers, Jurafsky, 2011</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2011. Templatebased information extraction without the templates. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 976– 986, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Guiding semi-supervision with constraintdriven learning.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>280--287</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="7861" citStr="Chang et al., 2007" startWordPosition="1212" endWordPosition="1215">s and then uses the template to extract information. Our system is different because it focuses on informal listings, which the components (such as a parser) used by these systems cannot handle. Field Segmentation (Sequence Modelling). This task focuses on segmenting a short text, such as bibliographies or listings. (Grenager et al., 2005) presents an unsupervised HMM based on the observation that the segmented fields tend to be of multiple words length. (Haghighi and Klein, 2006) exploits prototype words (e.g., close, near, shoping for the NEIGHBORHOOD attribute) in an unsupervised setting. (Chang et al., 2007) incorporates domain specific constraints in semi-supervised learning. Our task is different than these systems because we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The segmented fields are often a long unstructured text (e.g., 2 bath 1 bed for size rather than 2 for BathroomNum and 1 for BedroomNum). IE on Informal Texts. IE on informal texts is getting much attention because of the recent explosive growth of these texts. The informal texts </context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2007. Guiding semi-supervision with constraintdriven learning. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 280–287, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harr Chen</author>
<author>Edward Benson</author>
<author>Tahira Naseem</author>
<author>Regina Barzilay</author>
</authors>
<title>In-domain relation discovery with meta-constraints via posterior regularization.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>530--540</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6569" citStr="Chen et al., 2011" startWordPosition="1004" endWordPosition="1007">wledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al., 2011) focus on extracting frame-like structures (Baker et al., 1998) by defining two types of clusters, event clusters and role clusters. Event clusters define an event (a situation or a frame) such as BOMBING by clustering verbs/nominalized verbs such as {kill, explosion}. Role clusters define the semantic roles of the event (e.g., {terrorist, gunman} for the Perpetrator role in BOMBING). Similarly, our system defines two types of clusters – the main concept clusters (e.g., TV or book) and the attribute clusters (e.g., size, color). (Chambers and Jurafsky, 2011) is similar to our approach in that </context>
<context position="28040" citStr="Chen et al., 2011" startWordPosition="4520" endWordPosition="4523">tions by our system # correct extractions by our system Total # extractions by an annotator We say that an extraction result is correct if vi matches exactly the value extracted by the annotator and Ti matches the information type assigned to vi by the annotator. To enforce this criteria, we match the attribute clusters produced by our system to the information types. This matching step is needed because our approach is unsupervised and hence the clusters are unlabelled. We use two methods for this matching step – many-to-one mapping and one-toone mapping. For many-to-one mapping (as used in (Chen et al., 2011)), we match an attribute cluster to the information type whose values (as extracted by the annotator) have the highest overlap with the R= 1087 values of the cluster. Hence, many attribute clusters can map to the same information type. This method, however, has one major disadvantage: high performance can be easily achieved by creating smallsized clusters – e.g., singleton clusters in the extreme case. To mitigate this problem, we also use a oneto-one mapping method – i.e. at most one attribute cluster (i.e. the one with the best overlap) can be mapped to one information type. We report result</context>
</contexts>
<marker>Chen, Benson, Naseem, Barzilay, 2011</marker>
<rawString>Harr Chen, Edward Benson, Tahira Naseem, and Regina Barzilay. 2011. In-domain relation discovery with meta-constraints via posterior regularization. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 530–540, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rayid Ghani</author>
<author>Katharina Probst</author>
<author>Yan Liu</author>
<author>Marko Krema</author>
<author>Andrew Fano</author>
</authors>
<title>Text mining for product attribute extraction.</title>
<date>2006</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<volume>8</volume>
<issue>1</issue>
<pages>48</pages>
<contexts>
<context position="2694" citStr="Ghani et al., 2006" startWordPosition="420" endWordPosition="423">r and should be resolved (e.g., apartment/apt, bike/bicycle). Symbols could have the special meanings (e.g., x in 2x2 in Fig. 1 indicates number of bedrooms and bathrooms). Tokenization based only on space is insufficient (e.g., RawlingBaseball in Fig. 1). Multiwords such as granite top should also be detected. Applying offthe-shelf parsers is infeasible because of unusual phrasal forms in most listings, such as a long sequence of nouns/adjectives (e.g., “New Paint Wood Floors New Windows Gated Complex”) To address these challenges, several approaches have applied machine learning algorithms (Ghani et al., 2006) (Putthividhya and Hu, 2011) or an external knowledge base (Michelson and Knoblock, 2005). These approaches, however, commonly require human supervision to produce training data or to build a knowledge base. This is expensive, requiring repeated manual effort whenever a new domain or a new set of information to be extracted is introduced. In this paper, we present an unsupervised IE system for listings. The system extracts tokens from a corpus of listings and then clusters tokens of the same types, where each resulting cluster corresponds to an information type (e.g., size, brand, etc.). For f</context>
<context position="5465" citStr="Ghani et al., 2006" startWordPosition="836" endWordPosition="839">ly focuses on extracting main objects and the listing-focused clustering module helps group together extracted tokens of the same type. Our evaluation shows that our two main contributions (shallow semantic parser and listingfocused clustering) significantly improve performance across three different domains – Craigslist, EBay, and FatWallet. Our system achieves .50�.65 F1-score for the EBay and the FatWallet datasets based on gold standards constructed by human annotators. For the Craigslist dataset, which is more difficult than the other two, F1-score is .35. 2 Related Work IE on Listings. (Ghani et al., 2006) (Putthividhya and Hu, 2011) propose semi-supervised approaches to extract product types and their attributes from product listings. (Ghani et al., 2006) applies the EM (Expectation-Maximization) algorithm to incorporate unlabelled data. (Putthividhya and Hu, 2011) uses unlabelled data to build dictionaries of values to be extracted (e.g., brand or model names), which are then used as a feature for a machine learning system. (Michelson and Knoblock, 2005) uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function,</context>
</contexts>
<marker>Ghani, Probst, Liu, Krema, Fano, 2006</marker>
<rawString>Rayid Ghani, Katharina Probst, Yan Liu, Marko Krema, and Andrew Fano. 2006. Text mining for product attribute extraction. SIGKDD Explor. Newsl., 8(1):41– 48, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trond Grenager</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Unsupervised learning of field segmentation models for information extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>371--378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7583" citStr="Grenager et al., 2005" startWordPosition="1166" endWordPosition="1169">larly, our system defines two types of clusters – the main concept clusters (e.g., TV or book) and the attribute clusters (e.g., size, color). (Chambers and Jurafsky, 2011) is similar to our approach in that it learns a semantic model, called template, from unlabelled news articles and then uses the template to extract information. Our system is different because it focuses on informal listings, which the components (such as a parser) used by these systems cannot handle. Field Segmentation (Sequence Modelling). This task focuses on segmenting a short text, such as bibliographies or listings. (Grenager et al., 2005) presents an unsupervised HMM based on the observation that the segmented fields tend to be of multiple words length. (Haghighi and Klein, 2006) exploits prototype words (e.g., close, near, shoping for the NEIGHBORHOOD attribute) in an unsupervised setting. (Chang et al., 2007) incorporates domain specific constraints in semi-supervised learning. Our task is different than these systems because we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The</context>
</contexts>
<marker>Grenager, Klein, Manning, 2005</marker>
<rawString>Trond Grenager, Dan Klein, and Christopher D. Manning. 2005. Unsupervised learning of field segmentation models for information extraction. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05, pages 371–378, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gruhl</author>
<author>Meena Nagarajan</author>
<author>Jan Pieper</author>
<author>Christine Robson</author>
<author>Amit Sheth</author>
</authors>
<title>Context and domain knowledge enhanced entity spotting in informal text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 8th International Semantic Web Conference, ISWC ’09,</booktitle>
<pages>260--276</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="8529" citStr="Gruhl et al., 2009" startWordPosition="1320" endWordPosition="1323">-supervised learning. Our task is different than these systems because we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The segmented fields are often a long unstructured text (e.g., 2 bath 1 bed for size rather than 2 for BathroomNum and 1 for BedroomNum). IE on Informal Texts. IE on informal texts is getting much attention because of the recent explosive growth of these texts. The informal texts that are attempted for IE include online forums (Gruhl et al., 2009), SMS (Beaufort et al., 2010), twitter messages (Liu et al., 2011). 3 Our Approach Given a corpus of listings for a domain of interest, our system constructs a semantic model that represents the types of information and their values to be extracted. Our system then uses the resulting model to extract both the type and value from the corpus 1. We first describe the semantic model and then the two key steps for creating this model – shallow semantic parsing and listing-focused clustering. Fig. 3 illustrates these two steps with example listings. 3.1 Semantic Model Our semantic model captures two</context>
</contexts>
<marker>Gruhl, Nagarajan, Pieper, Robson, Sheth, 2009</marker>
<rawString>Daniel Gruhl, Meena Nagarajan, Jan Pieper, Christine Robson, and Amit Sheth. 2009. Context and domain knowledge enhanced entity spotting in informal text. In Proceedings of the 8th International Semantic Web Conference, ISWC ’09, pages 260–276, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL ’06,</booktitle>
<pages>320--327</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7727" citStr="Haghighi and Klein, 2006" startWordPosition="1191" endWordPosition="1194">. (Chambers and Jurafsky, 2011) is similar to our approach in that it learns a semantic model, called template, from unlabelled news articles and then uses the template to extract information. Our system is different because it focuses on informal listings, which the components (such as a parser) used by these systems cannot handle. Field Segmentation (Sequence Modelling). This task focuses on segmenting a short text, such as bibliographies or listings. (Grenager et al., 2005) presents an unsupervised HMM based on the observation that the segmented fields tend to be of multiple words length. (Haghighi and Klein, 2006) exploits prototype words (e.g., close, near, shoping for the NEIGHBORHOOD attribute) in an unsupervised setting. (Chang et al., 2007) incorporates domain specific constraints in semi-supervised learning. Our task is different than these systems because we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The segmented fields are often a long unstructured text (e.g., 2 bath 1 bed for size rather than 2 for BathroomNum and 1 for BedroomNum). IE on Inf</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>Aria Haghighi and Dan Klein. 2006. Prototype-driven learning for sequence models. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL ’06, pages 320–327, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Dirt @sbt@discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’01,</booktitle>
<pages>323--328</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="19168" citStr="Lin and Pantel, 2001" startWordPosition="3093" endWordPosition="3096">partial semantic model that contains a cluster for the main concept and a list of candidate attribute tokens. 3.3 Listing-Focused Clustering Listing-Focused Clustering (LFC) further expands the partial semantic model (constructed by SSP) by grouping the remaining candidate attribute tokens into attribute clusters – i.e. one cluster for each attribute of the main concept. LFC may also add a token to the main concept cluster if appropriate. For formal texts, distributional similarity is widely used for clustering words because the contextual clues in these texts are sufficiently discriminative (Lin and Pantel, 2001). This feature alone, however, is insufficient for listings because they lack discriminative contexts due to the short length. Hence, our approach augments context-based similarity with the following rules (presented in order of precedence), based on general properties we observed from listing data across various domains. • Two quantitative attribute tokens cannot be placed into the same cluster if they frequently appear together in a listing. For example, bed and bath should not be clustered because they frequently appear together (e.g. 2 bed/ 2bath). This rule is based on the observation tha</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Dirt @sbt@discovery of inference rules from text. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’01, pages 323–328, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Shaodian Zhang</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
</authors>
<title>Recognizing named entities in tweets.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>359--367</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8595" citStr="Liu et al., 2011" startWordPosition="1332" endWordPosition="1335">se we focus on extracting information to enable a variety of automated applications such as business 1082 intelligence reporting, faceted search or automated reasoning, rather than segmenting the text. The segmented fields are often a long unstructured text (e.g., 2 bath 1 bed for size rather than 2 for BathroomNum and 1 for BedroomNum). IE on Informal Texts. IE on informal texts is getting much attention because of the recent explosive growth of these texts. The informal texts that are attempted for IE include online forums (Gruhl et al., 2009), SMS (Beaufort et al., 2010), twitter messages (Liu et al., 2011). 3 Our Approach Given a corpus of listings for a domain of interest, our system constructs a semantic model that represents the types of information and their values to be extracted. Our system then uses the resulting model to extract both the type and value from the corpus 1. We first describe the semantic model and then the two key steps for creating this model – shallow semantic parsing and listing-focused clustering. Fig. 3 illustrates these two steps with example listings. 3.1 Semantic Model Our semantic model captures two important pieces of information – the main concept and its attrib</context>
</contexts>
<marker>Liu, Zhang, Wei, Zhou, 2011</marker>
<rawString>Xiaohua Liu, Shaodian Zhang, Furu Wei, and Ming Zhou. 2011. Recognizing named entities in tweets. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 359– 367, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Michelson</author>
<author>Craig A Knoblock</author>
</authors>
<title>Semantic annotation of unstructured and ungrammatical text.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th international joint conference on Artificial intelligence, IJCAI’05,</booktitle>
<pages>1091--1098</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="2783" citStr="Michelson and Knoblock, 2005" startWordPosition="433" endWordPosition="436">e the special meanings (e.g., x in 2x2 in Fig. 1 indicates number of bedrooms and bathrooms). Tokenization based only on space is insufficient (e.g., RawlingBaseball in Fig. 1). Multiwords such as granite top should also be detected. Applying offthe-shelf parsers is infeasible because of unusual phrasal forms in most listings, such as a long sequence of nouns/adjectives (e.g., “New Paint Wood Floors New Windows Gated Complex”) To address these challenges, several approaches have applied machine learning algorithms (Ghani et al., 2006) (Putthividhya and Hu, 2011) or an external knowledge base (Michelson and Knoblock, 2005). These approaches, however, commonly require human supervision to produce training data or to build a knowledge base. This is expensive, requiring repeated manual effort whenever a new domain or a new set of information to be extracted is introduced. In this paper, we present an unsupervised IE system for listings. The system extracts tokens from a corpus of listings and then clusters tokens of the same types, where each resulting cluster corresponds to an information type (e.g., size, brand, etc.). For formal texts, contexts (e.g., surrounding words) have been a major feature for word cluste</context>
<context position="5924" citStr="Michelson and Knoblock, 2005" startWordPosition="903" endWordPosition="906">structed by human annotators. For the Craigslist dataset, which is more difficult than the other two, F1-score is .35. 2 Related Work IE on Listings. (Ghani et al., 2006) (Putthividhya and Hu, 2011) propose semi-supervised approaches to extract product types and their attributes from product listings. (Ghani et al., 2006) applies the EM (Expectation-Maximization) algorithm to incorporate unlabelled data. (Putthividhya and Hu, 2011) uses unlabelled data to build dictionaries of values to be extracted (e.g., brand or model names), which are then used as a feature for a machine learning system. (Michelson and Knoblock, 2005) uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) </context>
<context position="30218" citStr="Michelson and Knoblock, 2005" startWordPosition="4888" endWordPosition="4891"> that the performance on extraction for the rent ad dataset is the lowest, confirming our hypothesis. We also measure the performance per each information type. Fig. 5 shows the result, revealing several facts. First, the main concept clusters (housing type and product type) achieve a high F1-score, showing the benefit of our semantic parser. Sec11We could not compare our system to other systems for several reasons. First, to the best of our knowledge, no unsupervised IE system has been built specifically for short listings. Second, semi-supervised systems such as (Putthividhya and Hu, 2011) (Michelson and Knoblock, 2005) require domainspecific dictionaries, which are expensive to build and scale. Third, even developing a supervised IE system is non-trivial. In our preliminary evaluation with the (linear chain) conditional random field (170/30 training/testing listings) using basic features (the lexemes and POS of the current word and words in the two left/right windows), precision/recall/F1-score are .5/.33/.4. This result is no better than our system. More training data and/or better features seem to be required. P Full F P Full(Par) F R R Rent Ad 0.3 0.41 0.35 0.43 0.55 0.48 (302/219) 0.34 0.46 0.39 0.65 0.</context>
</contexts>
<marker>Michelson, Knoblock, 2005</marker>
<rawString>Matthew Michelson and Craig A. Knoblock. 2005. Semantic annotation of unstructured and ungrammatical text. In Proceedings of the 19th international joint conference on Artificial intelligence, IJCAI’05, pages 1091–1098, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Michelson</author>
<author>Craig A Knoblock</author>
</authors>
<title>Exploiting background knowledge to build reference sets for information extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09,</booktitle>
<pages>2076--2082</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="6289" citStr="Michelson and Knoblock, 2009" startWordPosition="964" endWordPosition="967"> algorithm to incorporate unlabelled data. (Putthividhya and Hu, 2011) uses unlabelled data to build dictionaries of values to be extracted (e.g., brand or model names), which are then used as a feature for a machine learning system. (Michelson and Knoblock, 2005) uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al., 2011) focus on extracting frame-like structures (Baker et al., 1998) by defining two types of clusters, event clusters and role clusters. Event clusters define an event (a situation or a frame) such as BOMBING by clustering verbs/nominalized verbs such as {kill, explosion}. Role clusters define the semantic roles of the eve</context>
</contexts>
<marker>Michelson, Knoblock, 2009</marker>
<rawString>Matthew Michelson and Craig A. Knoblock. 2009. Exploiting background knowledge to build reference sets for information extraction. In Proceedings of the 21st international jont conference on Artifical intelligence, IJCAI’09, pages 2076–2082, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Joint inference in information extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 22nd national conference on Artificial intelligence - Volume 1, AAAI’07,</booktitle>
<pages>913--918</pages>
<publisher>AAAI Press.</publisher>
<marker>Poon, Domingos, 2007</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2007. Joint inference in information extraction. In Proceedings of the 22nd national conference on Artificial intelligence - Volume 1, AAAI’07, pages 913–918. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised ontology induction from text.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>296--305</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6549" citStr="Poon and Domingos, 2010" startWordPosition="1000" endWordPosition="1003">uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies tokens in listings that have a low distance score with the values defined in the reference set. They also propose a semi-supervised method to building reference sets (Michelson and Knoblock, 2009).Unlike these systems, our approach is unsupervised. Unsupervised Information Extraction. Most unsupervised IE systems produce clusters for tokens of same type extracted from a corpus of unlabelled texts. (Chambers and Jurafsky, 2011) (Poon and Domingos, 2010) (Chen et al., 2011) focus on extracting frame-like structures (Baker et al., 1998) by defining two types of clusters, event clusters and role clusters. Event clusters define an event (a situation or a frame) such as BOMBING by clustering verbs/nominalized verbs such as {kill, explosion}. Role clusters define the semantic roles of the event (e.g., {terrorist, gunman} for the Perpetrator role in BOMBING). Similarly, our system defines two types of clusters – the main concept clusters (e.g., TV or book) and the attribute clusters (e.g., size, color). (Chambers and Jurafsky, 2011) is similar to o</context>
<context position="36757" citStr="Poon and Domingos, 2010" startWordPosition="5964" endWordPosition="5967">e include only the rent domain result. However, all three datasets follow a similar pattern. F1 0.8 Full 0.7 Full(P) 0.6 Ext 0.5 Ext(P) 0.4 0.3 0.2 0.1 0 0 2000 4000 6000 8000 10000 number of listings Figure 6: F1-score of our system over varying corpus size for the rent domain low semantic parser and a listing-focused clustering module. Our evaluation shows the benefits of the two features across multiple domains. To improve our system further, we plan the following works. First, we plan to compare our system with supervised systems to identify the gap between the two systems. Second, as in (Poon and Domingos, 2010), we plan to explore a joint learning method to combine the tasks of tokenization, forming the main concept cluster and forming the attribute clusters; these tasks depend on the outputs of one another. Finally, we plan to explore that external knowledge resources such as DBPedia (Auer et al., 2007) and FreeBase (Bollacker et al., 2008) can be used to further improve performance. 6 Acknowledgements We would like to thank Colin Puri and Rey Vasquez for their contribution to this work. We also thank the anonymous reviewers for their helpful comments and suggestions for improving the paper. Refere</context>
</contexts>
<marker>Poon, Domingos, 2010</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2010. Unsupervised ontology induction from text. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 296–305, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duangmanee Putthividhya</author>
<author>Junling Hu</author>
</authors>
<title>Bootstrapped named entity recognition for product attribute extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1557--1567</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2722" citStr="Putthividhya and Hu, 2011" startWordPosition="424" endWordPosition="427">ved (e.g., apartment/apt, bike/bicycle). Symbols could have the special meanings (e.g., x in 2x2 in Fig. 1 indicates number of bedrooms and bathrooms). Tokenization based only on space is insufficient (e.g., RawlingBaseball in Fig. 1). Multiwords such as granite top should also be detected. Applying offthe-shelf parsers is infeasible because of unusual phrasal forms in most listings, such as a long sequence of nouns/adjectives (e.g., “New Paint Wood Floors New Windows Gated Complex”) To address these challenges, several approaches have applied machine learning algorithms (Ghani et al., 2006) (Putthividhya and Hu, 2011) or an external knowledge base (Michelson and Knoblock, 2005). These approaches, however, commonly require human supervision to produce training data or to build a knowledge base. This is expensive, requiring repeated manual effort whenever a new domain or a new set of information to be extracted is introduced. In this paper, we present an unsupervised IE system for listings. The system extracts tokens from a corpus of listings and then clusters tokens of the same types, where each resulting cluster corresponds to an information type (e.g., size, brand, etc.). For formal texts, contexts (e.g.,</context>
<context position="5493" citStr="Putthividhya and Hu, 2011" startWordPosition="840" endWordPosition="843">ing main objects and the listing-focused clustering module helps group together extracted tokens of the same type. Our evaluation shows that our two main contributions (shallow semantic parser and listingfocused clustering) significantly improve performance across three different domains – Craigslist, EBay, and FatWallet. Our system achieves .50�.65 F1-score for the EBay and the FatWallet datasets based on gold standards constructed by human annotators. For the Craigslist dataset, which is more difficult than the other two, F1-score is .35. 2 Related Work IE on Listings. (Ghani et al., 2006) (Putthividhya and Hu, 2011) propose semi-supervised approaches to extract product types and their attributes from product listings. (Ghani et al., 2006) applies the EM (Expectation-Maximization) algorithm to incorporate unlabelled data. (Putthividhya and Hu, 2011) uses unlabelled data to build dictionaries of values to be extracted (e.g., brand or model names), which are then used as a feature for a machine learning system. (Michelson and Knoblock, 2005) uses a manuallycrafted knowledge base called reference set to define standard forms of values to be extracted. Using a string edit function, the system then identifies </context>
<context position="30187" citStr="Putthividhya and Hu, 2011" startWordPosition="4884" endWordPosition="4887">ignment task). Table 5 shows that the performance on extraction for the rent ad dataset is the lowest, confirming our hypothesis. We also measure the performance per each information type. Fig. 5 shows the result, revealing several facts. First, the main concept clusters (housing type and product type) achieve a high F1-score, showing the benefit of our semantic parser. Sec11We could not compare our system to other systems for several reasons. First, to the best of our knowledge, no unsupervised IE system has been built specifically for short listings. Second, semi-supervised systems such as (Putthividhya and Hu, 2011) (Michelson and Knoblock, 2005) require domainspecific dictionaries, which are expensive to build and scale. Third, even developing a supervised IE system is non-trivial. In our preliminary evaluation with the (linear chain) conditional random field (170/30 training/testing listings) using basic features (the lexemes and POS of the current word and words in the two left/right windows), precision/recall/F1-score are .5/.33/.4. This result is no better than our system. More training data and/or better features seem to be required. P Full F P Full(Par) F R R Rent Ad 0.3 0.41 0.35 0.43 0.55 0.48 (</context>
</contexts>
<marker>Putthividhya, Hu, 2011</marker>
<rawString>Duangmanee (Pew) Putthividhya and Junling Hu. 2011. Bootstrapped named entity recognition for product attribute extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1557–1567, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Reisinger</author>
<author>Marius Pas¸ca</author>
</authors>
<title>Fine-grained class label markup of search queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1200--1209</pages>
<marker>Reisinger, Pas¸ca, 2011</marker>
<rawString>Joseph Reisinger and Marius Pas¸ca. 2011. Fine-grained class label markup of search queries. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1200–1209,</rawString>
</citation>
<citation valid="false">
<authors>
<author>PA Stroudsburg</author>
</authors>
<institution>USA. Association for Computational Linguistics.</institution>
<marker>Stroudsburg, </marker>
<rawString>Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In In Advances in Neural Information Processing Systems 17,</booktitle>
<pages>1185--1192</pages>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In In Advances in Neural Information Processing Systems 17, pages 1185–1192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>On-demand information extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06,</booktitle>
<pages>731--738</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Sekine, 2006</marker>
<rawString>Satoshi Sekine. 2006. On-demand information extraction. In Proceedings of the COLING/ACL on Main conference poster sessions, COLING-ACL ’06, pages 731–738, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Bidirectional inference with the easiest-first strategy for tagging sequence data.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>467--474</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="11877" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="1843" endWordPosition="1846">forms preprocessing and multiword detection. SSP then identifies which resulting tokens are the main concepts and which are their attributes. 3.2.1 Preprocessing and Multiword Detection SSP preprocesses the corpus through three steps. (1) SSP cleans the corpus by removing duplicate listings and HTML expressions/tags. (2) SSP tokenizes each listing based on spaces along with custom heuristics – e.g., handling alpha-numeric tokens starting with numbers (e.g., 3bedroom to 3 bedroom) and mixed case tokens (e.g., NikeShoes to Nike Shoes). (3) SSP performs POS tagging using an off-the-shelf tagger (Tsuruoka and Tsujii, 2005). To improve accuracy, SSP assigns to a token the most frequent POS across all occurrences of that token. This heuristic works well because most tokens in focused domains, like listings, have only one POS. SSP then detects multiword tokens based on the following rules: * Main Concept {house, condo, apt., apartment, townhouse, ...} * Qualitative Attribute+ {washer, dryer, w/d, washer hookup, d hookup,...} * Quantitative Attribute+ {bedroom, bdrm, bd, bed,...} 1083 A corpus of listings Semantically analyzed listings Semantic model * Brentwood Apt. with 3 bedroom * 2 BD/ 2 BA +Den – Open Sun 2/12</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka and Jun’ichi Tsujii. 2005. Bidirectional inference with the easiest-first strategy for tagging sequence data. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 467–474, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: vector space models of semantics.</title>
<date>2010</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="3413" citStr="Turney and Pantel, 2010" startWordPosition="537" endWordPosition="540">e approaches, however, commonly require human supervision to produce training data or to build a knowledge base. This is expensive, requiring repeated manual effort whenever a new domain or a new set of information to be extracted is introduced. In this paper, we present an unsupervised IE system for listings. The system extracts tokens from a corpus of listings and then clusters tokens of the same types, where each resulting cluster corresponds to an information type (e.g., size, brand, etc.). For formal texts, contexts (e.g., surrounding words) have been a major feature for word clustering (Turney and Pantel, 2010). This feature alone, however, is insufficient for short listings because of lack of contextual clues in short listings. 1081 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1081–1092, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics 2x2 Charming Condo – 1515 Martin Avenue near Downtown (from Craigslist) RawlingsBaseball Gloves Pro Preferred Black 12” (from EBay) HousingType: Condo, BedroomNum: 2, BathroomNum: 2, Location: 1515 Martin Avenue, Neighborhood: Downto</context>
<context position="21294" citStr="Turney and Pantel, 2010" startWordPosition="3444" endWordPosition="3447">r, preserving the order (e.g., bdrm and bedroom) If the above rules fail to determine the similarity between two tokens, LFC reverts to context-based similarity. For each token, LFC creates a context vector containing frequencies of the context words around the token with a window size of two. For example, in the first sentence in Fig. 3, the context words around apts. are l-start (beginning of the sentence), l-brentwood, r-with, and r-3 5. The frequencies in these vectors are also weighted using PMI scores (pointwise mutual information) between a token and its context words, as suggested by (Turney and Pantel, 2010). The intuition is that a high PMI indicates a context word is strongly associated with a token and hence has high discriminative power. We also apply a smoothing function suggested in (Turney and Pantel, 2010) to mitigate PMI’s bias towards infrequent events. The similarity score is based on a cosine similarity between the two weighted vectors. Based on this similarity function, LFC applies agglomerative clustering (with average linkage) to produce attribute clusters (or to expand the main concept cluster). However, calculating similarity scores for all pairs of tokens is expensive. To addres</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: vector space models of semantics. J. Artif. Int. Res., 37(1):141–188, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William E Winkler</author>
</authors>
<title>String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage.</title>
<date>1990</date>
<booktitle>In Proceedings of the Section on Survey Research,</booktitle>
<pages>354--359</pages>
<contexts>
<context position="10254" citStr="Winkler, 1990" startWordPosition="1599" endWordPosition="1600">a wide range of domains. We quantitatively show both benefits in our evaluation. Fig. 2 illustrates our model along with an instantiation for rental listings. The main concept is a cluster containing tokens referencing the main object in the listing. For example, in the rental listing, the main concept cluster includes tokens such as house, condo, and townhouse. Each attribute of the main concept (e.g. Address, BedroomNum, etc.) is also a cluster, and two types 1To handle string variations (e.g., typos) during extraction, our system uses a string edit distance function, Jaro-Winkler distance (Winkler, 1990) with a threshold, 0.9. Figure 2: Semantic model and its instantiation for rental listings. + indicates multiple clusters can be created. of attributes are defined in our model – quantitative attributes and qualitative ones. Quantitative attributes capture numeric values (e.g. 1 bedroom, 150 Hz, and 70 kg), and are generally a number followed by a token indicating the attribute (e.g., unit of measurement). Hence, clusters for quantitative attributes include these indicator tokens (see Fig. 2). Qualitative attributes capture descriptions about the main concept (e.g., address, shipping informati</context>
</contexts>
<marker>Winkler, 1990</marker>
<rawString>William E. Winkler. 1990. String comparator metrics and enhanced decision rules in the fellegi-sunter model of record linkage. In Proceedings of the Section on Survey Research, pages 354–359.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>