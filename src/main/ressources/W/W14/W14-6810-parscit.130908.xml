<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005009">
<title confidence="0.634684">
Bilingual Product Name Dictionary Construction Using a Two Stage
Method
</title>
<author confidence="0.991081">
Yatian Shen, Xuanjing Huang
</author>
<affiliation confidence="0.995315">
School of Computer Science, Fudan University, Shanghai, China
</affiliation>
<email confidence="0.996329">
shenyatian@gmail.com, xjhuang@fudan.edu.cn
</email>
<sectionHeader confidence="0.994755" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999912681818182">
This paper proposes a novel two-stage
method for bilingual product name dictio-
nary construction from comparable corpo-
ra. In previous work, some researchers s-
tudy the problem of expanding a set of giv-
en seed entities into a more complete set
by discovering other entities that also be-
long to the same concept, it just solves the
problem about expansion of entity set in a
monolingual language, but the expansion
of bilingual entity is really blank problem
from comparable corpora. A typical ex-
ample is to use&amp;quot;Honda-*[E”as seed en-
tity, and derive other entities(e.g.,&amp;quot;Ford-
fw ”) in the same concept set of product
name. We address this problem by utiliz-
ing a two-stage approach based on entity
set expansion and bilingual entity align-
ment from comparable corpora. Evalua-
tions using English and Chinese reviewer
corpus verify that our method outperforms
conventional methods.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9817938">
Bilingual lexicons are important resources for
bilingual tasks such as machine translation (MT)
and cross-language information retrieval (CLIR).
Therefore, the automatic building of bilingual
product name lexicons from corpus is one of
the important issues, however it has not attract-
ed many researchers. As a solution, a number of
previous works have been proposed for extracting
bilingual product name lexicons from comparable
corpora, in which documents are not direct trans-
lations but share the same topic or domain. The
use of comparable corpora is motivated by the fact
that large parallel corpora are only available for a
few language pairs and limited domains.
Bilingual product name lexicon is similar to tra-
ditional bilingual lexicon extraction, what they are
all common on is extract bilingual entity transla-
tion pair from comparable corpora, but there is
some difference between them. Our problem is:
first given an seed set for semantic classes, finding
the conceptually entities by extending semantic
classes. Then, the bilingual entity translation pairs
are extracted from comparable corpora. Tradition-
al bilingual lexicon extraction approaches can only
find entity translation pairs from comparable cor-
pora, but not expand semantic set.
Set expansion systems provide us a useful so-
lution to the above problem because they create a
more perfect set of name entities by expanding the
small number of seed words given for the target
domain. Google Sets is a well-known example of a
web-based set expansion system. Another promi-
nent work is the SEAL system (Wang and Cohen,
2007; Wang and Cohen, 2008; Wang and Cohen,
2009), which adoptes a two-phase strategy, where
they first build customized text wrappers based on
the input seeds in order to exact candidate enti-
ties from web pages. Then a graph-based random
walk approach is used to rank candidate entities
based on their closeness to the seeds on the graph.
The third method is set expansion by iterative sim-
ilarity aggregation (He and Xin, 2011), in which a
set of given seed entities is expanded into a more
complete set. All these methods are entity expan-
sion from monolingual data sources.
Another meaningful work is the bilingual lexi-
con extraction (Fung and McKeown, 1997; Rap-
p, 1999; Andrade et al., 2010; Fiˇser et al., 2011;
Daille and Morin, 2005; Vulic et al., 2011; An-
drade et al., 2011; Bo et al., 2011). Most of the
</bodyText>
<page confidence="0.990232">
61
</page>
<note confidence="0.9848415">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69,
Wuhan, China, 20-21 October 2014
</note>
<bodyText confidence="0.999966983333333">
previous methods are based on the assumption that
a word and its translation tend to appear in simi-
lar contexts across languages. Based on this as-
sumption, many methods calculate word similari-
ty using context and then extract word translation
pairs with a high context similarity. while their
researches aim to generate a general bilingual lex-
icons, our work is bilingual entity extraction of the
same semantic category, these entities are refer to
product name.
Considerable progresses have been made in de-
veloping high-quality set expansion systems in
the monolingual setting. while bilingual produc-
t name dictionary construction and extraction still
do not attract much research attention. For bilin-
gual product name dictionary construction, there
are two major fundamental problems. The first is
generating an extensive list of the same semantic
entity, while some seed entities of the same con-
cept are given as input. The second problem is to
find bilingual entity translation from comparable
corpora.
Facing the above problems, we present a novel
approach to construct bilingual product name dic-
tionary in this paper. In order to express the sim-
plification, we will replace word ”product name”
with ”entity” each other. Following the common
practice, our system proceeds in two stages, which
first expands the entity set for the semantic catego-
ry by giving some bilingual set pairs and then finds
bilingual product name translation pair from com-
parable corpora. Semantic category set expansion
is carried out through the bootstrapping algorithm.
In this stage ,our goal is to discover relevant enti-
ties by giving some entity seed set. In the second
stage, we use this assumption that a word and its
translation tend to appear in similar context across
languages (Rapp, 1999). Our method calculates
entity similarity using context and then extract en-
tity translation pairs with a high context similari-
ty. We call this method as context-similarity-based
methods. The context similarity is usually com-
puted using machine translation model by map-
ping contexts expressed in two different languages
into the same language space. In the mapping pro-
cess, information not represented by the seed lexi-
con is discarded.
The main contributions of this paper are as fol-
lows: 1) we propose a bilingual product name ex-
traction method that can get the set of semantic
category by bootstrapping. At the same time, we
can find bilingual product name translation pairs
based on context similarity from comparable cor-
pora. 2) we propose an the algorithm that can not
only build set of semantic category by giving some
bilingual seed set but also find entity translation
pairs from comparable corpora. 3) we construc-
t a dictionary of the bilingual product name from
comparable corpora, which do not need fully par-
allel data that is seldom.
</bodyText>
<sectionHeader confidence="0.999726" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.995913">
There is a significant body of related work in the
broad space of information extraction and named
entity extraction. We will only summarize work
most relevant to set expansion and bilingual entity
extraction due to the limit of space.
Google sets does set expansion using propriety
algorithms which are not publicly available. (He
and Xin, 2011) expand seeds by iterative simi-
larity aggregation. (Talukdar et al., 2006) stud-
ied the problem of set expansion of open text,
which proposes to automatically identify trigger-
words which indicate patterns in a bootstrapping
manner. (Ghahramani and Heller, 2005) used the
method of Bayesian inference to solve the problem
of set expansion. In comparison, our approach ex-
pands bilingual entity seeds set by using bootstrap-
ping algorithms ,which learn entity candidates and
their corresponding patterns iteratively. Our goal
is to find the same semantic concept set.
(Fung and McKeown, 1997) present a statis-
tical word feature that is said to the word rela-
tion matrix, which can be used to find translated
pairs of words and terms from non-parallel cor-
pora across language groups. (Daille and Morin,
2005) proposes a method of extracting bilingual
lexicon composed of single-word terms (SWTs)
and multi-word terms (MWTs) from comparable
corpora of a technical domain. First, this method
extracts MWTs in each language, and then uses s-
tatistical methods to align single words and multi-
word terms by exploiting the term contexts. The
alignment of words in translated texts are well es-
tablished, this algorithm is used to identify word
translations (Rapp, 1999). (Andrade et al., 2010)
suggest a new method which selects a subset of
words (pivot words) associated with a query and
then matches these words across languages, a new
Bayesian method for estimating Point-wise Mutu-
al Information is used to detect word association-
s. (Fiˇser et al., 2011) presents a series of exper-
</bodyText>
<page confidence="0.99415">
62
</page>
<figure confidence="0.842858">
St
</figure>
<figureCaption confidence="0.99898">
Figure 1: Flow chart of our two-stage system.
</figureCaption>
<bodyText confidence="0.99998092">
iments aimed at inducing and evaluating domain-
specific bilingual lexicon from comparable corpo-
ra. (Vulic et al., 2011) investigate the algorithm
of bilingual topic models, which finds translations
of terms in comparable corpora by using knowl-
edge from word-topic distributions. (Andrade et
al., 2011) propose to perform a linear transforma-
tion of the context vectors, the new word trans-
lations are found by context similarity. (Bo et
al., 2011) introduce a clustering-based approach
for enhancing corpus comparability which exploit-
s the homogeneity feature of the corpus, and p-
reserves most of the vocabulary of the original
corpus. (Tamura et al., 2012) proposes a novel
method for lexicon extraction that extracts trans-
lation pairs from comparable corpora by using
graph- based label propagation.
All the methods mentioned above may poten-
tially extract entities translation pairs when con-
text of entities are similarity. We are also based
on this assumption, but we are different from the
previous models where we use machine translation
model to map the context of entity to the same lan-
guage space, which can improve performance and
illustrate robustness.
</bodyText>
<sectionHeader confidence="0.985011" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.982262">
Figure 1 illustrates the framework of our proposed
methods. The proposed method has the follow-
ing components: Bootstrapping algorithm is used
to get entity sets and the patterns for Chinese and
English respectively, then we can find entity trans-
lation pairs by calculating context similarity and
construct bilingual product name lexicon.
Step 1. Using Bootstrapping algorithm gets en-
tity sets and the patterns for Chinese and English
respectively.
Step 2. Based on the assumption that the word
and its translation tend to appear in similar con-
texts across languages, we can find translation
pair.
Step 3. Construct bilingual product name lexi-
con.
</bodyText>
<sectionHeader confidence="0.9957115" genericHeader="method">
4 Bootstrapping for Entity Set
Expansion
</sectionHeader>
<bodyText confidence="0.999975375">
In this paper, we expand seed entity set into a more
complete set by discovering other entities that also
belong to the same concept set. A typical applica-
tion is to use seed entities to derive other entities in
the same concept set of brands. In order to discov-
er such relevant entities, we expand seed entities
to assign semantic similar entities to the same se-
mantic set using plenty of user reviews.
</bodyText>
<subsectionHeader confidence="0.998173">
4.1 Growing Seed Dictionary
</subsectionHeader>
<bodyText confidence="0.9999855">
We focus on the problem of how to grow the seed
dictionary and discovering new product names
from user reviews. In this section, we use the seed
entity to automatically generate semantic lexicons.
For the specific case of brand discovery, this initial
list used to generate semantic lexicons must con-
tain only names that are unambiguously. We hence
remove ambiguous names or phrases that belong
to multiple entity types from the dataset, and on-
ly choose those entities as entity seed that it owns
definite semantic. We used a weakly supervised
bootstrapping algorithm that automatically gener-
ates semantic lexicons (Thelen and Riloff, 2002).
Bootstrapping algorithms hypothesizes the se-
mantic class of entity by gathering collective ev-
idence about semantic associations from extrac-
tion pattern context. For our representation of ex-
traction patterns, we used the AutoSlog system
(Riloff, 1996), AutoSlog’s extraction patterns rep-
resent linguistic expressions that extract a noun
phrase in one of three syntactic roles: subject, di-
rect object, or prepositional phrase object. Be-
fore bootstrapping begins, we run AutoSlog ex-
haustively over the corpus to generate an extrac-
tion pattern for every noun phrase that appears. In
these, noun or noun phrase are entities, we will
</bodyText>
<figure confidence="0.993474">
Bili
and
Entit
sam
Boo
al
</figure>
<page confidence="0.994641">
63
</page>
<bodyText confidence="0.999851714285714">
possibly extract them as production name. The
patterns are then applied to the corpora and all of
theirs extracted noun phrases are recorded. For
every iteration, the top 20 extraction patterns are
put into a pattern pool. Every pattern used the R-
logF metric that has been used for extraction pat-
tern learning (Riloff, 1996).
All entities in the candidate entity pool are s-
cored and the top five words are added to the se-
mantic lexicon. Bootstrapping algorithm learns
pattern that associate entity to their correct expan-
sions, the intuition of our work is that the algorith-
m learns context that can associate some entities
that have the same semantic.
</bodyText>
<sectionHeader confidence="0.966751" genericHeader="method">
5 Finding Translation Pairs
</sectionHeader>
<bodyText confidence="0.999977315789474">
Translating domain-specific entities from one lan-
guage to another is challenging because they are
often not listed in a general dictionary. In this sec-
tion, we are based on this assumption that context
similarity is helpful since two words with iden-
tical meaning are often used in similar contexts
across languages(Rapp,1999). Let us briefly recal-
l the main idea for using context similarity to find
translation pairs. First, the context pattern of ev-
ery entity is found because the context of a entity
is usually defined by the word which occur around
it(bag-of-words model), we use ten forward and
backward window of word as context. Second, we
use machine translation model to translate contex-
t, the context of two entities can be aligned about
their probability. At last, if the context of two en-
tities is similar, so they corresponds to entity pairs
as bilingual product name pairs. The detail algo-
rithms is as follows:
</bodyText>
<subsectionHeader confidence="0.998481">
5.1 Looking Up Context of Every Entity
</subsectionHeader>
<bodyText confidence="0.973801">
With the bootstrapping algorithm, we get the set
of semantic category entity in English and Chinese
comparable corpora. For every entity, we look up
their context, and use the method of string match-
ing in the corpora. We use 3 forward and back-
ward window of word as context, That is what we
call the context. The context and their correspond-
ing entities have great relevance. As an example,
it is easier for us to find some words around ”Cam-
era” name,such as the pixel,the screen and cmos,
these words are the context of entity, which often
appear near the name of camera. By context, we
are able to find their corresponding entities.
Algorithm 1 Finding translation pairs in bilingual
Input: I = (xi), i = 1, 2, ... , l in which xi is
the ith entity of the same semantic entity set,
BilingualData is bilingual comparable corpo-
ra
Output: Entity tanslation pairs
</bodyText>
<listItem confidence="0.996630166666666">
1: repeat
2: for i = 1 ton do
3: Looking up the context of every entity
contexti in BilingualData ;
4: Calculating the alignment probability of
every entity’s context in different lan-
guages
5: Computing similarity of the context be-
tween contexti and contextj
6: if Similarity(contexti,contextj)is maxi-
mal then
7: For the highest similarity value of con-
text to corresponding entity pair, ex-
tracting them as an entity translation
pair
8: end if
9: end for
10: until no xi is in the I during iteration
</listItem>
<subsectionHeader confidence="0.99901">
5.2 Aligning the Context of two Entities
</subsectionHeader>
<bodyText confidence="0.99998775">
To bilingual context, how they are aligned with
each other is a major problem. This component is
to identify equivalence relation in every entity cor-
responding to bilingual context. We assume that
the same context appears around the same entity.
Thus, our aim is to find translation pairs between
Chinese and English corpora. Machine translation
is commonly used to complete the task. By the
tool of machine translation, two different language
context of entity is mapped to the same language
space.
Many studies on machine translation use
GIZA++ as their underlying word-by-word align-
ment system. Machine translation systems have
also benefited from such alignment, performing it
at the character level (AbdulJaleel and Larkey,
2003), (Virga and Khudanpur, 2003), (Gao et al.,
2005). GIZA++ is a statistical machine transla-
tion toolkit freely available for research purpos-
es. The extended version of this toolkit is called
GIZA++ and was developed by (Och and Ney,
2003). We employ the word-based translation
model to perform context alignment, we get the
alignment probability between the context pattern
</bodyText>
<page confidence="0.997186">
64
</page>
<bodyText confidence="0.999761571428571">
of two different entities. GIZA++ alignment sys-
tem is trained on parallel corpora English and Chi-
nese reviews, we manually annotate the context
of bilingual entity pair on 3000 parallel sentence
pairs about car domain reviews. A probability ta-
ble about the context of bilingual entity pair is gen-
erated by training GIZA++ model.
</bodyText>
<subsectionHeader confidence="0.989841">
5.3 Entity Translation Extraction
</subsectionHeader>
<bodyText confidence="0.999613384615385">
In order to find entity translation pairs in differen-
t languages, we use statistical machine translation
toolkit GIZA++ to calculate the alignment prob-
ability of every entity’s context in different lan-
guages. A pair of entity is treated as a bilingual
product name pair when the alignment probability
of their context is high. In this, if the alignment
probability of four words which is said to context
is greater than threshold, we will think that entity
pairs which have this context are bilingual entity
pair, We found that the word alignment probabili-
ty threshold of the context is set to 0.53 is a good
choice by experiment.
</bodyText>
<sectionHeader confidence="0.99981" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999228">
6.1 Dataset and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.992398592592593">
In order to evaluate our approach, we conduct ex-
periments on two real data sets, which are from
collection of brand reviews including digital cam-
eras and car domains. For the target language of
English, the product dataset contains 9542 reviews
which are collected from www.buzzilions.com
and www.carreview.com. For the source language
of Chinese, the product dataset contains 8432 re-
views which are collected from www.Amazon.cn
and www.xche.com.cn. For our experiment,we
use a Oxford English-Chinese bilingual dictionary
to match similarity semantic reviewer sentence,
any two of them are used as comparable corpus,the
copora are non-parallel, but loosely compara in
term of its content. Though the scale of Chinese
corpora is large, most of the reviews are short texts
and there are a lot noise in the content. For Chi-
nese, we use the ICTLAS 3.0 (Zhang et al., 2003)
toolkit to conduct word segmentation over sen-
tences.
To evaluate the effectiveness of our algorithms,
we select two semantic entity sets in camera do-
main and car domain as seeds, where set expan-
sion experiments are conducted . We select these
two categories because (1) they are from differen-
t domains; and (2) they have different degree of
difficulty for finding entity translation pairs.
</bodyText>
<table confidence="0.9933206">
Language Domain #Sentence #Reviews
Chinese Camera 2480862 1566
Car 3526109 2103
English Camera 1090862 4506
Car 2563120 5036
</table>
<tableCaption confidence="0.936040666666667">
Table 1: Statistics on English corpus about Cam-
era and Car domain. # denotes the size of the re-
views/sentences
</tableCaption>
<bodyText confidence="0.9997689">
In experiments, each English review is segment-
ed into sentences according to punctuation. Then
sentences are tokenized and the part-of-speech of
each word is assigned. Stanford NLP tool is used
to perform POS-tagging. Next, function word-
s were removed since function words with little
semantic information spuriously co-occurred with
many words. Table 1 shows the size of each cor-
pora.
We measure the performance on product name
translation pair extraction as Top N accuracy
(ACCN), which is the number of test words whose
top N translation candidates contain a correc-
t translation equivalent over the total number of
test words. We randomly select 50 Chinese word-
s as our test data. We manually evaluate whether
translation candidates contained a correct transla-
tion equivalent. We do not use recall because we
do not know whether the translation equivalents of
a test word appear or not in the corpus.
</bodyText>
<subsectionHeader confidence="0.999082">
6.2 Example Output
</subsectionHeader>
<bodyText confidence="0.9998902">
Table 2 lists the top 20 ranked results produced
by two stage algorithm for the two domains that
we experiment with. In each domain, those terms
in boldface are the input seeds. The underlined
terms are the results that do not belong to the
ground truth set and thus counted as incorrect re-
sults. While the remaining terms are correct re-
sults expanded from the input seeds.
From Table 2, we can see that in the top-
20 ranked results, the/Camera0domain have
high precision. /Camera0domain has on-
ly two incorrect result, the top-20 results
for/Car0domain, however, includes some noisy
entities that are incorrect, such as product work-
shop names (/ and /Audi compa-
</bodyText>
<page confidence="0.999161">
65
</page>
<bodyText confidence="0.9881105">
ny&amp;quot;), and the similarity concept name (&amp;quot;Honda
car&amp;quot; and &amp;quot;NeeA�4-&amp;quot;�A&amp;quot;).
</bodyText>
<subsectionHeader confidence="0.94196">
6.3 Our Methods VS. State-of-art Methods
</subsectionHeader>
<bodyText confidence="0.999956666666667">
To prove the effectiveness of our method, we se-
lect the following state-of-art methods as baseline
for comparison.
</bodyText>
<listItem confidence="0.785791666666667">
1) Rapp is a typical context-similarity-based
method (Rapp, 1999). Context words are words in
a window (window size is 10) and are treated sepa-
</listItem>
<bodyText confidence="0.997211">
rately for each position. Associations with context
words are computed using the log-likelihood ratio.
The similarity measure between context vectors is
the city-block metric.
2) Andrade is a sophisticated method in context-
similarity-based methods (Andrade et al., 2010).
Context is a set of words with a positive associa-
tion in a window (window size is 10). The asso-
ciation is calculated using the PMI estimated by
a Bayesian method, and a similarity between con-
texts is estimated based on the number of overlap-
ping words.
3)Tamura proposes a method for lexicon extrac-
tion that extracts translation pairs from compara-
ble corpora by using graph-based label propaga-
tion (Tamura et al., 2012). They utilize indirect
relations with the bilingual seeds together with di-
rect relations, in which each word is represented
by a distribution of translated seeds. The seed dis-
tributions are propagated over a graph represent-
ing relations among words, and translation pairs
are extracted by identifying word pairs with a high
similarity in the seed distributions.
</bodyText>
<figure confidence="0.999243926829269">
Camera Car
Ailh--audi
�ê-BMW
M-Bulk
NeeA-Ford
NeeWTT-Focus
*X-Honda
��i k-Mazda
´X-Toyota
ZÒ-Nissan
4X17W-Toyota Crown
textbfg &apos;ITC-Volvo
)�A-Volkswagen
i k6-Mazda6
H$JAS-Honda
JV¶-Benz
*X K-Honda
wjPWTT-Lexus
�JPLR-Hyundai
Ïf-GM
TcA-Citroen
�:E-FUJIFILM
k#î-Casio
*k-Leica
i k-Kodak
W_)�-Ricoh
*Z-SONY
A#LWTT-OLYMPUS
f21-F-Panasonic
gU-Canon
Zx-Nikon
I—M-Pentax
xg-Konka
Zk-Konica
ZxS2-Nikon S2
gU VTD-Canon VTD
Zx-Konka
&amp;-SAMSUNG
gU-Nikon
XUi k-Minolta
Zk-Konica
</figure>
<tableCaption confidence="0.869382">
Table 2: Top -20 results by two stage method
</tableCaption>
<subsectionHeader confidence="0.996145">
6.4 Experiments Results
</subsectionHeader>
<bodyText confidence="0.999950823529412">
Table 3 and Table 4 show the performance of each
method using Car and Camera review dataset. Ta-
ble 3 and Table 4 show that the proposed method-
s outperform the baselines on both datasets. The
results show that expansion of bilingual product
name by using two stage algorithm is effective .
Rapp’s method computed associations with
context words using the log-likelihood ratio. The
city-block metric is used to compute similarity be-
tween context vector. Andrade define context as a
set of words with a positive association in a win-
dow, Pointwise Mutual Information estimated by
a Bayesian method is used to calculate. The sim-
ilarity between contexts is estimated based on the
number of overlapping words. Tamura’s method
utilize indirect relations with the bilingual seeds
together with direct relations, in which each word
</bodyText>
<page confidence="0.983784">
66
</page>
<table confidence="0.9988054">
Methods Acc1 Acc10 Acc20
Rapp 1.6% 2.5% 3.9%
Andrade 1.8% 3.2% 4.1%
Tamura 2.5% 5.8% 7.5%
Ours 4.5 % 8.6% 12.4%
</table>
<tableCaption confidence="0.946485">
Table 3: Performance statistics on Camera domain
by using Top N accuracy (AccN).N is 1,10,20 re-
spectively.
</tableCaption>
<table confidence="0.9998332">
Methods Acc1 Acc10 Acc20
Rapp 1.5% 2.3% 4.5%
Andrade 1.7% 3.6% 5.1%
Tamura 2.3% 6.2% 8.5%
Ours 4.3 % 9.6% 13.8%
</table>
<tableCaption confidence="0.844883">
Table 4: Performance statistics on Car domain by
using Top N accuracy (AccN).N is 1,10,20 respec-
</tableCaption>
<bodyText confidence="0.960016888888889">
tively.
is represented by a distribution of translated seeds.
Then they extracts translation pairs from compa-
rable corpora by using graph-based label propaga-
tion. The parameter setting in these three baselines
are the same as the original papers. The overal-
l performance results are shown in Table 3 and 4.
From these results, we can make the following ob-
servations.
</bodyText>
<listItem confidence="0.997814777777778">
1) Ours achieves performance improvemen-
t over other methods. This indicates that our
method is effective for bilingual product name ex-
traction.
2) Our two stage method outperform Rapp’s
method, Andrade’s method and Tamura’s method.
The reason is that two stage-based method extrac-
t bilingual entity name in a flexible way, we first
consider entity set expansion, then find bilingual
entity pair by using machine translation methods
from comparable corpora, which is not only find
the same semantic entity, but also can find en-
tity translation pair, so we can extract bilingual
product name on specific domain. but Rapp’s
method, Andrade’s method and Tamura’s method
only build a general bilingual lexicon.
3) Our method construct context association by
utilizing machine translation model between bilin-
</listItem>
<bodyText confidence="0.996464952380952">
gual entity name. Machine translation model have
the characteristic of accurate and interpretation,
which favor our problems. Our test data, on the
other hand, includes many low-frequency word-
s. It is generally true that translation of high-
frequency words is much easier than that of low
frequency words. The accuracies of the baselines
in Table 3 and 4 are worse than the previous re-
ports: 14% Acc1 and 46% Acc10 (Andrade et al.,
2010), and 72% Acc1 (Rapp, 1999).
4) Our methods expand entity name of the same
semantic concept by using the bootstrapping algo-
rithm, which is weak-supervised learning algorith-
m. The algorihtm need not labeled dateset to train
model, meanwhile which is easier to implement it,
it exceeds Tamura’s method,which only considers
distribution of translated seeds, then each word is
represented by seeds distribution. The seed distri-
butions are propagated over a graph representing
relations among words, but constructing a graph is
consuming lot of forces, its effect is very low.
</bodyText>
<subsectionHeader confidence="0.998493">
6.5 Effect of Seeds Size
</subsectionHeader>
<bodyText confidence="0.999993190476191">
In this subsection, we aim to prove the effective-
ness and robustness of our algorithms for bilingual
entity extraction. We vary the number of input
seeds and report the corresponding bilingual enti-
ty extraction performance. Specifically, given the
4, 6 and 8 seeds for each of the two domains in the
experiments,we aim to test the performance of our
two stage algorithm. The results are reported in
Table 5, Table 6. The overall trend stands out that
the performance of our algorithm with 6 seeds is
in general much better and more stable than the
case where only 4 or 8 seeds are used as input. We
consider three kinds of the characters that the en-
tity seed set have. The seed must be first the most
representative of a semantic class, and polysemy
of a seed should be avoided, we also consider the
coverage of a seed set. This suggests that our al-
gorithm is more robust when a reasonable num-
ber of seeds are given, and the performance may
fluctuate with very few number of seeds, largely
depending on the quality of the seeds given.
</bodyText>
<subsectionHeader confidence="0.997287">
6.6 Effect of Translation Model
</subsectionHeader>
<bodyText confidence="0.9998055">
We can find entity of similar pattern by using
GIZA++ model, but the alignment model result in
some errors, there are two central reasons. Our
test data includes words whose translation equiv-
alence inherently cannot be found. The first of
these types are words whose equivalence does not
</bodyText>
<page confidence="0.9979">
67
</page>
<table confidence="0.997232">
Number Acc1 Acc10 Acc20
4 1.6% 2.5% 4.9%
6 2.7% 4.3% 6.5%
8 2.3% 3.9% 5.5%
</table>
<tableCaption confidence="0.805021333333333">
Table 5: Performance statistics on Car domain
by using Top N accuracy (AccN).The number of
seeds choose 4,6 and 8 respectively.
</tableCaption>
<table confidence="0.99910025">
Number Acc1 Acc10 Acc20
4 2.0% 3.5% 4.9%
6 2.7% 4.5% 7.4%
8 2.5% 4.1% 5.9%
</table>
<tableCaption confidence="0.993816">
Table 6: Performance statistics on Camera domain
</tableCaption>
<bodyText confidence="0.975856272727273">
by using Top N accuracy (AccN).The number of
seeds choose 4,6 and 8 respectively.
exist in the English corpus, which is an unavoid-
able problem for our methods based on compa-
rable corpora. The second reason of errors is
word sense ambiguity, which is different in ev-
ery language, the Chinese word &amp;quot;� &amp;quot; mean-
s either&amp;quot;horse&amp;quot;or&amp;quot;car&amp;quot; in English, the pro-
posed methods could not identify correct transla-
tion pairs. We will leave this word sense disam-
biguation problem for future work.
</bodyText>
<sectionHeader confidence="0.999124" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999967611111111">
This paper proposes a novel two-stage method for
product name dictionary construction from com-
parable corpora. The bootstrapping algorithm is
used to expand bilingual product name in the first
stage, Then in the second stage we find bilingual
product name pair by calculating context similar-
ity. The alignment model is used to Calculate
alignment probability of every entity’s context in
different languages. Evaluations using English
and Chinese comparable corpora outperforms con-
ventional methods.
In future work, we are planning to investigate
the following open problems : word sense disam-
biguation and translation of compound words in
bilingual entity extraction. We are also planning
an end-to-end evaluation, for instance, by employ-
ing the extracted bilingual product name into an
machine translation system.
</bodyText>
<sectionHeader confidence="0.982567" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999303235294118">
Nasreen AbdulJaleel and Leah S Larkey. 2003. Statis-
tical transliteration for english-arabic cross language
information retrieval. In Proceedings of the twelfth
international conference on Information and knowl-
edge management, pages 139–146. ACM.
Daniel Andrade, Tetsuya Nasukawa, and Jun’ichi Tsu-
jii. 2010. Robust measurement and comparison of
context similarity for finding translation pairs. In
Proceedings of the 23rd International Conference
on Computational Linguistics, pages 19–27. Asso-
ciation for Computational Linguistics.
Daniel Andrade, Takuya Matsuzaki, and Jun’ichi Tsu-
jii. 2011. Learning the optimal use of dependency-
parsing information for finding translations with
comparable corpora. In Proceedings of the 4th
Workshop on Building and Using Comparable Cor-
pora: Comparable Corpora and the Web, pages 10–
18. Association for Computational Linguistics.
Li Bo, Eric Gaussier, Akiko N Aizawa, et al. 2011.
Clustering comparable corpora for bilingual lexicon
extraction. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 473–478.
B´eatrice Daille and Emmanuel Morin. 2005. French-
english terminology extraction from comparable
corpora. In Natural Language Processing–IJCNLP
2005, pages 707–718. Springer.
Darja Fi&amp;quot;ser, &amp;quot;Spela Vintar, Nikola Ljube&amp;quot;si´c, and Sen-
ja Pollak. 2011. Building and using comparable
corpora for domain-specific bilingual lexicon extrac-
tion. In Proceedings of the 4th Workshop on Build-
ing and Using Comparable Corpora: Comparable
Corpora and the Web, pages 19–26. Association for
Computational Linguistics.
Pascale Fung and Kathleen McKeown. 1997. Finding
terminology translations from non-parallel corpora.
In Proceedings of the 5th Annual Workshop on Very
Large Corpora, pages 192–202.
Wei Gao, Kam-Fai Wong, and Wai Lam. 2005.
Phoneme-based transliteration of foreign names for
oov problem. In Natural Language Processing–
IJCNLP 2004, pages 110–119. Springer.
Zoubin Ghahramani and Katherine Heller. 2005.
Bayesian sets.
Yeye He and Dong Xin. 2011. Seisa: set expansion
by iterative similarity aggregation. In Proceedings
of the 20th international conference on World wide
web, pages 427–436. ACM.
Franz Josef Och and Hermann Ney. 2003. A systemat-
ic comparison of various statistical alignment mod-
els. Computational linguistics, 29(1):19–51.
</reference>
<page confidence="0.99851">
68
</page>
<bodyText confidence="0.725087">
workshop on Chinese language processing-Volume
17, pages 184–187. Association for Computational
Linguistics.
</bodyText>
<reference confidence="0.999524785714286">
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the 37th annual meeting
of the Association for Computational Linguistics on
Computational Linguistics, pages 519–526. Associ-
ation for Computational Linguistics.
Ellen Riloff. 1996. Automatically generating extrac-
tion patterns from untagged text. In Proceedings
of the national conference on artificial intelligence,
pages 1044–1049.
Partha Pratim Talukdar, Thorsten Brants, Mark Liber-
man, and Fernando Pereira. 2006. A context pattern
induction method for named entity extraction. In
Proceedings of the Tenth Conference on Computa-
tional Natural Language Learning, pages 141–148.
Association for Computational Linguistics.
Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.
2012. Bilingual lexicon extraction from compara-
ble corpora using label propagation. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 24–36. Associa-
tion for Computational Linguistics.
Michael Thelen and Ellen Riloff. 2002. A bootstrap-
ping method for learning semantic lexicons using
extraction pattern contexts. In Proceedings of the
ACL-02 conference on Empirical methods in natu-
ral language processing-Volume 10, pages 214–221.
Association for Computational Linguistics.
Paola Virga and Sanjeev Khudanpur. 2003. Transliter-
ation of proper names in cross-language application-
s. In Proceedings of the 26th annual international
ACM SIGIR conference on Research and develop-
ment in informaion retrieval, pages 365–366. ACM.
Ivan Vulic, Wim De Smet, Marie-Francine Moens, and
KU Leuven. 2011. Identifying word translations
from comparable corpora using latent topic models.
In Proceedings of ACL, pages 479–484.
Richard C Wang and William W Cohen. 2007.
Language-independent set expansion of named en-
tities using the web. In Data Mining,2007.ICDM
2007. Seventh IEEE International Conference on,
pages 342–350. IEEE.
Richard C Wang and William W Cohen. 2008. Itera-
tive set expansion of named entities using the web.
In Data Mining, 2008. ICDM’08. Eighth IEEE Inter-
national Conference on, pages 1091–1096. IEEE.
Richard C Wang and William W Cohen. 2009.
Character-level analysis of semi-structured docu-
ments for set expansion. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 3-Volume 3, pages 1503–
1512. Association for Computational Linguistics.
Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun
Liu. 2003. Hhmm-based chinese lexical analyz-
er ictclas. In Proceedings of the second SIGHAN
</reference>
<page confidence="0.999317">
69
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932968">
<title confidence="0.9950445">Bilingual Product Name Dictionary Construction Using a Two Stage Method</title>
<author confidence="0.996772">Yatian Shen</author>
<author confidence="0.996772">Xuanjing Huang</author>
<affiliation confidence="0.999853">School of Computer Science, Fudan University, Shanghai,</affiliation>
<email confidence="0.96716">shenyatian@gmail.com,xjhuang@fudan.edu.cn</email>
<abstract confidence="0.998998434782609">This paper proposes a novel two-stage method for bilingual product name dictionary construction from comparable corpora. In previous work, some researchers study the problem of expanding a set of given seed entities into a more complete set by discovering other entities that also belong to the same concept, it just solves the problem about expansion of entity set in a monolingual language, but the expansion of bilingual entity is really blank problem from comparable corpora. A typical exis to seed enand derive other in the same concept set of product name. We address this problem by utilizing a two-stage approach based on entity set expansion and bilingual entity alignment from comparable corpora. Evaluations using English and Chinese reviewer corpus verify that our method outperforms conventional methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nasreen AbdulJaleel</author>
<author>Leah S Larkey</author>
</authors>
<title>Statistical transliteration for english-arabic cross language information retrieval.</title>
<date>2003</date>
<booktitle>In Proceedings of the twelfth international conference on Information and knowledge management,</booktitle>
<pages>139--146</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15818" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="2567" endWordPosition="2570">ify equivalence relation in every entity corresponding to bilingual context. We assume that the same context appears around the same entity. Thus, our aim is to find translation pairs between Chinese and English corpora. Machine translation is commonly used to complete the task. By the tool of machine translation, two different language context of entity is mapped to the same language space. Many studies on machine translation use GIZA++ as their underlying word-by-word alignment system. Machine translation systems have also benefited from such alignment, performing it at the character level (AbdulJaleel and Larkey, 2003), (Virga and Khudanpur, 2003), (Gao et al., 2005). GIZA++ is a statistical machine translation toolkit freely available for research purposes. The extended version of this toolkit is called GIZA++ and was developed by (Och and Ney, 2003). We employ the word-based translation model to perform context alignment, we get the alignment probability between the context pattern 64 of two different entities. GIZA++ alignment system is trained on parallel corpora English and Chinese reviews, we manually annotate the context of bilingual entity pair on 3000 parallel sentence pairs about car domain review</context>
</contexts>
<marker>AbdulJaleel, Larkey, 2003</marker>
<rawString>Nasreen AbdulJaleel and Leah S Larkey. 2003. Statistical transliteration for english-arabic cross language information retrieval. In Proceedings of the twelfth international conference on Information and knowledge management, pages 139–146. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Andrade</author>
<author>Tetsuya Nasukawa</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Robust measurement and comparison of context similarity for finding translation pairs.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>pages</pages>
<contexts>
<context position="3380" citStr="Andrade et al., 2010" startWordPosition="532" endWordPosition="535">ase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages. Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity. while their researches aim to generate a general bilingual lexico</context>
<context position="8098" citStr="Andrade et al., 2010" startWordPosition="1293" endWordPosition="1296">matrix, which can be used to find translated pairs of words and terms from non-parallel corpora across language groups. (Daille and Morin, 2005) proposes a method of extracting bilingual lexicon composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and multiword terms by exploiting the term contexts. The alignment of words in translated texts are well established, this algorithm is used to identify word translations (Rapp, 1999). (Andrade et al., 2010) suggest a new method which selects a subset of words (pivot words) associated with a query and then matches these words across languages, a new Bayesian method for estimating Point-wise Mutual Information is used to detect word associations. (Fiˇser et al., 2011) presents a series of exper62 St Figure 1: Flow chart of our two-stage system. iments aimed at inducing and evaluating domainspecific bilingual lexicon from comparable corpora. (Vulic et al., 2011) investigate the algorithm of bilingual topic models, which finds translations of terms in comparable corpora by using knowledge from word-</context>
<context position="20957" citStr="Andrade et al., 2010" startWordPosition="3399" endWordPosition="3402">larity concept name (&amp;quot;Honda car&amp;quot; and &amp;quot;NeeA�4-&amp;quot;�A&amp;quot;). 6.3 Our Methods VS. State-of-art Methods To prove the effectiveness of our method, we select the following state-of-art methods as baseline for comparison. 1) Rapp is a typical context-similarity-based method (Rapp, 1999). Context words are words in a window (window size is 10) and are treated separately for each position. Associations with context words are computed using the log-likelihood ratio. The similarity measure between context vectors is the city-block metric. 2) Andrade is a sophisticated method in contextsimilarity-based methods (Andrade et al., 2010). Context is a set of words with a positive association in a window (window size is 10). The association is calculated using the PMI estimated by a Bayesian method, and a similarity between contexts is estimated based on the number of overlapping words. 3)Tamura proposes a method for lexicon extraction that extracts translation pairs from comparable corpora by using graph-based label propagation (Tamura et al., 2012). They utilize indirect relations with the bilingual seeds together with direct relations, in which each word is represented by a distribution of translated seeds. The seed distrib</context>
<context position="25134" citStr="Andrade et al., 2010" startWordPosition="4060" endWordPosition="4063">p’s method, Andrade’s method and Tamura’s method only build a general bilingual lexicon. 3) Our method construct context association by utilizing machine translation model between bilingual entity name. Machine translation model have the characteristic of accurate and interpretation, which favor our problems. Our test data, on the other hand, includes many low-frequency words. It is generally true that translation of highfrequency words is much easier than that of low frequency words. The accuracies of the baselines in Table 3 and 4 are worse than the previous reports: 14% Acc1 and 46% Acc10 (Andrade et al., 2010), and 72% Acc1 (Rapp, 1999). 4) Our methods expand entity name of the same semantic concept by using the bootstrapping algorithm, which is weak-supervised learning algorithm. The algorihtm need not labeled dateset to train model, meanwhile which is easier to implement it, it exceeds Tamura’s method,which only considers distribution of translated seeds, then each word is represented by seeds distribution. The seed distributions are propagated over a graph representing relations among words, but constructing a graph is consuming lot of forces, its effect is very low. 6.5 Effect of Seeds Size In </context>
</contexts>
<marker>Andrade, Nasukawa, Tsujii, 2010</marker>
<rawString>Daniel Andrade, Tetsuya Nasukawa, and Jun’ichi Tsujii. 2010. Robust measurement and comparison of context similarity for finding translation pairs. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 19–27. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Andrade</author>
<author>Takuya Matsuzaki</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Learning the optimal use of dependencyparsing information for finding translations with comparable corpora.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,</booktitle>
<pages>pages</pages>
<contexts>
<context position="3467" citStr="Andrade et al., 2011" startWordPosition="548" endWordPosition="552">in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages. Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity. while their researches aim to generate a general bilingual lexicons, our work is bilingual entity extraction of the same semantic category, these entiti</context>
<context position="8741" citStr="Andrade et al., 2011" startWordPosition="1396" endWordPosition="1399">which selects a subset of words (pivot words) associated with a query and then matches these words across languages, a new Bayesian method for estimating Point-wise Mutual Information is used to detect word associations. (Fiˇser et al., 2011) presents a series of exper62 St Figure 1: Flow chart of our two-stage system. iments aimed at inducing and evaluating domainspecific bilingual lexicon from comparable corpora. (Vulic et al., 2011) investigate the algorithm of bilingual topic models, which finds translations of terms in comparable corpora by using knowledge from word-topic distributions. (Andrade et al., 2011) propose to perform a linear transformation of the context vectors, the new word translations are found by context similarity. (Bo et al., 2011) introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and preserves most of the vocabulary of the original corpus. (Tamura et al., 2012) proposes a novel method for lexicon extraction that extracts translation pairs from comparable corpora by using graph- based label propagation. All the methods mentioned above may potentially extract entities translation pairs when context of en</context>
</contexts>
<marker>Andrade, Matsuzaki, Tsujii, 2011</marker>
<rawString>Daniel Andrade, Takuya Matsuzaki, and Jun’ichi Tsujii. 2011. Learning the optimal use of dependencyparsing information for finding translations with comparable corpora. In Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web, pages 10– 18. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Bo</author>
</authors>
<title>Eric Gaussier, Akiko</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>473--478</pages>
<marker>Bo, 2011</marker>
<rawString>Li Bo, Eric Gaussier, Akiko N Aizawa, et al. 2011. Clustering comparable corpora for bilingual lexicon extraction. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 473–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B´eatrice Daille</author>
<author>Emmanuel Morin</author>
</authors>
<title>Frenchenglish terminology extraction from comparable corpora.</title>
<date>2005</date>
<booktitle>In Natural Language Processing–IJCNLP</booktitle>
<pages>707--718</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3425" citStr="Daille and Morin, 2005" startWordPosition="540" endWordPosition="543">ized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages. Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity. while their researches aim to generate a general bilingual lexicons, our work is bilingual entity extraction o</context>
<context position="7621" citStr="Daille and Morin, 2005" startWordPosition="1218" endWordPosition="1221">s which indicate patterns in a bootstrapping manner. (Ghahramani and Heller, 2005) used the method of Bayesian inference to solve the problem of set expansion. In comparison, our approach expands bilingual entity seeds set by using bootstrapping algorithms ,which learn entity candidates and their corresponding patterns iteratively. Our goal is to find the same semantic concept set. (Fung and McKeown, 1997) present a statistical word feature that is said to the word relation matrix, which can be used to find translated pairs of words and terms from non-parallel corpora across language groups. (Daille and Morin, 2005) proposes a method of extracting bilingual lexicon composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and multiword terms by exploiting the term contexts. The alignment of words in translated texts are well established, this algorithm is used to identify word translations (Rapp, 1999). (Andrade et al., 2010) suggest a new method which selects a subset of words (pivot words) associated with a query and then matches these words ac</context>
</contexts>
<marker>Daille, Morin, 2005</marker>
<rawString>B´eatrice Daille and Emmanuel Morin. 2005. Frenchenglish terminology extraction from comparable corpora. In Natural Language Processing–IJCNLP 2005, pages 707–718. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darja Fiser</author>
<author>Spela Vintar</author>
<author>Nikola Ljubesi´c</author>
<author>Senja Pollak</author>
</authors>
<title>Building and using comparable corpora for domain-specific bilingual lexicon extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web,</booktitle>
<pages>pages</pages>
<marker>Fiser, Vintar, Ljubesi´c, Pollak, 2011</marker>
<rawString>Darja Fi&amp;quot;ser, &amp;quot;Spela Vintar, Nikola Ljube&amp;quot;si´c, and Senja Pollak. 2011. Building and using comparable corpora for domain-specific bilingual lexicon extraction. In Proceedings of the 4th Workshop on Building and Using Comparable Corpora: Comparable Corpora and the Web, pages 19–26. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Kathleen McKeown</author>
</authors>
<title>Finding terminology translations from non-parallel corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Annual Workshop on Very Large Corpora,</booktitle>
<pages>192--202</pages>
<contexts>
<context position="3346" citStr="Fung and McKeown, 1997" startWordPosition="525" endWordPosition="528">Cohen, 2009), which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages. Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity. while their researches aim to g</context>
<context position="7407" citStr="Fung and McKeown, 1997" startWordPosition="1180" endWordPosition="1183">blicly available. (He and Xin, 2011) expand seeds by iterative similarity aggregation. (Talukdar et al., 2006) studied the problem of set expansion of open text, which proposes to automatically identify triggerwords which indicate patterns in a bootstrapping manner. (Ghahramani and Heller, 2005) used the method of Bayesian inference to solve the problem of set expansion. In comparison, our approach expands bilingual entity seeds set by using bootstrapping algorithms ,which learn entity candidates and their corresponding patterns iteratively. Our goal is to find the same semantic concept set. (Fung and McKeown, 1997) present a statistical word feature that is said to the word relation matrix, which can be used to find translated pairs of words and terms from non-parallel corpora across language groups. (Daille and Morin, 2005) proposes a method of extracting bilingual lexicon composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and multiword terms by exploiting the term contexts. The alignment of words in translated texts are well established</context>
</contexts>
<marker>Fung, McKeown, 1997</marker>
<rawString>Pascale Fung and Kathleen McKeown. 1997. Finding terminology translations from non-parallel corpora. In Proceedings of the 5th Annual Workshop on Very Large Corpora, pages 192–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Gao</author>
<author>Kam-Fai Wong</author>
<author>Wai Lam</author>
</authors>
<title>Phoneme-based transliteration of foreign names for oov problem.</title>
<date>2005</date>
<booktitle>In Natural Language Processing– IJCNLP 2004,</booktitle>
<pages>110--119</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="15867" citStr="Gao et al., 2005" startWordPosition="2575" endWordPosition="2578">ingual context. We assume that the same context appears around the same entity. Thus, our aim is to find translation pairs between Chinese and English corpora. Machine translation is commonly used to complete the task. By the tool of machine translation, two different language context of entity is mapped to the same language space. Many studies on machine translation use GIZA++ as their underlying word-by-word alignment system. Machine translation systems have also benefited from such alignment, performing it at the character level (AbdulJaleel and Larkey, 2003), (Virga and Khudanpur, 2003), (Gao et al., 2005). GIZA++ is a statistical machine translation toolkit freely available for research purposes. The extended version of this toolkit is called GIZA++ and was developed by (Och and Ney, 2003). We employ the word-based translation model to perform context alignment, we get the alignment probability between the context pattern 64 of two different entities. GIZA++ alignment system is trained on parallel corpora English and Chinese reviews, we manually annotate the context of bilingual entity pair on 3000 parallel sentence pairs about car domain reviews. A probability table about the context of bilin</context>
</contexts>
<marker>Gao, Wong, Lam, 2005</marker>
<rawString>Wei Gao, Kam-Fai Wong, and Wai Lam. 2005. Phoneme-based transliteration of foreign names for oov problem. In Natural Language Processing– IJCNLP 2004, pages 110–119. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zoubin Ghahramani</author>
<author>Katherine Heller</author>
</authors>
<date>2005</date>
<note>Bayesian sets.</note>
<contexts>
<context position="7080" citStr="Ghahramani and Heller, 2005" startWordPosition="1129" endWordPosition="1132">eldom. 2 Related Work There is a significant body of related work in the broad space of information extraction and named entity extraction. We will only summarize work most relevant to set expansion and bilingual entity extraction due to the limit of space. Google sets does set expansion using propriety algorithms which are not publicly available. (He and Xin, 2011) expand seeds by iterative similarity aggregation. (Talukdar et al., 2006) studied the problem of set expansion of open text, which proposes to automatically identify triggerwords which indicate patterns in a bootstrapping manner. (Ghahramani and Heller, 2005) used the method of Bayesian inference to solve the problem of set expansion. In comparison, our approach expands bilingual entity seeds set by using bootstrapping algorithms ,which learn entity candidates and their corresponding patterns iteratively. Our goal is to find the same semantic concept set. (Fung and McKeown, 1997) present a statistical word feature that is said to the word relation matrix, which can be used to find translated pairs of words and terms from non-parallel corpora across language groups. (Daille and Morin, 2005) proposes a method of extracting bilingual lexicon composed</context>
</contexts>
<marker>Ghahramani, Heller, 2005</marker>
<rawString>Zoubin Ghahramani and Katherine Heller. 2005. Bayesian sets.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yeye He</author>
<author>Dong Xin</author>
</authors>
<title>Seisa: set expansion by iterative similarity aggregation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th international conference on World wide web,</booktitle>
<pages>427--436</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3115" citStr="He and Xin, 2011" startWordPosition="486" endWordPosition="489"> small number of seed words given for the target domain. Google Sets is a well-known example of a web-based set expansion system. Another prominent work is the SEAL system (Wang and Cohen, 2007; Wang and Cohen, 2008; Wang and Cohen, 2009), which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend</context>
<context position="6820" citStr="He and Xin, 2011" startWordPosition="1090" endWordPosition="1093">f semantic category by giving some bilingual seed set but also find entity translation pairs from comparable corpora. 3) we construct a dictionary of the bilingual product name from comparable corpora, which do not need fully parallel data that is seldom. 2 Related Work There is a significant body of related work in the broad space of information extraction and named entity extraction. We will only summarize work most relevant to set expansion and bilingual entity extraction due to the limit of space. Google sets does set expansion using propriety algorithms which are not publicly available. (He and Xin, 2011) expand seeds by iterative similarity aggregation. (Talukdar et al., 2006) studied the problem of set expansion of open text, which proposes to automatically identify triggerwords which indicate patterns in a bootstrapping manner. (Ghahramani and Heller, 2005) used the method of Bayesian inference to solve the problem of set expansion. In comparison, our approach expands bilingual entity seeds set by using bootstrapping algorithms ,which learn entity candidates and their corresponding patterns iteratively. Our goal is to find the same semantic concept set. (Fung and McKeown, 1997) present a st</context>
</contexts>
<marker>He, Xin, 2011</marker>
<rawString>Yeye He and Dong Xin. 2011. Seisa: set expansion by iterative similarity aggregation. In Proceedings of the 20th international conference on World wide web, pages 427–436. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="16055" citStr="Och and Ney, 2003" startWordPosition="2606" endWordPosition="2609">only used to complete the task. By the tool of machine translation, two different language context of entity is mapped to the same language space. Many studies on machine translation use GIZA++ as their underlying word-by-word alignment system. Machine translation systems have also benefited from such alignment, performing it at the character level (AbdulJaleel and Larkey, 2003), (Virga and Khudanpur, 2003), (Gao et al., 2005). GIZA++ is a statistical machine translation toolkit freely available for research purposes. The extended version of this toolkit is called GIZA++ and was developed by (Och and Ney, 2003). We employ the word-based translation model to perform context alignment, we get the alignment probability between the context pattern 64 of two different entities. GIZA++ alignment system is trained on parallel corpora English and Chinese reviews, we manually annotate the context of bilingual entity pair on 3000 parallel sentence pairs about car domain reviews. A probability table about the context of bilingual entity pair is generated by training GIZA++ model. 5.3 Entity Translation Extraction In order to find entity translation pairs in different languages, we use statistical machine trans</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics,</booktitle>
<pages>519--526</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3358" citStr="Rapp, 1999" startWordPosition="529" endWordPosition="531">tes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McKeown, 1997; Rapp, 1999; Andrade et al., 2010; Fiˇser et al., 2011; Daille and Morin, 2005; Vulic et al., 2011; Andrade et al., 2011; Bo et al., 2011). Most of the 61 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 61–69, Wuhan, China, 20-21 October 2014 previous methods are based on the assumption that a word and its translation tend to appear in similar contexts across languages. Based on this assumption, many methods calculate word similarity using context and then extract word translation pairs with a high context similarity. while their researches aim to generate a ge</context>
<context position="5414" citStr="Rapp, 1999" startWordPosition="861" endWordPosition="862">ll replace word ”product name” with ”entity” each other. Following the common practice, our system proceeds in two stages, which first expands the entity set for the semantic category by giving some bilingual set pairs and then finds bilingual product name translation pair from comparable corpora. Semantic category set expansion is carried out through the bootstrapping algorithm. In this stage ,our goal is to discover relevant entities by giving some entity seed set. In the second stage, we use this assumption that a word and its translation tend to appear in similar context across languages (Rapp, 1999). Our method calculates entity similarity using context and then extract entity translation pairs with a high context similarity. We call this method as context-similarity-based methods. The context similarity is usually computed using machine translation model by mapping contexts expressed in two different languages into the same language space. In the mapping process, information not represented by the seed lexicon is discarded. The main contributions of this paper are as follows: 1) we propose a bilingual product name extraction method that can get the set of semantic category by bootstrapp</context>
<context position="8074" citStr="Rapp, 1999" startWordPosition="1291" endWordPosition="1292">word relation matrix, which can be used to find translated pairs of words and terms from non-parallel corpora across language groups. (Daille and Morin, 2005) proposes a method of extracting bilingual lexicon composed of single-word terms (SWTs) and multi-word terms (MWTs) from comparable corpora of a technical domain. First, this method extracts MWTs in each language, and then uses statistical methods to align single words and multiword terms by exploiting the term contexts. The alignment of words in translated texts are well established, this algorithm is used to identify word translations (Rapp, 1999). (Andrade et al., 2010) suggest a new method which selects a subset of words (pivot words) associated with a query and then matches these words across languages, a new Bayesian method for estimating Point-wise Mutual Information is used to detect word associations. (Fiˇser et al., 2011) presents a series of exper62 St Figure 1: Flow chart of our two-stage system. iments aimed at inducing and evaluating domainspecific bilingual lexicon from comparable corpora. (Vulic et al., 2011) investigate the algorithm of bilingual topic models, which finds translations of terms in comparable corpora by us</context>
<context position="20609" citStr="Rapp, 1999" startWordPosition="3348" endWordPosition="3349">expanded from the input seeds. From Table 2, we can see that in the top20 ranked results, the/Camera0domain have high precision. /Camera0domain has only two incorrect result, the top-20 results for/Car0domain, however, includes some noisy entities that are incorrect, such as product workshop names (/ and /Audi compa65 ny&amp;quot;), and the similarity concept name (&amp;quot;Honda car&amp;quot; and &amp;quot;NeeA�4-&amp;quot;�A&amp;quot;). 6.3 Our Methods VS. State-of-art Methods To prove the effectiveness of our method, we select the following state-of-art methods as baseline for comparison. 1) Rapp is a typical context-similarity-based method (Rapp, 1999). Context words are words in a window (window size is 10) and are treated separately for each position. Associations with context words are computed using the log-likelihood ratio. The similarity measure between context vectors is the city-block metric. 2) Andrade is a sophisticated method in contextsimilarity-based methods (Andrade et al., 2010). Context is a set of words with a positive association in a window (window size is 10). The association is calculated using the PMI estimated by a Bayesian method, and a similarity between contexts is estimated based on the number of overlapping words</context>
<context position="25161" citStr="Rapp, 1999" startWordPosition="4067" endWordPosition="4068">ra’s method only build a general bilingual lexicon. 3) Our method construct context association by utilizing machine translation model between bilingual entity name. Machine translation model have the characteristic of accurate and interpretation, which favor our problems. Our test data, on the other hand, includes many low-frequency words. It is generally true that translation of highfrequency words is much easier than that of low frequency words. The accuracies of the baselines in Table 3 and 4 are worse than the previous reports: 14% Acc1 and 46% Acc10 (Andrade et al., 2010), and 72% Acc1 (Rapp, 1999). 4) Our methods expand entity name of the same semantic concept by using the bootstrapping algorithm, which is weak-supervised learning algorithm. The algorihtm need not labeled dateset to train model, meanwhile which is easier to implement it, it exceeds Tamura’s method,which only considers distribution of translated seeds, then each word is represented by seeds distribution. The seed distributions are propagated over a graph representing relations among words, but constructing a graph is consuming lot of forces, its effect is very low. 6.5 Effect of Seeds Size In this subsection, we aim to </context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, pages 519–526. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically generating extraction patterns from untagged text.</title>
<date>1996</date>
<booktitle>In Proceedings of the national conference on artificial intelligence,</booktitle>
<pages>1044--1049</pages>
<contexts>
<context position="11631" citStr="Riloff, 1996" startWordPosition="1862" endWordPosition="1863">tic lexicons must contain only names that are unambiguously. We hence remove ambiguous names or phrases that belong to multiple entity types from the dataset, and only choose those entities as entity seed that it owns definite semantic. We used a weakly supervised bootstrapping algorithm that automatically generates semantic lexicons (Thelen and Riloff, 2002). Bootstrapping algorithms hypothesizes the semantic class of entity by gathering collective evidence about semantic associations from extraction pattern context. For our representation of extraction patterns, we used the AutoSlog system (Riloff, 1996), AutoSlog’s extraction patterns represent linguistic expressions that extract a noun phrase in one of three syntactic roles: subject, direct object, or prepositional phrase object. Before bootstrapping begins, we run AutoSlog exhaustively over the corpus to generate an extraction pattern for every noun phrase that appears. In these, noun or noun phrase are entities, we will Bili and Entit sam Boo al 63 possibly extract them as production name. The patterns are then applied to the corpora and all of theirs extracted noun phrases are recorded. For every iteration, the top 20 extraction patterns</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically generating extraction patterns from untagged text. In Proceedings of the national conference on artificial intelligence, pages 1044–1049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Thorsten Brants</author>
<author>Mark Liberman</author>
<author>Fernando Pereira</author>
</authors>
<title>A context pattern induction method for named entity extraction.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>141--148</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6894" citStr="Talukdar et al., 2006" startWordPosition="1101" endWordPosition="1104">ntity translation pairs from comparable corpora. 3) we construct a dictionary of the bilingual product name from comparable corpora, which do not need fully parallel data that is seldom. 2 Related Work There is a significant body of related work in the broad space of information extraction and named entity extraction. We will only summarize work most relevant to set expansion and bilingual entity extraction due to the limit of space. Google sets does set expansion using propriety algorithms which are not publicly available. (He and Xin, 2011) expand seeds by iterative similarity aggregation. (Talukdar et al., 2006) studied the problem of set expansion of open text, which proposes to automatically identify triggerwords which indicate patterns in a bootstrapping manner. (Ghahramani and Heller, 2005) used the method of Bayesian inference to solve the problem of set expansion. In comparison, our approach expands bilingual entity seeds set by using bootstrapping algorithms ,which learn entity candidates and their corresponding patterns iteratively. Our goal is to find the same semantic concept set. (Fung and McKeown, 1997) present a statistical word feature that is said to the word relation matrix, which can</context>
</contexts>
<marker>Talukdar, Brants, Liberman, Pereira, 2006</marker>
<rawString>Partha Pratim Talukdar, Thorsten Brants, Mark Liberman, and Fernando Pereira. 2006. A context pattern induction method for named entity extraction. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 141–148. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora using label propagation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>24--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9095" citStr="Tamura et al., 2012" startWordPosition="1453" endWordPosition="1456">ating domainspecific bilingual lexicon from comparable corpora. (Vulic et al., 2011) investigate the algorithm of bilingual topic models, which finds translations of terms in comparable corpora by using knowledge from word-topic distributions. (Andrade et al., 2011) propose to perform a linear transformation of the context vectors, the new word translations are found by context similarity. (Bo et al., 2011) introduce a clustering-based approach for enhancing corpus comparability which exploits the homogeneity feature of the corpus, and preserves most of the vocabulary of the original corpus. (Tamura et al., 2012) proposes a novel method for lexicon extraction that extracts translation pairs from comparable corpora by using graph- based label propagation. All the methods mentioned above may potentially extract entities translation pairs when context of entities are similarity. We are also based on this assumption, but we are different from the previous models where we use machine translation model to map the context of entity to the same language space, which can improve performance and illustrate robustness. 3 Proposed Method Figure 1 illustrates the framework of our proposed methods. The proposed met</context>
<context position="21377" citStr="Tamura et al., 2012" startWordPosition="3472" endWordPosition="3475"> using the log-likelihood ratio. The similarity measure between context vectors is the city-block metric. 2) Andrade is a sophisticated method in contextsimilarity-based methods (Andrade et al., 2010). Context is a set of words with a positive association in a window (window size is 10). The association is calculated using the PMI estimated by a Bayesian method, and a similarity between contexts is estimated based on the number of overlapping words. 3)Tamura proposes a method for lexicon extraction that extracts translation pairs from comparable corpora by using graph-based label propagation (Tamura et al., 2012). They utilize indirect relations with the bilingual seeds together with direct relations, in which each word is represented by a distribution of translated seeds. The seed distributions are propagated over a graph representing relations among words, and translation pairs are extracted by identifying word pairs with a high similarity in the seed distributions. Camera Car Ailh--audi �ê-BMW M-Bulk NeeA-Ford NeeWTT-Focus *X-Honda ��i k-Mazda ´X-Toyota ZÒ-Nissan 4X17W-Toyota Crown textbfg &apos;ITC-Volvo )�A-Volkswagen i k6-Mazda6 H$JAS-Honda JV¶-Benz *X K-Honda wjPWTT-Lexus �JPLR-Hyundai Ïf-GM TcA-</context>
</contexts>
<marker>Tamura, Watanabe, Sumita, 2012</marker>
<rawString>Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita. 2012. Bilingual lexicon extraction from comparable corpora using label propagation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 24–36. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>214--221</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11379" citStr="Thelen and Riloff, 2002" startWordPosition="1824" endWordPosition="1827">problem of how to grow the seed dictionary and discovering new product names from user reviews. In this section, we use the seed entity to automatically generate semantic lexicons. For the specific case of brand discovery, this initial list used to generate semantic lexicons must contain only names that are unambiguously. We hence remove ambiguous names or phrases that belong to multiple entity types from the dataset, and only choose those entities as entity seed that it owns definite semantic. We used a weakly supervised bootstrapping algorithm that automatically generates semantic lexicons (Thelen and Riloff, 2002). Bootstrapping algorithms hypothesizes the semantic class of entity by gathering collective evidence about semantic associations from extraction pattern context. For our representation of extraction patterns, we used the AutoSlog system (Riloff, 1996), AutoSlog’s extraction patterns represent linguistic expressions that extract a noun phrase in one of three syntactic roles: subject, direct object, or prepositional phrase object. Before bootstrapping begins, we run AutoSlog exhaustively over the corpus to generate an extraction pattern for every noun phrase that appears. In these, noun or noun</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 214–221. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-language applications.</title>
<date>2003</date>
<booktitle>In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval,</booktitle>
<pages>365--366</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15847" citStr="Virga and Khudanpur, 2003" startWordPosition="2571" endWordPosition="2574">y entity corresponding to bilingual context. We assume that the same context appears around the same entity. Thus, our aim is to find translation pairs between Chinese and English corpora. Machine translation is commonly used to complete the task. By the tool of machine translation, two different language context of entity is mapped to the same language space. Many studies on machine translation use GIZA++ as their underlying word-by-word alignment system. Machine translation systems have also benefited from such alignment, performing it at the character level (AbdulJaleel and Larkey, 2003), (Virga and Khudanpur, 2003), (Gao et al., 2005). GIZA++ is a statistical machine translation toolkit freely available for research purposes. The extended version of this toolkit is called GIZA++ and was developed by (Och and Ney, 2003). We employ the word-based translation model to perform context alignment, we get the alignment probability between the context pattern 64 of two different entities. GIZA++ alignment system is trained on parallel corpora English and Chinese reviews, we manually annotate the context of bilingual entity pair on 3000 parallel sentence pairs about car domain reviews. A probability table about </context>
</contexts>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-language applications. In Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, pages 365–366. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vulic</author>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
<author>KU Leuven</author>
</authors>
<title>Identifying word translations from comparable corpora using latent topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>479--484</pages>
<marker>Vulic, De Smet, Moens, Leuven, 2011</marker>
<rawString>Ivan Vulic, Wim De Smet, Marie-Francine Moens, and KU Leuven. 2011. Identifying word translations from comparable corpora using latent topic models. In Proceedings of ACL, pages 479–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Language-independent set expansion of named entities using the web.</title>
<date>2007</date>
<booktitle>In Data Mining,2007.ICDM 2007. Seventh IEEE International Conference on,</booktitle>
<pages>342--350</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2691" citStr="Wang and Cohen, 2007" startWordPosition="414" endWordPosition="417"> conceptually entities by extending semantic classes. Then, the bilingual entity translation pairs are extracted from comparable corpora. Traditional bilingual lexicon extraction approaches can only find entity translation pairs from comparable corpora, but not expand semantic set. Set expansion systems provide us a useful solution to the above problem because they create a more perfect set of name entities by expanding the small number of seed words given for the target domain. Google Sets is a well-known example of a web-based set expansion system. Another prominent work is the SEAL system (Wang and Cohen, 2007; Wang and Cohen, 2008; Wang and Cohen, 2009), which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is t</context>
</contexts>
<marker>Wang, Cohen, 2007</marker>
<rawString>Richard C Wang and William W Cohen. 2007. Language-independent set expansion of named entities using the web. In Data Mining,2007.ICDM 2007. Seventh IEEE International Conference on, pages 342–350. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Iterative set expansion of named entities using the web.</title>
<date>2008</date>
<booktitle>In Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on,</booktitle>
<pages>1091--1096</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="2713" citStr="Wang and Cohen, 2008" startWordPosition="418" endWordPosition="421"> by extending semantic classes. Then, the bilingual entity translation pairs are extracted from comparable corpora. Traditional bilingual lexicon extraction approaches can only find entity translation pairs from comparable corpora, but not expand semantic set. Set expansion systems provide us a useful solution to the above problem because they create a more perfect set of name entities by expanding the small number of seed words given for the target domain. Google Sets is a well-known example of a web-based set expansion system. Another prominent work is the SEAL system (Wang and Cohen, 2007; Wang and Cohen, 2008; Wang and Cohen, 2009), which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon e</context>
</contexts>
<marker>Wang, Cohen, 2008</marker>
<rawString>Richard C Wang and William W Cohen. 2008. Iterative set expansion of named entities using the web. In Data Mining, 2008. ICDM’08. Eighth IEEE International Conference on, pages 1091–1096. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard C Wang</author>
<author>William W Cohen</author>
</authors>
<title>Character-level analysis of semi-structured documents for set expansion.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>3</volume>
<pages>1503--1512</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2736" citStr="Wang and Cohen, 2009" startWordPosition="422" endWordPosition="425"> classes. Then, the bilingual entity translation pairs are extracted from comparable corpora. Traditional bilingual lexicon extraction approaches can only find entity translation pairs from comparable corpora, but not expand semantic set. Set expansion systems provide us a useful solution to the above problem because they create a more perfect set of name entities by expanding the small number of seed words given for the target domain. Google Sets is a well-known example of a web-based set expansion system. Another prominent work is the SEAL system (Wang and Cohen, 2007; Wang and Cohen, 2008; Wang and Cohen, 2009), which adoptes a two-phase strategy, where they first build customized text wrappers based on the input seeds in order to exact candidate entities from web pages. Then a graph-based random walk approach is used to rank candidate entities based on their closeness to the seeds on the graph. The third method is set expansion by iterative similarity aggregation (He and Xin, 2011), in which a set of given seed entities is expanded into a more complete set. All these methods are entity expansion from monolingual data sources. Another meaningful work is the bilingual lexicon extraction (Fung and McK</context>
</contexts>
<marker>Wang, Cohen, 2009</marker>
<rawString>Richard C Wang and William W Cohen. 2009. Character-level analysis of semi-structured documents for set expansion. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 3-Volume 3, pages 1503– 1512. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua-Ping Zhang</author>
<author>Hong-Kui Yu</author>
<author>De-Yi Xiong</author>
<author>Qun Liu</author>
</authors>
<title>Hhmm-based chinese lexical analyzer ictclas.</title>
<date>2003</date>
<booktitle>In Proceedings of the second SIGHAN</booktitle>
<contexts>
<context position="18105" citStr="Zhang et al., 2003" startWordPosition="2937" endWordPosition="2940">h are collected from www.buzzilions.com and www.carreview.com. For the source language of Chinese, the product dataset contains 8432 reviews which are collected from www.Amazon.cn and www.xche.com.cn. For our experiment,we use a Oxford English-Chinese bilingual dictionary to match similarity semantic reviewer sentence, any two of them are used as comparable corpus,the copora are non-parallel, but loosely compara in term of its content. Though the scale of Chinese corpora is large, most of the reviews are short texts and there are a lot noise in the content. For Chinese, we use the ICTLAS 3.0 (Zhang et al., 2003) toolkit to conduct word segmentation over sentences. To evaluate the effectiveness of our algorithms, we select two semantic entity sets in camera domain and car domain as seeds, where set expansion experiments are conducted . We select these two categories because (1) they are from different domains; and (2) they have different degree of difficulty for finding entity translation pairs. Language Domain #Sentence #Reviews Chinese Camera 2480862 1566 Car 3526109 2103 English Camera 1090862 4506 Car 2563120 5036 Table 1: Statistics on English corpus about Camera and Car domain. # denotes the siz</context>
</contexts>
<marker>Zhang, Yu, Xiong, Liu, 2003</marker>
<rawString>Hua-Ping Zhang, Hong-Kui Yu, De-Yi Xiong, and Qun Liu. 2003. Hhmm-based chinese lexical analyzer ictclas. In Proceedings of the second SIGHAN</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>