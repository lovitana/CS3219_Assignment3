<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000291">
<title confidence="0.99924">
Post-hoc Manipulations of Vector Space Models
with Application to Semantic Role Labeling
</title>
<author confidence="0.998253">
Jenna Kanerva and Filip Ginter
</author>
<affiliation confidence="0.998659">
Department of Information Technology
University of Turku, Finland
</affiliation>
<email confidence="0.996386">
jmnybl@utu.fi,figint@utu.fi
</email>
<sectionHeader confidence="0.997359" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935333333333">
In this paper, we introduce several vector
space manipulation methods that are ap-
plied to trained vector space models in a
post-hoc fashion, and present an applica-
tion of these techniques in semantic role
labeling for Finnish and English. Specifi-
cally, we show that the vectors can be cir-
cularly shifted to encode syntactic infor-
mation and subsequently averaged to pro-
duce representations of predicate senses
and arguments. Further, we show that it is
possible to effectively learn a linear trans-
formation between the vector representa-
tions of predicates and their arguments,
within the same vector space.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999920222222223">
Recently, there has been much progress in the de-
velopment of highly scalable methods for induc-
ing vector space representations of language. In
particular, the word2vec method (Mikolov et al.,
2013b) is capable of training on billions of tokens
in a matter of hours, producing high quality rep-
resentations. An exciting property exhibited by
the vector spaces induced using word2vec is that
they preserve a number of linguistic regularities,
lending themselves to simple algebraic operations
with the vectors (Mikolov et al., 2013c) and linear
mapping between different spaces (Mikolov et al.,
2013a). These can be seen as post-hoc operations
manipulating the vector space with the significant
advantage of not requiring a new task-specific rep-
resentation to be induced, as is customary.
In this paper, we will investigate several addi-
tional such methods. Firstly, we will show how
syntax information can be encoded by the circular
shift operation and demonstrate that such shifted
vectors can be averaged in a meaningful manner to
represent predicate arguments. And secondly, we
will show that linear transformations of the vec-
tor spaces can be successfully applied also within
a single vector space, to tasks such as transform-
ing the vector of a predicate into the vector of its
argument with a particular role.
To test the above-mentioned operations in an
extrinsic setting, we will develop these methods
within the context of the Semantic Role Label-
ing (SRL) task. Automatic Semantic Role Label-
ing is the process of identifying the semantic ar-
guments of predicates, and assigning them labels
describing their roles. A predicate and its argu-
ments form a predicate-argument structure, which
describes events such as who does what to whom,
when and where.
The SRL task is “semantic” in its nature and
therefore suitable for the application and testing
of vector space representations and methods for
their manipulation. However, rather than merely
adding features derived from vector spaces into
an existing system, we will approach the develop-
ment from a different angle and test whether these
representations of words and the similarities they
induce can be used for predicate argument role as-
signment and predicate sense disambiguation as
the primary source of information, with little ad-
ditional features.
In addition to the standard English CoNLL’09
dataset, we will apply the methods also to Finnish
SRL, testing the applicability of word2vec and the
overall methodology that we will develop in this
paper to this highly inflective language. With its
considerably larger and sparser surface form lex-
icon, Finnish poses interesting challenges of its
own, and only little attention has been dedicated
to the application of distributional semantics meth-
ods specifically to Finnish. This is also partly due
to the lack of sufficiently sized corpora, which we
address in this work by using a 1.5B token corpus
of Internet Finnish.
In order to be able to test the proposed meth-
</bodyText>
<page confidence="0.822237">
1
</page>
<note confidence="0.9962885">
Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) @ EACL 2014, pages 1–10,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.924887166666667">
punct&gt;
&lt;nsubj:A0
conj&gt;
cc&gt;
&lt;nsubj:A0 dobj:A1&gt; &lt;advmod:AM-TMP dobj:A1&gt;
He ate.01 lunch and then washed.01 dishes .
</figure>
<figureCaption confidence="0.937735">
Figure 1: Extended Stanford Dependencies
scheme combined with PropBank annotation.
sense combinations. The English CoNLL data is
derived from the PropBank and NomBank corpora
(Palmer et al., 2005; Meyers et al., 2004) and it has
</figureCaption>
<bodyText confidence="0.96211752">
a total of 54 different argument roles. In addition
to the same 22 roles as Finnish, English also has
discontinuous variants for each role. The English
data has 958,024 training tokens with 178,988 oc-
currences of 15,880 unique predicate-sense com-
binations.
All Finnish results are reported on the test sub-
set of the Finnish PropBank, and have no previ-
ously published baseline to compare with. The
results we report for English are produced on the
official test section of the CoNLL’09 data and are
thus directly comparable to the official results re-
ported in the Shared Task.
In the test phase, we follow the Shared Task set-
ting whereby morphological and syntactic analy-
sis is predicted as well, i.e., no gold standard data
enters the system other than the tokenization and
the information of which tokens constitute predi-
cates. We produce the Finnish morphological and
syntactic analyses for the test set with the parsing
pipeline of Haverinen et al. (2013b), composed of
a morphological analyzer and tagger (Hal´acsy et
al., 2007; Pirinen, 2008; Lind´en et al., 2009), de-
pendency parser (Bohnet, 2010) and a machine-
learning based component for predicting the ex-
tended SD dependencies (Nyblom et al., 2013).
While the English data is provided with automati-
cally produced dependency parses, we are specifi-
cally interested in the SD scheme and therefore we
re-parse the corpus with the Stanford parser2 tak-
ing a union of the base and collapsed dependency
outputs to match the Finnish data.
The vector space models used throughout this
paper are induced using the word2vec software
(skip-gram architecture with default parameters).
For Finnish, the model is trained on 1.5 billion to-
kens of Finnish Internet texts gathered from the
Common Crawl dataset.3 The data was sentence-
ods on SRL, we need to carry out not only role
labeling and predicate sense disambiguation, but
also argument detection. As a secondary theme,
we thus test whether dependency parse graphs in
the semantically motivated Stanford Dependen-
cies (SD) scheme can be used as-is to perform ar-
gument identification. We are especially interested
in this scheme as it is designed to capture seman-
tically contentful relations (de Marneffe and Man-
ning, 2008) and would thus appear to be the ideal
choice as the underlying syntactic representation
for SRL.
</bodyText>
<sectionHeader confidence="0.94317" genericHeader="introduction">
2 Data and Task Setting
</sectionHeader>
<bodyText confidence="0.9997614">
Throughout the paper, we will use the exact same
task setting as in the CoNLL’09 Shared Task on
Syntactic and Semantic Dependencies in Multiple
Languages (Hajiˇc et al., 2009). The input of the
SRL system are automatically generated syntactic
parses and the list of predicate tokens to be con-
sidered in each sentence. For each of the predi-
cates, the SRL system is expected to predict the
sense of the predicate, identify all tokens which
are its arguments, and for each argument, iden-
tify its role. As the primary measure of perfor-
mance, we will use the semantic F-score defined
in the CoNLL shared task. This F-score is cal-
culated from the precision and recall of argument
identification (calculated in the obvious manner)
and also incorporates the sense of the predicate via
an additional “dummy” argument. We use the of-
ficial implementation of the metric distributed on
the Shared Task site.1
We will report our results on two SRL datasets:
the Finnish PropBank (Haverinen et al., 2013a)
and the English SRL dataset from the CoNLL’09
Shared Task. The Finnish PropBank is built on
top of the Turku Dependency Treebank (TDT), a
205K token corpus of general Finnish (Haverinen
et al., 2013b) annotated using the SD scheme, in-
cluding manually annotated conjunct propagation
and other dependency relations from the non-basic
layer of the scheme. These extended SD analyzes
are thus not strictly trees, rather they are directed
labeled graphs (see Figure 1). The Finnish Prop-
Bank has 22 different argument roles of which 7
are numbered core roles and 15 are modifier roles.
The Finnish data has 164,530 training tokens with
27,603 occurrences of 2,826 unique predicate-
</bodyText>
<footnote confidence="0.99957325">
1http://ufal.mff.cuni.cz/conll2009-st/
scorer.html
2Version 3.3.1, October 2013
3http://commoncrawl.org/
</footnote>
<page confidence="0.995989">
2
</page>
<bodyText confidence="0.999968857142857">
split and tokenized using the OpenNLP4 toolchain
trained on TDT, and processed in the same man-
ner as the above-mentioned test set. This gives us
the opportunity to build two models, one for the
word forms and the other for the lemmas. Both
Finnish models have 300 dimensions. For En-
glish, the vector representation is induced on the
union of the English Wikipedia (1.7B tokens) and
the English Gigaword corpus (4B tokens), the to-
tal training data size thus being 5.7 billion tokens.5
Sentence splitting and tokenization was carried out
using the relevant modules from the BRAT pack-
age (Stenetorp et al., 2012).6 The English model
has 200 dimensions.
</bodyText>
<sectionHeader confidence="0.991848" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.9992102">
In this section, we will describe the methods de-
veloped for argument identification, argument role
labeling and predicate sense disambiguation, the
three steps that must be implemented to obtain a
full SRL system.
</bodyText>
<subsectionHeader confidence="0.999324">
3.1 Argument identification
</subsectionHeader>
<bodyText confidence="0.999987541666667">
In a semantically-oriented dependency scheme,
such as SD, it can be expected that a notable
proportion of arguments (in the SRL sense) are
directly attached to the predicate, and argument
identification can be reduced to assuming that —
with a limited number of systematic exceptions —
every argument is a dependent of the predicate.
The most frequent case where the assumption does
not hold in Finnish are the copula verbs, which are
not analyzed as heads in the SD scheme. For En-
glish, a common case are the auxiliaries, which
govern the main verb in the CoNLL data and are
thus marked as arguments for other higher-level
predicates as well. In the SD scheme, on the other
hand, the main verb governs the auxiliary taking
also its place in the syntactic tree. Since the fo-
cus of this paper lies in role assignment, we do
not go beyond developing a simple rule set to deal
with a limited number of such cases. In Section 6,
we will contrast this simple argument identifica-
tion method to that of the winning CoNLL’09 sys-
tem and we will show that while for Finnish the
above holds surprisingly well, the performance on
the English data is clearly sub-optimal.
</bodyText>
<footnote confidence="0.997087">
4http://opennlp.apache.org/
5We are thankful to Sampo Pyysalo for providing us with
the English word2vec model.
6http://brat.nlplab.org
</footnote>
<figure confidence="0.614032285714286">
Finnish
eat + A1 AM-TMP
salted fish not until
eggs now
wheat bread again
nuts when
pickled cucumbers then
English
drive + A1 drive + AM-TMP
car immediately
truck morning
cars now
vehicle afternoon
tires finally
</figure>
<tableCaption confidence="0.835518">
Table 1: Five most similar words for the given
</tableCaption>
<bodyText confidence="0.72885275">
average argument vectors. AM-TMP refers to the
temporal modifier role. Note that the average vec-
tors for Finnish modifier roles are estimated inde-
pendently from the predicates (see Section 3.4).
</bodyText>
<subsectionHeader confidence="0.998308">
3.2 Role Classification
</subsectionHeader>
<bodyText confidence="0.999989">
Our initial role classification algorithm is based on
calculating the vector representation of an “aver-
age argument” with a given role. For every predi-
cate x and every role r, we calculate the represen-
tation of the average argument with the role as
</bodyText>
<equation confidence="0.987865333333333">
�(r,x,y) yˆ
A(x, r) = (1)
count ,
</equation>
<bodyText confidence="0.99311615">
where yˆ refers to the L2 normalized version of y,
and count to the number of training pairs that are
summed over. We are thus averaging the normal-
ized vectors of all words y seen in the training data
as an argument of the predicate x with the role r.
To establish the role for some argument y during
testing, we can simply choose the role whose av-
erage argument vector has the maximal similarity
to y, i.e.
arg max sim(A(x, r), y), (2)
r
where sim(a, b) is the standard cosine similarity.
To gain an intuitive insight into whether the av-
erage argument vectors behave as expected, we
show in Table 1 the top five most similar words
to the average argument vectors for several roles
and predicates. When evaluated with the data sets
described in Section 2, this initial method leads to
61.32% semantic F-score for Finnish and 65.05%
for English.
</bodyText>
<page confidence="0.986947">
3
</page>
<subsectionHeader confidence="0.998456">
3.3 Incorporating syntax
</subsectionHeader>
<bodyText confidence="0.998632923076923">
As we will demonstrate shortly, incorporating in-
formation about dependency relations can lead to
a substantial performance gain. To incorporate the
dependency relation information into the role clas-
sification method introduced above, we apply the
technique of circular shifting of vectors. This tech-
nique was previously used in the context of Ran-
dom Indexing (RI) to derive new vectors from ex-
isting ones in a deterministic fashion (Basile and
Caputo, 2012). In RI, the shift operation is how-
ever not used on the final vectors, but rather al-
ready during the induction of the vector represen-
tation.
Given a vector representation of an argument y,
we can encode the dependency relation of y and
its predicate by circularly shifting the vector of
y by an offset assigned separately to each possi-
ble dependency relation. The assignment is arbi-
trary, but such that no two relations are assigned
the same offset. We will denote this operation as
y»d, meaning the vector y circularly shifted to
the right by the offset assigned to the dependency
relation d. For instance, circularly shifting a vec-
tor a = (1, 2, 3, 4, 5) to the right by an offset of 2
results in a»2 = (4, 5, 1, 2, 3).
We can incorporate the dependency relations
when calculating the average vectors representing
arguments as follows:
where (r, d, x, y) iterates over all predicate-
argument pairs (x, y) where y has the dependency
relation d and role r. The role of an argument in
the test phase is established as before, by taking
the role which maximizes the similarity to the av-
erage vector:
arg max sim(A(x, r), y»d) (4)
r
In the cases, where arguments are not direct de-
pendents of the predicate, we use zero as the shift
offset.
To motivate this approach and illustrate its im-
plications, consider the two sentences (1) The cat
chases the dog. (2) The dog chases the cat. In
the first sentence the dog is an object which cor-
responds to the theme role A1, whereas in the
second sentence it is a subject with the agent
role A0. The role labeling decision is, how-
ever, in both cases based on the similarity value
sim(A(chases, r), dog), predicting A1, which is
incorrect in the latter case. When we incorporate
the syntactic information by shifting the vector ac-
cording to its syntactic relation to the predicate,
we obtain two diverging similarity values because
dog » nsubj and dog » dobj are essentially two
different vectors. This leads to the correct predic-
tion in both cases.
Relative to the base method, incorporating
the syntax improves the semantic F-score from
61.32% to 66.23% for Finnish and from 65.05%
to 66.55% for English. For Finnish, the gain is
rather substantial, while for English we see only
a moderate but nevertheless positive effect. This
demonstrates that, indeed, the circular shifting op-
eration successfully encodes syntactic information
both into the average vectors A and the candidate
argument vectors y.
</bodyText>
<subsectionHeader confidence="0.975743">
3.4 Core arguments vs. modifiers
</subsectionHeader>
<bodyText confidence="0.998804741935484">
In comparison to modifier roles, the assignment
of core (numbered) argument roles is consider-
ably more influenced by the predicate sense and
therefore must be learned separately, which we
also confirmed in initial experiments. The modi-
fier roles, on the other hand, are global in the sense
that they are not tied to any particular predicate.
This brings out an interesting question of whether
the modifier roles should be learned independently
of the predicate or not. We find that the best strat-
egy is to learn predicate-specific modifier vectors
in English and global modifier vectors in Finnish.
Another problem, particularly common in the
Finnish PropBank stems from the distinction be-
tween core roles and modifier roles. For instance,
for the predicate to move the argument meaning
the destination of the moving action has the core
role A2, while for a number of other predicates
which may optionally take a destination argument,
the directional modifier role AM-DIR would be
used. This leads to a situation where core argu-
ments receive a high score for a modifier role, and
modifier roles are over-predicted at the expense
of core argument roles. To account for this, we
introduce the following simple heuristics. If the
predicate lacks a core role r after prediction, iter-
ate through predicted modifier roles p1... pn and
change the prediction from pi to r if r has the max-
imum similarity among the core roles and the dif-
ference sim(pi, y) − sim(r, y) is smaller than a
threshold value optimized on a held-out develop-
</bodyText>
<figure confidence="0.8900842">
� (r,d,x,y) ˆy»d
A(x, r) =
(3)
count
,
</figure>
<page confidence="0.955564">
4
</page>
<bodyText confidence="0.994577">
ment set distinct from the test set.
We observe a 2.05pp gain in Finnish when using
this method, whereas in English this feature is less
significant with an improvement of only 0.3pp.
</bodyText>
<sectionHeader confidence="0.638175" genericHeader="method">
3.5 Fall-back for unknown words
</sectionHeader>
<bodyText confidence="0.999987952380953">
The above-mentioned techniques based purely on
vector representations with no additional features
fail if the vector space model lacks the argument
token which prevents the calculation of the nec-
essary similarities. To address this problem, we
build separately for each POS a “generic” repre-
sentation by averaging the vectors of all training
data tokens that have the POS and occurred only
once. These vectors, representing a typical rare
word of a given POS, are then used in place of
words missing from the vector space model.
Another solution taking advantage from the
vector space representation is used in cases where
a predicate is not seen in the training data and
therefore we have no information about its argu-
ment structure. We query for predicates closest
to the unseen predicate and take the average argu-
ment vectors from the most similar predicate that
was seen during the training.
Together, these two techniques result in a mod-
est gain of approximately 1pp for both languages.
</bodyText>
<subsectionHeader confidence="0.988885">
3.6 Sense classification
</subsectionHeader>
<bodyText confidence="0.99997685">
One final step required in SRL is the disambigua-
tion of the sense of the predicate. Here we ap-
ply an approach very similar to that used for role
classification, whereby for every sense of every
predicate, we calculate an average vector repre-
senting that sense. This is done as follows: For
every predicate sense, we average the vector rep-
resentations of all dependents and governors7 of
all occurrences of that sense in the training data,
circularly shifted to encode their syntactic relation
to the predicate. To assign a sense to a predicate
during testing, we average the shifted vectors cor-
responding to its dependents and governors in the
sentence, and choose the sense whose average vec-
tor is the nearest. Using this approach, we obtain a
84.18% accuracy for Finnish and 92.68% for En-
glish, compared to 79.89% and 92.88% without
the syntax information. This corresponds to a sub-
stantial gain for Finnish but, surprisingly, a small
drop for English. For the rare predicates that are
</bodyText>
<footnote confidence="0.5164485">
7Recall we use the extended SD scheme where a word can
have several governors in various situations.
</footnote>
<bodyText confidence="0.9956414">
not seen in the training data, we have no informa-
tion about their sense inventory and therefore we
simply predict the sense “.01” which is the cor-
rect choice in 79.56% of the cases in Finnish and
86.64% in English.
</bodyText>
<sectionHeader confidence="0.9859295" genericHeader="method">
4 Role Labeling with Linear
Transformations
</sectionHeader>
<bodyText confidence="0.999986">
As we discussed earlier, it was recently shown that
the word2vec spaces preserve a number of lin-
guistic regularities, and an accurate mapping be-
tween two word2vec-induced vector spaces can
be achieved using a simple linear transformation.
Mikolov et al. (2013a) have demonstrated that a
linear transformation trained on source-target lan-
guage word pairs obtained from Google Translate
can surprisingly accurately map word vectors from
one language to another, with obvious applications
to machine translation. It is also worth noting that
this is not universally true of all vector space rep-
resentation methods, as Mikolov et al. have shown
for example for Latent Semantic Analysis, which
exhibits this property to a considerably lesser ex-
tent. In addition to testing the applicability of the
word2vec method in general, we are specifically
interested whether these additional properties can
be exploited in the context of SRL. In particular,
we will test whether a similar linear vector space
transformation can be used to map the vectors of
the predicates onto those of their arguments.
More formally, for each role r, we will learn a
transformation matrix Wr such that for a vector
representation x of some predicate, Wrx will be
close to the vector representation of its arguments
with the role r. For instance, if x is the represen-
tation of the predicate (to) eat, we aim for WA1x
to be a vector similar to the vectors representing
edible items (role A1). The transformation can be
trained using the tuples (r, x, y) of predicate x and
its argument y with the role r gathered from the
training data, minimizing the error
</bodyText>
<equation confidence="0.9751835">
E kWrx − yk2 (5)
(x,y)
</equation>
<bodyText confidence="0.9908798">
over all training pairs (separately for each r). We
minimize the error using the standard stochastic
gradient descent method, whereby the transfor-
mation matrix is updated separately for each pair
(x, y) using the equation
</bodyText>
<equation confidence="0.685672">
Wr ← Wr − E(Wrx − y)xT (6)
</equation>
<page confidence="0.945746">
5
</page>
<bodyText confidence="0.992414">
where c is the learning rate whose suitable value is
selected on the development set. The whole proce-
dure is repeated until convergence is reached, ran-
domly shuffling the training data after each round
of training.
Using the transformation, we can establish the
most likely role for the argument y of a predicate
x as
</bodyText>
<equation confidence="0.9794245">
arg max sim(Wrx, y) (7)
r
</equation>
<bodyText confidence="0.999828">
where sim is the cosine similarity function, i.e. in
the exact same manner as for the average argument
method described in the previous section, with the
difference that the vector for the average argument
is not calculated directly from the training data,
but rather obtained through the linear transforma-
tion of the predicate vector.
As an alternative approach, we can also learn
the reverse transformation RWr such that RWry
is close to x, i.e. the transformation of the argu-
ment y onto the predicate x. Note that here RWr is
not the same as WrT ; we train this reverse transfor-
mation separately using the same gradient descent
method. We then modify the method for finding
the most likely role for an argument by taking the
average of the forward and reverse transformation
similarities:
</bodyText>
<equation confidence="0.9112845">
sim(Wrx, y) + sim(x, RWry) (8)
2
</equation>
<bodyText confidence="0.999960552631579">
Note that we make no assumptions about the
vector spaces where x and y are drawn from; they
may be different spaces and they do not need to be
matched in their dimensionality either, as there is
no requirement that W and RW be square matri-
ces. In practice, we find that the best strategy for
both Finnish and English is to represent both the
predicates and arguments using the space induced
from word forms, however, we have also tested on
Finnish representing the predicates using the space
induced from lemmas and the arguments using a
space induced from word forms, with only mini-
mally worse results. This shows that the transfor-
mation does not degrade substantially even when
mapping between two different spaces.
With this strategy, we reach an F-score of
62.71% in Finnish and 63.01% in English. These
results are on par with the scores obtained with
the average argument method, showing that a lin-
ear transformation is effective also in this kind of
problems.
To incorporate syntax information, we train
transformation matrices Wr,d and RWr,d for each
dependency relation d rather than relying on the
circular shift operation which cannot be captured
by linear transformations.8 As some combinations
of r and d may occur only in the test data, we use
the matrices Wr and RWr as a fall-back strategy.
In testing, we found that even if the (r, d) com-
bination is known from the training data, a small
improvement can be obtained by taking the aver-
age of the similarities with and without syntactic
information as the final similarity. Incorporating
these techniques into the basic linear transforma-
tion improves the semantic F-score from 62.71%
to 65.88% for Finnish and from 63.01% to 67.04%
for English. The improvement for both languages
is substantial.
</bodyText>
<sectionHeader confidence="0.990565" genericHeader="method">
5 Supervised classification approach
</sectionHeader>
<bodyText confidence="0.999954166666667">
In the previous sections, we have studied an ap-
proach to SRL based purely on the vector space
representations with no additional features. We
have addressed the choice of the argument role by
simply assigning the role with the maximum sim-
ilarity to the argument. To test the gain that could
be obtained by employing a more advanced tech-
nique for aggregating the scores and incorporating
additional features, we train a linear multi-class
support vector machine to assign the role to every
detected argument. As features, we use the simi-
larity values for each possible role using the best
performing method for each language,9 the sense
of the predicate, and — separately for the predi-
cate and the argument — the token itself, its POS,
morphological tags, every dependency relation to
its governors, and every dependency relation to
its dependents. The similarities are encoded as
feature weights, while all other features are bi-
nary. We use the multi-class SVM implementa-
tion from the SVM-multiclass package (Joachims,
1999), setting the regularization parameter on the
development set using a grid search.
For both languages, we observe a notable gain
in performance, leading to the best scores so far.
In Finnish the improvement in F-score is from
66.23% to 73.83% and in English from 67.04%
to 70.38%. However, as we will further discuss in
Section 6, in Finnish the contribution of the simi-
larity features is modest.
</bodyText>
<footnote confidence="0.988935">
8Note that this does not affect the overall computational
cost, as the total number of training examples remains un-
changed and the transformation matrices are small in size.
9Average vectors for Finnish and transformation for En-
glish (Table 2).
</footnote>
<figure confidence="0.5317965">
arg max
r
</figure>
<page confidence="0.988124">
6
</page>
<table confidence="0.999595076923077">
Finnish English
Average vectors
full method 66.23 66.55
–modifier vs. core role 64.18 66.25
–syntax 61.32 65.05
Linear transformation 65.88 67.04
full method
–syntax 62.71 63.01
Supervised classification 73.83 70.38
full method
only similarity features 64.21 65.89
–similarity features 73.54 67.51
–lexical features 65.51 58.42
</table>
<tableCaption confidence="0.990645">
Table 2: Overview of main results and a feature
</tableCaption>
<bodyText confidence="0.7986542">
ablation study. Modifier vs. core role refers to the
algorithm presented in Section 3.4. In the super-
vised classification part, -lexical features refers to
the removal of features based on word forms, pred-
icate sense and role similarities.
</bodyText>
<sectionHeader confidence="0.999077" genericHeader="evaluation">
6 Results and discussion
</sectionHeader>
<bodyText confidence="0.999699034482759">
All results discussed throughout Sections 3 to 5
are summarized in Table 2, which also serves as
a coarse feature ablation study. Overall, we see
that the average vector and linear transformation
methods perform roughly on par, with the aver-
age vector method being slightly better for Finnish
and slightly worse for English. Both vector space-
based methods gain notably from syntax informa-
tion, confirming that the manner in which this in-
formation is incorporated is indeed meaningful.
Adding the SVM classifier on top of these two
methods results in a substantial further raise in per-
formance, demonstrating that to be competitive on
SRL, it is necessary to explicitly model also ad-
ditional information besides the semantic similar-
ity between the predicate and the argument. This
is particularly pronounced for Finnish where the
present SVM method does not gain substantially
from the similarity-based features, while English
clearly benefits. To shed some light on this differ-
ence, we show in Table 3 the oracle accuracy of
role labeling for top-1 through top-10 roles as or-
dered by their similarity scores. The performance
on English is clearly superior to that on Finnish.
An important factor may be the fact that — in
terms of token count — the CoNLL’09 English
training size is nearly six times that of the Finnish
PropBank and the English vector space model was
induced on a nearly four times larger text corpus.
</bodyText>
<table confidence="0.999415416666667">
Finnish English
n Recall n Recall
1 58.23 1 67.39
2 68.29 2 82.82
3 74.30 3 88.49
4 78.71 4 91.58
5 82.21 5 93.20
6 84.74 6 94.29
7 87.04 7 94.91
8 88.98 8 95.31
9 90.76 9 95.65
10 92.05 10 95.86
</table>
<tableCaption confidence="0.8450395">
Table 3: A study of how many times (%) the cor-
rect role is among the top n most similar roles
when the arguments are known in advance. Left:
Similarities taken from the average vector method
on Finnish. Right: Similarities from the linear
transformation method on English.
</tableCaption>
<table confidence="0.999062">
Finnish English
Average vectors 66.23 / 89.89 66.55 / 79.57
Linear transf. 65.88 / 89.92 67.04 / 80.85
Supervised 73.83 / 89.29 70.38 / 78.71
</table>
<tableCaption confidence="0.980005">
Table 4: Overall results separately for all main
methods (labeled/unlabeled semantic F-score).
</tableCaption>
<bodyText confidence="0.999841666666667">
Returning to our original question of whether
the SD scheme can be used as-is for argument
identification, we show in Table 4 the unlabeled
F-scores for the main methods. These scores re-
flect the performance of the argument identifica-
tion step in isolation. While Finnish approaches
90% which is comparable to the best systems in
the CoNLL’09 task, English lags behind by over
10pp. To test to what extent the results would be
affected if a more accurate argument identification
system was applied, we used the output of the win-
ning (for English) CoNLL’09 Shared Task system
(Zhao et al., 2009a) as the argument identifica-
tion component, while predicting the roles with
the methods introduced so far. The results are
summarized in Table 5, where we see a substan-
tial gain for all the methods presented in this pa-
per, achieving an F-score of 82.33%, only 3.82pp
lower than best CoNLL’09 system. These results
give a mixed signal as to whether the extended SD
scheme is usable nearly as-is for argument identi-
fication (Finnish) or not (English). Despite our ef-
forts, we were unable to pinpoint the cause for this
difference, beyond the fact that the Finnish Prop-
</bodyText>
<page confidence="0.999492">
7
</page>
<table confidence="0.9961738">
Semantic F-score
CoNLL’09 best 86.15 / 91.97
Average vectors 73.12 / 91.97
Linear transformation 74.41 / 91.97
Supervised classif. 82.33 / 91.97
</table>
<tableCaption confidence="0.959473">
Table 5: Performance of suggested methods with
argument identification from the top-performing
CoNLL’09 system (labeled/unlabeled F-score).
</tableCaption>
<bodyText confidence="0.990784333333333">
Bank was originally developed specifically on top
of the SD scheme, while the English PropBank
and NomBank corpora were not.
</bodyText>
<sectionHeader confidence="0.999981" genericHeader="evaluation">
7 Related work
</sectionHeader>
<bodyText confidence="0.999915130434783">
While different methods have been studied to
build task specific vector space representations,
post-hoc methods to manipulate the vector spaces
without retraining are rare. Current SRL systems
utilize supervised machine learning approaches,
and typically a large set of features. For instance,
the winning system in the CoNLL’09 shared task
(SRL-only) introduces a heavy feature engineer-
ing system, which has about 1000 potential fea-
ture templates from which the system discovers
the best set to be used (Zhao et al., 2009b). Word
similarities are usually introduced to SRL as a
part of unsupervised or semi-supervised meth-
ods. For example, Titov and Klementiev (2012)
present an unsupervised clustering method ap-
plying word representation techniques, and De-
schacht and Moens (2009) used vector similarities
to automatically expand the small training set to
build semi-supervised SRL system. Additionally,
Turian et al. (2010) have shown that word repre-
sentations can be included among the features to
improve the performance of named entity recogni-
tion and chunking systems.
</bodyText>
<sectionHeader confidence="0.999034" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999996537037037">
We set out to test two post-hoc vector space ma-
nipulation techniques in the context of semantic
role labeling. We found that the circular shift op-
eration can indeed be applied also to other vector
representations as a way to encode syntactic infor-
mation. Importantly, the circular shift is applied to
a pre-existing vector space representation, rather
than during its induction, and is therefore task-
independent. Further, we find that such shifted
vectors can be meaningfully averaged to represent
predicate senses and arguments.
We also extended the study of the linear trans-
formation between two vector spaces and show
that the same technique can be used also within
a single space, mapping the vectors of predicates
onto the vectors of their arguments. This map-
ping produces results that are performance-wise
on par with the average vectors method, demon-
strating a good generalization ability of the lin-
ear mapping and the underlying word2vec vector
space representation. Here it is worth noting that
— if we gloss over some obvious issues of am-
biguity — the mapping between two languages
demonstrated by Mikolov et al. is conceptually a
one-to-one mapping, at least in contrast to the one-
to-many nature of the mapping between predicates
and their arguments. These results hint at the pos-
sibility that a number of problems which can be re-
duced to the “predict a word given a word” pattern
may be addressable with this simple technique.
With respect to the application to SRL, we have
shown that it is possible to carry out SRL based
purely on the vector space manipulation meth-
ods introduced in this paper, outperforming sev-
eral entries in the CoNLL-09 Shared Task. How-
ever, it is perhaps not too surprising that much
more is needed to build a competitive SRL sys-
tem. Adding an SVM classifier with few relatively
simple features derived from the syntactic analy-
ses in addition to features based on vector similar-
ities, and especially adding a well-performing ar-
gument identification method, can result in a sys-
tem close to approaching state-of-the-art perfor-
mance, which is encouraging.
As future work, it will be interesting to study to
which extent SRL, and similar applications would
benefit from addressing the one-to-many nature of
the underlying problem. While for some predi-
cates the arguments likely form a cluster that can
be represented as a single average vector, for other
predicates, such as to see, it is not the case. Find-
ing methods which allow us to model this property
of the problem will constitute an interesting direc-
tion with broader applications beyond SRL.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999119833333333">
This work has been supported by the Emil Aal-
tonen Foundation and Kone Foundation. Com-
putational resources were provided by CSC – IT
Center for Science. We would also like to thank
Sampo Pyysalo and Hans Moen for comments and
general discussion.
</bodyText>
<page confidence="0.997335">
8
</page>
<sectionHeader confidence="0.992774" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985386572727272">
Pierpaolo Basile and Annalina Caputo. 2012. Encod-
ing syntactic dependencies using Random Indexing
and Wikipedia as a corpus. In Proceedings of the
3rd Italian Information Retrieval (IIR) Workshop,
volume 835, pages 144–154.
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, pages 89–97. Association for
Computational Linguistics.
Koen Deschacht and Marie-Francine Moens. 2009.
Semi-supervised semantic role labeling using the la-
tent words language model. In Proceedings of the
2009 Conference on Empirical Methods in Natural
Language Processing: Volume 1-Volume 1, pages
21–29. Association for Computational Linguistics.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, et al. 2009. The CoNLL-2009
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 1–18. Associa-
tion for Computational Linguistics.
P´eter Hal´acsy, Andr´as Kornai, and Csaba Oravecz.
2007. HunPos: an open source trigram tagger. In
Proceedings of the 45th annual meeting of the ACL
on interactive poster and demonstration sessions,
pages 209–212. Association for Computational Lin-
guistics.
Katri Haverinen, Veronika Laippala, Samuel Kohonen,
Anna Missil¨a, Jenna Nyblom, Stina Ojala, Timo Vil-
janen, Tapio Salakoski, and Filip Ginter. 2013a.
Towards a dependency-based PropBank of general
Finnish. In Proceedings of the 19th Nordic Confer-
ence on Computational Linguistics (NoDaLiDa’13),
pages 41–57.
Katri Haverinen, Jenna Nyblom, Timo Viljanen,
Veronika Laippala, Samuel Kohonen, Anna Mis-
sil¨a, Stina Ojala, Tapio Salakoski, and Filip Ginter.
2013b. Building the essential resources for Finnish:
the Turku Dependency Treebank. Language Re-
sources and Evaluation, pages 1–39.
Thorsten Joachims. 1999. Making large-scale SVM
learning practical. In Advances in Kernel Meth-
ods - Support Vector Learning, pages 169–184. MIT
Press.
Krister Lind´en, Miikka Silfverberg, and Tommi Piri-
nen. 2009. HFST tools for morphology — an effi-
cient open-source package for construction of mor-
phological analyzers. In State of the Art in Com-
putational Morphology, volume 41 of Communica-
tions in Computer and Information Science, pages
28–47.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The Stanford typed dependencies rep-
resentation. In Coling 2008: Proceedings of the
workshop on Cross-Framework and Cross-Domain
Parser Evaluation, pages 1–8. Coling 2008 Organiz-
ing Committee.
Adam Meyers, Ruth Reeves, Catherine Macleod,
Rachel Szekely, Veronika Zielinska, Brian Young,
and Ralph Grishman. 2004. The NomBank project:
An interim report. In HLT-NAACL 2004 Workshop:
Frontiers in Corpus Annotation, pages 24–31.
Tomas Mikolov, Quoc V. Le, and Ilya Sutskever.
2013a. Exploiting similarities among languages
for machine translation. CoRR (arxiv.org),
abs/1309.4168.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013b. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems 26, pages 3111–3119.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 746–751. Associa-
tion for Computational Linguistics, June.
Jenna Nyblom, Samuel Kohonen, Katri Haverinen,
Tapio Salakoski, and Filip Ginter. 2013. Pre-
dicting conjunct propagation and other extended
Stanford Dependencies. In Proceedings of the In-
ternational Conference on Dependency Linguistics
(Depling 2013), pages 252–261.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The proposition bank: An annotated cor-
pus of semantic roles. Computational Linguistics,
31(1):71–106.
Tommi Pirinen. 2008. Suomen kielen ¨a¨arellistilainen
automaattinen morfologinen j¨asennin avoimen
l¨ahdekoodin resurssein. Master’s thesis, University
of Helsinki.
Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. BRAT: a web-based tool for nlp-assisted
text annotation. In Proceedings of the Demonstra-
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 102–107. Association for Computational Lin-
guistics.
Ivan Titov and Alexandre Klementiev. 2012. A
Bayesian approach to unsupervised semantic role in-
duction. In Proceedings of the 13th Conference of
the European Chapter of the Association for Com-
putational Linguistics, pages 12–22. Association for
Computational Linguistics.
</reference>
<page confidence="0.944661">
9
</page>
<reference confidence="0.999514428571428">
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 384–394. Association for
Computational Linguistics.
Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka
Uchimoto, and Kentaro Torisawa. 2009a. Multilin-
gual dependency learning: Exploiting rich features
for tagging syntactic and semantic dependencies.
In Proceedings of the Thirteenth Conference on
Computational Natural Language Learning: Shared
Task, pages 61–66. Association for Computational
Linguistics.
Hai Zhao, Wenliang Chen, Chunyu Kit, and Guodong
Zhou. 2009b. Multilingual dependency learning:
a huge feature engineering method to semantic de-
pendency parsing. In Proceedings of the Thirteenth
Conference on Computational Natural Language
Learning: Shared Task, pages 55–60. Association
for Computational Linguistics.
</reference>
<page confidence="0.997784">
10
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888822">
<title confidence="0.9993085">Post-hoc Manipulations of Vector Space with Application to Semantic Role Labeling</title>
<author confidence="0.894806">Kanerva</author>
<affiliation confidence="0.999792">Department of Information University of Turku,</affiliation>
<abstract confidence="0.9996595">In this paper, we introduce several vector space manipulation methods that are applied to trained vector space models in a post-hoc fashion, and present an application of these techniques in semantic role labeling for Finnish and English. Specifically, we show that the vectors can be circularly shifted to encode syntactic information and subsequently averaged to produce representations of predicate senses and arguments. Further, we show that it is possible to effectively learn a linear transformation between the vector representations of predicates and their arguments, within the same vector space.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pierpaolo Basile</author>
<author>Annalina Caputo</author>
</authors>
<title>Encoding syntactic dependencies using Random Indexing and Wikipedia as a corpus.</title>
<date>2012</date>
<booktitle>In Proceedings of the 3rd Italian Information Retrieval (IIR) Workshop,</booktitle>
<volume>835</volume>
<pages>144--154</pages>
<contexts>
<context position="12774" citStr="Basile and Caputo, 2012" startWordPosition="2068" endWordPosition="2071">aluated with the data sets described in Section 2, this initial method leads to 61.32% semantic F-score for Finnish and 65.05% for English. 3 3.3 Incorporating syntax As we will demonstrate shortly, incorporating information about dependency relations can lead to a substantial performance gain. To incorporate the dependency relation information into the role classification method introduced above, we apply the technique of circular shifting of vectors. This technique was previously used in the context of Random Indexing (RI) to derive new vectors from existing ones in a deterministic fashion (Basile and Caputo, 2012). In RI, the shift operation is however not used on the final vectors, but rather already during the induction of the vector representation. Given a vector representation of an argument y, we can encode the dependency relation of y and its predicate by circularly shifting the vector of y by an offset assigned separately to each possible dependency relation. The assignment is arbitrary, but such that no two relations are assigned the same offset. We will denote this operation as y»d, meaning the vector y circularly shifted to the right by the offset assigned to the dependency relation d. For in</context>
</contexts>
<marker>Basile, Caputo, 2012</marker>
<rawString>Pierpaolo Basile and Annalina Caputo. 2012. Encoding syntactic dependencies using Random Indexing and Wikipedia as a corpus. In Proceedings of the 3rd Italian Information Retrieval (IIR) Workshop, volume 835, pages 144–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>89--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5480" citStr="Bohnet, 2010" startWordPosition="861" endWordPosition="862">and are thus directly comparable to the official results reported in the Shared Task. In the test phase, we follow the Shared Task setting whereby morphological and syntactic analysis is predicted as well, i.e., no gold standard data enters the system other than the tokenization and the information of which tokens constitute predicates. We produce the Finnish morphological and syntactic analyses for the test set with the parsing pipeline of Haverinen et al. (2013b), composed of a morphological analyzer and tagger (Hal´acsy et al., 2007; Pirinen, 2008; Lind´en et al., 2009), dependency parser (Bohnet, 2010) and a machinelearning based component for predicting the extended SD dependencies (Nyblom et al., 2013). While the English data is provided with automatically produced dependency parses, we are specifically interested in the SD scheme and therefore we re-parse the corpus with the Stanford parser2 taking a union of the base and collapsed dependency outputs to match the Finnish data. The vector space models used throughout this paper are induced using the word2vec software (skip-gram architecture with default parameters). For Finnish, the model is trained on 1.5 billion tokens of Finnish Intern</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 89–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koen Deschacht</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Semi-supervised semantic role labeling using the latent words language model.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>21--29</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="31072" citStr="Deschacht and Moens (2009)" startWordPosition="5133" endWordPosition="5137">aining are rare. Current SRL systems utilize supervised machine learning approaches, and typically a large set of features. For instance, the winning system in the CoNLL’09 shared task (SRL-only) introduces a heavy feature engineering system, which has about 1000 potential feature templates from which the system discovers the best set to be used (Zhao et al., 2009b). Word similarities are usually introduced to SRL as a part of unsupervised or semi-supervised methods. For example, Titov and Klementiev (2012) present an unsupervised clustering method applying word representation techniques, and Deschacht and Moens (2009) used vector similarities to automatically expand the small training set to build semi-supervised SRL system. Additionally, Turian et al. (2010) have shown that word representations can be included among the features to improve the performance of named entity recognition and chunking systems. 8 Conclusions We set out to test two post-hoc vector space manipulation techniques in the context of semantic role labeling. We found that the circular shift operation can indeed be applied also to other vector representations as a way to encode syntactic information. Importantly, the circular shift is ap</context>
</contexts>
<marker>Deschacht, Moens, 2009</marker>
<rawString>Koen Deschacht and Marie-Francine Moens. 2009. Semi-supervised semantic role labeling using the latent words language model. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 21–29. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Mart´ı</author>
<author>Llu´ıs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
</authors>
<title>The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Mart´ı, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Mart´ı, Llu´ıs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, et al. 2009. The CoNLL-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–18. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P´eter Hal´acsy</author>
<author>Andr´as Kornai</author>
<author>Csaba Oravecz</author>
</authors>
<title>HunPos: an open source trigram tagger.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions,</booktitle>
<pages>209--212</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hal´acsy, Kornai, Oravecz, 2007</marker>
<rawString>P´eter Hal´acsy, Andr´as Kornai, and Csaba Oravecz. 2007. HunPos: an open source trigram tagger. In Proceedings of the 45th annual meeting of the ACL on interactive poster and demonstration sessions, pages 209–212. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katri Haverinen</author>
<author>Veronika Laippala</author>
<author>Samuel Kohonen</author>
<author>Anna Missil¨a</author>
<author>Jenna Nyblom</author>
<author>Stina Ojala</author>
<author>Timo Viljanen</author>
<author>Tapio Salakoski</author>
<author>Filip Ginter</author>
</authors>
<title>Towards a dependency-based PropBank of general Finnish.</title>
<date>2013</date>
<booktitle>In Proceedings of the 19th Nordic Conference on Computational Linguistics (NoDaLiDa’13),</booktitle>
<pages>41--57</pages>
<marker>Haverinen, Laippala, Kohonen, Missil¨a, Nyblom, Ojala, Viljanen, Salakoski, Ginter, 2013</marker>
<rawString>Katri Haverinen, Veronika Laippala, Samuel Kohonen, Anna Missil¨a, Jenna Nyblom, Stina Ojala, Timo Viljanen, Tapio Salakoski, and Filip Ginter. 2013a. Towards a dependency-based PropBank of general Finnish. In Proceedings of the 19th Nordic Conference on Computational Linguistics (NoDaLiDa’13), pages 41–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katri Haverinen</author>
<author>Jenna Nyblom</author>
</authors>
<title>Timo Viljanen, Veronika Laippala, Samuel Kohonen,</title>
<date>2013</date>
<pages>1--39</pages>
<location>Anna Missil¨a, Stina Ojala, Tapio</location>
<marker>Haverinen, Nyblom, 2013</marker>
<rawString>Katri Haverinen, Jenna Nyblom, Timo Viljanen, Veronika Laippala, Samuel Kohonen, Anna Missil¨a, Stina Ojala, Tapio Salakoski, and Filip Ginter. 2013b. Building the essential resources for Finnish: the Turku Dependency Treebank. Language Resources and Evaluation, pages 1–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Making large-scale SVM learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods - Support Vector Learning,</booktitle>
<pages>169--184</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="25283" citStr="Joachims, 1999" startWordPosition="4187" endWordPosition="4188">e train a linear multi-class support vector machine to assign the role to every detected argument. As features, we use the similarity values for each possible role using the best performing method for each language,9 the sense of the predicate, and — separately for the predicate and the argument — the token itself, its POS, morphological tags, every dependency relation to its governors, and every dependency relation to its dependents. The similarities are encoded as feature weights, while all other features are binary. We use the multi-class SVM implementation from the SVM-multiclass package (Joachims, 1999), setting the regularization parameter on the development set using a grid search. For both languages, we observe a notable gain in performance, leading to the best scores so far. In Finnish the improvement in F-score is from 66.23% to 73.83% and in English from 67.04% to 70.38%. However, as we will further discuss in Section 6, in Finnish the contribution of the similarity features is modest. 8Note that this does not affect the overall computational cost, as the total number of training examples remains unchanged and the transformation matrices are small in size. 9Average vectors for Finnish </context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>Thorsten Joachims. 1999. Making large-scale SVM learning practical. In Advances in Kernel Methods - Support Vector Learning, pages 169–184. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krister Lind´en</author>
<author>Miikka Silfverberg</author>
<author>Tommi Pirinen</author>
</authors>
<title>HFST tools for morphology — an efficient open-source package for construction of morphological analyzers.</title>
<date>2009</date>
<booktitle>In State of the Art in Computational Morphology, volume 41 of Communications in Computer and Information Science,</booktitle>
<pages>28--47</pages>
<marker>Lind´en, Silfverberg, Pirinen, 2009</marker>
<rawString>Krister Lind´en, Miikka Silfverberg, and Tommi Pirinen. 2009. HFST tools for morphology — an efficient open-source package for construction of morphological analyzers. In State of the Art in Computational Morphology, volume 41 of Communications in Computer and Information Science, pages 28–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford typed dependencies representation.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation,</booktitle>
<pages>pages</pages>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation, pages 1–8. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekely</author>
<author>Veronika Zielinska</author>
<author>Brian Young</author>
<author>Ralph Grishman</author>
</authors>
<title>The NomBank project: An interim report.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="4365" citStr="Meyers et al., 2004" startWordPosition="674" endWordPosition="677">n corpus of Internet Finnish. In order to be able to test the proposed meth1 Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) @ EACL 2014, pages 1–10, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics punct&gt; &lt;nsubj:A0 conj&gt; cc&gt; &lt;nsubj:A0 dobj:A1&gt; &lt;advmod:AM-TMP dobj:A1&gt; He ate.01 lunch and then washed.01 dishes . Figure 1: Extended Stanford Dependencies scheme combined with PropBank annotation. sense combinations. The English CoNLL data is derived from the PropBank and NomBank corpora (Palmer et al., 2005; Meyers et al., 2004) and it has a total of 54 different argument roles. In addition to the same 22 roles as Finnish, English also has discontinuous variants for each role. The English data has 958,024 training tokens with 178,988 occurrences of 15,880 unique predicate-sense combinations. All Finnish results are reported on the test subset of the Finnish PropBank, and have no previously published baseline to compare with. The results we report for English are produced on the official test section of the CoNLL’09 data and are thus directly comparable to the official results reported in the Shared Task. In the test </context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekely, Veronika Zielinska, Brian Young, and Ralph Grishman. 2004. The NomBank project: An interim report. In HLT-NAACL 2004 Workshop: Frontiers in Corpus Annotation, pages 24–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Quoc V Le</author>
<author>Ilya Sutskever</author>
</authors>
<title>Exploiting similarities among languages for machine translation. CoRR (arxiv.org),</title>
<date>2013</date>
<pages>1309--4168</pages>
<contexts>
<context position="1040" citStr="Mikolov et al., 2013" startWordPosition="153" endWordPosition="156">ic role labeling for Finnish and English. Specifically, we show that the vectors can be circularly shifted to encode syntactic information and subsequently averaged to produce representations of predicate senses and arguments. Further, we show that it is possible to effectively learn a linear transformation between the vector representations of predicates and their arguments, within the same vector space. 1 Introduction Recently, there has been much progress in the development of highly scalable methods for inducing vector space representations of language. In particular, the word2vec method (Mikolov et al., 2013b) is capable of training on billions of tokens in a matter of hours, producing high quality representations. An exciting property exhibited by the vector spaces induced using word2vec is that they preserve a number of linguistic regularities, lending themselves to simple algebraic operations with the vectors (Mikolov et al., 2013c) and linear mapping between different spaces (Mikolov et al., 2013a). These can be seen as post-hoc operations manipulating the vector space with the significant advantage of not requiring a new task-specific representation to be induced, as is customary. In this pa</context>
<context position="19651" citStr="Mikolov et al. (2013" startWordPosition="3238" endWordPosition="3241"> 7Recall we use the extended SD scheme where a word can have several governors in various situations. not seen in the training data, we have no information about their sense inventory and therefore we simply predict the sense “.01” which is the correct choice in 79.56% of the cases in Finnish and 86.64% in English. 4 Role Labeling with Linear Transformations As we discussed earlier, it was recently shown that the word2vec spaces preserve a number of linguistic regularities, and an accurate mapping between two word2vec-induced vector spaces can be achieved using a simple linear transformation. Mikolov et al. (2013a) have demonstrated that a linear transformation trained on source-target language word pairs obtained from Google Translate can surprisingly accurately map word vectors from one language to another, with obvious applications to machine translation. It is also worth noting that this is not universally true of all vector space representation methods, as Mikolov et al. have shown for example for Latent Semantic Analysis, which exhibits this property to a considerably lesser extent. In addition to testing the applicability of the word2vec method in general, we are specifically interested whether</context>
</contexts>
<marker>Mikolov, Le, Sutskever, 2013</marker>
<rawString>Tomas Mikolov, Quoc V. Le, and Ilya Sutskever. 2013a. Exploiting similarities among languages for machine translation. CoRR (arxiv.org), abs/1309.4168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems 26,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="1040" citStr="Mikolov et al., 2013" startWordPosition="153" endWordPosition="156">ic role labeling for Finnish and English. Specifically, we show that the vectors can be circularly shifted to encode syntactic information and subsequently averaged to produce representations of predicate senses and arguments. Further, we show that it is possible to effectively learn a linear transformation between the vector representations of predicates and their arguments, within the same vector space. 1 Introduction Recently, there has been much progress in the development of highly scalable methods for inducing vector space representations of language. In particular, the word2vec method (Mikolov et al., 2013b) is capable of training on billions of tokens in a matter of hours, producing high quality representations. An exciting property exhibited by the vector spaces induced using word2vec is that they preserve a number of linguistic regularities, lending themselves to simple algebraic operations with the vectors (Mikolov et al., 2013c) and linear mapping between different spaces (Mikolov et al., 2013a). These can be seen as post-hoc operations manipulating the vector space with the significant advantage of not requiring a new task-specific representation to be induced, as is customary. In this pa</context>
<context position="19651" citStr="Mikolov et al. (2013" startWordPosition="3238" endWordPosition="3241"> 7Recall we use the extended SD scheme where a word can have several governors in various situations. not seen in the training data, we have no information about their sense inventory and therefore we simply predict the sense “.01” which is the correct choice in 79.56% of the cases in Finnish and 86.64% in English. 4 Role Labeling with Linear Transformations As we discussed earlier, it was recently shown that the word2vec spaces preserve a number of linguistic regularities, and an accurate mapping between two word2vec-induced vector spaces can be achieved using a simple linear transformation. Mikolov et al. (2013a) have demonstrated that a linear transformation trained on source-target language word pairs obtained from Google Translate can surprisingly accurately map word vectors from one language to another, with obvious applications to machine translation. It is also worth noting that this is not universally true of all vector space representation methods, as Mikolov et al. have shown for example for Latent Semantic Analysis, which exhibits this property to a considerably lesser extent. In addition to testing the applicability of the word2vec method in general, we are specifically interested whether</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013b. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems 26, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>746--751</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="1040" citStr="Mikolov et al., 2013" startWordPosition="153" endWordPosition="156">ic role labeling for Finnish and English. Specifically, we show that the vectors can be circularly shifted to encode syntactic information and subsequently averaged to produce representations of predicate senses and arguments. Further, we show that it is possible to effectively learn a linear transformation between the vector representations of predicates and their arguments, within the same vector space. 1 Introduction Recently, there has been much progress in the development of highly scalable methods for inducing vector space representations of language. In particular, the word2vec method (Mikolov et al., 2013b) is capable of training on billions of tokens in a matter of hours, producing high quality representations. An exciting property exhibited by the vector spaces induced using word2vec is that they preserve a number of linguistic regularities, lending themselves to simple algebraic operations with the vectors (Mikolov et al., 2013c) and linear mapping between different spaces (Mikolov et al., 2013a). These can be seen as post-hoc operations manipulating the vector space with the significant advantage of not requiring a new task-specific representation to be induced, as is customary. In this pa</context>
<context position="19651" citStr="Mikolov et al. (2013" startWordPosition="3238" endWordPosition="3241"> 7Recall we use the extended SD scheme where a word can have several governors in various situations. not seen in the training data, we have no information about their sense inventory and therefore we simply predict the sense “.01” which is the correct choice in 79.56% of the cases in Finnish and 86.64% in English. 4 Role Labeling with Linear Transformations As we discussed earlier, it was recently shown that the word2vec spaces preserve a number of linguistic regularities, and an accurate mapping between two word2vec-induced vector spaces can be achieved using a simple linear transformation. Mikolov et al. (2013a) have demonstrated that a linear transformation trained on source-target language word pairs obtained from Google Translate can surprisingly accurately map word vectors from one language to another, with obvious applications to machine translation. It is also worth noting that this is not universally true of all vector space representation methods, as Mikolov et al. have shown for example for Latent Semantic Analysis, which exhibits this property to a considerably lesser extent. In addition to testing the applicability of the word2vec method in general, we are specifically interested whether</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013c. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 746–751. Association for Computational Linguistics, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenna Nyblom</author>
<author>Samuel Kohonen</author>
<author>Katri Haverinen</author>
<author>Tapio Salakoski</author>
<author>Filip Ginter</author>
</authors>
<title>Predicting conjunct propagation and other extended Stanford Dependencies.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference on Dependency Linguistics (Depling</booktitle>
<pages>252--261</pages>
<contexts>
<context position="5584" citStr="Nyblom et al., 2013" startWordPosition="876" endWordPosition="879"> phase, we follow the Shared Task setting whereby morphological and syntactic analysis is predicted as well, i.e., no gold standard data enters the system other than the tokenization and the information of which tokens constitute predicates. We produce the Finnish morphological and syntactic analyses for the test set with the parsing pipeline of Haverinen et al. (2013b), composed of a morphological analyzer and tagger (Hal´acsy et al., 2007; Pirinen, 2008; Lind´en et al., 2009), dependency parser (Bohnet, 2010) and a machinelearning based component for predicting the extended SD dependencies (Nyblom et al., 2013). While the English data is provided with automatically produced dependency parses, we are specifically interested in the SD scheme and therefore we re-parse the corpus with the Stanford parser2 taking a union of the base and collapsed dependency outputs to match the Finnish data. The vector space models used throughout this paper are induced using the word2vec software (skip-gram architecture with default parameters). For Finnish, the model is trained on 1.5 billion tokens of Finnish Internet texts gathered from the Common Crawl dataset.3 The data was sentenceods on SRL, we need to carry out </context>
</contexts>
<marker>Nyblom, Kohonen, Haverinen, Salakoski, Ginter, 2013</marker>
<rawString>Jenna Nyblom, Samuel Kohonen, Katri Haverinen, Tapio Salakoski, and Filip Ginter. 2013. Predicting conjunct propagation and other extended Stanford Dependencies. In Proceedings of the International Conference on Dependency Linguistics (Depling 2013), pages 252–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="4343" citStr="Palmer et al., 2005" startWordPosition="670" endWordPosition="673"> by using a 1.5B token corpus of Internet Finnish. In order to be able to test the proposed meth1 Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) @ EACL 2014, pages 1–10, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics punct&gt; &lt;nsubj:A0 conj&gt; cc&gt; &lt;nsubj:A0 dobj:A1&gt; &lt;advmod:AM-TMP dobj:A1&gt; He ate.01 lunch and then washed.01 dishes . Figure 1: Extended Stanford Dependencies scheme combined with PropBank annotation. sense combinations. The English CoNLL data is derived from the PropBank and NomBank corpora (Palmer et al., 2005; Meyers et al., 2004) and it has a total of 54 different argument roles. In addition to the same 22 roles as Finnish, English also has discontinuous variants for each role. The English data has 958,024 training tokens with 178,988 occurrences of 15,880 unique predicate-sense combinations. All Finnish results are reported on the test subset of the Finnish PropBank, and have no previously published baseline to compare with. The results we report for English are produced on the official test section of the CoNLL’09 data and are thus directly comparable to the official results reported in the Sha</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommi Pirinen</author>
</authors>
<title>Suomen kielen ¨a¨arellistilainen automaattinen morfologinen j¨asennin avoimen l¨ahdekoodin resurssein. Master’s thesis,</title>
<date>2008</date>
<institution>University of Helsinki.</institution>
<contexts>
<context position="5423" citStr="Pirinen, 2008" startWordPosition="852" endWordPosition="853">oduced on the official test section of the CoNLL’09 data and are thus directly comparable to the official results reported in the Shared Task. In the test phase, we follow the Shared Task setting whereby morphological and syntactic analysis is predicted as well, i.e., no gold standard data enters the system other than the tokenization and the information of which tokens constitute predicates. We produce the Finnish morphological and syntactic analyses for the test set with the parsing pipeline of Haverinen et al. (2013b), composed of a morphological analyzer and tagger (Hal´acsy et al., 2007; Pirinen, 2008; Lind´en et al., 2009), dependency parser (Bohnet, 2010) and a machinelearning based component for predicting the extended SD dependencies (Nyblom et al., 2013). While the English data is provided with automatically produced dependency parses, we are specifically interested in the SD scheme and therefore we re-parse the corpus with the Stanford parser2 taking a union of the base and collapsed dependency outputs to match the Finnish data. The vector space models used throughout this paper are induced using the word2vec software (skip-gram architecture with default parameters). For Finnish, the</context>
</contexts>
<marker>Pirinen, 2008</marker>
<rawString>Tommi Pirinen. 2008. Suomen kielen ¨a¨arellistilainen automaattinen morfologinen j¨asennin avoimen l¨ahdekoodin resurssein. Master’s thesis, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pontus Stenetorp</author>
<author>Sampo Pyysalo</author>
<author>Goran Topi´c</author>
<author>Tomoko Ohta</author>
<author>Sophia Ananiadou</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>BRAT: a web-based tool for nlp-assisted text annotation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>102--107</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Stenetorp, Pyysalo, Topi´c, Ohta, Ananiadou, Tsujii, 2012</marker>
<rawString>Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c, Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsujii. 2012. BRAT: a web-based tool for nlp-assisted text annotation. In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102–107. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A Bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>12--22</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="30958" citStr="Titov and Klementiev (2012)" startWordPosition="5118" endWordPosition="5121"> to build task specific vector space representations, post-hoc methods to manipulate the vector spaces without retraining are rare. Current SRL systems utilize supervised machine learning approaches, and typically a large set of features. For instance, the winning system in the CoNLL’09 shared task (SRL-only) introduces a heavy feature engineering system, which has about 1000 potential feature templates from which the system discovers the best set to be used (Zhao et al., 2009b). Word similarities are usually introduced to SRL as a part of unsupervised or semi-supervised methods. For example, Titov and Klementiev (2012) present an unsupervised clustering method applying word representation techniques, and Deschacht and Moens (2009) used vector similarities to automatically expand the small training set to build semi-supervised SRL system. Additionally, Turian et al. (2010) have shown that word representations can be included among the features to improve the performance of named entity recognition and chunking systems. 8 Conclusions We set out to test two post-hoc vector space manipulation techniques in the context of semantic role labeling. We found that the circular shift operation can indeed be applied al</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. A Bayesian approach to unsupervised semantic role induction. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 12–22. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="31216" citStr="Turian et al. (2010)" startWordPosition="5154" endWordPosition="5157">system in the CoNLL’09 shared task (SRL-only) introduces a heavy feature engineering system, which has about 1000 potential feature templates from which the system discovers the best set to be used (Zhao et al., 2009b). Word similarities are usually introduced to SRL as a part of unsupervised or semi-supervised methods. For example, Titov and Klementiev (2012) present an unsupervised clustering method applying word representation techniques, and Deschacht and Moens (2009) used vector similarities to automatically expand the small training set to build semi-supervised SRL system. Additionally, Turian et al. (2010) have shown that word representations can be included among the features to improve the performance of named entity recognition and chunking systems. 8 Conclusions We set out to test two post-hoc vector space manipulation techniques in the context of semantic role labeling. We found that the circular shift operation can indeed be applied also to other vector representations as a way to encode syntactic information. Importantly, the circular shift is applied to a pre-existing vector space representation, rather than during its induction, and is therefore taskindependent. Further, we find that s</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Kiyotaka Uchimoto</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>61--66</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="29296" citStr="Zhao et al., 2009" startWordPosition="4857" endWordPosition="4860">eled semantic F-score). Returning to our original question of whether the SD scheme can be used as-is for argument identification, we show in Table 4 the unlabeled F-scores for the main methods. These scores reflect the performance of the argument identification step in isolation. While Finnish approaches 90% which is comparable to the best systems in the CoNLL’09 task, English lags behind by over 10pp. To test to what extent the results would be affected if a more accurate argument identification system was applied, we used the output of the winning (for English) CoNLL’09 Shared Task system (Zhao et al., 2009a) as the argument identification component, while predicting the roles with the methods introduced so far. The results are summarized in Table 5, where we see a substantial gain for all the methods presented in this paper, achieving an F-score of 82.33%, only 3.82pp lower than best CoNLL’09 system. These results give a mixed signal as to whether the extended SD scheme is usable nearly as-is for argument identification (Finnish) or not (English). Despite our efforts, we were unable to pinpoint the cause for this difference, beyond the fact that the Finnish Prop7 Semantic F-score CoNLL’09 best </context>
<context position="30812" citStr="Zhao et al., 2009" startWordPosition="5096" endWordPosition="5099"> top of the SD scheme, while the English PropBank and NomBank corpora were not. 7 Related work While different methods have been studied to build task specific vector space representations, post-hoc methods to manipulate the vector spaces without retraining are rare. Current SRL systems utilize supervised machine learning approaches, and typically a large set of features. For instance, the winning system in the CoNLL’09 shared task (SRL-only) introduces a heavy feature engineering system, which has about 1000 potential feature templates from which the system discovers the best set to be used (Zhao et al., 2009b). Word similarities are usually introduced to SRL as a part of unsupervised or semi-supervised methods. For example, Titov and Klementiev (2012) present an unsupervised clustering method applying word representation techniques, and Deschacht and Moens (2009) used vector similarities to automatically expand the small training set to build semi-supervised SRL system. Additionally, Turian et al. (2010) have shown that word representations can be included among the features to improve the performance of named entity recognition and chunking systems. 8 Conclusions We set out to test two post-hoc </context>
</contexts>
<marker>Zhao, Chen, Kazama, Uchimoto, Torisawa, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa. 2009a. Multilingual dependency learning: Exploiting rich features for tagging syntactic and semantic dependencies. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 61–66. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Wenliang Chen</author>
<author>Chunyu Kit</author>
<author>Guodong Zhou</author>
</authors>
<title>Multilingual dependency learning: a huge feature engineering method to semantic dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>55--60</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="29296" citStr="Zhao et al., 2009" startWordPosition="4857" endWordPosition="4860">eled semantic F-score). Returning to our original question of whether the SD scheme can be used as-is for argument identification, we show in Table 4 the unlabeled F-scores for the main methods. These scores reflect the performance of the argument identification step in isolation. While Finnish approaches 90% which is comparable to the best systems in the CoNLL’09 task, English lags behind by over 10pp. To test to what extent the results would be affected if a more accurate argument identification system was applied, we used the output of the winning (for English) CoNLL’09 Shared Task system (Zhao et al., 2009a) as the argument identification component, while predicting the roles with the methods introduced so far. The results are summarized in Table 5, where we see a substantial gain for all the methods presented in this paper, achieving an F-score of 82.33%, only 3.82pp lower than best CoNLL’09 system. These results give a mixed signal as to whether the extended SD scheme is usable nearly as-is for argument identification (Finnish) or not (English). Despite our efforts, we were unable to pinpoint the cause for this difference, beyond the fact that the Finnish Prop7 Semantic F-score CoNLL’09 best </context>
<context position="30812" citStr="Zhao et al., 2009" startWordPosition="5096" endWordPosition="5099"> top of the SD scheme, while the English PropBank and NomBank corpora were not. 7 Related work While different methods have been studied to build task specific vector space representations, post-hoc methods to manipulate the vector spaces without retraining are rare. Current SRL systems utilize supervised machine learning approaches, and typically a large set of features. For instance, the winning system in the CoNLL’09 shared task (SRL-only) introduces a heavy feature engineering system, which has about 1000 potential feature templates from which the system discovers the best set to be used (Zhao et al., 2009b). Word similarities are usually introduced to SRL as a part of unsupervised or semi-supervised methods. For example, Titov and Klementiev (2012) present an unsupervised clustering method applying word representation techniques, and Deschacht and Moens (2009) used vector similarities to automatically expand the small training set to build semi-supervised SRL system. Additionally, Turian et al. (2010) have shown that word representations can be included among the features to improve the performance of named entity recognition and chunking systems. 8 Conclusions We set out to test two post-hoc </context>
</contexts>
<marker>Zhao, Chen, Kit, Zhou, 2009</marker>
<rawString>Hai Zhao, Wenliang Chen, Chunyu Kit, and Guodong Zhou. 2009b. Multilingual dependency learning: a huge feature engineering method to semantic dependency parsing. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 55–60. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>