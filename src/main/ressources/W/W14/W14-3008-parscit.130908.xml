<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020042">
<title confidence="0.979302">
Using Frame Semantics in Natural Language Processing
</title>
<author confidence="0.991492">
Apoorv Agarwal
</author>
<affiliation confidence="0.9963775">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.9737">
New York, NY
</address>
<email confidence="0.999116">
apoorv@cs.columbia.edu
</email>
<author confidence="0.99653">
Daniel Bauer
</author>
<affiliation confidence="0.996426">
Dept. of Computer Science
Columbia University
</affiliation>
<address confidence="0.973707">
New York, NY
</address>
<email confidence="0.999096">
bauer@cs.columbia.edu
</email>
<author confidence="0.979571">
Owen Rambow
</author>
<affiliation confidence="0.9684565">
CCLS
Columbia University
</affiliation>
<address confidence="0.970072">
New York, NY
</address>
<email confidence="0.99935">
rambow@ccls.columbia.edu
</email>
<sectionHeader confidence="0.993913" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999848333333333">
We summarize our experience using
FrameNet in two rather different projects
in natural language processing (NLP).
We conclude that NLP can benefit from
FrameNet in different ways, but we sketch
some problems that need to be overcome.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999987518518518">
We present two projects at Columbia in which we
use FrameNet. In these projects, we do not de-
velop basic NLP tools for FrameNet, and we do
not develop FramNets for new languages: we sim-
ply use FrameNet or a FrameNet parser in an NLP
application. The first application concerns the ex-
traction of social networks from narrative texts.
The second application aims at generating three-
dimensional pictures from textual descriptions.
The applications are very different: they differ
in terms of their goals, and they differ in terms
of how they use FrameNet. However, they have
in common that they can use FrameNet because it
provides a particular level of semantic abstraction
which is suited for both applications. Consider
verbs of saying, such as declare, deny, mention,
remark, tell, or say: they do not have the same
meaning. However, they share enough common
meaning, and in particular they share the same set
of participants, so that for our two applications
they can be considered as interchangeable: they
represent the communication of verbal informa-
tion (the Message) from a Speaker to an Ad-
dressee. This is precisely what the Statement
frame encodes. We will use this example in the
next two sections, in which we discuss our two
projects in more detail.
</bodyText>
<sectionHeader confidence="0.66166" genericHeader="method">
2 Using an Off-the-Shelf FrameNet
Parser
</sectionHeader>
<bodyText confidence="0.998680179487179">
Our first application is SINNET, a system that ex-
tracts a social network from narrative text. It uses
the notion of a social event (Agarwal et al., 2010),
a particular kind of event which involves (at least)
two people such that at least one of them is aware
of the other person. If only one person is aware
of the event, we call it Observation (OBS): for
example, someone is talking about someone else
in their absence. If both people are aware of the
event, we call it Interaction (INR): for example,
one person is telling the other a story. Our claim
is that links in social networks are in fact made
up of social events: OBS social events give rise
to one-way links, and INR social events to two-
way links. For more information, see (Agarwal
and Rambow, 2010; Agarwal et al., 2013a; Agar-
wal et al., 2013b).
From an NLP point of view, we have a difficult
cluster of phenomena: we have a precise defini-
tion of what we want to find, but it is based on the
cognitive state of the event participants, which is
almost never described explicitly in the text. Fur-
thermore, the definitions cover a large number of
diverse situations such as talking, spying, having
lunch, fist fighting, or kissing. Furthermore, some
semantic differences are not relevant: verbs such
as talk, tell, deny, all have the same meaning with
respect to social events. Finally, in order to de-
code the events in terms of social events, we need
to understand the roles: if I am talking to Sudeep
about Mae, Sudeep and I have an INR social event
with each other, and we both have a OBS social
event with Mae. Thus, this problem sounds like
an excellent application for frame semantics!
We present initial results in (Agarwal et al.,
2014), and summarize them here. We use Semafor
(Chen et al., 2010) as a black box to obtain the se-
mantic parse of a sentence. However, there are
several problems:
</bodyText>
<listItem confidence="0.999941333333333">
• FrameNet does not yet have complete lexical
coverage.
• Semafor does not produce a single semantic
</listItem>
<page confidence="0.939727">
30
</page>
<subsubsectionHeader confidence="0.393373">
Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 30–33,
</subsubsectionHeader>
<bodyText confidence="0.923688588235294">
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
representation for a sentence, as we would
want in order to perform subsequent process-
ing. Instead, it annotates separate, discon-
nected frame structures for each frame evok-
ing element it finds.
• The data annotated with FrameNet consists
of the example sentences as well as a compar-
atively small corpus. For this reason, it is not
easy to use standard machine learning tech-
niques for frame semantic parsing. As a re-
sult, the output is fairly errorful (as compared
to, say, a state-of-the-art dependency parser
trained on nearly a million annotated words).
Errors include mislabeled frames, mislabeled
frame elements, and missing frame elements.
To overcome these problems, we constructed
several tree representations out of the partial an-
notations returned by Semafor. We then used tree
kernels on these syntactic and semantic tree rep-
resentations, as well as bags of words. The tree
kernels can automatically identify important sub-
structures in the syntactic and semantic trees with-
out the need for feature engineering on our part.
Our hypothesis is that the kernels can learn which
parts of the semantic structures are reliable and
can be used for prediction.
The tree structures are shown in Figure 1. The
structure on the left (FrameForest) is created by
taking all identified instances of frames, and col-
lecting them under a common root node. The
frame elements are filled in with dependency syn-
tax. The structure on the right (FrameTree) is our
attempt to create a single arborescent structure to
capture the semantics of the whole sentence. Our
third structure, FrameTreeProp (not shown), is de-
rived from FrameTree by multiplying the nodes of
interest up the path from their normal place to the
root. This allows us to overcome problems with
the limited locality of the tree kernels.
We present some results in Table 1. Compar-
ing lines “Syntax” with “Synt FrameTreeProp”,
we see a slight but statistically significant increase.
This increase comes from using FrameNet seman-
tics. When we look at only the semantic structures,
we see that they all perform worse than syntax on
its own. “BOF” is simply a bag of frames; we
see that the arborescent structures outperform it,
so semantic structure is useful in addition to se-
mantic tags. “RULES” is a comprehensive set of
hand-written rules we attached to frames; if frame
</bodyText>
<table confidence="0.9998688">
Detection
Model P R F1
Syntax 0.464 0.751 0.574
RULES 0.508 0.097 0.164
BOF 0.296 0.416 0.346
FrameForest 0.331 0.594 0.425
FrameTree 0.295 0.594 0.395
FrameTreeProp 0.308 0.554 0.396
All 0.494 0.641 0.558
Synt FrameTreeProp 0.484 0.740 0.585
</table>
<tableCaption confidence="0.996287">
Table 1: Results for Social Event Detection.
</tableCaption>
<bodyText confidence="0.991666037037037">
“Syntax” is an optimized model using various
syntactic representations (Agarwal and Rambow,
2010). The next five models are the novel se-
mantic features and structures. “All” refers to the
model that uses all the listed structures together.
“Synt FrameTreeProp” is a linear combination of
“Syntax” and FrameTreeProp.
semantic parsing were perfect, these rules should
perform pretty well. They do in fact achieve the
best precision of all our systems, but the recall is
so low that overall they are not useful. We inter-
pret this result as supporting our claim that part of
the problem with using frame-semantic parsers is
the high error rate.
Even though the gain so far from frame seman-
tic parsing is small, we are encouraged by the fact
that an off-the-shelf semantic parser can help at
all. We are currently exploring other semantic
structures we can create from the semantic parse,
including structures which are dags rather than
trees. We would like to point out that the com-
bination of the parser, the creation of our seman-
tic trees, and the training with tree kernels can be
applied to any other problem that is sensitive to
the meaning of text. Based on our experience, we
expect to see an increase in “black box” uses of
FrameNet parsing for other applications in NLP.
</bodyText>
<sectionHeader confidence="0.993026" genericHeader="method">
3 Extending the FrameNet Resource
</sectionHeader>
<bodyText confidence="0.99966375">
FrameNet can be a useful starting point for a richer
knowledge representation which is needed for a
specific task. In our example, we need a repre-
sentation that we can use in the WordsEye project
(Coyne and Sproat, 2001), in which pictures are
created automatically from text descriptions. This
can be understood as providing a particular type
of decompositional semantics for the input text.
</bodyText>
<page confidence="0.999658">
31
</page>
<figure confidence="0.999356157894737">
ROOT Statement
Target
claimed
Speaker
T1’-Ind
Message
A
Speaker
T1-Ind
Coleman
Message
Commerce buy
Buyer Seller
T1’-Ind T2-Grp
he defendants
Target Buyer Seller
A T1-Ind from
T2-Grp
Commerce buy Statement
</figure>
<figureCaption confidence="0.999818">
Figure 1: Semantic trees for the sentence “Coleman claimed [he]T1−Ind bought drugs from the
</figureCaption>
<bodyText confidence="0.984741154929577">
[defendants]T2−Grp.”. The tree on the left is FrameForest and the tree on the right is FrameTree. A
in FrameForest refers to the subtree (bought (T1-Ind) (from T2-Grp)). Ind refers to individual and Grp
refers to group.
We extend FrameNet in two ways to obtain the re-
source we need, which we call VigNet (Coyne et
al., 2011).
The pictures created by the WordsEye system
are based on spatial arrangements (scenes) of pre-
defined 3D models. At a low level, scenes are de-
scribed by primitive spatial relations between sets
of these models (The man is in front of the woman.
He is looking at her. His mouth is open.). We
would like to use WordsEye to depict scenarios,
events, and actions (John told Mary his life story).
These can be seen as complex relations between
event participants.
We turn to FrameNet frames as representations
for such relations. FrameNet offers a large in-
ventory of frames, together with additional struc-
tured information about them in the form of frame
relations. Most importantly, FrameNet provides
example annotations illustrating the patterns in
which frames are evoked and syntactic arguments
are mapped to frame elements.
However, there are two main problems if we
want to turn frame annotations into pictures. First,
in frame annotations frame elements are only filled
with text spans, not with semantic objects. Anno-
tations are therefore restricted to individual predi-
cate/argument structures and do not represent the
meaning of a full sentence. To address this prob-
lem we essentially use FrameNet frames as an in-
ventory of predicates in a graph-based semantic
representation. We use semantic nodes, which are
identifiers representing events and entities that fill
frame elements. Frame instances then describe re-
lations between these semantic nodes, building a
graph structure that can represent a full text frag-
ment (including coreference). We are planning
to develop parsers that convert text directly into
such graph-based representations, inspired by re-
cent work on semantic parsing (Jones et al., 2012).
Second, FrameNet frames usually describe
functional relationships between frame elements,
not graphical ones. To turn a frame into its graphi-
cal representation we therefore need (a) a set of of
graphical frames and a formal way of decompos-
ing these frames into primitives and (b) a mech-
anism for relating FrameNet frames to graphi-
cal frames. Our solution is VigNet (Coyne et
al., 2011), an extension of FrameNet. VigNet
makes use of existing frame-to-frame relations
to extend FrameNet with a number of graphical
frames called Vignettes. Vignettes are subframes
of FrameNet frames, each representing a specific
way in which a frame can be realized based on the
specific lexical unit or on context. For instance,
a proper visualization of the INGESTION frame
will depend on the INGESTOR (human vs. ani-
mals of different sizes), the INGESTIBLE (differ-
ent types of foods and drinks are ingested accord-
ing to different social conventions, each a differ-
ent Vignette). Note however, that many FrameNet
frames provide useful abstractions that allow us
to use a single Vignette as a good default visu-
alization for the entire frame. For instance, all
lexical units in the STATEMENT frame can be de-
picted as the SPEAKER standing opposite of the
ADDRESSEE with an open mouth.
A new frame-to-frame relation, called subframe
parallel, is used to decompose a Vignette into
</bodyText>
<page confidence="0.998183">
32
</page>
<bodyText confidence="0.999944344827586">
graphical sub-relations, which are in turn frames
(either graphical primitives or other vignettes).
Like any frame-to-frame relation, it maps frame
elements of the source frame to frame elements
of the target frame. New frame elements can also
be introduced. For instance, one Vignette for IN-
GESTION that can be used if the INGESTIBLE is a
liquid contains a new frame element CONTAINER.
The INGESTOR is holding the container and the
liquid is in the container.
We have populated the VigNet resource us-
ing a number of different approaches (Coyne et
al., 2012), including multiple choice questions on
Amazon Mechanical Turk to define vignettes for
locations (rooms), using the system itself to define
locations, and a number of web-based annotation
tools to define vignettes for actions.
An ongoing project is exploring the use of
WordsEye and VigNet as a tool for field linguists
and for language documentation and preserva-
tion. The WordsEye Linguistics Toolkit (WELT,
(Ulinski et al., 2014)) makes it easy to produce
pictures for field linguistic elicitation. It will
also provide an environment to essentially de-
velop language specific VigNets as models of the
syntax/semantics interface and conceptual cate-
gories. This work may be relevant to other projects
that aim to build non-English and multi-lingual
FrameNets.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999905">
We have tried to motivate the claim that FrameNet
provides the right layer of semantic abstraction
for many NLP applications by summarizing two
ongoing NLP projects at Columbia. We have
also suggested that part of the problem in using
FrameNet in NLP projects is the lack of a single
structure that is produced, either in manual anno-
tations, or in the output of a FrameNet parser. We
suspect that research into how to construct such
unified semantic representations will continue to
be a major component of the use of FrameNet in
NLP.
</bodyText>
<sectionHeader confidence="0.99829" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997855">
This paper is based upon work supported in part by
the NSF (grants IIS-0713548 and IIS-0904361),
and by the DARPA DEFT Program. We thank
our collaborators on the two projects used as ex-
amples in this extended abstract. We thank Chuck
Fillmore for FrameNet.
</bodyText>
<sectionHeader confidence="0.989403" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998449452830189">
Apoorv Agarwal and Owen Rambow. 2010. Automatic de-
tection and classification of social events. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1024–1034, Cambridge,
MA, October. Association for Computational Linguistics.
Apoorv Agarwal, Owen C. Rambow, and Rebecca J. Passon-
neau. 2010. Annotation scheme for social network ex-
traction from text. In Proceedings of the Fourth Linguistic
Annotation Workshop.
Apoorv Agarwal, Anup Kotalwar, and Owen Rambow.
2013a. Automatic extraction of social networks from lit-
erary text: A case study on alice in wonderland. In the
Proceedings of the 6th International Joint Conference on
Natural Language Processing (IJCNLP 2013).
Apoorv Agarwal, Anup Kotalwar, Jiehan Zheng, and Owen
Rambow. 2013b. Sinnet: Social interaction network ex-
tractor from text. In Sixth International Joint Conference
on Natural Language Processing, page 33.
Apoorv Agarwal, Sriramkumar Balasubramanian, Anup Ko-
talwar, Jiehan Zheng, and Owen Rambow. 2014. Frame
semantic tree kernels for social network extraction from
text. In Proceedings of the 14th Conference of the Euro-
pean Chapter of the Association for Computational Lin-
guistics, Gothenburg, Sweden.
Desai Chen, Nathan Schneider, Dipanjan Das, and Noah A.
Smith. 2010. Semafor: Frame argument resolution with
log-linear models. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 264–267, Up-
psala, Sweden, July. Association for Computational Lin-
guistics.
Bob Coyne and Richard Sproat. 2001. Wordseye: an au-
tomatic text-to-scene conversion system. In 28th annual
conference on Computer graphics and interactive tech-
niques.
Bob Coyne, Daniel Bauer, and Owen Rambow. 2011. Vi-
gnet: Grounding language in graphics using frame seman-
tics. In ACL Workshop on Relational Semantics (RELMS),
Portland, Oregon.
Bob Coyne, Alex Klapheke, Masoud Rouhizadeh, Richard
Sproat, and Daniel Bauer. 2012. Annotation tools and
knowledge representation for a text-to-scene system. In
COLING, Mumbai, India.
Bevan Jones, Jacob Andreas*, Daniel Bauer*, Karl Moritz
Hermann*, and Kevin Knight. 2012. Semantics-based
machine translation with hyperedge replacement gram-
mars. In COLING, Mumbai, India. *first authorship
shared.
Morgan Ulinski, Anusha Balakrishnan, Daniel Bauer, Bob
Coyne, Julia Hirschberg, and Owen Rambow. 2014. Doc-
umenting endangered languages with the wordseye lin-
guistics tool. In Proceedings of the ACL ComputEL work-
shop: The use of computational methods in the study of
endangered languages, Baltimore, MD, USA.
</reference>
<page confidence="0.999369">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.167659">
<title confidence="0.999866">Using Frame Semantics in Natural Language Processing</title>
<author confidence="0.659104">Apoorv</author>
<affiliation confidence="0.998273">Dept. of Computer</affiliation>
<address confidence="0.8171855">Columbia New York, NY</address>
<email confidence="0.998973">apoorv@cs.columbia.edu</email>
<author confidence="0.915938">Daniel</author>
<affiliation confidence="0.99996">Dept. of Computer</affiliation>
<address confidence="0.8230625">Columbia New York, NY</address>
<email confidence="0.999457">bauer@cs.columbia.edu</email>
<author confidence="0.851331">Owen</author>
<affiliation confidence="0.758844">Columbia</affiliation>
<address confidence="0.902702">New York, NY</address>
<email confidence="0.999647">rambow@ccls.columbia.edu</email>
<abstract confidence="0.999227714285714">We summarize our experience using FrameNet in two rather different projects in natural language processing (NLP). We conclude that NLP can benefit from FrameNet in different ways, but we sketch some problems that need to be overcome.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Owen Rambow</author>
</authors>
<title>Automatic detection and classification of social events.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1024--1034</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="2640" citStr="Agarwal and Rambow, 2010" startWordPosition="433" endWordPosition="436">al et al., 2010), a particular kind of event which involves (at least) two people such that at least one of them is aware of the other person. If only one person is aware of the event, we call it Observation (OBS): for example, someone is talking about someone else in their absence. If both people are aware of the event, we call it Interaction (INR): for example, one person is telling the other a story. Our claim is that links in social networks are in fact made up of social events: OBS social events give rise to one-way links, and INR social events to twoway links. For more information, see (Agarwal and Rambow, 2010; Agarwal et al., 2013a; Agarwal et al., 2013b). From an NLP point of view, we have a difficult cluster of phenomena: we have a precise definition of what we want to find, but it is based on the cognitive state of the event participants, which is almost never described explicitly in the text. Furthermore, the definitions cover a large number of diverse situations such as talking, spying, having lunch, fist fighting, or kissing. Furthermore, some semantic differences are not relevant: verbs such as talk, tell, deny, all have the same meaning with respect to social events. Finally, in order to d</context>
<context position="6748" citStr="Agarwal and Rambow, 2010" startWordPosition="1115" endWordPosition="1118"> own. “BOF” is simply a bag of frames; we see that the arborescent structures outperform it, so semantic structure is useful in addition to semantic tags. “RULES” is a comprehensive set of hand-written rules we attached to frames; if frame Detection Model P R F1 Syntax 0.464 0.751 0.574 RULES 0.508 0.097 0.164 BOF 0.296 0.416 0.346 FrameForest 0.331 0.594 0.425 FrameTree 0.295 0.594 0.395 FrameTreeProp 0.308 0.554 0.396 All 0.494 0.641 0.558 Synt FrameTreeProp 0.484 0.740 0.585 Table 1: Results for Social Event Detection. “Syntax” is an optimized model using various syntactic representations (Agarwal and Rambow, 2010). The next five models are the novel semantic features and structures. “All” refers to the model that uses all the listed structures together. “Synt FrameTreeProp” is a linear combination of “Syntax” and FrameTreeProp. semantic parsing were perfect, these rules should perform pretty well. They do in fact achieve the best precision of all our systems, but the recall is so low that overall they are not useful. We interpret this result as supporting our claim that part of the problem with using frame-semantic parsers is the high error rate. Even though the gain so far from frame semantic parsing </context>
</contexts>
<marker>Agarwal, Rambow, 2010</marker>
<rawString>Apoorv Agarwal and Owen Rambow. 2010. Automatic detection and classification of social events. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1024–1034, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Owen C Rambow</author>
<author>Rebecca J Passonneau</author>
</authors>
<title>Annotation scheme for social network extraction from text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth Linguistic Annotation Workshop.</booktitle>
<contexts>
<context position="2032" citStr="Agarwal et al., 2010" startWordPosition="321" endWordPosition="324"> they share enough common meaning, and in particular they share the same set of participants, so that for our two applications they can be considered as interchangeable: they represent the communication of verbal information (the Message) from a Speaker to an Addressee. This is precisely what the Statement frame encodes. We will use this example in the next two sections, in which we discuss our two projects in more detail. 2 Using an Off-the-Shelf FrameNet Parser Our first application is SINNET, a system that extracts a social network from narrative text. It uses the notion of a social event (Agarwal et al., 2010), a particular kind of event which involves (at least) two people such that at least one of them is aware of the other person. If only one person is aware of the event, we call it Observation (OBS): for example, someone is talking about someone else in their absence. If both people are aware of the event, we call it Interaction (INR): for example, one person is telling the other a story. Our claim is that links in social networks are in fact made up of social events: OBS social events give rise to one-way links, and INR social events to twoway links. For more information, see (Agarwal and Ramb</context>
</contexts>
<marker>Agarwal, Rambow, Passonneau, 2010</marker>
<rawString>Apoorv Agarwal, Owen C. Rambow, and Rebecca J. Passonneau. 2010. Annotation scheme for social network extraction from text. In Proceedings of the Fourth Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Anup Kotalwar</author>
<author>Owen Rambow</author>
</authors>
<title>Automatic extraction of social networks from literary text: A case study on alice in wonderland.</title>
<date>2013</date>
<booktitle>In the Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<contexts>
<context position="2662" citStr="Agarwal et al., 2013" startWordPosition="437" endWordPosition="440">ular kind of event which involves (at least) two people such that at least one of them is aware of the other person. If only one person is aware of the event, we call it Observation (OBS): for example, someone is talking about someone else in their absence. If both people are aware of the event, we call it Interaction (INR): for example, one person is telling the other a story. Our claim is that links in social networks are in fact made up of social events: OBS social events give rise to one-way links, and INR social events to twoway links. For more information, see (Agarwal and Rambow, 2010; Agarwal et al., 2013a; Agarwal et al., 2013b). From an NLP point of view, we have a difficult cluster of phenomena: we have a precise definition of what we want to find, but it is based on the cognitive state of the event participants, which is almost never described explicitly in the text. Furthermore, the definitions cover a large number of diverse situations such as talking, spying, having lunch, fist fighting, or kissing. Furthermore, some semantic differences are not relevant: verbs such as talk, tell, deny, all have the same meaning with respect to social events. Finally, in order to decode the events in te</context>
</contexts>
<marker>Agarwal, Kotalwar, Rambow, 2013</marker>
<rawString>Apoorv Agarwal, Anup Kotalwar, and Owen Rambow. 2013a. Automatic extraction of social networks from literary text: A case study on alice in wonderland. In the Proceedings of the 6th International Joint Conference on Natural Language Processing (IJCNLP 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Anup Kotalwar</author>
<author>Jiehan Zheng</author>
<author>Owen Rambow</author>
</authors>
<title>Sinnet: Social interaction network extractor from text.</title>
<date>2013</date>
<booktitle>In Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>33</pages>
<contexts>
<context position="2662" citStr="Agarwal et al., 2013" startWordPosition="437" endWordPosition="440">ular kind of event which involves (at least) two people such that at least one of them is aware of the other person. If only one person is aware of the event, we call it Observation (OBS): for example, someone is talking about someone else in their absence. If both people are aware of the event, we call it Interaction (INR): for example, one person is telling the other a story. Our claim is that links in social networks are in fact made up of social events: OBS social events give rise to one-way links, and INR social events to twoway links. For more information, see (Agarwal and Rambow, 2010; Agarwal et al., 2013a; Agarwal et al., 2013b). From an NLP point of view, we have a difficult cluster of phenomena: we have a precise definition of what we want to find, but it is based on the cognitive state of the event participants, which is almost never described explicitly in the text. Furthermore, the definitions cover a large number of diverse situations such as talking, spying, having lunch, fist fighting, or kissing. Furthermore, some semantic differences are not relevant: verbs such as talk, tell, deny, all have the same meaning with respect to social events. Finally, in order to decode the events in te</context>
</contexts>
<marker>Agarwal, Kotalwar, Zheng, Rambow, 2013</marker>
<rawString>Apoorv Agarwal, Anup Kotalwar, Jiehan Zheng, and Owen Rambow. 2013b. Sinnet: Social interaction network extractor from text. In Sixth International Joint Conference on Natural Language Processing, page 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Sriramkumar Balasubramanian</author>
<author>Anup Kotalwar</author>
<author>Jiehan Zheng</author>
<author>Owen Rambow</author>
</authors>
<title>Frame semantic tree kernels for social network extraction from text.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<location>Gothenburg,</location>
<contexts>
<context position="3584" citStr="Agarwal et al., 2014" startWordPosition="600" endWordPosition="603">cover a large number of diverse situations such as talking, spying, having lunch, fist fighting, or kissing. Furthermore, some semantic differences are not relevant: verbs such as talk, tell, deny, all have the same meaning with respect to social events. Finally, in order to decode the events in terms of social events, we need to understand the roles: if I am talking to Sudeep about Mae, Sudeep and I have an INR social event with each other, and we both have a OBS social event with Mae. Thus, this problem sounds like an excellent application for frame semantics! We present initial results in (Agarwal et al., 2014), and summarize them here. We use Semafor (Chen et al., 2010) as a black box to obtain the semantic parse of a sentence. However, there are several problems: • FrameNet does not yet have complete lexical coverage. • Semafor does not produce a single semantic 30 Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 30–33, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics representation for a sentence, as we would want in order to perform subsequent processing. Instead, it annotates separate, disconnected frame stru</context>
</contexts>
<marker>Agarwal, Balasubramanian, Kotalwar, Zheng, Rambow, 2014</marker>
<rawString>Apoorv Agarwal, Sriramkumar Balasubramanian, Anup Kotalwar, Jiehan Zheng, and Owen Rambow. 2014. Frame semantic tree kernels for social network extraction from text. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Desai Chen</author>
<author>Nathan Schneider</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
</authors>
<title>Semafor: Frame argument resolution with log-linear models.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>264--267</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="3645" citStr="Chen et al., 2010" startWordPosition="611" endWordPosition="614">ng, having lunch, fist fighting, or kissing. Furthermore, some semantic differences are not relevant: verbs such as talk, tell, deny, all have the same meaning with respect to social events. Finally, in order to decode the events in terms of social events, we need to understand the roles: if I am talking to Sudeep about Mae, Sudeep and I have an INR social event with each other, and we both have a OBS social event with Mae. Thus, this problem sounds like an excellent application for frame semantics! We present initial results in (Agarwal et al., 2014), and summarize them here. We use Semafor (Chen et al., 2010) as a black box to obtain the semantic parse of a sentence. However, there are several problems: • FrameNet does not yet have complete lexical coverage. • Semafor does not produce a single semantic 30 Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 30–33, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics representation for a sentence, as we would want in order to perform subsequent processing. Instead, it annotates separate, disconnected frame structures for each frame evoking element it finds. • The data an</context>
</contexts>
<marker>Chen, Schneider, Das, Smith, 2010</marker>
<rawString>Desai Chen, Nathan Schneider, Dipanjan Das, and Noah A. Smith. 2010. Semafor: Frame argument resolution with log-linear models. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 264–267, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Richard Sproat</author>
</authors>
<title>Wordseye: an automatic text-to-scene conversion system.</title>
<date>2001</date>
<booktitle>In 28th annual conference on Computer graphics and interactive techniques.</booktitle>
<contexts>
<context position="8181" citStr="Coyne and Sproat, 2001" startWordPosition="1363" endWordPosition="1366">ich are dags rather than trees. We would like to point out that the combination of the parser, the creation of our semantic trees, and the training with tree kernels can be applied to any other problem that is sensitive to the meaning of text. Based on our experience, we expect to see an increase in “black box” uses of FrameNet parsing for other applications in NLP. 3 Extending the FrameNet Resource FrameNet can be a useful starting point for a richer knowledge representation which is needed for a specific task. In our example, we need a representation that we can use in the WordsEye project (Coyne and Sproat, 2001), in which pictures are created automatically from text descriptions. This can be understood as providing a particular type of decompositional semantics for the input text. 31 ROOT Statement Target claimed Speaker T1’-Ind Message A Speaker T1-Ind Coleman Message Commerce buy Buyer Seller T1’-Ind T2-Grp he defendants Target Buyer Seller A T1-Ind from T2-Grp Commerce buy Statement Figure 1: Semantic trees for the sentence “Coleman claimed [he]T1−Ind bought drugs from the [defendants]T2−Grp.”. The tree on the left is FrameForest and the tree on the right is FrameTree. A in FrameForest refers to t</context>
</contexts>
<marker>Coyne, Sproat, 2001</marker>
<rawString>Bob Coyne and Richard Sproat. 2001. Wordseye: an automatic text-to-scene conversion system. In 28th annual conference on Computer graphics and interactive techniques.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Daniel Bauer</author>
<author>Owen Rambow</author>
</authors>
<title>Vignet: Grounding language in graphics using frame semantics.</title>
<date>2011</date>
<booktitle>In ACL Workshop on Relational Semantics (RELMS),</booktitle>
<location>Portland, Oregon.</location>
<contexts>
<context position="8979" citStr="Coyne et al., 2011" startWordPosition="1490" endWordPosition="1493">T Statement Target claimed Speaker T1’-Ind Message A Speaker T1-Ind Coleman Message Commerce buy Buyer Seller T1’-Ind T2-Grp he defendants Target Buyer Seller A T1-Ind from T2-Grp Commerce buy Statement Figure 1: Semantic trees for the sentence “Coleman claimed [he]T1−Ind bought drugs from the [defendants]T2−Grp.”. The tree on the left is FrameForest and the tree on the right is FrameTree. A in FrameForest refers to the subtree (bought (T1-Ind) (from T2-Grp)). Ind refers to individual and Grp refers to group. We extend FrameNet in two ways to obtain the resource we need, which we call VigNet (Coyne et al., 2011). The pictures created by the WordsEye system are based on spatial arrangements (scenes) of predefined 3D models. At a low level, scenes are described by primitive spatial relations between sets of these models (The man is in front of the woman. He is looking at her. His mouth is open.). We would like to use WordsEye to depict scenarios, events, and actions (John told Mary his life story). These can be seen as complex relations between event participants. We turn to FrameNet frames as representations for such relations. FrameNet offers a large inventory of frames, together with additional stru</context>
<context position="11079" citStr="Coyne et al., 2011" startWordPosition="1825" endWordPosition="1828">e that can represent a full text fragment (including coreference). We are planning to develop parsers that convert text directly into such graph-based representations, inspired by recent work on semantic parsing (Jones et al., 2012). Second, FrameNet frames usually describe functional relationships between frame elements, not graphical ones. To turn a frame into its graphical representation we therefore need (a) a set of of graphical frames and a formal way of decomposing these frames into primitives and (b) a mechanism for relating FrameNet frames to graphical frames. Our solution is VigNet (Coyne et al., 2011), an extension of FrameNet. VigNet makes use of existing frame-to-frame relations to extend FrameNet with a number of graphical frames called Vignettes. Vignettes are subframes of FrameNet frames, each representing a specific way in which a frame can be realized based on the specific lexical unit or on context. For instance, a proper visualization of the INGESTION frame will depend on the INGESTOR (human vs. animals of different sizes), the INGESTIBLE (different types of foods and drinks are ingested according to different social conventions, each a different Vignette). Note however, that many</context>
</contexts>
<marker>Coyne, Bauer, Rambow, 2011</marker>
<rawString>Bob Coyne, Daniel Bauer, and Owen Rambow. 2011. Vignet: Grounding language in graphics using frame semantics. In ACL Workshop on Relational Semantics (RELMS), Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Alex Klapheke</author>
<author>Masoud Rouhizadeh</author>
<author>Richard Sproat</author>
<author>Daniel Bauer</author>
</authors>
<title>Annotation tools and knowledge representation for a text-to-scene system.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<location>Mumbai, India.</location>
<contexts>
<context position="12613" citStr="Coyne et al., 2012" startWordPosition="2076" endWordPosition="2079">d subframe parallel, is used to decompose a Vignette into 32 graphical sub-relations, which are in turn frames (either graphical primitives or other vignettes). Like any frame-to-frame relation, it maps frame elements of the source frame to frame elements of the target frame. New frame elements can also be introduced. For instance, one Vignette for INGESTION that can be used if the INGESTIBLE is a liquid contains a new frame element CONTAINER. The INGESTOR is holding the container and the liquid is in the container. We have populated the VigNet resource using a number of different approaches (Coyne et al., 2012), including multiple choice questions on Amazon Mechanical Turk to define vignettes for locations (rooms), using the system itself to define locations, and a number of web-based annotation tools to define vignettes for actions. An ongoing project is exploring the use of WordsEye and VigNet as a tool for field linguists and for language documentation and preservation. The WordsEye Linguistics Toolkit (WELT, (Ulinski et al., 2014)) makes it easy to produce pictures for field linguistic elicitation. It will also provide an environment to essentially develop language specific VigNets as models of </context>
</contexts>
<marker>Coyne, Klapheke, Rouhizadeh, Sproat, Bauer, 2012</marker>
<rawString>Bob Coyne, Alex Klapheke, Masoud Rouhizadeh, Richard Sproat, and Daniel Bauer. 2012. Annotation tools and knowledge representation for a text-to-scene system. In COLING, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bevan Jones</author>
<author>Jacob Andreas</author>
<author>Daniel Bauer</author>
<author>Karl Moritz Hermann</author>
<author>Kevin Knight</author>
</authors>
<title>Semantics-based machine translation with hyperedge replacement grammars.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<location>Mumbai,</location>
<note>first authorship shared.</note>
<contexts>
<context position="10692" citStr="Jones et al., 2012" startWordPosition="1761" endWordPosition="1764">res and do not represent the meaning of a full sentence. To address this problem we essentially use FrameNet frames as an inventory of predicates in a graph-based semantic representation. We use semantic nodes, which are identifiers representing events and entities that fill frame elements. Frame instances then describe relations between these semantic nodes, building a graph structure that can represent a full text fragment (including coreference). We are planning to develop parsers that convert text directly into such graph-based representations, inspired by recent work on semantic parsing (Jones et al., 2012). Second, FrameNet frames usually describe functional relationships between frame elements, not graphical ones. To turn a frame into its graphical representation we therefore need (a) a set of of graphical frames and a formal way of decomposing these frames into primitives and (b) a mechanism for relating FrameNet frames to graphical frames. Our solution is VigNet (Coyne et al., 2011), an extension of FrameNet. VigNet makes use of existing frame-to-frame relations to extend FrameNet with a number of graphical frames called Vignettes. Vignettes are subframes of FrameNet frames, each representin</context>
</contexts>
<marker>Jones, Andreas, Bauer, Hermann, Knight, 2012</marker>
<rawString>Bevan Jones, Jacob Andreas*, Daniel Bauer*, Karl Moritz Hermann*, and Kevin Knight. 2012. Semantics-based machine translation with hyperedge replacement grammars. In COLING, Mumbai, India. *first authorship shared.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morgan Ulinski</author>
<author>Anusha Balakrishnan</author>
<author>Daniel Bauer</author>
<author>Bob Coyne</author>
<author>Julia Hirschberg</author>
<author>Owen Rambow</author>
</authors>
<title>Documenting endangered languages with the wordseye linguistics tool.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACL ComputEL workshop: The use of computational methods in the</booktitle>
<location>Baltimore, MD, USA.</location>
<contexts>
<context position="13045" citStr="Ulinski et al., 2014" startWordPosition="2142" endWordPosition="2145">lement CONTAINER. The INGESTOR is holding the container and the liquid is in the container. We have populated the VigNet resource using a number of different approaches (Coyne et al., 2012), including multiple choice questions on Amazon Mechanical Turk to define vignettes for locations (rooms), using the system itself to define locations, and a number of web-based annotation tools to define vignettes for actions. An ongoing project is exploring the use of WordsEye and VigNet as a tool for field linguists and for language documentation and preservation. The WordsEye Linguistics Toolkit (WELT, (Ulinski et al., 2014)) makes it easy to produce pictures for field linguistic elicitation. It will also provide an environment to essentially develop language specific VigNets as models of the syntax/semantics interface and conceptual categories. This work may be relevant to other projects that aim to build non-English and multi-lingual FrameNets. 4 Conclusion We have tried to motivate the claim that FrameNet provides the right layer of semantic abstraction for many NLP applications by summarizing two ongoing NLP projects at Columbia. We have also suggested that part of the problem in using FrameNet in NLP project</context>
</contexts>
<marker>Ulinski, Balakrishnan, Bauer, Coyne, Hirschberg, Rambow, 2014</marker>
<rawString>Morgan Ulinski, Anusha Balakrishnan, Daniel Bauer, Bob Coyne, Julia Hirschberg, and Owen Rambow. 2014. Documenting endangered languages with the wordseye linguistics tool. In Proceedings of the ACL ComputEL workshop: The use of computational methods in the study of endangered languages, Baltimore, MD, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>