<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9924355">
An approach to measure pronunciation similarity in second
language learning using radial basis function kernel
</title>
<author confidence="0.994889">
Christos Koniaris
</author>
<affiliation confidence="0.993315">
University of Gothenburg, Centre for Language Technology
Department of Philosophy, Linguistics and Theory of Science
Dialogue Technology Lab, Gothenburg, Sweden
</affiliation>
<email confidence="0.99123">
christos.koniaris@gu.se
</email>
<sectionHeader confidence="0.995093" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999641727272727">
This paper shows a method to diagnose potential mispronunciations in second language learning
by studying the characteristics of the speech produced by a group of native speakers and the
speech produced by various non-native groups of speakers from diverse language backgrounds.
The method compares the native auditory perception and the non-native spectral representation
on the phoneme level using similarity measures that are based on the radial basis function
kernel. A list of ordered problematic phonemes is found for each non-native group of speakers
and the results are analyzed based on a relevant linguistic survey found in the literature. The
experimental results indicate an agreement with linguistic findings of up to 80.8% for vowels
and 80.3% for consonants.
KEYWORDS: pronunciation error detection, similarity measure, radial basis function kernel,
phoneme, second language learning.
</bodyText>
<note confidence="0.286090666666667">
Christos Koniaris 2014. An approach to measure pronunciation similarity in second language learning
using radial basis function kernel. Proceedings of the third workshop on NLP for computer-assisted language learning.
NEALT Proceedings Series 22 / Linköping Electronic Conference Proceedings 107: 74–86.
</note>
<page confidence="0.998083">
74
</page>
<sectionHeader confidence="0.992881" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999984022727273">
Second language (L2) speakers are generally having trouble with certain phonemes of the target
language that do not exist in the sound system of their native language (Flege, 1995; Guion
et al., 2000). It is therefore common practice to include speech sounds from their first language
(L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within
a computer-assisted language learning (CALL) program, the task of automatic pronunciation
error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in
order to assist L2 learners to improve their oral capabilities.
In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for
performing automatic speech recognition (ASR) is turned into an automatic pronunciation
scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone
log-likelihood, are compared to human listeners’ evaluation. The experiments show that certain
scores, such as the log-posterior and the normalized duration correlate well with human ratings.
Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in
(Witt and Young, 2000), which measures the quality of pronunciations of non-native speakers.
The idea is to score each phone of an utterance depending on how close the pronunciation
of the non-native speaker is to that of native speakers. A method that combines knowledge
from acoustic-phonetic, linguistic, and from expert listeners is presented in (Park and Rhee,
2004), in which the analysis of the results is done by finding the correlation of human listeners
and machine-based rating. In (Truong et al., 2005), a set of classification approaches based on
linear discriminant analysis (LDA) and decision trees is presented. These classifiers are used
to analyze the mispronunciations of second language learners of Dutch. In (Tepperman and
Narayanan, 2008), the research is oriented in introducing articulatory information in PED by
reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan,
2005) and deriving new articulatory-based features for classification. In (Strik et al., 2009), four
different classification systems are examined: a GOP-based, one combining cepstral coefficients
and LDA, a method based on the work described in (Weigelt et al., 1990), which is an algorithm
that discriminates voiceless fricatives from voiceless plosives, and an LDA-acoustic-phonetic
feature classifier. It is found that the two LDA-based classification systems perform better in
mispronunciation detection. In (Wei et al., 2009), the authors use support vector machines
(SVM) to model phones with several parallel acoustic models that represent the variation in
pronunciation at various proficiency levels. This approach seems to achieve better results in
comparison to more traditional posterior probability based methods.
Since the pronunciation of a phone is not only related to its acoustics, aspects, such as fluency,
syllable structure, word stress, intonation, prosody or segmental quality may also be considered
for investigation of pronunciation errors. For example, the work that is presented in (Delmonte,
2000) concerns a prosodic module of a CALL system called SLIM. This module deals with
phonetic and prosodic problems both at the word but also at the segmental level. Prosodic
measures based on F0, power and duration of L2 and L1 speech are used in (Yamashita et al.,
2005) within a multiple regression framework to predict the prosodic proficiency of L2 learners.
In (Raux and Kawahara, 2002), a probabilistic algorithm is applied to derive intelligibility
from error rates and also define a function of error priority to indicate which errors are most
critical to intelligibility. Finally, in (Xu et al., 2009), linguistic knowledge obtained from the
non-native speakers’ most common mistakes, and pronunciation space constructed using revised
log-posterior probability vectors is considered along with an SVM classifier.
</bodyText>
<page confidence="0.997733">
75
</page>
<bodyText confidence="0.999985666666667">
In this paper, a PED method based on psychoacoustic knowledge from a spectral auditory
model (van de Par et al., 2002) is presented that models the native perception to evaluate
non-native pronunciations based on acoustic and auditory processing of the speech sounds. The
fundamental assumption is based on the ability of the human auditory system to distinguish
speech sounds of various type. The method compares the acoustic and auditory-perceptual
characteristics of uttered phones on a frame-by-frame basis. In doing so, it utilizes a similarity
measure based on radial basis function kernel or RBF kernel, which is compared with a
Euclidean distance measure that was used in (Koniaris and Engwall, 2011; Koniaris et al.,
2013). The motivation for this arrives from the fact that the data become sparse in a high
dimensional space and hence choosing RBF kernel seems a more suitable solution since it is
considered more appropriate for such conditions (Braun et al., 2008). Roughly speaking, the
method performs a comparison between speech sounds generated by a group of native speakers
with the corresponding speech sounds generated by different L2 groups of speakers. This is
done separately for each phoneme category and the uttered phones are transformed into their
auditory representations for the native speech, and into their spectrum representations for the
non-native speech. In each domain, a distortion measure based on the RBF kernel is computed
for each speech frame and then the two distortion measures are explored – considering all the
frames – to investigate, quantitatively, the similarities between the native and the non-native
phones.
The paper is organized as follows. Section 2 presents the method and implementation issues,
Section 3 discusses the experiments and the findings and finally Section 4 provides conclusions.
</bodyText>
<sectionHeader confidence="0.938008" genericHeader="introduction">
2 Method
</sectionHeader>
<bodyText confidence="0.999831411764706">
The underlying idea behind the pronunciation error detection method that is described here is
based on the auditory ability of a native speaker to discriminate the mispronounced phonemes
produced by L2 speakers while hearing them speaking. The diagnostic evaluation of the
pronunciation errors is done on the speech signal level by comparing the similarities between
the auditory perceptual domain of the native speech and the power spectrum domain of the
non-native speech. It is assumed that a non-native acoustic representation will have very similar
characteristics to native provided that the non-native speech is produced without significant
mispronunciation. On the other hand, if the non-native speech suffers from severe pronunciation
errors then the two representations, of the L2 and L1 speakers, will differ a lot and thus the
measured similarities will become minimal (Koniaris et al., 2013).
In short, the approach tries to measure the distortion in a set of phones that belong to a specific
phoneme, produced by a group of native speakers n and compare it to that of non-native
speakers of some specific language background ℓ. For this, it is assumed that some form of
acoustic representation x is extracted from the speech signal s of a phone p to evaluate the
distortion measure φ in the corresponding transformed domain, where φ : RN x RN — R+,
with R+ denoting the non-negative real numbers and N indicating the dimensionality of the
vector x. Then, the RBF kernel-based similarity measure is,
</bodyText>
<equation confidence="0.999436">
φ(si,ˆsi,j) = eγIIx(si)−x(ˆsi,j)II2, (1)
</equation>
<bodyText confidence="0.999684">
where i E Z is the index of the considered speech frame, ˆsi,j is the j’th perturbation of si that
is used to compute distortion and γ = − 1
2σ2 . It is noted that σ will determine the size of the
considered area around si. An analogous measure is defined for the auditory perception domain
where the speech signal is transformed into the auditory model output representation y. Again,
</bodyText>
<page confidence="0.971266">
76
</page>
<bodyText confidence="0.9954895">
a RBF kernel-based distortion measure is computed in the auditory domain υ : RM × RM → R+,
where M is the dimensionality of the internal representation y, as
</bodyText>
<equation confidence="0.997339">
υ(si,ˆsi,j) = eγky(si)−y(ˆsi,j)k2. (2)
</equation>
<bodyText confidence="0.997478">
The above distortion measures of Eqs. (1) and (2) are then compared using the following
similarity measure
</bodyText>
<equation confidence="0.978950666666667">
1 []2 ,
υ(si,ˆsi,j) − φ(si,ˆsi,j) (3)
Ji j∈Ji
</equation>
<bodyText confidence="0.999933333333333">
where i ∈ I and j ∈ Ji represent a finite frame sequence and a finite set of acoustic perturba-
tions, respectively. This measure is used to find mispronunciations as described in (Koniaris
et al., 2013), i.e., by computing the distortion measure υ(si,ˆsi,j) using only native speech
and the spectral distortion measure φ(si,ˆsi,j), calculated separately for non-native (and thus
computing Aℓ) and native speech (and thus computing An). Finally, the native-perceptual
assessment degree (nPAD) is computed for every phoneme and L1 background as
</bodyText>
<equation confidence="0.9444205">
nPAD = Aℓ ,(4)
An
</equation>
<bodyText confidence="0.999880333333333">
which is a normalized ratio that shows the degree of the similarity between the native perceptual
outcome and the non-native speech signal representation, as compared to the native-only case.
The higher the nPAD value is, the more problematic the L2 phoneme is.
</bodyText>
<subsectionHeader confidence="0.994962">
2.1 Practical implementation
</subsectionHeader>
<bodyText confidence="0.999805">
Considering p to be a phone that a speaker has produced, the speech power spectrum x(p) can
be seen simply as a function of p that maps this phone onto the spectral domain. If additionally
is considered a small area around p, a local approximation is possible using the Taylor series
expansion, thus
</bodyText>
<equation confidence="0.965928">
x(ˆp) ≈ x(p) + Jx[ˆp − p], (5)
</equation>
<bodyText confidence="0.97416">
where Jx = ∂ x(p)and pˆ is the perturbed phone. Assuming that the small distortion [ˆp − p]
</bodyText>
<subsectionHeader confidence="0.822779">
Lp
</subsectionHeader>
<bodyText confidence="0.9996506">
remains the same independently of the language background of the speaker, Eq. (5) can be used
either for native speech xn or non-native speech xℓ of a language background ℓ. This means
that is possible to find a linearized relation between these two and compute the speech power
spectrum distortion in a non-native subspace into the native speech power spectrum domain.
Thus,
</bodyText>
<equation confidence="0.99817">
xℓ(ˆp) ≈ xℓ(p) + Wℓ [xn(ˆp) − xn(p)], (6)
</equation>
<bodyText confidence="0.999766625">
where Wℓ = Jxℓ [Jxn]−1. Eq. (6) implies that a different Wℓ should be calculated for each frame.
However, the duration of phones or silence mismatches between the native and non-native
speech signal prevent such computation. In addition, the matrices are non-invertible. Therefore
the estimation of Wℓ is done by considering a common matrix for all frames i of a specific
L2 group of speakers ℓ. In speech processing is often assumed that a speech signal follows a
Gaussian distribution. Thus, Eq. (6) can be expressed as N (µℓ, Eℓ) ∼ N(Wℓ µn, Wℓ En [Wℓ]T ),
where µℓ, µn are the mean vectors of the distortion in non-native and native speech signals,
respectively and Eℓ, En their covariance matrices.
</bodyText>
<equation confidence="0.633142">
A=
1 �
I i∈I
</equation>
<page confidence="0.97098">
77
</page>
<bodyText confidence="0.9642505">
Considering a matrix decomposition (e.g., eigendecomposition), the two covariance matrices
can be expressed as
</bodyText>
<equation confidence="0.977991">
Eζ = Vζ Sζ [Vζ]T, (7)
</equation>
<bodyText confidence="0.9956255">
where ζ = n for the native language group, and ζ = ℓ for the non-native language group. Next,
assuming the following distributions
</bodyText>
<equation confidence="0.997288428571429">
Z ∼ N ([Vn]T Nn, [Vn]T En Vn)
Q ∼ N ([Sn]− 2 NZ, [Sn]− 12 EZ [Sn]− T
1
2 ),
1 1 T
K ∼ N ([SL] 2 NQ, [SL] 2 EQ [SL] 2 ),
Ψ ∼ N (VL NK, VL EK [VL]T ), (8)
</equation>
<bodyText confidence="0.883903">
and performing a decomposition in each of them, it can be proved that matrix Wℓ is given by
</bodyText>
<equation confidence="0.872434666666667">
Wℓ = Vℓ [Sℓ]1 2 [Sn]−12 [Vn]T . (9)
Then, the power spectrum distortion measure for the non-native speech signal is calculated as
φℓ(xℓi, ˆxℓi,j) ∼ = φℓ(xni, ˆxni,j; xℓi, ˆxℓi,j) ≈[xni − ˆxni,j]T [Wℓ]T Wℓ [xni −ˆxni,j], (10)
</equation>
<bodyText confidence="0.991985833333333">
where i ∈ I , j ∈ Ji.
As mentioned above, a small area is considered around each phone. In practice, this is done by
allowing small perturbations, i.e., adding 30 dB SNR independent and identically distributed
(i.i.d.) Gaussian noise to each xi and generate a set of 100 vectors ˆxi,j for the native speech
data n as well as for non-native speech data of all language backgrounds ℓ. All data from native
speech are used to calculate the perceptual distortion measure Eq. (2) on a frame by frame basis
by exploiting auditory information from the psychoacoustic model presented in (van de Par
et al., 2002). Analogously, all data from non-native speech of each language group ℓ are used to
compute Eq. (1) and, separately, all data from native speech, too. Next, the similarity measure
Aℓ is calculated using the native perceptual distortion and the non-native spectral distortion
measures and also the corresponding similarity measure for the native speakers An using the
native perceptual and spectral measures. Then for each phoneme class, the RBF kernel-based
</bodyText>
<subsectionHeader confidence="0.739882">
nPAD Θr bf
</subsectionHeader>
<bodyText confidence="0.980018">
ℓ is computed for every L2 background using Eq. (4). Finally, a Euclidean-based
nPAD Θℓ, described in (Koniaris and Engwall, 2011; Koniaris et al., 2013), is calculated by
considering Euclidean distances in Eqs. (1) and (2), i.e., φ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2 and
υ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2, respectively.
</bodyText>
<sectionHeader confidence="0.998846" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999936666666667">
This section describes the experiments and discusses the findings of the RBF kernel-based
approach in relation to the Euclidean-based approach and the theoretical linguistic survey
presented in (Bannert, 1984).
</bodyText>
<subsectionHeader confidence="0.999833">
3.1 Speech data
</subsectionHeader>
<bodyText confidence="0.99977125">
The speech data were recorded with a sampling frequency of 16 kHz consisting of 23 phone-
tically rich single words and 55 sentences of varying complexity and length. The utterances
were specifically designed for L2 learners of Swedish that were using a CALL program (Wik and
Hjalmarsson, 2009). The collection of the data was done through a desktop microphone while
</bodyText>
<page confidence="0.994702">
78
</page>
<table confidence="0.9717164">
L1 bkgr. male/female utt. L1 bkgr. male/female utt. L1 bkgr. male/female utt.
Eng.(US) 1/1 318 Russian 1/3 583 Arabic 0/1 164
German 2/0 249 Greek 3/0 393 Chinese 2/3 832
French 3/0 347 Spanish 4/1 882 Persian 3/3 987
Polish 0/2 317 Turkish 4/0 604 Swedish 9/2 888
</table>
<tableCaption confidence="0.982392">
Table 1: Distribution of the total number of male and female speakers and the number of
utterances (utt.) for each language background (L1 bkgr.).
</tableCaption>
<bodyText confidence="0.999827956521739">
students repeated a word or sentence after the virtual language tutor, the main character of
the program. The procedure was simple; first, the animated agent produced an utterance – a
pre-recorded natural speech produced by a native speaker – accompanied by a subtitle text and
the student repeated afterwards.
The total number of participants was 37 of which 23 were male students and 14 female, from 11
different language backgrounds as it is shown in Table 1. The data recordings took place twice
within one month’s time, before and after practicing at home. The duration of each recording
session was approximately 30 minutes. In addition, 9 male and 2 female Swedish speakers
without regional accent varieties were also recorded once each. Non-linguistic information,
such as coughs, long pauses, repetitions or fillers was excluded from the final corpus used
for experiments. Each speech file was accompanied by a text file, the content of which was
adjusted to the actual utterance, thus any deletion or insertion that may have occurred was not
considered into the text file. A phone-level transcription was then automatically generated from
the speech signal and the text file, using an HMM-based aligner (Sjölander, 2003). These phone-
level transcription files were used to separate the speech data into phoneme categories. The
material contained all Swedish phonemes, but the two short and more open pre-r allophones
/æ/, /œ/ and the retroflexes /ï/, /ã/, and /í/ were not considered in the experiments because
the number of occurrences in the database was not sufficiently large.
For each language background, the speech data were divided into different phoneme categories
according to the phone-level transcription files. The speech signal was first pre-emphasized and
then windowed every 25 ms with an overlap of 10 ms using a Hamming window. A discrete
Fourier transform of 512 points was applied to the windowed frame to compute the signal’s
power spectrum.
</bodyText>
<subsectionHeader confidence="0.902441">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.99978">
This section deals with the experiments and results of the described method. The goal is
to identify a list of the most problematic phonemes for a given group of L2 speakers using
previously recorded data. Hence, the experiments are done offline and the error detection
was not made on an utterance basis but on the whole data for each phoneme category. The
method is focusing on repeated mispronunciations made by the L2 speakers that deviate from
the L1 speakers. Only the speech signal is considered without further linguistic or paralinguistic
information. The list of problematic phonemes for each language group is then compared to a
linguistic study (Bannert, 1984).
Table 2 lists the vowels identified by the PED algorithms as being problematic for the different
groups of non-native speakers. For each L2 speaker group, the first line shows, in decreasing
order, the most deviating vowels according to the Euclidean-based nPAD Θℓ. Correspondingly,
</bodyText>
<page confidence="0.993975">
79
</page>
<note confidence="0.6502085">
L1 bkgr. nPAD ver. detected phonemes missed phonemes
accord. to Bannert (1984)
</note>
<figure confidence="0.997445289473685">
English ®ℓ æ:, E, y:, u:, U, œ:, E:, ø, 8, ø:, (i:), A:, (@), e:, e, O, a, 0: Y, o:
(US) ®Cbf 250 e:, E:, æ:, A:, Y, ø:, E, a, 0:, (i), y:, (@), (i:), O, 8, U, o:, e u:, œ:, ø
®r bf 500 æ:, E:, e:, A:, E, ø:, Y, a, 0:, (i), y:, (@), (i:), e, œ:, O, 8, U u:, o:, ø
ℓ
®r bf 1000 æ:, E:, e:, E, A:, ø:, Y, a, 0:, œ:, e, (i), ø, (@), y:, (i:), O, 8 u:, o:, U
ℓ
German ®ℓ æ:, (E), y:, u:, (U), E:, (ø), œ:, ø:, i:, @, A: 0:, 8, Y
®r bf 250 æ:, (e:), Y, ø:, A:, 0:, E:, (i), y:, (a), @, i: u:, 8, œ:
ℓ
®r bf 500 æ:, (e:), Y, ø:, A:, E:, 0:, (a), (i), y:, @, i: u:, 8, œ:
ℓ
®r bf 1000 æ:, ø:, Y, (e:), A:, E:, (a), 0:, (i), œ:, y:, @ u:, 8, i:
ℓ
French ®ℓ æ:, E, y:, u:, œ:, (U), E:, (ø), 8, ø:, i:, @, A:, e:, e, O, (a) 0:, o:, Y
®r bf 250 e:, E:, æ:, Y, ø:, A:, 0:, (a), (i), y:, i:, @, E, O, o:, (U), 8 u:, œ:, e
ℓ
®r bf 500 æ:, e:, E:, Y, ø:, A:, (a), 0:, E, (i), y:, @, i:, œ:, O, e, o: u:, 8
ℓ
®r bf 1000 æ:, E:, e:, ø:, Y, A:, E, (a), œ:, 0:, (i), (ø), e, y:, @, i:, O u:, 8, o:
ℓ
Polish ®ℓ æ:, (E), y:, u:, œ:, (U), E:, ø, 8, ø:, i:, A:, @, e:, (e), (O) 0:, Y, o:, a
®r bf 250 e:, E:, æ:, A:, Y, ø:, (E), a, 0:, (i), y:, i:, @, (O), o:, 8 u:, ø, œ:
ℓ
®r bf 500 æ:, E:, e:, A:, (E), ø:, Y, a, 0:, (i), y:, @, (e), i:, œ:, (O) u:, 8, o:, ø
ℓ
®r bf 1000 æ:, E:, (E), e:, A:, ø:, Y, a, œ:, 0:, (e), (i), ø, @, y:, i: u:, o:, 8
ℓ
Russian ®ℓ E, y:, E:, ø, ø:, i:, A:, 8, e:, e, 0:, a, (O), Y, (@), (i), œ: u:, æ:, o:
®r bf 250 Y, E:, 0:, ø:, y:, e:, A:, i:, a, 8, (O), æ:, (i), (@), œ:, e, u: ø, o:, E
ℓ
®r bf 500 Y, E:, 0:, ø:, y:, e:, A:, a, œ:, i:, æ:, ø, 8, e, (O), (i), (@) u:, o:, E
ℓ
®r bf 1000 Y, E:, ø:, 0:, œ:, ø, A:, e:, y:, a, i:, e, æ:, E, 8, (O), (i) u:, o:
ℓ
Greek ®ℓ æ:, (E), y:, u:, œ:, (U), E:, ø, 8, ø:, i:, A:, @, e:, e, (O) 0:, Y, o:
®r bf 250 E:, e:, æ:, A:, Y, ø:, (E), (a), 0:, (i), y:, i:, @, (O), 8, o: u:, ø, œ:, e
ℓ
®r bf 500 æ:, E:, e:, A:, (E), Y, ø:, (a), 0:, (i), y:, @, e, i:, œ:, (O) u:, 8, o:, ø
ℓ
®r bf 1000 æ:, E:, (E), e:, A:, ø:, Y, (a), œ:, e, 0:, (i), ø, @, y:, i: u:, 8, o:
ℓ
Spanish ®ℓ u:, æ:, E, ø, i:, 8, e:, e, ø:, (a), 0:, A:, (i), @, Y, (O), o: y:, E:, œ:
®r bf 250 0:, æ:, e:, (a), E:, i:, Y, (i), 8, A:, ø:, @, (O), e, œ:, o:, (U) u:, y:, E, ø
ℓ
®r bf 500 0:, (a), e:, Y, i:, (i), E:, A:, 8, œ:, æ:, ø:, e, @, (O), E, ø u:, y:, o:
ℓ
®r bf 1000 0:, (a), e:, Y, (i), i:, œ:, e, ø, ø:, E, 8, A:, @, æ:, E:, (O) u:, y:, o:
ℓ
Turkish ®ℓ æ:, (E), y:, (E:), (ø), u:, 8, U, ø:, i:, A:, e:, (@) e, 0:, o:, œ:
®r bf 250 e:, (E:), (Y), ø:, æ:, (a), 0:, (i), A:, i:, y:, (O), (@) e, u:, U, 8, o:, œ:
ℓ
®r bf 500 e:, (Y), æ:, (E:), ø:, (a), A:, (i), 0:, (E), i:, y:, (O) e, u:, U, 8, o:, œ:
ℓ
®r bf 1000 e:, æ:, (Y), (E:), ø:, (a), (E), A:, (i), 0:, (o), œ:, e u:, U, 8, o:, y:, i:
ℓ
Arabic ®ℓ æ:, E, y:, u:, œ:, (U), E:, ø, 8, ø:, i:, A:, @, e:, e, (O), a, 0: Y, o:
®r bf 250 e:, E:, æ:, A:, Y, ø:, E, a, 0:, (i), y:, i:, @, (O), o:, (U), 8, e u:, ø, œ:
ℓ
®r bf 500 æ:, e:, E:, A:, E, ø:, Y, a, 0:, (i), y:, @, e, i:, œ:, (O), (U), 8 u:, o:, ø
ℓ
®r bf 1000 æ:, E:, e:, E, A:, ø:, Y, a, œ:, 0:, e, (i), ø, @, y:, i:, (O), 8 u:, o:
ℓ
Chinese ®ℓ 8, æ:, E, y:, u:, E:, ø, ø:, i:, A:, e:, e, O, (@), a, 0:, (i), o: Y, œ:
®r bf 250 8, A:, 0:, e:, (i), E:, ø:, æ:, i:, O, a, y:, o:, (@), u:, e, (U), œ: Y, ø, E
ℓ
®r bf 500 8, A:, æ:, 0:, E:, e:, ø:, (i), a, O, i:, y:, o:, œ:, e, (@), u:, E Y, ø
ℓ
®r bf 1000 A:, æ:, E:, ø:, 0:, e:, (i), a, œ:, O, e, i:, E, o:, y:, ø, (@), u: Y, 8
ℓ
Persian ®ℓ 8, æ:, y:, (E), ø, ø:, Y, (i), 0:, e:, a, (e), (A:), o:, (O) i:, u:, E:, œ:, @
®r bf 250 8, æ:, (e), (E), @, E:, a, ø:, e:, Y, (i), 0:, (A:), u:, œ: i:, y:, o:, ø
ℓ
®r bf 500 æ:, 8, (e), (E), ø:, @, E:, œ:, 0:, ø, Y, e:, a, (i), (A:) i:, u:, y:, o:
ℓ
®r bf 1000 æ:, ø:, ø, œ:, E:, (e), (E), 8, Y, 0:, (i), @, e:, (A:), a i:, y:, o:, u:
ℓ
</figure>
<tableCaption confidence="0.9733685">
Table 2: Problematic vowels per language background. To the left, the vowels are shown in
decreasing order, starting from the one with the highest nPAD. Phonemes that differ from the
linguistic study findings are in parentheses, and the seriously problematic according to Bannert
(1984) are underscored. To the right, the missed vowels.
</tableCaption>
<page confidence="0.906515">
80
</page>
<table confidence="0.998443428571428">
Θ1 Θr bf 250 Θr bf 500 Θr bf 1000
1 1 1
Better performance in no. of language groups 3 2 3 4
Mismatches with theory (total) 19.2% 22.0% 20.9% 19.2%
Seriously problematic phonemes missed (total) 21.3% 22.0% 26.0% 25.2%
Mismatches in top 5 phonemes 8 7 8 7
Seriously problematic captured in top 5 phonemes 34 35 34 34
</table>
<tableCaption confidence="0.999667">
Table 3: Summary of findings for vowels.
</tableCaption>
<bodyText confidence="0.5383945">
the second, third and fourth lines show the results of the RBF kernel-based nPAD Θrbf 1for
Q2 = 0.002, 0.001 and 0.0005, respectively. These are shown in table as Θr bf 250, Θr bf 500 and
</bodyText>
<equation confidence="0.623963333333333">
1 1
Θr bf 1000, respectively because y in Eqs. (1) and (2) becomes 250, 500 and 1000, respectively.
1
</equation>
<bodyText confidence="0.99369275">
As ground truth is considered the linguistic survey described in (Bannert, 1984). False rejections
according to (Bannert, 1984) are indicated in parentheses and false accepts according to
(Bannert, 1984) are listed in the right-most column. Some phonemes are shown underscored.
These are the seriously problematic phonemes according to (Bannert, 1984), i.e., they are
totally mispronounced by the non-native speakers. Generally, the nPAD methods capture most
of the common errors made by each language group when its members are trying to learn
Swedish. The Euclidean-based nPAD Θ1 is better for American English, Spanish and Turkish
speakers. The RBF kernel-based nPAD Θr bf 250 is better for Polish, Θr bf 500 is better for French
</bodyText>
<figure confidence="0.9245374">
1 1
and Chinese and Θr bf 1000 is better for Russian, Greek, Arabic and Persian speakers. For the
1
German speaking group both Θr b f 250 and Θr b f 500 perform equally well.
1 1
</figure>
<bodyText confidence="0.8768813">
Table 3 summarizes the findings of the approaches for vowels. The Euclidean-based measure
achieves a lower percentage of mismatches with the theoretical linguistic findings and also
misses less seriously mispronounced vowels compared to the RBF kernel-based measures. On
the other hand, Θr bf 250 captures the most seriously problematic vowels of all methods when
1
looking only at the top 5 vowels of the list of problematic ones and also has the least mismatches
with Bannert, again when only the five most problematic phonemes according to the method
are considered. Θr bf 500 seems not achieving better performance compared to the rest of the
1
methods according to the table list and finally, Θr bf 1000 is generally performing better in more
</bodyText>
<equation confidence="0.696429">
1
groups of L2 speakers, has the least mismatches with theory (as Θ1 does, too) and also has less
mismatches when only the top 5 most problematic vowels are considered (the same as Θr bf 250
1 ).
</equation>
<bodyText confidence="0.994717909090909">
The reported findings show clearly that for many groups of L2 speakers the open pre-r allophone
/æ:/ is very problematic as it appears most of times at the top of the problematic vowels. Another
vowel that appears problematic is /E:/, which is often not pronounced with a long duration
as it is supposed but rather short, often being replaced by /E/. Generally, it is revealed that
most of the foreign speakers face difficulties when trying to produce the Swedish long vowels.
Hence, /u:/, /A:/ and /e:/ are vowels that both the tested methods and Bannert’s linguistic
survey diagnose as seriously problematic for most of the L2 groups.
Table 4 lists the consonants that are diagnosed as being mispronounced by the L2 groups. As
in Table 2, the first row shows, in decreasing order, the most deviating consonants according
to the Euclidean-based nPAD Θ1 and the following rows the three RBF kernel-based nPADs
Θrbf 250, Θrbf 500 and Θrbf 1000, respectively. Θ1 is better for French, Greek, Spanish and Turkish
</bodyText>
<footnote confidence="0.647666">
1 1 1
speakers. Θr bf 1000 is better for Persian speakers while all three RBF kernel-based nPADs are
1
</footnote>
<page confidence="0.995635">
81
</page>
<note confidence="0.826886">
L1 bkgr. nPAD ver. detected phonemes missed phonemes
accord. to Bannert (1984)
</note>
<figure confidence="0.994540230769231">
English Θℓ Ê, N, (v), m, n, (b), r, (d), l, k, ù, t s, C, ú
Θr bf 250
(US) ù, C, s, (j), Ê, r, l, (g), (d), N, k, t m, n, ú
ℓ
Θr bf 500 ù, C, s, (j), r, l, Ê, (g), N, k, (d), t m, n, ú
ℓ
Θrbf 1000 ù, C, s, (j), r, l, (g), k, N, Ê, t, (d) m, n, ú
ℓ
German Θℓ Ê, N, v, n, (m), b, r, d, (l), k, ù, t, p, (h), f, C, s g, ú, j
Θr bf 250 ù, C, s, r, (l), Ê, g, N, d, k, t, b, (h), f, v, n, p ú, j
ℓ
Θrbf 500 C, ù, s, r, (l), g, N, d, k, Ê, t, b, (h), f, v, n, p ú, j
ℓ
Θr bf 1000 C, ù, s, r, (l), g, N, k, d, t, (h), b, f, v, n, Ê, j ú, p
ℓ
French Θℓ N, Ê, (v), m, n, b, r, (l), d, ù, k, t, p, h, C, g s, ú
Θr bf 250 ù, C, (j), r, (l), g, N, s, d, Ê, b, k, h, t, m, (v) p, ú, n
ℓ
Θrbf 500 ù, C, (j), r, (l), g, N, s, d, b, k, h, t, m, Ê, n p, ú
ℓ
Θr bf 1000 ù, C, (j), r, (l), N, s, g, k, d, b, h, t, m, n, (v) p, ú, Ê
ℓ
Polish Θℓ Ê, N, v, (m), n, b, (r), d, (l), k, ù, t, p, s, (f) g, h, C, ú
Θr bf 250 ù, s, C, (j), Ê, (l), (r), g, N, d, t, k, b, (f), v h, p, n, ú
ℓ
Θrbf 500 ù, s, C, (j), (r), (l), Ê, g, N, k, t, b, d, (f), v h, p, n, ú
ℓ
Θr bf 1000 ù, s, C, (j), (r), (l), g, N, k, t, Ê, b, d, (f), v h, p, n, ú
ℓ
Russian Θℓ v, N, (m), (n), (r), d, (l), h, b, k, t, g, (s), f, j p, Ê, ù, C, ú
Θr bf 250 j, (l), (s), (r), N, g, v, k, f, (m), (n), t, b, d, p Ê, ù, C, h, ú
ℓ
Θr bf 500 j, (s), (l), (r), N, g, v, k, (m), f, (n), t, b, d, p Ê, ù, C, h, ú
ℓ
Θr b f 1000 j, (s), (l), (r), N, g, v, k, (m), (n), f, t, b, d, p Ê, ù, C, h, ú
ℓ
Greek Θℓ Ê, N, (v), m, n, b, (r), d, l, ù, k, t, p, C, (f), s g, h, t
Θr b f 250 ù, C, (j), s, Ê, (r), l, g, N, d, t, b, k, (f), (v), m h, n, p, ú
ℓ
Θr bf 500 ù, C, (j), s, (r), l, g, Ê, N, t, d, k, b, (f), (v), m h, n, p, ú
ℓ
Θr bf 1000 ù, C, (j), s, (r), l, g, N, t, k, d, b, Ê, (f), (v), m h, n, p, ú
ℓ
Spanish Θℓ N, v, (r), n, (l), b, t, ù, (f), k, g, d, j, p, C, s, h Ê, m, ú
Θr bf 250 (l), (r), ù, N, (f), v, n, t, k, g, p, d, b, m, h, j, ú s, Ê, C
ℓ
Θr b f 500 (l), ù, (r), N, (f), v, n, t, k, p, g, d, m, b, j, h, ú s, Ê, C
ℓ
Θr bf 1000 (l), ù, (r), N, (f), v, n, t, k, g, p, d, m, b, j, h, ú s, Ê, C
ℓ
Turkish Θℓ N, v, (m), n, b, r, l, d, k, (ù), t, p, f, h, g, ú, j, s Ê, C
Θr bf 250 (ù), j, l, r, N, g, k, t, b, s, v, f, d, (m), p, n, h, ú Ê, C
ℓ
Θr bf 500 (ù), j, l, r, N, g, k, t, s, b, v, f, (m), d, n, p, h, ú Ê, C
ℓ
Θr bf 1000 (ù), j, l, r, N, k, g, t, s, b, v, (m), d, f, n, p, h, ú Ê, C
ℓ
Arabic Θℓ Ê, N, v, (m), (n), (b), r, d, (l), k, ù, t, p f, s, C, ú
Θr bf 250 ù, C, s, (j), Ê, r, (l), (g), d, N, k, t, (b) f, p, v, ú
ℓ
Θr bf 500 C, ù, s, (j), r, (l), Ê, (g), k, d, N, t, (b) f, p, v, ú
ℓ
Θr bf 1000 C, ù, s, (j), r, (l), k, (g), N, t, d, Ê, (b) f, p, v, ú
ℓ
Chinese Θℓ Ê, N, v, m, n, b, r, l, d, k, t, f, g, ú, p, j, (h), (s) ù, C
Θr bf 250 Ê, l, r, N, j, g, f, k, b, v, m, n, t, ú, p, d, (h), (s) ù, C
ℓ
Θr bf 500 l, r, Ê, N, j, g, k, f, b, v, m, n, t, ú, p, d, (h), (s) ù, C
ℓ
Θr bf 1000 l, r, N, j, g, k, Ê, b, f, m, v, n, t, ú, p, d, (h), (s) ù, C
ℓ
Persian Θℓ b, d, (Ê), v, (f), g, (h), t, s, (j), C, p, ú, k, l, r n, N, ù, m
Θr bf 250 b, (f), (Ê), v, g, t, (h), p, n, l, ú, r, d, N, k, m s, ù, C
ℓ
Θr bf 500 b, (f), (Ê), v, g, t, (h), p, n, l, k, ú, r, N, d, m s, ù, C
ℓ
Θr bf 1000 (f), v, (Ê), g, t, p, (h), n, k, b, l, ú, N, r, d, m s, ù, C
ℓ
</figure>
<tableCaption confidence="0.86636175">
Table 4: Problematic consonants per language background. To the left, the consonants are
shown in decreasing order, starting from the one with the highest nPAD. Phonemes that differ
from the linguistic study findings are in parentheses, and the seriously problematic according to
Bannert (1984) are underscored. To the right, the missed consonants.
</tableCaption>
<page confidence="0.942801">
82
</page>
<table confidence="0.998894428571429">
Better performance in no. of language groups Θℓ Θr bf 250 Θr bf 500 Θr bf 1000
ℓ ℓ ℓ
5 6 5 5
Mismatches with theory (total) 20.2% 20.2% 19.7% 20.2%
Seriously problematic phonemes missed (total) 19.5% 18.6% 18.6% 18.6%
Mismatches in top 5 phonemes 15 16 18 18
Seriously problematic captured in top 5 phonemes 28 29 27 27
</table>
<tableCaption confidence="0.860420333333333">
Table 5: Summary of findings for consonants.
equally better for American English, German, Russian and Arabic speakers in comparison to the
Euclidean-based measure. Finally, Θℓ and Θr b f 250 are better for the Polish group and Θr b f 250
</tableCaption>
<figure confidence="0.498828666666667">
ℓ ℓ
and Θr b f 500 for the Chinese speakers.
ℓ
</figure>
<bodyText confidence="0.927128756756757">
Table 5 summarizes the findings of the Table 4. The Euclidean-based measure has less mis-
matches with Bannert in the top five most problematic consonants as compared to the RBF
kernel-based approaches. Θrbf 250 is better in most language groups and can better capture the
ℓ
seriously problematic consonants both when the focus is on the five most problematic ones, but
also in terms of the total number of the seriously problematic consonants (although in the latter
case, all three RBF kernel-based approaches perform equally good). In addition, Θr bf 500 has
ℓ
the least mismatches with the linguistic study.
The Swedish retroflex /g/ is very problematic according to the reported results and likewise
the unique &amp;quot;sje-sound&amp;quot; /fj/, a rounded velar fricative that does not exist in other languages.
Moreover, many L2 speakers seem to have problems producing the velar nasal /lj/, which is
commonly mispronounced as /ljg/. Another difficult consonant is the fricative /r/ that is also
one of the most problematic sounds for second language speakers of Swedish.
In summary, RBF kernel generally seems to work better for consonants vis-à-vis vowels when
compared with (Bannert, 1984) but also with the Euclidean distance measure. A small improve-
ment in the percentage of the seriously problematic consonants is confirmed – accomplished
by all three RBF-based measures – compared to the Euclidean measure. The figures remain
better even in the case in which only the five most problematic consonants are taken into
account. The results of the RBF kernel metrics are still in a better agreement with linguistic
findings in comparison to the Euclidean-based one. On the other hand for the case of vowels,
the two metrics perform nearly the same based on the criteria listed in Table 3. While for
instance, Θℓ is better considering the total number of mismatches with theory and, in addition,
misses less seriously problematic vowels according to Bannert’s study, Θr bf 250 has a slightly
ℓ
better performance when concentrating on the five most problematic vowels and Θrbf 1000 is
ℓ
mainly preferable for more L2 groups compared to the rest of the metrics. Generally speaking,
RBF-kernel may be considered to outperform to a small extent the Euclidean measure, though
the two measures do not have major differences and they both seem to work well and achieve
positive results as they regurarly agree with Bannert’s linguistic survey. It is noted that the
intention of the research described in this paper was to investigate alternative measures for
the perceptually-motivated PED approach and carry out experiments to explore their behavior.
Moreover, the deviations from the theoretical findings that both distance measures have can,
for the most part, be explained by the nature of the two studies (theoretical linguistic vs.
computational automatic) and the methodology that was followed. Bannert studied the pronun-
ciation problem from a pure linguistic perspective, including lots of subjective observations and
</bodyText>
<page confidence="0.996043">
83
</page>
<bodyText confidence="0.9998857">
analysis. The computational methods do not consider many linguistic aspects, such as context
and influence from preceding or succeeding phonemes. In addition, the PED methods aim at
diagnosing mispronunciations made by the examined learners and are not designed to be used
for identifying general problems related to the L1 of a group of speakers as Bannert’s study was.
It is noted that Bannert collected data from L2 speakers that were not influenced by repeating
after a native speaker. The reason was that the study was aimed at making an inventory of
mispronunciations for various groups of L2 students that would be used as a reference list
for the teachers of Swedish as a second language. This may partly explain why some of the
seriously problematic phonemes in Bannert’s study were not diagnosed likewise with the nPAD
approaches.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.998126428571429">
In this paper, a RBF kernel-based similarity measure was investigated as part of a pronunciation
error detection algorithm previously presented in (Koniaris and Engwall, 2011; Koniaris et al.,
2013) where a Euclidean distance measure was utilized. The idea was to investigate whether it
can achieve good performance in relation to relevant linguistic literature and in comparison
to the Euclidean similarity measure. The experiments show that good results can be obtained
using this measure. In the future, it will be interesting to extend the idea by applying support
vector machines in combination to the RBF kernel measure.
</bodyText>
<page confidence="0.997556">
84
</page>
<sectionHeader confidence="0.998345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999329837837838">
Bannert, R. (1984). Problems in learning Swedish pronunciation and in understanding foreign
accent. Folia Linguistica, 18(1-2):193–222.
Braun, M. L., Buhmann, J. M., and Müller, K.-R. (2008). On relevant dimensions in kernel
feature spaces. J. Machine Learn. Research, 9:1875–1908.
Delmonte, R. (2000). SLIM prosodic automatic tools for self-learning instruction. Speech
Communication, 30(2-3):145–166.
Flege, J. E. (1995). Second-language speech learning: theory, findings, and problems. Strange,
W. (Ed.), Speech Perception and Linguistic Experience: Theoretical and Methodological Issues
in Cross-Language Speech Research. Timonium, MD: York Press Inc.
Franco, H., Neumeyer, L., Kim, Y., and Ronen, O. (1997). Automatic pronunciation scoring for
language instruction. In IEEE Int. Conf. Acoust., Speech, Sig. Proc., Munich, Germany, pages
1471–1474.
Guion, S. G., Flege, J. E., Ahahane-Yamada, R., and Pruitt, J. C. (2000). An investigation of
current models of second language speech perception: the case of japanese adults’ perception
of english consonants. J. Acoust. Soc. Am., 107(5):2711–2724.
Koniaris, C. and Engwall, O. (2011). Phoneme level non-native pronunciation analysis by
an auditory model-based native assessment scheme. In Interspeech, Florence, Italy, pages
1157–1160.
Koniaris, C., Salvi, G., and Engwall, O. (2013). On mispronunciation analysis of individual
foreign speakers using auditory periphery models. Speech Communication, 55(5):691–706.
Neumeyer, L., Franco, H., Digalakis, V., and Weintraub, M. (2000). Automatic scoring of
pronunciation quality. Speech Communication, 30:83–93.
Neumeyer, L., Franco, H., Weintraub, M., and Price, P. (1996). Automatic text-independent
pronunciation scoring of foreign language student speech. In Int. Conf. Spoken Lang. Proc.,
Philadelphia, PA , USA, pages 1457–1460.
Park, J. G. and Rhee, S. C. (2004). Development of the knowledge-based spoken english
evaluation system and its application. In ISCA Interspeech, Jeju Island, South Korea, pages
1681–1684.
Piske, T., Flege, J., and MacKay, I. (2001). Factors affecting degree of foreign accent in an l2:
a review. J. Phonetics, 29(2):191–215.
Raux, A. and Kawahara, T. (2002). Automatic intelligibility assessment and diagnosis of critical
pronunciation errors for computer-assisted pronunciation learning. In Int. Conf. Spoken Lang.
Proc., Denver, CO, USA, pages 737–740.
Sjölander, K. (2003). An HMM-based system for automatic segmentation and alignment of
speech. In Fonetik, pages 93–96.
Strik, H., Truong, K., de Wet, F., and Cucchiarini, C. (2009). Comparing different approaches
for automatic pronunciation error detection. Speech Communication, 51(10):845–852.
</reference>
<page confidence="0.993219">
85
</page>
<reference confidence="0.99200104">
Tepperman, J. and Narayanan, S. (2005). Hidden-articulator markov models for pronunciation
evaluation. In Proc. ASRU, San Juan, Puerto Rico, pages 174–179.
Tepperman, J. and Narayanan, S. (2008). Using articulatory representations to detect segmen-
tal errors in nonnative pronunciation. IEEE Tr. Audio, Speech, Lang. Proc., 16(1):8–22.
Truong, K. P., Neri, A., de Wet, F., Cucchiarini, C., and Strik, H. (2005). Automatic detection
of frequent pronunciation errors made by L2-learners. In ISCA Interspeech, Lisbon, Portugal,
pages 1345–1348.
van de Par, S., Kohlrausch, A., Charestan, G., and Heusdens, R. (2002). A new psychoacoustical
masking model for audio coding applications. In IEEE Int. Conf. on Acoust., Speech, Sig. Proc.,
Orlando, FL, USA, volume 2, pages 1805–1808.
Wei, S., Hu, G., Hu, Y., and Wang, R.-H. (2009). A new method for mispronunciation detection
using support vector machine based on pronunciation space models. Speech Communication,
51(10):896–905.
Weigelt, L. F., Sadoff, S. J., and Miller, J. D. (1990). Plosive/fricative distinction: the voiceless
case. J. Acoust. Soc. Am., 87:2729–2737.
Wik, P. and Hjalmarsson, A. (2009). Embodied conversational agents in computer assisted
language learning. Speech Communication, 51(10):1024–1037.
Witt, S. M. and Young, S. (2000). Phone-level pronunciation scoring and assessment for
interactive language learning. Speech Communication, 30:95–108.
Xu, S., Jiang, J., Chen, Z., and Xu, B. (2009). Automatic pronunciation error detection based
on linguistic knowledge and pronunciation space. In IEEE Int. Conf. Acoust. Speech Sig. Proc.
(ICASSP), Taipei, Taiwan, pages 4841–4844.
Yamashita, Y., Kato, K., and Nozawa, K. (2005). Automatic scoring for prosodic proficiency
of english sentences spoken by japanese based on utterance comparison. IECE Trans. Inform.
Systems, E88-D:496–501.
</reference>
<page confidence="0.998492">
86
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.150968">
<title confidence="0.971132">An approach to measure pronunciation similarity in second language learning using radial basis function kernel</title>
<author confidence="0.99748">Christos Koniaris</author>
<affiliation confidence="0.930502666666667">University of Gothenburg, Centre for Language Department of Philosophy, Linguistics and Theory of Science Dialogue Technology Lab, Gothenburg, Sweden</affiliation>
<email confidence="0.522806">christos.koniaris@gu.se</email>
<abstract confidence="0.997841846153846">This paper shows a method to diagnose potential mispronunciations in second language learning by studying the characteristics of the speech produced by a group of native speakers and the speech produced by various non-native groups of speakers from diverse language backgrounds. The method compares the native auditory perception and the non-native spectral representation on the phoneme level using similarity measures that are based on the radial basis function kernel. A list of ordered problematic phonemes is found for each non-native group of speakers and the results are analyzed based on a relevant linguistic survey found in the literature. The experimental results indicate an agreement with linguistic findings of up to 80.8% for vowels and 80.3% for consonants. error detection, similarity measure, radial basis function kernel, phoneme, second language learning. Christos Koniaris 2014. An approach to measure pronunciation similarity in second language learning radial basis function kernel. of the third workshop on NLP for computer-assisted language learning.</abstract>
<note confidence="0.570442">NEALT Proceedings Series 22 / Linköping Electronic Conference Proceedings 107: 74–86. 74</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Bannert</author>
</authors>
<title>Problems in learning Swedish pronunciation and in understanding foreign accent. Folia Linguistica,</title>
<date>1984</date>
<pages>18--1</pages>
<contexts>
<context position="14507" citStr="Bannert, 1984" startWordPosition="2295" endWordPosition="2296">measures. Then for each phoneme class, the RBF kernel-based nPAD Θr bf ℓ is computed for every L2 background using Eq. (4). Finally, a Euclidean-based nPAD Θℓ, described in (Koniaris and Engwall, 2011; Koniaris et al., 2013), is calculated by considering Euclidean distances in Eqs. (1) and (2), i.e., φ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2 and υ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2, respectively. 3 Experiments This section describes the experiments and discusses the findings of the RBF kernel-based approach in relation to the Euclidean-based approach and the theoretical linguistic survey presented in (Bannert, 1984). 3.1 Speech data The speech data were recorded with a sampling frequency of 16 kHz consisting of 23 phonetically rich single words and 55 sentences of varying complexity and length. The utterances were specifically designed for L2 learners of Swedish that were using a CALL program (Wik and Hjalmarsson, 2009). The collection of the data was done through a desktop microphone while 78 L1 bkgr. male/female utt. L1 bkgr. male/female utt. L1 bkgr. male/female utt. Eng.(US) 1/1 318 Russian 1/3 583 Arabic 0/1 164 German 2/0 249 Greek 3/0 393 Chinese 2/3 832 French 3/0 347 Spanish 4/1 882 Persian 3/3 </context>
<context position="17961" citStr="Bannert, 1984" startWordPosition="2855" endWordPosition="2856"> described method. The goal is to identify a list of the most problematic phonemes for a given group of L2 speakers using previously recorded data. Hence, the experiments are done offline and the error detection was not made on an utterance basis but on the whole data for each phoneme category. The method is focusing on repeated mispronunciations made by the L2 speakers that deviate from the L1 speakers. Only the speech signal is considered without further linguistic or paralinguistic information. The list of problematic phonemes for each language group is then compared to a linguistic study (Bannert, 1984). Table 2 lists the vowels identified by the PED algorithms as being problematic for the different groups of non-native speakers. For each L2 speaker group, the first line shows, in decreasing order, the most deviating vowels according to the Euclidean-based nPAD Θℓ. Correspondingly, 79 L1 bkgr. nPAD ver. detected phonemes missed phonemes accord. to Bannert (1984) English ®ℓ æ:, E, y:, u:, U, œ:, E:, ø, 8, ø:, (i:), A:, (@), e:, e, O, a, 0: Y, o: (US) ®Cbf 250 e:, E:, æ:, A:, Y, ø:, E, a, 0:, (i), y:, (@), (i:), O, 8, U, o:, e u:, œ:, ø ®r bf 500 æ:, E:, e:, A:, E, ø:, Y, a, 0:, (i), y:, (@), </context>
<context position="22373" citStr="Bannert (1984)" startWordPosition="3960" endWordPosition="3961"> (E), ø, ø:, Y, (i), 0:, e:, a, (e), (A:), o:, (O) i:, u:, E:, œ:, @ ®r bf 250 8, æ:, (e), (E), @, E:, a, ø:, e:, Y, (i), 0:, (A:), u:, œ: i:, y:, o:, ø ℓ ®r bf 500 æ:, 8, (e), (E), ø:, @, E:, œ:, 0:, ø, Y, e:, a, (i), (A:) i:, u:, y:, o: ℓ ®r bf 1000 æ:, ø:, ø, œ:, E:, (e), (E), 8, Y, 0:, (i), @, e:, (A:), a i:, y:, o:, u: ℓ Table 2: Problematic vowels per language background. To the left, the vowels are shown in decreasing order, starting from the one with the highest nPAD. Phonemes that differ from the linguistic study findings are in parentheses, and the seriously problematic according to Bannert (1984) are underscored. To the right, the missed vowels. 80 Θ1 Θr bf 250 Θr bf 500 Θr bf 1000 1 1 1 Better performance in no. of language groups 3 2 3 4 Mismatches with theory (total) 19.2% 22.0% 20.9% 19.2% Seriously problematic phonemes missed (total) 21.3% 22.0% 26.0% 25.2% Mismatches in top 5 phonemes 8 7 8 7 Seriously problematic captured in top 5 phonemes 34 35 34 34 Table 3: Summary of findings for vowels. the second, third and fourth lines show the results of the RBF kernel-based nPAD Θrbf 1for Q2 = 0.002, 0.001 and 0.0005, respectively. These are shown in table as Θr bf 250, Θr bf 500 and 1</context>
<context position="26124" citStr="Bannert (1984)" startWordPosition="4606" endWordPosition="4607">nose as seriously problematic for most of the L2 groups. Table 4 lists the consonants that are diagnosed as being mispronounced by the L2 groups. As in Table 2, the first row shows, in decreasing order, the most deviating consonants according to the Euclidean-based nPAD Θ1 and the following rows the three RBF kernel-based nPADs Θrbf 250, Θrbf 500 and Θrbf 1000, respectively. Θ1 is better for French, Greek, Spanish and Turkish 1 1 1 speakers. Θr bf 1000 is better for Persian speakers while all three RBF kernel-based nPADs are 1 81 L1 bkgr. nPAD ver. detected phonemes missed phonemes accord. to Bannert (1984) English Θℓ Ê, N, (v), m, n, (b), r, (d), l, k, ù, t s, C, ú Θr bf 250 (US) ù, C, s, (j), Ê, r, l, (g), (d), N, k, t m, n, ú ℓ Θr bf 500 ù, C, s, (j), r, l, Ê, (g), N, k, (d), t m, n, ú ℓ Θrbf 1000 ù, C, s, (j), r, l, (g), k, N, Ê, t, (d) m, n, ú ℓ German Θℓ Ê, N, v, n, (m), b, r, d, (l), k, ù, t, p, (h), f, C, s g, ú, j Θr bf 250 ù, C, s, r, (l), Ê, g, N, d, k, t, b, (h), f, v, n, p ú, j ℓ Θrbf 500 C, ù, s, r, (l), g, N, d, k, Ê, t, b, (h), f, v, n, p ú, j ℓ Θr bf 1000 C, ù, s, r, (l), g, N, k, d, t, (h), b, f, v, n, Ê, j ú, p ℓ French Θℓ N, Ê, (v), m, n, b, r, (l), d, ù, k, t, p, h, C, g s, </context>
<context position="29628" citStr="Bannert (1984)" startWordPosition="5635" endWordPosition="5636"> p, d, (h), (s) ù, C ℓ Persian Θℓ b, d, (Ê), v, (f), g, (h), t, s, (j), C, p, ú, k, l, r n, N, ù, m Θr bf 250 b, (f), (Ê), v, g, t, (h), p, n, l, ú, r, d, N, k, m s, ù, C ℓ Θr bf 500 b, (f), (Ê), v, g, t, (h), p, n, l, k, ú, r, N, d, m s, ù, C ℓ Θr bf 1000 (f), v, (Ê), g, t, p, (h), n, k, b, l, ú, N, r, d, m s, ù, C ℓ Table 4: Problematic consonants per language background. To the left, the consonants are shown in decreasing order, starting from the one with the highest nPAD. Phonemes that differ from the linguistic study findings are in parentheses, and the seriously problematic according to Bannert (1984) are underscored. To the right, the missed consonants. 82 Better performance in no. of language groups Θℓ Θr bf 250 Θr bf 500 Θr bf 1000 ℓ ℓ ℓ 5 6 5 5 Mismatches with theory (total) 20.2% 20.2% 19.7% 20.2% Seriously problematic phonemes missed (total) 19.5% 18.6% 18.6% 18.6% Mismatches in top 5 phonemes 15 16 18 18 Seriously problematic captured in top 5 phonemes 28 29 27 27 Table 5: Summary of findings for consonants. equally better for American English, German, Russian and Arabic speakers in comparison to the Euclidean-based measure. Finally, Θℓ and Θr b f 250 are better for the Polish group</context>
<context position="31470" citStr="Bannert, 1984" startWordPosition="5946" endWordPosition="5947"> least mismatches with the linguistic study. The Swedish retroflex /g/ is very problematic according to the reported results and likewise the unique &amp;quot;sje-sound&amp;quot; /fj/, a rounded velar fricative that does not exist in other languages. Moreover, many L2 speakers seem to have problems producing the velar nasal /lj/, which is commonly mispronounced as /ljg/. Another difficult consonant is the fricative /r/ that is also one of the most problematic sounds for second language speakers of Swedish. In summary, RBF kernel generally seems to work better for consonants vis-à-vis vowels when compared with (Bannert, 1984) but also with the Euclidean distance measure. A small improvement in the percentage of the seriously problematic consonants is confirmed – accomplished by all three RBF-based measures – compared to the Euclidean measure. The figures remain better even in the case in which only the five most problematic consonants are taken into account. The results of the RBF kernel metrics are still in a better agreement with linguistic findings in comparison to the Euclidean-based one. On the other hand for the case of vowels, the two metrics perform nearly the same based on the criteria listed in Table 3. </context>
</contexts>
<marker>Bannert, 1984</marker>
<rawString>Bannert, R. (1984). Problems in learning Swedish pronunciation and in understanding foreign accent. Folia Linguistica, 18(1-2):193–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M L Braun</author>
<author>J M Buhmann</author>
<author>K-R Müller</author>
</authors>
<title>On relevant dimensions in kernel feature spaces.</title>
<date>2008</date>
<journal>J. Machine Learn. Research,</journal>
<pages>9--1875</pages>
<contexts>
<context position="6568" citStr="Braun et al., 2008" startWordPosition="965" endWordPosition="968">guish speech sounds of various type. The method compares the acoustic and auditory-perceptual characteristics of uttered phones on a frame-by-frame basis. In doing so, it utilizes a similarity measure based on radial basis function kernel or RBF kernel, which is compared with a Euclidean distance measure that was used in (Koniaris and Engwall, 2011; Koniaris et al., 2013). The motivation for this arrives from the fact that the data become sparse in a high dimensional space and hence choosing RBF kernel seems a more suitable solution since it is considered more appropriate for such conditions (Braun et al., 2008). Roughly speaking, the method performs a comparison between speech sounds generated by a group of native speakers with the corresponding speech sounds generated by different L2 groups of speakers. This is done separately for each phoneme category and the uttered phones are transformed into their auditory representations for the native speech, and into their spectrum representations for the non-native speech. In each domain, a distortion measure based on the RBF kernel is computed for each speech frame and then the two distortion measures are explored – considering all the frames – to investig</context>
</contexts>
<marker>Braun, Buhmann, Müller, 2008</marker>
<rawString>Braun, M. L., Buhmann, J. M., and Müller, K.-R. (2008). On relevant dimensions in kernel feature spaces. J. Machine Learn. Research, 9:1875–1908.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Delmonte</author>
</authors>
<title>SLIM prosodic automatic tools for self-learning instruction.</title>
<date>2000</date>
<journal>Speech Communication,</journal>
<pages>30--2</pages>
<contexts>
<context position="4770" citStr="Delmonte, 2000" startWordPosition="685" endWordPosition="686">In (Wei et al., 2009), the authors use support vector machines (SVM) to model phones with several parallel acoustic models that represent the variation in pronunciation at various proficiency levels. This approach seems to achieve better results in comparison to more traditional posterior probability based methods. Since the pronunciation of a phone is not only related to its acoustics, aspects, such as fluency, syllable structure, word stress, intonation, prosody or segmental quality may also be considered for investigation of pronunciation errors. For example, the work that is presented in (Delmonte, 2000) concerns a prosodic module of a CALL system called SLIM. This module deals with phonetic and prosodic problems both at the word but also at the segmental level. Prosodic measures based on F0, power and duration of L2 and L1 speech are used in (Yamashita et al., 2005) within a multiple regression framework to predict the prosodic proficiency of L2 learners. In (Raux and Kawahara, 2002), a probabilistic algorithm is applied to derive intelligibility from error rates and also define a function of error priority to indicate which errors are most critical to intelligibility. Finally, in (Xu et al.</context>
</contexts>
<marker>Delmonte, 2000</marker>
<rawString>Delmonte, R. (2000). SLIM prosodic automatic tools for self-learning instruction. Speech Communication, 30(2-3):145–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Flege</author>
</authors>
<title>Second-language speech learning: theory, findings, and problems.</title>
<date>1995</date>
<publisher>York Press Inc.</publisher>
<location>Timonium, MD:</location>
<contexts>
<context position="1724" citStr="Flege, 1995" startWordPosition="240" endWordPosition="241">ciation error detection, similarity measure, radial basis function kernel, phoneme, second language learning. Christos Koniaris 2014. An approach to measure pronunciation similarity in second language learning using radial basis function kernel. Proceedings of the third workshop on NLP for computer-assisted language learning. NEALT Proceedings Series 22 / Linköping Electronic Conference Proceedings 107: 74–86. 74 1 Introduction Second language (L2) speakers are generally having trouble with certain phonemes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into </context>
</contexts>
<marker>Flege, 1995</marker>
<rawString>Flege, J. E. (1995). Second-language speech learning: theory, findings, and problems. Strange, W. (Ed.), Speech Perception and Linguistic Experience: Theoretical and Methodological Issues in Cross-Language Speech Research. Timonium, MD: York Press Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Franco</author>
<author>L Neumeyer</author>
<author>Y Kim</author>
<author>O Ronen</author>
</authors>
<title>Automatic pronunciation scoring for language instruction.</title>
<date>1997</date>
<booktitle>In IEEE Int. Conf. Acoust., Speech, Sig. Proc.,</booktitle>
<pages>1471--1474</pages>
<location>Munich, Germany,</location>
<contexts>
<context position="2220" citStr="Franco et al., 1997" startWordPosition="314" endWordPosition="317">le with certain phonemes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunciation scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone log-likelihood, are compared to human listeners’ evaluation. The experiments show that certain scores, such as the log-posterior and the normalized duration correlate well with human ratings. Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in (Witt and Young, 2000), which measures the quality of pronunciations of non-native speakers. The</context>
</contexts>
<marker>Franco, Neumeyer, Kim, Ronen, 1997</marker>
<rawString>Franco, H., Neumeyer, L., Kim, Y., and Ronen, O. (1997). Automatic pronunciation scoring for language instruction. In IEEE Int. Conf. Acoust., Speech, Sig. Proc., Munich, Germany, pages 1471–1474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Guion</author>
<author>J E Flege</author>
<author>R Ahahane-Yamada</author>
<author>J C Pruitt</author>
</authors>
<title>An investigation of current models of second language speech perception: the case of japanese adults’ perception of english consonants.</title>
<date>2000</date>
<journal>J. Acoust. Soc. Am.,</journal>
<volume>107</volume>
<issue>5</issue>
<contexts>
<context position="1745" citStr="Guion et al., 2000" startWordPosition="242" endWordPosition="245"> detection, similarity measure, radial basis function kernel, phoneme, second language learning. Christos Koniaris 2014. An approach to measure pronunciation similarity in second language learning using radial basis function kernel. Proceedings of the third workshop on NLP for computer-assisted language learning. NEALT Proceedings Series 22 / Linköping Electronic Conference Proceedings 107: 74–86. 74 1 Introduction Second language (L2) speakers are generally having trouble with certain phonemes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunci</context>
</contexts>
<marker>Guion, Flege, Ahahane-Yamada, Pruitt, 2000</marker>
<rawString>Guion, S. G., Flege, J. E., Ahahane-Yamada, R., and Pruitt, J. C. (2000). An investigation of current models of second language speech perception: the case of japanese adults’ perception of english consonants. J. Acoust. Soc. Am., 107(5):2711–2724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Koniaris</author>
<author>O Engwall</author>
</authors>
<title>Phoneme level non-native pronunciation analysis by an auditory model-based native assessment scheme.</title>
<date>2011</date>
<booktitle>In Interspeech,</booktitle>
<pages>1157--1160</pages>
<location>Florence, Italy,</location>
<contexts>
<context position="6299" citStr="Koniaris and Engwall, 2011" startWordPosition="920" endWordPosition="923">itory model (van de Par et al., 2002) is presented that models the native perception to evaluate non-native pronunciations based on acoustic and auditory processing of the speech sounds. The fundamental assumption is based on the ability of the human auditory system to distinguish speech sounds of various type. The method compares the acoustic and auditory-perceptual characteristics of uttered phones on a frame-by-frame basis. In doing so, it utilizes a similarity measure based on radial basis function kernel or RBF kernel, which is compared with a Euclidean distance measure that was used in (Koniaris and Engwall, 2011; Koniaris et al., 2013). The motivation for this arrives from the fact that the data become sparse in a high dimensional space and hence choosing RBF kernel seems a more suitable solution since it is considered more appropriate for such conditions (Braun et al., 2008). Roughly speaking, the method performs a comparison between speech sounds generated by a group of native speakers with the corresponding speech sounds generated by different L2 groups of speakers. This is done separately for each phoneme category and the uttered phones are transformed into their auditory representations for the </context>
<context position="14093" citStr="Koniaris and Engwall, 2011" startWordPosition="2232" endWordPosition="2235">in (van de Par et al., 2002). Analogously, all data from non-native speech of each language group ℓ are used to compute Eq. (1) and, separately, all data from native speech, too. Next, the similarity measure Aℓ is calculated using the native perceptual distortion and the non-native spectral distortion measures and also the corresponding similarity measure for the native speakers An using the native perceptual and spectral measures. Then for each phoneme class, the RBF kernel-based nPAD Θr bf ℓ is computed for every L2 background using Eq. (4). Finally, a Euclidean-based nPAD Θℓ, described in (Koniaris and Engwall, 2011; Koniaris et al., 2013), is calculated by considering Euclidean distances in Eqs. (1) and (2), i.e., φ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2 and υ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2, respectively. 3 Experiments This section describes the experiments and discusses the findings of the RBF kernel-based approach in relation to the Euclidean-based approach and the theoretical linguistic survey presented in (Bannert, 1984). 3.1 Speech data The speech data were recorded with a sampling frequency of 16 kHz consisting of 23 phonetically rich single words and 55 sentences of varying complexity and length. The</context>
</contexts>
<marker>Koniaris, Engwall, 2011</marker>
<rawString>Koniaris, C. and Engwall, O. (2011). Phoneme level non-native pronunciation analysis by an auditory model-based native assessment scheme. In Interspeech, Florence, Italy, pages 1157–1160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Koniaris</author>
<author>G Salvi</author>
<author>O Engwall</author>
</authors>
<title>On mispronunciation analysis of individual foreign speakers using auditory periphery models.</title>
<date>2013</date>
<journal>Speech Communication,</journal>
<volume>55</volume>
<issue>5</issue>
<contexts>
<context position="6323" citStr="Koniaris et al., 2013" startWordPosition="924" endWordPosition="927">l., 2002) is presented that models the native perception to evaluate non-native pronunciations based on acoustic and auditory processing of the speech sounds. The fundamental assumption is based on the ability of the human auditory system to distinguish speech sounds of various type. The method compares the acoustic and auditory-perceptual characteristics of uttered phones on a frame-by-frame basis. In doing so, it utilizes a similarity measure based on radial basis function kernel or RBF kernel, which is compared with a Euclidean distance measure that was used in (Koniaris and Engwall, 2011; Koniaris et al., 2013). The motivation for this arrives from the fact that the data become sparse in a high dimensional space and hence choosing RBF kernel seems a more suitable solution since it is considered more appropriate for such conditions (Braun et al., 2008). Roughly speaking, the method performs a comparison between speech sounds generated by a group of native speakers with the corresponding speech sounds generated by different L2 groups of speakers. This is done separately for each phoneme category and the uttered phones are transformed into their auditory representations for the native speech, and into </context>
<context position="8354" citStr="Koniaris et al., 2013" startWordPosition="1234" endWordPosition="1237">tion errors is done on the speech signal level by comparing the similarities between the auditory perceptual domain of the native speech and the power spectrum domain of the non-native speech. It is assumed that a non-native acoustic representation will have very similar characteristics to native provided that the non-native speech is produced without significant mispronunciation. On the other hand, if the non-native speech suffers from severe pronunciation errors then the two representations, of the L2 and L1 speakers, will differ a lot and thus the measured similarities will become minimal (Koniaris et al., 2013). In short, the approach tries to measure the distortion in a set of phones that belong to a specific phoneme, produced by a group of native speakers n and compare it to that of non-native speakers of some specific language background ℓ. For this, it is assumed that some form of acoustic representation x is extracted from the speech signal s of a phone p to evaluate the distortion measure φ in the corresponding transformed domain, where φ : RN x RN — R+, with R+ denoting the non-negative real numbers and N indicating the dimensionality of the vector x. Then, the RBF kernel-based similarity mea</context>
<context position="9944" citStr="Koniaris et al., 2013" startWordPosition="1512" endWordPosition="1515">transformed into the auditory model output representation y. Again, 76 a RBF kernel-based distortion measure is computed in the auditory domain υ : RM × RM → R+, where M is the dimensionality of the internal representation y, as υ(si,ˆsi,j) = eγky(si)−y(ˆsi,j)k2. (2) The above distortion measures of Eqs. (1) and (2) are then compared using the following similarity measure 1 []2 , υ(si,ˆsi,j) − φ(si,ˆsi,j) (3) Ji j∈Ji where i ∈ I and j ∈ Ji represent a finite frame sequence and a finite set of acoustic perturbations, respectively. This measure is used to find mispronunciations as described in (Koniaris et al., 2013), i.e., by computing the distortion measure υ(si,ˆsi,j) using only native speech and the spectral distortion measure φ(si,ˆsi,j), calculated separately for non-native (and thus computing Aℓ) and native speech (and thus computing An). Finally, the native-perceptual assessment degree (nPAD) is computed for every phoneme and L1 background as nPAD = Aℓ ,(4) An which is a normalized ratio that shows the degree of the similarity between the native perceptual outcome and the non-native speech signal representation, as compared to the native-only case. The higher the nPAD value is, the more problemati</context>
<context position="14117" citStr="Koniaris et al., 2013" startWordPosition="2236" endWordPosition="2239">. Analogously, all data from non-native speech of each language group ℓ are used to compute Eq. (1) and, separately, all data from native speech, too. Next, the similarity measure Aℓ is calculated using the native perceptual distortion and the non-native spectral distortion measures and also the corresponding similarity measure for the native speakers An using the native perceptual and spectral measures. Then for each phoneme class, the RBF kernel-based nPAD Θr bf ℓ is computed for every L2 background using Eq. (4). Finally, a Euclidean-based nPAD Θℓ, described in (Koniaris and Engwall, 2011; Koniaris et al., 2013), is calculated by considering Euclidean distances in Eqs. (1) and (2), i.e., φ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2 and υ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2, respectively. 3 Experiments This section describes the experiments and discusses the findings of the RBF kernel-based approach in relation to the Euclidean-based approach and the theoretical linguistic survey presented in (Bannert, 1984). 3.1 Speech data The speech data were recorded with a sampling frequency of 16 kHz consisting of 23 phonetically rich single words and 55 sentences of varying complexity and length. The utterances were specifi</context>
</contexts>
<marker>Koniaris, Salvi, Engwall, 2013</marker>
<rawString>Koniaris, C., Salvi, G., and Engwall, O. (2013). On mispronunciation analysis of individual foreign speakers using auditory periphery models. Speech Communication, 55(5):691–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Neumeyer</author>
<author>H Franco</author>
<author>V Digalakis</author>
<author>M Weintraub</author>
</authors>
<title>Automatic scoring of pronunciation quality.</title>
<date>2000</date>
<journal>Speech Communication,</journal>
<pages>30--83</pages>
<contexts>
<context position="2244" citStr="Neumeyer et al., 2000" startWordPosition="318" endWordPosition="321">mes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunciation scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone log-likelihood, are compared to human listeners’ evaluation. The experiments show that certain scores, such as the log-posterior and the normalized duration correlate well with human ratings. Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in (Witt and Young, 2000), which measures the quality of pronunciations of non-native speakers. The idea is to score each p</context>
</contexts>
<marker>Neumeyer, Franco, Digalakis, Weintraub, 2000</marker>
<rawString>Neumeyer, L., Franco, H., Digalakis, V., and Weintraub, M. (2000). Automatic scoring of pronunciation quality. Speech Communication, 30:83–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Neumeyer</author>
<author>H Franco</author>
<author>M Weintraub</author>
<author>P Price</author>
</authors>
<title>Automatic text-independent pronunciation scoring of foreign language student speech.</title>
<date>1996</date>
<booktitle>In Int. Conf. Spoken Lang. Proc.,</booktitle>
<pages>1457--1460</pages>
<location>Philadelphia, PA , USA,</location>
<contexts>
<context position="2199" citStr="Neumeyer et al., 1996" startWordPosition="310" endWordPosition="313"> generally having trouble with certain phonemes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunciation scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone log-likelihood, are compared to human listeners’ evaluation. The experiments show that certain scores, such as the log-posterior and the normalized duration correlate well with human ratings. Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in (Witt and Young, 2000), which measures the quality of pronunciations of non</context>
</contexts>
<marker>Neumeyer, Franco, Weintraub, Price, 1996</marker>
<rawString>Neumeyer, L., Franco, H., Weintraub, M., and Price, P. (1996). Automatic text-independent pronunciation scoring of foreign language student speech. In Int. Conf. Spoken Lang. Proc., Philadelphia, PA , USA, pages 1457–1460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J G Park</author>
<author>S C Rhee</author>
</authors>
<title>Development of the knowledge-based spoken english evaluation system and its application.</title>
<date>2004</date>
<booktitle>In ISCA Interspeech, Jeju Island, South Korea,</booktitle>
<pages>1681--1684</pages>
<contexts>
<context position="3095" citStr="Park and Rhee, 2004" startWordPosition="444" endWordPosition="447">man listeners’ evaluation. The experiments show that certain scores, such as the log-posterior and the normalized duration correlate well with human ratings. Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in (Witt and Young, 2000), which measures the quality of pronunciations of non-native speakers. The idea is to score each phone of an utterance depending on how close the pronunciation of the non-native speaker is to that of native speakers. A method that combines knowledge from acoustic-phonetic, linguistic, and from expert listeners is presented in (Park and Rhee, 2004), in which the analysis of the results is done by finding the correlation of human listeners and machine-based rating. In (Truong et al., 2005), a set of classification approaches based on linear discriminant analysis (LDA) and decision trees is presented. These classifiers are used to analyze the mispronunciations of second language learners of Dutch. In (Tepperman and Narayanan, 2008), the research is oriented in introducing articulatory information in PED by reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan, 2005) and deriving new articulatory-based features</context>
</contexts>
<marker>Park, Rhee, 2004</marker>
<rawString>Park, J. G. and Rhee, S. C. (2004). Development of the knowledge-based spoken english evaluation system and its application. In ISCA Interspeech, Jeju Island, South Korea, pages 1681–1684.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Piske</author>
<author>J Flege</author>
<author>I MacKay</author>
</authors>
<title>Factors affecting degree of foreign accent in an l2: a review.</title>
<date>2001</date>
<journal>J. Phonetics,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="1881" citStr="Piske et al., 2001" startWordPosition="264" endWordPosition="267">measure pronunciation similarity in second language learning using radial basis function kernel. Proceedings of the third workshop on NLP for computer-assisted language learning. NEALT Proceedings Series 22 / Linköping Electronic Conference Proceedings 107: 74–86. 74 1 Introduction Second language (L2) speakers are generally having trouble with certain phonemes of the target language that do not exist in the sound system of their native language (Flege, 1995; Guion et al., 2000). It is therefore common practice to include speech sounds from their first language (L1) or ignore unfamiliar ones (Piske et al., 2001) while practicing a new language. Within a computer-assisted language learning (CALL) program, the task of automatic pronunciation error detection (PED) is to find effective techniques to diagnose and detect mispronunciations in order to assist L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunciation scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone log-likelihood, are compared to human li</context>
</contexts>
<marker>Piske, Flege, MacKay, 2001</marker>
<rawString>Piske, T., Flege, J., and MacKay, I. (2001). Factors affecting degree of foreign accent in an l2: a review. J. Phonetics, 29(2):191–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Raux</author>
<author>T Kawahara</author>
</authors>
<title>Automatic intelligibility assessment and diagnosis of critical pronunciation errors for computer-assisted pronunciation learning.</title>
<date>2002</date>
<booktitle>In Int. Conf. Spoken Lang. Proc.,</booktitle>
<pages>737--740</pages>
<location>Denver, CO, USA,</location>
<contexts>
<context position="5158" citStr="Raux and Kawahara, 2002" startWordPosition="749" endWordPosition="752">acoustics, aspects, such as fluency, syllable structure, word stress, intonation, prosody or segmental quality may also be considered for investigation of pronunciation errors. For example, the work that is presented in (Delmonte, 2000) concerns a prosodic module of a CALL system called SLIM. This module deals with phonetic and prosodic problems both at the word but also at the segmental level. Prosodic measures based on F0, power and duration of L2 and L1 speech are used in (Yamashita et al., 2005) within a multiple regression framework to predict the prosodic proficiency of L2 learners. In (Raux and Kawahara, 2002), a probabilistic algorithm is applied to derive intelligibility from error rates and also define a function of error priority to indicate which errors are most critical to intelligibility. Finally, in (Xu et al., 2009), linguistic knowledge obtained from the non-native speakers’ most common mistakes, and pronunciation space constructed using revised log-posterior probability vectors is considered along with an SVM classifier. 75 In this paper, a PED method based on psychoacoustic knowledge from a spectral auditory model (van de Par et al., 2002) is presented that models the native perception </context>
</contexts>
<marker>Raux, Kawahara, 2002</marker>
<rawString>Raux, A. and Kawahara, T. (2002). Automatic intelligibility assessment and diagnosis of critical pronunciation errors for computer-assisted pronunciation learning. In Int. Conf. Spoken Lang. Proc., Denver, CO, USA, pages 737–740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sjölander</author>
</authors>
<title>An HMM-based system for automatic segmentation and alignment of speech. In Fonetik,</title>
<date>2003</date>
<pages>93--96</pages>
<contexts>
<context position="16535" citStr="Sjölander, 2003" startWordPosition="2627" endWordPosition="2628">tely 30 minutes. In addition, 9 male and 2 female Swedish speakers without regional accent varieties were also recorded once each. Non-linguistic information, such as coughs, long pauses, repetitions or fillers was excluded from the final corpus used for experiments. Each speech file was accompanied by a text file, the content of which was adjusted to the actual utterance, thus any deletion or insertion that may have occurred was not considered into the text file. A phone-level transcription was then automatically generated from the speech signal and the text file, using an HMM-based aligner (Sjölander, 2003). These phonelevel transcription files were used to separate the speech data into phoneme categories. The material contained all Swedish phonemes, but the two short and more open pre-r allophones /æ/, /œ/ and the retroflexes /ï/, /ã/, and /í/ were not considered in the experiments because the number of occurrences in the database was not sufficiently large. For each language background, the speech data were divided into different phoneme categories according to the phone-level transcription files. The speech signal was first pre-emphasized and then windowed every 25 ms with an overlap of 10 ms</context>
</contexts>
<marker>Sjölander, 2003</marker>
<rawString>Sjölander, K. (2003). An HMM-based system for automatic segmentation and alignment of speech. In Fonetik, pages 93–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Strik</author>
<author>K Truong</author>
<author>F de Wet</author>
<author>C Cucchiarini</author>
</authors>
<title>Comparing different approaches for automatic pronunciation error detection.</title>
<date>2009</date>
<journal>Speech Communication,</journal>
<volume>51</volume>
<issue>10</issue>
<marker>Strik, Truong, de Wet, Cucchiarini, 2009</marker>
<rawString>Strik, H., Truong, K., de Wet, F., and Cucchiarini, C. (2009). Comparing different approaches for automatic pronunciation error detection. Speech Communication, 51(10):845–852.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tepperman</author>
<author>S Narayanan</author>
</authors>
<title>Hidden-articulator markov models for pronunciation evaluation.</title>
<date>2005</date>
<booktitle>In Proc. ASRU,</booktitle>
<pages>174--179</pages>
<location>San Juan, Puerto Rico,</location>
<contexts>
<context position="3650" citStr="Tepperman and Narayanan, 2005" startWordPosition="524" endWordPosition="527">linguistic, and from expert listeners is presented in (Park and Rhee, 2004), in which the analysis of the results is done by finding the correlation of human listeners and machine-based rating. In (Truong et al., 2005), a set of classification approaches based on linear discriminant analysis (LDA) and decision trees is presented. These classifiers are used to analyze the mispronunciations of second language learners of Dutch. In (Tepperman and Narayanan, 2008), the research is oriented in introducing articulatory information in PED by reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan, 2005) and deriving new articulatory-based features for classification. In (Strik et al., 2009), four different classification systems are examined: a GOP-based, one combining cepstral coefficients and LDA, a method based on the work described in (Weigelt et al., 1990), which is an algorithm that discriminates voiceless fricatives from voiceless plosives, and an LDA-acoustic-phonetic feature classifier. It is found that the two LDA-based classification systems perform better in mispronunciation detection. In (Wei et al., 2009), the authors use support vector machines (SVM) to model phones with sever</context>
</contexts>
<marker>Tepperman, Narayanan, 2005</marker>
<rawString>Tepperman, J. and Narayanan, S. (2005). Hidden-articulator markov models for pronunciation evaluation. In Proc. ASRU, San Juan, Puerto Rico, pages 174–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tepperman</author>
<author>S Narayanan</author>
</authors>
<title>Using articulatory representations to detect segmental errors in nonnative pronunciation.</title>
<date>2008</date>
<journal>IEEE Tr. Audio, Speech, Lang. Proc.,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="3484" citStr="Tepperman and Narayanan, 2008" startWordPosition="503" endWordPosition="506"> utterance depending on how close the pronunciation of the non-native speaker is to that of native speakers. A method that combines knowledge from acoustic-phonetic, linguistic, and from expert listeners is presented in (Park and Rhee, 2004), in which the analysis of the results is done by finding the correlation of human listeners and machine-based rating. In (Truong et al., 2005), a set of classification approaches based on linear discriminant analysis (LDA) and decision trees is presented. These classifiers are used to analyze the mispronunciations of second language learners of Dutch. In (Tepperman and Narayanan, 2008), the research is oriented in introducing articulatory information in PED by reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan, 2005) and deriving new articulatory-based features for classification. In (Strik et al., 2009), four different classification systems are examined: a GOP-based, one combining cepstral coefficients and LDA, a method based on the work described in (Weigelt et al., 1990), which is an algorithm that discriminates voiceless fricatives from voiceless plosives, and an LDA-acoustic-phonetic feature classifier. It is found that the two LDA-base</context>
</contexts>
<marker>Tepperman, Narayanan, 2008</marker>
<rawString>Tepperman, J. and Narayanan, S. (2008). Using articulatory representations to detect segmental errors in nonnative pronunciation. IEEE Tr. Audio, Speech, Lang. Proc., 16(1):8–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K P Truong</author>
<author>A Neri</author>
<author>F de Wet</author>
<author>C Cucchiarini</author>
<author>H Strik</author>
</authors>
<title>Automatic detection of frequent pronunciation errors made by L2-learners.</title>
<date>2005</date>
<booktitle>In ISCA Interspeech,</booktitle>
<pages>1345--1348</pages>
<location>Lisbon, Portugal,</location>
<marker>Truong, Neri, de Wet, Cucchiarini, Strik, 2005</marker>
<rawString>Truong, K. P., Neri, A., de Wet, F., Cucchiarini, C., and Strik, H. (2005). Automatic detection of frequent pronunciation errors made by L2-learners. In ISCA Interspeech, Lisbon, Portugal, pages 1345–1348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S van de Par</author>
<author>A Kohlrausch</author>
<author>G Charestan</author>
<author>R Heusdens</author>
</authors>
<title>A new psychoacoustical masking model for audio coding applications.</title>
<date>2002</date>
<booktitle>In IEEE Int. Conf. on Acoust., Speech, Sig. Proc.,</booktitle>
<volume>2</volume>
<pages>1805--1808</pages>
<location>Orlando, FL, USA,</location>
<marker>van de Par, Kohlrausch, Charestan, Heusdens, 2002</marker>
<rawString>van de Par, S., Kohlrausch, A., Charestan, G., and Heusdens, R. (2002). A new psychoacoustical masking model for audio coding applications. In IEEE Int. Conf. on Acoust., Speech, Sig. Proc., Orlando, FL, USA, volume 2, pages 1805–1808.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wei</author>
<author>G Hu</author>
<author>Y Hu</author>
<author>R-H Wang</author>
</authors>
<title>A new method for mispronunciation detection using support vector machine based on pronunciation space models.</title>
<date>2009</date>
<journal>Speech Communication,</journal>
<volume>51</volume>
<issue>10</issue>
<contexts>
<context position="4176" citStr="Wei et al., 2009" startWordPosition="597" endWordPosition="600">y reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan, 2005) and deriving new articulatory-based features for classification. In (Strik et al., 2009), four different classification systems are examined: a GOP-based, one combining cepstral coefficients and LDA, a method based on the work described in (Weigelt et al., 1990), which is an algorithm that discriminates voiceless fricatives from voiceless plosives, and an LDA-acoustic-phonetic feature classifier. It is found that the two LDA-based classification systems perform better in mispronunciation detection. In (Wei et al., 2009), the authors use support vector machines (SVM) to model phones with several parallel acoustic models that represent the variation in pronunciation at various proficiency levels. This approach seems to achieve better results in comparison to more traditional posterior probability based methods. Since the pronunciation of a phone is not only related to its acoustics, aspects, such as fluency, syllable structure, word stress, intonation, prosody or segmental quality may also be considered for investigation of pronunciation errors. For example, the work that is presented in (Delmonte, 2000) conce</context>
</contexts>
<marker>Wei, Hu, Hu, Wang, 2009</marker>
<rawString>Wei, S., Hu, G., Hu, Y., and Wang, R.-H. (2009). A new method for mispronunciation detection using support vector machine based on pronunciation space models. Speech Communication, 51(10):896–905.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L F Weigelt</author>
<author>S J Sadoff</author>
<author>J D Miller</author>
</authors>
<title>Plosive/fricative distinction: the voiceless case.</title>
<date>1990</date>
<journal>J. Acoust. Soc. Am.,</journal>
<pages>87--2729</pages>
<contexts>
<context position="3913" citStr="Weigelt et al., 1990" startWordPosition="562" endWordPosition="565">iscriminant analysis (LDA) and decision trees is presented. These classifiers are used to analyze the mispronunciations of second language learners of Dutch. In (Tepperman and Narayanan, 2008), the research is oriented in introducing articulatory information in PED by reformulating the hidden-articulator Markov models (HAMM) (Tepperman and Narayanan, 2005) and deriving new articulatory-based features for classification. In (Strik et al., 2009), four different classification systems are examined: a GOP-based, one combining cepstral coefficients and LDA, a method based on the work described in (Weigelt et al., 1990), which is an algorithm that discriminates voiceless fricatives from voiceless plosives, and an LDA-acoustic-phonetic feature classifier. It is found that the two LDA-based classification systems perform better in mispronunciation detection. In (Wei et al., 2009), the authors use support vector machines (SVM) to model phones with several parallel acoustic models that represent the variation in pronunciation at various proficiency levels. This approach seems to achieve better results in comparison to more traditional posterior probability based methods. Since the pronunciation of a phone is not</context>
</contexts>
<marker>Weigelt, Sadoff, Miller, 1990</marker>
<rawString>Weigelt, L. F., Sadoff, S. J., and Miller, J. D. (1990). Plosive/fricative distinction: the voiceless case. J. Acoust. Soc. Am., 87:2729–2737.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wik</author>
<author>A Hjalmarsson</author>
</authors>
<title>Embodied conversational agents in computer assisted language learning.</title>
<date>2009</date>
<journal>Speech Communication,</journal>
<volume>51</volume>
<issue>10</issue>
<contexts>
<context position="14817" citStr="Wik and Hjalmarsson, 2009" startWordPosition="2344" endWordPosition="2347">e., φ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2 and υ(si,ˆsi,j) =k x(si) − x(ˆsi,j) k2, respectively. 3 Experiments This section describes the experiments and discusses the findings of the RBF kernel-based approach in relation to the Euclidean-based approach and the theoretical linguistic survey presented in (Bannert, 1984). 3.1 Speech data The speech data were recorded with a sampling frequency of 16 kHz consisting of 23 phonetically rich single words and 55 sentences of varying complexity and length. The utterances were specifically designed for L2 learners of Swedish that were using a CALL program (Wik and Hjalmarsson, 2009). The collection of the data was done through a desktop microphone while 78 L1 bkgr. male/female utt. L1 bkgr. male/female utt. L1 bkgr. male/female utt. Eng.(US) 1/1 318 Russian 1/3 583 Arabic 0/1 164 German 2/0 249 Greek 3/0 393 Chinese 2/3 832 French 3/0 347 Spanish 4/1 882 Persian 3/3 987 Polish 0/2 317 Turkish 4/0 604 Swedish 9/2 888 Table 1: Distribution of the total number of male and female speakers and the number of utterances (utt.) for each language background (L1 bkgr.). students repeated a word or sentence after the virtual language tutor, the main character of the program. The pr</context>
</contexts>
<marker>Wik, Hjalmarsson, 2009</marker>
<rawString>Wik, P. and Hjalmarsson, A. (2009). Embodied conversational agents in computer assisted language learning. Speech Communication, 51(10):1024–1037.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Witt</author>
<author>S Young</author>
</authors>
<title>Phone-level pronunciation scoring and assessment for interactive language learning.</title>
<date>2000</date>
<journal>Speech Communication,</journal>
<pages>30--95</pages>
<contexts>
<context position="2746" citStr="Witt and Young, 2000" startWordPosition="390" endWordPosition="393"> L2 learners to improve their oral capabilities. In (Neumeyer et al., 1996; Franco et al., 1997; Neumeyer et al., 2000) a system used for performing automatic speech recognition (ASR) is turned into an automatic pronunciation scoring system, in which several different scores, e.g., hidden Markov models (HMM) phone log-likelihood, are compared to human listeners’ evaluation. The experiments show that certain scores, such as the log-posterior and the normalized duration correlate well with human ratings. Scoring is also the main characteristic of the goodness of pronunciation (GOP) proposed in (Witt and Young, 2000), which measures the quality of pronunciations of non-native speakers. The idea is to score each phone of an utterance depending on how close the pronunciation of the non-native speaker is to that of native speakers. A method that combines knowledge from acoustic-phonetic, linguistic, and from expert listeners is presented in (Park and Rhee, 2004), in which the analysis of the results is done by finding the correlation of human listeners and machine-based rating. In (Truong et al., 2005), a set of classification approaches based on linear discriminant analysis (LDA) and decision trees is prese</context>
</contexts>
<marker>Witt, Young, 2000</marker>
<rawString>Witt, S. M. and Young, S. (2000). Phone-level pronunciation scoring and assessment for interactive language learning. Speech Communication, 30:95–108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Xu</author>
<author>J Jiang</author>
<author>Z Chen</author>
<author>B Xu</author>
</authors>
<title>Automatic pronunciation error detection based on linguistic knowledge and pronunciation space.</title>
<date>2009</date>
<booktitle>In IEEE Int. Conf. Acoust. Speech Sig. Proc. (ICASSP),</booktitle>
<pages>4841--4844</pages>
<location>Taipei, Taiwan,</location>
<contexts>
<context position="5377" citStr="Xu et al., 2009" startWordPosition="783" endWordPosition="786">te, 2000) concerns a prosodic module of a CALL system called SLIM. This module deals with phonetic and prosodic problems both at the word but also at the segmental level. Prosodic measures based on F0, power and duration of L2 and L1 speech are used in (Yamashita et al., 2005) within a multiple regression framework to predict the prosodic proficiency of L2 learners. In (Raux and Kawahara, 2002), a probabilistic algorithm is applied to derive intelligibility from error rates and also define a function of error priority to indicate which errors are most critical to intelligibility. Finally, in (Xu et al., 2009), linguistic knowledge obtained from the non-native speakers’ most common mistakes, and pronunciation space constructed using revised log-posterior probability vectors is considered along with an SVM classifier. 75 In this paper, a PED method based on psychoacoustic knowledge from a spectral auditory model (van de Par et al., 2002) is presented that models the native perception to evaluate non-native pronunciations based on acoustic and auditory processing of the speech sounds. The fundamental assumption is based on the ability of the human auditory system to distinguish speech sounds of vario</context>
</contexts>
<marker>Xu, Jiang, Chen, Xu, 2009</marker>
<rawString>Xu, S., Jiang, J., Chen, Z., and Xu, B. (2009). Automatic pronunciation error detection based on linguistic knowledge and pronunciation space. In IEEE Int. Conf. Acoust. Speech Sig. Proc. (ICASSP), Taipei, Taiwan, pages 4841–4844.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Yamashita</author>
<author>K Kato</author>
<author>K Nozawa</author>
</authors>
<title>Automatic scoring for prosodic proficiency of english sentences spoken by japanese based on utterance comparison.</title>
<date>2005</date>
<journal>IECE Trans. Inform. Systems,</journal>
<pages>88--496</pages>
<contexts>
<context position="5038" citStr="Yamashita et al., 2005" startWordPosition="731" endWordPosition="734">to more traditional posterior probability based methods. Since the pronunciation of a phone is not only related to its acoustics, aspects, such as fluency, syllable structure, word stress, intonation, prosody or segmental quality may also be considered for investigation of pronunciation errors. For example, the work that is presented in (Delmonte, 2000) concerns a prosodic module of a CALL system called SLIM. This module deals with phonetic and prosodic problems both at the word but also at the segmental level. Prosodic measures based on F0, power and duration of L2 and L1 speech are used in (Yamashita et al., 2005) within a multiple regression framework to predict the prosodic proficiency of L2 learners. In (Raux and Kawahara, 2002), a probabilistic algorithm is applied to derive intelligibility from error rates and also define a function of error priority to indicate which errors are most critical to intelligibility. Finally, in (Xu et al., 2009), linguistic knowledge obtained from the non-native speakers’ most common mistakes, and pronunciation space constructed using revised log-posterior probability vectors is considered along with an SVM classifier. 75 In this paper, a PED method based on psychoaco</context>
</contexts>
<marker>Yamashita, Kato, Nozawa, 2005</marker>
<rawString>Yamashita, Y., Kato, K., and Nozawa, K. (2005). Automatic scoring for prosodic proficiency of english sentences spoken by japanese based on utterance comparison. IECE Trans. Inform. Systems, E88-D:496–501.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>