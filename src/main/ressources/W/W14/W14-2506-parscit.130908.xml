<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008830">
<title confidence="0.998979">
Context-based Natural Language Processing for
GIS-based Vague Region Visualization
</title>
<author confidence="0.987209">
1,2Wei Chen
</author>
<affiliation confidence="0.9945045">
1Department of Computer Science and Engineering, 2Department of Geography
The Ohio State University, Columbus OH, USA 43210
</affiliation>
<email confidence="0.994604">
chen.1381@osu.edu
</email>
<sectionHeader confidence="0.99378" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999935521739131">
Vernacular regions such as central Ohio
are popularly used in everyday language;
but their vague and indeterministic bound-
aries affect the clarity of communicating
them over the geographic space. This pa-
per introduced a context-based natural
language processing approach to retrieve
geographic entities. Geographic entities
extracted from news articles were used as
location-based behavioral samples to map
out the vague region of central Ohio. Par-
ticularly, part of speech tagging and parse
tree generation were employed to filter out
candidate entities from English sentences.
Propositional logic of context (PLC) was
introduced and adapted to build the con-
textual model for deciding the member-
ship of named entities. Results were auto-
matically generated and visualized in GIS
using both symbol and density mapping.
Final maps were consistent with our intu-
ition and common sense knowledge of the
vague region.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999788893617022">
Central Ohio is commonly used vernacular term
to refer to an approximate area around the city of
Columbus in Ohio. Although it may be effortless
for humans to tell the relative location of this re-
gion, it remains challenging for computers to au-
tomatically locate this region by harvesting and
analyzing online data such as news articles. Com-
puters that are capable of automatically delineat-
ing such vague regions may be of potential use to
social science researchers for understanding other
concepts that may not be as obvious such as cul-
tural regions, the Muslim world.
In the study of vague regions, previous studies
introduced a behavioral method to map out down-
town Santa Barbara based on human survey data
(Montello, Goodchild, Gottsegen, &amp; Fohl, 2003).
Their approach collected hand-drawn point-based
locations and plotted them on the map of the city.
Such data collection process may be very costly
compared to computer-based automated ap-
proach. By comparison, natural language pro-
cessing (NLP) techniques such as part of speech
tagging and parse tree generation provide power-
ful linguistic analysis tools that can help quickly
retrieve data from a large number of corpus data
(Jurafsky, Martin, Kehler, Vander Linden, &amp;
Ward, 2000). However, these NLP techniques
have yet been widely used to extract geographic
entities for visualizing vague regions like central
Ohio.
On the other hand, linguistic contexts of named
entities are important for deciding its relevancy to
the underlying vague regions. For instance, for a
place to be part of central Ohio, it must be in the
context of Ohio as a precondition. Propositional
logic of context (PLC) is a logic model in the field
of artificial intelligence for formalizing contexts
into propositional calculus (BuvaE &amp; Mason,
1993). Based on PLC, an arbitrary predicate cal-
culus can be evaluated according to selected con-
texts.
In this paper, central Ohio is chosen as the ex-
perimental area to experiment the context-based
natural language approach for visualizing vague
regions. News articles are used and analyzed on
three contextual levels: document, paragraph and
sentence. Results are visualized in GIS.
</bodyText>
<subsectionHeader confidence="0.998543">
1.1 News data
</subsectionHeader>
<bodyText confidence="0.999776555555556">
News articles are extracted from LexisNexis, a
comprehensive database of both national and lo-
cal news (Smith, Ellenberg, Bell, &amp; Rubin, 2008).
All articles are retrieved based on caseless key-
word match for relevancy. The only keyword used
is central Ohio and only news articles that contain
this exact phrase are retrieved. As a result, 3281
different articles are collected which cover central
Ohio news from the year 1990 to the year 2013.
</bodyText>
<page confidence="0.969627">
8
</page>
<note confidence="0.3914095">
Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 8‚Äì12,
Baltimore, Maryland, USA, June 26, 2014. cÔøΩ2014 Association for Computational Linguistics
</note>
<subsectionHeader confidence="0.981106">
1.2 Geonames database
</subsectionHeader>
<bodyText confidence="0.976760111111111">
Geonames database contains names and locations
of geographic entities. We create our geonames
database two sources: the United States Geologi-
cal Survey&apos;s Geographic Names
Information Server (USGS, 2013) and Census
gazetteers (Census, 2013). Only place and feature
names in Ohio used for analysis. Table 1 summa-
rizes compositions of entities in our Ohio
geonames database.
</bodyText>
<table confidence="0.997205333333333">
Category Percentages
Administrative places 23.0% cities
(1054 records) 66.3% villages
10.6% CDPs (census desig-
nated place)
Geographic features 14.9% church
(67804 records) 13.7% school
12.6% populated place
among 53 categories
</table>
<tableCaption confidence="0.999938">
Table 1. Geographic named entities in Ohio
</tableCaption>
<sectionHeader confidence="0.93163" genericHeader="method">
2 Natural Language Processing
</sectionHeader>
<bodyText confidence="0.999977181818182">
Part of speech tagging and parse tree generation
are used to automatically extract geographic
named entities from news articles in this paper.
Part of speech (POS) tagging is the process of de-
ciding the functions of words such as nouns or
verbs. Parse tree generation is based on POS tag-
ging results. It aims to generate hierarchical rep-
resentations of sentences for semantic understand-
ing (Jurafsky et al., 2000). Noun phrases in the
parse tree are often useful indicators to named en-
tities in geolinguistic analysis (Chen et al., 2013).
</bodyText>
<subsectionHeader confidence="0.998988">
2.1 Part of speech tagging
</subsectionHeader>
<bodyText confidence="0.999782285714286">
Part-of-speech (POS) tagging assigns a POS tag
to each token in a sentence. A token can be either
a word or a punctuation. The single best POS tag
assigned to a token depends on the function of the
word, the tag set, and POS tagging algorithm
(Jurafsky et al., 2000). Contemporary POS tag-
gers can reach an average accuracy of above 97%
on tokens (Manning, 2011).
The part of speech tagger we use is Stanford
NLP tagger with english-caseless-left3words-
distsim tagger model. This tagger model is trained
with WSJ sections 0-18 and extra parser training
data using the left3words architecture. It includes
word shape and distributional similarity features
for training the tagger (Gimpel et al., 2010). The
results are represented using Penn Treebank tags
and the average parsing accuracy is above 97% on
sentences in news. Box 1 is the tagged sentence
from one article with POS tags appended after the
slash in uppercase letters. For a complete list, one
may refer to Penn Treebank tag sets.
</bodyText>
<equation confidence="0.850085">
Her/PRP$ friends/NNS at/IN the/DT Central/NNP
Ohio/NNP Nazarene/NNP Church/NNP Camp/NNP
she/PRP attended/VBD every/DT summer/NN in/IN Co-
lumbus/NNP convinced/VBD her/PRP to/TO
attend/VB Mount/NNP Vernon/NNP Nazarene/NNP Col-
lege/NNP in/IN Knox/JJ county/NN ,/, OH/NNP ./.
Box 1. Tagged sentence
</equation>
<subsectionHeader confidence="0.998245">
2.2 Parsing
</subsectionHeader>
<bodyText confidence="0.999843235294118">
Stanford parsers are used to produce the parse tree
from which noun phrases, named entity candi-
dates, can be extracted (De Marneffe,
MacCartney, &amp; Manning, 2006) . Fig.1 shows the
result of parsing the tagged sentence in Box 1. It
is observed that only noun phrases (NP) at the
lowest level of the tree are useful for extracting
named entities. Noun phrases at other levels con-
tain auxiliary structures such as prepositions often
do not suggest named entities.
In Fig.1, NPs in dashed rectangles are candi-
date entities that do not match any records in our
Ohio database. When looking up the database for
a match, determinants like the are skipped as well
as entity type terms like city and county. To find
the location of a matched entity, a SQL query is
used to return the latitude and longitude pair.
</bodyText>
<figureCaption confidence="0.979664">
Figure 1. Parse tree of tagged sentence in Box 1
</figureCaption>
<sectionHeader confidence="0.994809" genericHeader="method">
3 Geographic Information Retrieval
</sectionHeader>
<subsectionHeader confidence="0.997651">
3.1 Propositional logic of context (PLC)
</subsectionHeader>
<bodyText confidence="0.9999797">
As previously discussed, candidate named entities
are primarily noun phrases extracted at the root
level of a parse tree. However, not all such entities
should be considered as part of central Ohio. To
determine the membership, we may define fol-
lowing logic heuristics: if (1) the name of an entity
is in the same text segment as the phrase central
Ohio and (2) the entity is an Ohio place, then the
entity is of greater likelihood of being a central
Ohio place than otherwise. Here, Ohio and central
</bodyText>
<page confidence="0.989388">
9
</page>
<bodyText confidence="0.8702708">
Ohio are linguistic contexts for discriminating
central Ohio entities.
To formalize the contexts of analysis, we intro-
duce propositional logic of context (PLC) (BuvaE
&amp; Mason, 1993). Here, we only adapt its basic
form as it already suffice the needs of our analysis.
For detailed information of PLC, one may read the
original paper from BuvaE (BuvaE &amp; Mason,
1993). The minimum PLC definition is below:
x: subject
p: preposition about the subject
c: context
c1ÔÉôc2: logic AND, intersection of two contexts
c1ÔÉöc2: logic OR, union of two contexts
ist(c, p): the proposition p is true in context c.
</bodyText>
<subsectionHeader confidence="0.999316">
3.2 PLC-based matching and counting
</subsectionHeader>
<bodyText confidence="0.954997148148148">
Based on the PLC definition, we count the men-
tions of named entities in all news articles.
Here, we define the following PLC notations for
our analysis:
p: the preposition that x is a central Ohio city
c1: the context of Ohio
c2: the context of central Ohio
c3: the context of not-central Ohio
Ohio context is defined according to records in
geonames database. If an entity name is in the da-
tabase, it is said to be in the Ohio context. Central
Ohio context is defined as the text segment con-
taining both the entity name and the phrase central
Ohio. Not-central Ohio context is defined as the
text segment with the following terms in it:
north(ern) Ohio, northeast(ern) Ohio, east(ern)
Ohio, southeast(ern) Ohio, south(ern) Ohio,
southwest(ern) Ohio, west(ern) Ohio, and north-
west(ern) Ohio. Based on our observation, these
eight azimuth phrases are found to be good indi-
cators of places that are obviously not in central
Ohio.
Accordingly, three types of entity counts are
also developed.
(1)Positive count (E): the total number of occur-
rences of the name of an entity E in the context
c1ÔÉôc2.
</bodyText>
<listItem confidence="0.976896166666667">
(2) Neutral count (E): the total number of occur-
rences of the name of an entity E in the context
c1ÔÉôÔÉòc2ÔÉôÔÉòc3.
(3) Negative count (E): the total number of occur-
rences of the name of an entity E in the context
c1ÔÉôc3.
</listItem>
<subsectionHeader confidence="0.978197">
3.3 Count and normalization
</subsectionHeader>
<bodyText confidence="0.94371276">
We calculate the membership of an entity to the
concept central Ohio using following counting
and normalization rules. We define three variables
to count entity occurrences in different contexts:
Cpos : positive count of the entity E.
Cneg : negative count of the entity E.
Cneu : neutral count of the entity E.
IF ist(c1ÔÉôc2, p), Cpos++.
IF ist(c1ÔÉôc3, p), Cneg++.
IF ist(c1ÔÉôÔÉòc2ÔÉôÔÉòc3, p), Cneu++.
Based on observations, big cities like Colum-
bus are mentioned more frequently than other
smaller places in term of both Cpos and Cneg. As
it is the difference between Cpos and Cnegthat de-
termines the sign of the membership, we decide to
use Cneu as the normalization denominator for
calculating the membership.
Membership r of a place is calculated using
Equation 1. It is a real value between -1 and 1. All
places are classified by the sign of the member-
ship as either central Ohio or not-central Ohio
place with the magnitude of the value being the
strength of the membership. 1 means definitely a
central Ohio place and -1 means definitely not a
central Ohio place.
</bodyText>
<equation confidence="0.992148">
r = r (Cpos C ‚Äî Cneg)‚ÅÑCneu , if Cneu &gt; 0 Equation 1
1 , otherwise
</equation>
<bodyText confidence="0.999677875">
As Cneu is in the denominator, it must not be
zero. Given observations, entities with Cneu being
zero are primarily entities with less than 3 total
mentions. These entities take up 3.9% of all ex-
tracted entities. Therefore, we decide to exclude
them from analysis as they are of a small percent-
age and are not expected to affect the overall re-
sults.
</bodyText>
<sectionHeader confidence="0.999378" genericHeader="evaluation">
4 Results and discussions
</sectionHeader>
<bodyText confidence="0.9985326">
Geographic entities are extracted from all 3281
news articles and their membership values are
mapped using the geographic information system
(GIS) software ArcGIS which are popular in so-
cial science geographic research.
</bodyText>
<subsectionHeader confidence="0.981857">
4.1 Graduated symbol maps
</subsectionHeader>
<bodyText confidence="0.996252083333333">
Graduated symbol map is a type of map that uses
symbols of different sizes to represent geographic
entities (Thrall, 1999). The symbol we choose is
circle. The radius of the circle is decided by the
attribute value associated with each entity. The
map is configured as follows:
(1)The size of each point is proportioned to the
membership of the underlying named entity
with size 4 and 24 representing the minimum
and maximum membership respectively.
(2)Symbols are classified into 10 classes based on
equal interval classification method.
</bodyText>
<page confidence="0.997003">
10
</page>
<bodyText confidence="0.999468941176471">
There is one exception of using the member-
ship for making the graduated symbol map. On
the article level, all entity counts are added to
CPùëúS, and therefore there are no negative or neu-
tral counts. To make a map on the article level, we
only use the positive count as the surrogate to the
membership value.
Graduated symbol maps on three analytical
levels are shown in Fig. 2. Results on the sentence
level and paragraph levels conforms better to our
intuition and common sense knowledge than on
the article level. This is because results on the ar-
ticle level do not consider the contexts of c1 and c2
discussed in section 4.2. Results from the sentence
and paragraph levels are very similar with the
membership on the paragraph level being slightly
more visually significant.
</bodyText>
<figureCaption confidence="0.992277">
Figure 2. Graduated symbol map of central Ohio
</figureCaption>
<subsectionHeader confidence="0.931864">
4.2 Kernel density map
</subsectionHeader>
<bodyText confidence="0.999948555555555">
Results produced by graduated symbol maps are
not continuous. Kernel density mapping is a GIS
mapping technique that generates a continuous
surface based on the locations of the entities and
their attribute values (Elgammal, Duraiswami,
Harwood, &amp; Davis, 2002). To create kernel den-
sity maps, a search radius need be defined. All
data points within this radius will be used to inter-
polate a density area using a quadratic kernel
function described in Silverman (p. 76, equation
4.5) (Silverman, 1986).
The kernel density tool in ArcGIS is used to
create the density map. In ArcGIS, the search ra-
dius is defined as a percentage of the area‚Äôs mini-
mum extent width. We experiment on choosing
1/10, 1/5, 1/20 of the area‚Äôs minimum extent
width as the radius to generate the surface and find
1/10 of the width most appropriate to generate a
balanced looking map.
A kernel density map of central Ohio visual-
izes its estimated central location and extending
trend over the space of Ohio. Fig. 3 is a kernel
density result based on the paragraph level. It
shows that the concept of central Ohio generated
through automated approach conforms to our
common sense knowledge of the assumptive loca-
tion of the vague region.
</bodyText>
<figureCaption confidence="0.96247">
Figure 3. Kernel density map of central Ohio
</figureCaption>
<sectionHeader confidence="0.999408" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999951621621622">
Vague geographic regions are important part of
the entire geographic space; however they are dif-
ficult to be located and delineated on a map. Geo-
graphic questions like Where is central Ohio? re-
mains a challenge to computers because comput-
ers are not automatically given the knowledge of
either central or Ohio as humans do.
This paper introduced a context-based ap-
proach to extract geographic entities from news
articles. Propositional logic of context was
adapted to contextualize the reasoning process.
Three types of context have been defined: Ohio,
central Ohio, not-central Ohio, which corre-
sponded to Ohio places, central Ohio places and
not-central Ohio places, respectively.
Analysis was conducted on three contextual
levels: article, paragraph and sentence. Visuali-
zation results showed that context was of signifi-
cant importance to deciding the membership of a
place to central Ohio. Without defining the con-
text (e.g. results on the article level in Fig. 2), vis-
ualization results were largely incorrect compared
with common sense knowledge.
Natural language processing (NLP) techniques
such as part of speech tagging and parse tree gen-
eration were shown to be effective for extracting
geographic information. Noun phrases could
serve as good candidates to place names. For fu-
ture research, we suggest studies on experiment-
ing with different regional concepts using pro-
posed approach. It may also be useful to experi-
ment with methods that can quickly generate sam-
ples other than the tree parsing method used in this
paper. Despite the possibility of generating more
coarse results, noisier method may be more scala-
ble for building practical applications with scaled
live data.
</bodyText>
<page confidence="0.998946">
11
</page>
<sectionHeader confidence="0.996542" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999176875">
The author would like to thank Dr. Xiang Chen,
Dr. Zhe Xu, Dr. Lili Wang, Dr. Xueying Zhang,
Dr. Bo Zhao, Dr. Ningchuan Xiao and two other
anonymous reviewers for their valuable com-
ments and suggestions for improving the paper.
Presentation of the work was supported by the re-
search data and computing center of the research
institute at the Nationwide Children‚Äôs Hospital.
</bodyText>
<sectionHeader confidence="0.989769" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999575339285715">
BuvaE, Saga, &amp; Mason, Ian A. (1993). Propositional
logic of context. Paper presented at the Proceedings
of the eleventh national conference on artificial
intelligence.
Census. (2013). U.S. Gazetteer Files. from
http://www.census.gov/geo/www/gazetteer/files/Ga
z_places_national.txt
Chen, Wei, Fosler-Lussier, Eric, Xiao, Ningchuan,
Raje, Satyajeet, Ramnath, Rajiv, &amp; Sui, Daniel.
(2013). A Synergistic Framework for Geographic
Question Answering. Paper presented at the
Semantic Computing (ICSC), 2013 IEEE Seventh
International Conference on.
De Marneffe, Marie-Catherine, MacCartney, Bill, &amp;
Manning, Christopher D. (2006). Generating typed
dependency parses from phrase structure parses.
Paper presented at the Proceedings of LREC.
Elgammal, Ahmed, Duraiswami, Ramani, Harwood,
David, &amp; Davis, Larry S. (2002). Background and
foreground modeling using nonparametric kernel
density estimation for visual surveillance.
Proceedings of the IEEE, 90(7), 1151-1163.
Gimpel, Kevin, Schneider, Nathan, O&apos;Connor,
Brendan, Das, Dipanjan, Mills, Daniel, Eisenstein,
Jacob, . . . Smith, Noah A. (2010). Part-of-speech
tagging for twitter: Annotation, features, and
experiments: DTIC Document.
Jurafsky, Dan, Martin, James H, Kehler, Andrew,
Vander Linden, Keith, &amp; Ward, Nigel. (2000).
Speech and language processing: An introduction to
natural language processing, computational
linguistics, and speech recognition (Vol. 2): MIT
Press.
Manning, Christopher D. (2011). Part-of-speech
tagging from 97% to 100%: is it time for some
linguistics? Computational Linguistics and
Intelligent Text Processing (pp. 171-189): Springer.
Montello, Daniel R, Goodchild, Michael F, Gottsegen,
Jonathon, &amp; Fohl, Peter. (2003). Where&apos;s
downtown?: Behavioral methods for determining
referents of vague spatial queries. Spatial Cognition
&amp; Computation, 3(2-3), 185-204.
Silverman, Bernard W. (1986). Density estimation for
statistics and data analysis (Vol. 26): CRC press.
Smith, Michael J, Ellenberg, Susan S, Bell, Louis M,
&amp; Rubin, David M. (2008). Media coverage of the
measles-mumps-rubella vaccine and autism
controversy and its relationship to MMR
immunization rates in the United States. Pediatrics,
121(4), e836-e843.
Thrall, Susan Elshaw. (1999). Geographic information
system (GIS) hardware and software. Journal of
Public Health Management and Practice, 5(2),
82&amp;hyhen.
USGS. (2013). Geographic Names Information Server.
from http://geonames.usgs.gov/index.html
</reference>
<page confidence="0.998408">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.248077">
<title confidence="0.9364595">Context-based Natural Language Processing for GIS-based Vague Region Visualization</title>
<author confidence="0.307844">of Computer Science</author>
<author confidence="0.307844">of Engineering</author>
<affiliation confidence="0.444966">The Ohio State University, Columbus OH, USA</affiliation>
<email confidence="0.969224">chen.1381@osu.edu</email>
<abstract confidence="0.999318166666667">regions such as Ohio are popularly used in everyday language; but their vague and indeterministic boundaries affect the clarity of communicating them over the geographic space. This paper introduced a context-based natural language processing approach to retrieve geographic entities. Geographic entities extracted from news articles were used as location-based behavioral samples to map the vague region of Particularly, part of speech tagging and parse tree generation were employed to filter out candidate entities from English sentences. Propositional logic of context (PLC) was introduced and adapted to build the contextual model for deciding the membership of named entities. Results were automatically generated and visualized in GIS using both symbol and density mapping. Final maps were consistent with our intuition and common sense knowledge of the vague region.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Saga BuvaE</author>
<author>Ian A Mason</author>
</authors>
<title>Propositional logic of context.</title>
<date>1993</date>
<booktitle>Paper presented at the Proceedings of the eleventh national conference on artificial intelligence.</booktitle>
<contexts>
<context position="2956" citStr="BuvaE &amp; Mason, 1993" startWordPosition="453" endWordPosition="456">umber of corpus data (Jurafsky, Martin, Kehler, Vander Linden, &amp; Ward, 2000). However, these NLP techniques have yet been widely used to extract geographic entities for visualizing vague regions like central Ohio. On the other hand, linguistic contexts of named entities are important for deciding its relevancy to the underlying vague regions. For instance, for a place to be part of central Ohio, it must be in the context of Ohio as a precondition. Propositional logic of context (PLC) is a logic model in the field of artificial intelligence for formalizing contexts into propositional calculus (BuvaE &amp; Mason, 1993). Based on PLC, an arbitrary predicate calculus can be evaluated according to selected contexts. In this paper, central Ohio is chosen as the experimental area to experiment the context-based natural language approach for visualizing vague regions. News articles are used and analyzed on three contextual levels: document, paragraph and sentence. Results are visualized in GIS. 1.1 News data News articles are extracted from LexisNexis, a comprehensive database of both national and local news (Smith, Ellenberg, Bell, &amp; Rubin, 2008). All articles are retrieved based on caseless keyword match for re</context>
<context position="8157" citStr="BuvaE &amp; Mason, 1993" startWordPosition="1289" endWordPosition="1292">noun phrases extracted at the root level of a parse tree. However, not all such entities should be considered as part of central Ohio. To determine the membership, we may define following logic heuristics: if (1) the name of an entity is in the same text segment as the phrase central Ohio and (2) the entity is an Ohio place, then the entity is of greater likelihood of being a central Ohio place than otherwise. Here, Ohio and central 9 Ohio are linguistic contexts for discriminating central Ohio entities. To formalize the contexts of analysis, we introduce propositional logic of context (PLC) (BuvaE &amp; Mason, 1993). Here, we only adapt its basic form as it already suffice the needs of our analysis. For detailed information of PLC, one may read the original paper from BuvaE (BuvaE &amp; Mason, 1993). The minimum PLC definition is below: x: subject p: preposition about the subject c: context c1c2: logic AND, intersection of two contexts c1c2: logic OR, union of two contexts ist(c, p): the proposition p is true in context c. 3.2 PLC-based matching and counting Based on the PLC definition, we count the mentions of named entities in all news articles. Here, we define the following PLC notations for our analysi</context>
</contexts>
<marker>BuvaE, Mason, 1993</marker>
<rawString>BuvaE, Saga, &amp; Mason, Ian A. (1993). Propositional logic of context. Paper presented at the Proceedings of the eleventh national conference on artificial intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Census</author>
</authors>
<title>U.S. Gazetteer Files.</title>
<date>2013</date>
<note>from http://www.census.gov/geo/www/gazetteer/files/Ga z_places_national.txt</note>
<contexts>
<context position="4251" citStr="Census, 2013" startWordPosition="652" endWordPosition="653"> this exact phrase are retrieved. As a result, 3281 different articles are collected which cover central Ohio news from the year 1990 to the year 2013. 8 Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 8‚Äì12, Baltimore, Maryland, USA, June 26, 2014. cÔøΩ2014 Association for Computational Linguistics 1.2 Geonames database Geonames database contains names and locations of geographic entities. We create our geonames database two sources: the United States Geological Survey&apos;s Geographic Names Information Server (USGS, 2013) and Census gazetteers (Census, 2013). Only place and feature names in Ohio used for analysis. Table 1 summarizes compositions of entities in our Ohio geonames database. Category Percentages Administrative places 23.0% cities (1054 records) 66.3% villages 10.6% CDPs (census designated place) Geographic features 14.9% church (67804 records) 13.7% school 12.6% populated place among 53 categories Table 1. Geographic named entities in Ohio 2 Natural Language Processing Part of speech tagging and parse tree generation are used to automatically extract geographic named entities from news articles in this paper. Part of speech (POS) tag</context>
</contexts>
<marker>Census, 2013</marker>
<rawString>Census. (2013). U.S. Gazetteer Files. from http://www.census.gov/geo/www/gazetteer/files/Ga z_places_national.txt</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Chen</author>
<author>Eric Fosler-Lussier</author>
<author>Ningchuan Xiao</author>
<author>Satyajeet Raje</author>
<author>Rajiv Ramnath</author>
<author>Daniel Sui</author>
</authors>
<title>A Synergistic Framework for Geographic Question Answering. Paper presented at the Semantic Computing (ICSC),</title>
<date>2013</date>
<booktitle>IEEE Seventh International Conference on.</booktitle>
<contexts>
<context position="5221" citStr="Chen et al., 2013" startWordPosition="803" endWordPosition="806">egories Table 1. Geographic named entities in Ohio 2 Natural Language Processing Part of speech tagging and parse tree generation are used to automatically extract geographic named entities from news articles in this paper. Part of speech (POS) tagging is the process of deciding the functions of words such as nouns or verbs. Parse tree generation is based on POS tagging results. It aims to generate hierarchical representations of sentences for semantic understanding (Jurafsky et al., 2000). Noun phrases in the parse tree are often useful indicators to named entities in geolinguistic analysis (Chen et al., 2013). 2.1 Part of speech tagging Part-of-speech (POS) tagging assigns a POS tag to each token in a sentence. A token can be either a word or a punctuation. The single best POS tag assigned to a token depends on the function of the word, the tag set, and POS tagging algorithm (Jurafsky et al., 2000). Contemporary POS taggers can reach an average accuracy of above 97% on tokens (Manning, 2011). The part of speech tagger we use is Stanford NLP tagger with english-caseless-left3wordsdistsim tagger model. This tagger model is trained with WSJ sections 0-18 and extra parser training data using the left3</context>
</contexts>
<marker>Chen, Fosler-Lussier, Xiao, Raje, Ramnath, Sui, 2013</marker>
<rawString>Chen, Wei, Fosler-Lussier, Eric, Xiao, Ningchuan, Raje, Satyajeet, Ramnath, Rajiv, &amp; Sui, Daniel. (2013). A Synergistic Framework for Geographic Question Answering. Paper presented at the Semantic Computing (ICSC), 2013 IEEE Seventh International Conference on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses. Paper presented at the</title>
<date>2006</date>
<booktitle>Proceedings of LREC.</booktitle>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>De Marneffe, Marie-Catherine, MacCartney, Bill, &amp; Manning, Christopher D. (2006). Generating typed dependency parses from phrase structure parses. Paper presented at the Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Elgammal</author>
<author>Ramani Duraiswami</author>
<author>David Harwood</author>
<author>Larry S Davis</author>
</authors>
<title>Background and foreground modeling using nonparametric kernel density estimation for visual surveillance.</title>
<date>2002</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>90</volume>
<issue>7</issue>
<pages>1151--1163</pages>
<contexts>
<context position="13343" citStr="Elgammal, Duraiswami, Harwood, &amp; Davis, 2002" startWordPosition="2174" endWordPosition="2179">nd common sense knowledge than on the article level. This is because results on the article level do not consider the contexts of c1 and c2 discussed in section 4.2. Results from the sentence and paragraph levels are very similar with the membership on the paragraph level being slightly more visually significant. Figure 2. Graduated symbol map of central Ohio 4.2 Kernel density map Results produced by graduated symbol maps are not continuous. Kernel density mapping is a GIS mapping technique that generates a continuous surface based on the locations of the entities and their attribute values (Elgammal, Duraiswami, Harwood, &amp; Davis, 2002). To create kernel density maps, a search radius need be defined. All data points within this radius will be used to interpolate a density area using a quadratic kernel function described in Silverman (p. 76, equation 4.5) (Silverman, 1986). The kernel density tool in ArcGIS is used to create the density map. In ArcGIS, the search radius is defined as a percentage of the area‚Äôs minimum extent width. We experiment on choosing 1/10, 1/5, 1/20 of the area‚Äôs minimum extent width as the radius to generate the surface and find 1/10 of the width most appropriate to generate a balanced looking map. A</context>
</contexts>
<marker>Elgammal, Duraiswami, Harwood, Davis, 2002</marker>
<rawString>Elgammal, Ahmed, Duraiswami, Ramani, Harwood, David, &amp; Davis, Larry S. (2002). Background and foreground modeling using nonparametric kernel density estimation for visual surveillance. Proceedings of the IEEE, 90(7), 1151-1163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O&apos;Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments:</title>
<date>2010</date>
<journal>DTIC Document.</journal>
<contexts>
<context position="5948" citStr="Gimpel et al., 2010" startWordPosition="924" endWordPosition="927">token can be either a word or a punctuation. The single best POS tag assigned to a token depends on the function of the word, the tag set, and POS tagging algorithm (Jurafsky et al., 2000). Contemporary POS taggers can reach an average accuracy of above 97% on tokens (Manning, 2011). The part of speech tagger we use is Stanford NLP tagger with english-caseless-left3wordsdistsim tagger model. This tagger model is trained with WSJ sections 0-18 and extra parser training data using the left3words architecture. It includes word shape and distributional similarity features for training the tagger (Gimpel et al., 2010). The results are represented using Penn Treebank tags and the average parsing accuracy is above 97% on sentences in news. Box 1 is the tagged sentence from one article with POS tags appended after the slash in uppercase letters. For a complete list, one may refer to Penn Treebank tag sets. Her/PRP$ friends/NNS at/IN the/DT Central/NNP Ohio/NNP Nazarene/NNP Church/NNP Camp/NNP she/PRP attended/VBD every/DT summer/NN in/IN Columbus/NNP convinced/VBD her/PRP to/TO attend/VB Mount/NNP Vernon/NNP Nazarene/NNP College/NNP in/IN Knox/JJ county/NN ,/, OH/NNP ./. Box 1. Tagged sentence 2.2 Parsing Sta</context>
</contexts>
<marker>Gimpel, Schneider, O&apos;Connor, Das, Mills, Eisenstein, 2010</marker>
<rawString>Gimpel, Kevin, Schneider, Nathan, O&apos;Connor, Brendan, Das, Dipanjan, Mills, Daniel, Eisenstein, Jacob, . . . Smith, Noah A. (2010). Part-of-speech tagging for twitter: Annotation, features, and experiments: DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Jurafsky</author>
<author>James H Martin</author>
<author>Andrew Kehler</author>
<author>Vander Linden</author>
<author>Keith</author>
<author>Nigel Ward</author>
</authors>
<title>Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition</title>
<date>2000</date>
<volume>2</volume>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5097" citStr="Jurafsky et al., 2000" startWordPosition="782" endWordPosition="785"> CDPs (census designated place) Geographic features 14.9% church (67804 records) 13.7% school 12.6% populated place among 53 categories Table 1. Geographic named entities in Ohio 2 Natural Language Processing Part of speech tagging and parse tree generation are used to automatically extract geographic named entities from news articles in this paper. Part of speech (POS) tagging is the process of deciding the functions of words such as nouns or verbs. Parse tree generation is based on POS tagging results. It aims to generate hierarchical representations of sentences for semantic understanding (Jurafsky et al., 2000). Noun phrases in the parse tree are often useful indicators to named entities in geolinguistic analysis (Chen et al., 2013). 2.1 Part of speech tagging Part-of-speech (POS) tagging assigns a POS tag to each token in a sentence. A token can be either a word or a punctuation. The single best POS tag assigned to a token depends on the function of the word, the tag set, and POS tagging algorithm (Jurafsky et al., 2000). Contemporary POS taggers can reach an average accuracy of above 97% on tokens (Manning, 2011). The part of speech tagger we use is Stanford NLP tagger with english-caseless-left3w</context>
</contexts>
<marker>Jurafsky, Martin, Kehler, Linden, Keith, Ward, 2000</marker>
<rawString>Jurafsky, Dan, Martin, James H, Kehler, Andrew, Vander Linden, Keith, &amp; Ward, Nigel. (2000). Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition (Vol. 2): MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
</authors>
<title>Part-of-speech tagging from 97% to 100%: is it time for some linguistics?</title>
<date>2011</date>
<booktitle>Computational Linguistics and Intelligent Text Processing</booktitle>
<pages>171--189</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5611" citStr="Manning, 2011" startWordPosition="876" endWordPosition="877">enerate hierarchical representations of sentences for semantic understanding (Jurafsky et al., 2000). Noun phrases in the parse tree are often useful indicators to named entities in geolinguistic analysis (Chen et al., 2013). 2.1 Part of speech tagging Part-of-speech (POS) tagging assigns a POS tag to each token in a sentence. A token can be either a word or a punctuation. The single best POS tag assigned to a token depends on the function of the word, the tag set, and POS tagging algorithm (Jurafsky et al., 2000). Contemporary POS taggers can reach an average accuracy of above 97% on tokens (Manning, 2011). The part of speech tagger we use is Stanford NLP tagger with english-caseless-left3wordsdistsim tagger model. This tagger model is trained with WSJ sections 0-18 and extra parser training data using the left3words architecture. It includes word shape and distributional similarity features for training the tagger (Gimpel et al., 2010). The results are represented using Penn Treebank tags and the average parsing accuracy is above 97% on sentences in news. Box 1 is the tagged sentence from one article with POS tags appended after the slash in uppercase letters. For a complete list, one may refe</context>
</contexts>
<marker>Manning, 2011</marker>
<rawString>Manning, Christopher D. (2011). Part-of-speech tagging from 97% to 100%: is it time for some linguistics? Computational Linguistics and Intelligent Text Processing (pp. 171-189): Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel R Montello</author>
<author>Michael F Goodchild</author>
<author>Jonathon Gottsegen</author>
<author>Peter Fohl</author>
</authors>
<title>Where&apos;s downtown?: Behavioral methods for determining referents of vague spatial queries.</title>
<date>2003</date>
<journal>Spatial Cognition &amp; Computation,</journal>
<volume>3</volume>
<issue>2</issue>
<pages>185--204</pages>
<contexts>
<context position="1929" citStr="Montello, Goodchild, Gottsegen, &amp; Fohl, 2003" startWordPosition="290" endWordPosition="295">o. Although it may be effortless for humans to tell the relative location of this region, it remains challenging for computers to automatically locate this region by harvesting and analyzing online data such as news articles. Computers that are capable of automatically delineating such vague regions may be of potential use to social science researchers for understanding other concepts that may not be as obvious such as cultural regions, the Muslim world. In the study of vague regions, previous studies introduced a behavioral method to map out downtown Santa Barbara based on human survey data (Montello, Goodchild, Gottsegen, &amp; Fohl, 2003). Their approach collected hand-drawn point-based locations and plotted them on the map of the city. Such data collection process may be very costly compared to computer-based automated approach. By comparison, natural language processing (NLP) techniques such as part of speech tagging and parse tree generation provide powerful linguistic analysis tools that can help quickly retrieve data from a large number of corpus data (Jurafsky, Martin, Kehler, Vander Linden, &amp; Ward, 2000). However, these NLP techniques have yet been widely used to extract geographic entities for visualizing vague region</context>
</contexts>
<marker>Montello, Goodchild, Gottsegen, Fohl, 2003</marker>
<rawString>Montello, Daniel R, Goodchild, Michael F, Gottsegen, Jonathon, &amp; Fohl, Peter. (2003). Where&apos;s downtown?: Behavioral methods for determining referents of vague spatial queries. Spatial Cognition &amp; Computation, 3(2-3), 185-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard W Silverman</author>
</authors>
<title>Density estimation for statistics and data analysis</title>
<date>1986</date>
<journal>Vol.</journal>
<volume>26</volume>
<publisher>CRC press.</publisher>
<contexts>
<context position="13584" citStr="Silverman, 1986" startWordPosition="2219" endWordPosition="2220">vel being slightly more visually significant. Figure 2. Graduated symbol map of central Ohio 4.2 Kernel density map Results produced by graduated symbol maps are not continuous. Kernel density mapping is a GIS mapping technique that generates a continuous surface based on the locations of the entities and their attribute values (Elgammal, Duraiswami, Harwood, &amp; Davis, 2002). To create kernel density maps, a search radius need be defined. All data points within this radius will be used to interpolate a density area using a quadratic kernel function described in Silverman (p. 76, equation 4.5) (Silverman, 1986). The kernel density tool in ArcGIS is used to create the density map. In ArcGIS, the search radius is defined as a percentage of the area‚Äôs minimum extent width. We experiment on choosing 1/10, 1/5, 1/20 of the area‚Äôs minimum extent width as the radius to generate the surface and find 1/10 of the width most appropriate to generate a balanced looking map. A kernel density map of central Ohio visualizes its estimated central location and extending trend over the space of Ohio. Fig. 3 is a kernel density result based on the paragraph level. It shows that the concept of central Ohio generated thr</context>
</contexts>
<marker>Silverman, 1986</marker>
<rawString>Silverman, Bernard W. (1986). Density estimation for statistics and data analysis (Vol. 26): CRC press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Smith</author>
<author>Susan S Ellenberg</author>
<author>Louis M Bell</author>
<author>David M Rubin</author>
</authors>
<title>Media coverage of the measles-mumps-rubella vaccine and autism controversy and its relationship to MMR immunization rates in the United States.</title>
<date>2008</date>
<journal>Pediatrics,</journal>
<volume>121</volume>
<issue>4</issue>
<pages>836--843</pages>
<contexts>
<context position="3488" citStr="Smith, Ellenberg, Bell, &amp; Rubin, 2008" startWordPosition="534" endWordPosition="539">eld of artificial intelligence for formalizing contexts into propositional calculus (BuvaE &amp; Mason, 1993). Based on PLC, an arbitrary predicate calculus can be evaluated according to selected contexts. In this paper, central Ohio is chosen as the experimental area to experiment the context-based natural language approach for visualizing vague regions. News articles are used and analyzed on three contextual levels: document, paragraph and sentence. Results are visualized in GIS. 1.1 News data News articles are extracted from LexisNexis, a comprehensive database of both national and local news (Smith, Ellenberg, Bell, &amp; Rubin, 2008). All articles are retrieved based on caseless keyword match for relevancy. The only keyword used is central Ohio and only news articles that contain this exact phrase are retrieved. As a result, 3281 different articles are collected which cover central Ohio news from the year 1990 to the year 2013. 8 Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 8‚Äì12, Baltimore, Maryland, USA, June 26, 2014. cÔøΩ2014 Association for Computational Linguistics 1.2 Geonames database Geonames database contains names and locations of geographic entities. We cr</context>
</contexts>
<marker>Smith, Ellenberg, Bell, Rubin, 2008</marker>
<rawString>Smith, Michael J, Ellenberg, Susan S, Bell, Louis M, &amp; Rubin, David M. (2008). Media coverage of the measles-mumps-rubella vaccine and autism controversy and its relationship to MMR immunization rates in the United States. Pediatrics, 121(4), e836-e843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Elshaw Thrall</author>
</authors>
<title>Geographic information system (GIS) hardware and software.</title>
<date>1999</date>
<journal>Journal of Public Health Management and Practice,</journal>
<volume>5</volume>
<issue>2</issue>
<pages>82</pages>
<contexts>
<context position="11817" citStr="Thrall, 1999" startWordPosition="1925" endWordPosition="1926">ess than 3 total mentions. These entities take up 3.9% of all extracted entities. Therefore, we decide to exclude them from analysis as they are of a small percentage and are not expected to affect the overall results. 4 Results and discussions Geographic entities are extracted from all 3281 news articles and their membership values are mapped using the geographic information system (GIS) software ArcGIS which are popular in social science geographic research. 4.1 Graduated symbol maps Graduated symbol map is a type of map that uses symbols of different sizes to represent geographic entities (Thrall, 1999). The symbol we choose is circle. The radius of the circle is decided by the attribute value associated with each entity. The map is configured as follows: (1)The size of each point is proportioned to the membership of the underlying named entity with size 4 and 24 representing the minimum and maximum membership respectively. (2)Symbols are classified into 10 classes based on equal interval classification method. 10 There is one exception of using the membership for making the graduated symbol map. On the article level, all entity counts are added to CPùëúS, and therefore there are no negative o</context>
</contexts>
<marker>Thrall, 1999</marker>
<rawString>Thrall, Susan Elshaw. (1999). Geographic information system (GIS) hardware and software. Journal of Public Health Management and Practice, 5(2), 82&amp;hyhen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>USGS</author>
</authors>
<title>Geographic Names Information Server.</title>
<date>2013</date>
<note>from http://geonames.usgs.gov/index.html</note>
<contexts>
<context position="4214" citStr="USGS, 2013" startWordPosition="647" endWordPosition="648">and only news articles that contain this exact phrase are retrieved. As a result, 3281 different articles are collected which cover central Ohio news from the year 1990 to the year 2013. 8 Proceedings of the ACL 2014 Workshop on Language Technologies and Computational Social Science, pages 8‚Äì12, Baltimore, Maryland, USA, June 26, 2014. cÔøΩ2014 Association for Computational Linguistics 1.2 Geonames database Geonames database contains names and locations of geographic entities. We create our geonames database two sources: the United States Geological Survey&apos;s Geographic Names Information Server (USGS, 2013) and Census gazetteers (Census, 2013). Only place and feature names in Ohio used for analysis. Table 1 summarizes compositions of entities in our Ohio geonames database. Category Percentages Administrative places 23.0% cities (1054 records) 66.3% villages 10.6% CDPs (census designated place) Geographic features 14.9% church (67804 records) 13.7% school 12.6% populated place among 53 categories Table 1. Geographic named entities in Ohio 2 Natural Language Processing Part of speech tagging and parse tree generation are used to automatically extract geographic named entities from news articles in</context>
</contexts>
<marker>USGS, 2013</marker>
<rawString>USGS. (2013). Geographic Names Information Server. from http://geonames.usgs.gov/index.html</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>