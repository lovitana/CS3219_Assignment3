<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.9981805">
Cross-lingual Dependency Parsing of Related Languages with Rich
Morphosyntactic Tagsets
</title>
<author confidence="0.550075">
ˇZeljko Agi´c J¨org Tiedemann Kaja Dobrovoljc
</author>
<email confidence="0.629528">
zagic@uni-potsdam.de jorg.tiedemann@lingfil.uu.se kaja.dobrovoljc@trojina.si
</email>
<author confidence="0.712047">
Simon Krek Danijela Merkler Sara Moˇze
</author>
<email confidence="0.892239">
simon.krek@ijs.si dmerkler@ffzg.hr s.moze@wlv.ac.uk
</email>
<sectionHeader confidence="0.978315" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99994265">
This paper addresses cross-lingual depen-
dency parsing using rich morphosyntac-
tic tagsets. In our case study, we experi-
ment with three related Slavic languages:
Croatian, Serbian and Slovene. Four dif-
ferent dependency treebanks are used for
monolingual parsing, direct cross-lingual
parsing, and a recently introduced cross-
lingual parsing approach that utilizes sta-
tistical machine translation and annota-
tion projection. We argue for the benefits
of using rich morphosyntactic tagsets in
cross-lingual parsing and empirically sup-
port the claim by showing large improve-
ments over an impoverished common fea-
ture representation in form of a reduced
part-of-speech tagset. In the process, we
improve over the previous state-of-the-art
scores in dependency parsing for all three
languages.
</bodyText>
<sectionHeader confidence="0.995164" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999990166666667">
A large majority of human languages are under-
resourced in terms of text corpora and tools avail-
able for applications in natural language process-
ing (NLP). According to recent surveys (Bender,
2011; Uszkoreit and Rehm, 2012; Bender, 2013),
this is especially apparent with syntactically anno-
tated corpora, i.e., treebanks – both dependency-
based ones and others. In this paper, we fo-
cus on dependency parsing (K¨ubler et al., 2009),
but the claims should hold in general. The lack
of dependency treebanks is due to the fact that
they are expensive and time-consuming to con-
struct (Abeill´e, 2003). Since dependency parsing
of under-resourced languages nonetheless draws
substantial interest in the NLP research commu-
nity, over time, we have seen a number of research
efforts directed towards their processing despite
the absence of training data for supervised learn-
ing of parsing models. We give a brief overview of
the major research directions in the following sub-
section. Here, we focus on supervised learning of
dependency parsers, as the performance of unsu-
pervised approaches still falls far behind the state
of the art in supervised parser induction.
</bodyText>
<sectionHeader confidence="0.667717" genericHeader="related work">
1.1 Related Work
</sectionHeader>
<bodyText confidence="0.9998030625">
There are two basic strategies for data-driven pars-
ing of languages with no dependency treebanks:
annotation projection and model transfer. Both
fall into the general category of cross-lingual de-
pendency parsing as they attempt to utilize ex-
isting dependency treebanks or parsers from a
resource-rich language (source) for parsing the
under-resourced (target) language.
Annotation projection: In this approach, de-
pendency trees are projected from a source lan-
guage to a target language using word alignments
in parallel corpora. It is based on a presumption
that source-target parallel corpora are more read-
ily available than dependency treebanks. The ap-
proach comes in two varieties. In the first one, par-
allel corpora are exploited by applying the avail-
able state-of-the-art parsers on the source side
and subsequent projection to the target side us-
ing word alignments and heuristics for resolving
possible link ambiguities (Yarowsky et al., 2001;
Hwa et al., 2005). Since dependency parsers typ-
ically make heavy use of various morphological
and other features, the apparent benefit of this ap-
proach is the possibility of straightforward pro-
jection of these features, resulting in a feature-
rich representation for the target language. On the
downside, the annotation projection noise adds up
to dependency parsing noise and errors in word
alignment, influencing the quality of the resulting
target language parser.
The other variety is rare, since it relies on paral-
lel corpora in which the source side is a depen-
</bodyText>
<page confidence="0.640229">
13
</page>
<note confidence="0.952523">
Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 13–24,
October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999887818181818">
dency treebank, i.e., it is already manually an-
notated for syntactic dependencies (Agi´c et al.,
2012). This removes the automatic parsing noise,
while the issues with word alignment and annota-
tion heuristics still remain.
Model transfer: In its simplest form, transfer-
ring a model amounts to training a source lan-
guage parser and running it directly on the target
language. It is usually coupled with delexicaliza-
tion, i.e., removing all lexical features from the
source treebank for training the parser (Zeman and
Resnik, 2008; McDonald et al., 2013). This in turn
relies on the same underlying feature model, typi-
cally drawing from a shared part-of-speech (POS)
representation such as the Universal POS Tagset of
Petrov et al. (2012). Negative effects of using such
an impoverished shared representation are typi-
cally addressed by adapting the model to better fit
the target language. This includes selecting source
language data points appropriate for the target lan-
guage (Søgaard, 2011; T¨ackstr¨om et al., 2013),
transferring from multiple sources (McDonald et
al., 2011) and using cross-lingual word clusters
(T¨ackstr¨om et al., 2012). These approaches need
no projection and enable the usage of source-side
gold standard annotations, but they all rely on
a shared feature representation across languages,
which can be seen as a strong bottleneck. Also,
while most of the earlier research made use of
heterogenous treebanks and thus yielded linguisti-
cally implausible observations, research stemming
from an uniform dependency scheme across lan-
guages (De Marneffe and Manning, 2008; Mc-
Donald et al., 2013) made it possible to perform
more consistent experiments and to assess the ac-
curacy of dependency labels.
Other approaches: More recently, Durrett et
al. (2012) suggested a hybrid approach that in-
volves bilingual lexica in cross-lingual phrase-
based parsing. In their approach, a source-side
treebank is adapted to a target language by ”trans-
lating” the source words to target words through
a bilingual lexicon. This approach is advanced
by Tiedemann et al. (2014), who utilize full-
scale statistical machine translation (SMT) sys-
tems for generating synthetic target language tree-
banks. This approach relates to annotation pro-
jection, while bypassing the issue of dependency
parsing noise as gold standard annotations are pro-
jected. The SMT noise is in turn mitigated by
better word alignment quality for synthetic data.
The influence of various projection algorithms in
this approach is further investigated by Tiedemann
(2014). This line of cross-lingual parsing research
substantially improves over previous work.
</bodyText>
<subsectionHeader confidence="0.991497">
1.2 Paper Overview
</subsectionHeader>
<bodyText confidence="0.989326604651163">
All lines of previous cross-lingual parsing research
left the topics of related languages and shared rich
feature representations largely unaddressed, with
the exception of Zeman and Resnik (2008), who
deal with phrase-based parsing test-cased on Dan-
ish and Swedish treebanks, utilizing a mapping
over relatively small POS tagsets.
In our contribution, the goal is to observe the
properties of cross-lingual parsing in an envi-
ronment of relatively free-word-order languages,
which are related and characterized by rich mor-
phology and very large morphosyntactic tagsets.
We experiment with four different small- and
medium-size dependency treebanks of Croatian
and Slovene, and cross-lingually parse into Croa-
tian, Serbian and Slovene. Along with monolin-
gual and direct transfer parsing, we make use of
the SMT framework of Tiedemann et al. (2014).
We are motivated by:
■ observing the performance of various ap-
proaches to cross-lingual dependency parsing
for closely related languages, including the very
recent treebank translation approach by Tiede-
mann et al. (2014);
■ doing so by using rich morphosyntactic tagsets,
in contrast to virtually all other recent cross-
lingual dependency parsing experiments, which
mainly utilize the Universal POS tagset of
Petrov et al. (2012);
■ reliably testing for labeled parsing accuracy in
an environment with heterogenous dependency
annotation schemes; and
■ improving the state of the art for Croatian,
Slovene and Serbian dependency parsing across
these heterogenous schemes.
In Section 2, we describe the language resources
used: treebanks, tagsets and test sets. Section 3
describes the experimental setup, which includes
a description of parsing, machine translation and
annotation projection. In Section 4, we discuss the
results of the experiments, and we conclude the
discussion by sketching the possible directions for
future research in Section 5.
</bodyText>
<page confidence="0.888898">
14
</page>
<table confidence="0.994463">
Feature hr PDT hr SET sl PDT sl SSJ
Sentences 4,626 8,655 1,534 11,217
Tokens 117,369 192,924 28,750 232,241
Types 25,038 37,749 7,128 48,234
Parts of speech 13 13 12 13
MSDs 821 685 725 1,142
Syntactic tags 26 15 26 10
</table>
<tableCaption confidence="0.993867">
Table 1: Basic treebank statistics.
</tableCaption>
<figureCaption confidence="0.9891606">
Figure 1: Histogram of edge distances in the tree-
banks. Edge distance is measured in tokens be-
tween heads and dependents. Distance of 1 de-
notes adjacent tokens.
Figure 2: Histogram of average tree depths.
</figureCaption>
<sectionHeader confidence="0.993379" genericHeader="method">
2 Resources
</sectionHeader>
<bodyText confidence="0.999978727272727">
We make use of the publicly available language re-
sources for Croatian, Serbian and Slovene. These
include dependency treebanks, test sets annotated
for morphology and dependency syntax, and a
morphosyntactic feature representation drawing
from the Multext East project (Erjavec, 2012).
A detailed assessment of the current state of de-
velopment for morphosyntactic and syntactic pro-
cessing of these languages is given by Agi´c et al.
(2013) and Uszkoreit and Rehm (2012). Here, we
provide only a short description.
</bodyText>
<subsectionHeader confidence="0.977332">
2.1 Treebanks
</subsectionHeader>
<bodyText confidence="0.974975581395349">
We use two Croatian and two Slovene dependency
treebanks.1 One for each language is based on the
Prague Dependency Treebank (PDT) (B¨ohmov´a
et al., 2003) annotation scheme, while the other
two introduced novel and more simplified syntac-
tic tagsets. All four treebanks use adaptations of
1No treebanks of Serbian were publicly available at the
time of conducting this experiment.
the Multext East version 4 tagset (Erjavec, 2012)
for the underlying morphological annotation layer,
which we shortly describe further down. Basic
statistics for the treebanks are given in Table 1.
hr PDT: This treebank is natively referred to
as the Croatian Dependency Treebank (HOBS)
(Tadi´c, 2007; Berovi´c et al., 2012). Its most recent
instance, HOBS 2.0 (Agi´c et al., 2014) slightly de-
parts from the PDT scheme. Thus, in this exper-
iment, we use the older version, HOBS 1.0, and
henceforth refer to it as hr PDT for consistency and
more clear reference to its annotation.2
hr SET: The SETIMES.HR dependency treebank
of Croatian has a 15-tag scheme. It is targeted
towards high parsing accuracy, while maintaining
a clear distinction between all basic grammatical
categories of Croatian. Its publicly available 1.0
release consists of approximately 2,500 sentences
(Agi´c and Merkler, 2013), while release 2.0 has
just under 4,000 sentences (Agi´c and Ljubeˇsi´c,
2014) of newspaper text. Here, we use an even
newer, recently developed version with more than
8,500 sentences from multiple domains.3
sl PDT: The PDT-based Slovene Dependency
Treebank (Dˇzeroski et al., 2006) is built on top of
a rather small portion of Orwell’s novel 1984 from
the Multext East project (Erjavec, 2012). Even if
the project was discontinued, it is still heavily used
as part of the venerable CoNLL 2006 and 2007
shared task datasets (Buchholz and Marsi, 2006;
Nivre et al., 2007).4
sl SSJ: The Slovene take on simplifying syntac-
tic annotations resulted in the 10-tag strong JOS
Corpus of Slovene (Erjavec et al., 2010). Similar
to hr SET, this new annotation scheme is loosely
</bodyText>
<equation confidence="0.8462745">
2HOBS is available through META-SHARE (Tadi´c and
V´aradi, 2012).
3http://nlp.ffzg.hr/resources/corpora/
setimes-hr/
4http://nl.ijs.si/sdt/
15
</equation>
<bodyText confidence="0.99996117948718">
PDT-based, but considerably reduced to facilitate
manual annotation. The initial 100,000 token cor-
pus has recently doubled in size, as described by
Dobrovoljc et al. (2012). We use the latter version
in our experiment.5
The statistics in Table 1 show a variety of tree-
bank sizes and annotations. Figure 1 illustrates the
structural complexity of the treebanks by provid-
ing a histogram of egdes by token distance. While
adjacent edges expectedly dominate the distribu-
tions, it is interesting to see that almost 30% of
all edges in sl SSJ attach to root, resulting in an
easily parsable flattened tree structure. Knowing
that relations denoting attributes account for more
than one third of all non-root dependents in the re-
mainder, one can expect dependency parsing per-
formance comparable to CoNLL-style chunking
(Tjong Kim Sang and Buchholz, 2000). This is
further supported by the distributions of sentences
in the four treebanks by average tree depth in Fig-
ure 2. We can see that virtually all sl SSJ trees have
average depths of 1 to 3, while the other treebanks
exhibit the more common structural properties of
dependency trees.
In these terms of complexity, the Croatian tree-
banks are richer than their Slovene counterparts.
In sl SSJ, attributes and edges to root account for
more than 60% of all dependencies. Even in the
other three treebanks, 20-30% of the edges are la-
beled as attributes, while the rest is spread more
evenly between the basic syntactic categories such
as predicates, subject and objects. More detailed
and more linguistically motivated comparisons of
the three annotation guidelines fall outside the
scope of our paper. Instead, we refer to the pre-
viously noted publications on the respective tree-
banks, and to (Agi´c and Merkler, 2013; Agi´c et
al., 2013) for comparisons between PDT and SET
in parsing Croatian and Serbian.
</bodyText>
<subsectionHeader confidence="0.999512">
2.2 Morphosyntactic Tagset
</subsectionHeader>
<bodyText confidence="0.999971125">
All four treebanks were manually created: they
are sentence- and token-split, lemmatized, mor-
phosyntactically tagged and syntactically anno-
tated. In morphosyntactic annotation, they all
make use of the Multext East version 4 (MTE
4) guidelines (Erjavec, 2012).6 MTE 4 is a po-
sitional tagset in which morphosyntactic descrip-
tors of word forms are captured by a morphosyn-
</bodyText>
<footnote confidence="0.831754333333333">
5http://eng.slovenscina.eu/
tehnologije/ucni-korpus
6http://nl.ijs.si/ME/V4/
</footnote>
<bodyText confidence="0.999981055555556">
tactic tag (MSD) created by merging atomic at-
tributes in the predefined positions. This is illus-
trated in Table 2 through an example verb tag. The
first character of the tag denotes the part of speech
(POS), while each of the following characters en-
codes a specific attribute in a specific position.
Both the positions and the attributes are language-
dependent in MTE 4, but the attributes are still
largely shared between these three languages due
to their relatedness.
The Slovene treebanks closely adhere to the
specification, while each of the Croatian treebanks
implements slight adaptations of the tagset to-
wards Croatian specifics. In hr PDT, the adaptation
is governed by and documented in the Croatian
Morphological Lexicon (Tadi´c and Fulgosi, 2003),
and the modifications in hr SET were targeted to
more closely match the ones for Slovene.7
</bodyText>
<subsectionHeader confidence="0.999952">
2.3 Test Sets
</subsectionHeader>
<bodyText confidence="0.999991758620689">
Recent research by McDonald et al. (2013) has
uncovered the downsides of experimenting with
parsing using heterogenous dependency annota-
tions, while at the same time providing possi-
bly the first reliable results in cross-lingual pars-
ing. They did so by creating the uniformly anno-
tated Universal Dependency Treebanks collection
based on Stanford Typed Dependencies (De Marn-
effe and Manning, 2008), which in turn also en-
abled measuring both labeled (LAS) and unla-
beled (UAS) parsing accuracy.
Having four treebanks with three different an-
notation schemes, we seek to enable reliable ex-
perimentation through our test sets. Along with
Croatian and Slovene, which are represented in the
training sets, we introduce Serbian as a target-only
language in the test data. Following the CoNLL
shared tasks setup (Buchholz and Marsi, 2006;
Nivre et al., 2007), our test sets have 200 sentences
(approx. 5,000 tokens) per language, split 50:50
between newswire and Wikipedia text. Each test
set is manually annotated for morphosyntax, fol-
lowing the MTE 4 guidelines for the respective
languages, and checked by native speakers for va-
lidity. On top of that, all test sets are annotated
with all three dependency schemes: PDT, SET and
SSJ. This enables observing LAS in a heteroge-
nous experimental environment, as we test each
monolingual and cross-lingual parser on an anno-
</bodyText>
<equation confidence="0.908665">
7http://nlp.ffzg.hr/data/tagging/
msd-hr.html
16
Language MSD tag Attribute-value pairs
hr Vmn Category = Verb, Type = main, Vform = infinitive
sl Vmen Category = Verb, Type = main, Aspect = perfective, VForm = infinitive
sr Vmn----an-n---e Category = Verb, Type = main, VForm = infinitive, Voice = active,
Negative = no, Clitic = no, Aspect = perfective
</equation>
<bodyText confidence="0.968738111111111">
Table 2: Illustration of the Multext East version 4 tagset for Croatian, Serbian and Slovene. The attributes
are language-dependent, as well as their positions in the tag, which are also dependent on the part of
speech, denoted by position zero in the tag.
tation layer matching its training set. In contrast,
the MTE 4 tagsets are not adjusted, i.e., each test
set only has a single language-specific MTE 4 an-
notation. We rely on their underlying similarities
in feature representations to suffice for improved
cross-lingual parsing performance.
</bodyText>
<sectionHeader confidence="0.990833" genericHeader="method">
3 Experiment Setup
</sectionHeader>
<bodyText confidence="0.9999926">
This section describes the experiment settings. We
list the general workflow of the experiment and
then provide the details on the parser setup and
the more advanced approaches used for target lan-
guage adaptation of the models.
</bodyText>
<subsectionHeader confidence="0.997025">
3.1 Workflow
</subsectionHeader>
<bodyText confidence="0.999974407407408">
The experiment consists of three work packages:
(1) monolingual parsing, (2) direct cross-lingual
parsing, and (3) cross-lingual parsing using syn-
thetic training data from SMT. In the first one, we
train dependency parsers on the four treebanks and
test them on the corresponding languages, thus
assessing the monolingual parsing performance.
The second stage observes the effects of directly
applying the parsers from the first stage across the
languages. Finaly, in the third work package, we
use four different approaches to automatic transla-
tion to create synthetic training data. We translate
the Croatian treebanks to Slovene and vice versa,
project the annotations using two different projec-
tion algorithms, and train and apply the adapted
parsers across the languages. The details are in-
cluded in the two following subsections.
Two general remarks apply to our experiment.
First, we perform cross-lingual parsing, and not
cross-annotation-scheme parsing. Thus, we do not
compare the dependency parsing scores between
the annotation schemes, but rather just between
the in-scheme parsers. Second, we use Serbian as
a test-set-only language. As there are no treebanks
of Serbian, we cannot use it as a source language,
and we leave SMT and annotation projection into
Serbian for future work.
</bodyText>
<subsectionHeader confidence="0.99929">
3.2 Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999963648648649">
In all experiments, we use the graph-based de-
pendency parser by Bohnet (2010) with default
settings. We base our parser choice on its state-
of-the-art performance across various morpholog-
ically rich languages in the SPMLR 2013 shared
task (Seddah et al., 2013). While newer contribu-
tions targeted at joint morphological and syntactic
analysis (Bohnet and Kuhn, 2012; Bohnet et al.,
2013) report slightly higher scores, we chose the
former one for speed and robustness, and because
we use gold standard POS/MSD annotations. The
choice of gold standard preprocessing is motivated
by previous research in parsing Croatian and Ser-
bian (Agi´c et al., 2013), and by insight of Sed-
dah et al. (2013), who report a predictable linear
decrease in accuracy for automatic preprocessing.
This decrease amounts to approximately 3 points
LAS for Croatian and Serbian across various test
cases in (Agi´c et al., 2013).
We observe effects of (de)lexicalization and of
using full MSD tagset as opposed to only POS tags
in all experiments. Namely, in all work packages,
we compare parsers trained with {lexicalized,
delexicalized} × {MSD, POS} features. In lexi-
calized parsers, we use word forms and features,
while we exclude lemmas from all experiments –
both previous research using MSTParser (McDon-
ald et al., 2005) and our own test runs show no
use for lemmas as features in dependency parsing.
Delexicalized parsers are stripped of all lexical
features, i.e., word forms are omitted from training
and testing data. Full MSD parsers use both the
POS information and the sub-POS features in the
form of atomic attribute-value pairs, while POS-
only parsers are stripped of the MSD features –
they use just the POS information. The delexi-
calized POS scenario is thus very similar to the
</bodyText>
<page confidence="0.772891">
17
</page>
<bodyText confidence="0.997881">
direct transfer by McDonald et al. (2013), since
MTE 4 POS is virtually identical to Universal POS
(Petrov et al., 2012).8
</bodyText>
<subsectionHeader confidence="0.9955165">
3.3 Treebank Translation and Annotation
Projection
</subsectionHeader>
<bodyText confidence="0.999854810810811">
For machine translation, we closely adhere to the
setup implemented by Tiedemann et al. (2014) in
their treebank translation experiments. Namely,
our translations are based on automatic word
alignment and subsequent extraction of translation
equivalents as common in phrase-based SMT. We
perform word alignment by using GIZA++ (Och
and Ney, 2003), while utilizing IBM model 4 for
creating the Viterbi word alignments for parallel
corpora. For the extraction of translation tables,
we use the de facto standard SMT toolbox Moses
(Koehn et al., 2007) with default settings. Phrase-
based SMT models are tuned using minimum er-
ror rate training (Och, 2003). Our monolingual
language modeling using KenLM tools9 (Heafield,
2011) produces standard 5-gram language mod-
els using modified Kneser-Ney smoothing without
pruning.
For building the translation models, we use
the OpenSubtitles parallel resources from OPUS10
(Tiedemann, 2009) for the Croatian-Slovene pair.
Even if we expect this to be a rather noisy paral-
lel resource, we justify the choice by (1) the fact
that no other parallel corpora11 of Croatian and
Slovene exist, other than Orwell’s 1984 from the
Multext East project, which is too small for SMT
training and falls into a very narrow domain, and
(2) evidence from (Tiedemann et al., 2014) that the
SMT-supported cross-lingual parsing approach is
very robust to translation noise.
For translating Croatian treebanks into Slovene
and vice versa, we implement and test four dif-
ferent methods of translation. They are coupled
with approaches to annotation projection from the
source side gold dependency trees to the target
translations via the word alignment information
available from SMT.
</bodyText>
<footnote confidence="0.8976352">
8A mapping from Slovene MTE 4 to Universal
POS is available at https://code.google.com/p/
universal-pos-tags/ as an example.
9https://kheafield.com/code/kenlm/
10http://opus.lingfil.uu.se/
</footnote>
<bodyText confidence="0.961628240740741">
11We note the Croatian-Slovene parallel corpus project de-
scribed by Poˇzgaj Hadˇzi and Tadi´c (2000), but it appears that
the project was not completed and the corpus itself is not pub-
licly available.
LOOKUP: The first approach to translation in
our experiment is the dictionary lookup approach.
We simply select the most reliable translations of
single words in the source language into the tar-
get language by looking up the phrase translation
tables extracted from the parallel corpus. This is
very similar to what Agi´c et al. (2012) did for the
Croatian-Slovene pair. However, their approach
involved both translating and testing on the same
small corpus (Orwell’s novel), while here we ex-
tract the translations from full-blown SMT phrase
tables on a much larger scale. The trees projec-
tion from source to target is trivial since the num-
ber and the ordering of words between them does
not change. Thus, the dependencies are simply
copied.
CHAR: By this acronym, we refer to an ap-
proach known as character-based statistical ma-
chine translation. It is shown to perform very
well for closely related languages (Vilar et al.,
2007; Tiedemann, 2012; Tiedemann and Nakov,
2013). The motivation for character-level transla-
tion is the ability of such models to better gener-
alize the mapping between similar languages es-
pecially in cases of rich productive morphology
and limited amounts of training data. With this,
character-level models largely reduce the num-
ber of out-of-vocabulary words. In a nutshell,
our character-based model performs word-to-word
translation using character-level modeling. Simi-
lar to LOOKUP, this is also a word-to-word trans-
lation model, which also requires no adaptation of
the source dependency trees – they are once again
simply copied to target sentences.
WORD: Our third take on SMT is slightly more
elaborate but still restricts the translation model
to one-to-one word mappings. In particular, we
extract all single word translation pairs from the
phrase tables and apply the standard beam-search
decoder implemented in Moses to translate the
original treebanks to all target languages. Thus,
we allow word reordering and use a language
model while still keeping the projection of anno-
tated data as simple as possible. The language
model may influence not only the word order but
also the lexical choice as we now allow multiple
translation options in our phrase table. Also note
that this approach may introduce additional non-
projectivity in the projected trees. This system
is the overall top-performer in (Tiedemann et al.,
</bodyText>
<figure confidence="0.940534113636363">
18
Pred
Pred
Obj
Atv
Sb
Obj
Obj
Sb
Atr
Atv
Sb
Atv
Atr
Ncfsn Vmip3s Vmn Afpmpa Ncmpa
Vlada planira otvoriti informativne urede
Vlada naˇcrtuje odprtje informacijske pisarne
Ncfsn Vmip3s Vmn Afpmpa Ncmpa
Ncfsn Vmip3s Vmn Afpmpa Ncmpa
Vlada planira otvoriti informativne urede
Vlada naˇcrtuje odprtje pisarne informativne
Ncfsn Vmip3s Vmn Afpmpa Ncmpa
Sb
Atv Atr
Sb
Atv
Obj
Atr
Obj
Pred
Pred
Pred
Pred
Ncfsn Vmip3s Vmn Afpmpa Ncmpa
Vlada planira otvoriti informativne urede
Vlada naˇcrtuje , da bo odprla DUMMY informacijske pisarne
Ncfsn Vmip3s -- dummy dummy dummy Vmn Afpmpa Ncmpa
Sb
dummy
Atr
dummy
dummy
Obj
Pred Atv
</figure>
<figureCaption confidence="0.9984895">
Figure 3: An illustration of the projections. Left side = CHAR, middle = WORD, right side = PHRASE. As
illustrated, WORD might introduce reorderings, while PHRASE can enter dummy nodes and edges to the
dependency trees. The sentence: The government plans to open information offices. See (Tiedemann et
al., 2014; Tiedemann, 2014) for detailed insight into projection algorithms.
</figureCaption>
<bodyText confidence="0.998639157894737">
2014), where reordering played an important role
in adapting the models to the target languages. We
test whether it holds for related languages as well.
PHRASE: This model implements translation
based on the entire phrase table using the standard
approach to phrase-based SMT. We basically run
the Moses decoder with default settings and the
parameters and models trained on our parallel cor-
pus. Here, we can have many-to-many word align-
ments, which require a more elaborate approach to
the projection of the source side dependency an-
notations. It is important for the annotation trans-
fer to keep track of the alignment between phrases
and words of the input and output sentences. The
Moses decoder provides both, phrase segmenta-
tion and word alignment. We use the annotation
projection algorithm of Hwa et al. (2005). As
illustrated in Figure 3, it resolves many-to-many
alignments by introducing dummy nodes to the
dependency trees. We use the implementation by
Tiedemann (2014), which addresses certain issues
with algorithm choices for ambiguous alignments
which were left unaccounted for in the original
work. Since this paper does not focus on the intri-
cacies of annotation projection, but rather on ap-
plying it in an environment of related languages
and rich MSD tagsets, we refer the reader to re-
lated work regarding the details.
We translate from Croatian to Slovene and vice
versa using four different treebanks and these
four different methods of translation and annota-
tion projection. As we stated in the experiment
overview, for each of these, we also experiment
with (de)lexicalization and MSD vs. POS, and we
test on all three languages. The three experimental
batches – monolingual, direct and SMT-supported
transfer – produce a large number of observations,
all of which we assess in the following section.
</bodyText>
<sectionHeader confidence="0.994785" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999994875">
We split our discussion of the parsing results into
the following three subsections. We first observe
the performance of monolingual parsers. Sec-
ondly, we measure the quality of these when ap-
plied directly on the other two languages. Finally,
we look into the accuracy of parsers trained on
SMT-generated artificial treebank data when ap-
plied across the test languages.
</bodyText>
<subsectionHeader confidence="0.995578">
4.1 Monolingual Parsing
</subsectionHeader>
<bodyText confidence="0.999895">
Accuracies of parsers trained and applied on train-
ing and testing data belonging to the same lan-
guage – i.e., our monolingual parsers – are pro-
vided in the grayed out sections of Table 3.
Parsing Croatian using hr PDT yields a high
score of 69.45 LAS, better than the former state
of the art on this test set (Agi´c et al., 2013) simply
due to applying a newer generation parser. This
score is provided by a lexicalized model with the
full MSD feature set. Replacing MSD with POS or
delexicalizing this model results in a 3-point drop
in LAS, while applying both replacements sub-
stantially decreases the score – by more than 11
points LAS. We observe virtually the same pattern
for the other Croatian treebank, hr SET, where this
latter drop is even more significant, at 14 points.
Incidentally, 76.36 points LAS is also the new
state of the art for hr SET parsing, owing to the
recent enlargement of the treebank.
The Slovene parsers exhibit effectively the same
behavior as the Croatian ones. The lexicalized
MSD models of sl PDT and sl SSJ both record new
state-of-the-art scores, although the latter one on a
different test set than in previous research (Dobro-
voljc et al., 2012). At over 92 points LAS, sl SSJ
</bodyText>
<page confidence="0.783077">
19
</page>
<tableCaption confidence="0.398205">
lexicalized delexicalized
hr sl sr hr sl sr
</tableCaption>
<table confidence="0.996835">
MSD POS MSD POS MSD POS MSD POS MSD POS MSD POS
hr PDT 69.45 66.95 60.09 50.19 69.42 66.96 66.03 57.79 57.98 42.66 66.79 57.41
SET 76.36 73.02 68.65 59.52 76.08 73.37 72.52 62.31 68.16 55.17 72.71 62.04
sl PDT 51.19 47.99 76.46 73.33 52.46 49.64 49.58 42.59 71.96 62.99 50.41 44.11
SSJ 78.50 74.18 92.38 88.93 78.94 75.96 75.23 66.23 87.19 77.92 75.25 67.47
</table>
<tableCaption confidence="0.822561333333333">
Table 3: Monolingual and direct cross-lingual parsing accuracy, expressed by the labeled accuracy metric
(LAS). Scores are split for lexicalized and delexicalized, full MSD and POS only parsers. Monolingual
scores are in grey. Row indices represent source languages and treebanks.
</tableCaption>
<bodyText confidence="0.999684">
expectedly shows to be the easiest to parse, most
likely due to the relatively flat tree structure and its
small label set.
We note the following general pattern of fea-
ture importance. Dropping MSD features seems
to carry the most weight in all models, followed
by lexicalization. Dropping MSD is compensated
in part by lexical features paired with POS, while
dropping both MSD and word forms severely de-
grades all models. At this point, it is very impor-
tant to note that at 60-70 points LAS, these de-
creased scores closely resemble those of McDon-
ald et al. (2013) for the six languages in the Uni-
versal Treebanks. This observation is taken further
in the next subsection.
</bodyText>
<subsectionHeader confidence="0.992595">
4.2 Direct Cross-lingual Parsing
</subsectionHeader>
<bodyText confidence="0.999992545454546">
The models used for monolingual parsing are here
directly applied on all languages but the treebank
source language, thus constituting a direct cross-
lingual parsing scenario. Its scores are also given
in Table 3, but now in the non-grey parts.
Croatian models are applied to Slovene and Ser-
bian test sets. For hr PDT, the highest score is
60.09 LAS on Slovene and 69.42 LAS on Serbian,
the latter noted as the state of the art for Serbian
PDT parsing. Comparing the cross-lingual score to
monolingual Slovene, the difference is substantial
as expected and comparable to the drops observed
by McDonald et al. (2013) in their experiments.
Our ranking of feature significance established in
the monolingual experiments holds here as well,
or rather, the absolute differences are even more
pronounced. Most notably, the difference between
the lexicalized MSD model and the delexicalized
POS model is 17 points LAS in favor of the for-
mer one on Slovene. hr SET appears to be more
resilient to delexicalization and tagset reduction
when applied on Slovene and Serbian, most likely
due to the treebank’s size, well-balanced depen-
dency label set and closer conformance with the
official MTE 4 guidelines. That said, the feature
patterns still hold. Also, 76.08 LAS for Serbian is
the new state of the art for SET parsing.
Slovene PDT is an outlier due to its small size,
as its training set is just over 1,500 sentences. Still,
the scores maintain the level of those in related
research, and the feature rankings hold. Perfor-
mance of parsing Croatian and Serbian using sl
SSJ is high, arguably up to the level of usability
in down-stream applications. These are the first
recorded scores in parsing the two languages us-
ing SSJ, and they reach above 78 points LAS for
both. Even if the scores are not comparable across
the annotation schemes due to their differences, it
still holds that the SSJ scores are the highest ab-
solute parsing scores recorded in the experiment.
This might hold significance in applications that
require robust parsing for shallow syntax.
Generally, the best transfer scores are quite
high in comparison with those on Universal Tree-
banks (McDonald et al., 2013; Tiedemann et al.,
2014). This is surely due to the relatedness of
the three languages. However, even for these ar-
guably closely related languages, the performance
of delexicalized models that rely only on POS fea-
tures – averaging at around 55 points LAS – is vir-
tually identical to that on more distant languages
test-cased in related work. We see this as a very
strong indicator of fundamental limitations of us-
ing linguistically impoverished shared feature rep-
resentations in cross-lingual parsing.
</bodyText>
<subsectionHeader confidence="0.9360955">
4.3 Cross-lingual Parsing with Treebank
Translation
</subsectionHeader>
<bodyText confidence="0.9999176">
Finally, we discuss what happens to parsing per-
formance when we replace direct cross-lingual ap-
plication of parsers with training models on trans-
lated treebanks. We take a treebank, Croatian or
Slovene, and translate it into the other language.
</bodyText>
<table confidence="0.948100833333333">
20
Target Approach PDT SET SSJ
hr monolingual 69.45 76.36 –
direct 51.19 – 78.50
translated 67.55 v 74.68 0 79.51 4
sl monolingual 76.46 – 92.38
direct 60.09 68.65 –
translated 72.35 4 70.52 4 88.71 4
sr monolingual – – –
direct 69.42 76.08 78.94
translated 68.11 4 74.31 0 79.81 v4
Legend: 4 CHAR v LOOKUP 0 PHRASE 4 WORD
</table>
<tableCaption confidence="0.99487">
Table 4: Parsing score (LAS) summary for the top-
</tableCaption>
<bodyText confidence="0.9951554375">
performing systems with respect to language and
approach to parser induction. All models are MSD
+ lexicalized.
We then train a parser on the translation and ap-
ply it on all three target test sets. We do this for all
the treebanks, and in all variations regarding trans-
lation and projection methods, morphological fea-
tures and lexicalization.
All scores for this evaluation stage are given in
Table 5 for completeness. The table contains 192
different LAS scores, possibly constituting a te-
dious read. Thus, in Table 4 we provide a sum-
mary of information on the top-performing parsers
from all three experimental stages, which includes
treebank translation.
We can see that the best models based on
translating the treebanks predominantly stem from
word-to-word SMT, i.e., from WORD transla-
tion models that basically enrich the lexical fea-
ture space and perform word reordering, enabling
straightforward copying of syntactic structures
from translation sources to translation targets. Fol-
lowing them are the CHAR and LOOKUP models,
expectedly leaving – although not too far behind
– PHRASE behind given the similarities of the lan-
guage pair. Since Croatian and Slovene are related
languages, the differences between the models are
not as substantial as in (Tiedemann et al., 2014),
but WORD models still turn out to be the most ro-
bust ones, even if word reordering might not be so
frequent in this language pair as in the data from
(McDonald et al., 2013). Further, when compar-
ing the best SMT-supported models to monolin-
gual parsers, we see that the models with trans-
lation come really close to monolingual perfor-
mance. In comparison with direct transfer, models
trained on translated treebanks manage to outper-
form them in most cases, especially for the more
distant language pairs. For example, the sl H hr
SSJ WORD model is 1 point LAS better on Croat-
ian than the directly applied Slovene model, and
the same holds for testing on Serbian with the
same dataset. On the other side, directly applied
models from Croatian SET outperform the trans-
lated ones for Serbian. For PDT, the translated
models are substantially better between Croatian
and Slovene since sl PDT is an outlier in terms
of size and dataset selection, while direct trans-
fer from Croatian seems to work better for Serbian
than the translated models.
Reflecting on the summary in Table 4 more
generally, by and large, we see high parsing ac-
curacies. Averages across the formalisms reach
well beyond 70 points LAS. We attribute this to
the relatedness of the languages selected for this
case study, as well as to the quality of the un-
derlying language resources. From another view-
point, the table clearly shows the prominence of
lexical and especially rich morphosyntactic tagset
features throughout the experiment. Across our
monolingual, direct and SMT-supported parsing
experiments, these features are represented in the
best systems, and dropping them incurs significant
decreasesin accuracy.
</bodyText>
<sectionHeader confidence="0.977676" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999964181818182">
In this contribution, we addressed the topic of
cross-lingual dependency parsing, i.e., applying
dependency parsers from typically resource-rich
source languages to under-resourced target lan-
guages. We used three Slavic languages – Croat-
ian, Slovene and Serbian – as a test case for related
languages in different stages of language resource
development. As these are relatively free-word-
order languages with rich morphology, we were
able to test the cross-lingual parsers for perfor-
mance when using training features drawing from
large morphosyntactic tagsets – typically consist-
ing of over 1,000 different tags – in contrast to
impoverished common part-of-speech representa-
tions. We tested monolingual parsing, direct cross-
lingual parsing and a very recent promising ap-
proach with artificial creation of training data via
machine translation. In the experiments, we ob-
served state-of-the-art results in dependency pars-
ing for all three languages. We strongly argued
and supported the case for using common rich rep-
resentations of morphology in dependency parsing
</bodyText>
<page confidence="0.80552">
21
</page>
<table confidence="0.999352518518519">
lexicalized delexicalized
hr sl sr hr sl sr
MSD POS MSD POS MSD POS MSD POS MSD POS MSD POS
PDT 66.92 60.25 61.49 55.57 67.83 62.04 66.56 57.63 58.34 43.04 66.89 57.65
SET 73.65 64.64 70.52 66.11 72.95 64.44 72.98 62.98 69.03 54.81 72.74 62.73
PDT 51.96 48.14 72.35 63.71 53.11 49.47 49.58 42.59 71.96 62.99 50.41 44.11
SSJ 78.69 75.45 88.21 78.88 79.25 77.09 75.23 66.23 87.19 77.92 75.25 67.47
PDT 67.55 59.96 60.81 56.54 67.78 61.41 66.56 57.63 58.34 43.04 66.89 57.65
SET 73.58 64.98 69.93 68.09 73.70 64.25 72.52 62.72 68.47 55.27 72.71 62.73
PDT 51.74 49.15 72.02 63.08 53.49 51.33 49.58 42.59 71.96 62.99 50.41 44.11
SSJ 79.25 77.06 88.10 78.53 79.81 77.23 75.23 66.23 87.19 77.92 75.25 67.47
PDT 67.33 59.24 61.80 57.14 68.11 61.13 65.84 57.12 58.17 42.99 67.12 57.70
SET 73.26 65.87 69.98 68.98 73.63 65.85 72.71 62.29 68.50 55.06 73.14 62.40
PDT 51.67 49.58 71.47 63.51 54.62 51.82 50.25 43.17 71.27 62.79 50.79 44.07
SSJ 79.51 76.89 88.71 79.69 79.81 78.03 75.95 67.19 86.92 77.28 75.89 68.18
PDT 67.28 58.90 60.53 56.79 67.92 61.36 65.77 55.06 58.18 45.41 66.16 55.79
SET 74.68 65.29 69.42 68.55 74.31 65.17 73.36 60.77 68.16 58.42 72.15 61.55
PDT 49.92 46.82 68.18 58.18 52.15 49.42 47.73 41.08 68.51 55.29 48.93 42.59
SSJ 79.29 78.09 88.24 78.75 79.32 78.85 75.33 68.10 86.59 75.66 75.91 68.67
CHAR hr ( sl
sl ( hr
LOOKUP hr ( sl
sl ( hr
WORD hr ( sl
sl ( hr
PHRASE hr ( sl
sl ( hr
</table>
<tableCaption confidence="0.988566">
Table 5: Parsing scores (LAS) for cross-lingual parsers trained on translated treebanks. Scores are
</tableCaption>
<bodyText confidence="0.999233839285715">
split for lexicalized and delexicalized, full MSD and POS only parsers, and with respect to the trans-
lation/projection approaches. Row indices represent source languages and treebanks, and indicate the
direction of applying SMT (e.g., hr ( sl denotes a Croatian treebank translated to Slovene).
for morphologically rich languages. Through our
multilayered test set annotation, we also facilitated
a reliable cross-lingual evaluation in a heteroge-
nous testing environment. We list our most impor-
tant observations:
■ Even for closely related languages, using only
the basic POS features – which are virtually
identical to the widely-used Universal POS of
Petrov et al. (2012) – substantially decreases
parsing accuracy up to the level comparable with
results of McDonald et al. (2013) across the Uni-
versal Treebanks language groups.
■ Adding MSD features heavily influences all the
scores in a positive way. This has obvious im-
plications for improving over McDonald et al.
(2013) on the Universal Treebanks dataset.
■ Other than that, we show that it is possible
to cross-lingually parse Croatian, Serbian and
Slovene using all three syntactic annotation
schemes, and with high accuracy. A treebank for
Serbian does not exist, but we accurately parse
Serbian by using PDT, SET and SSJ-style annota-
tions. We parse Croatian using SSJ (transferred
from Slovene) and Slovene using SSJ (trans-
ferred from Croatian). This clearly indicates the
possibilities of uniform downstream pipelining
for any of the schemes.
■ We show clear benefits of using the SMT ap-
proach for transferring SSJ parsers to Croatian
and SET parsers to Slovene. We observe these
benefits regardless of the low-quality, out-of-
domain SMT training data (OpenSubs).
Given the current interest for cross-lingual depen-
dency parsing in the natural language processing
community, we will seek to further test our obser-
vations on shared morphological features by us-
ing other pairs of languages of varying relatedness,
drawing from datasets such as Google Universal
Treebanks (McDonald et al., 2013) or HamleDT
(Zeman et al., 2012; Rosa et al., 2014). The goal
of cross-lingual processing in general is to enable
improved general access to under-resourced lan-
guages. With this in mind, seeing how we intro-
duced a test case of Serbian as a language cur-
rently without a treebank, we hope to explore other
options for performing cross-lingual experiments
on actual under-resourced languages, rather than
in an exclusive group of resource-rich placehold-
ers, possibly by means of down-stream evaluation.
Acknowledgments The second author was sup-
ported by the Swedish Research Council (Veten-
skapsr˚adet), project 2012-916. The fifth author is
funded by the EU FP7 STREP project XLike.
</bodyText>
<page confidence="0.793105">
22
</page>
<sectionHeader confidence="0.987122" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997426989361702">
Anne Abeill´e. 2003. Treebanks: Building and Using
Parsed Corpora. Springer.
&amp;quot;Zeljko Agi´c and Nikola Ljube&amp;quot;si´c. 2014. The SE-
Times.HR Linguistically Annotated Corpus of Croa-
tian. In Proc. LREC, pages 1724–1727.
&amp;quot;Zeljko Agi´c and Danijela Merkler. 2013. Three
Syntactic Formalisms for Data-Driven Dependency
Parsing of Croatian. LNCS, 8082:560–567.
&amp;quot;Zeljko Agi´c, Danijela Merkler, and Da&amp;quot;sa Berovi´c.
2012. Slovene-Croatian Treebank Transfer Using
Bilingual Lexicon Improves Croatian Dependency
Parsing. In Proc. IS-LTC, pages 5–9.
&amp;quot;Zeljko Agi´c, Danijela Merkler, and Da&amp;quot;sa Berovi´c.
2013. Parsing Croatian and Serbian by Using Croat-
ian Dependency Treebanks. In Proc. SPMRL, pages
22–33.
&amp;quot;Zeljko Agi´c, Da&amp;quot;sa Berovi´c, Danijela Merkler, and
Marko Tadi´c. 2014. Croatian Dependency Tree-
bank 2.0: New Annotation Guidelines for Improved
Parsing. In Proc. LREC, pages 2313–2319.
Emily Bender. 2011. On achieving and evaluating
language-independence in nlp. Linguistic Issues in
Language Technology, 6(3):1–26.
Emily Bender. 2013. Linguistic Fundamentals for
Natural Language Processing: 100 Essentials from
Morphology and Syntax. Morgan &amp; Claypool Pub-
lishers.
Dass&amp;quot;a Berovi´c, &amp;quot;Zeljko Agi´c, and Marko Tadi´c. 2012.
Croatian Dependency Treebank: Recent Develop-
ment and Initial Experiments. In Proc. LREC, pages
1902–1906.
Alena B¨ohmov´a, Jan Haji&amp;quot;c, Eva Haji&amp;quot;cov´a, and Barbora
Hladk´a. 2003. The Prague Dependency Treebank.
In Treebanks, pages 103–127.
Bernd Bohnet and Jonas Kuhn. 2012. The Best of
Both Worlds – A Graph-based Completion Model
for Transition-based Parsers. In Proc. EACL, pages
77–87.
Bernd Bohnet, Joakim Nivre, Igor Boguslavsky,
Rich´ard Farkas, Filip Ginter, and Jan Hajic. 2013.
Joint Morphological and Syntactic Analysis for
Richly Inflected Languages. TACL, 1:415–428.
Bernd Bohnet. 2010. Top Accuracy and Fast Depen-
dency Parsing is not a Contradiction. In Proc. COL-
ING, pages 89–97.
Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X
Shared Task on Multilingual Dependency Parsing.
In Proc. CoNLL, pages 149–164.
Marie-Catherine De Marneffe and Christopher D Man-
ning. 2008. The Stanford Typed Dependencies Rep-
resentation. In Proc. COLING, pages 1–8.
Kaja Dobrovoljc, Simon Krek, and Jan Rupnik. 2012.
Skladenjski raz&amp;quot;clenjevalnik za sloven&amp;quot;s&amp;quot;cino. In Proc.
IS-LTC, pages 42–47.
Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syn-
tactic Transfer Using a Bilingual Lexicon. In Proc.
EMNLP-CoNLL, pages 1–11.
Sa&amp;quot;so Dz&amp;quot;eroski, Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pa-
jas, Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele. 2006.
Towards a Slovene Dependency Treebank. In Proc.
LREC, pages 1388–1391.
Toma&amp;quot;z Erjavec, Darja Fi&amp;quot;ser, Simon Krek, and Nina
Ledinek. 2010. The JOS Linguistically Tagged Cor-
pus of Slovene. In Proc. LREC, pages 1806–1809.
Toma&amp;quot;z Erjavec. 2012. MULTEXT-East: Morphosyn-
tactic Resources for Central and Eastern European
Languages. Language Resources and Evaluation,
46(1):131–142.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proc. WSMT, pages
187–197.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrap-
ping Parsers via Syntactic Projection across Parallel
Texts. Natural Language Engineering, 11(3):311–
325.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, et al. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Proc.
ACL, pages 177–180.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Morgan &amp; Claypool
Publishers.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Haji&amp;quot;c. 2005. Non-projective Dependency Pars-
ing Using Spanning Tree Algorithms. In Proc. HLT-
EMNLP, pages 523–530.
Ryan McDonald, Slav Petrov, and Keith Hall. 2011.
Multi-Source Transfer of Delexicalized Dependency
Parsers. In Proc. EMNLP, pages 62–72.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria
Bertomeu Castell´o, and Jungmee Lee. 2013.
Universal Dependency Annotation for Multilingual
Parsing. In Proc. ACL, pages 92–97.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 Shared Task on De-
pendency Parsing. In Proc. CoNLL, pages 915–932.
23
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19–51.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proc. ACL,
pages 160–167.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A Universal Part-of-Speech Tagset. In Proc. LREC,
pages 2089–2096.
Vesna Poz&amp;quot;gaj Had&amp;quot;zi and Marko Tadi´c. 2000. Croatian-
Slovene Parallel Corpus. In Proc. IS-LTC.
Rudolf Rosa, Jan Ma&amp;quot;sek, David Mare&amp;quot;cek, Martin
Popel, Daniel Zeman, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y.
2014. HamleDT 2.0: Thirty Dependency Treebanks
Stanfordized. In Proc. LREC, pages 2334–2341.
Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie
Candito, Jinho D. Choi, Rich´ard Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola Gal-
letebeitia, Yoav Goldberg, Spence Green, Nizar
Habash, Marco Kuhlmann, Wolfgang Maier, Joakim
Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang
Seeker, Yannick Versley, Veronika Vincze, Marcin
Woli´nski, Alina Wr´oblewska, and Eric Villemonte
de la Clergerie. 2013. Overview of the SPMRL
2013 Shared Task: Cross-framework Evaluation of
Parsing Morphologically Rich Languages. In Proc.
SPMRL, pages 146–182.
Anders Søgaard. 2011. Data Point Selection for Cross-
language Adaptation of Dependency Parsers. In
Proc. ACL, pages 682–686.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszko-
reit. 2012. Cross-lingual Word Clusters for Direct
Transfer of Linguistic Structure. In Proc. NAACL,
pages 477–487.
Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre.
2013. Target Language Adaptation of Discrimina-
tive Transfer Parsers. In Proc. NAACL, pages 1061–
1071.
Marko Tadi´c and Sanja Fulgosi. 2003. Building the
Croatian Morphological Lexicon. In Proc. BSNLP,
pages 41–46.
Marko Tadi´c and Tam´as V´aradi. 2012. Central and
South-East European Resources in META-SHARE.
Proc. COLING, pages 431–438.
Marko Tadi´c. 2007. Building the Croatian Depen-
dency Treebank: The Initial Stages. Suvremena
lingvistika, 63:85–92.
J¨org Tiedemann and Preslav Nakov. 2013. Analyzing
the Use of Character-Level Translation with Sparse
and Noisy Datasets. In Proc. RANLP, pages 676–
684.
J¨org Tiedemann, &amp;quot;Zeljko Agi´c, and Joakim Nivre. 2014.
Treebank Translation for Cross-Lingual Parser In-
duction. In Proc. CoNLL, pages 130–140.
J¨org Tiedemann. 2009. News from OPUS: A Collec-
tion of Multilingual Parallel Corpora with Tools and
Interfaces. In Proc. RANLP, volume 5, pages 237–
248.
J¨org Tiedemann. 2012. Character-Based Pivot Trans-
lations for Under-Resourced Languages and Do-
mains. In Proc. EACL, pages 141–151.
J¨org Tiedemann. 2014. Rediscovering Annotation
Projection for Cross-Lingual Parser Induction. In
Proc. COLING.
Erik F Tjong Kim Sang and Sabine Buchholz. 2000.
Introduction to the CoNLL-2000 Shared Task:
Chunking. In Proc. CoNLL, pages 127–132.
Hans Uszkoreit and Georg Rehm. 2012. Language
White Paper Series. Springer.
David Vilar, Jan-Thorsten Peter, and Hermann Ney.
2007. Can We Translate Letters? In Proc. WMT,
pages 33–39.
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing Multilingual Text Analy-
sis Tools via Robust Projection Across Aligned Cor-
pora. In Proc. HLT, pages 1–8.
Daniel Zeman and Philip Resnik. 2008. Cross-
Language Parser Adaptation between Related Lan-
guages. In Proc. IJCNLP, pages 35–42.
Daniel Zeman, David Marecek, Martin Popel,
Loganathan Ramasamy, Jan Step´anek, Zdenek
Zabokrtsk`y, and Jan Hajic. 2012. HamleDT: To
Parse or Not to Parse? In Proc. LREC, pages 2735–
2741.
</reference>
<page confidence="0.952425">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.415489">
<title confidence="0.9984615">Cross-lingual Dependency Parsing of Related Languages with Morphosyntactic Tagsets</title>
<author confidence="0.838426">Agi´c J¨org Tiedemann Kaja Dobrovoljc</author>
<email confidence="0.492435">zagic@uni-potsdam.dejorg.tiedemann@lingfil.uu.sekaja.dobrovoljc@trojina.si</email>
<author confidence="0.981131">Simon Krek Danijela Merkler Sara Moˇze</author>
<email confidence="0.877007">simon.krek@ijs.sidmerkler@ffzg.hrs.moze@wlv.ac.uk</email>
<abstract confidence="0.998008619047619">This paper addresses cross-lingual dependency parsing using rich morphosyntactic tagsets. In our case study, we experiment with three related Slavic languages: Croatian, Serbian and Slovene. Four different dependency treebanks are used for monolingual parsing, direct cross-lingual parsing, and a recently introduced crosslingual parsing approach that utilizes statistical machine translation and annotation projection. We argue for the benefits of using rich morphosyntactic tagsets in cross-lingual parsing and empirically support the claim by showing large improvements over an impoverished common feature representation in form of a reduced part-of-speech tagset. In the process, we improve over the previous state-of-the-art scores in dependency parsing for all three languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anne Abeill´e</author>
</authors>
<title>Treebanks: Building and Using Parsed Corpora.</title>
<date>2003</date>
<publisher>Springer.</publisher>
<marker>Abeill´e, 2003</marker>
<rawString>Anne Abeill´e. 2003. Treebanks: Building and Using Parsed Corpora. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeljko Agi´c</author>
<author>Nikola Ljubesi´c</author>
</authors>
<title>The SETimes.HR Linguistically Annotated Corpus of Croatian. In</title>
<date>2014</date>
<booktitle>Proc. LREC,</booktitle>
<pages>1724--1727</pages>
<marker>Agi´c, Ljubesi´c, 2014</marker>
<rawString>&amp;quot;Zeljko Agi´c and Nikola Ljube&amp;quot;si´c. 2014. The SETimes.HR Linguistically Annotated Corpus of Croatian. In Proc. LREC, pages 1724–1727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeljko Agi´c</author>
<author>Danijela Merkler</author>
</authors>
<title>Three Syntactic Formalisms for Data-Driven Dependency Parsing of Croatian.</title>
<date>2013</date>
<booktitle>LNCS,</booktitle>
<pages>8082--560</pages>
<marker>Agi´c, Merkler, 2013</marker>
<rawString>&amp;quot;Zeljko Agi´c and Danijela Merkler. 2013. Three Syntactic Formalisms for Data-Driven Dependency Parsing of Croatian. LNCS, 8082:560–567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeljko Agi´c</author>
<author>Danijela Merkler</author>
<author>Dasa Berovi´c</author>
</authors>
<title>Slovene-Croatian Treebank Transfer Using Bilingual Lexicon Improves Croatian Dependency Parsing. In</title>
<date>2012</date>
<booktitle>Proc. IS-LTC,</booktitle>
<pages>5--9</pages>
<marker>Agi´c, Merkler, Berovi´c, 2012</marker>
<rawString>&amp;quot;Zeljko Agi´c, Danijela Merkler, and Da&amp;quot;sa Berovi´c. 2012. Slovene-Croatian Treebank Transfer Using Bilingual Lexicon Improves Croatian Dependency Parsing. In Proc. IS-LTC, pages 5–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeljko Agi´c</author>
<author>Danijela Merkler</author>
<author>Dasa Berovi´c</author>
</authors>
<title>Parsing Croatian and Serbian by Using Croatian Dependency Treebanks.</title>
<date>2013</date>
<booktitle>In Proc. SPMRL,</booktitle>
<pages>22--33</pages>
<marker>Agi´c, Merkler, Berovi´c, 2013</marker>
<rawString>&amp;quot;Zeljko Agi´c, Danijela Merkler, and Da&amp;quot;sa Berovi´c. 2013. Parsing Croatian and Serbian by Using Croatian Dependency Treebanks. In Proc. SPMRL, pages 22–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zeljko Agi´c</author>
<author>Dasa Berovi´c</author>
<author>Danijela Merkler</author>
<author>Marko Tadi´c</author>
</authors>
<title>Croatian Dependency Treebank 2.0: New Annotation Guidelines for Improved Parsing. In</title>
<date>2014</date>
<booktitle>Proc. LREC,</booktitle>
<pages>2313--2319</pages>
<marker>Agi´c, Berovi´c, Merkler, Tadi´c, 2014</marker>
<rawString>&amp;quot;Zeljko Agi´c, Da&amp;quot;sa Berovi´c, Danijela Merkler, and Marko Tadi´c. 2014. Croatian Dependency Treebank 2.0: New Annotation Guidelines for Improved Parsing. In Proc. LREC, pages 2313–2319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Bender</author>
</authors>
<title>On achieving and evaluating language-independence in nlp.</title>
<date>2011</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="1306" citStr="Bender, 2011" startWordPosition="175" endWordPosition="176">anslation and annotation projection. We argue for the benefits of using rich morphosyntactic tagsets in cross-lingual parsing and empirically support the claim by showing large improvements over an impoverished common feature representation in form of a reduced part-of-speech tagset. In the process, we improve over the previous state-of-the-art scores in dependency parsing for all three languages. 1 Introduction A large majority of human languages are underresourced in terms of text corpora and tools available for applications in natural language processing (NLP). According to recent surveys (Bender, 2011; Uszkoreit and Rehm, 2012; Bender, 2013), this is especially apparent with syntactically annotated corpora, i.e., treebanks – both dependencybased ones and others. In this paper, we focus on dependency parsing (K¨ubler et al., 2009), but the claims should hold in general. The lack of dependency treebanks is due to the fact that they are expensive and time-consuming to construct (Abeill´e, 2003). Since dependency parsing of under-resourced languages nonetheless draws substantial interest in the NLP research community, over time, we have seen a number of research efforts directed towards their </context>
</contexts>
<marker>Bender, 2011</marker>
<rawString>Emily Bender. 2011. On achieving and evaluating language-independence in nlp. Linguistic Issues in Language Technology, 6(3):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Bender</author>
</authors>
<title>Linguistic Fundamentals for Natural Language Processing:</title>
<date>2013</date>
<booktitle>100 Essentials from Morphology and Syntax.</booktitle>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1347" citStr="Bender, 2013" startWordPosition="181" endWordPosition="182">argue for the benefits of using rich morphosyntactic tagsets in cross-lingual parsing and empirically support the claim by showing large improvements over an impoverished common feature representation in form of a reduced part-of-speech tagset. In the process, we improve over the previous state-of-the-art scores in dependency parsing for all three languages. 1 Introduction A large majority of human languages are underresourced in terms of text corpora and tools available for applications in natural language processing (NLP). According to recent surveys (Bender, 2011; Uszkoreit and Rehm, 2012; Bender, 2013), this is especially apparent with syntactically annotated corpora, i.e., treebanks – both dependencybased ones and others. In this paper, we focus on dependency parsing (K¨ubler et al., 2009), but the claims should hold in general. The lack of dependency treebanks is due to the fact that they are expensive and time-consuming to construct (Abeill´e, 2003). Since dependency parsing of under-resourced languages nonetheless draws substantial interest in the NLP research community, over time, we have seen a number of research efforts directed towards their processing despite the absence of trainin</context>
</contexts>
<marker>Bender, 2013</marker>
<rawString>Emily Bender. 2013. Linguistic Fundamentals for Natural Language Processing: 100 Essentials from Morphology and Syntax. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dassa Berovi´c</author>
</authors>
<title>Zeljko Agi´c, and Marko Tadi´c.</title>
<date>2012</date>
<booktitle>In Proc. LREC,</booktitle>
<pages>1902--1906</pages>
<marker>Berovi´c, 2012</marker>
<rawString>Dass&amp;quot;a Berovi´c, &amp;quot;Zeljko Agi´c, and Marko Tadi´c. 2012. Croatian Dependency Treebank: Recent Development and Initial Experiments. In Proc. LREC, pages 1902–1906.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajic</author>
<author>Eva Hajicov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The Prague Dependency Treebank. In Treebanks,</title>
<date>2003</date>
<pages>103--127</pages>
<marker>B¨ohmov´a, Hajic, Hajicov´a, Hladk´a, 2003</marker>
<rawString>Alena B¨ohmov´a, Jan Haji&amp;quot;c, Eva Haji&amp;quot;cov´a, and Barbora Hladk´a. 2003. The Prague Dependency Treebank. In Treebanks, pages 103–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Jonas Kuhn</author>
</authors>
<title>The Best of Both Worlds – A Graph-based Completion Model for Transition-based Parsers. In</title>
<date>2012</date>
<booktitle>Proc. EACL,</booktitle>
<pages>77--87</pages>
<contexts>
<context position="19120" citStr="Bohnet and Kuhn, 2012" startWordPosition="2948" endWordPosition="2951"> between the in-scheme parsers. Second, we use Serbian as a test-set-only language. As there are no treebanks of Serbian, we cannot use it as a source language, and we leave SMT and annotation projection into Serbian for future work. 3.2 Dependency Parsing In all experiments, we use the graph-based dependency parser by Bohnet (2010) with default settings. We base our parser choice on its stateof-the-art performance across various morphologically rich languages in the SPMLR 2013 shared task (Seddah et al., 2013). While newer contributions targeted at joint morphological and syntactic analysis (Bohnet and Kuhn, 2012; Bohnet et al., 2013) report slightly higher scores, we chose the former one for speed and robustness, and because we use gold standard POS/MSD annotations. The choice of gold standard preprocessing is motivated by previous research in parsing Croatian and Serbian (Agi´c et al., 2013), and by insight of Seddah et al. (2013), who report a predictable linear decrease in accuracy for automatic preprocessing. This decrease amounts to approximately 3 points LAS for Croatian and Serbian across various test cases in (Agi´c et al., 2013). We observe effects of (de)lexicalization and of using full MSD</context>
</contexts>
<marker>Bohnet, Kuhn, 2012</marker>
<rawString>Bernd Bohnet and Jonas Kuhn. 2012. The Best of Both Worlds – A Graph-based Completion Model for Transition-based Parsers. In Proc. EACL, pages 77–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Joakim Nivre</author>
<author>Igor Boguslavsky</author>
<author>Rich´ard Farkas</author>
<author>Filip Ginter</author>
<author>Jan Hajic</author>
</authors>
<title>Joint Morphological and Syntactic Analysis for Richly Inflected Languages.</title>
<date>2013</date>
<tech>TACL,</tech>
<pages>1--415</pages>
<contexts>
<context position="19142" citStr="Bohnet et al., 2013" startWordPosition="2952" endWordPosition="2955">parsers. Second, we use Serbian as a test-set-only language. As there are no treebanks of Serbian, we cannot use it as a source language, and we leave SMT and annotation projection into Serbian for future work. 3.2 Dependency Parsing In all experiments, we use the graph-based dependency parser by Bohnet (2010) with default settings. We base our parser choice on its stateof-the-art performance across various morphologically rich languages in the SPMLR 2013 shared task (Seddah et al., 2013). While newer contributions targeted at joint morphological and syntactic analysis (Bohnet and Kuhn, 2012; Bohnet et al., 2013) report slightly higher scores, we chose the former one for speed and robustness, and because we use gold standard POS/MSD annotations. The choice of gold standard preprocessing is motivated by previous research in parsing Croatian and Serbian (Agi´c et al., 2013), and by insight of Seddah et al. (2013), who report a predictable linear decrease in accuracy for automatic preprocessing. This decrease amounts to approximately 3 points LAS for Croatian and Serbian across various test cases in (Agi´c et al., 2013). We observe effects of (de)lexicalization and of using full MSD tagset as opposed to </context>
</contexts>
<marker>Bohnet, Nivre, Boguslavsky, Farkas, Ginter, Hajic, 2013</marker>
<rawString>Bernd Bohnet, Joakim Nivre, Igor Boguslavsky, Rich´ard Farkas, Filip Ginter, and Jan Hajic. 2013. Joint Morphological and Syntactic Analysis for Richly Inflected Languages. TACL, 1:415–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top Accuracy and Fast Dependency Parsing is not a Contradiction. In</title>
<date>2010</date>
<booktitle>Proc. COLING,</booktitle>
<pages>89--97</pages>
<contexts>
<context position="18833" citStr="Bohnet (2010)" startWordPosition="2906" endWordPosition="2907">ils are included in the two following subsections. Two general remarks apply to our experiment. First, we perform cross-lingual parsing, and not cross-annotation-scheme parsing. Thus, we do not compare the dependency parsing scores between the annotation schemes, but rather just between the in-scheme parsers. Second, we use Serbian as a test-set-only language. As there are no treebanks of Serbian, we cannot use it as a source language, and we leave SMT and annotation projection into Serbian for future work. 3.2 Dependency Parsing In all experiments, we use the graph-based dependency parser by Bohnet (2010) with default settings. We base our parser choice on its stateof-the-art performance across various morphologically rich languages in the SPMLR 2013 shared task (Seddah et al., 2013). While newer contributions targeted at joint morphological and syntactic analysis (Bohnet and Kuhn, 2012; Bohnet et al., 2013) report slightly higher scores, we chose the former one for speed and robustness, and because we use gold standard POS/MSD annotations. The choice of gold standard preprocessing is motivated by previous research in parsing Croatian and Serbian (Agi´c et al., 2013), and by insight of Seddah </context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top Accuracy and Fast Dependency Parsing is not a Contradiction. In Proc. COLING, pages 89–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>CoNLL-X Shared Task on Multilingual Dependency Parsing.</title>
<date>2006</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>149--164</pages>
<contexts>
<context position="11359" citStr="Buchholz and Marsi, 2006" startWordPosition="1731" endWordPosition="1734">elease consists of approximately 2,500 sentences (Agi´c and Merkler, 2013), while release 2.0 has just under 4,000 sentences (Agi´c and Ljubeˇsi´c, 2014) of newspaper text. Here, we use an even newer, recently developed version with more than 8,500 sentences from multiple domains.3 sl PDT: The PDT-based Slovene Dependency Treebank (Dˇzeroski et al., 2006) is built on top of a rather small portion of Orwell’s novel 1984 from the Multext East project (Erjavec, 2012). Even if the project was discontinued, it is still heavily used as part of the venerable CoNLL 2006 and 2007 shared task datasets (Buchholz and Marsi, 2006; Nivre et al., 2007).4 sl SSJ: The Slovene take on simplifying syntactic annotations resulted in the 10-tag strong JOS Corpus of Slovene (Erjavec et al., 2010). Similar to hr SET, this new annotation scheme is loosely 2HOBS is available through META-SHARE (Tadi´c and V´aradi, 2012). 3http://nlp.ffzg.hr/resources/corpora/ setimes-hr/ 4http://nl.ijs.si/sdt/ 15 PDT-based, but considerably reduced to facilitate manual annotation. The initial 100,000 token corpus has recently doubled in size, as described by Dobrovoljc et al. (2012). We use the latter version in our experiment.5 The statistics in </context>
<context position="15740" citStr="Buchholz and Marsi, 2006" startWordPosition="2418" endWordPosition="2421"> results in cross-lingual parsing. They did so by creating the uniformly annotated Universal Dependency Treebanks collection based on Stanford Typed Dependencies (De Marneffe and Manning, 2008), which in turn also enabled measuring both labeled (LAS) and unlabeled (UAS) parsing accuracy. Having four treebanks with three different annotation schemes, we seek to enable reliable experimentation through our test sets. Along with Croatian and Slovene, which are represented in the training sets, we introduce Serbian as a target-only language in the test data. Following the CoNLL shared tasks setup (Buchholz and Marsi, 2006; Nivre et al., 2007), our test sets have 200 sentences (approx. 5,000 tokens) per language, split 50:50 between newswire and Wikipedia text. Each test set is manually annotated for morphosyntax, following the MTE 4 guidelines for the respective languages, and checked by native speakers for validity. On top of that, all test sets are annotated with all three dependency schemes: PDT, SET and SSJ. This enables observing LAS in a heterogenous experimental environment, as we test each monolingual and cross-lingual parser on an anno7http://nlp.ffzg.hr/data/tagging/ msd-hr.html 16 Language MSD tag A</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. CoNLL-X Shared Task on Multilingual Dependency Parsing. In Proc. CoNLL, pages 149–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford Typed Dependencies Representation.</title>
<date>2008</date>
<booktitle>In Proc. COLING,</booktitle>
<pages>1--8</pages>
<marker>De Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine De Marneffe and Christopher D Manning. 2008. The Stanford Typed Dependencies Representation. In Proc. COLING, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaja Dobrovoljc</author>
<author>Simon Krek</author>
<author>Jan Rupnik</author>
</authors>
<title>Skladenjski raz&amp;quot;clenjevalnik za sloven&amp;quot;s&amp;quot;cino.</title>
<date>2012</date>
<booktitle>In Proc. IS-LTC,</booktitle>
<pages>42--47</pages>
<contexts>
<context position="11893" citStr="Dobrovoljc et al. (2012)" startWordPosition="1807" endWordPosition="1810">s part of the venerable CoNLL 2006 and 2007 shared task datasets (Buchholz and Marsi, 2006; Nivre et al., 2007).4 sl SSJ: The Slovene take on simplifying syntactic annotations resulted in the 10-tag strong JOS Corpus of Slovene (Erjavec et al., 2010). Similar to hr SET, this new annotation scheme is loosely 2HOBS is available through META-SHARE (Tadi´c and V´aradi, 2012). 3http://nlp.ffzg.hr/resources/corpora/ setimes-hr/ 4http://nl.ijs.si/sdt/ 15 PDT-based, but considerably reduced to facilitate manual annotation. The initial 100,000 token corpus has recently doubled in size, as described by Dobrovoljc et al. (2012). We use the latter version in our experiment.5 The statistics in Table 1 show a variety of treebank sizes and annotations. Figure 1 illustrates the structural complexity of the treebanks by providing a histogram of egdes by token distance. While adjacent edges expectedly dominate the distributions, it is interesting to see that almost 30% of all edges in sl SSJ attach to root, resulting in an easily parsable flattened tree structure. Knowing that relations denoting attributes account for more than one third of all non-root dependents in the remainder, one can expect dependency parsing perform</context>
<context position="29570" citStr="Dobrovoljc et al., 2012" startWordPosition="4622" endWordPosition="4626">oth replacements substantially decreases the score – by more than 11 points LAS. We observe virtually the same pattern for the other Croatian treebank, hr SET, where this latter drop is even more significant, at 14 points. Incidentally, 76.36 points LAS is also the new state of the art for hr SET parsing, owing to the recent enlargement of the treebank. The Slovene parsers exhibit effectively the same behavior as the Croatian ones. The lexicalized MSD models of sl PDT and sl SSJ both record new state-of-the-art scores, although the latter one on a different test set than in previous research (Dobrovoljc et al., 2012). At over 92 points LAS, sl SSJ 19 lexicalized delexicalized hr sl sr hr sl sr MSD POS MSD POS MSD POS MSD POS MSD POS MSD POS hr PDT 69.45 66.95 60.09 50.19 69.42 66.96 66.03 57.79 57.98 42.66 66.79 57.41 SET 76.36 73.02 68.65 59.52 76.08 73.37 72.52 62.31 68.16 55.17 72.71 62.04 sl PDT 51.19 47.99 76.46 73.33 52.46 49.64 49.58 42.59 71.96 62.99 50.41 44.11 SSJ 78.50 74.18 92.38 88.93 78.94 75.96 75.23 66.23 87.19 77.92 75.25 67.47 Table 3: Monolingual and direct cross-lingual parsing accuracy, expressed by the labeled accuracy metric (LAS). Scores are split for lexicalized and delexicalized,</context>
</contexts>
<marker>Dobrovoljc, Krek, Rupnik, 2012</marker>
<rawString>Kaja Dobrovoljc, Simon Krek, and Jan Rupnik. 2012. Skladenjski raz&amp;quot;clenjevalnik za sloven&amp;quot;s&amp;quot;cino. In Proc. IS-LTC, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Syntactic Transfer Using a Bilingual Lexicon. In</title>
<date>2012</date>
<booktitle>Proc. EMNLP-CoNLL,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="5757" citStr="Durrett et al. (2012)" startWordPosition="863" endWordPosition="866">proaches need no projection and enable the usage of source-side gold standard annotations, but they all rely on a shared feature representation across languages, which can be seen as a strong bottleneck. Also, while most of the earlier research made use of heterogenous treebanks and thus yielded linguistically implausible observations, research stemming from an uniform dependency scheme across languages (De Marneffe and Manning, 2008; McDonald et al., 2013) made it possible to perform more consistent experiments and to assess the accuracy of dependency labels. Other approaches: More recently, Durrett et al. (2012) suggested a hybrid approach that involves bilingual lexica in cross-lingual phrasebased parsing. In their approach, a source-side treebank is adapted to a target language by ”translating” the source words to target words through a bilingual lexicon. This approach is advanced by Tiedemann et al. (2014), who utilize fullscale statistical machine translation (SMT) systems for generating synthetic target language treebanks. This approach relates to annotation projection, while bypassing the issue of dependency parsing noise as gold standard annotations are projected. The SMT noise is in turn miti</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntactic Transfer Using a Bilingual Lexicon. In Proc. EMNLP-CoNLL, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saso Dzeroski</author>
</authors>
<title>Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pajas, Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele.</title>
<date>2006</date>
<booktitle>Proc. LREC,</booktitle>
<pages>1388--1391</pages>
<marker>Dzeroski, 2006</marker>
<rawString>Sa&amp;quot;so Dz&amp;quot;eroski, Toma&amp;quot;z Erjavec, Nina Ledinek, Petr Pajas, Zdenek &amp;quot;Zabokrtsky, and Andreja &amp;quot;Zele. 2006. Towards a Slovene Dependency Treebank. In Proc. LREC, pages 1388–1391.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaz Erjavec</author>
<author>Darja Fiser</author>
<author>Simon Krek</author>
<author>Nina Ledinek</author>
</authors>
<title>The JOS Linguistically Tagged Corpus of Slovene. In</title>
<date>2010</date>
<booktitle>Proc. LREC,</booktitle>
<pages>1806--1809</pages>
<contexts>
<context position="11519" citStr="Erjavec et al., 2010" startWordPosition="1758" endWordPosition="1761">per text. Here, we use an even newer, recently developed version with more than 8,500 sentences from multiple domains.3 sl PDT: The PDT-based Slovene Dependency Treebank (Dˇzeroski et al., 2006) is built on top of a rather small portion of Orwell’s novel 1984 from the Multext East project (Erjavec, 2012). Even if the project was discontinued, it is still heavily used as part of the venerable CoNLL 2006 and 2007 shared task datasets (Buchholz and Marsi, 2006; Nivre et al., 2007).4 sl SSJ: The Slovene take on simplifying syntactic annotations resulted in the 10-tag strong JOS Corpus of Slovene (Erjavec et al., 2010). Similar to hr SET, this new annotation scheme is loosely 2HOBS is available through META-SHARE (Tadi´c and V´aradi, 2012). 3http://nlp.ffzg.hr/resources/corpora/ setimes-hr/ 4http://nl.ijs.si/sdt/ 15 PDT-based, but considerably reduced to facilitate manual annotation. The initial 100,000 token corpus has recently doubled in size, as described by Dobrovoljc et al. (2012). We use the latter version in our experiment.5 The statistics in Table 1 show a variety of treebank sizes and annotations. Figure 1 illustrates the structural complexity of the treebanks by providing a histogram of egdes by t</context>
</contexts>
<marker>Erjavec, Fiser, Krek, Ledinek, 2010</marker>
<rawString>Toma&amp;quot;z Erjavec, Darja Fi&amp;quot;ser, Simon Krek, and Nina Ledinek. 2010. The JOS Linguistically Tagged Corpus of Slovene. In Proc. LREC, pages 1806–1809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomaz Erjavec</author>
</authors>
<title>MULTEXT-East: Morphosyntactic Resources for Central and Eastern European Languages. Language Resources and Evaluation,</title>
<date>2012</date>
<pages>46--1</pages>
<contexts>
<context position="9289" citStr="Erjavec, 2012" startWordPosition="1403" endWordPosition="1404">arts of speech 13 13 12 13 MSDs 821 685 725 1,142 Syntactic tags 26 15 26 10 Table 1: Basic treebank statistics. Figure 1: Histogram of edge distances in the treebanks. Edge distance is measured in tokens between heads and dependents. Distance of 1 denotes adjacent tokens. Figure 2: Histogram of average tree depths. 2 Resources We make use of the publicly available language resources for Croatian, Serbian and Slovene. These include dependency treebanks, test sets annotated for morphology and dependency syntax, and a morphosyntactic feature representation drawing from the Multext East project (Erjavec, 2012). A detailed assessment of the current state of development for morphosyntactic and syntactic processing of these languages is given by Agi´c et al. (2013) and Uszkoreit and Rehm (2012). Here, we provide only a short description. 2.1 Treebanks We use two Croatian and two Slovene dependency treebanks.1 One for each language is based on the Prague Dependency Treebank (PDT) (B¨ohmov´a et al., 2003) annotation scheme, while the other two introduced novel and more simplified syntactic tagsets. All four treebanks use adaptations of 1No treebanks of Serbian were publicly available at the time of cond</context>
<context position="11203" citStr="Erjavec, 2012" startWordPosition="1706" endWordPosition="1707">ds high parsing accuracy, while maintaining a clear distinction between all basic grammatical categories of Croatian. Its publicly available 1.0 release consists of approximately 2,500 sentences (Agi´c and Merkler, 2013), while release 2.0 has just under 4,000 sentences (Agi´c and Ljubeˇsi´c, 2014) of newspaper text. Here, we use an even newer, recently developed version with more than 8,500 sentences from multiple domains.3 sl PDT: The PDT-based Slovene Dependency Treebank (Dˇzeroski et al., 2006) is built on top of a rather small portion of Orwell’s novel 1984 from the Multext East project (Erjavec, 2012). Even if the project was discontinued, it is still heavily used as part of the venerable CoNLL 2006 and 2007 shared task datasets (Buchholz and Marsi, 2006; Nivre et al., 2007).4 sl SSJ: The Slovene take on simplifying syntactic annotations resulted in the 10-tag strong JOS Corpus of Slovene (Erjavec et al., 2010). Similar to hr SET, this new annotation scheme is loosely 2HOBS is available through META-SHARE (Tadi´c and V´aradi, 2012). 3http://nlp.ffzg.hr/resources/corpora/ setimes-hr/ 4http://nl.ijs.si/sdt/ 15 PDT-based, but considerably reduced to facilitate manual annotation. The initial 1</context>
<context position="13861" citStr="Erjavec, 2012" startWordPosition="2127" endWordPosition="2128">led and more linguistically motivated comparisons of the three annotation guidelines fall outside the scope of our paper. Instead, we refer to the previously noted publications on the respective treebanks, and to (Agi´c and Merkler, 2013; Agi´c et al., 2013) for comparisons between PDT and SET in parsing Croatian and Serbian. 2.2 Morphosyntactic Tagset All four treebanks were manually created: they are sentence- and token-split, lemmatized, morphosyntactically tagged and syntactically annotated. In morphosyntactic annotation, they all make use of the Multext East version 4 (MTE 4) guidelines (Erjavec, 2012).6 MTE 4 is a positional tagset in which morphosyntactic descriptors of word forms are captured by a morphosyn5http://eng.slovenscina.eu/ tehnologije/ucni-korpus 6http://nl.ijs.si/ME/V4/ tactic tag (MSD) created by merging atomic attributes in the predefined positions. This is illustrated in Table 2 through an example verb tag. The first character of the tag denotes the part of speech (POS), while each of the following characters encodes a specific attribute in a specific position. Both the positions and the attributes are languagedependent in MTE 4, but the attributes are still largely shared</context>
</contexts>
<marker>Erjavec, 2012</marker>
<rawString>Toma&amp;quot;z Erjavec. 2012. MULTEXT-East: Morphosyntactic Resources for Central and Eastern European Languages. Language Resources and Evaluation, 46(1):131–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and Smaller Language Model Queries. In</title>
<date>2011</date>
<booktitle>Proc. WSMT,</booktitle>
<pages>187--197</pages>
<contexts>
<context position="21422" citStr="Heafield, 2011" startWordPosition="3319" endWordPosition="3320">eebank translation experiments. Namely, our translations are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. We perform word alignment by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 2007) with default settings. Phrasebased SMT models are tuned using minimum error rate training (Och, 2003). Our monolingual language modeling using KenLM tools9 (Heafield, 2011) produces standard 5-gram language models using modified Kneser-Ney smoothing without pruning. For building the translation models, we use the OpenSubtitles parallel resources from OPUS10 (Tiedemann, 2009) for the Croatian-Slovene pair. Even if we expect this to be a rather noisy parallel resource, we justify the choice by (1) the fact that no other parallel corpora11 of Croatian and Slovene exist, other than Orwell’s 1984 from the Multext East project, which is too small for SMT training and falls into a very narrow domain, and (2) evidence from (Tiedemann et al., 2014) that the SMT-supported</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and Smaller Language Model Queries. In Proc. WSMT, pages 187–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping Parsers via Syntactic Projection across Parallel Texts. Natural Language Engineering,</title>
<date>2005</date>
<volume>11</volume>
<issue>3</issue>
<pages>325</pages>
<contexts>
<context position="3251" citStr="Hwa et al., 2005" startWordPosition="477" endWordPosition="480"> (target) language. Annotation projection: In this approach, dependency trees are projected from a source language to a target language using word alignments in parallel corpora. It is based on a presumption that source-target parallel corpora are more readily available than dependency treebanks. The approach comes in two varieties. In the first one, parallel corpora are exploited by applying the available state-of-the-art parsers on the source side and subsequent projection to the target side using word alignments and heuristics for resolving possible link ambiguities (Yarowsky et al., 2001; Hwa et al., 2005). Since dependency parsers typically make heavy use of various morphological and other features, the apparent benefit of this approach is the possibility of straightforward projection of these features, resulting in a featurerich representation for the target language. On the downside, the annotation projection noise adds up to dependency parsing noise and errors in word alignment, influencing the quality of the resulting target language parser. The other variety is rare, since it relies on parallel corpora in which the source side is a depen13 Language Technology for Closely Related Languages</context>
<context position="26961" citStr="Hwa et al. (2005)" startWordPosition="4188" endWordPosition="4191"> on the entire phrase table using the standard approach to phrase-based SMT. We basically run the Moses decoder with default settings and the parameters and models trained on our parallel corpus. Here, we can have many-to-many word alignments, which require a more elaborate approach to the projection of the source side dependency annotations. It is important for the annotation transfer to keep track of the alignment between phrases and words of the input and output sentences. The Moses decoder provides both, phrase segmentation and word alignment. We use the annotation projection algorithm of Hwa et al. (2005). As illustrated in Figure 3, it resolves many-to-many alignments by introducing dummy nodes to the dependency trees. We use the implementation by Tiedemann (2014), which addresses certain issues with algorithm choices for ambiguous alignments which were left unaccounted for in the original work. Since this paper does not focus on the intricacies of annotation projection, but rather on applying it in an environment of related languages and rich MSD tagsets, we refer the reader to related work regarding the details. We translate from Croatian to Slovene and vice versa using four different treeb</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping Parsers via Syntactic Projection across Parallel Texts. Natural Language Engineering, 11(3):311– 325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation. In</title>
<date>2007</date>
<booktitle>Proc. ACL,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="21249" citStr="Koehn et al., 2007" startWordPosition="3291" endWordPosition="3294">rov et al., 2012).8 3.3 Treebank Translation and Annotation Projection For machine translation, we closely adhere to the setup implemented by Tiedemann et al. (2014) in their treebank translation experiments. Namely, our translations are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. We perform word alignment by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 2007) with default settings. Phrasebased SMT models are tuned using minimum error rate training (Och, 2003). Our monolingual language modeling using KenLM tools9 (Heafield, 2011) produces standard 5-gram language models using modified Kneser-Ney smoothing without pruning. For building the translation models, we use the OpenSubtitles parallel resources from OPUS10 (Tiedemann, 2009) for the Croatian-Slovene pair. Even if we expect this to be a rather noisy parallel resource, we justify the choice by (1) the fact that no other parallel corpora11 of Croatian and Slovene exist, other than Orwell’s 1984 </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, et al. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proc. ACL, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing.</title>
<date>2009</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective Dependency Parsing Using Spanning Tree Algorithms.</title>
<date>2005</date>
<booktitle>In Proc. HLTEMNLP,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="20055" citStr="McDonald et al., 2005" startWordPosition="3098" endWordPosition="3102">et al. (2013), who report a predictable linear decrease in accuracy for automatic preprocessing. This decrease amounts to approximately 3 points LAS for Croatian and Serbian across various test cases in (Agi´c et al., 2013). We observe effects of (de)lexicalization and of using full MSD tagset as opposed to only POS tags in all experiments. Namely, in all work packages, we compare parsers trained with {lexicalized, delexicalized} × {MSD, POS} features. In lexicalized parsers, we use word forms and features, while we exclude lemmas from all experiments – both previous research using MSTParser (McDonald et al., 2005) and our own test runs show no use for lemmas as features in dependency parsing. Delexicalized parsers are stripped of all lexical features, i.e., word forms are omitted from training and testing data. Full MSD parsers use both the POS information and the sub-POS features in the form of atomic attribute-value pairs, while POSonly parsers are stripped of the MSD features – they use just the POS information. The delexicalized POS scenario is thus very similar to the 17 direct transfer by McDonald et al. (2013), since MTE 4 POS is virtually identical to Universal POS (Petrov et al., 2012).8 3.3 T</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Haji&amp;quot;c. 2005. Non-projective Dependency Parsing Using Spanning Tree Algorithms. In Proc. HLTEMNLP, pages 523–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Slav Petrov</author>
<author>Keith Hall</author>
</authors>
<title>Multi-Source Transfer of Delexicalized Dependency Parsers.</title>
<date>2011</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>62--72</pages>
<contexts>
<context position="5061" citStr="McDonald et al., 2011" startWordPosition="757" endWordPosition="760"> from the source treebank for training the parser (Zeman and Resnik, 2008; McDonald et al., 2013). This in turn relies on the same underlying feature model, typically drawing from a shared part-of-speech (POS) representation such as the Universal POS Tagset of Petrov et al. (2012). Negative effects of using such an impoverished shared representation are typically addressed by adapting the model to better fit the target language. This includes selecting source language data points appropriate for the target language (Søgaard, 2011; T¨ackstr¨om et al., 2013), transferring from multiple sources (McDonald et al., 2011) and using cross-lingual word clusters (T¨ackstr¨om et al., 2012). These approaches need no projection and enable the usage of source-side gold standard annotations, but they all rely on a shared feature representation across languages, which can be seen as a strong bottleneck. Also, while most of the earlier research made use of heterogenous treebanks and thus yielded linguistically implausible observations, research stemming from an uniform dependency scheme across languages (De Marneffe and Manning, 2008; McDonald et al., 2013) made it possible to perform more consistent experiments and to </context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>Ryan McDonald, Slav Petrov, and Keith Hall. 2011. Multi-Source Transfer of Delexicalized Dependency Parsers. In Proc. EMNLP, pages 62–72.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev,</title>
<location>Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria</location>
<marker>McDonald, </marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bertomeu Castell´o</author>
<author>Jungmee Lee</author>
</authors>
<title>Universal Dependency Annotation for Multilingual Parsing. In</title>
<date>2013</date>
<booktitle>Proc. ACL,</booktitle>
<pages>92--97</pages>
<marker>Castell´o, Lee, 2013</marker>
<rawString>Bertomeu Castell´o, and Jungmee Lee. 2013. Universal Dependency Annotation for Multilingual Parsing. In Proc. ACL, pages 92–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>Shared Task on Dependency Parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 Shared Task on Dependency Parsing. In Proc. CoNLL, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="21047" citStr="Och and Ney, 2003" startWordPosition="3258" endWordPosition="3261"> they use just the POS information. The delexicalized POS scenario is thus very similar to the 17 direct transfer by McDonald et al. (2013), since MTE 4 POS is virtually identical to Universal POS (Petrov et al., 2012).8 3.3 Treebank Translation and Annotation Projection For machine translation, we closely adhere to the setup implemented by Tiedemann et al. (2014) in their treebank translation experiments. Namely, our translations are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. We perform word alignment by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 2007) with default settings. Phrasebased SMT models are tuned using minimum error rate training (Och, 2003). Our monolingual language modeling using KenLM tools9 (Heafield, 2011) produces standard 5-gram language models using modified Kneser-Ney smoothing without pruning. For building the translation models, we use the OpenSubtitles parallel resources from OPUS10 (Tiedemann, 2009) for the Croatian-Sl</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation. In</title>
<date>2003</date>
<booktitle>Proc. ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="21351" citStr="Och, 2003" startWordPosition="3310" endWordPosition="3311">re to the setup implemented by Tiedemann et al. (2014) in their treebank translation experiments. Namely, our translations are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. We perform word alignment by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 2007) with default settings. Phrasebased SMT models are tuned using minimum error rate training (Och, 2003). Our monolingual language modeling using KenLM tools9 (Heafield, 2011) produces standard 5-gram language models using modified Kneser-Ney smoothing without pruning. For building the translation models, we use the OpenSubtitles parallel resources from OPUS10 (Tiedemann, 2009) for the Croatian-Slovene pair. Even if we expect this to be a rather noisy parallel resource, we justify the choice by (1) the fact that no other parallel corpora11 of Croatian and Slovene exist, other than Orwell’s 1984 from the Multext East project, which is too small for SMT training and falls into a very narrow domain</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proc. ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A Universal Part-of-Speech Tagset.</title>
<date>2012</date>
<booktitle>In Proc. LREC,</booktitle>
<pages>2089--2096</pages>
<contexts>
<context position="4720" citStr="Petrov et al. (2012)" startWordPosition="707" endWordPosition="710"> the automatic parsing noise, while the issues with word alignment and annotation heuristics still remain. Model transfer: In its simplest form, transferring a model amounts to training a source language parser and running it directly on the target language. It is usually coupled with delexicalization, i.e., removing all lexical features from the source treebank for training the parser (Zeman and Resnik, 2008; McDonald et al., 2013). This in turn relies on the same underlying feature model, typically drawing from a shared part-of-speech (POS) representation such as the Universal POS Tagset of Petrov et al. (2012). Negative effects of using such an impoverished shared representation are typically addressed by adapting the model to better fit the target language. This includes selecting source language data points appropriate for the target language (Søgaard, 2011; T¨ackstr¨om et al., 2013), transferring from multiple sources (McDonald et al., 2011) and using cross-lingual word clusters (T¨ackstr¨om et al., 2012). These approaches need no projection and enable the usage of source-side gold standard annotations, but they all rely on a shared feature representation across languages, which can be seen as a</context>
<context position="7907" citStr="Petrov et al. (2012)" startWordPosition="1185" endWordPosition="1188">ian and Slovene, and cross-lingually parse into Croatian, Serbian and Slovene. Along with monolingual and direct transfer parsing, we make use of the SMT framework of Tiedemann et al. (2014). We are motivated by: ■ observing the performance of various approaches to cross-lingual dependency parsing for closely related languages, including the very recent treebank translation approach by Tiedemann et al. (2014); ■ doing so by using rich morphosyntactic tagsets, in contrast to virtually all other recent crosslingual dependency parsing experiments, which mainly utilize the Universal POS tagset of Petrov et al. (2012); ■ reliably testing for labeled parsing accuracy in an environment with heterogenous dependency annotation schemes; and ■ improving the state of the art for Croatian, Slovene and Serbian dependency parsing across these heterogenous schemes. In Section 2, we describe the language resources used: treebanks, tagsets and test sets. Section 3 describes the experimental setup, which includes a description of parsing, machine translation and annotation projection. In Section 4, we discuss the results of the experiments, and we conclude the discussion by sketching the possible directions for future r</context>
<context position="20647" citStr="Petrov et al., 2012" startWordPosition="3201" endWordPosition="3204">rser (McDonald et al., 2005) and our own test runs show no use for lemmas as features in dependency parsing. Delexicalized parsers are stripped of all lexical features, i.e., word forms are omitted from training and testing data. Full MSD parsers use both the POS information and the sub-POS features in the form of atomic attribute-value pairs, while POSonly parsers are stripped of the MSD features – they use just the POS information. The delexicalized POS scenario is thus very similar to the 17 direct transfer by McDonald et al. (2013), since MTE 4 POS is virtually identical to Universal POS (Petrov et al., 2012).8 3.3 Treebank Translation and Annotation Projection For machine translation, we closely adhere to the setup implemented by Tiedemann et al. (2014) in their treebank translation experiments. Namely, our translations are based on automatic word alignment and subsequent extraction of translation equivalents as common in phrase-based SMT. We perform word alignment by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 200</context>
<context position="40572" citStr="Petrov et al. (2012)" startWordPosition="6444" endWordPosition="6447"> POS only parsers, and with respect to the translation/projection approaches. Row indices represent source languages and treebanks, and indicate the direction of applying SMT (e.g., hr ( sl denotes a Croatian treebank translated to Slovene). for morphologically rich languages. Through our multilayered test set annotation, we also facilitated a reliable cross-lingual evaluation in a heterogenous testing environment. We list our most important observations: ■ Even for closely related languages, using only the basic POS features – which are virtually identical to the widely-used Universal POS of Petrov et al. (2012) – substantially decreases parsing accuracy up to the level comparable with results of McDonald et al. (2013) across the Universal Treebanks language groups. ■ Adding MSD features heavily influences all the scores in a positive way. This has obvious implications for improving over McDonald et al. (2013) on the Universal Treebanks dataset. ■ Other than that, we show that it is possible to cross-lingually parse Croatian, Serbian and Slovene using all three syntactic annotation schemes, and with high accuracy. A treebank for Serbian does not exist, but we accurately parse Serbian by using PDT, SE</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A Universal Part-of-Speech Tagset. In Proc. LREC, pages 2089–2096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vesna Pozgaj Hadzi</author>
<author>Marko Tadi´c</author>
</authors>
<title>CroatianSlovene Parallel Corpus. In</title>
<date>2000</date>
<booktitle>Proc. IS-LTC.</booktitle>
<marker>Hadzi, Tadi´c, 2000</marker>
<rawString>Vesna Poz&amp;quot;gaj Had&amp;quot;zi and Marko Tadi´c. 2000. CroatianSlovene Parallel Corpus. In Proc. IS-LTC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolf Rosa</author>
<author>Jan Masek</author>
<author>David Marecek</author>
<author>Martin Popel</author>
<author>Daniel Zeman</author>
<author>Zdenek Zabokrtsk´y</author>
</authors>
<title>HamleDT 2.0: Thirty Dependency Treebanks Stanfordized. In</title>
<date>2014</date>
<booktitle>Proc. LREC,</booktitle>
<pages>2334--2341</pages>
<marker>Rosa, Masek, Marecek, Popel, Zeman, Zabokrtsk´y, 2014</marker>
<rawString>Rudolf Rosa, Jan Ma&amp;quot;sek, David Mare&amp;quot;cek, Martin Popel, Daniel Zeman, and Zden&amp;quot;ek &amp;quot;Zabokrtsk´y. 2014. HamleDT 2.0: Thirty Dependency Treebanks Stanfordized. In Proc. LREC, pages 2334–2341.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra K¨ubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie.</title>
<date>2013</date>
<booktitle>Overview of the SPMRL</booktitle>
<pages>146--182</pages>
<marker>Seddah, Tsarfaty, K¨ubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra K¨ubler, Marie Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie. 2013. Overview of the SPMRL 2013 Shared Task: Cross-framework Evaluation of Parsing Morphologically Rich Languages. In Proc. SPMRL, pages 146–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Data Point Selection for Crosslanguage Adaptation of Dependency Parsers.</title>
<date>2011</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>682--686</pages>
<contexts>
<context position="4974" citStr="Søgaard, 2011" startWordPosition="747" endWordPosition="748"> is usually coupled with delexicalization, i.e., removing all lexical features from the source treebank for training the parser (Zeman and Resnik, 2008; McDonald et al., 2013). This in turn relies on the same underlying feature model, typically drawing from a shared part-of-speech (POS) representation such as the Universal POS Tagset of Petrov et al. (2012). Negative effects of using such an impoverished shared representation are typically addressed by adapting the model to better fit the target language. This includes selecting source language data points appropriate for the target language (Søgaard, 2011; T¨ackstr¨om et al., 2013), transferring from multiple sources (McDonald et al., 2011) and using cross-lingual word clusters (T¨ackstr¨om et al., 2012). These approaches need no projection and enable the usage of source-side gold standard annotations, but they all rely on a shared feature representation across languages, which can be seen as a strong bottleneck. Also, while most of the earlier research made use of heterogenous treebanks and thus yielded linguistically implausible observations, research stemming from an uniform dependency scheme across languages (De Marneffe and Manning, 2008;</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Data Point Selection for Crosslanguage Adaptation of Dependency Parsers. In Proc. ACL, pages 682–686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure.</title>
<date>2012</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>477--487</pages>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure. In Proc. NAACL, pages 477–487.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Target Language Adaptation of Discriminative Transfer Parsers.</title>
<date>2013</date>
<booktitle>In Proc. NAACL,</booktitle>
<pages>1061--1071</pages>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre. 2013. Target Language Adaptation of Discriminative Transfer Parsers. In Proc. NAACL, pages 1061– 1071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marko Tadi´c</author>
<author>Sanja Fulgosi</author>
</authors>
<title>Building the Croatian Morphological Lexicon. In</title>
<date>2003</date>
<booktitle>Proc. BSNLP,</booktitle>
<pages>41--46</pages>
<marker>Tadi´c, Fulgosi, 2003</marker>
<rawString>Marko Tadi´c and Sanja Fulgosi. 2003. Building the Croatian Morphological Lexicon. In Proc. BSNLP, pages 41–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marko Tadi´c</author>
<author>Tam´as V´aradi</author>
</authors>
<title>Central and South-East European Resources in META-SHARE.</title>
<date>2012</date>
<booktitle>Proc. COLING,</booktitle>
<pages>431--438</pages>
<marker>Tadi´c, V´aradi, 2012</marker>
<rawString>Marko Tadi´c and Tam´as V´aradi. 2012. Central and South-East European Resources in META-SHARE. Proc. COLING, pages 431–438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marko Tadi´c</author>
</authors>
<title>Building the Croatian Dependency Treebank: The Initial Stages. Suvremena lingvistika,</title>
<date>2007</date>
<pages>63--85</pages>
<marker>Tadi´c, 2007</marker>
<rawString>Marko Tadi´c. 2007. Building the Croatian Dependency Treebank: The Initial Stages. Suvremena lingvistika, 63:85–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
<author>Preslav Nakov</author>
</authors>
<title>Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets.</title>
<date>2013</date>
<booktitle>In Proc. RANLP,</booktitle>
<pages>676--684</pages>
<contexts>
<context position="23763" citStr="Tiedemann and Nakov, 2013" startWordPosition="3680" endWordPosition="3683">Croatian-Slovene pair. However, their approach involved both translating and testing on the same small corpus (Orwell’s novel), while here we extract the translations from full-blown SMT phrase tables on a much larger scale. The trees projection from source to target is trivial since the number and the ordering of words between them does not change. Thus, the dependencies are simply copied. CHAR: By this acronym, we refer to an approach known as character-based statistical machine translation. It is shown to perform very well for closely related languages (Vilar et al., 2007; Tiedemann, 2012; Tiedemann and Nakov, 2013). The motivation for character-level translation is the ability of such models to better generalize the mapping between similar languages especially in cases of rich productive morphology and limited amounts of training data. With this, character-level models largely reduce the number of out-of-vocabulary words. In a nutshell, our character-based model performs word-to-word translation using character-level modeling. Similar to LOOKUP, this is also a word-to-word translation model, which also requires no adaptation of the source dependency trees – they are once again simply copied to target se</context>
</contexts>
<marker>Tiedemann, Nakov, 2013</marker>
<rawString>J¨org Tiedemann and Preslav Nakov. 2013. Analyzing the Use of Character-Level Translation with Sparse and Noisy Datasets. In Proc. RANLP, pages 676– 684.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Zeljko Agi´c, and Joakim Nivre.</title>
<date>2014</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>130--140</pages>
<contexts>
<context position="6523" citStr="Tiedemann (2014)" startWordPosition="982" endWordPosition="983"> to a target language by ”translating” the source words to target words through a bilingual lexicon. This approach is advanced by Tiedemann et al. (2014), who utilize fullscale statistical machine translation (SMT) systems for generating synthetic target language treebanks. This approach relates to annotation projection, while bypassing the issue of dependency parsing noise as gold standard annotations are projected. The SMT noise is in turn mitigated by better word alignment quality for synthetic data. The influence of various projection algorithms in this approach is further investigated by Tiedemann (2014). This line of cross-lingual parsing research substantially improves over previous work. 1.2 Paper Overview All lines of previous cross-lingual parsing research left the topics of related languages and shared rich feature representations largely unaddressed, with the exception of Zeman and Resnik (2008), who deal with phrase-based parsing test-cased on Danish and Swedish treebanks, utilizing a mapping over relatively small POS tagsets. In our contribution, the goal is to observe the properties of cross-lingual parsing in an environment of relatively free-word-order languages, which are related</context>
<context position="26094" citStr="Tiedemann, 2014" startWordPosition="4051" endWordPosition="4052">Vmn Afpmpa Ncmpa Sb Atv Atr Sb Atv Obj Atr Obj Pred Pred Pred Pred Ncfsn Vmip3s Vmn Afpmpa Ncmpa Vlada planira otvoriti informativne urede Vlada naˇcrtuje , da bo odprla DUMMY informacijske pisarne Ncfsn Vmip3s -- dummy dummy dummy Vmn Afpmpa Ncmpa Sb dummy Atr dummy dummy Obj Pred Atv Figure 3: An illustration of the projections. Left side = CHAR, middle = WORD, right side = PHRASE. As illustrated, WORD might introduce reorderings, while PHRASE can enter dummy nodes and edges to the dependency trees. The sentence: The government plans to open information offices. See (Tiedemann et al., 2014; Tiedemann, 2014) for detailed insight into projection algorithms. 2014), where reordering played an important role in adapting the models to the target languages. We test whether it holds for related languages as well. PHRASE: This model implements translation based on the entire phrase table using the standard approach to phrase-based SMT. We basically run the Moses decoder with default settings and the parameters and models trained on our parallel corpus. Here, we can have many-to-many word alignments, which require a more elaborate approach to the projection of the source side dependency annotations. It is</context>
</contexts>
<marker>Tiedemann, 2014</marker>
<rawString>J¨org Tiedemann, &amp;quot;Zeljko Agi´c, and Joakim Nivre. 2014. Treebank Translation for Cross-Lingual Parser Induction. In Proc. CoNLL, pages 130–140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>News from OPUS: A Collection of Multilingual Parallel Corpora with Tools and Interfaces.</title>
<date>2009</date>
<booktitle>In Proc. RANLP,</booktitle>
<volume>5</volume>
<pages>237--248</pages>
<contexts>
<context position="21627" citStr="Tiedemann, 2009" startWordPosition="3346" endWordPosition="3347"> by using GIZA++ (Och and Ney, 2003), while utilizing IBM model 4 for creating the Viterbi word alignments for parallel corpora. For the extraction of translation tables, we use the de facto standard SMT toolbox Moses (Koehn et al., 2007) with default settings. Phrasebased SMT models are tuned using minimum error rate training (Och, 2003). Our monolingual language modeling using KenLM tools9 (Heafield, 2011) produces standard 5-gram language models using modified Kneser-Ney smoothing without pruning. For building the translation models, we use the OpenSubtitles parallel resources from OPUS10 (Tiedemann, 2009) for the Croatian-Slovene pair. Even if we expect this to be a rather noisy parallel resource, we justify the choice by (1) the fact that no other parallel corpora11 of Croatian and Slovene exist, other than Orwell’s 1984 from the Multext East project, which is too small for SMT training and falls into a very narrow domain, and (2) evidence from (Tiedemann et al., 2014) that the SMT-supported cross-lingual parsing approach is very robust to translation noise. For translating Croatian treebanks into Slovene and vice versa, we implement and test four different methods of translation. They are co</context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>J¨org Tiedemann. 2009. News from OPUS: A Collection of Multilingual Parallel Corpora with Tools and Interfaces. In Proc. RANLP, volume 5, pages 237– 248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Character-Based Pivot Translations for Under-Resourced Languages and Domains. In</title>
<date>2012</date>
<booktitle>Proc. EACL,</booktitle>
<pages>141--151</pages>
<contexts>
<context position="23735" citStr="Tiedemann, 2012" startWordPosition="3678" endWordPosition="3679">012) did for the Croatian-Slovene pair. However, their approach involved both translating and testing on the same small corpus (Orwell’s novel), while here we extract the translations from full-blown SMT phrase tables on a much larger scale. The trees projection from source to target is trivial since the number and the ordering of words between them does not change. Thus, the dependencies are simply copied. CHAR: By this acronym, we refer to an approach known as character-based statistical machine translation. It is shown to perform very well for closely related languages (Vilar et al., 2007; Tiedemann, 2012; Tiedemann and Nakov, 2013). The motivation for character-level translation is the ability of such models to better generalize the mapping between similar languages especially in cases of rich productive morphology and limited amounts of training data. With this, character-level models largely reduce the number of out-of-vocabulary words. In a nutshell, our character-based model performs word-to-word translation using character-level modeling. Similar to LOOKUP, this is also a word-to-word translation model, which also requires no adaptation of the source dependency trees – they are once agai</context>
</contexts>
<marker>Tiedemann, 2012</marker>
<rawString>J¨org Tiedemann. 2012. Character-Based Pivot Translations for Under-Resourced Languages and Domains. In Proc. EACL, pages 141–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Rediscovering Annotation Projection for Cross-Lingual Parser Induction. In</title>
<date>2014</date>
<booktitle>Proc. COLING.</booktitle>
<contexts>
<context position="6523" citStr="Tiedemann (2014)" startWordPosition="982" endWordPosition="983"> to a target language by ”translating” the source words to target words through a bilingual lexicon. This approach is advanced by Tiedemann et al. (2014), who utilize fullscale statistical machine translation (SMT) systems for generating synthetic target language treebanks. This approach relates to annotation projection, while bypassing the issue of dependency parsing noise as gold standard annotations are projected. The SMT noise is in turn mitigated by better word alignment quality for synthetic data. The influence of various projection algorithms in this approach is further investigated by Tiedemann (2014). This line of cross-lingual parsing research substantially improves over previous work. 1.2 Paper Overview All lines of previous cross-lingual parsing research left the topics of related languages and shared rich feature representations largely unaddressed, with the exception of Zeman and Resnik (2008), who deal with phrase-based parsing test-cased on Danish and Swedish treebanks, utilizing a mapping over relatively small POS tagsets. In our contribution, the goal is to observe the properties of cross-lingual parsing in an environment of relatively free-word-order languages, which are related</context>
<context position="26094" citStr="Tiedemann, 2014" startWordPosition="4051" endWordPosition="4052">Vmn Afpmpa Ncmpa Sb Atv Atr Sb Atv Obj Atr Obj Pred Pred Pred Pred Ncfsn Vmip3s Vmn Afpmpa Ncmpa Vlada planira otvoriti informativne urede Vlada naˇcrtuje , da bo odprla DUMMY informacijske pisarne Ncfsn Vmip3s -- dummy dummy dummy Vmn Afpmpa Ncmpa Sb dummy Atr dummy dummy Obj Pred Atv Figure 3: An illustration of the projections. Left side = CHAR, middle = WORD, right side = PHRASE. As illustrated, WORD might introduce reorderings, while PHRASE can enter dummy nodes and edges to the dependency trees. The sentence: The government plans to open information offices. See (Tiedemann et al., 2014; Tiedemann, 2014) for detailed insight into projection algorithms. 2014), where reordering played an important role in adapting the models to the target languages. We test whether it holds for related languages as well. PHRASE: This model implements translation based on the entire phrase table using the standard approach to phrase-based SMT. We basically run the Moses decoder with default settings and the parameters and models trained on our parallel corpus. Here, we can have many-to-many word alignments, which require a more elaborate approach to the projection of the source side dependency annotations. It is</context>
</contexts>
<marker>Tiedemann, 2014</marker>
<rawString>J¨org Tiedemann. 2014. Rediscovering Annotation Projection for Cross-Lingual Parser Induction. In Proc. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 Shared Task: Chunking.</title>
<date>2000</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>127--132</pages>
<contexts>
<context position="12568" citStr="Sang and Buchholz, 2000" startWordPosition="1917" endWordPosition="1920"> statistics in Table 1 show a variety of treebank sizes and annotations. Figure 1 illustrates the structural complexity of the treebanks by providing a histogram of egdes by token distance. While adjacent edges expectedly dominate the distributions, it is interesting to see that almost 30% of all edges in sl SSJ attach to root, resulting in an easily parsable flattened tree structure. Knowing that relations denoting attributes account for more than one third of all non-root dependents in the remainder, one can expect dependency parsing performance comparable to CoNLL-style chunking (Tjong Kim Sang and Buchholz, 2000). This is further supported by the distributions of sentences in the four treebanks by average tree depth in Figure 2. We can see that virtually all sl SSJ trees have average depths of 1 to 3, while the other treebanks exhibit the more common structural properties of dependency trees. In these terms of complexity, the Croatian treebanks are richer than their Slovene counterparts. In sl SSJ, attributes and edges to root account for more than 60% of all dependencies. Even in the other three treebanks, 20-30% of the edges are labeled as attributes, while the rest is spread more evenly between the</context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 Shared Task: Chunking. In Proc. CoNLL, pages 127–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Uszkoreit</author>
<author>Georg Rehm</author>
</authors>
<title>Language White Paper Series.</title>
<date>2012</date>
<publisher>Springer.</publisher>
<contexts>
<context position="1332" citStr="Uszkoreit and Rehm, 2012" startWordPosition="177" endWordPosition="180">annotation projection. We argue for the benefits of using rich morphosyntactic tagsets in cross-lingual parsing and empirically support the claim by showing large improvements over an impoverished common feature representation in form of a reduced part-of-speech tagset. In the process, we improve over the previous state-of-the-art scores in dependency parsing for all three languages. 1 Introduction A large majority of human languages are underresourced in terms of text corpora and tools available for applications in natural language processing (NLP). According to recent surveys (Bender, 2011; Uszkoreit and Rehm, 2012; Bender, 2013), this is especially apparent with syntactically annotated corpora, i.e., treebanks – both dependencybased ones and others. In this paper, we focus on dependency parsing (K¨ubler et al., 2009), but the claims should hold in general. The lack of dependency treebanks is due to the fact that they are expensive and time-consuming to construct (Abeill´e, 2003). Since dependency parsing of under-resourced languages nonetheless draws substantial interest in the NLP research community, over time, we have seen a number of research efforts directed towards their processing despite the abs</context>
<context position="9474" citStr="Uszkoreit and Rehm (2012)" startWordPosition="1432" endWordPosition="1435">distance is measured in tokens between heads and dependents. Distance of 1 denotes adjacent tokens. Figure 2: Histogram of average tree depths. 2 Resources We make use of the publicly available language resources for Croatian, Serbian and Slovene. These include dependency treebanks, test sets annotated for morphology and dependency syntax, and a morphosyntactic feature representation drawing from the Multext East project (Erjavec, 2012). A detailed assessment of the current state of development for morphosyntactic and syntactic processing of these languages is given by Agi´c et al. (2013) and Uszkoreit and Rehm (2012). Here, we provide only a short description. 2.1 Treebanks We use two Croatian and two Slovene dependency treebanks.1 One for each language is based on the Prague Dependency Treebank (PDT) (B¨ohmov´a et al., 2003) annotation scheme, while the other two introduced novel and more simplified syntactic tagsets. All four treebanks use adaptations of 1No treebanks of Serbian were publicly available at the time of conducting this experiment. the Multext East version 4 tagset (Erjavec, 2012) for the underlying morphological annotation layer, which we shortly describe further down. Basic statistics for</context>
</contexts>
<marker>Uszkoreit, Rehm, 2012</marker>
<rawString>Hans Uszkoreit and Georg Rehm. 2012. Language White Paper Series. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vilar</author>
<author>Jan-Thorsten Peter</author>
<author>Hermann Ney</author>
</authors>
<title>Can We Translate Letters? In</title>
<date>2007</date>
<booktitle>Proc. WMT,</booktitle>
<pages>33--39</pages>
<contexts>
<context position="23718" citStr="Vilar et al., 2007" startWordPosition="3674" endWordPosition="3677">what Agi´c et al. (2012) did for the Croatian-Slovene pair. However, their approach involved both translating and testing on the same small corpus (Orwell’s novel), while here we extract the translations from full-blown SMT phrase tables on a much larger scale. The trees projection from source to target is trivial since the number and the ordering of words between them does not change. Thus, the dependencies are simply copied. CHAR: By this acronym, we refer to an approach known as character-based statistical machine translation. It is shown to perform very well for closely related languages (Vilar et al., 2007; Tiedemann, 2012; Tiedemann and Nakov, 2013). The motivation for character-level translation is the ability of such models to better generalize the mapping between similar languages especially in cases of rich productive morphology and limited amounts of training data. With this, character-level models largely reduce the number of out-of-vocabulary words. In a nutshell, our character-based model performs word-to-word translation using character-level modeling. Similar to LOOKUP, this is also a word-to-word translation model, which also requires no adaptation of the source dependency trees – t</context>
</contexts>
<marker>Vilar, Peter, Ney, 2007</marker>
<rawString>David Vilar, Jan-Thorsten Peter, and Hermann Ney. 2007. Can We Translate Letters? In Proc. WMT, pages 33–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora. In</title>
<date>2001</date>
<booktitle>Proc. HLT,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="3232" citStr="Yarowsky et al., 2001" startWordPosition="473" endWordPosition="476">ing the under-resourced (target) language. Annotation projection: In this approach, dependency trees are projected from a source language to a target language using word alignments in parallel corpora. It is based on a presumption that source-target parallel corpora are more readily available than dependency treebanks. The approach comes in two varieties. In the first one, parallel corpora are exploited by applying the available state-of-the-art parsers on the source side and subsequent projection to the target side using word alignments and heuristics for resolving possible link ambiguities (Yarowsky et al., 2001; Hwa et al., 2005). Since dependency parsers typically make heavy use of various morphological and other features, the apparent benefit of this approach is the possibility of straightforward projection of these features, resulting in a featurerich representation for the target language. On the downside, the annotation projection noise adds up to dependency parsing noise and errors in word alignment, influencing the quality of the resulting target language parser. The other variety is rare, since it relies on parallel corpora in which the source side is a depen13 Language Technology for Closel</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing Multilingual Text Analysis Tools via Robust Projection Across Aligned Corpora. In Proc. HLT, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>Philip Resnik</author>
</authors>
<title>CrossLanguage Parser Adaptation between Related Languages. In</title>
<date>2008</date>
<booktitle>Proc. IJCNLP,</booktitle>
<pages>35--42</pages>
<contexts>
<context position="4512" citStr="Zeman and Resnik, 2008" startWordPosition="673" endWordPosition="676">pages 13–24, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics dency treebank, i.e., it is already manually annotated for syntactic dependencies (Agi´c et al., 2012). This removes the automatic parsing noise, while the issues with word alignment and annotation heuristics still remain. Model transfer: In its simplest form, transferring a model amounts to training a source language parser and running it directly on the target language. It is usually coupled with delexicalization, i.e., removing all lexical features from the source treebank for training the parser (Zeman and Resnik, 2008; McDonald et al., 2013). This in turn relies on the same underlying feature model, typically drawing from a shared part-of-speech (POS) representation such as the Universal POS Tagset of Petrov et al. (2012). Negative effects of using such an impoverished shared representation are typically addressed by adapting the model to better fit the target language. This includes selecting source language data points appropriate for the target language (Søgaard, 2011; T¨ackstr¨om et al., 2013), transferring from multiple sources (McDonald et al., 2011) and using cross-lingual word clusters (T¨ackstr¨om</context>
<context position="6827" citStr="Zeman and Resnik (2008)" startWordPosition="1022" endWordPosition="1025">to annotation projection, while bypassing the issue of dependency parsing noise as gold standard annotations are projected. The SMT noise is in turn mitigated by better word alignment quality for synthetic data. The influence of various projection algorithms in this approach is further investigated by Tiedemann (2014). This line of cross-lingual parsing research substantially improves over previous work. 1.2 Paper Overview All lines of previous cross-lingual parsing research left the topics of related languages and shared rich feature representations largely unaddressed, with the exception of Zeman and Resnik (2008), who deal with phrase-based parsing test-cased on Danish and Swedish treebanks, utilizing a mapping over relatively small POS tagsets. In our contribution, the goal is to observe the properties of cross-lingual parsing in an environment of relatively free-word-order languages, which are related and characterized by rich morphology and very large morphosyntactic tagsets. We experiment with four different small- and medium-size dependency treebanks of Croatian and Slovene, and cross-lingually parse into Croatian, Serbian and Slovene. Along with monolingual and direct transfer parsing, we make u</context>
</contexts>
<marker>Zeman, Resnik, 2008</marker>
<rawString>Daniel Zeman and Philip Resnik. 2008. CrossLanguage Parser Adaptation between Related Languages. In Proc. IJCNLP, pages 35–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Zeman</author>
<author>David Marecek</author>
<author>Martin Popel</author>
<author>Loganathan Ramasamy</author>
<author>Jan Step´anek</author>
<author>Zdenek Zabokrtsk`y</author>
<author>Jan Hajic</author>
</authors>
<title>HamleDT: To Parse or Not to Parse? In</title>
<date>2012</date>
<booktitle>Proc. LREC,</booktitle>
<pages>2735--2741</pages>
<marker>Zeman, Marecek, Popel, Ramasamy, Step´anek, Zabokrtsk`y, Hajic, 2012</marker>
<rawString>Daniel Zeman, David Marecek, Martin Popel, Loganathan Ramasamy, Jan Step´anek, Zdenek Zabokrtsk`y, and Jan Hajic. 2012. HamleDT: To Parse or Not to Parse? In Proc. LREC, pages 2735– 2741.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>