<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000098">
<title confidence="0.784540333333333">
ArCADE: An Arabic Corpus of Auditory Dictation Errors
C. Anton Rytting
Paul Rodrigues
</title>
<author confidence="0.852932666666667">
Tim Buckwalter
Valerie Novak
Aric Bills
</author>
<affiliation confidence="0.996783">
University of Maryland
</affiliation>
<address confidence="0.9471275">
7005 52nd Avenue
College Park, MD 20742
</address>
<email confidence="0.8469375">
{crytting,prr,tbuckwal,
vnovak,abills}@umd.edu
</email>
<author confidence="0.733744">
Noah H. Silbert
</author>
<affiliation confidence="0.703231">
Communication
Sciences &amp; Disorders
University of Cincinnati
</affiliation>
<address confidence="0.370859">
2600 Clifton Avenue
Cincinnati, Ohio
silbernh
</address>
<email confidence="0.992255">
@ucmail.uc.edu
</email>
<author confidence="0.814574">
Mohini Madgavkar
</author>
<affiliation confidence="0.760499">
Independent Researcher
</affiliation>
<address confidence="0.6135805">
6120 Dhaka Pl. 20189-6120
Dhaka, Bangladesh
</address>
<email confidence="0.6896305">
mohini.madgavkar
@gmail.com
</email>
<sectionHeader confidence="0.995337" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999810875">
We present a new corpus of word-level lis-
tening errors collected from 62 native En-
glish speakers learning Arabic designed to
inform models of spell checking for this
learner population. While we use the cor-
pus to assist in automated detection and
correction of auditory errors in electronic
dictionary lookup, the corpus can also be
used as a phonological error layer, to be
combined with a composition error layer
in a more complex spell-checking system
for non-native speakers. The corpus may
be useful to instructors of Arabic as a sec-
ond language, and researchers who study
second language phonology and listening
perception.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999927185185185">
Learner corpora have received attention as an im-
portant resource both for guiding teachers in cur-
riculum development (Nesselhauf, 2004) and for
providing training and evaluation material the de-
velopment of tools for computer-assisted language
learning (CALL). One of the most commonly used
technologies in CALL is spell correction. Spell
correction is used for providing automated feed-
back to language learners (cf. Warschauer and
Ware, 2006), automatic assessment (Bestgen and
Granger, 2011), and in providing cleaner input
to downstream natural language processing (NLP)
tools, thereby improving their performance (e.g.
Nagata et al., 2011). However, off-the-shelf spell
correctors developed for native speakers of the tar-
get language are of only limited use for repairing
language learners’ spelling errors, since their error
patterns are different (e.g. Hovermale, 2011; Mit-
ton and Okada, 2007; Okada, 2005).
Most learner corpora (and spell correctors) are
understandably focused on learner-written texts.
Thus, they allow a greater understanding (and im-
provement) of learners’ writing skills. However,
another important aspect of language learning is
listening comprehension (cf. Field, 2008; Prince,
2012). A better understanding of listening errors
can guide teachers and curriculum development
just as written production errors do. Listening er-
ror data may also be helpful for improving tech-
nologies for listening training tools, by helping
prioritize the most critical pairs of phonemes for
discrimination, and pointing out the most trouble-
some contexts for phoneme discrimination.
Finally, spell correction specifically designed
to correct listening errors may aid listening com-
prehension and vocabulary acquisition. If learn-
ers are unable to hear, recall and record accu-
rately what they heard, they will be less able to
search dictionaries or the Web for more informa-
tion on new vocabulary items they otherwise could
have learned from listening exercises. While data-
driven spelling correction on popular search en-
gines may catch some non-native errors, native er-
rors are likely to ‘drown out’ any non-native errors
they conflict with due to larger numbers of native
users of these search engines. On the other hand, if
the most common listening and transcription errors
are automatically corrected within a search tool,
learners will have greater success in finding the
new vocabulary items they may have misheard in
speech.
Learner corpora focused on written production
may not have enough samples of phonologically-
based errors to aid in developing such tools, and
</bodyText>
<page confidence="0.987946">
109
</page>
<bodyText confidence="0.83936525">
Proceedings of the Ninth Workshop on Innovative Use of NLP for Building Educational Applications, pages 109–115,
Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics
even in a large corpus, word avoidance strategies
and other biases would make the source unreli-
able for estimating relative magnitudes of listening
problems accurately. It may be more effective to
target listening errors directly, through other tasks
such as listening dictation.
</bodyText>
<sectionHeader confidence="0.999346" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999961263157895">
Tools for language learning and maintenance, and
learner corpora from which to build them, typically
focus on language pairs for which there is a large
market. Learner corpora for native English learn-
ers of low resource languages such as Arabic have
been until recently comparatively rare, and often
too small to be of practical use for the develop-
ment of educational technology. In the past few
years, however, a number of learner corpora for
Arabic have become available, including a corpus
of 19 non-native (mostly Malaysian) students at Al
Al-Bayt University (Abu al-Rub, 2007); the Ara-
bic Interlanguage Database (ARIDA; Abuhakema
et al., 2008, 2009); the Arabic Learners Writ-
ten Corpus from the University of Arizona Center
for Educational Resources in Culture, Language,
and Literacy (CERCLL; Farwaneh and Tamimi,
2012);1 and the Arabic Learner Corpus v1 (Alfaifi
and Atwell, 2013).2
These corpora are all derived from learner writ-
ing samples, such as essays, and as such they con-
tain many different types of errors, including errors
in morphology, syntax, and word choice. Spelling
errors are also observed, but relatively rarely, and
the relevance of these spelling errors to listening
competence is unclear. Hence, while they are
likely to be useful for many applications in teach-
ing Arabic writing, their usefulness for other pur-
poses, such as examining listening skills and the
effects of learner phonology on spelling, is limited.
Corpora or datasets focused on speaking and lis-
tening skills in Arabic are rarer. One such corpus,
the West Point Arabic Speech Corpus, available
from the LDC, contains one hour of non-native
(learner) speech (LaRocca and Chouairi, 2002)
Sethy et al. (2005) describe a corpus of elicited
Arabic speech, but because none of the partici-
pants had prior exposure to Arabic, its use for un-
</bodyText>
<footnote confidence="0.993145">
1Available from http://l2arabiccorpus.cercll.
arizona.edu/?q=homepage.
2As of February 2014, a second version, with about 130K
words from non-native speakers, is available from http:
//www.arabiclearnercorpus.com/. It also has a small
(three hour) speech component.
</footnote>
<bodyText confidence="0.999233428571428">
derstanding learner Arabic is limited. While there
have been a few studies of Arabic listening skills
(e.g. Huthaily, 2008; Faircloth, 2013), their cov-
erage was not sufficiently broad to make reuse of
their data likely to inform such purposes as the de-
velopment of phoneme discrimination training or
other CALL technology.
</bodyText>
<sectionHeader confidence="0.991523" genericHeader="method">
3 Motivation
</sectionHeader>
<bodyText confidence="0.999912391304348">
We present here the Arabic Corpus of Auditory
Dictation Errors (ArCADE) version 1, a corpus
of Arabic words as transcribed by 62 native En-
glish speakers learning Arabic. This corpus fills
the current gap in non-native spelling error cor-
pora, and particularly for spelling errors due to lis-
tening difficulties. Unlike error corpora collected
from non-native Arabic writing samples, it is de-
signed to elicit spelling errors arising from percep-
tual errors; it provides more naturalistic data than
is typical in phoneme identification or confusion
studies.
A principal purpose for creating the corpus was
to aid in the development and evaluation of tools
for detecting and correcting listening errors to aid
in dictionary lookup of words learners encountered
in spoken language (cf. Rytting et al., 2010). As
such, it serves as a complementary dataset for the
dictionary search engine’s query logs, since in this
case the intended target of each transcription is
known (rather than having to be inferred, in the
case of query logs). We list three other potential
uses for this corpus in Section 5.
</bodyText>
<sectionHeader confidence="0.867338" genericHeader="method">
4 Corpus Design and Creation
</sectionHeader>
<bodyText confidence="0.999979090909091">
The ArCADE corpus was created through an
elicitation experiment, similar in structure to an
American-style spelling test. The principal differ-
ence (other than the language) is that in this case,
the participants are expected to be unfamiliar with
the words, and thus forced to rely on what they hear
in the moment, rather than their lexical knowledge.
We selected words from a commonly-used dictio-
nary of Modern Standard Arabic such that the set
of words would contain a complete set of non-glide
consonants in various phonetic contexts.
</bodyText>
<subsectionHeader confidence="0.999945">
4.1 Selection of Stimulus Words
</subsectionHeader>
<bodyText confidence="0.99998175">
Since the corpus was originally collected for a
study focused on the perception of consonants
within the context of real Arabic words, the stim-
ulus set was designed with three purposes in
</bodyText>
<page confidence="0.986602">
110
</page>
<bodyText confidence="0.985156693877551">
mind: coverage of target sounds, exclusion of ba-
sic words, and brevity (so that participants could
complete the task in one sitting).
In order to differentiate consonants that are rela-
tively unpredictable (and thus test listening ability)
from consonants whose value could be predicted
from non-acoustic cues (such as prior knowledge
of morphological structure), the corpus is anno-
tated for target consonants vs. non-target conso-
nants. A target consonant is defined as a consonant
that should not be predictable (assuming the word
is unknown to the listener) except by the acoustic
cues alone. Glides /w/ and /j/ were not targeted
in the study because orthographic ambiguities be-
tween glides and vowels would complicate the er-
ror analysis.
Each Arabic consonant other than the glides oc-
curs as a target consonant in the stimulus set in six
consonant/vowel/word-boundary contexts: C_V,
V_C, V_V, #_V, V_#, and C_#.3 (The contexts
#_C and C_C are phonotactically illegal in Mod-
ern Standard Arabic.)
Consonants that were judged morphologically
predictable within a word were considered non-
target consonants. These included: (1) non-root
consonants, when Semitic roots were known to the
researchers; (2) consonants participating in a redu-
plicative pattern such as /tamtam/ and /zalzala/;
and (3) Consonants found in doubled (R2=R3)
roots if the two consonants surfaced separately
(e.g., in broken plurals such as /ʔasnan/).
We excluded words from our stimulus set if
we anticipated that an intermediate Arabic student
would already be familiar with them or would eas-
ily be able to guess their spellings. Items found
in vocabulary lists associated with two commonly-
used introductory textbooks (Al-Kitaab and Alif-
Baa) were excluded (Brustad et al., 2004a,b).
Loanwords from Western languages were also ex-
cluded, as were well-known place names (e.g.,
/ʔiskotlanda/ = “Scotland”). Words found only in
colloquial dialects and terms that might be offen-
sive or otherwise distracting (as judged by native
speaker of Arabic) were removed, as well.
In order to keep the stimulus set as short as pos-
sible while maintaining coverage of the full set of
target stimuli consonants in each targeted context,
we chose words with multiple target consonants
whenever possible. The final set of 261 words con-
</bodyText>
<equation confidence="0.9435555">
3C = consonant, V = vowel, # = word boundary, and ‘_’
(underscore) = location of target consonant.
</equation>
<bodyText confidence="0.999920666666667">
tained 649 instances of target consonants: one in-
stance of each geminate consonant and between 17
and 50 instances of each singleton consonant (at
least two instances for each of the six contexts),
with a few exceptions.4 Although glides and vow-
els were not specifically targeted, 6 instances of
/w/, 10 instances of /j/, and at least 12 instances of
each of the monophthong vowels (/a/, /i/, /u/, /a:/,
/i:/, /u:/) occur in the stimulus set.
</bodyText>
<subsectionHeader confidence="0.999809">
4.2 Recording of the Stimuli
</subsectionHeader>
<bodyText confidence="0.999675">
The audio data used in the dictation was recorded
in a sound-proof booth with a unidirectional micro-
phone (Earthworks SR30/HC) equipped with a pop
filter, and saved as WAV files (stereo, 44.1kHz,
32-bit) with Adobe Audition. The stimuli were
spoken at a medium-fast rate. The audio files were
segmented and normalized with respect to peak
amplitude with Matlab.
The native Arabic speaker in the audio recording
is of Egyptian and Levantine background, but was
instructed to speak with a neutral (“BBC Arabic”)
accent.
</bodyText>
<subsectionHeader confidence="0.949726">
4.3 Participants and Methodology
</subsectionHeader>
<bodyText confidence="0.999944136363636">
Seventy-five participants were recruited from six
universities. To be eligible, participants had to be
18 years of age or older, native speakers of En-
glish, and have no known history of speech lan-
guage pathology or hearing loss. Participants were
required to have completed at least two semesters
of university level Arabic courses in order to en-
sure that they were able to correctly write the Ara-
bic characters and to transcribe Arabic speech.
Heritage speakers of Arabic and non-English dom-
inant bilinguals were excluded from the study. The
corpus contains responses from 62 participants.
The mean duration of Arabic study completed was
5.6 semesters (median 4).
Before beginning the experiment, participants
were asked to fill out a biographical questionnaire.
This included questions about language exposure
during childhood and languages studied in a class-
room setting. There were additional questions
about time spent outside of the United States to
ascertain possible exposure to languages not ad-
dressed in previous questions.
</bodyText>
<footnote confidence="0.9858368">
4These exceptions include only one instance of a phone
rather than two for the following contexts: (1) /h/ in the con-
text C_#, (2) /f/ in the context V_#, and (3) /z/ in the context
#_V. One geminate consonant, /x:/, was inadvertently omitted
from the stimulus set.
</footnote>
<page confidence="0.996941">
111
</page>
<bodyText confidence="0.999950916666667">
Participants wrote their responses to the 261
stimulus words on a response sheet that contained
numbered boxes. They were asked to use Arabic
orthography with full diacritics and short vowels
(fatha, damma, kasra, shadda and sukun). The
shadda (gemination) mark was required in order
to analyze the participants’ perception of geminate
consonants; the other diacritics were included so as
to not single out shadda for special attention (since
participants were naïve to the purpose of the study)
and also to increase the value of the resulting error
corpus for later analysis of short vowels.
</bodyText>
<subsectionHeader confidence="0.998976">
4.4 Presentation of the Stumuli
</subsectionHeader>
<bodyText confidence="0.999990227272727">
The proctors who ran the experiment supplied an
iPod Touch tablet to each participant, pre-loaded
with a custom stimuli presentation application.
In this custom iPod application, 261 Arabic
words were randomized into 9 stimulus sets. Each
stimulus set was preceded by four practice items
which were not scored; thus each participant saw
265 items. Each touch screen tablet was initialized
by the testers to deliver a specific stimulus set. A
button on the touch screen allowed the participants
to begin the experiment. After a few seconds’ de-
lay, the first word was played. A stimulus num-
ber identifying the word appeared in a large font
to aid the participants in recording the word on pa-
per. Participants were given 15 seconds to write
their response, before the tablet automatically ad-
vanced to the next word. Participants were not able
to replay a word.
The participants used noise-canceling head-
phones (Audio-Technica ATH-ANC7 or ATH-
ANC7B) for listening to the audio stimuli. The
experiment was performed in a quiet classroom.
</bodyText>
<subsectionHeader confidence="0.992836">
4.5 Data Coding
</subsectionHeader>
<bodyText confidence="0.999990169230769">
The participants’ handwritten responses were
typed in as they were written, using Arabic Uni-
code characters. Any diacritics (short vowels or
gemination) written by the participants were pre-
served. An automatic post-process was used to en-
sure that the gemination mark was ordered prop-
erly with respect to an adjacent short vowel mark.
The corpus consists of two main sections: ortho-
graphic and phonemic. The orthographic section is
very simple: each stimulus word is given in its tar-
get orthography (with diacritics) and in each par-
ticipant’s corresponding orthographic transcrip-
tion (including diacritics if the participant provided
them as instructed). The phonemic section is more
elaborate, containing additional fields designed for
a phone level analysis of target consonants. Its
construction is described in further detail below.
Both the orthographic response and the canon-
ical (reference) spelling were automatically con-
verted to a phonemic representation. This conver-
sion normalizes certain orthographic distinctions,
such as various spellings for word-final vowels.
This phonemic representation of the response for
each stimulus item was then compared with the
phonemic representation of the item’s canonical
pronunciation, and each phoneme of the response
was aligned automatically with the most probable
phoneme (or set of equally plausible phonemes)
in the canonical phonemic representation of the
auditory stimulus. This alignment was done via
dynamic programming with a weighted Leven-
shtein edit distance metric. Specifically, weights
were used to favor the alignment of vowels and
glides with each other rather than with non-glide
consonants (since the scope of our original study
was non-glide consonants). Thus substitutions be-
tween short vowels, long vowels, and glides are
given preference over other confusions. This is in-
tended to reduce the ambiguity of the alignments
and to ensure that non-glide consonants are aligned
with non-glide consonants when possible, without
introducing any bias in the non-glide consonants
alignments. When one unique alignment had the
lowest cost, it was used as the alignment for that
item. In some cases, multiple alignments were tied
for minimal cost. In this case, all alignments were
used and assigned equal probability.
Once the least-cost alignment(s) were found be-
tween a response string and the reference string for
an item, the target consonants within the reference
string were then each paired with the correspond-
ing phonemes in the response, and an error cate-
gory (&lt;substitution&gt;, &lt;deletion&gt;, or &lt;match&gt; for
no error) was assigned. In the case of geminate
phonemes, two subtypes of&lt;substitution&gt; were in-
troduced: &lt;gemination&gt; and &lt;degemination&gt;.
Where an entire word had no response, ‘NA’
was used to indicate that no edit operation can be
assigned. (A total of 112 items were missing).
Note that insertions were not marked, because
only the 649 instances of target consonants were
analyzed for the phonemic portion of the corpus,
and no other material in each stimulus word (in-
cluding any possible insertion points for additional
material) were annotated for errors. Insertions can
</bodyText>
<page confidence="0.996649">
112
</page>
<bodyText confidence="0.999838545454546">
be recovered from the orthographic portion of the
corpus.
The coding method described above yielded a
set of 41,121 target consonant records of partici-
pants’ responses to target consonants (not count-
ing the 112 non-response items), including 29,634
matches (72.1%) and 11,487 errors (27.9%). At
the word level, there are 16,217 words, of which
8321 (48.2%) contain at least one error in a tar-
geted consonant, and 5969 (37.1%) are spelled
perfectly (excluding diacritics).
</bodyText>
<sectionHeader confidence="0.96844" genericHeader="method">
5 Potential Uses of the Corpus
</sectionHeader>
<bodyText confidence="0.999972925">
In addition to the uses described in Section 3, we
believe the data could be used for several other
uses, such as examining linguistic correlates of
proficiency, developing phonemic training, and in-
vestigating non-native Arabic handwriting.
One potential use of the corpus is to analyze the
errors by individual learners to determine which
sounds are confused only by relatively beginning
learners (after two semesters) and which are con-
fused by beginning and experienced learners alike.
While hard measures of proficiency are not avail-
able for the participants, the language question-
naire includes time of study and self-report mea-
sures of proficiency. To the extent to which these
proxies are reliable, the corpus may lead to the de-
velopment of hypotheses which can be tested in
more targeted studies.
Since the corpus allows quantitative evidence
for the relative difficulty of particular sound pairs
in particular contexts, it may guide the prioritiza-
tion of foci for phonemic discrimination training
and other listening exercises. At the most basic
level, a teacher can take our original audio stimuli
and use them as dictation exercises for beginning
students (who may not be ready for sentence or
paragraph level dictation). It may also form the ba-
sis for automated phonemic discrimination train-
ing, such as Michael et al. (2013). Cf. Bradlow
(2008) for a review.
Since the participants handwrote their re-
sponses, the corpus contains, as a byproduct, a
set of 16,329 words in non-native handwriting and
their digital transcriptions. As Alfaifi and Atwell
(2013) note, this could be used as a corpus of non-
native handwriting for training or evaluating OCR
on L2 Arabic script. If corresponding native tran-
scriptions of the same (or similar) strings were ob-
tained, the corpus could also be used to differenti-
ate native from non-native handwriting (cf. Farooq
et al., 2006; Ramaiah et al., 2013).
</bodyText>
<sectionHeader confidence="0.863307" genericHeader="evaluation">
6 Limitations and future work
</sectionHeader>
<bodyText confidence="0.999971882352941">
The corpus as it currently stands has some limita-
tions worth noting. First, there is no control set
of native Arabic listeners to provide a comparison
point for distinguishing non-native perceptual er-
rors from acoustic errors that even native speakers
are subject to. Second, the survey does not con-
tain proficiency ratings (except self-report) for the
participants, making direct correlation of particu-
lar confusion patterns with proficiency level more
difficult.
Statistical analysis of the participants’ accuracy
at distinguishing Arabic consonants is currently
underway (Silbert et al., in preparation). An inves-
tigation of the utility of the corpus for training and
evaluating spelling correction for L1 English late
learners of Arabic, including the effects of training
corpus size on accuracy, is also in progress.
</bodyText>
<sectionHeader confidence="0.991026" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999928375">
The Arabic Corpus of Auditory Dictation Errors
(ArCADE) version 1 provides a corpus of word-
level transcriptions of Arabic speech by native En-
glish speakers learning Arabic, ideal for the anal-
ysis of within-word listening errors, as well as the
development and evaluation of NLP tools that seek
to aid either in developing listening skill or in com-
pensating for typical non-native deficits in listen-
ing. Since most learner corpora only include writ-
ten composition or spoken production from stu-
dents, this corpus fills a gap in the resources avail-
able for the study of Arabic as a second language.
The corpus, along with the original audio
stimuli and participants’ handwriting samples,
is available at http://www.casl.umd.edu/
datasets/cade/arcade/index.html.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.986059125">
This material is based on work supported, in whole
or in part, with funding from the United States
Government. Any opinions, findings, and conclu-
sions or recommendations expressed in this mate-
rial are those of the authors and do not necessarily
reflect the views of the University of Maryland,
College Park and/or any agency or entity of the
United States Government.
</bodyText>
<page confidence="0.997484">
113
</page>
<note confidence="0.394733">
References
Muhammad Abu al-Rub. 2007. aﯿﺑﺎﺘﻜﻟا ءﺎﻄﺧﻷا ﻞﯿﻠﲢ
.ﺎﻫﲑﻐﺑ ﲔﻘﻃﺎﻨﻟا aﯿﺑﺮﻌﻟا aﻐﻠﻟا ﻲﻤﻠﻌﺘﻣ ىلد ءﻼﻣﻹا ىﻮﺘـﺴﻣ ﲆﻋ
</note>
<bodyText confidence="0.68723275">
Taḥlīl al-akhṭā’ al-kitābīyah ‘ala mustawá
al-imlā’ ladá muta‘allimī al-lughah al-‘arabīyah
al-nāṭiqīna bi-ghayrihā [Analysis of written
spelling errors among non-native speak-
</bodyText>
<reference confidence="0.97413234065934">
ing learners of Arabic]. aﯿﻧﺎﺴﻧﻹا مﻮﻠﻌﻟا ،تﺎﺳارد
.aﯿsltﺟالا y Dirāsāt, al-‘Ulūm al-Insānīyah wa-al-
Ijtimā‘īyah [Humanities and Social Sciences],
34(2). http://journals.ju.edu.jo/
DirasatHum/article/view/1911/1898.
Ghazi Abuhakema, Anna Feldman, and Eileen
Fitzpatrick. 2008. Annotating an Arabic learner
corpus for error. In Proceedings of the Interna-
tional Conference on Language Resources and
Evaluation (LREC 2008). Marrakech, Morocco.
Ghazi Abuhakema, Anna Feldman, and Eileen
Fitzpatrick. 2009. ARIDA: An Arabic inter-
language database and its applications: A pilot
study. Journal of the National Council of Less
Commonly Taught Languages (NCOLCTL),
7:161–184.
Abdullah Alfaifi and Eric Atwell. 2013. Potential
uses of the Arabic Learner Corpus. In Leeds
Language, Linguistics, and Translation PGR
Conference 2013. University of Leeds, Leeds,
UK.
Yves Bestgen and Sylvaine Granger. 2011. Cat-
egorising spelling errors to assess L2 writ-
ing. International Journal of Continuing En-
gineering Education and Life-Long Learning,
21(2/3):235–252.
Ann Bradlow. 2008. Training non-native language
sound patterns. In Phonology and Second Lan-
guage Acquisition, Benjamins, Amsterdam and
Philadelphia, pages 287–308.
Kristin Brustad, Mahmoud Al-Batal, and Abbas
Al-Tonsi. 2004a. Al-Kitaab fii Ta‘allum al-
‘Arabiyya, volume 1. Georgetown University
Press, Washington, DC, 1st edition.
Kristin Brustad, Mahmoud Al-Batal, and Abbas
Al-Tonsi. 2004b. AlifBaa: Introduction to Ara-
bic Letters and Sounds. Georgetown University
Press, Washington, DC, 2nd edition.
Laura Rose Faircloth. 2013. The L2 Perception
of Phonemic Distinctions in Arabic by English
Speakers. BA Thesis, The College of William
and Mary. https://digitalarchive.wm.
edu/bitstream/handle/10288/18160/
FairclothLauraRose2013Thesis.pdf?
sequence=1.
Faisal Farooq, Liana Lorigo, and Venu Govin-
daraju. 2006. On the accent in handwrit-
ing of individuals. In Tenth Interna-
tional Workshop on Frontiers in Hand-
writing Recognition. La Baule, France.
http://hal.inria.fr/docs/00/11/26/
30/PDF/cr103741695994.pdf.
Samira Farwaneh and Mohammed Tamimi. 2012.
Arabic learners written corpus: A resource for
research and learning. Available from the
University of Arizona Center for Educational
Resources in Culture, Language, and Literacy
web site. http://l2arabiccorpus.cercll.
arizona.edu/?q=homepage.
John Field. 2008. Listening in the Language Class-
room. Cambridge University Press, Cambridge,
UK.
DJ Hovermale. 2011. Erron: A Phrase-Based
Machine Traslation Approach to Customized
Spelling Correction. Ph.D. thesis, The Ohio
State University.
Khaled Yahya Huthaily. 2008. Second Lan-
guage Instruction with Phonological Knowl-
edge: Teaching Arabic to Speakers of English.
Ph.D. thesis, The University of Montana.
Col. Stephen A. LaRocca and Rajaa Chouairi.
2002. West Point Arabic speech corpus. Tech-
nical report, LDC, Philadelphia.
Erica B. Michael, Greg Colflesh, Valerie Karuzis,
Michael Key, Svetlana Cook, Noah H. Silbert,
Christopher Green, Evelyn Browne, C. Anton
Rytting, Eric Pelzl, and Michael Bunting. 2013.
Perceptual training for second language speech
perception: Validation study to assess the ef-
ficacy of a new training regimen (TTO 2013).
Technical report, University of Maryland Cen-
ter for Advanced Study of Language, College
Park, MD.
Roger Mitton and Takeshi Okada. 2007. The adap-
tation of an English spellchecker for Japanese
writers. Birbeck ePrints, London. http://
eprints.bbk.ac.uk/archive/00000592.
Ryo Nagata, Edward Whittaker, and Vera Shein-
man. 2011. Creating a manually error-tagged
and shallow-parsed learner corpus. In Proceed-
ings of the 49th Annual Meeting of the Asso-
</reference>
<page confidence="0.988984">
114
</page>
<reference confidence="0.992031744680851">
ciation for Computational Linguistics. Associ-
ation for Computational Linguistics, Portland,
OR, pages 1210–1219.
Nadja Nesselhauf. 2004. Learner corpora and their
potential in language teaching. In How to Use
Corpora in Language Teaching, Benjamins,
Amsterdam and Philadelphia, pages 125–152.
Takeshi Okada. 2005. Spelling errors made by
Japanese EFL writers: with reference to errors
occurring at the word-initial and word-final po-
sitions. In Vivian Cook and Benedetta Bassetti,
editors, Second language writing systems, Mul-
tilingual Matters, Clevedon, UK, pages 164–
183.
Peter Prince. 2012. Writing it down: Issues re-
lating to the use of restitution tasks in listening
comprehension. TESOL Journal, 3(1):65–86.
Chetan Ramaiah, Arti Shivram, and Venu
Govindaraju. 2013. A Baysian framework
for modeling accents in handwriting. In
12th International Conference on Docu-
ment Analysis and Recognition (ICDAR).
http://ieeexplore.ieee.org/xpls/abs_
all.jsp?arnumber=6628752.
C. Anton Rytting, Paul Rodrigues, Tim Buckwal-
ter, David M. Zajic, Bridget Hirsch, Jeff Carnes,
Nathanael Lynn, Sarah Wayland, Chris Taylor,
Jason White, Charles Blake, Evelyn Browne,
Corey Miller, and Tristan Purvis. 2010. Error
correction for Arabic dictionary lookup. In Sev-
enth International Conference on Language Re-
sources and Evaluation (LREC 2010). Valletta,
Malta.
Abhinav Sethy, Shrikanth Narayanan, Nicolaus
Mote, and W. Lewis Johnson. 2005. Modeling
and automating detection of errors in Arabic lan-
guage learner speech. In INTERSPEECH-2005.
pages 177–180.
Noah H. Silbert, C. Anton Rytting, Paul Ro-
drigues, Tim Buckwalter, Valerie Novak, Mo-
hini Madgavkar, Katharine Burk, and Aric Bills.
in preparation. Similarity and bias in non-native
Arabic consonant perception.
Mark Warschauer and Paige Ware. 2006. Auto-
mated writing evaluation: Defining the class-
room research agenda. Language Teaching Re-
search, 10(2):157–180.
</reference>
<page confidence="0.999">
115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.178921">
<title confidence="0.999706">ArCADE: An Arabic Corpus of Auditory Dictation Errors</title>
<author confidence="0.8756826">C Anton Paul Tim Valerie Aric</author>
<affiliation confidence="0.998994">University of</affiliation>
<address confidence="0.94668">7005 52nd College Park, MD</address>
<email confidence="0.996997">vnovak,abills}@umd.edu</email>
<author confidence="0.998224">H Noah</author>
<affiliation confidence="0.9978155">Sciences &amp; University of</affiliation>
<address confidence="0.8449055">2600 Clifton Cincinnati,</address>
<email confidence="0.999874">@ucmail.uc.edu</email>
<author confidence="0.766832">Mohini</author>
<affiliation confidence="0.878213">Independent</affiliation>
<address confidence="0.9272955">6120 Dhaka Pl. Dhaka,</address>
<email confidence="0.999924">@gmail.com</email>
<abstract confidence="0.995635941176471">We present a new corpus of word-level listening errors collected from 62 native English speakers learning Arabic designed to inform models of spell checking for this learner population. While we use the corpus to assist in automated detection and correction of auditory errors in electronic dictionary lookup, the corpus can also be used as a phonological error layer, to be combined with a composition error layer in a more complex spell-checking system for non-native speakers. The corpus may be useful to instructors of Arabic as a second language, and researchers who study second language phonology and listening perception.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>ing learners of Arabic]. aﯿﻧﺎﺴﻧﻹا مﻮﻠﻌﻟا ،تﺎﺳارد .aﯿsltﺟالا y</title>
<booktitle>Dirāsāt, al-‘Ulūm al-Insānīyah wa-alIjtimā‘īyah [Humanities and Social Sciences],</booktitle>
<volume>34</volume>
<issue>2</issue>
<note>http://journals.ju.edu.jo/ DirasatHum/article/view/1911/1898.</note>
<marker></marker>
<rawString>ing learners of Arabic]. aﯿﻧﺎﺴﻧﻹا مﻮﻠﻌﻟا ،تﺎﺳارد .aﯿsltﺟالا y Dirāsāt, al-‘Ulūm al-Insānīyah wa-alIjtimā‘īyah [Humanities and Social Sciences], 34(2). http://journals.ju.edu.jo/ DirasatHum/article/view/1911/1898.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ghazi Abuhakema</author>
<author>Anna Feldman</author>
<author>Eileen Fitzpatrick</author>
</authors>
<title>Annotating an Arabic learner corpus for error.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="4864" citStr="Abuhakema et al., 2008" startWordPosition="724" endWordPosition="727">ng and maintenance, and learner corpora from which to build them, typically focus on language pairs for which there is a large market. Learner corpora for native English learners of low resource languages such as Arabic have been until recently comparatively rare, and often too small to be of practical use for the development of educational technology. In the past few years, however, a number of learner corpora for Arabic have become available, including a corpus of 19 non-native (mostly Malaysian) students at Al Al-Bayt University (Abu al-Rub, 2007); the Arabic Interlanguage Database (ARIDA; Abuhakema et al., 2008, 2009); the Arabic Learners Written Corpus from the University of Arizona Center for Educational Resources in Culture, Language, and Literacy (CERCLL; Farwaneh and Tamimi, 2012);1 and the Arabic Learner Corpus v1 (Alfaifi and Atwell, 2013).2 These corpora are all derived from learner writing samples, such as essays, and as such they contain many different types of errors, including errors in morphology, syntax, and word choice. Spelling errors are also observed, but relatively rarely, and the relevance of these spelling errors to listening competence is unclear. Hence, while they are likely t</context>
</contexts>
<marker>Abuhakema, Feldman, Fitzpatrick, 2008</marker>
<rawString>Ghazi Abuhakema, Anna Feldman, and Eileen Fitzpatrick. 2008. Annotating an Arabic learner corpus for error. In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2008). Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ghazi Abuhakema</author>
<author>Anna Feldman</author>
<author>Eileen Fitzpatrick</author>
</authors>
<title>ARIDA: An Arabic interlanguage database and its applications: A pilot study.</title>
<date>2009</date>
<journal>Journal of the National Council of Less Commonly Taught Languages (NCOLCTL),</journal>
<pages>7--161</pages>
<marker>Abuhakema, Feldman, Fitzpatrick, 2009</marker>
<rawString>Ghazi Abuhakema, Anna Feldman, and Eileen Fitzpatrick. 2009. ARIDA: An Arabic interlanguage database and its applications: A pilot study. Journal of the National Council of Less Commonly Taught Languages (NCOLCTL), 7:161–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abdullah Alfaifi</author>
<author>Eric Atwell</author>
</authors>
<title>Potential uses of the Arabic Learner Corpus.</title>
<date>2013</date>
<booktitle>In Leeds Language, Linguistics, and Translation PGR Conference</booktitle>
<institution>University of Leeds,</institution>
<location>Leeds, UK.</location>
<contexts>
<context position="5104" citStr="Alfaifi and Atwell, 2013" startWordPosition="760" endWordPosition="763">ecently comparatively rare, and often too small to be of practical use for the development of educational technology. In the past few years, however, a number of learner corpora for Arabic have become available, including a corpus of 19 non-native (mostly Malaysian) students at Al Al-Bayt University (Abu al-Rub, 2007); the Arabic Interlanguage Database (ARIDA; Abuhakema et al., 2008, 2009); the Arabic Learners Written Corpus from the University of Arizona Center for Educational Resources in Culture, Language, and Literacy (CERCLL; Farwaneh and Tamimi, 2012);1 and the Arabic Learner Corpus v1 (Alfaifi and Atwell, 2013).2 These corpora are all derived from learner writing samples, such as essays, and as such they contain many different types of errors, including errors in morphology, syntax, and word choice. Spelling errors are also observed, but relatively rarely, and the relevance of these spelling errors to listening competence is unclear. Hence, while they are likely to be useful for many applications in teaching Arabic writing, their usefulness for other purposes, such as examining listening skills and the effects of learner phonology on spelling, is limited. Corpora or datasets focused on speaking and </context>
<context position="20138" citStr="Alfaifi and Atwell (2013)" startWordPosition="3138" endWordPosition="3141">e prioritization of foci for phonemic discrimination training and other listening exercises. At the most basic level, a teacher can take our original audio stimuli and use them as dictation exercises for beginning students (who may not be ready for sentence or paragraph level dictation). It may also form the basis for automated phonemic discrimination training, such as Michael et al. (2013). Cf. Bradlow (2008) for a review. Since the participants handwrote their responses, the corpus contains, as a byproduct, a set of 16,329 words in non-native handwriting and their digital transcriptions. As Alfaifi and Atwell (2013) note, this could be used as a corpus of nonnative handwriting for training or evaluating OCR on L2 Arabic script. If corresponding native transcriptions of the same (or similar) strings were obtained, the corpus could also be used to differentiate native from non-native handwriting (cf. Farooq et al., 2006; Ramaiah et al., 2013). 6 Limitations and future work The corpus as it currently stands has some limitations worth noting. First, there is no control set of native Arabic listeners to provide a comparison point for distinguishing non-native perceptual errors from acoustic errors that even n</context>
</contexts>
<marker>Alfaifi, Atwell, 2013</marker>
<rawString>Abdullah Alfaifi and Eric Atwell. 2013. Potential uses of the Arabic Learner Corpus. In Leeds Language, Linguistics, and Translation PGR Conference 2013. University of Leeds, Leeds, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Sylvaine Granger</author>
</authors>
<title>Categorising spelling errors to assess</title>
<date>2011</date>
<booktitle>L2 writing. International Journal of Continuing Engineering Education and Life-Long Learning,</booktitle>
<pages>21--2</pages>
<contexts>
<context position="1631" citStr="Bestgen and Granger, 2011" startWordPosition="233" endWordPosition="236">tructors of Arabic as a second language, and researchers who study second language phonology and listening perception. 1 Introduction Learner corpora have received attention as an important resource both for guiding teachers in curriculum development (Nesselhauf, 2004) and for providing training and evaluation material the development of tools for computer-assisted language learning (CALL). One of the most commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing sk</context>
</contexts>
<marker>Bestgen, Granger, 2011</marker>
<rawString>Yves Bestgen and Sylvaine Granger. 2011. Categorising spelling errors to assess L2 writing. International Journal of Continuing Engineering Education and Life-Long Learning, 21(2/3):235–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bradlow</author>
</authors>
<title>Training non-native language sound patterns.</title>
<date>2008</date>
<booktitle>In Phonology and Second Language Acquisition, Benjamins,</booktitle>
<pages>287--308</pages>
<location>Amsterdam and Philadelphia,</location>
<contexts>
<context position="19926" citStr="Bradlow (2008)" startWordPosition="3107" endWordPosition="3108">t of hypotheses which can be tested in more targeted studies. Since the corpus allows quantitative evidence for the relative difficulty of particular sound pairs in particular contexts, it may guide the prioritization of foci for phonemic discrimination training and other listening exercises. At the most basic level, a teacher can take our original audio stimuli and use them as dictation exercises for beginning students (who may not be ready for sentence or paragraph level dictation). It may also form the basis for automated phonemic discrimination training, such as Michael et al. (2013). Cf. Bradlow (2008) for a review. Since the participants handwrote their responses, the corpus contains, as a byproduct, a set of 16,329 words in non-native handwriting and their digital transcriptions. As Alfaifi and Atwell (2013) note, this could be used as a corpus of nonnative handwriting for training or evaluating OCR on L2 Arabic script. If corresponding native transcriptions of the same (or similar) strings were obtained, the corpus could also be used to differentiate native from non-native handwriting (cf. Farooq et al., 2006; Ramaiah et al., 2013). 6 Limitations and future work The corpus as it currentl</context>
</contexts>
<marker>Bradlow, 2008</marker>
<rawString>Ann Bradlow. 2008. Training non-native language sound patterns. In Phonology and Second Language Acquisition, Benjamins, Amsterdam and Philadelphia, pages 287–308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristin Brustad</author>
<author>Mahmoud Al-Batal</author>
<author>Abbas Al-Tonsi</author>
</authors>
<title>edition.</title>
<date>2004</date>
<booktitle>Al-Kitaab fii Ta‘allum al‘Arabiyya,</booktitle>
<volume>1</volume>
<publisher>Georgetown University Press,</publisher>
<location>Washington, DC,</location>
<contexts>
<context position="10278" citStr="Brustad et al., 2004" startWordPosition="1578" endWordPosition="1581">n-root consonants, when Semitic roots were known to the researchers; (2) consonants participating in a reduplicative pattern such as /tamtam/ and /zalzala/; and (3) Consonants found in doubled (R2=R3) roots if the two consonants surfaced separately (e.g., in broken plurals such as /ʔasnan/). We excluded words from our stimulus set if we anticipated that an intermediate Arabic student would already be familiar with them or would easily be able to guess their spellings. Items found in vocabulary lists associated with two commonlyused introductory textbooks (Al-Kitaab and AlifBaa) were excluded (Brustad et al., 2004a,b). Loanwords from Western languages were also excluded, as were well-known place names (e.g., /ʔiskotlanda/ = “Scotland”). Words found only in colloquial dialects and terms that might be offensive or otherwise distracting (as judged by native speaker of Arabic) were removed, as well. In order to keep the stimulus set as short as possible while maintaining coverage of the full set of target stimuli consonants in each targeted context, we chose words with multiple target consonants whenever possible. The final set of 261 words con3C = consonant, V = vowel, # = word boundary, and ‘_’ (undersco</context>
</contexts>
<marker>Brustad, Al-Batal, Al-Tonsi, 2004</marker>
<rawString>Kristin Brustad, Mahmoud Al-Batal, and Abbas Al-Tonsi. 2004a. Al-Kitaab fii Ta‘allum al‘Arabiyya, volume 1. Georgetown University Press, Washington, DC, 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristin Brustad</author>
<author>Mahmoud Al-Batal</author>
<author>Abbas Al-Tonsi</author>
</authors>
<title>AlifBaa: Introduction to Arabic Letters and Sounds.</title>
<date>2004</date>
<publisher>Georgetown University Press,</publisher>
<location>Washington, DC,</location>
<note>2nd edition.</note>
<contexts>
<context position="10278" citStr="Brustad et al., 2004" startWordPosition="1578" endWordPosition="1581">n-root consonants, when Semitic roots were known to the researchers; (2) consonants participating in a reduplicative pattern such as /tamtam/ and /zalzala/; and (3) Consonants found in doubled (R2=R3) roots if the two consonants surfaced separately (e.g., in broken plurals such as /ʔasnan/). We excluded words from our stimulus set if we anticipated that an intermediate Arabic student would already be familiar with them or would easily be able to guess their spellings. Items found in vocabulary lists associated with two commonlyused introductory textbooks (Al-Kitaab and AlifBaa) were excluded (Brustad et al., 2004a,b). Loanwords from Western languages were also excluded, as were well-known place names (e.g., /ʔiskotlanda/ = “Scotland”). Words found only in colloquial dialects and terms that might be offensive or otherwise distracting (as judged by native speaker of Arabic) were removed, as well. In order to keep the stimulus set as short as possible while maintaining coverage of the full set of target stimuli consonants in each targeted context, we chose words with multiple target consonants whenever possible. The final set of 261 words con3C = consonant, V = vowel, # = word boundary, and ‘_’ (undersco</context>
</contexts>
<marker>Brustad, Al-Batal, Al-Tonsi, 2004</marker>
<rawString>Kristin Brustad, Mahmoud Al-Batal, and Abbas Al-Tonsi. 2004b. AlifBaa: Introduction to Arabic Letters and Sounds. Georgetown University Press, Washington, DC, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Rose Faircloth</author>
</authors>
<title>The L2 Perception of Phonemic Distinctions in Arabic by English Speakers. BA Thesis, The College of William and Mary.</title>
<date>2013</date>
<note>https://digitalarchive.wm. sequence=1.</note>
<contexts>
<context position="6450" citStr="Faircloth, 2013" startWordPosition="969" endWordPosition="970">our of non-native (learner) speech (LaRocca and Chouairi, 2002) Sethy et al. (2005) describe a corpus of elicited Arabic speech, but because none of the participants had prior exposure to Arabic, its use for un1Available from http://l2arabiccorpus.cercll. arizona.edu/?q=homepage. 2As of February 2014, a second version, with about 130K words from non-native speakers, is available from http: //www.arabiclearnercorpus.com/. It also has a small (three hour) speech component. derstanding learner Arabic is limited. While there have been a few studies of Arabic listening skills (e.g. Huthaily, 2008; Faircloth, 2013), their coverage was not sufficiently broad to make reuse of their data likely to inform such purposes as the development of phoneme discrimination training or other CALL technology. 3 Motivation We present here the Arabic Corpus of Auditory Dictation Errors (ArCADE) version 1, a corpus of Arabic words as transcribed by 62 native English speakers learning Arabic. This corpus fills the current gap in non-native spelling error corpora, and particularly for spelling errors due to listening difficulties. Unlike error corpora collected from non-native Arabic writing samples, it is designed to elici</context>
</contexts>
<marker>Faircloth, 2013</marker>
<rawString>Laura Rose Faircloth. 2013. The L2 Perception of Phonemic Distinctions in Arabic by English Speakers. BA Thesis, The College of William and Mary. https://digitalarchive.wm. sequence=1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Faisal Farooq</author>
<author>Liana Lorigo</author>
<author>Venu Govindaraju</author>
</authors>
<title>On the accent in handwriting of individuals.</title>
<date>2006</date>
<booktitle>In Tenth International Workshop on Frontiers in Handwriting Recognition. La Baule,</booktitle>
<note>http://hal.inria.fr/docs/00/11/26/ 30/PDF/cr103741695994.pdf.</note>
<contexts>
<context position="20446" citStr="Farooq et al., 2006" startWordPosition="3191" endWordPosition="3194">s for automated phonemic discrimination training, such as Michael et al. (2013). Cf. Bradlow (2008) for a review. Since the participants handwrote their responses, the corpus contains, as a byproduct, a set of 16,329 words in non-native handwriting and their digital transcriptions. As Alfaifi and Atwell (2013) note, this could be used as a corpus of nonnative handwriting for training or evaluating OCR on L2 Arabic script. If corresponding native transcriptions of the same (or similar) strings were obtained, the corpus could also be used to differentiate native from non-native handwriting (cf. Farooq et al., 2006; Ramaiah et al., 2013). 6 Limitations and future work The corpus as it currently stands has some limitations worth noting. First, there is no control set of native Arabic listeners to provide a comparison point for distinguishing non-native perceptual errors from acoustic errors that even native speakers are subject to. Second, the survey does not contain proficiency ratings (except self-report) for the participants, making direct correlation of particular confusion patterns with proficiency level more difficult. Statistical analysis of the participants’ accuracy at distinguishing Arabic cons</context>
</contexts>
<marker>Farooq, Lorigo, Govindaraju, 2006</marker>
<rawString>Faisal Farooq, Liana Lorigo, and Venu Govindaraju. 2006. On the accent in handwriting of individuals. In Tenth International Workshop on Frontiers in Handwriting Recognition. La Baule, France. http://hal.inria.fr/docs/00/11/26/ 30/PDF/cr103741695994.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samira Farwaneh</author>
<author>Mohammed Tamimi</author>
</authors>
<title>Arabic learners written corpus: A resource for research and learning. Available from the</title>
<date>2012</date>
<institution>University of Arizona Center for Educational</institution>
<note>http://l2arabiccorpus.cercll. arizona.edu/?q=homepage.</note>
<contexts>
<context position="5042" citStr="Farwaneh and Tamimi, 2012" startWordPosition="750" endWordPosition="753">ners of low resource languages such as Arabic have been until recently comparatively rare, and often too small to be of practical use for the development of educational technology. In the past few years, however, a number of learner corpora for Arabic have become available, including a corpus of 19 non-native (mostly Malaysian) students at Al Al-Bayt University (Abu al-Rub, 2007); the Arabic Interlanguage Database (ARIDA; Abuhakema et al., 2008, 2009); the Arabic Learners Written Corpus from the University of Arizona Center for Educational Resources in Culture, Language, and Literacy (CERCLL; Farwaneh and Tamimi, 2012);1 and the Arabic Learner Corpus v1 (Alfaifi and Atwell, 2013).2 These corpora are all derived from learner writing samples, such as essays, and as such they contain many different types of errors, including errors in morphology, syntax, and word choice. Spelling errors are also observed, but relatively rarely, and the relevance of these spelling errors to listening competence is unclear. Hence, while they are likely to be useful for many applications in teaching Arabic writing, their usefulness for other purposes, such as examining listening skills and the effects of learner phonology on spel</context>
</contexts>
<marker>Farwaneh, Tamimi, 2012</marker>
<rawString>Samira Farwaneh and Mohammed Tamimi. 2012. Arabic learners written corpus: A resource for research and learning. Available from the University of Arizona Center for Educational Resources in Culture, Language, and Literacy web site. http://l2arabiccorpus.cercll. arizona.edu/?q=homepage.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Field</author>
</authors>
<title>Listening in the Language Classroom.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<contexts>
<context position="2335" citStr="Field, 2008" startWordPosition="334" endWordPosition="335">by improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of listening errors can guide teachers and curriculum development just as written production errors do. Listening error data may also be helpful for improving technologies for listening training tools, by helping prioritize the most critical pairs of phonemes for discrimination, and pointing out the most troublesome contexts for phoneme discrimination. Finally, spell correction specifically designed to correct listening errors may aid listening comprehension and vocabulary acquisition. If learners are unable to hear, recall and record accurately what the</context>
</contexts>
<marker>Field, 2008</marker>
<rawString>John Field. 2008. Listening in the Language Classroom. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>DJ Hovermale</author>
</authors>
<title>Erron: A Phrase-Based Machine Traslation Approach to Customized Spelling Correction.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>The Ohio State University.</institution>
<contexts>
<context position="2012" citStr="Hovermale, 2011" startWordPosition="289" endWordPosition="290">. One of the most commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of listening errors can guide teachers and curriculum development just as written production errors do. Listening error data may also be helpful for improving technologies for listening training tools, by helping prioritize the most crit</context>
</contexts>
<marker>Hovermale, 2011</marker>
<rawString>DJ Hovermale. 2011. Erron: A Phrase-Based Machine Traslation Approach to Customized Spelling Correction. Ph.D. thesis, The Ohio State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khaled Yahya Huthaily</author>
</authors>
<title>Second Language Instruction with Phonological Knowledge: Teaching Arabic to Speakers of English.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>The University of Montana.</institution>
<contexts>
<context position="6432" citStr="Huthaily, 2008" startWordPosition="967" endWordPosition="968">, contains one hour of non-native (learner) speech (LaRocca and Chouairi, 2002) Sethy et al. (2005) describe a corpus of elicited Arabic speech, but because none of the participants had prior exposure to Arabic, its use for un1Available from http://l2arabiccorpus.cercll. arizona.edu/?q=homepage. 2As of February 2014, a second version, with about 130K words from non-native speakers, is available from http: //www.arabiclearnercorpus.com/. It also has a small (three hour) speech component. derstanding learner Arabic is limited. While there have been a few studies of Arabic listening skills (e.g. Huthaily, 2008; Faircloth, 2013), their coverage was not sufficiently broad to make reuse of their data likely to inform such purposes as the development of phoneme discrimination training or other CALL technology. 3 Motivation We present here the Arabic Corpus of Auditory Dictation Errors (ArCADE) version 1, a corpus of Arabic words as transcribed by 62 native English speakers learning Arabic. This corpus fills the current gap in non-native spelling error corpora, and particularly for spelling errors due to listening difficulties. Unlike error corpora collected from non-native Arabic writing samples, it is</context>
</contexts>
<marker>Huthaily, 2008</marker>
<rawString>Khaled Yahya Huthaily. 2008. Second Language Instruction with Phonological Knowledge: Teaching Arabic to Speakers of English. Ph.D. thesis, The University of Montana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen A LaRocca</author>
<author>Rajaa Chouairi</author>
</authors>
<title>West Point Arabic speech corpus.</title>
<date>2002</date>
<tech>Technical report, LDC, Philadelphia.</tech>
<contexts>
<context position="5897" citStr="LaRocca and Chouairi, 2002" startWordPosition="887" endWordPosition="890">, syntax, and word choice. Spelling errors are also observed, but relatively rarely, and the relevance of these spelling errors to listening competence is unclear. Hence, while they are likely to be useful for many applications in teaching Arabic writing, their usefulness for other purposes, such as examining listening skills and the effects of learner phonology on spelling, is limited. Corpora or datasets focused on speaking and listening skills in Arabic are rarer. One such corpus, the West Point Arabic Speech Corpus, available from the LDC, contains one hour of non-native (learner) speech (LaRocca and Chouairi, 2002) Sethy et al. (2005) describe a corpus of elicited Arabic speech, but because none of the participants had prior exposure to Arabic, its use for un1Available from http://l2arabiccorpus.cercll. arizona.edu/?q=homepage. 2As of February 2014, a second version, with about 130K words from non-native speakers, is available from http: //www.arabiclearnercorpus.com/. It also has a small (three hour) speech component. derstanding learner Arabic is limited. While there have been a few studies of Arabic listening skills (e.g. Huthaily, 2008; Faircloth, 2013), their coverage was not sufficiently broad to </context>
</contexts>
<marker>LaRocca, Chouairi, 2002</marker>
<rawString>Col. Stephen A. LaRocca and Rajaa Chouairi. 2002. West Point Arabic speech corpus. Technical report, LDC, Philadelphia.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Erica B Michael</author>
<author>Greg Colflesh</author>
<author>Valerie Karuzis</author>
<author>Michael Key</author>
<author>Svetlana Cook</author>
<author>Noah H Silbert</author>
<author>Christopher Green</author>
<author>Evelyn Browne</author>
<author>C Anton Rytting</author>
<author>Eric Pelzl</author>
<author>Michael Bunting</author>
</authors>
<title>Perceptual training for second language speech perception: Validation study to assess the efficacy of a new training regimen (TTO</title>
<date>2013</date>
<tech>Technical report,</tech>
<institution>University of Maryland Center for Advanced Study of Language,</institution>
<location>College Park, MD.</location>
<contexts>
<context position="19906" citStr="Michael et al. (2013)" startWordPosition="3102" endWordPosition="3105"> may lead to the development of hypotheses which can be tested in more targeted studies. Since the corpus allows quantitative evidence for the relative difficulty of particular sound pairs in particular contexts, it may guide the prioritization of foci for phonemic discrimination training and other listening exercises. At the most basic level, a teacher can take our original audio stimuli and use them as dictation exercises for beginning students (who may not be ready for sentence or paragraph level dictation). It may also form the basis for automated phonemic discrimination training, such as Michael et al. (2013). Cf. Bradlow (2008) for a review. Since the participants handwrote their responses, the corpus contains, as a byproduct, a set of 16,329 words in non-native handwriting and their digital transcriptions. As Alfaifi and Atwell (2013) note, this could be used as a corpus of nonnative handwriting for training or evaluating OCR on L2 Arabic script. If corresponding native transcriptions of the same (or similar) strings were obtained, the corpus could also be used to differentiate native from non-native handwriting (cf. Farooq et al., 2006; Ramaiah et al., 2013). 6 Limitations and future work The c</context>
</contexts>
<marker>Michael, Colflesh, Karuzis, Key, Cook, Silbert, Green, Browne, Rytting, Pelzl, Bunting, 2013</marker>
<rawString>Erica B. Michael, Greg Colflesh, Valerie Karuzis, Michael Key, Svetlana Cook, Noah H. Silbert, Christopher Green, Evelyn Browne, C. Anton Rytting, Eric Pelzl, and Michael Bunting. 2013. Perceptual training for second language speech perception: Validation study to assess the efficacy of a new training regimen (TTO 2013). Technical report, University of Maryland Center for Advanced Study of Language, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Mitton</author>
<author>Takeshi Okada</author>
</authors>
<title>The adaptation of an English spellchecker for Japanese writers. Birbeck ePrints, London.</title>
<date>2007</date>
<note>http:// eprints.bbk.ac.uk/archive/00000592.</note>
<contexts>
<context position="2036" citStr="Mitton and Okada, 2007" startWordPosition="291" endWordPosition="295"> commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of listening errors can guide teachers and curriculum development just as written production errors do. Listening error data may also be helpful for improving technologies for listening training tools, by helping prioritize the most critical pairs of phonemes f</context>
</contexts>
<marker>Mitton, Okada, 2007</marker>
<rawString>Roger Mitton and Takeshi Okada. 2007. The adaptation of an English spellchecker for Japanese writers. Birbeck ePrints, London. http:// eprints.bbk.ac.uk/archive/00000592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Nagata</author>
<author>Edward Whittaker</author>
<author>Vera Sheinman</author>
</authors>
<title>Creating a manually error-tagged and shallow-parsed learner corpus.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,</booktitle>
<pages>1210--1219</pages>
<location>Portland, OR,</location>
<contexts>
<context position="1781" citStr="Nagata et al., 2011" startWordPosition="254" endWordPosition="257">eceived attention as an important resource both for guiding teachers in curriculum development (Nesselhauf, 2004) and for providing training and evaluation material the development of tools for computer-assisted language learning (CALL). One of the most commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of lis</context>
</contexts>
<marker>Nagata, Whittaker, Sheinman, 2011</marker>
<rawString>Ryo Nagata, Edward Whittaker, and Vera Sheinman. 2011. Creating a manually error-tagged and shallow-parsed learner corpus. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Portland, OR, pages 1210–1219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadja Nesselhauf</author>
</authors>
<title>Learner corpora and their potential in language teaching.</title>
<date>2004</date>
<booktitle>In How to Use Corpora in Language Teaching, Benjamins,</booktitle>
<pages>125--152</pages>
<location>Amsterdam and Philadelphia,</location>
<contexts>
<context position="1274" citStr="Nesselhauf, 2004" startWordPosition="183" endWordPosition="184">is learner population. While we use the corpus to assist in automated detection and correction of auditory errors in electronic dictionary lookup, the corpus can also be used as a phonological error layer, to be combined with a composition error layer in a more complex spell-checking system for non-native speakers. The corpus may be useful to instructors of Arabic as a second language, and researchers who study second language phonology and listening perception. 1 Introduction Learner corpora have received attention as an important resource both for guiding teachers in curriculum development (Nesselhauf, 2004) and for providing training and evaluation material the development of tools for computer-assisted language learning (CALL). One of the most commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target languag</context>
</contexts>
<marker>Nesselhauf, 2004</marker>
<rawString>Nadja Nesselhauf. 2004. Learner corpora and their potential in language teaching. In How to Use Corpora in Language Teaching, Benjamins, Amsterdam and Philadelphia, pages 125–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Okada</author>
</authors>
<title>Spelling errors made by Japanese EFL writers: with reference to errors occurring at the word-initial and word-final positions.</title>
<date>2005</date>
<booktitle>Second language writing systems, Multilingual Matters,</booktitle>
<pages>164--183</pages>
<editor>In Vivian Cook and Benedetta Bassetti, editors,</editor>
<location>Clevedon, UK,</location>
<contexts>
<context position="2050" citStr="Okada, 2005" startWordPosition="296" endWordPosition="297">ies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of listening errors can guide teachers and curriculum development just as written production errors do. Listening error data may also be helpful for improving technologies for listening training tools, by helping prioritize the most critical pairs of phonemes for discriminat</context>
</contexts>
<marker>Okada, 2005</marker>
<rawString>Takeshi Okada. 2005. Spelling errors made by Japanese EFL writers: with reference to errors occurring at the word-initial and word-final positions. In Vivian Cook and Benedetta Bassetti, editors, Second language writing systems, Multilingual Matters, Clevedon, UK, pages 164– 183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Prince</author>
</authors>
<title>Writing it down: Issues relating to the use of restitution tasks in listening comprehension.</title>
<date>2012</date>
<journal>TESOL Journal,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="2350" citStr="Prince, 2012" startWordPosition="336" endWordPosition="337">their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater understanding (and improvement) of learners’ writing skills. However, another important aspect of language learning is listening comprehension (cf. Field, 2008; Prince, 2012). A better understanding of listening errors can guide teachers and curriculum development just as written production errors do. Listening error data may also be helpful for improving technologies for listening training tools, by helping prioritize the most critical pairs of phonemes for discrimination, and pointing out the most troublesome contexts for phoneme discrimination. Finally, spell correction specifically designed to correct listening errors may aid listening comprehension and vocabulary acquisition. If learners are unable to hear, recall and record accurately what they heard, they w</context>
</contexts>
<marker>Prince, 2012</marker>
<rawString>Peter Prince. 2012. Writing it down: Issues relating to the use of restitution tasks in listening comprehension. TESOL Journal, 3(1):65–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chetan Ramaiah</author>
<author>Arti Shivram</author>
<author>Venu Govindaraju</author>
</authors>
<title>A Baysian framework for modeling accents in handwriting.</title>
<date>2013</date>
<booktitle>In 12th International Conference on Document Analysis and Recognition (ICDAR). http://ieeexplore.ieee.org/xpls/abs_ all.jsp?arnumber=6628752.</booktitle>
<contexts>
<context position="20469" citStr="Ramaiah et al., 2013" startWordPosition="3195" endWordPosition="3198">mic discrimination training, such as Michael et al. (2013). Cf. Bradlow (2008) for a review. Since the participants handwrote their responses, the corpus contains, as a byproduct, a set of 16,329 words in non-native handwriting and their digital transcriptions. As Alfaifi and Atwell (2013) note, this could be used as a corpus of nonnative handwriting for training or evaluating OCR on L2 Arabic script. If corresponding native transcriptions of the same (or similar) strings were obtained, the corpus could also be used to differentiate native from non-native handwriting (cf. Farooq et al., 2006; Ramaiah et al., 2013). 6 Limitations and future work The corpus as it currently stands has some limitations worth noting. First, there is no control set of native Arabic listeners to provide a comparison point for distinguishing non-native perceptual errors from acoustic errors that even native speakers are subject to. Second, the survey does not contain proficiency ratings (except self-report) for the participants, making direct correlation of particular confusion patterns with proficiency level more difficult. Statistical analysis of the participants’ accuracy at distinguishing Arabic consonants is currently und</context>
</contexts>
<marker>Ramaiah, Shivram, Govindaraju, 2013</marker>
<rawString>Chetan Ramaiah, Arti Shivram, and Venu Govindaraju. 2013. A Baysian framework for modeling accents in handwriting. In 12th International Conference on Document Analysis and Recognition (ICDAR). http://ieeexplore.ieee.org/xpls/abs_ all.jsp?arnumber=6628752.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Anton Rytting</author>
<author>Paul Rodrigues</author>
<author>Tim Buckwalter</author>
<author>David M Zajic</author>
<author>Bridget Hirsch</author>
<author>Jeff Carnes</author>
<author>Nathanael Lynn</author>
<author>Sarah Wayland</author>
<author>Chris Taylor</author>
<author>Jason White</author>
<author>Charles Blake</author>
<author>Evelyn Browne</author>
<author>Corey Miller</author>
<author>Tristan Purvis</author>
</authors>
<title>Error correction for Arabic dictionary lookup.</title>
<date>2010</date>
<booktitle>In Seventh International Conference on Language Resources and Evaluation (LREC 2010).</booktitle>
<location>Valletta,</location>
<contexts>
<context position="7446" citStr="Rytting et al., 2010" startWordPosition="1125" endWordPosition="1128">us fills the current gap in non-native spelling error corpora, and particularly for spelling errors due to listening difficulties. Unlike error corpora collected from non-native Arabic writing samples, it is designed to elicit spelling errors arising from perceptual errors; it provides more naturalistic data than is typical in phoneme identification or confusion studies. A principal purpose for creating the corpus was to aid in the development and evaluation of tools for detecting and correcting listening errors to aid in dictionary lookup of words learners encountered in spoken language (cf. Rytting et al., 2010). As such, it serves as a complementary dataset for the dictionary search engine’s query logs, since in this case the intended target of each transcription is known (rather than having to be inferred, in the case of query logs). We list three other potential uses for this corpus in Section 5. 4 Corpus Design and Creation The ArCADE corpus was created through an elicitation experiment, similar in structure to an American-style spelling test. The principal difference (other than the language) is that in this case, the participants are expected to be unfamiliar with the words, and thus forced to </context>
</contexts>
<marker>Rytting, Rodrigues, Buckwalter, Zajic, Hirsch, Carnes, Lynn, Wayland, Taylor, White, Blake, Browne, Miller, Purvis, 2010</marker>
<rawString>C. Anton Rytting, Paul Rodrigues, Tim Buckwalter, David M. Zajic, Bridget Hirsch, Jeff Carnes, Nathanael Lynn, Sarah Wayland, Chris Taylor, Jason White, Charles Blake, Evelyn Browne, Corey Miller, and Tristan Purvis. 2010. Error correction for Arabic dictionary lookup. In Seventh International Conference on Language Resources and Evaluation (LREC 2010). Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abhinav Sethy</author>
<author>Shrikanth Narayanan</author>
<author>Nicolaus Mote</author>
<author>W Lewis Johnson</author>
</authors>
<title>Modeling and automating detection of errors in Arabic language learner speech.</title>
<date>2005</date>
<booktitle>In INTERSPEECH-2005.</booktitle>
<pages>177--180</pages>
<contexts>
<context position="5917" citStr="Sethy et al. (2005)" startWordPosition="891" endWordPosition="894">pelling errors are also observed, but relatively rarely, and the relevance of these spelling errors to listening competence is unclear. Hence, while they are likely to be useful for many applications in teaching Arabic writing, their usefulness for other purposes, such as examining listening skills and the effects of learner phonology on spelling, is limited. Corpora or datasets focused on speaking and listening skills in Arabic are rarer. One such corpus, the West Point Arabic Speech Corpus, available from the LDC, contains one hour of non-native (learner) speech (LaRocca and Chouairi, 2002) Sethy et al. (2005) describe a corpus of elicited Arabic speech, but because none of the participants had prior exposure to Arabic, its use for un1Available from http://l2arabiccorpus.cercll. arizona.edu/?q=homepage. 2As of February 2014, a second version, with about 130K words from non-native speakers, is available from http: //www.arabiclearnercorpus.com/. It also has a small (three hour) speech component. derstanding learner Arabic is limited. While there have been a few studies of Arabic listening skills (e.g. Huthaily, 2008; Faircloth, 2013), their coverage was not sufficiently broad to make reuse of their </context>
</contexts>
<marker>Sethy, Narayanan, Mote, Johnson, 2005</marker>
<rawString>Abhinav Sethy, Shrikanth Narayanan, Nicolaus Mote, and W. Lewis Johnson. 2005. Modeling and automating detection of errors in Arabic language learner speech. In INTERSPEECH-2005. pages 177–180.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Noah H Silbert</author>
<author>C Anton Rytting</author>
<author>Paul Rodrigues</author>
<author>Tim Buckwalter</author>
<author>Valerie Novak</author>
<author>Mohini Madgavkar</author>
<author>Katharine Burk</author>
</authors>
<title>and Aric Bills. in preparation. Similarity and bias in non-native Arabic consonant perception.</title>
<marker>Silbert, Rytting, Rodrigues, Buckwalter, Novak, Madgavkar, Burk, </marker>
<rawString>Noah H. Silbert, C. Anton Rytting, Paul Rodrigues, Tim Buckwalter, Valerie Novak, Mohini Madgavkar, Katharine Burk, and Aric Bills. in preparation. Similarity and bias in non-native Arabic consonant perception.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Warschauer</author>
<author>Paige Ware</author>
</authors>
<title>Automated writing evaluation: Defining the classroom research agenda.</title>
<date>2006</date>
<journal>Language Teaching Research,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="1581" citStr="Warschauer and Ware, 2006" startWordPosition="227" endWordPosition="230">n-native speakers. The corpus may be useful to instructors of Arabic as a second language, and researchers who study second language phonology and listening perception. 1 Introduction Learner corpora have received attention as an important resource both for guiding teachers in curriculum development (Nesselhauf, 2004) and for providing training and evaluation material the development of tools for computer-assisted language learning (CALL). One of the most commonly used technologies in CALL is spell correction. Spell correction is used for providing automated feedback to language learners (cf. Warschauer and Ware, 2006), automatic assessment (Bestgen and Granger, 2011), and in providing cleaner input to downstream natural language processing (NLP) tools, thereby improving their performance (e.g. Nagata et al., 2011). However, off-the-shelf spell correctors developed for native speakers of the target language are of only limited use for repairing language learners’ spelling errors, since their error patterns are different (e.g. Hovermale, 2011; Mitton and Okada, 2007; Okada, 2005). Most learner corpora (and spell correctors) are understandably focused on learner-written texts. Thus, they allow a greater under</context>
</contexts>
<marker>Warschauer, Ware, 2006</marker>
<rawString>Mark Warschauer and Paige Ware. 2006. Automated writing evaluation: Defining the classroom research agenda. Language Teaching Research, 10(2):157–180.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>