<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.4756552">
The error-driven ranking model of the acquisition of phonotactics:
how to keep the faithfulness constraints at bay
Giorgio Magri
SFL (CNRS and University of Paris 8)
UiL OTS (Utrecht University)
</note>
<email confidence="0.995593">
magrigrg@gmail.com
</email>
<sectionHeader confidence="0.994718" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961611111111">
A problem which arises in the theory of
the error-driven ranking model of the ac-
quisition of phonotactics is that the faith-
fulness constraints need to be promoted
but should not be promoted too high. This
paper motivates this technical problem and
shows how to tune the promotion compo-
nent of the re-ranking rule so as to keep the
faithfulness constraints at bay.
Sections 1-2 introduce the algorithmic frame-
work considered in the paper, namely the error-
driven ranking model of the acquisition of phono-
tactics. Section 3 motivates a specific problem
which arises in the design and analysis of this
model, namely the problem of controlling the
height reached by the faithfulness (F) constraints.
Sections 4-6 sketch the theory of F-controlling.
Magri (2014a) presents the theory in more detail.
</bodyText>
<sectionHeader confidence="0.908457" genericHeader="method">
1 The acquisition of phonotactics
</sectionHeader>
<bodyText confidence="0.999948970588235">
Generative linguistics assumes that the learner is
provided with a typology of grammars G1, G2...
The language-learning problem thus consists of
individuating the target adult grammar G* within
the typology, on the basis of a finite set of data
generated by that grammar. Various formulations
of this problem differ for the structural assump-
tions about the underlying typology, for the type
of data fed to the learner, and for the criteria of
success used to evaluate the grammar Gˆ chosen
by the learner relative to the target grammar G*.
In this paper, I focus on the following spe-
cific formulation of this general language learn-
ing problem. The typology consists of the phono-
logical grammars defined in Optimality Theoretic
(OT) terms through the rankings of a given set of
constraints (Prince and Smolensky, 2004). The
data fed to the learner consist of surface forms
sampled from the language L* generated by the
target OT grammar G*, namely the set of surface
forms which are the phonological realizations of
some underlying forms according to G*. The cri-
teria for success is that the OT grammar Gˆ chosen
by the learner generates a language Lˆ which coin-
cides with the target one: Lˆ = L*.
This specific formulation is called the problem
of the acquisition of phonotactics. In fact, phono-
tactics is the knowledge of the distinction between
licit and illicit forms. Assuming that the distinc-
tion is categorical (Gorman, 2013), knowledge of
phonotactics reduces to knowledge of the set of
licit forms (the set of illicit forms is just the com-
plement). And the set of licit forms relative to an
OT grammar G is the corresponding language LG.
</bodyText>
<sectionHeader confidence="0.987504" genericHeader="method">
2 The EDRA model
</sectionHeader>
<bodyText confidence="0.878836888888889">
In this paper, I focus on a specific algorithmic ap-
proach to the problem of the acquisition of phono-
tactics, based on error-driven ranking algorithms
(EDRAs). This approach is summarized below
and explained in the rest of this section.
Algorithm 1 The EDRA model
Initialize
the ranking values of F constraints to zero
the ranking values of M constraints to θinit &gt;0
</bodyText>
<sectionHeader confidence="0.749622" genericHeader="method">
Repeat
</sectionHeader>
<bodyText confidence="0.930191181818182">
1 get a surface form [y] from the target language
2 pick a loser form [z]
3 check whether the current ranking vector 0 is
consistent with the underlying/winner/loser
form triplet (/y/, [y], [z])
4 if it isn’t, update the current ranking vector 0
until no more mistakes are made at step 3
The EDRA model maintains a current hypothe-
sis of the target adult grammar, namely a current
constraint ranking. This ranking is represented nu-
merically through a ranking vector 0 = (θ1, , θn)
</bodyText>
<page confidence="0.986262">
10
</page>
<note confidence="0.7867795">
Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 10–18,
Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999954542857143">
which assigns to each constraint Ck a numerical
ranking value Ok. A constraint Ck is ranked above
another constraint Ch according to a ranking vec-
tor 0 provided the ranking value Ok of the former
is (strictly) larger than the ranking value Oh of the
latter (Boersma, 1998; Boersma, 2009).
The current ranking (vector) is initialized in
such a way that the corresponding initial language
is as small as possible. OT constraints come in two
varieties: faithfulness (F) and markedness (M)
constraints. A smallest language corresponds to
a ranking which assigns all F constraints under-
neath all M constraints. Thus, the F constraints
are assigned a small initial ranking value, say zero
for concreteness; and the M constraints start with
a large positive initial ranking value Oinit &gt; 0. The
algorithm then loops through the three steps 1-4.
At step 1, the EDRA model receives a piece of
data, namely a surface form [y] sampled from the
target language L∗. Assuming that the underly-
ing typology satisfies Tesar’s (2013) Surface Ori-
entedness Condition, this piece of data provides
evidence that the target grammar G∗ maps this
phonological form (construed as the underlying
form /y/) into itself (construed as the surface form
[y]) rather than reducing it to some non-faithful
candidate [z] (as a mnemonic, I strike out a candi-
date construed as a loser). In other words, the tar-
get adult ranking (vector) 0∗ is consistent with the
underlying/winner/loser form triplet (/y/, [y], [z])
for any loser [z], namely it satisfies condition (1).
Here, W (L) is the set of winner-preferring (loser-
preferring) constraints, namely those which assign
less (more) violations to the faithful mapping of
/y/ to [y] than to the neutralization of /y/ to [z].
</bodyText>
<equation confidence="0.6664015">
O∗k &gt; max O∗h
Ch∈L
</equation>
<bodyText confidence="0.99911464516129">
This consistency condition (1) says that there is
at least a winner-preferring constraint which is
ranked above all loser-preferring constraints by
the target ranking (vector) 0∗ = (O∗1, ... , O∗n).
At steps 2 and 3, the EDRA model thus picks
a specific loser [z] and checks whether its cur-
rent ranking vector 0 satisfies the corresponding
consistency condition (1). Failure to satisfy this
condition means that the current ranking values
of the loser-preferring (winner-preferring) con-
straints are too large (too small). The algorithm
thus promotes the winner-preferring constraints
by a small promotion amount and demotes the
loser-preferring constraints by a small demotion
amount. What matters is not the actual values of
the promotion and demotion amounts, but rather
their ratio. Thus, the demotion amount can be
set equal to 1 for concreteness, letting instead the
promotion amount be equal to an arbitrary non-
negative constant p ≥ 0, as in (2).
(2) a. Increase the ranking value of each winner-
preferring constraint by p ≥ 0;
b. decrease the ranking value of each undom-
inated loser-preferring constraint by 1.
Crucially, not all loser-preferring constraints are
demoted by (2b), but only those that need to be
demoted, namely the undominated ones (Tesar and
Smolensky, 1998), whose current ranking value is
at least as large as the ranking value of all winner-
preferring constraints and thus are responsible for
flouting the consistency condition (1).
</bodyText>
<sectionHeader confidence="0.977447" genericHeader="method">
3 The problem of F-control
</sectionHeader>
<bodyText confidence="0.99998525">
The crucial implementation parameter of the
EDRA model is the promotion amount p ≥ 0 used
in the promotion component (2a) of the re-ranking
rule. How should this parameter be tuned so as to
optimize the performance of the EDRA model of
the acquisition of phonotactics? This section ex-
plains how this question leads to the problem of
controlling the height of the F constraints.
</bodyText>
<subsectionHeader confidence="0.999776">
3.1 Some initial guarantees
</subsectionHeader>
<bodyText confidence="0.999986363636364">
The problem of the acquisition of phonotactics
in OT is intractable: no algorithm can solve effi-
ciently an arbitrary instance of the problem cor-
responding to an arbitrary constraint set (Magri,
2013a). Prompted by this intractability result, Ma-
gri (2013b) starts to tackle the problem by looking
at a class of “easy” cases.
The intuitive idea is that the relative ranking
of the F constraints might often be irrelevant for
phonotactics, namely for drawing the line between
licit and illicit forms (although it is of course al-
ways crucial for phonology, namely for the spe-
cific way in which illicit forms are repaired). This
intuition that the relative ranking of the F con-
straints is not relevant to describe a certain phono-
tactic pattern can be formalized as follows. A
partial constraint ranking is any partial order on
the constraint set. A partial ranking generates
a language provided each one of its total refine-
ments generates that language in the usual OT
sense (Yanovich, 2012). A language is called F-
irrelevant provided it can be generated in this tech-
</bodyText>
<equation confidence="0.797748">
(1) max
Ck∈W
</equation>
<page confidence="0.990053">
11
</page>
<bodyText confidence="0.997795918918919">
nical sense by a partial ranking which does not
rank any two F constraints relative to each other
(see subsection 3.2 for an example).
Suppose that the EDRA model is trained on a
target language L∗ which is F-irrelevant. The
M constraints start out high, with an initial rank-
ing value Oinit usually larger than the number m
of markedness constraints. The F constraints in-
stead start out low, with a null initial ranking
value. Throughout learning, the F constraints will
raise, if the algorithm adopts a non-null promotion
amount p &gt; 0. Theorem 1 provides guarantees
that the EDRA model learns the target phonotac-
tics, as long as the F constraints don’t raise too
high, namely their ranking values remain smaller
by at least m than the initial ranking value Oinit of
the M constraints, as stated in (3).
Theorem 1 Suppose that the underlying OT ty-
pology satisfies the following two assumptions.
First, if a surface form [y] is a non-faithful candi-
date of an underlying form /x/, then there exists
at least one faithfulness constraint which assigns
at least one violation to the mapping of /x/ into
[y] (F-discernibility assumption). Second, a form
[y] is a candidate of an underlying form /x/ if and
only if the latter form construed as the surface
form [x] is vice versa a candidate of the former
form construed as the underlying form /y/ (sym-
metric candidacy assumption). Consider a lan-
guage in this OT typology which is F-irrelevant.
Suppose that the EDRA model only makes a fi-
nite number of errors and then converges to a fi-
nal ranking vector which is never updated again.
Suppose furthermore that the ranking value OF of
any F constraint F at any time in the run satisfies
condition (3), where m is the number of M con-
straints and Oinit &gt; m their initial ranking value.
</bodyText>
<listItem confidence="0.889994">
(3) OF G Oinit − m
</listItem>
<bodyText confidence="0.999820952380952">
Then, the language generated by (an arbitrary re-
finement of) the final ranking vector learned by the
EDRA model coincides with the target language
the EDRA model has been trained on. ■
The two assumptions of F-discernibility and
symmetric candidacy required by theorem 1 are
extremely mild. Magri (2013b; 2014b) conjec-
tures that the relative ranking of the faithfulness
constraints turns out to matter for phonotactics
only in very special configurations, so that the
F-irrelevancy assumption might plausibly hold in
the vast majority of cases. Theorem 1 thus pro-
vides guarantees that the EDRA model succeeds
at the problem of the acquisition of phonotactics
in a large class of cases under two crucial assump-
tions. One assumption is that it can only make a
finite number of errors before it converges to a fi-
nal ranking which is consistent with any form and
thus never updated. The other assumption is the
condition (3) that the height of the F-constraints
can be properly controlled.
</bodyText>
<subsectionHeader confidence="0.999921">
3.2 Some examples
</subsectionHeader>
<bodyText confidence="0.999984294117647">
To illustrate the issues raised by convergence and
F-control, consider the following OT typology.
The set of forms consists of only four forms
{apsa, apza, absa, abza}. The faithfulness con-
straints are the two identity constraints for voicing
in stops and fricatives (F1, F2). The markedness
constraints are the two corresponding constraints
against stop and fricative voicing (M1, M2) plus
an additional constraint M which bans sequences
of stops and fricatives which agree in voicing,
namely it is violated by the two forms apsa and
abza. The candidacy relation is total: the four
forms are all candidates of each other.
The OT typology just described contains in par-
ticular the language L = {[absa], [apza]}. This
language is generated by any ranking which satis-
fies the ranking conditions (4).
</bodyText>
<equation confidence="0.979241666666667">
(4) M
F2 F1
M1 M2
</equation>
<bodyText confidence="0.999440727272727">
These ranking conditions (4) say nothing about the
relative ranking of the two F constraints F1 and
F2. The language L thus qualifies as F-irrelevant.
When trained on this language, the EDRA
model will be provided at step 1 with a sequence
of the two licit forms [absa] and [apza]. It will then
complete them into an underlying/winner/loser
form triplet at steps 2 and 3 by assuming a faith-
ful underlying form and a non-faithful loser form.
The list of all possible such triplets that the algo-
rithm can consider is provided in (5).
</bodyText>
<equation confidence="0.886782333333333">
(5) F1 F2 M1 M2 M
⎡
(/absa/, [absa], [apsa]) W e
(/absa/, [absa], [abza]) e W
⎢ ⎢
(/absa/, [absa], [apza]) W W
⎢ ⎢
(/apza/, [apza], [abza]) W e
⎢ ⎢
(/apza/, [apza], [apsa]) e W
⎣
(/apza/, [apza], [absa]) W W
L e
e W
L W
W e
e L
W L
⎤W
⎥
W ⎥
e ⎥ ⎥ ⎥
W ⎥
W ⎦e
</equation>
<page confidence="0.938412">
12
</page>
<bodyText confidence="0.998507181818182">
Each triplet is described here in ERC notation
(Prince, 2002): constraints which are winner- or
loser-preferring or even relative to a triplet are
marked with a corresponding W or L or e.
The triplets where the constraint M is winner-
preferring will trigger virtually no update, since
that constraint starts high and is never demoted,
and will thus always ensure consistency with those
triplets. The learning run is thus driven by the two
remaining triplets, boldfaced in (5), which I as-
sume are fed one after the other to the algorithm.
Suppose the promotion amount is non-null, say
equal to the demotion amount: p = 1. The re-
sulting learning run is described in (6).
The two F constraints end up too high, namely
with a final ranking value θF1 = θF2 = 6 which
is larger than the initial ranking value θinit = 5
of the M constraints. And indeed the EDRA has
failed at learning the target phonotactics: since the
F constraints are ranked at the top, the model has
incorrectly learned that any form is licit.
A trivial strategy to enforce the F-control con-
dition (3) would be to threshold the promotion
component (2a) of the re-ranking rule, as in (2a&apos;).
(2) a&apos;. Increase the ranking value of each
winner-preferring constraint by p, except
for an F constraint which is already
close to the forbidden threshold θinit−m.
Yet, suppose we tried to remedy to the failure
in (6) by thresholding the promotions as in (2a&apos;).
When an F constraint reaches the height θinit −
m = 5 − 3 = 2, we stop promoting it, as bold-
faced in the learning run (7).
</bodyText>
<equation confidence="0.8029568">
⎤ ⎡ 1 ⎤
1
⎦⎥ → ⎢ ⎣4 ⎦ ⎥
6
5
</equation>
<bodyText confidence="0.999975875">
In this run, the constraint M stays put at its initial
position. The constraints M1 and M2 oscillate up
and down, because promoted and demoted by the
two boldfaced triplets in (5). The constraints F1
and F2 raise a bit until they hit the threshold, and
then settle. The EDRA model will thus keep mak-
ing mistakes forever, without ever converging to a
ranking vector consistent with the data.
</bodyText>
<subsectionHeader confidence="0.999163">
3.3 Against a null promotion amount
</subsectionHeader>
<bodyText confidence="0.999993916666667">
These difficulties with convergence and the F-
control condition (3) would disappear if the pro-
motion amount p was set equal to zero, so that
the EDRA performs no constraint promotion at
all. In fact, Tesar and Smolensky (1998) guarantee
convergence for the demotion-only case. And the
F constraints could not possibly be promoted too
high, as they would not be promoted at all.
Unfortunately, the option of a null promotion
amount is not viable, as argued in Magri (2012;
2014b). In fact, recall that the EDRA model at
step 3 always considers underlying/winner/loser
form triplets (/y/, [y], [z]) which have an underly-
ing form /y/ faithful to the winner [y]. This means
that the F constraints are never loser-preferring
and are therefore never demoted. If the promotion
amount is set equal to zero, then they will not be
promoted either. In the end, the F constraints will
thus never be re-ranked. This hampers the ability
of the EDRA model to learn the correct relative
ranking of the F constraints when trained on a F-
relevant language, namely when it needs to learn a
phonotactic pattern which crucially does require a
specific relative ranking of the F constraints.
</bodyText>
<subsectionHeader confidence="0.998876">
3.4 Convergence through calibration
</subsectionHeader>
<bodyText confidence="0.999153571428572">
As recalled above, Tesar and Smolensky (1998)
show that the EDRA model converges when the
promotion amount is null and the algorithm per-
forms only constraint demotion. It could in princi-
ple be the case that convergence does not extend to
the demotion/promotion case, because any amount
of promotion disrupts convergence. But Magri
(2012) shows that is not the case: convergence ex-
tends to EDRAs which perform constraint promo-
tion as well, as long as the promotion amount is
small enough. In particular, consider a promotion
amount p which scales as in (8) with the numbers
` and w of currently undominated loser-preferring
constraints and of winner-preferring constraints.
</bodyText>
<listItem confidence="0.358835">
`
(8) p = w + σ
</listItem>
<bodyText confidence="0.99865675">
It turns out that the EDRA model converges ef-
ficiently if (and only if) the promotion amount
is calibrated, namely has the shape in (8) corre-
sponding to some strictly positive calibration con-
stant σ &gt; 0. The larger the calibration constant σ,
the smaller the promotion amount. The case of a
null promotion amount corresponds to the limiting
case σ = ∞.
</bodyText>
<figure confidence="0.9968085">
(6) ⎡
F1 0
F2 0
M15
⎢ ⎣
M2 5
M 5
⎤ ⎡ 1 ⎤
1
⎦⎥ → ⎢ ⎣4 ⎦ ⎥
6
5
⎡ ⎤ ⎡4 ⎤
3
→ ⎢3 ⎥
⎣4
4⎦⎥→5
⎣ ⎦
6 5
5 5
⎡ 2 ⎤
2
→ ⎢ ⎣5 ⎦ ⎥
5
5
⎡ 5 ⎤
5
→ ⎢ ⎣4 ⎦ ⎥
6
5
→ ⎢ ⎥
6
6
5
5
5
⎡ ⎤
⎣ ⎦
⎡ 2 ⎤ ⎡ 2 ⎤ ⎡ 2 ⎤ ⎡ 2 ⎤ ⎡ 2 ⎤ . . .
2 2 2 2 2
→ ⎢ ⎣5 ⎦ ⎥ → ⎢ ⎣4 ⎦ ⎥ → ⎢ ⎣5 ⎦ ⎥ → ⎢ ⎣4 ⎦ ⎥ → ⎢ ⎣5 ⎦ ⎥
5 6 5 6 5
5 5 5 5 5
(7) ⎡
F1 0
F2 0
M15
⎢ ⎣
M2 5
M 5
</figure>
<page confidence="0.975196">
13
</page>
<subsectionHeader confidence="0.934556">
3.5 F-control through calibration as well
</subsectionHeader>
<bodyText confidence="0.999993916666667">
Let’s take stock. Theorem 1 provides some ini-
tial guarantees of success of the EDRA model of
the acquisition of phonotactics. These guarantees
hold under two crucial assumptions: convergence
and the F-control condition (3). Do these assump-
tions hold when the promotion amount is non-
null? Convergence does hold, if the promotion
amount, although not null, is nonetheless small,
namely calibrated as in (8). What about the F-
control condition (3)? Can we play the same trick
of a small promotion amount? Or is it the case
that, no matter how small the promotion amount,
as soon as it is allowed to be non-null, the F con-
straints raise too high through a long sequence of
very small promotions? Section 4 shows that the
latter scenario can never arise: the F constraints
can never raise too high if the promotion amount
is small enough. More precisely, it assumes a cal-
ibrated promotion amount as in (8). And it shows
that the F-control condition (3) holds when the
calibration constant σ is large enough, namely it
grows as the number m of M constraints.
As the calibration constant increases as the
number m of markedness constraints, the promo-
tion amount decreases quickly. Is it possible to
improve on the analysis of section 4 and guaran-
tee the F-control condition (3) with a calibration
constant σ which does not grow with the number
m of markedness constraints? Unfortunately, sec-
tion 5 shows that the calibration constant must in-
crease with m. More precisely, this section con-
siders the very simple case where there is a single
F constraint and where the M constraints are al-
ways loser-preferring (or even) but never winner-
preferring. In this case, the F-control condition
fails if the calibration constant σ does not grow
</bodyText>
<equation confidence="0.781454">
with m at least as m
log m.
</equation>
<bodyText confidence="0.761996">
Interestingly, the derivative of the function m
</bodyText>
<equation confidence="0.546327">
log m
</equation>
<bodyText confidence="0.999916416666667">
goes to zero as m grows. In other words, although
the function increases with m, the rate of increase
becomes smaller and smaller, making this func-
tion as close as possible to a constant. Is this par-
ticularly favorable choice of the calibration con-
stant only possible in the peculiar case considered
in section 5? or does this favorable choice of the
calibration constant ensure F-calibration also in
the general case? Section 6 shows how to relax at
least one of the two restrictive assumptions made
in section 5, namely the assumption that the M
constraints are never winner-preferring.
</bodyText>
<sectionHeader confidence="0.730698" genericHeader="method">
4 F-controlling with a non-null
promotion amount
</sectionHeader>
<bodyText confidence="0.9999727">
The most basic question of the theory of F-control
is as follows: is it possible to guarantee the F-
control condition (3) despite a non-null promotion
amount? This section provides a positive answer
to this question. In particular, assume the promo-
tion amount p is calibrated as in (8), through the
calibration constant σ. The F-control condition
then holds provided the calibration constant σ sat-
isfies the bound (9), where m is the number of M
constraints and θinit is their initial ranking value.
</bodyText>
<equation confidence="0.9820185">
2m + mθinit
(9) σ ≥ θinit − m
</equation>
<bodyText confidence="0.999378666666667">
To get a sense of the bound (9), assume that the
initial ranking value θinit of the M constraints is
some power of the number m of M constraints:
</bodyText>
<equation confidence="0.791251">
θinit =
becomes m mk−1−1, which is approximately m.
</equation>
<bodyText confidence="0.99192995">
At each update, each of the ` currently undom-
inated loser-preferring constraints is demoted by
1 and each of the w winner-preferring constraints
is promoted by p. Because of the specific shape
(8) of the promotion amount p, the sum of the
current ranking values decreases by ` − wp =
w+σ . And the latter is at least σ
`σ w+σ ,
as every update requires at least one undominated
loser-preferring constraint, namely ` ≥ 1. Let αi
be the number of updates triggered by the ith ERC
in the run considered up to the time considered
(note that there is only a finite number of ERCs
relative to a finite number of constraints). Thus,
the sum Ek θk of the current ranking values has
overall decreased by at least Ei αi σ
w +σ relative
to the the sum Ek θinit
k of the initial ranking val-
ues, as stated in (10).
</bodyText>
<equation confidence="0.9294438">
�
θinit −
k
i
The sum Ek θinit
</equation>
<bodyText confidence="0.9840344">
k of the initial ranking values
can be computed explicitly as in (11), as the m
M constraints start with the initial ranking value
θinit while the F constraints start with a null initial
ranking value.
</bodyText>
<listItem confidence="0.790969">
� θinit = m θinit
(11) k
k
</listItem>
<bodyText confidence="0.838847666666667">
The sum Ek θk of the current ranking values can
be lower bounded as in (12).
mk for some k &gt; 1. The bound (9) thus
</bodyText>
<equation confidence="0.9584855">
k+2
` − w`
w+σ
(10) � θk ≤ �
k k
σ
αi
wi + σ
14
X
(a)
θk =
k F M
≥ 0 + X θM
M
&gt; 0 + m(−2) = −2m
</equation>
<bodyText confidence="0.999951592592593">
In step (11a), I have split the sum over all con-
straints into the sum over the faithfulness and the
markedness constraints. In step (11b), I have noted
that the ranking value θF of any faithfulness con-
straint F is always at least as large as 0. In fact,
the faithfulness constraints start with a null ini-
tial ranking value and are never demoted, because
the EDRA model always assumes an underlying
form faithful to the winner, so that the faithful-
ness constraints are never loser-preferring. In step
(11c), I have noted that the ranking value θM of
a markedness constraint M can never get smaller
than −2. In fact, suppose by contradiction that M
managed to be demoted that low. That would im-
ply that some ERC triggers an update that demotes
M despite the fact that its current ranking value
is strictly smaller than 0. And that is impossible.
In fact, at least one faithfulness constraint F must
be winner-preferring relative to that ERC, because
of the F-discernibility assumption. Furthermore,
that constraint F must already dominate M, be-
cause F has a non-negative current ranking value
while M has a negative current ranking value.
Using the expressions for the sum of the ini-
tial and the current ranking values obtained in (11)
and (12) respectively, the original inequality (10)
yields the bound in (13).
</bodyText>
<equation confidence="0.974929333333333">
2m + mθinit
αi
σ
</equation>
<bodyText confidence="0.6165755">
The ranking value θF of a generic faithfulness
constraint F can now be bound as in (14).
</bodyText>
<equation confidence="0.988626333333333">
(14) θF
σ
(c) ≤ θinit − m
</equation>
<bodyText confidence="0.995203037037037">
In step (14a), I have used the fact that the faithful-
ness constraint F starts with a null initial ranking
value and is promoted by w.+σ for each one of the
z
αi updates triggered by the ith ERC, as long as F
is winner-preferring relative to that ERC. In step
(14b), I have used the bound computed in (13).
And in step (14c), I have used the choice (9) of the
calibration constant σ.
The bound obtained in (14) guarantees that
the generic faithfulness constraint F never raises
above the forbidden threshold θinit −m, thus com-
plying with the F-control condition (3). In other
words, we have obtained the following sufficient
solution to the problem of F-controlling.
Theorem 2 Suppose the underlying typology sat-
isfies the F-discernibility assumption. Consider a
run of the EDRA model on an arbitrary language
in that typology. Assume that the F constraints
start out with a null initial ranking value while the
m M constraints start out with an initial rank-
ing value θinit &gt; m. Assume furthermore that the
promotion amount is calibrated as in (8) and that
the calibration constant σ is large enough to sat-
isfy the bound (9). Then, the ranking values of the
F constraints remain smaller than the forbidden
threshold θinit − m throughout the entire run. ■
</bodyText>
<sectionHeader confidence="0.731765" genericHeader="method">
5 F-controlling on the diagonal case
</sectionHeader>
<bodyText confidence="0.998448689655172">
The preceding section has established the F-
control condition (3) when the promotion amount
is not null, provided it is small enough, namely it
corresponds to a calibration constant which grows
as the number m of M constraints. Is it possible to
do better? In particular, is it possible to guarantee
F-control when the calibration constant does not
increase with m? This section sketches a coun-
terexample which provides a negative answer to
this question; see Magri (2014a) for details.
At every iteration, the EDRA model receives
a winner form sampled from the target language,
assumes a corresponding faithful underlying form
and picks a corresponding loser candidate. At ev-
ery iteration, the model thus constructs an under-
lying/winner/loser form triplet, which can be de-
scribed in terms of the corresponding ERC, as ex-
emplified in (5) above. Since there are only a finite
number of ERCs corresponding to a finite number
of constraints, the ERCs considered in a run of the
model can be stacked one on top of the other into
an input ERC matrix.
Without loss of generality, assume that each
input ERC has a unique loser-preferring con-
straint. Next, let me make two crucial assump-
tions. First, assume that the constraint set contains
a single faithfulness constraint F – plus of course
a certain number m of markedness constraints
M1, ... , Mm. Second, assume that M1, ... , Mm
</bodyText>
<equation confidence="0.976127642857143">
X
(12)
θF + X θM
X
(13)
i
1
&lt;
wi + σ
(a) X αi 1
≤
i
wi + σ
&lt; 2m + mθinit
</equation>
<page confidence="0.969192">
15
</page>
<figureCaption confidence="0.998883">
Figure 1: First three stages of the learning dynamics where each diagonal ERC is fed persistently in turn
</figureCaption>
<figure confidence="0.998202741935484">
M4, , Mm
ERC 1 ERC 2 ERC 3
M1
F
M2
M3
27
4 θinit
ERC 1
ERC 1 ERC 2
θinit
θinit/3
0
M2, , Mm
M1
F
M3, , Mm
M2
M1
F
θinit
2 θinit
9
1 θinit
3
0
θinit
2 θinit
9
θinit/3
0
</figure>
<figureCaption confidence="0.459130333333333">
are either loser-preferring or even in the input
ERCs, but never winner-preferring. The input
ERC matrix thus is (a subset of) the matrix (15).
</figureCaption>
<table confidence="0.9357374">
(15) F M1 ... ...
�ERC 1 W L Mm
..  |e e
.� L 1
ERC m W
</table>
<bodyText confidence="0.998438710526316">
The column corresponding to F consists of all
W’s. The entries corresponding to M1, ... , Mm
are all equal to e’s but for the diagonal of L’s. This
ERC matrix is thus called diagonal.
What is the maximum height that the constraint
F can reach in a run of the EDRA model on the
input diagonal ERC matrix (15)? To address this
question, consider the following special run. To
start, we persistently feed ERC 1 to the algorithm,
until the markedness constraint M1 is demoted
underneath the faithfulness constraint F and that
ERC cannot trigger any further update. Only at
that point, we stop feeding ERC 1 to the algo-
rithm, and persistently feed ERC 2 instead, again
until it cannot trigger any further update. Only at
that point, we stop feeding ERC 2 and persistently
feed ERC 3. And so on.
Assume that the promotion amount has the
shape (8) and suppose for concreteness that the
calibration constant is σ = 1, so that the faith-
fulness constraint is promoted by 1/2 with each
update. The dynamics of the ranking values is
depicted in Figure 1 for the first three learning
stages. Throughout stage 1, it is ERC 1 that trig-
gers updates, whereby the markedness constraint
M1 is demoted and the faithfulness constraint is
promoted by 13θ = 1
2+σ θinit, until the two con-
straints meet. Throughout stage 2, it is ERC 2 that
triggers updates, whereby the markedness con-
straint M2 is demoted and the faithfulness con-
straint is promoted by another 29θ = 1+σ
(2+σ)2θinit,
until the two constraints meet. Throughout the
generic kth stage, it is the kth ERC that trig-
gers updates, whereby the markedness constraint
Mk is demoted and the faithfulness constraint pro-
moted by an amount that turns out to be equal to
</bodyText>
<equation confidence="0.425692">
(1+σ)k−1
</equation>
<bodyText confidence="0.9885076">
(2+σ)k θinit. The height θF reached by the faith-
fulness constraint at the end of the special run con-
sidered is thus Ek 1 (12+)kk 1 θinit It turns out
that this is indeed the maximum height reacheable
by the faithfulness constraint F on any run on the
diagonal ERC matrix (15).
The F-control condition (3) thus boils down to
the inequality Ek 1 (12+� kk1θinit ≤ θinit − m
Assume that the m markedness constraints start
out with the initial ranking value θinit = mk. This
inequality can then be solved analytically yielding
σ(m) = (1 − exp {(−k log m)/m})−1. By a first
order Taylor expansion exp(x) ∼ 1+x+o(x2) of
the exponential function, the latter expression can
be approximated as in (16).
</bodyText>
<equation confidence="0.979185333333333">
m
(16) σ = σ(m) ∼
k log m
</equation>
<bodyText confidence="0.999965666666667">
The latter bound for the calibration threshold
is substantially smaller than the linear bound
σ(m) ∼ m obtained through the elementary anal-
ysis of section 6. In particular, although (16) is not
bounded as a function of m, its derivative goes to
zero as 1/ log m.
</bodyText>
<sectionHeader confidence="0.908582" genericHeader="method">
6 F-controlling when the promotion
</sectionHeader>
<bodyText confidence="0.9645605">
amount decreases slowly
The preceding section has made two restrictive as-
sumptions. First, that there is a unique F con-
straint. Second, that the M constraints are never
winner-preferring. Under these assumptions, it
has shown that the F-control condition (3) holds
when the calibration constant grows only very
slowly with m, namely as in (16). Does this favor-
able result also hold when we relax the two restric-
tive assumptions? This section shows how to relax
one of the two assumptions, namely the assump-
tion that the M constraints cannot be winner-
preferring. At this stage, I do know how to relax
the other assumption that there is a unique F con-
straint. Again, the reasoning here is only sketched;
see Magri (2014a) for details.
</bodyText>
<page confidence="0.990152">
16
</page>
<bodyText confidence="0.989629619047619">
To illustrate the core idea, suppose that the
EDRA model is trained on the input ERC matrix
(17a) and walks through the run (18a). Here, I
am assuming that the promotion amount p has the
shape in (8), with the calibration constant σ = 0
set equal to zero for concreteness.
(17)a. F M1 M2 b. F M1 M2
ERC 1 r W L e ERC 1 W L e 1
ERC 2 L W W L � ERC 2 � W e LJ
Consider the diagonal ERC matrix (17b) corre-
sponding to m = 2 markedness constraints. The
original run (18a) on the original ERC matrix
(17a) can be simulated with the run (18b) on the
diagonal ERC matrix (17b) in such a way that all
constraints end up at the same high in the two runs.
This reasoning holds in complete generality. In-
deed, under the assumption that there is a unique
F constraint but no restrictions on the M con-
straints, the input ERC matrix looks like (19).
Any run of the EDRA model on this input ERC
matrix (19) can be mimicked by a corresponding
run on the diagonal ERC matrix (15). This reduc-
tion to the diagonal case holds provided the pro-
motion amount is calibrated, namely has the shape
in (8), no matter the choice of the calibration con-
stant σ &gt; 0. This reduction fails if the promotion
amount is not calibrated.
Another crucial condition needed for the re-
duction to the diagonal case is the following: in
the original run, the markedness constraints are
allowed to raise only slightly above their initial
ranking value θinit. Indeed, if a markedness con-
straint could raise arbitrarily high above its initial
ranking value in the original run, there would be
no way to mimic that increasing ranking dynam-
ics with a derived run on the diagonal ERC ma-
trix (15), as the latter only demotes but never pro-
motes the markedness constraints. The fact that
the markedness constraints can raise by a small
amount does not threaten the reduction to the diag-
onal case, because the markedness constraints can
be assigned a slightly larger initial ranking value
in the derived run on the diagonal ERC matrix.
Fortunately, the markedness constraints
M1, ... , Mm indeed can raise above their initial
ranking value θinit only by a small amount,
namely never by more than m, as stated in (20).
(20) θ1, ... , θm :5 θinit + m
Obviously, this bound (20) holds at the beginning
of the run. It is thus sufficient to prove that this
bound is an invariant of the algorithm: if it holds
of the current ranking values at some time t − 1,
then it also holds at the subsequent time t. The
challenge is that a winner-preferring markedness
constraint M1 sitting right at θinit + m at time
t − 1 could in principle be promoted above that
forbidden threshold, so that the bound (20) would
hold at time t − 1 but fail at time t. Yet, in order
for such an update to happen, there has got to ex-
ist another constraint M2 which is loser-preferring
and is ranked at time t − 1 at least as high as
the winer-preferring constraint M1. This means
in turn that the sum θt−1
</bodyText>
<equation confidence="0.968013">
1 + θt−1
</equation>
<bodyText confidence="0.999629052631579">
2 of the two rank-
ing values of M1 and M2 at time t − 1 is at least
(θinit + m) + (θinit + m). This suggests to cope
with the difficulty just highlighted by strengthen-
ing the invariant. Not only a single ranking value
cannot get larger than θinit + m, but also the sum
of any two ranking values can never reach (θinit +
m)+(θinit+m). For instance, let’s say it can never
get larger than (θinit + m) + (θinit + m − 1). But
now again, in order to prove that the latter bound
on the sum of two ranking values holds at time t,
I need an assumption about the sum of three rank-
ing values at time t − 1. And so on. Indeed, the
sum θi1 +...+θik of the current ranking values of
any number k of different markedness constraints
Mi1, ... , Mik can be bound as in (21). This bound
holds for any promotion amount with the shape (8)
corresponding to a calibration constant σ which is
not too small, namely σ &gt; 1.
</bodyText>
<equation confidence="0.972429333333333">
k k
(21) θih :5 (θinit + m − h + 1)
h=1 h=1
</equation>
<bodyText confidence="0.942465">
For k = 1, (21) yields the desired bound (20).
</bodyText>
<sectionHeader confidence="0.996608" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.867408">
This research was supported by a Marie Curie In-
tra European Fellowship within the 7th European
</bodyText>
<figure confidence="0.998518862068965">
⎡
⎣
b. F
M1
M2
(18) a. F
M1
M2
⎡ ⎤ ⎡ ⎤ ⎡ ⎤0 ERC 1 1 ERC 1 2 C 2⎡2.5⎤ERC 2⎡3
10 9 8 ⎣8.5 ⎦ ⎣9
10 10 10 9 8
⎤
⎦
O⎤ERC 1 9 ERC 2 9 ERC 2⎡9 ⎦
10 10 9 8
(19)
F1 M1 ... Mm
...
. ..
�
W
�
L, e, W
⎤
⎦⎥
.
... ..
⎡
⎢ ⎣
</figure>
<page confidence="0.976036">
17
</page>
<sectionHeader confidence="0.8074275" genericHeader="conclusions">
Community Framework Programme.
References
</sectionHeader>
<reference confidence="0.99972274">
Paul Boersma. 1998. Functional Phonology. Ph.D.
thesis, University of Amsterdam, The Netherlands.
The Hague: Holland Academic Graphics.
Paul Boersma. 2009. Some correct error-driven ver-
sions of the constraint demotion algorithm. Linguis-
tic Inquiry, 40:667–686.
Kyle Gorman. 2013. Generative phonotactics. Ph.D.
thesis, University of Pennsylvania.
Giorgio Magri. 2012. Convergence of error-driven
ranking algorithms. Phonology, 29(2):213–269.
Giorgio Magri. 2013a. The complexity of learning in
OT and its implications for the acquisition of phono-
tactics. Linguistic Inquiry, 44.3:433468.
Giorgio Magri. 2013b. An initial result on the re-
strictiveness of the error-driven ranking model of the
early stage of the acquisition of phonotactics. In
Hsin-Lun Huang, Ethan Poole, and Amanda Rys-
ling, editors, Proceedings of NELS 43: the 43rd an-
nual meeting of the North East Linguistic Society.
Giorgio Magri. 2014a. The error-driven ranking model
of the acquisition of phonotactics: how to control the
height of the faithfulness constraints. CNRS, UiL-
OTS ms.
Giorgio Magri. 2014b. Error-driven versus batch mod-
els of the acquisition of phonotactics: David defeats
Goliath. In John Kingston, Claire Moore-Cantwell,
Joe Pater, and Robert Staubs, editors, Supplemental
Proceedings of Phonology 2013, Washington DC.
Linguistic Society of America.
Joe Pater. 2009. Weighted constraints in Generative
Linguistics. Cognitive Science, 33:999–1035.
Alan Prince and Paul Smolensky. 2004. Optimality
Theory: Constraint Interaction in generative gram-
mar. Blackwell, Oxford. As Technical Report CU-
CS-696-93, Department of Computer Science, Uni-
versity of Colorado at Boulder, and Technical Report
TR-2, Rutgers Center for Cognitive Science, Rut-
gers University, New Brunswick, NJ, April 1993.
Also available as ROA 537 version.
Alan Prince. 2002. Entailed ranking arguments.
Ms., Rutgers University, New Brunswick, NJ. Rut-
gers Optimality Archive, ROA 500. Available at
http://www.roa.rutgers.edu.
Bruce Tesar and Paul Smolensky. 1998. Learnability
in Optimality Theory. Linguistic Inquiry, 29:229–
268.
Bruce Tesar. 2013. Output-Driven Phonology: Theory
and Learning. Cambridge Studies in Linguistics.
Igor Yanovich. 2012. The logic of OT rankings. MIT
manuscript.
</reference>
<page confidence="0.99929">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000160">
<title confidence="0.852525">The error-driven ranking model of the acquisition of how to keep the faithfulness constraints at bay</title>
<author confidence="0.987879">Giorgio</author>
<affiliation confidence="0.9477985">SFL (CNRS and University of Paris UiL OTS (Utrecht</affiliation>
<email confidence="0.999544">magrigrg@gmail.com</email>
<abstract confidence="0.982303757756564">A problem which arises in the theory of the error-driven ranking model of the acquisition of phonotactics is that the faithfulness constraints need to be promoted but should not be promoted too high. This paper motivates this technical problem and shows how to tune the promotion component of the re-ranking rule so as to keep the faithfulness constraints at bay. Sections 1-2 introduce the algorithmic frameconsidered in the paper, namely the errorranking model the acquisition of phonotactics. Section 3 motivates a specific problem which arises in the design and analysis of this namely the problem of reached by the constraints. 4-6 sketch the theory of Magri (2014a) presents the theory in more detail. 1 The acquisition of phonotactics Generative linguistics assumes that the learner is with a typology of grammars The language-learning problem thus consists of the target adult grammar within the typology, on the basis of a finite set of data generated by that grammar. Various formulations of this problem differ for the structural assumptions about the underlying typology, for the type of data fed to the learner, and for the criteria of used to evaluate the grammar chosen the learner relative to the target grammar In this paper, I focus on the following specific formulation of this general language learning problem. The typology consists of the phonogrammars defined in Theoretic (OT) terms through the rankings of a given set of constraints (Prince and Smolensky, 2004). The data fed to the learner consist of surface forms from the generated by the OT grammar namely the set of surface forms which are the phonological realizations of underlying forms according to The crifor success is that the OT grammar chosen the learner generates a language which coinwith the target one: = specific formulation is called the the acquisition of In fact, phonotactics is the knowledge of the distinction between licit and illicit forms. Assuming that the distinction is categorical (Gorman, 2013), knowledge of phonotactics reduces to knowledge of the set of licit forms (the set of illicit forms is just the complement). And the set of licit forms relative to an grammar the corresponding language 2 The EDRA model In this paper, I focus on a specific algorithmic approach to the problem of the acquisition of phonobased on ranking algorithms (EDRAs). This approach is summarized below and explained in the rest of this section. 1 EDRA model Initialize ranking values of to zero ranking values of to Repeat a surface form the target language a loser form whether the current ranking vector consistent with the underlying/winner/loser triplet it isn’t, update the current ranking vector more mistakes are made at step 3 The EDRA model maintains a current hypothesis of the target adult grammar, namely a current constraint ranking. This ranking is represented nuthrough a vector , 10 of the 2014 Joint Meeting of SIGMORPHON and pages Maryland USA, June 27 2014. Association for Computational Linguistics assigns to each constraint numerical value A constraint ranked above constraint to a ranking vecthe ranking value the former (strictly) larger than the ranking value the latter (Boersma, 1998; Boersma, 2009). The current ranking (vector) is initialized in such a way that the corresponding initial language is as small as possible. OT constraints come in two and constraints. A smallest language corresponds to ranking which assigns all underall Thus, the are assigned a small initial ranking value, say zero concreteness; and the start with large positive initial ranking value then loops through the three steps step the EDRA model receives a piece of namely a surface form from the language Assuming that the underlytypology satisfies Tesar’s (2013) Orithis piece of data provides that the target grammar maps this phonological form (construed as the underlying into itself (construed as the surface form rather than reducing it to some non-faithful a mnemonic, I strike out a candidate construed as a loser). In other words, the taradult ranking (vector) is the form triplet any loser it satisfies condition (1). is the set of constraints, namely those which assign less (more) violations to the faithful mapping of to the neutralization of &gt; This consistency condition (1) says that there is at least a winner-preferring constraint which is ranked above all loser-preferring constraints by target ranking (vector) = ... , steps the EDRA model thus picks specific loser checks whether its curranking vector the corresponding consistency condition (1). Failure to satisfy this condition means that the current ranking values of the loser-preferring (winner-preferring) constraints are too large (too small). The algorithm thus promotes the winner-preferring constraints a small amount demotes the constraints by a small What matters is not the actual values of the promotion and demotion amounts, but rather their ratio. Thus, the demotion amount can be set equal to 1 for concreteness, letting instead the promotion amount be equal to an arbitrary nonconstant in (2). (2) a. Increase the ranking value of each winnerconstraint by decrease the ranking value of each undomconstraint by 1. not constraints are demoted by (2b), but only those that need to be namely the (Tesar and Smolensky, 1998), whose current ranking value is at least as large as the ranking value of all winnerpreferring constraints and thus are responsible for flouting the consistency condition (1). The problem of The crucial implementation parameter of the model is the promotion amount in the promotion component (2a) of the re-ranking rule. How should this parameter be tuned so as to optimize the performance of the EDRA model of the acquisition of phonotactics? This section explains how this question leads to the problem of the height of the 3.1 Some initial guarantees The problem of the acquisition of phonotactics in OT is intractable: no algorithm can solve efficiently an arbitrary instance of the problem corresponding to an arbitrary constraint set (Magri, 2013a). Prompted by this intractability result, Magri (2013b) starts to tackle the problem by looking at a class of “easy” cases. The intuitive idea is that the relative ranking the might often be irrelevant for phonotactics, namely for drawing the line between licit and illicit forms (although it is of course always crucial for phonology, namely for the specific way in which illicit forms are repaired). This that the relative ranking of the constraints is not relevant to describe a certain phonotactic pattern can be formalized as follows. A ranking is any partial order on constraint set. A partial ranking a language provided each one of its total refinements generates that language in the usual OT (Yanovich, 2012). A language is called it can be generated in this tech- 11 nical sense by a partial ranking which does not any two relative to each other (see subsection 3.2 for an example). Suppose that the EDRA model is trained on a language is The start out high, with an initial rankvalue larger than the number markedness constraints. The instead start out low, with a null initial ranking Throughout learning, the will raise, if the algorithm adopts a non-null promotion &gt; Theorem 1 provides guarantees that the EDRA model learns the target phonotacas long as the don’t raise too high, namely their ranking values remain smaller at least the initial ranking value as stated in (3). 1 that the underlying OT typology satisfies the following two assumptions. if a surface form a non-faithful candiof an underlying form then there exists at least one faithfulness constraint which assigns least one violation to the mapping of Second, a form a candidate of an underlying form and only if the latter form construed as the surface vice versa a candidate of the former construed as the underlying form candidacy Consider a lanin this OT typology which is Suppose that the EDRA model only makes a finite number of errors and then converges to a final ranking vector which is never updated again. furthermore that the ranking value any time in the run satisfies (3), where the number of conand m initial ranking value. Then, the language generated by (an arbitrary refinement of) the final ranking vector learned by the EDRA model coincides with the target language EDRA model has been trained on. two assumptions of and symmetric candidacy required by theorem 1 are extremely mild. Magri (2013b; 2014b) conjectures that the relative ranking of the faithfulness constraints turns out to matter for phonotactics only in very special configurations, so that the assumption might plausibly hold in the vast majority of cases. Theorem 1 thus provides guarantees that the EDRA model succeeds at the problem of the acquisition of phonotactics in a large class of cases under two crucial assumptions. One assumption is that it can only make a number of errors before it a final ranking which is consistent with any form and thus never updated. The other assumption is the (3) that the height of the can be properly controlled. 3.2 Some examples To illustrate the issues raised by convergence and consider the following OT typology. The set of forms consists of only four forms apza, absa, The faithfulness constraints are the two identity constraints for voicing stops and fricatives The markedness constraints are the two corresponding constraints stop and fricative voicing plus additional constraint bans sequences of stops and fricatives which agree in voicing, it is violated by the two forms The candidacy relation is total: the four forms are all candidates of each other. The OT typology just described contains in parthe language This language is generated by any ranking which satisfies the ranking conditions (4). These ranking conditions (4) say nothing about the ranking of the two The language qualifies as When trained on this language, the EDRA model will be provided at step 1 with a sequence of the two licit forms [absa] and [apza]. It will then complete them into an underlying/winner/loser form triplet at steps 2 and 3 by assuming a faithful underlying form and a non-faithful loser form. The list of all possible such triplets that the algorithm can consider is provided in (5). ⎡ [absa], [apsa]) [absa], [abza]) ⎢ ⎢ [absa], [apza]) ⎢ ⎢ [apza], [abza]) ⎢ ⎢ [apza], [apsa]) ⎣ [apza], [absa]) W L W W L ⎥ ⎥ ⎥ 12 triplet is described here in notation (Prince, 2002): constraints which are winneror loser-preferring or even relative to a triplet are with a corresponding triplets where the constraint winnerpreferring will trigger virtually no update, since that constraint starts high and is never demoted, and will thus always ensure consistency with those triplets. The learning run is thus driven by the two remaining triplets, boldfaced in (5), which I assume are fed one after the other to the algorithm. Suppose the promotion amount is non-null, say to the demotion amount: The resulting learning run is described in (6). two end up too high, namely a final ranking value 6 larger than the initial ranking value 5 the And indeed the EDRA has failed at learning the target phonotactics: since the are ranked at the top, the model has incorrectly learned that any form is licit. trivial strategy to enforce the condition (3) would be to threshold the promotion component (2a) of the re-ranking rule, as in (2a&apos;). Increase the ranking value of each constraint by an which is already to the forbidden threshold Yet, suppose we tried to remedy to the failure in (6) by thresholding the promotions as in (2a&apos;). an reaches the height 5 = we stop promoting it, as boldfaced in the learning run (7). ⎡ 1 ⎥ 6 5 this run, the constraint put at its initial The constraints up and down, because promoted and demoted by the boldfaced triplets in (5). The constraints a bit until they hit the threshold, and then settle. The EDRA model will thus keep making mistakes forever, without ever converging to a ranking vector consistent with the data. 3.3 Against a null promotion amount difficulties with convergence and the control condition (3) would disappear if the proamount set equal to zero, so that the EDRA performs no constraint promotion at all. In fact, Tesar and Smolensky (1998) guarantee convergence for the demotion-only case. And the could not possibly be promoted too high, as they would not be promoted at all. Unfortunately, the option of a null promotion amount is not viable, as argued in Magri (2012; 2014b). In fact, recall that the EDRA model at considers underlying/winner/loser triplets have an underlyform to the winner This means the are never loser-preferring and are therefore never demoted. If the promotion amount is set equal to zero, then they will not be either. In the end, the will thus never be re-ranked. This hampers the ability of the EDRA model to learn the correct relative of the when trained on a relevant language, namely when it needs to learn a phonotactic pattern which crucially does require a relative ranking of the 3.4 Convergence through calibration As recalled above, Tesar and Smolensky (1998) show that the EDRA model converges when the promotion amount is null and the algorithm performs only constraint demotion. It could in principle be the case that convergence does not extend to the demotion/promotion case, because any amount of promotion disrupts convergence. But Magri (2012) shows that is not the case: convergence extends to EDRAs which perform constraint promotion as well, as long as the promotion amount is small enough. In particular, consider a promotion scales as in (8) with the numbers currently undominated loser-preferring constraints and of winner-preferring constraints. ` It turns out that the EDRA model converges efficiently if (and only if) the promotion amount namely has the shape in (8) correto some strictly positive con- &gt; The larger the calibration constant the smaller the promotion amount. The case of a null promotion amount corresponds to the limiting ⎢ ⎣ ⎡ 1 ⎥ 6 5 ⎤ 3 ⎣ ⎦ 6 5 5 5 2 ⎥ 5 5 5 ⎥ 6 5 ⎥ 6 6 5 5 5 ⎡ ⎤ ⎣ ⎦ . . . 2 ⎥ 5 5 2 ⎥ 6 5 2 ⎥ 5 5 2 ⎥ 6 5 2 ⎥ 5 5 ⎢ ⎣ 13 through calibration as well Let’s take stock. Theorem 1 provides some initial guarantees of success of the EDRA model of the acquisition of phonotactics. These guarantees hold under two crucial assumptions: convergence the condition (3). Do these assumptions hold when the promotion amount is nonnull? Convergence does hold, if the promotion amount, although not null, is nonetheless small, calibrated as in (8). What about the control condition (3)? Can we play the same trick of a small promotion amount? Or is it the case that, no matter how small the promotion amount, soon as it is allowed to be non-null, the constraints raise too high through a long sequence of very small promotions? Section 4 shows that the scenario can never arise: the can never raise too high if the promotion amount is small enough. More precisely, it assumes a calibrated promotion amount as in (8). And it shows the condition (3) holds when the constant large enough, namely it as the number As the calibration constant increases as the markedness constraints, the promotion amount decreases quickly. Is it possible to improve on the analysis of section 4 and guaranthe condition (3) with a calibration does not grow with the number markedness constraints? Unfortunately, section 5 shows that the calibration constant must inwith More precisely, this section considers the very simple case where there is a single and where the are always loser-preferring (or even) but never winner- In this case, the condition if the calibration constant not grow least as the derivative of the function log m to zero as In other words, although function increases with the rate of increase becomes smaller and smaller, making this function as close as possible to a constant. Is this particularly favorable choice of the calibration constant only possible in the peculiar case considered in section 5? or does this favorable choice of the constant ensure also in the general case? Section 6 shows how to relax at least one of the two restrictive assumptions made section 5, namely the assumption that the constraints are never winner-preferring. with a non-null promotion amount most basic question of the theory of as follows: is it possible to guarantee the control condition (3) despite a non-null promotion amount? This section provides a positive answer to this question. In particular, assume the promoamount calibrated as in (8), through the constant The condition holds provided the calibration constant satthe bound (9), where the number of and their initial ranking value. To get a sense of the bound (9), assume that the ranking value the is power of the number m which is approximately each update, each of the undominated loser-preferring constraints is demoted by and each of the constraints promoted by Because of the specific shape of the promotion amount the sum of the ranking values decreases by And the latter is at least σ `σw+σ as every update requires at least one undominated constraint, namely Let the number of updates triggered by the ERC in the run considered up to the time considered (note that there is only a finite number of ERCs relative to a finite number of constraints). Thus, sum the current ranking values has decreased by at least +σ the the sum the initial ranking values, as stated in (10). � k i sum the initial ranking values be computed explicitly as in (11), as the start with the initial ranking value the start with a null initial ranking value. � k (11) k sum the current ranking values can be lower bounded as in (12). some &gt; The bound (9) thus w+σ k k σ 14 X (a) k F M ≥ 0 M (c) &gt; 0 In step (11a), I have split the sum over all constraints into the sum over the faithfulness and the markedness constraints. In step (11b), I have noted the ranking value any faithfulness conalways at least as large as 0. In fact, the faithfulness constraints start with a null initial ranking value and are never demoted, because the EDRA model always assumes an underlying form faithful to the winner, so that the faithfulness constraints are never loser-preferring. In step I have noted that the ranking value markedness constraint never get smaller In fact, suppose by contradiction that managed to be demoted that low. That would imply that some ERC triggers an update that demotes the fact that its current ranking value is strictly smaller than 0. And that is impossible. fact, at least one faithfulness constraint be winner-preferring relative to that ERC, because the assumption. Furthermore, constraint already dominate bea non-negative current ranking value a negative current ranking value. Using the expressions for the sum of the initial and the current ranking values obtained in (11) and (12) respectively, the original inequality (10) yields the bound in (13). σ ranking value a generic faithfulness now be bound as in (14). σ In step (14a), I have used the fact that the faithfulconstraint with a null initial ranking and is promoted by each one of the z triggered by the ERC, as long as is winner-preferring relative to that ERC. In step (14b), I have used the bound computed in (13). And in step (14c), I have used the choice (9) of the constant The bound obtained in (14) guarantees that generic faithfulness constraint raises the forbidden threshold thus comwith the condition (3). In other words, we have obtained the following sufficient to the problem of 2 the underlying typology satthe assumption. Consider a run of the EDRA model on an arbitrary language that typology. Assume that the start out with a null initial ranking value while the start out with an initial rankvalue Assume furthermore that the promotion amount is calibrated as in (8) and that calibration constant large enough to satisfy the bound (9). Then, the ranking values of the remain smaller than the forbidden the entire run. on the diagonal case preceding section has established the control condition (3) when the promotion amount is not null, provided it is small enough, namely it corresponds to a calibration constant which grows the number Is it possible to do better? In particular, is it possible to guarantee when the calibration constant does not with This section sketches a counterexample which provides a negative answer to this question; see Magri (2014a) for details. At every iteration, the EDRA model receives a winner form sampled from the target language, assumes a corresponding faithful underlying form and picks a corresponding loser candidate. At every iteration, the model thus constructs an underlying/winner/loser form triplet, which can be described in terms of the corresponding ERC, as exemplified in (5) above. Since there are only a finite number of ERCs corresponding to a finite number of constraints, the ERCs considered in a run of the model can be stacked one on top of the other into ERC Without loss of generality, assume that each input ERC has a unique loser-preferring constraint. Next, let me make two crucial assumptions. First, assume that the constraint set contains single faithfulness constraint plus of course certain number markedness constraints ... , Second, assume that ... , X (12) X (13) i 1 &lt; (a) X 1 ≤ i &lt; 15 Figure 1: First three stages of the learning dynamics where each diagonal ERC is fed persistently in turn , ERC 1 ERC 2 ERC 3 F 27 ERC 1 ERC 1 ERC 2 0 , F , F 2 9 3 0 2 9 0 are either loser-preferring or even in the input ERCs, but never winner-preferring. The input ERC matrix thus is (a subset of) the matrix (15). (15) F L ... 1 e e 1 m column corresponding to of all The entries corresponding to ... , all equal to but for the diagonal of This matrix is thus called What is the maximum height that the constraint reach in a run of the EDRA model on the input diagonal ERC matrix (15)? To address this question, consider the following special run. To start, we persistently feed ERC 1 to the algorithm, the markedness constraint demoted the faithfulness constraint that ERC cannot trigger any further update. Only at that point, we stop feeding ERC 1 to the algorithm, and persistently feed ERC 2 instead, again until it cannot trigger any further update. Only at that point, we stop feeding ERC 2 and persistently feed ERC 3. And so on. Assume that the promotion amount has the shape (8) and suppose for concreteness that the constant is 1, that the faithconstraint is promoted by each update. The dynamics of the ranking values is depicted in Figure 1 for the first three learning stages. Throughout stage 1, it is ERC 1 that triggers updates, whereby the markedness constraint demoted and the faithfulness constraint is by until the two constraints meet. Throughout stage 2, it is ERC 2 that triggers updates, whereby the markedness condemoted and the faithfulness conis promoted by another until the two constraints meet. Throughout the stage, it is the ERC that triggers updates, whereby the markedness constraint demoted and the faithfulness constraint promoted by an amount that turns out to be equal to The height by the faithfulness constraint at the end of the special run conis thus 1 1 turns out that this is indeed the maximum height reacheable the faithfulness constraint on the diagonal ERC matrix (15). condition (3) thus boils down to inequality 1 that the constraints start with the initial ranking value This inequality can then be solved analytically yielding = (1 By a first Taylor expansion the exponential function, the latter expression can be approximated as in (16). m The latter bound for the calibration threshold is substantially smaller than the linear bound through the elementary analysis of section 6. In particular, although (16) is not as a function of its derivative goes to as when the promotion decreases The preceding section has made two restrictive as- First, that there is a unique con- Second, that the are never winner-preferring. Under these assumptions, it shown that the condition (3) holds when the calibration constant grows only very with namely as in (16). Does this favorable result also hold when we relax the two restrictive assumptions? This section shows how to relax one of the two assumptions, namely the assumpthat the cannot be winnerpreferring. At this stage, I do know how to relax other assumption that there is a unique constraint. Again, the reasoning here is only sketched; see Magri (2014a) for details. 16 To illustrate the core idea, suppose that the EDRA model is trained on the input ERC matrix (17a) and walks through the run (18a). Here, I assuming that the promotion amount the in (8), with the calibration constant 0 set equal to zero for concreteness. L 1 2 1 e 2 Consider the diagonal ERC matrix (17b) correto 2 constraints. The original run (18a) on the original ERC matrix (17a) can be simulated with the run (18b) on the diagonal ERC matrix (17b) in such a way that all constraints end up at the same high in the two runs. This reasoning holds in complete generality. Indeed, under the assumption that there is a unique but no restrictions on the constraints, the input ERC matrix looks like (19). Any run of the EDRA model on this input ERC matrix (19) can be mimicked by a corresponding run on the diagonal ERC matrix (15). This reduction to the diagonal case holds provided the promotion amount is calibrated, namely has the shape in (8), no matter the choice of the calibration conreduction fails if the promotion amount is not calibrated. Another crucial condition needed for the reduction to the diagonal case is the following: in the original run, the markedness constraints are allowed to raise only slightly above their initial value Indeed, if a markedness constraint could raise arbitrarily high above its initial ranking value in the original run, there would be no way to mimic that increasing ranking dynamics with a derived run on the diagonal ERC matrix (15), as the latter only demotes but never promotes the markedness constraints. The fact that the markedness constraints can raise by a small amount does not threaten the reduction to the diagonal case, because the markedness constraints can be assigned a slightly larger initial ranking value in the derived run on the diagonal ERC matrix. Fortunately, the markedness constraints ... , indeed can raise above their initial value by a small amount, never by more than as stated in (20). (20) ... , :5 Obviously, this bound (20) holds at the beginning of the run. It is thus sufficient to prove that this is an the algorithm: if it holds the current ranking values at some time it also holds at the subsequent time The challenge is that a winner-preferring markedness right at time in principle be promoted above that forbidden threshold, so that the bound (20) would at time fail at time Yet, in order for such an update to happen, there has got to exanother constraint is loser-preferring is ranked at time least as high as winer-preferring constraint This means turn that the sum the two rankvalues of time at least + + suggests to cope with the difficulty just highlighted by strengthenthe invariant. Not only a value get larger than but also the sum any two ranking values can never reach instance, let’s say it can never larger than + + now again, in order to prove that the latter bound the sum of values holds at time need an assumption about the sum of rankvalues at time so on. Indeed, the of the current ranking values of number different markedness constraints ... , be bound as in (21). This bound holds for any promotion amount with the shape (8) to a calibration constant is too small, namely k k (21) 1) 1, yields the desired bound (20). Acknowledgments This research was supported by a Marie Curie Intra European Fellowship within the 7th European ⎡ ⎣ F a. F ⎤ ⎡ ⎤ ⎡ 1 1 9 8 10 10 10 9 8 ⎤ ⎦ 1 ERC 10 10 9 8 (19) ... . .. � W � e, ⎤ ⎦⎥ . ... .. ⎡ ⎢ ⎣</abstract>
<note confidence="0.7978862">17 Community Framework Programme. References Boersma. 1998. Ph.D. thesis, University of Amsterdam, The Netherlands.</note>
<title confidence="0.717715">The Hague: Holland Academic Graphics.</title>
<author confidence="0.873671">Some correct error-driven ver-</author>
<abstract confidence="0.877100789473684">of the constraint demotion algorithm. Linguis- 40:667–686. Gorman. 2013. Ph.D. thesis, University of Pennsylvania. Giorgio Magri. 2012. Convergence of error-driven algorithms. 29(2):213–269. Giorgio Magri. 2013a. The complexity of learning in OT and its implications for the acquisition of phono- 44.3:433468. Giorgio Magri. 2013b. An initial result on the restrictiveness of the error-driven ranking model of the early stage of the acquisition of phonotactics. In Hsin-Lun Huang, Ethan Poole, and Amanda Ryseditors, of NELS 43: the 43rd anmeeting of the North East Linguistic Giorgio Magri. 2014a. The error-driven ranking model of the acquisition of phonotactics: how to control the height of the faithfulness constraints. CNRS, UiL- OTS ms.</abstract>
<note confidence="0.835383631578947">Giorgio Magri. 2014b. Error-driven versus batch models of the acquisition of phonotactics: David defeats Goliath. In John Kingston, Claire Moore-Cantwell, Pater, and Robert Staubs, editors, of Phonology Washington DC. Linguistic Society of America. Joe Pater. 2009. Weighted constraints in Generative 33:999–1035. Prince and Paul Smolensky. 2004. Theory: Constraint Interaction in generative gram- Blackwell, Oxford. As Technical Report CU- CS-696-93, Department of Computer Science, University of Colorado at Boulder, and Technical Report TR-2, Rutgers Center for Cognitive Science, Rutgers University, New Brunswick, NJ, April 1993. Also available as ROA 537 version. Alan Prince. 2002. Entailed ranking arguments. Ms., Rutgers University, New Brunswick, NJ. Rutgers Optimality Archive, ROA 500. Available at</note>
<web confidence="0.820672">http://www.roa.rutgers.edu.</web>
<note confidence="0.92988425">Bruce Tesar and Paul Smolensky. 1998. Learnability Optimality Theory. 29:229– 268. Tesar. 2013. Phonology: Theory Cambridge Studies in Linguistics. Igor Yanovich. 2012. The logic of OT rankings. MIT manuscript. 18</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
</authors>
<title>Functional Phonology.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Amsterdam, The</institution>
<contexts>
<context position="4006" citStr="Boersma, 1998" startWordPosition="668" endWordPosition="669">ntains a current hypothesis of the target adult grammar, namely a current constraint ranking. This ranking is represented numerically through a ranking vector 0 = (θ1, , θn) 10 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 10–18, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics which assigns to each constraint Ck a numerical ranking value Ok. A constraint Ck is ranked above another constraint Ch according to a ranking vector 0 provided the ranking value Ok of the former is (strictly) larger than the ranking value Oh of the latter (Boersma, 1998; Boersma, 2009). The current ranking (vector) is initialized in such a way that the corresponding initial language is as small as possible. OT constraints come in two varieties: faithfulness (F) and markedness (M) constraints. A smallest language corresponds to a ranking which assigns all F constraints underneath all M constraints. Thus, the F constraints are assigned a small initial ranking value, say zero for concreteness; and the M constraints start with a large positive initial ranking value Oinit &gt; 0. The algorithm then loops through the three steps 1-4. At step 1, the EDRA model receive</context>
</contexts>
<marker>Boersma, 1998</marker>
<rawString>Paul Boersma. 1998. Functional Phonology. Ph.D. thesis, University of Amsterdam, The Netherlands. The Hague: Holland Academic Graphics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Boersma</author>
</authors>
<title>Some correct error-driven versions of the constraint demotion algorithm. Linguistic Inquiry,</title>
<date>2009</date>
<pages>40--667</pages>
<contexts>
<context position="4022" citStr="Boersma, 2009" startWordPosition="670" endWordPosition="671">t hypothesis of the target adult grammar, namely a current constraint ranking. This ranking is represented numerically through a ranking vector 0 = (θ1, , θn) 10 Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 10–18, Baltimore, Maryland USA, June 27 2014. c�2014 Association for Computational Linguistics which assigns to each constraint Ck a numerical ranking value Ok. A constraint Ck is ranked above another constraint Ch according to a ranking vector 0 provided the ranking value Ok of the former is (strictly) larger than the ranking value Oh of the latter (Boersma, 1998; Boersma, 2009). The current ranking (vector) is initialized in such a way that the corresponding initial language is as small as possible. OT constraints come in two varieties: faithfulness (F) and markedness (M) constraints. A smallest language corresponds to a ranking which assigns all F constraints underneath all M constraints. Thus, the F constraints are assigned a small initial ranking value, say zero for concreteness; and the M constraints start with a large positive initial ranking value Oinit &gt; 0. The algorithm then loops through the three steps 1-4. At step 1, the EDRA model receives a piece of dat</context>
</contexts>
<marker>Boersma, 2009</marker>
<rawString>Paul Boersma. 2009. Some correct error-driven versions of the constraint demotion algorithm. Linguistic Inquiry, 40:667–686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyle Gorman</author>
</authors>
<title>Generative phonotactics.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="2482" citStr="Gorman, 2013" startWordPosition="404" endWordPosition="405"> The data fed to the learner consist of surface forms sampled from the language L* generated by the target OT grammar G*, namely the set of surface forms which are the phonological realizations of some underlying forms according to G*. The criteria for success is that the OT grammar Gˆ chosen by the learner generates a language Lˆ which coincides with the target one: Lˆ = L*. This specific formulation is called the problem of the acquisition of phonotactics. In fact, phonotactics is the knowledge of the distinction between licit and illicit forms. Assuming that the distinction is categorical (Gorman, 2013), knowledge of phonotactics reduces to knowledge of the set of licit forms (the set of illicit forms is just the complement). And the set of licit forms relative to an OT grammar G is the corresponding language LG. 2 The EDRA model In this paper, I focus on a specific algorithmic approach to the problem of the acquisition of phonotactics, based on error-driven ranking algorithms (EDRAs). This approach is summarized below and explained in the rest of this section. Algorithm 1 The EDRA model Initialize the ranking values of F constraints to zero the ranking values of M constraints to θinit &gt;0 Re</context>
</contexts>
<marker>Gorman, 2013</marker>
<rawString>Kyle Gorman. 2013. Generative phonotactics. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Magri</author>
</authors>
<title>Convergence of error-driven ranking algorithms.</title>
<date>2012</date>
<journal>Phonology,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="15329" citStr="Magri (2012" startWordPosition="2629" endWordPosition="2630"> thus keep making mistakes forever, without ever converging to a ranking vector consistent with the data. 3.3 Against a null promotion amount These difficulties with convergence and the Fcontrol condition (3) would disappear if the promotion amount p was set equal to zero, so that the EDRA performs no constraint promotion at all. In fact, Tesar and Smolensky (1998) guarantee convergence for the demotion-only case. And the F constraints could not possibly be promoted too high, as they would not be promoted at all. Unfortunately, the option of a null promotion amount is not viable, as argued in Magri (2012; 2014b). In fact, recall that the EDRA model at step 3 always considers underlying/winner/loser form triplets (/y/, [y], [z]) which have an underlying form /y/ faithful to the winner [y]. This means that the F constraints are never loser-preferring and are therefore never demoted. If the promotion amount is set equal to zero, then they will not be promoted either. In the end, the F constraints will thus never be re-ranked. This hampers the ability of the EDRA model to learn the correct relative ranking of the F constraints when trained on a Frelevant language, namely when it needs to learn a </context>
</contexts>
<marker>Magri, 2012</marker>
<rawString>Giorgio Magri. 2012. Convergence of error-driven ranking algorithms. Phonology, 29(2):213–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Magri</author>
</authors>
<title>The complexity of learning in OT and its implications for the acquisition of phonotactics. Linguistic Inquiry,</title>
<date>2013</date>
<pages>44--3</pages>
<contexts>
<context position="7580" citStr="Magri, 2013" startWordPosition="1251" endWordPosition="1252">ontrol The crucial implementation parameter of the EDRA model is the promotion amount p ≥ 0 used in the promotion component (2a) of the re-ranking rule. How should this parameter be tuned so as to optimize the performance of the EDRA model of the acquisition of phonotactics? This section explains how this question leads to the problem of controlling the height of the F constraints. 3.1 Some initial guarantees The problem of the acquisition of phonotactics in OT is intractable: no algorithm can solve efficiently an arbitrary instance of the problem corresponding to an arbitrary constraint set (Magri, 2013a). Prompted by this intractability result, Magri (2013b) starts to tackle the problem by looking at a class of “easy” cases. The intuitive idea is that the relative ranking of the F constraints might often be irrelevant for phonotactics, namely for drawing the line between licit and illicit forms (although it is of course always crucial for phonology, namely for the specific way in which illicit forms are repaired). This intuition that the relative ranking of the F constraints is not relevant to describe a certain phonotactic pattern can be formalized as follows. A partial constraint ranking </context>
<context position="10556" citStr="Magri (2013" startWordPosition="1770" endWordPosition="1771">number of errors and then converges to a final ranking vector which is never updated again. Suppose furthermore that the ranking value OF of any F constraint F at any time in the run satisfies condition (3), where m is the number of M constraints and Oinit &gt; m their initial ranking value. (3) OF G Oinit − m Then, the language generated by (an arbitrary refinement of) the final ranking vector learned by the EDRA model coincides with the target language the EDRA model has been trained on. ■ The two assumptions of F-discernibility and symmetric candidacy required by theorem 1 are extremely mild. Magri (2013b; 2014b) conjectures that the relative ranking of the faithfulness constraints turns out to matter for phonotactics only in very special configurations, so that the F-irrelevancy assumption might plausibly hold in the vast majority of cases. Theorem 1 thus provides guarantees that the EDRA model succeeds at the problem of the acquisition of phonotactics in a large class of cases under two crucial assumptions. One assumption is that it can only make a finite number of errors before it converges to a final ranking which is consistent with any form and thus never updated. The other assumption is</context>
</contexts>
<marker>Magri, 2013</marker>
<rawString>Giorgio Magri. 2013a. The complexity of learning in OT and its implications for the acquisition of phonotactics. Linguistic Inquiry, 44.3:433468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Magri</author>
</authors>
<title>An initial result on the restrictiveness of the error-driven ranking model of the early stage of the acquisition of phonotactics.</title>
<date>2013</date>
<booktitle>In Hsin-Lun Huang, Ethan Poole, and Amanda Rysling, editors, Proceedings of NELS 43: the 43rd annual meeting of the North East Linguistic Society.</booktitle>
<contexts>
<context position="7580" citStr="Magri, 2013" startWordPosition="1251" endWordPosition="1252">ontrol The crucial implementation parameter of the EDRA model is the promotion amount p ≥ 0 used in the promotion component (2a) of the re-ranking rule. How should this parameter be tuned so as to optimize the performance of the EDRA model of the acquisition of phonotactics? This section explains how this question leads to the problem of controlling the height of the F constraints. 3.1 Some initial guarantees The problem of the acquisition of phonotactics in OT is intractable: no algorithm can solve efficiently an arbitrary instance of the problem corresponding to an arbitrary constraint set (Magri, 2013a). Prompted by this intractability result, Magri (2013b) starts to tackle the problem by looking at a class of “easy” cases. The intuitive idea is that the relative ranking of the F constraints might often be irrelevant for phonotactics, namely for drawing the line between licit and illicit forms (although it is of course always crucial for phonology, namely for the specific way in which illicit forms are repaired). This intuition that the relative ranking of the F constraints is not relevant to describe a certain phonotactic pattern can be formalized as follows. A partial constraint ranking </context>
<context position="10556" citStr="Magri (2013" startWordPosition="1770" endWordPosition="1771">number of errors and then converges to a final ranking vector which is never updated again. Suppose furthermore that the ranking value OF of any F constraint F at any time in the run satisfies condition (3), where m is the number of M constraints and Oinit &gt; m their initial ranking value. (3) OF G Oinit − m Then, the language generated by (an arbitrary refinement of) the final ranking vector learned by the EDRA model coincides with the target language the EDRA model has been trained on. ■ The two assumptions of F-discernibility and symmetric candidacy required by theorem 1 are extremely mild. Magri (2013b; 2014b) conjectures that the relative ranking of the faithfulness constraints turns out to matter for phonotactics only in very special configurations, so that the F-irrelevancy assumption might plausibly hold in the vast majority of cases. Theorem 1 thus provides guarantees that the EDRA model succeeds at the problem of the acquisition of phonotactics in a large class of cases under two crucial assumptions. One assumption is that it can only make a finite number of errors before it converges to a final ranking which is consistent with any form and thus never updated. The other assumption is</context>
</contexts>
<marker>Magri, 2013</marker>
<rawString>Giorgio Magri. 2013b. An initial result on the restrictiveness of the error-driven ranking model of the early stage of the acquisition of phonotactics. In Hsin-Lun Huang, Ethan Poole, and Amanda Rysling, editors, Proceedings of NELS 43: the 43rd annual meeting of the North East Linguistic Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Magri</author>
</authors>
<title>The error-driven ranking model of the acquisition of phonotactics: how to control the height of the faithfulness constraints. CNRS, UiLOTS ms.</title>
<date>2014</date>
<contexts>
<context position="978" citStr="Magri (2014" startWordPosition="154" endWordPosition="155">eed to be promoted but should not be promoted too high. This paper motivates this technical problem and shows how to tune the promotion component of the re-ranking rule so as to keep the faithfulness constraints at bay. Sections 1-2 introduce the algorithmic framework considered in the paper, namely the errordriven ranking model of the acquisition of phonotactics. Section 3 motivates a specific problem which arises in the design and analysis of this model, namely the problem of controlling the height reached by the faithfulness (F) constraints. Sections 4-6 sketch the theory of F-controlling. Magri (2014a) presents the theory in more detail. 1 The acquisition of phonotactics Generative linguistics assumes that the learner is provided with a typology of grammars G1, G2... The language-learning problem thus consists of individuating the target adult grammar G* within the typology, on the basis of a finite set of data generated by that grammar. Various formulations of this problem differ for the structural assumptions about the underlying typology, for the type of data fed to the learner, and for the criteria of success used to evaluate the grammar Gˆ chosen by the learner relative to the target</context>
<context position="25127" citStr="Magri (2014" startWordPosition="4463" endWordPosition="4464">of the F constraints remain smaller than the forbidden threshold θinit − m throughout the entire run. ■ 5 F-controlling on the diagonal case The preceding section has established the Fcontrol condition (3) when the promotion amount is not null, provided it is small enough, namely it corresponds to a calibration constant which grows as the number m of M constraints. Is it possible to do better? In particular, is it possible to guarantee F-control when the calibration constant does not increase with m? This section sketches a counterexample which provides a negative answer to this question; see Magri (2014a) for details. At every iteration, the EDRA model receives a winner form sampled from the target language, assumes a corresponding faithful underlying form and picks a corresponding loser candidate. At every iteration, the model thus constructs an underlying/winner/loser form triplet, which can be described in terms of the corresponding ERC, as exemplified in (5) above. Since there are only a finite number of ERCs corresponding to a finite number of constraints, the ERCs considered in a run of the model can be stacked one on top of the other into an input ERC matrix. Without loss of generalit</context>
<context position="30025" citStr="Magri (2014" startWordPosition="5369" endWordPosition="5370"> unique F constraint. Second, that the M constraints are never winner-preferring. Under these assumptions, it has shown that the F-control condition (3) holds when the calibration constant grows only very slowly with m, namely as in (16). Does this favorable result also hold when we relax the two restrictive assumptions? This section shows how to relax one of the two assumptions, namely the assumption that the M constraints cannot be winnerpreferring. At this stage, I do know how to relax the other assumption that there is a unique F constraint. Again, the reasoning here is only sketched; see Magri (2014a) for details. 16 To illustrate the core idea, suppose that the EDRA model is trained on the input ERC matrix (17a) and walks through the run (18a). Here, I am assuming that the promotion amount p has the shape in (8), with the calibration constant σ = 0 set equal to zero for concreteness. (17)a. F M1 M2 b. F M1 M2 ERC 1 r W L e ERC 1 W L e 1 ERC 2 L W W L � ERC 2 � W e LJ Consider the diagonal ERC matrix (17b) corresponding to m = 2 markedness constraints. The original run (18a) on the original ERC matrix (17a) can be simulated with the run (18b) on the diagonal ERC matrix (17b) in such a wa</context>
</contexts>
<marker>Magri, 2014</marker>
<rawString>Giorgio Magri. 2014a. The error-driven ranking model of the acquisition of phonotactics: how to control the height of the faithfulness constraints. CNRS, UiLOTS ms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Magri</author>
</authors>
<title>Error-driven versus batch models of the acquisition of phonotactics: David defeats Goliath. In</title>
<date>2014</date>
<booktitle>Supplemental Proceedings of Phonology 2013,</booktitle>
<editor>John Kingston, Claire Moore-Cantwell, Joe Pater, and Robert Staubs, editors,</editor>
<publisher>Linguistic Society of America.</publisher>
<location>Washington</location>
<contexts>
<context position="978" citStr="Magri (2014" startWordPosition="154" endWordPosition="155">eed to be promoted but should not be promoted too high. This paper motivates this technical problem and shows how to tune the promotion component of the re-ranking rule so as to keep the faithfulness constraints at bay. Sections 1-2 introduce the algorithmic framework considered in the paper, namely the errordriven ranking model of the acquisition of phonotactics. Section 3 motivates a specific problem which arises in the design and analysis of this model, namely the problem of controlling the height reached by the faithfulness (F) constraints. Sections 4-6 sketch the theory of F-controlling. Magri (2014a) presents the theory in more detail. 1 The acquisition of phonotactics Generative linguistics assumes that the learner is provided with a typology of grammars G1, G2... The language-learning problem thus consists of individuating the target adult grammar G* within the typology, on the basis of a finite set of data generated by that grammar. Various formulations of this problem differ for the structural assumptions about the underlying typology, for the type of data fed to the learner, and for the criteria of success used to evaluate the grammar Gˆ chosen by the learner relative to the target</context>
<context position="25127" citStr="Magri (2014" startWordPosition="4463" endWordPosition="4464">of the F constraints remain smaller than the forbidden threshold θinit − m throughout the entire run. ■ 5 F-controlling on the diagonal case The preceding section has established the Fcontrol condition (3) when the promotion amount is not null, provided it is small enough, namely it corresponds to a calibration constant which grows as the number m of M constraints. Is it possible to do better? In particular, is it possible to guarantee F-control when the calibration constant does not increase with m? This section sketches a counterexample which provides a negative answer to this question; see Magri (2014a) for details. At every iteration, the EDRA model receives a winner form sampled from the target language, assumes a corresponding faithful underlying form and picks a corresponding loser candidate. At every iteration, the model thus constructs an underlying/winner/loser form triplet, which can be described in terms of the corresponding ERC, as exemplified in (5) above. Since there are only a finite number of ERCs corresponding to a finite number of constraints, the ERCs considered in a run of the model can be stacked one on top of the other into an input ERC matrix. Without loss of generalit</context>
<context position="30025" citStr="Magri (2014" startWordPosition="5369" endWordPosition="5370"> unique F constraint. Second, that the M constraints are never winner-preferring. Under these assumptions, it has shown that the F-control condition (3) holds when the calibration constant grows only very slowly with m, namely as in (16). Does this favorable result also hold when we relax the two restrictive assumptions? This section shows how to relax one of the two assumptions, namely the assumption that the M constraints cannot be winnerpreferring. At this stage, I do know how to relax the other assumption that there is a unique F constraint. Again, the reasoning here is only sketched; see Magri (2014a) for details. 16 To illustrate the core idea, suppose that the EDRA model is trained on the input ERC matrix (17a) and walks through the run (18a). Here, I am assuming that the promotion amount p has the shape in (8), with the calibration constant σ = 0 set equal to zero for concreteness. (17)a. F M1 M2 b. F M1 M2 ERC 1 r W L e ERC 1 W L e 1 ERC 2 L W W L � ERC 2 � W e LJ Consider the diagonal ERC matrix (17b) corresponding to m = 2 markedness constraints. The original run (18a) on the original ERC matrix (17a) can be simulated with the run (18b) on the diagonal ERC matrix (17b) in such a wa</context>
</contexts>
<marker>Magri, 2014</marker>
<rawString>Giorgio Magri. 2014b. Error-driven versus batch models of the acquisition of phonotactics: David defeats Goliath. In John Kingston, Claire Moore-Cantwell, Joe Pater, and Robert Staubs, editors, Supplemental Proceedings of Phonology 2013, Washington DC. Linguistic Society of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joe Pater</author>
</authors>
<title>Weighted constraints in Generative Linguistics.</title>
<date>2009</date>
<journal>Cognitive Science,</journal>
<pages>33--999</pages>
<marker>Pater, 2009</marker>
<rawString>Joe Pater. 2009. Weighted constraints in Generative Linguistics. Cognitive Science, 33:999–1035.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality Theory: Constraint Interaction in generative grammar.</title>
<date>2004</date>
<tech>Technical Report CUCS-696-93,</tech>
<publisher>Blackwell,</publisher>
<institution>Department of Computer Science, University of Colorado at Boulder, and</institution>
<location>Oxford. As</location>
<contexts>
<context position="1868" citStr="Prince and Smolensky, 2004" startWordPosition="297" endWordPosition="300">hin the typology, on the basis of a finite set of data generated by that grammar. Various formulations of this problem differ for the structural assumptions about the underlying typology, for the type of data fed to the learner, and for the criteria of success used to evaluate the grammar Gˆ chosen by the learner relative to the target grammar G*. In this paper, I focus on the following specific formulation of this general language learning problem. The typology consists of the phonological grammars defined in Optimality Theoretic (OT) terms through the rankings of a given set of constraints (Prince and Smolensky, 2004). The data fed to the learner consist of surface forms sampled from the language L* generated by the target OT grammar G*, namely the set of surface forms which are the phonological realizations of some underlying forms according to G*. The criteria for success is that the OT grammar Gˆ chosen by the learner generates a language Lˆ which coincides with the target one: Lˆ = L*. This specific formulation is called the problem of the acquisition of phonotactics. In fact, phonotactics is the knowledge of the distinction between licit and illicit forms. Assuming that the distinction is categorical </context>
</contexts>
<marker>Prince, Smolensky, 2004</marker>
<rawString>Alan Prince and Paul Smolensky. 2004. Optimality Theory: Constraint Interaction in generative grammar. Blackwell, Oxford. As Technical Report CUCS-696-93, Department of Computer Science, University of Colorado at Boulder, and Technical Report TR-2, Rutgers Center for Cognitive Science, Rutgers University, New Brunswick, NJ, April 1993. Also available as ROA 537 version.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
</authors>
<title>Entailed ranking arguments.</title>
<date>2002</date>
<journal>Rutgers Optimality Archive, ROA</journal>
<institution>Ms., Rutgers University,</institution>
<location>New Brunswick, NJ.</location>
<note>500. Available at http://www.roa.rutgers.edu.</note>
<contexts>
<context position="12928" citStr="Prince, 2002" startWordPosition="2195" endWordPosition="2196">f the two licit forms [absa] and [apza]. It will then complete them into an underlying/winner/loser form triplet at steps 2 and 3 by assuming a faithful underlying form and a non-faithful loser form. The list of all possible such triplets that the algorithm can consider is provided in (5). (5) F1 F2 M1 M2 M ⎡ (/absa/, [absa], [apsa]) W e (/absa/, [absa], [abza]) e W ⎢ ⎢ (/absa/, [absa], [apza]) W W ⎢ ⎢ (/apza/, [apza], [abza]) W e ⎢ ⎢ (/apza/, [apza], [apsa]) e W ⎣ (/apza/, [apza], [absa]) W W L e e W L W W e e L W L ⎤W ⎥ W ⎥ e ⎥ ⎥ ⎥ W ⎥ W ⎦e 12 Each triplet is described here in ERC notation (Prince, 2002): constraints which are winner- or loser-preferring or even relative to a triplet are marked with a corresponding W or L or e. The triplets where the constraint M is winnerpreferring will trigger virtually no update, since that constraint starts high and is never demoted, and will thus always ensure consistency with those triplets. The learning run is thus driven by the two remaining triplets, boldfaced in (5), which I assume are fed one after the other to the algorithm. Suppose the promotion amount is non-null, say equal to the demotion amount: p = 1. The resulting learning run is described i</context>
</contexts>
<marker>Prince, 2002</marker>
<rawString>Alan Prince. 2002. Entailed ranking arguments. Ms., Rutgers University, New Brunswick, NJ. Rutgers Optimality Archive, ROA 500. Available at http://www.roa.rutgers.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
<author>Paul Smolensky</author>
</authors>
<date>1998</date>
<booktitle>Learnability in Optimality Theory. Linguistic Inquiry,</booktitle>
<pages>29--229</pages>
<contexts>
<context position="6772" citStr="Tesar and Smolensky, 1998" startWordPosition="1115" endWordPosition="1118">s by a small demotion amount. What matters is not the actual values of the promotion and demotion amounts, but rather their ratio. Thus, the demotion amount can be set equal to 1 for concreteness, letting instead the promotion amount be equal to an arbitrary nonnegative constant p ≥ 0, as in (2). (2) a. Increase the ranking value of each winnerpreferring constraint by p ≥ 0; b. decrease the ranking value of each undominated loser-preferring constraint by 1. Crucially, not all loser-preferring constraints are demoted by (2b), but only those that need to be demoted, namely the undominated ones (Tesar and Smolensky, 1998), whose current ranking value is at least as large as the ranking value of all winnerpreferring constraints and thus are responsible for flouting the consistency condition (1). 3 The problem of F-control The crucial implementation parameter of the EDRA model is the promotion amount p ≥ 0 used in the promotion component (2a) of the re-ranking rule. How should this parameter be tuned so as to optimize the performance of the EDRA model of the acquisition of phonotactics? This section explains how this question leads to the problem of controlling the height of the F constraints. 3.1 Some initial g</context>
<context position="15085" citStr="Tesar and Smolensky (1998)" startWordPosition="2586" endWordPosition="2589">t M stays put at its initial position. The constraints M1 and M2 oscillate up and down, because promoted and demoted by the two boldfaced triplets in (5). The constraints F1 and F2 raise a bit until they hit the threshold, and then settle. The EDRA model will thus keep making mistakes forever, without ever converging to a ranking vector consistent with the data. 3.3 Against a null promotion amount These difficulties with convergence and the Fcontrol condition (3) would disappear if the promotion amount p was set equal to zero, so that the EDRA performs no constraint promotion at all. In fact, Tesar and Smolensky (1998) guarantee convergence for the demotion-only case. And the F constraints could not possibly be promoted too high, as they would not be promoted at all. Unfortunately, the option of a null promotion amount is not viable, as argued in Magri (2012; 2014b). In fact, recall that the EDRA model at step 3 always considers underlying/winner/loser form triplets (/y/, [y], [z]) which have an underlying form /y/ faithful to the winner [y]. This means that the F constraints are never loser-preferring and are therefore never demoted. If the promotion amount is set equal to zero, then they will not be promo</context>
</contexts>
<marker>Tesar, Smolensky, 1998</marker>
<rawString>Bruce Tesar and Paul Smolensky. 1998. Learnability in Optimality Theory. Linguistic Inquiry, 29:229– 268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Tesar</author>
</authors>
<title>Output-Driven Phonology: Theory and Learning. Cambridge Studies in Linguistics.</title>
<date>2013</date>
<marker>Tesar, 2013</marker>
<rawString>Bruce Tesar. 2013. Output-Driven Phonology: Theory and Learning. Cambridge Studies in Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Yanovich</author>
</authors>
<title>The logic of OT rankings.</title>
<date>2012</date>
<note>MIT manuscript.</note>
<contexts>
<context position="8368" citStr="Yanovich, 2012" startWordPosition="1384" endWordPosition="1385"> of the F constraints might often be irrelevant for phonotactics, namely for drawing the line between licit and illicit forms (although it is of course always crucial for phonology, namely for the specific way in which illicit forms are repaired). This intuition that the relative ranking of the F constraints is not relevant to describe a certain phonotactic pattern can be formalized as follows. A partial constraint ranking is any partial order on the constraint set. A partial ranking generates a language provided each one of its total refinements generates that language in the usual OT sense (Yanovich, 2012). A language is called Firrelevant provided it can be generated in this tech(1) max Ck∈W 11 nical sense by a partial ranking which does not rank any two F constraints relative to each other (see subsection 3.2 for an example). Suppose that the EDRA model is trained on a target language L∗ which is F-irrelevant. The M constraints start out high, with an initial ranking value Oinit usually larger than the number m of markedness constraints. The F constraints instead start out low, with a null initial ranking value. Throughout learning, the F constraints will raise, if the algorithm adopts a non-</context>
</contexts>
<marker>Yanovich, 2012</marker>
<rawString>Igor Yanovich. 2012. The logic of OT rankings. MIT manuscript.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>