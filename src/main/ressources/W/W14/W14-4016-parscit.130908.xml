<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011363">
<title confidence="0.992853">
Context Sense Clustering for Translation
</title>
<author confidence="0.70581">
João Casteleiro
</author>
<affiliation confidence="0.7177305">
Universidade Nova de Lisboa
Departamento de Informática
</affiliation>
<address confidence="0.743254">
2829-516 Caparica, Portugal
</address>
<email confidence="0.996559">
casteleiroalves@gmail.com
</email>
<author confidence="0.863874">
Gabriel Lopes
</author>
<affiliation confidence="0.775542">
Universidade Nova de Lisboa
Departamento de Informática
</affiliation>
<address confidence="0.741692">
2829-516 Caparica, Portugal
</address>
<email confidence="0.995399">
gpl@fct.unl.pt
</email>
<author confidence="0.682043">
Joaquim Silva
</author>
<affiliation confidence="0.647643">
Universidade Nova de Lisboa
Departamento de Informática
</affiliation>
<address confidence="0.713921">
2829-516 Caparica, Portugal
</address>
<email confidence="0.98999">
jfs@fct.unl.pt
</email>
<subsectionHeader confidence="0.534695">
Extended Abstract
</subsectionHeader>
<bodyText confidence="0.999873387500001">
Word sense ambiguity is present in all words
with more than one meaning in several natural
languages and is a fundamental characteristic of
human language. This has consequences in trans-
lation as it is necessary to find the right sense and
the correct translation for each word. For this
reason, the English word fair can mean reasona-
ble or market such as plant also can mean factory
or herb.
The disambiguation problem has been recog-
nize as a major problem in natural languages
processing research. Several words have several
meanings or senses. The disambiguation task
seeks to find out which sense of an ambiguous
word is invoked in a particular use of that word.
A system for automatic translation from English
to Portuguese should know how to translate the
word bank as banco (an institution for receiving,
lending, exchanging, and safeguarding money),
and as margem (the land alongside or sloping
down to a river or lake), and also should know
that the word banana may appear in the same
context as acerola and that these two belongs to
hyperonym fruit. Whenever a translation systems
depends on the meaning of the text being pro-
cessed, disambiguation is beneficial or even nec-
essary. Word Sense Disambiguation is thus es-
sentially a classification problem; given a word X
and an inventory of possible semantic tags for
that word that might be translation, we seek
which tag is appropriate for each individual in-
stance of that word in a particularly context.
In recent years research in the field has
evolved in different directions. Several studies
that combine clustering processes with word
senses has been assessed by several. Apidianaki
in (2010) presents a clustering algorithm for
cross-lingual sense induction that generates bi-
lingual semantic inventories from parallel corpo-
ra. Li and Church in (2007) state that should not
be necessary to look at the entire corpus to know
if two words are strongly associated or not, thus,
they proposed an algorithm for efficiently com-
puting word associations. In (Bansal et al.,
2012), authors proposed an unsupervised method
for clustering translations of words through
point-wise mutual information, based on a mono-
lingual and a parallel corpora. Gamallo, Agustini
and Lopes presented in (2005) an unsupervised
strategy to partially acquire syntactic-semantic
requirements of nouns, verbs and adjectives from
partially parsed monolingual text corpora. The
goal is to identify clusters of similar positions by
identifying the words that define their require-
ments extensionally. In (1991) Brown et al. de-
scribed a statistical technique for assigning sens-
es to words based on the context in which they
appear. Incorporating the method in a machine
translation system, they have achieved to signifi-
cantly reduce translation error rate. Tufis et al. in
(2004) presented a method that exploits word
clustering based on automatic extraction of trans-
lation equivalents, being supported by available
aligned wordnets. In (2013), Apidianaki de-
scribed a system for SemEval-2013 Cross-
lingual Word Sense Disambiguation task, where
word senses are represented by means of transla-
tion clusters in a cross-lingual strategy.
In this article, a Sense Disambiguation ap-
proach, using Context Sense Clustering, within a
mono-lingual strategy of neighbor features is
proposed. We described a semi-supervised meth-
od to classify words based on clusters of contexts
strongly correlated. For this purpose, we used a
covariance-based correlation measure (Equation
1). Covariance (Equation 2) measure how much
two random variables change together. If the
values of one variable (sense x) mainly corre-
spond to the values of the other variable (sense
y), the variables tend to show similar behavior
</bodyText>
<page confidence="0.991407">
135
</page>
<bodyText confidence="0.931368333333333">
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 135–137,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
and the covariance is positive. In the opposite
case, covariance is negative. Note that this pro-
cess is computationally heavy. The system needs
to compute all relations between all features of
all left words. If the number of features is very
large, the processing time increases proportional-
ly.
</bodyText>
<equation confidence="0.991947166666667">
(1)
௙௠
1
Cov(x, y) = ݉ − 1 Y (dist(x, ݂). dist(y, ݂))
௙ୀ௙ଵ
(2)
</equation>
<bodyText confidence="0.869425666666667">
Our goal is to join similar senses of the same
ambiguous word in the same cluster, based on
features correlation. Through the analysis of cor-
relation data, we easily induce sense relations. In
order to streamline the task of creating clusters,
we opted to use WEKA tool (Hall et al., 2009)
with X-means (Pelleg et al., 2000) algorithm.
Clusters
fructose, glucose
football, chess
title, appendix, annex
telephone, fax
liver, hepatic, kidney
aquatic, marine
disciplinary, infringement, criminal
</bodyText>
<tableCaption confidence="0.972283">
Table 1. Well-formed resulting clusters
</tableCaption>
<bodyText confidence="0.999913333333333">
In order to determine the consistence of the
obtained clusters, all of these were evaluated
with V-measure. V-measure introduce two crite-
ria presented in (Rosenberg and Hirschberg,
2007), homogeneity (h) and completeness (c). A
clustering process is considered homogeneously
well-formed if all of its clusters contain only data
points which are members of a single class.
Comparatively, a clustering result satisfies com-
pleteness if all data points that are members of a
given class are elements of the same cluster.
Analysing the results of context sense clusters
obtained (Table 1) we easily understand that al-
most all clusters are generally well formed, get-
ting a final V-measure average rating of 67%.
Finally, in order to train a classifier we choose
to use a training data set with 60 well formed
clusters (with V-measure value ranging between
0.9 and 1). Our testing data set is composed by
60 words related to the clusters but which are not
contained there. The classifier used was a Sup-
port Vector Machine (SVM) (2011). The kernel
type applied was the Radial Basis Function
(RBF). This kernel non linearly maps samples
into a higher dimensional space, so it can handle
the case when the relation between class labels
and attributes is nonlinear, that is the case. Each
word of training and testing data sets were en-
coded according the frequency in a corpora of all
characteristics contained in the clusters. Our pur-
pose was to classify each one of the new poten-
tial ambiguous words, and fit it in the corre-
sponding cluster (Table 2 and Table 3).
</bodyText>
<table confidence="0.999410875">
Test Words Label assigned by (SVM)
Fruit Cluster 29
Infectious Cluster 7
Kiwi Cluster 60
Back Cluster 57
Legislative Cluster 34
Grape Cluster 29
Russian Cluster 59
</table>
<tableCaption confidence="0.999585">
Table 2. Results generated by (SVM)
</tableCaption>
<table confidence="0.997379571428571">
Clusters Content of Clusters
Cluster 7 Viral, contagious, hepatic
Cluster 29 Banana, apple
Cluster 34 Legal, criminal, infringement
Cluster 57 Cervical, lumbar
Cluster 59 French, Italian, Belgian, German
Cluster 60 Thyroid, mammary
</table>
<tableCaption confidence="0.999475">
Table 3. Cluster correspondence
</tableCaption>
<bodyText confidence="0.999763166666667">
The obtained results showed that almost all
words were tagged in the corresponding cluster.
Evaluating system accuracy we obtained an av-
erage value of 78%, which means that from the
60 tested words, 47 words were assigned to the
corresponding context cluster.
</bodyText>
<equation confidence="0.998975333333333">
Cov( x, y )
Corr (x, y) =
VCov(x,x) + VCov(y, y)
</equation>
<page confidence="0.997687">
136
</page>
<sectionHeader confidence="0.986759" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.9364864">
Marianna Apidianaki, Yifan He, et al. 2010. An
algorithm for cross-lingual sense-clustering
tested in a mt evaluation setting. In Proceed-
ings of the International Workshop on Spoken
Language Translation, pages 219–226.
Li, P., Church, K.W.: A sketch algorithm for es-
timating two-way and multi-way associations.
Computational Linguistics 33 (3), 305 - 354
(2007).
Bansal, M., DeNero, J., Lin, D.: Unsupervised
translation sense clustering. In: Proceedings of
the 2012 Conference of the North American
Chapter of the Association for Computational
Linguistics: Human Language Technologies.
pp. 773-782. Association for Computational
Linguistics (2012).
Gamallo, P., Agustini, A., Lopes, G.P.: Cluster-
ing syntactic positions with similar semantic
requirements. Computational Linguistics
31(1), 107-146 (2005).
Brown, P.F., Pietra, S.A.D., Pietra, V.J.D., Mer-
cer, R.L.: Word-sense disambiguation using
statistical methods. In: Proceedings of the 29th
annual meeting on Association for Computa-
tional Linguistics. pp. 264-270. Association
for Computational Linguistics (1991).
TufiS, D., Ion, R., Ide, N.: Fine-grained word
sense disambiguation based on parallel corpo-
ra, word alignment, word clustering and
aligned wordnets. In: Proceedings of the 20th
international conference on Computational
Linguistics. p. 1312. Association for Compu-
tational Linguistics (2004).
Apidianaki, M.: Cross-lingual word sense dis-
ambiguation using translation sense clustering.
In: Proceedings of the 7th International Work-
shop on Semantic Evaluation (SemEval 2013).
pp. 178-182. *SEM and NAACL (2013)
Mark Hall, Eibe Frank, Geoffrey Holmes, Bern-
hard Pfahringer, Peter Reutemann, and Ian H
Witten. 2009. The weka data mining software:
an update. ACM SIGKDD Explorations
Newsletter, 11(1):10–18.
Dan Pelleg, Andrew W Moore, et al. 2000. X-
means: Extending k-means with efficient es-
timation of the number of clusters. In ICML,
pages 727–734.
Andrew Rosenberg and Julia Hirschberg. 2007.
Vmeasure: A conditional entropy-based exter-
nal cluster evaluation measure. In EMNLP-
CoNLL, volume 7, pages 410–420.
Chih-Chung Chang and Chih-Jen Lin. 2011.
Libsvm: a library for support vector machines.
ACM Transactions on Intelligent Systems and
Technology (TIST), 2(3):27.
</reference>
<page confidence="0.997822">
137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000725">
<title confidence="0.999731">Context Sense Clustering for Translation</title>
<author confidence="0.983829">João Casteleiro</author>
<affiliation confidence="0.991303">Universidade Nova de Lisboa Departamento de Informática</affiliation>
<address confidence="0.999638">2829-516 Caparica, Portugal</address>
<email confidence="0.999731">casteleiroalves@gmail.com</email>
<author confidence="0.999551">Gabriel Lopes</author>
<affiliation confidence="0.994739">Universidade Nova de Lisboa Departamento de Informática</affiliation>
<address confidence="0.999857">2829-516 Caparica, Portugal</address>
<email confidence="0.993484">gpl@fct.unl.pt</email>
<author confidence="0.814522">Joaquim Silva</author>
<affiliation confidence="0.991971">Universidade Nova de Lisboa Departamento de Informática</affiliation>
<address confidence="0.999843">2829-516 Caparica, Portugal</address>
<email confidence="0.763638">jfs@fct.unl.pt</email>
<abstract confidence="0.996351889655172">Extended Abstract Word sense ambiguity is present in all words with more than one meaning in several natural languages and is a fundamental characteristic of human language. This has consequences in translation as it is necessary to find the right sense and the correct translation for each word. For this the English word mean reasonaas can mean The disambiguation problem has been recognize as a major problem in natural languages processing research. Several words have several meanings or senses. The disambiguation task seeks to find out which sense of an ambiguous word is invoked in a particular use of that word. system for automatic translation from know how to translate the institution for receiving, lending, exchanging, and safeguarding money), as land alongside or sloping down to a river or lake), and also should know the word appear in the same as that these two belongs to Whenever a translation systems depends on the meaning of the text being processed, disambiguation is beneficial or even necessary. Word Sense Disambiguation is thus esa classification problem; given a word and an inventory of possible semantic tags for that word that might be translation, we seek which tag is appropriate for each individual instance of that word in a particularly context. In recent years research in the field has evolved in different directions. Several studies that combine clustering processes with word senses has been assessed by several. Apidianaki in (2010) presents a clustering algorithm for cross-lingual sense induction that generates bilingual semantic inventories from parallel corpora. Li and Church in (2007) state that should not be necessary to look at the entire corpus to know if two words are strongly associated or not, thus, they proposed an algorithm for efficiently computing word associations. In (Bansal et al., 2012), authors proposed an unsupervised method for clustering translations of words through point-wise mutual information, based on a monolingual and a parallel corpora. Gamallo, Agustini and Lopes presented in (2005) an unsupervised strategy to partially acquire syntactic-semantic requirements of nouns, verbs and adjectives from partially parsed monolingual text corpora. The goal is to identify clusters of similar positions by identifying the words that define their requirements extensionally. In (1991) Brown et al. described a statistical technique for assigning senses to words based on the context in which they appear. Incorporating the method in a machine translation system, they have achieved to significantly reduce translation error rate. Tufis et al. in (2004) presented a method that exploits word clustering based on automatic extraction of translation equivalents, being supported by available aligned wordnets. In (2013), Apidianaki described a system for SemEval-2013 Crosslingual Word Sense Disambiguation task, where word senses are represented by means of translation clusters in a cross-lingual strategy. In this article, a Sense Disambiguation approach, using Context Sense Clustering, within a mono-lingual strategy of neighbor features is proposed. We described a semi-supervised method to classify words based on clusters of contexts strongly correlated. For this purpose, we used a covariance-based correlation measure (Equation 1). Covariance (Equation 2) measure how much two random variables change together. If the of one variable (sense mainly correspond to the values of the other variable (sense the variables tend to show similar behavior 135 of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical pages 135–137, 25, 2014, Doha, Qatar. Association for Computational Linguistics and the covariance is positive. In the opposite case, covariance is negative. Note that this process is computationally heavy. The system needs to compute all relations between all features of all left words. If the number of features is very large, the processing time increases proportionally. (1) ௙௠ 1 Cov(x, y) = ݉ − 1 Y (dist(x, ݂). dist(y, ݂)) ௙ୀ௙ଵ (2) Our goal is to join similar senses of the same ambiguous word in the same cluster, based on features correlation. Through the analysis of correlation data, we easily induce sense relations. In order to streamline the task of creating clusters, opted to use (Hall et al., 2009) et al., 2000) algorithm. Clusters fructose, glucose football, chess title, appendix, annex telephone, fax liver, hepatic, kidney aquatic, marine disciplinary, infringement, criminal 1. resulting clusters In order to determine the consistence of the obtained clusters, all of these were evaluated two criteria presented in (Rosenberg and Hirschberg, homogeneity completeness clustering process is considered homogeneously well-formed if all of its clusters contain only data points which are members of a single class. Comparatively, a clustering result satisfies completeness if all data points that are members of a given class are elements of the same cluster. Analysing the results of context sense clusters obtained (Table 1) we easily understand that almost all clusters are generally well formed, geta final rating of 67%. Finally, in order to train a classifier we choose to use a training data set with 60 well formed clusters (with V-measure value ranging between 0.9 and 1). Our testing data set is composed by 60 words related to the clusters but which are not there. The classifier used was a Sup- Vector Machine (SVM) The kernel applied was the Basis Function kernel non linearly maps samples into a higher dimensional space, so it can handle the case when the relation between class labels and attributes is nonlinear, that is the case. Each word of training and testing data sets were encoded according the frequency in a corpora of all characteristics contained in the clusters. Our purpose was to classify each one of the new potential ambiguous words, and fit it in the corresponding cluster (Table 2 and Table 3).</abstract>
<note confidence="0.955310235294118">Test Words assigned by Fruit Cluster 29 Infectious Cluster 7 Kiwi Cluster 60 Back Cluster 57 Legislative Cluster 34 Grape Cluster 29 Russian Cluster 59 2. generated by Clusters Content of Clusters Cluster 7 Viral, contagious, hepatic Cluster 29 Banana, apple Cluster 34 Legal, criminal, infringement Cluster 57 Cervical, lumbar Cluster 59 French, Italian, Belgian, German Cluster 60 Thyroid, mammary 3. correspondence</note>
<abstract confidence="0.674992611111111">The obtained results showed that almost all words were tagged in the corresponding cluster. Evaluating system accuracy we obtained an average value of 78%, which means that from the 60 tested words, 47 words were assigned to the corresponding context cluster. Cov( x, y ) Corr (x, y) = VCov(x,x) + VCov(y, y) 136 References Marianna Apidianaki, Yifan He, et al. 2010. An algorithm for cross-lingual sense-clustering tested in a mt evaluation setting. In Proceedings of the International Workshop on Spoken Language Translation, pages 219–226. Li, P., Church, K.W.: A sketch algorithm for estimating two-way and multi-way associations.</abstract>
<note confidence="0.905976071428572">Computational Linguistics 33 (3), 305 - 354 (2007). Bansal, M., DeNero, J., Lin, D.: Unsupervised translation sense clustering. In: Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 773-782. Association for Computational Linguistics (2012). Gamallo, P., Agustini, A., Lopes, G.P.: Clustering syntactic positions with similar semantic requirements. Computational Linguistics 31(1), 107-146 (2005). Brown, P.F., Pietra, S.A.D., Pietra, V.J.D., Mer-</note>
<abstract confidence="0.788767928571429">cer, R.L.: Word-sense disambiguation using statistical methods. In: Proceedings of the 29th annual meeting on Association for Computational Linguistics. pp. 264-270. Association for Computational Linguistics (1991). TufiS, D., Ion, R., Ide, N.: Fine-grained word sense disambiguation based on parallel corpora, word alignment, word clustering and aligned wordnets. In: Proceedings of the 20th international conference on Computational Linguistics. p. 1312. Association for Computational Linguistics (2004). Apidianaki, M.: Cross-lingual word sense disambiguation using translation sense clustering.</abstract>
<note confidence="0.818395380952381">In: Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013). pp. 178-182. *SEM and NAACL (2013) Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10–18. Dan Pelleg, Andrew W Moore, et al. 2000. Xmeans: Extending k-means with efficient estimation of the number of clusters. In ICML, pages 727–734. Andrew Rosenberg and Julia Hirschberg. 2007. Vmeasure: A conditional entropy-based external cluster evaluation measure. In EMNLP- CoNLL, volume 7, pages 410–420. Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27. 137</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
<author>Yifan He</author>
</authors>
<title>An algorithm for cross-lingual sense-clustering tested in a mt evaluation setting.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>219--226</pages>
<marker>Apidianaki, He, 2010</marker>
<rawString>Marianna Apidianaki, Yifan He, et al. 2010. An algorithm for cross-lingual sense-clustering tested in a mt evaluation setting. In Proceedings of the International Workshop on Spoken Language Translation, pages 219–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Li</author>
<author>Church</author>
</authors>
<title>K.W.: A sketch algorithm for estimating two-way and multi-way associations.</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>33</volume>
<issue>3</issue>
<pages>305--354</pages>
<marker>Li, Church, 2007</marker>
<rawString>Li, P., Church, K.W.: A sketch algorithm for estimating two-way and multi-way associations. Computational Linguistics 33 (3), 305 - 354 (2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bansal</author>
<author>J DeNero</author>
<author>D Lin</author>
</authors>
<title>Unsupervised translation sense clustering. In:</title>
<date>2012</date>
<booktitle>Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</booktitle>
<pages>773--782</pages>
<institution>Association for Computational Linguistics</institution>
<contexts>
<context position="2446" citStr="Bansal et al., 2012" startWordPosition="379" endWordPosition="382">instance of that word in a particularly context. In recent years research in the field has evolved in different directions. Several studies that combine clustering processes with word senses has been assessed by several. Apidianaki in (2010) presents a clustering algorithm for cross-lingual sense induction that generates bilingual semantic inventories from parallel corpora. Li and Church in (2007) state that should not be necessary to look at the entire corpus to know if two words are strongly associated or not, thus, they proposed an algorithm for efficiently computing word associations. In (Bansal et al., 2012), authors proposed an unsupervised method for clustering translations of words through point-wise mutual information, based on a monolingual and a parallel corpora. Gamallo, Agustini and Lopes presented in (2005) an unsupervised strategy to partially acquire syntactic-semantic requirements of nouns, verbs and adjectives from partially parsed monolingual text corpora. The goal is to identify clusters of similar positions by identifying the words that define their requirements extensionally. In (1991) Brown et al. described a statistical technique for assigning senses to words based on the conte</context>
</contexts>
<marker>Bansal, DeNero, Lin, 2012</marker>
<rawString>Bansal, M., DeNero, J., Lin, D.: Unsupervised translation sense clustering. In: Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. pp. 773-782. Association for Computational Linguistics (2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Gamallo</author>
<author>A Agustini</author>
<author>Lopes</author>
</authors>
<title>G.P.: Clustering syntactic positions with similar semantic requirements.</title>
<date>2005</date>
<journal>Computational Linguistics</journal>
<volume>31</volume>
<issue>1</issue>
<pages>107--146</pages>
<marker>Gamallo, Agustini, Lopes, 2005</marker>
<rawString>Gamallo, P., Agustini, A., Lopes, G.P.: Clustering syntactic positions with similar semantic requirements. Computational Linguistics 31(1), 107-146 (2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A D Pietra</author>
<author>V J D Pietra</author>
<author>Mercer</author>
</authors>
<title>R.L.: Word-sense disambiguation using statistical methods. In:</title>
<date>1991</date>
<booktitle>Proceedings of the 29th annual meeting on Association for Computational Linguistics.</booktitle>
<pages>264--270</pages>
<institution>Association for Computational Linguistics</institution>
<marker>Brown, Pietra, Pietra, Mercer, 1991</marker>
<rawString>Brown, P.F., Pietra, S.A.D., Pietra, V.J.D., Mercer, R.L.: Word-sense disambiguation using statistical methods. In: Proceedings of the 29th annual meeting on Association for Computational Linguistics. pp. 264-270. Association for Computational Linguistics (1991).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D TufiS</author>
<author>R Ion</author>
<author>N Ide</author>
</authors>
<title>Fine-grained word sense disambiguation based on parallel corpora, word alignment, word clustering and aligned wordnets. In:</title>
<date>2004</date>
<booktitle>Proceedings of the 20th international conference on Computational Linguistics. p. 1312. Association for Computational Linguistics</booktitle>
<marker>TufiS, Ion, Ide, 2004</marker>
<rawString>TufiS, D., Ion, R., Ide, N.: Fine-grained word sense disambiguation based on parallel corpora, word alignment, word clustering and aligned wordnets. In: Proceedings of the 20th international conference on Computational Linguistics. p. 1312. Association for Computational Linguistics (2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Apidianaki</author>
</authors>
<title>Cross-lingual word sense disambiguation using translation sense clustering. In:</title>
<date>2013</date>
<journal>SEM and NAACL</journal>
<booktitle>Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>178--182</pages>
<marker>Apidianaki, 2013</marker>
<rawString>Apidianaki, M.: Cross-lingual word sense disambiguation using translation sense clustering. In: Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013). pp. 178-182. *SEM and NAACL (2013)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="4982" citStr="Hall et al., 2009" startWordPosition="772" endWordPosition="775">. In the opposite case, covariance is negative. Note that this process is computationally heavy. The system needs to compute all relations between all features of all left words. If the number of features is very large, the processing time increases proportionally. (1)  1 Cov(x, y) = ݉ − 1 Y (dist(x, ݂). dist(y, ݂)) ୀଵ (2) Our goal is to join similar senses of the same ambiguous word in the same cluster, based on features correlation. Through the analysis of correlation data, we easily induce sense relations. In order to streamline the task of creating clusters, we opted to use WEKA tool (Hall et al., 2009) with X-means (Pelleg et al., 2000) algorithm. Clusters fructose, glucose football, chess title, appendix, annex telephone, fax liver, hepatic, kidney aquatic, marine disciplinary, infringement, criminal Table 1. Well-formed resulting clusters In order to determine the consistence of the obtained clusters, all of these were evaluated with V-measure. V-measure introduce two criteria presented in (Rosenberg and Hirschberg, 2007), homogeneity (h) and completeness (c). A clustering process is considered homogeneously well-formed if all of its clusters contain only data points which are members of </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Pelleg</author>
<author>Andrew W Moore</author>
</authors>
<title>Xmeans: Extending k-means with efficient estimation of the number of clusters.</title>
<date>2000</date>
<booktitle>In ICML,</booktitle>
<pages>727--734</pages>
<marker>Pelleg, Moore, 2000</marker>
<rawString>Dan Pelleg, Andrew W Moore, et al. 2000. Xmeans: Extending k-means with efficient estimation of the number of clusters. In ICML, pages 727–734.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>Vmeasure: A conditional entropy-based external cluster evaluation measure.</title>
<date>2007</date>
<booktitle>In EMNLPCoNLL,</booktitle>
<volume>7</volume>
<pages>410--420</pages>
<contexts>
<context position="5412" citStr="Rosenberg and Hirschberg, 2007" startWordPosition="830" endWordPosition="833"> on features correlation. Through the analysis of correlation data, we easily induce sense relations. In order to streamline the task of creating clusters, we opted to use WEKA tool (Hall et al., 2009) with X-means (Pelleg et al., 2000) algorithm. Clusters fructose, glucose football, chess title, appendix, annex telephone, fax liver, hepatic, kidney aquatic, marine disciplinary, infringement, criminal Table 1. Well-formed resulting clusters In order to determine the consistence of the obtained clusters, all of these were evaluated with V-measure. V-measure introduce two criteria presented in (Rosenberg and Hirschberg, 2007), homogeneity (h) and completeness (c). A clustering process is considered homogeneously well-formed if all of its clusters contain only data points which are members of a single class. Comparatively, a clustering result satisfies completeness if all data points that are members of a given class are elements of the same cluster. Analysing the results of context sense clusters obtained (Table 1) we easily understand that almost all clusters are generally well formed, getting a final V-measure average rating of 67%. Finally, in order to train a classifier we choose to use a training data set wit</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2007</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. 2007. Vmeasure: A conditional entropy-based external cluster evaluation measure. In EMNLPCoNLL, volume 7, pages 410–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Libsvm: a library for support vector machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. Libsvm: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>