<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.075885">
<title confidence="0.9993">
A Conceptual Framework of Online Natural Language Processing
Pipeline Application
</title>
<author confidence="0.99818">
Chunqi Shi, Marc Verhagen, James Pustejovsky
</author>
<affiliation confidence="0.9150495">
Brandeis University
Waltham, United States
</affiliation>
<email confidence="0.978761">
{shicq, jamesp, marc}@cs.brandeis.edu
</email>
<sectionHeader confidence="0.993873" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999936571428571">
This paper describes a conceptual framework that enables online NLP pipelined applications to
solve various interoperability issues and data exchange problems between tools and platforms;
e.g., tokenizers and part-of-speech taggers from GATE, UIMA, or other platforms. We propose
a restful wrapping solution, which allows for universal resource identification for data manage-
ment, a unified interface for data exchange, and a light-weight serialization for data visualization.
In addition, we propose a semantic mapping-based pipeline composition, which allows experts
to interactively exchange data between heterogeneous components.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.976699344827586">
The recent work on open infrastructures for human language technology (HLT) research and develop-
ment has stressed the important role that interoperability should play in developing Natural Language
Processing (NLP) pipelines. For example, GATE (Cunningham et al., 2002), UIMA (Ferrucci and Lally,
2004), and NLTK (Loper and Bird, 2002) all allow integrating components from different categories
based on common XML, or object-based (e.g., Java or Python) data presentation. The major categories
of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer,
Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution,
etc. Pipelined NLP applications can be built by composing several components; for example, a text
analysis application such as “relationship analysis from medical records” can be composed by Sentence
Splitter, Tokenizer, POS Tagger, NER, and Coreference Resolution components.
In addition to interoperability, the very availability of a component can also play an important role in
building online application based on distributed components, especially in tasks such as online testing
and judging new NLP techniques by comparing to existing components. For example, the Language Grid
(Ishida, 2006) addresses issues relating to accessing components from different locations or providers
based on Service-Oriented Architecture (SOAs) models. In this paper, we explore structural, conceptual
interoperability, and availability issues, and provide a conceptual framework for building online pipelined
NLP applications.
The conventional view of structural interoperability is that a common set of data formats and com-
munication protocols should be specified by considering data management, data exchange, and data
visualization issues. Data management determines how to access, store and locate sources of data. For
example, GATE provides pluggable document readers or writers and XML (with meta-data configura-
tion) serialization of reusable objected-based data. UIMA provides document or database readers and
writers and XMI serialization of common object-based data structures. The Language Grid provides Java
object serialization of data collections. Data exchange strategies describe how components communi-
cate their data. For example, GATE provides CREOLE (Collection of REusable Objects for Language
Engineering) data collections for data exchange. UIMA provides CAS (Common Analysis Structure),
and NLTK provides API modules for each component type. Similarly, the Language Grid provides LSI
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.914596">
53
</page>
<note confidence="0.9828115">
Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 53–59,
Dublin, Ireland, August 23rd 2014.
</note>
<bodyText confidence="0.99725">
(Language Service Interface) for a concrete ontology for a given language infrastructure. Data visu-
alization facilitates manual reading, editing and adjudication. For example, GATE and UIMA provide
XML-based viewers for selection, searching, matching and comparison functionality.
The conventional view of conceptual interoperability is that expert knowledge should be used in bridg-
ing heterogeneous components. For example, GATE provides integration plugins for UIMA, OpenNLP,
and Stanford NLP, where experts have already engineered the specific knowledge on conversion strate-
gies among these components. This leaves open the question of how one would ensure the interoperable
pipelining of new or never-before-seen heterogeneous components, for which experts have not encoded
bridge protocols.
In order to achieve an open infrastructure of online pipelined applications, we will argue two points
regarding the conceptual design, considering both interoperability and availability:
</bodyText>
<listItem confidence="0.918641">
• Universal resource identification, a SQL-like data management, and a light-weight data serialization
should be added with structural interoperability in online infrastructure of distributed components.
• By verifying and modifying inconsistent ontology mappings, experts can interactively learn con-
ceptual interoperability for online heterogeneous components pipelines.
2 Data, Tool and Knowledge Types
</listItem>
<bodyText confidence="0.999518833333333">
Interoperability in building pipelined NLP applications is intended ensure the exchange of information
between the different NLP tools. For this purpose, existing infrastructures like GATE or UIMA have
paid a lot of attention to common entity based data exchanges between the tools. When exchanging
data between heterogeneous tools (e.g., the GATE tokenizer pipelined with the NLTK POS tagger),
the knowledge of how these different entity based NLP tools can work together becomes much more
important, because there might be exchange problems between heterogeneous data or tool information,
and we may need specific knowledge to fix them. Thus, when considering interoperability, the main flow
of information should be exchanged in the open infrastructure consisting of source data information,
NLP tools information, and the knowledge that allows the tools to work together.
What are the main entity types of data and tools in designing an open infrastructure for online NLP
pipeline applications? From an abstract view of how linguistic analysis is related to human knowledge,
there are the following: Morphological, Lexical, Syntactic, Semantic, Pragmatic tool classifications; and
Utterance, Phoneme, Morpheme, Token, Syntactic Structure, Semantic Interpretation, and Pragmatic In-
terpretation data classifications. (Manaris, 1998; Pustejovsky and Stubbs, 2013). From a concrete appli-
cation perspective, where tools are available for concrete text mining for communities such as OpenNLP,
Stanford CoreNLP and NLTK, there are classification tools such as Sentence Splitter, Tokenizer, POS
Tagger, Phrase Chunker, Shallow Parser, NER, Lemmatizer, Coreference; and data classifications such
as Document, Sentence, Annotation, and Feature (Cunningham et al., 2002).
</bodyText>
<figureCaption confidence="0.999069">
Figure 1: A NLP pipeline can be a (sub)-process of an abstract five-step process
</figureCaption>
<figure confidence="0.957518428571428">
Morphological
Lexical
Syntactic
Semantic
Pragmatic
Sentence Splitter
Tokenization
POS Tagging
Noun-phrase
chunking
Lemmatization
NER
Coreference
Resolution
</figure>
<figureCaption confidence="0.999101">
Figure 2: An example NLP pipeline of a concrete six-step process
</figureCaption>
<bodyText confidence="0.999587166666667">
The knowledge types needed for designing an open infrastructure also can be seen abstractly or con-
cretely. Abstractly, an NLP pipeline should be part of the process of morphological, lexical, syntactic,
semantic to pragmatic processing (see Figure 1). From a concrete view, each component of an NLP
pipeline should have any requisite preprocessing. For example, tokenization is required preprocessing
for POS tagging (see Figure 2). Such knowledge for building NLP pipelines can be interactively deter-
mined by the NLP expert or preset as built-in pipeline models.
</bodyText>
<figureCaption confidence="0.994455">
Figure 3: Information for NLP pipeline application description
</figureCaption>
<bodyText confidence="0.99999248">
We can put the above analyzed data, tool, and knowledge types with their meta-information together as
the information required for describing an NLP pipeline application (see Figure 3). Regarding the docu-
ment format, structure and style, for example, the Text Encoding Initiative (TEI)1 provides one standard
for text encoding and interchange, which also enables meta-information description. Concerning the
main part (see dashdotted-line part of Figure 3), it is generally referred to as the model of annotation.
For example, GATE has its own single unified model of annotation, which is organized in annotation
graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of
features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic
Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and
Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntac-
tic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation
framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization
for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML stand-
off annotations for natively XML support, and provides XSLT-based online integration mechanism of
various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of anno-
tation, which also has a unified XML serialization (Hahn et al., 2007). Differently from Heart of Gold’s
XSLT-based mechanism, the conversion tools that bridge GATE annotation and UIMA annotation use
GrAF as a pivot and are provided as GATE plugins and UIMA modules (Ide and Suderman, 2009).
Thus, while a pivot standard annotation model like GrAF seems very promising, popular annotation
models like those provided by GATE annotations (see Figure 4) or UIMA annotations (see Figure 4)
will continue to exist and evolve for a long time. As a result, more bridge strategies, like the conversion
plugin (module) of GATE (UIMA) and the XSLT-based middleware mechanism, will continue to be nec-
essary. In the following sections, we consider the issue of the continuing availability of such conversion
functions, and whether the current realization of those two conversion strategies is sufficient to bridge the
various annotations made available by linguistic experts, without further substantial engineering work.
</bodyText>
<sectionHeader confidence="0.96597" genericHeader="method">
3 Towards A Conceptual Design of Online Infrastructure
</sectionHeader>
<bodyText confidence="0.975828">
In this section, we discuss the conceptual design of online infrastructure, focusing on both the interop-
erability and availability of the tools. Concerning the latter, the Service-oriented architecture (SOA) is
</bodyText>
<footnote confidence="0.938119">
1http://www.tei-c.org/ 55
</footnote>
<figure confidence="0.999716954545454">
Knowledge
Knowledge of Tool Requirements, Data
Interpretation
Data
Tool
Semantic
(NER, Coreference)
Lexical &amp; Syntactic
(Lemmatization, Chunking, Parsing)
Morphological
(Splitter, Tokenizer, POS Tagger)
Pragmatic
(Indexing, Retrieval)
Document Format, Structure, Style
Meta-
Information
of
Knowledge,
Tool, and
Data.
&lt;!-- GATE --&gt;
&lt;GateDocument&gt;
&lt;TextWithNodes&gt;
&lt;Node id=&amp;quot;15&amp;quot;/&gt;Sonnet&lt;Node id=&amp;quot;21&amp;quot;/&gt;
&lt;/TextWithNodes&gt;
&lt;AnnotationSet&gt;
&lt;Annotation Id=&amp;quot;18&amp;quot; Type=&amp;quot;Token&amp;quot;
StartNode=&amp;quot;15&amp;quot; EndNode=&amp;quot;21&amp;quot;&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;length&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;6&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;category&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;NNP&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;kind&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;word&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;string&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;Sonnet&lt;/Value&gt;
&lt;/Feature&gt;
&lt;/Annotation&gt;
&lt;/AnnotationSet&gt;
&lt;/GateDocument&gt;
&lt;!-- UIMA --&gt;
&lt;xmi:XMI
xmlns:xmi=&amp;quot;http://www.omg.org/XMI&amp;quot;
xmlns:opennlp=
&amp;quot;http:///org/apache/uima/examples/opennlp.ecore&amp;quot;
xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot;
xmi:version=&amp;quot;2.0&amp;quot;&gt;
&lt;cas:Sofa
xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot;
xmi:id=&amp;quot;1&amp;quot; sofaNum=&amp;quot;1&amp;quot; sofaID=&amp;quot;_InitialView&amp;quot;
mimetype=&amp;quot;text&amp;quot;
sofaString=&amp;quot;Sonnet.&amp;quot; /&gt;
&lt;opennlp:Token
xmi:id=&amp;quot;18&amp;quot; sofa=&amp;quot;1&amp;quot;
begin=&amp;quot;0&amp;quot; end=&amp;quot;6&amp;quot;
posTag=&amp;quot;NNP&amp;quot; /&gt;
&lt;cas:View sofa=&amp;quot;1&amp;quot;
members=&amp;quot;18&amp;quot;/&gt;
&lt;/xmi:XMI&gt;
</figure>
<figureCaption confidence="0.999992">
Figure 4: Examples of GATE XML annotation and UIMA XML annotation
</figureCaption>
<bodyText confidence="0.998855419354838">
a promising approach. For example, while the Language Grid infrastructure makes NLP tools highly
available (Ishida, 2006), it can still have limitations regarding interoperability issues. Generally, service
interfaces can be either operation-oriented which allows flexible operations with simple input/output
data, or resource-oriented which allows flexible input/output data with simple operations. The NLP
processing services of Language Grid are more or less operation-oriented, and lack a certain structural
flexibility for composing with each other. We present a resource-oriented view of NLP tools, which
should have universal resource identification for distributed reference, an SQL-like data management,
and a light-weight data serialization for online visualization. We propose Restful wrapping both data and
tools into Web services for this purpose.
Restful wrapping makes both data and tools easy-to-access and with a unified interface, enabling
structural interoperability between heterogeneous tools, assuming standoff annotation from various NLP
tools is applied. For example, if the NLP tools are wrapped into Restful services so that they are operated
through HTTP GET protocol, and the XML serialization of UIMA annotation is applied for input and
output, each NLP components will have the same interface and data structure.
Once an internationalized resource identifier (IRI) is given, all the input and output of tools can be
distributed and ubiquitously identified. Moreover, a PUT/GET/POST/DELETE protocol of restful data
management is equivalent to an SQL-like CRUD data management interface. For example, an IRI can
be defined by a location identifier and the URL of the data service (Wright, 2014).
In addition, a lightweight serialization of stand-off annotation can benefit the online visualization of
data, which will be easy for experts to read, judge, or edit. For example, the XML serialization of UIMA
annotation can be transferred into JSON serialization, which is preferred for online reading or editing.
NLP tool services will be available by applying restful wrapping (see Figure 5). However, structural
interoperability based on the restful wrapping is not enough for conceptual interoperability. For example,
if an OpenNLP tokenizer is wrapped using HTTP GET protocol and GATE annotation, but a Stanford
NLP POS tagger is wrapped using UIMA annotation, it will raise conceptual interoperability issues.
Based on the previously mentioned bridging strategies, a conversion service from GATE annotation to
UIMA annotation should work, or a transformation interaction with a XSLT-like service should work.
We would like to assume that the interaction and contribution of linguistic experts without online support
by engineers can solve this issue. But how can we design the interaction to take advantage of such expert
knowledge?
We present a semantic mapping-based composer56 for building an NLP pipeline application (see Fig-
</bodyText>
<figureCaption confidence="0.996691">
Figure 5: Conceptual design of online NLP pipeline application
</figureCaption>
<bodyText confidence="0.981201277777778">
ure 5). Conceptual interoperability requires the same vocabularies for the same concept of a standoff
annotation. Once we have the standoff ontology of annotation, we can perform automatic semantic map-
ping from NLP tool output to that ontology. The interaction from experts will be triggered once the
automatic semantic mapping has failed (see Figure 6). For example, both GATE and UIMA XML an-
notations could be transformed into JSON formation, which is easy to present as tree structure entities.
Based on these tree structure entities, automatic ontology mapping tools like UFOme, which identifies
correspondences among entities in different ontologies (Pirr´o and Talia, 2010), can be applied to build
up various mapping solutions. Knowledge from experts can also be applied interactively, and successful
mapping solutions can be stored for further reference and use.
Figure 6: Interactive ontology mapping of two different annotations of NLP tools (Tree structures are
learned from XML annotations in Figure 4 )
The semantic mapping will be interactively created by the experts, when heterogeneous components
with different data models are used in the NLP pipeline created by the end-users, who create the NLP
pipeline without consideration of components interoperability. It means that this semi-automatically
created semantic mapping separates acquiring the knowledge of tool requirements from end-users and
acquiring the knowledge of data interpretation from experts (see Figure 3). For example, the end-users
chooses two POS Taggers (OpenNLP and NLTK) and two NER tools (OpenNLP and Stanford NLP)
components in the NLP application of “relationship57 analysis from medical records”. When NLTK POS
</bodyText>
<figure confidence="0.997739989010989">
NLP Pipeline Application
Workflow Engine
( BPEL )
Semantic Mapping based Composing
1. NLP tool service pipeline engine
2. Proxy service of interactive ontology mapping
Stand-off Ontology
(Vocabulary)
Meta-Information
(Process Requirements)
NLP Tool Service
Restful Wrapping
1. International resource identifier (IRI) ID
2. Unified interface, GET/PUT/POST/DELETE
3. Self-description message like XML or JSON
Source Data
(Document, Database)
NLP Tool
( OpenNLP, Standard
NLP, NLTK, etc)
Meta-Information
( Provider, License,
Location)
GATE Annotation
&lt;!-- GATE -&gt;
&lt;GateDocument&gt;
&lt;TextWithNodes&gt;
&lt;Node id=&amp;quot;15&amp;quot;/&gt;Sonnet&lt;Node id=&amp;quot;21&amp;quot;/&gt;
&lt;/TextWithNodes&gt;
&lt;AnnotationSet&gt;
&lt;Annotation Id=&amp;quot;18&amp;quot; Type=&amp;quot;Token&amp;quot;
StartNode=&amp;quot;15&amp;quot; EndNode=&amp;quot;21&amp;quot;&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;length&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;6&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;category&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;NNP&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;kind&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;word&lt;/Value&gt;
&lt;/Feature&gt;
&lt;Feature&gt;
&lt;Name className=&amp;quot;java.lang.String&amp;quot;&gt;string&lt;/Name&gt;
&lt;Value className=&amp;quot;java.lang.String&amp;quot;&gt;Sonnet&lt;/Value&gt;
&lt;/Feature&gt;
&lt;/Annotation&gt;
&lt;/AnnotationSet&gt;
&lt;/GateDocument&gt;
Annotation
@Type
@StartNode
@EndNode
@Id
Feature
Category
Length
String
Vocabulary
Ontology
Mapping
Token
@posTag
@begin
@sofa
@end
@id
UIMA Annotation
&lt;!-- UIMA --&gt;
&lt;xmi:XMI
xmlns:xmi=&amp;quot;http://www.omg.org/XMI&amp;quot;
xmlns:opennlp=
&amp;quot;http:///org/apache/uima/examples/opennlp.ecore&amp;quot;
xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot;
xmi:version=&amp;quot;2.0&amp;quot;&gt;
&lt;cas:Sofa
xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot;
xmi:id=&amp;quot;1&amp;quot; sofaNum=&amp;quot;1&amp;quot; sofaID=&amp;quot;_InitialView&amp;quot;
mimetype=&amp;quot;text&amp;quot;
sofaString=&amp;quot;Sonnet.&amp;quot; /&gt;
&lt;opennlp:Token
xmi:id=&amp;quot;18&amp;quot; sofa=&amp;quot;1&amp;quot;
begin=&amp;quot;0&amp;quot; end=&amp;quot;6&amp;quot;
posTag=&amp;quot;NNP&amp;quot; /&gt;
&lt;cas:View sofa=&amp;quot;1&amp;quot;
members=&amp;quot;18&amp;quot;/&gt;
&lt;/xmi:XMI&gt;
Mapping
Storage
</figure>
<bodyText confidence="0.999211058823529">
Tagger output are serialized in to JSON formats but cannot be directly used as the input of Stanford NLP
NER component which requires the UIMA annotation, a semantic mapping issue will be automatically
created and reported to experts. This NLTK POS Tagger JSON format output will be mapped into
the standoff ontology of annotation of POS Tagger. After that, this output will bridge with the UIMA
annotation of the Stanford NLP NER. This particular semantic mapping between JSON serialization of
a NLTK POS Tagger and the standoff ontology of annotation of POS Tagger, and between the standoff
ontology of annotation of POS Tagger and the UIMA annotation of Stanford NLP NER will be reused in
the NLP application created by other end-users.
Our conceptual framework does not exclusively rely on the above interoperability design. Our con-
ceptual framework (see Figure 5) should integrate existing knowledge of various annotation frameworks,
for example, the alignment knowledge from the Open Annotation models (Verspoor and Livingston,
2012) and the pivot bridge knowledge from the GrAF (Ide and Suderman, 2007) under the Linguistic
Annotation Framework (LAF). Thus, existing pivot conversion solutions and XSLT-based middleware
solutions can also be applied. Our interactive ontology mapping design provides a more flexible choice
for linguistic experts to build up NLP pipeline applications on top of heterogeneous components, without
online help from engineers. Below we present varying levels of online NLP applications, according to
what kind of extra support would be needed for composing different NLP components:
</bodyText>
<listItem confidence="0.998109714285714">
• Components are interoperable without extra data exchange issues. For example, tools are from the
same community (e.g., only using OpenNLP tools).
• Components are interoperable with existing solutions of data exchange issues. For example, tools
are from popular communities such as GATE plugins or UIMA modules.
• Components are interoperable with extra knowledge from experts. For example, tools are both from
popular communities and personal developments or inner group software.
• Components are interoperable with considerable effort from both experts and engineers. For exam-
</listItem>
<bodyText confidence="0.9051685">
ple, tools are developed under novel ontology designs.
According to these levels, our conceptual framework is targeted at the third level of interoperability
issues. Our proposal will generate a ontology mapping storage (see Figure 6), which we hope will
contribute to improving a standard annotation ontology.
</bodyText>
<sectionHeader confidence="0.999375" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999917444444444">
In this paper, we have tried to present a conceptual framework for building online NLP pipeline applica-
tions. We have argued that restful wrapping based on the Service-Oriented Architecture and a semantic
mapping based pipeline composition benefit both the availability and interoperability of online pipeline
applications. By looking at the information surrounding the data, tools, and knowledge needed for NLP
components pipelines, we explained how experts can be limited in building online NLP pipeline applica-
tions without help from engineers, and our restful wrapping and interactive ontology mapping design can
help in such situations. Finally, we have described various levels of support needed for building online
NLP pipelines, and we believe that this study can contribute to further online implementations of NLP
applications.
</bodyText>
<sectionHeader confidence="0.997687" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.915788">
This work was supported by National Science Foundation grants NSF-ACI 1147944.
</bodyText>
<sectionHeader confidence="0.998642" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997129375">
Kalina Bontcheva, Valentin Tablan, Diana Maynard, and Hamish Cunningham. 2004. Evolving gate to meet new
challenges in language engineering. Nat. Lang. Eng., 10(3-4):349–373, September.
Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: A Framework
and Graphical Development Environment for Robust NLP Tools and Applications. In Proceedings of the 40th
Anniversary Meeting of the Association for Computational Linguistics (ACL’02).
Thierry Declerck. 2006. Synaf: Towards a standard for syntactic annotation. In Proceedings of the Fifth In-
ternational Conference on Language Resources and Evaluation (LREC’06). European Language Resources
Association (ELRA).
Thierry Declerck. 2008. A framework for standardized syntactic annotation. In Bente Maegaard Joseph
Mariani Jan Odijk Stelios Piperidis Daniel Tapias Nicoletta Calzolari (Conference Chair), Khalid Choukri,
editor, Proceedings of the Sixth International Conference on Language Resources and Evaluation
(LREC’08), Marrakech, Morocco, may. European Language Resources Association (ELRA). http://www.lrec-
conf.org/proceedings/lrec2008/.
David Ferrucci and Adam Lally. 2004. Uima: An architectural approach to unstructured information processing
in the corporate research environment. Nat. Lang. Eng., 10(3-4):327–348, September.
Udo Hahn, Ekaterina Buyko, Katrin Tomanek, Scott Piao, John McNaught, Yoshimasa Tsuruoka, and Sophia
Ananiadou. 2007. An annotation type system for a data-driven nlp pipeline. In Proceedings of the Linguistic
Annotation Workshop, LAW ’07, pages 33–40, Stroudsburg, PA, USA. Association for Computational Linguis-
tics.
Nancy Ide and Laurent Romary. 2004. International standard for a linguistic annotation framework. Nat. Lang.
Eng., 10(3-4):211–225, September.
Nancy Ide and Keith Suderman. 2007. Graf: A graph-based format for linguistic annotations. In Proceedings of
the Linguistic Annotation Workshop, LAW ’07, pages 1–8, Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Nancy Ide and Keith Suderman. 2009. Bridging the gaps: Interoperability for graf, gate, and uima. In Pro-
ceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP ’09, pages 27–34, Stroudsburg, PA, USA.
Association for Computational Linguistics.
T. Ishida. 2006. Language grid: an infrastructure for intercultural collaboration. In Applications and the Internet,
2006. SAINT 2006. International Symposium on, pages 5 pp.–100, Jan.
Edward Loper and Steven Bird. 2002. Nltk: The natural language toolkit. In Proceedings of the ACL-02 Work-
shop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational
Linguistics - Volume 1, ETMTNLP ’02, pages 63–70, Stroudsburg, PA, USA. Association for Computational
Linguistics.
Bill Manaris. 1998. Natural language processing: A human-computer interaction perspective.
Giuseppe Pirr´o and Domenico Talia. 2010. Ufome: An ontology mapping system with strategy prediction capa-
bilities. Data Knowl. Eng., 69(5):444–471, May.
James Pustejovsky and Amber Stubbs. 2013. Natural language annotation for machine learning. O’Reilly Media,
Sebastopol, CA.
Ulrich Sch¨afer. 2006. Middleware for creating and combining multi-dimensional nlp markup. In Proceedings of
the 5th Workshop on NLP and XML: Multi-Dimensional Markup in Natural Language Processing, NLPXML
’06, pages 81–84, Stroudsburg, PA, USA. Association for Computational Linguistics.
Karin Verspoor and Kevin Livingston. 2012. Towards adaptation of linguistic annotations to scholarly annotation
formalisms on the semantic web. In Proceedings of the Sixth Linguistic Annotation Workshop, LAW VI ’12,
pages 75–84, Stroudsburg, PA, USA. Association for Computational Linguistics.
Jonathan Wright. 2014. Restful annotation and efficient collaboration. In Nicoletta Calzolari (Conference Chair),
Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan
Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources
and Evaluation (LREC’14), Reykjavik, Iceland, may. European Language Resources Association (ELRA).
</reference>
<page confidence="0.99926">
59
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.393263">
<title confidence="0.9990225">A Conceptual Framework of Online Natural Language Pipeline Application</title>
<author confidence="0.944363">Chunqi Shi</author>
<author confidence="0.944363">Marc Verhagen</author>
<author confidence="0.944363">James</author>
<affiliation confidence="0.618472">Brandeis</affiliation>
<address confidence="0.568798">Waltham, United</address>
<email confidence="0.908466">jamesp,</email>
<abstract confidence="0.972133375">This paper describes a conceptual framework that enables online NLP pipelined applications to solve various interoperability issues and data exchange problems between tools and platforms; e.g., tokenizers and part-of-speech taggers from GATE, UIMA, or other platforms. We propose a restful wrapping solution, which allows for universal resource identification for data management, a unified interface for data exchange, and a light-weight serialization for data visualization. In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
<author>Diana Maynard</author>
<author>Hamish Cunningham</author>
</authors>
<title>Evolving gate to meet new challenges in language engineering.</title>
<date>2004</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>10--3</pages>
<contexts>
<context position="8630" citStr="Bontcheva et al., 2004" startWordPosition="1196" endWordPosition="1199">red for describing an NLP pipeline application (see Figure 3). Regarding the document format, structure and style, for example, the Text Encoding Initiative (TEI)1 provides one standard for text encoding and interchange, which also enables meta-information description. Concerning the main part (see dashdotted-line part of Figure 3), it is generally referred to as the model of annotation. For example, GATE has its own single unified model of annotation, which is organized in annotation graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML sup</context>
</contexts>
<marker>Bontcheva, Tablan, Maynard, Cunningham, 2004</marker>
<rawString>Kalina Bontcheva, Valentin Tablan, Diana Maynard, and Hamish Cunningham. 2004. Evolving gate to meet new challenges in language engineering. Nat. Lang. Eng., 10(3-4):349–373, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hamish Cunningham</author>
<author>Diana Maynard</author>
<author>Kalina Bontcheva</author>
<author>Valentin Tablan</author>
</authors>
<title>GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics (ACL’02).</booktitle>
<contexts>
<context position="1135" citStr="Cunningham et al., 2002" startWordPosition="145" endWordPosition="148">ping solution, which allows for universal resource identification for data management, a unified interface for data exchange, and a light-weight serialization for data visualization. In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components. 1 Introduction The recent work on open infrastructures for human language technology (HLT) research and development has stressed the important role that interoperability should play in developing Natural Language Processing (NLP) pipelines. For example, GATE (Cunningham et al., 2002), UIMA (Ferrucci and Lally, 2004), and NLTK (Loper and Bird, 2002) all allow integrating components from different categories based on common XML, or object-based (e.g., Java or Python) data presentation. The major categories of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer, Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution, etc. Pipelined NLP applications can be built by composing several components; for example, a text analysis application such as “relationship analysis from medical records” can b</context>
<context position="6953" citStr="Cunningham et al., 2002" startWordPosition="942" endWordPosition="945">Semantic, Pragmatic tool classifications; and Utterance, Phoneme, Morpheme, Token, Syntactic Structure, Semantic Interpretation, and Pragmatic Interpretation data classifications. (Manaris, 1998; Pustejovsky and Stubbs, 2013). From a concrete application perspective, where tools are available for concrete text mining for communities such as OpenNLP, Stanford CoreNLP and NLTK, there are classification tools such as Sentence Splitter, Tokenizer, POS Tagger, Phrase Chunker, Shallow Parser, NER, Lemmatizer, Coreference; and data classifications such as Document, Sentence, Annotation, and Feature (Cunningham et al., 2002). Figure 1: A NLP pipeline can be a (sub)-process of an abstract five-step process Morphological Lexical Syntactic Semantic Pragmatic Sentence Splitter Tokenization POS Tagging Noun-phrase chunking Lemmatization NER Coreference Resolution Figure 2: An example NLP pipeline of a concrete six-step process The knowledge types needed for designing an open infrastructure also can be seen abstractly or concretely. Abstractly, an NLP pipeline should be part of the process of morphological, lexical, syntactic, semantic to pragmatic processing (see Figure 1). From a concrete view, each component of an N</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications. In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics (ACL’02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Declerck</author>
</authors>
<title>Synaf: Towards a standard for syntactic annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06). European Language Resources Association (ELRA).</booktitle>
<contexts>
<context position="8947" citStr="Declerck, 2006" startWordPosition="1241" endWordPosition="1242">igure 3), it is generally referred to as the model of annotation. For example, GATE has its own single unified model of annotation, which is organized in annotation graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration mechanism of various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of annotation, which also has a unified XML serialization (Hahn et al., 2007). Differently from Heart of Gold’s XSLT-based mechanism, the conversion tools that brid</context>
</contexts>
<marker>Declerck, 2006</marker>
<rawString>Thierry Declerck. 2006. Synaf: Towards a standard for syntactic annotation. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06). European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Thierry Declerck</author>
</authors>
<title>A framework for standardized syntactic annotation.</title>
<date>2008</date>
<booktitle>In Bente Maegaard Joseph Mariani Jan Odijk Stelios Piperidis Daniel Tapias Nicoletta Calzolari (Conference Chair), Khalid Choukri, editor, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="9030" citStr="Declerck, 2008" startWordPosition="1251" endWordPosition="1252"> has its own single unified model of annotation, which is organized in annotation graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration mechanism of various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of annotation, which also has a unified XML serialization (Hahn et al., 2007). Differently from Heart of Gold’s XSLT-based mechanism, the conversion tools that bridge GATE annotation and UIMA annotation use GrAF as a pivot and are provided as GATE</context>
</contexts>
<marker>Declerck, 2008</marker>
<rawString>Thierry Declerck. 2008. A framework for standardized syntactic annotation. In Bente Maegaard Joseph Mariani Jan Odijk Stelios Piperidis Daniel Tapias Nicoletta Calzolari (Conference Chair), Khalid Choukri, editor, Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC’08), Marrakech, Morocco, may. European Language Resources Association (ELRA). http://www.lrecconf.org/proceedings/lrec2008/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Adam Lally</author>
</authors>
<title>Uima: An architectural approach to unstructured information processing in the corporate research environment.</title>
<date>2004</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>10--3</pages>
<contexts>
<context position="1168" citStr="Ferrucci and Lally, 2004" startWordPosition="150" endWordPosition="153">universal resource identification for data management, a unified interface for data exchange, and a light-weight serialization for data visualization. In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components. 1 Introduction The recent work on open infrastructures for human language technology (HLT) research and development has stressed the important role that interoperability should play in developing Natural Language Processing (NLP) pipelines. For example, GATE (Cunningham et al., 2002), UIMA (Ferrucci and Lally, 2004), and NLTK (Loper and Bird, 2002) all allow integrating components from different categories based on common XML, or object-based (e.g., Java or Python) data presentation. The major categories of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer, Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution, etc. Pipelined NLP applications can be built by composing several components; for example, a text analysis application such as “relationship analysis from medical records” can be composed by Sentence Splitter, </context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>David Ferrucci and Adam Lally. 2004. Uima: An architectural approach to unstructured information processing in the corporate research environment. Nat. Lang. Eng., 10(3-4):327–348, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Udo Hahn</author>
<author>Ekaterina Buyko</author>
<author>Katrin Tomanek</author>
<author>Scott Piao</author>
<author>John McNaught</author>
<author>Yoshimasa Tsuruoka</author>
<author>Sophia Ananiadou</author>
</authors>
<title>An annotation type system for a data-driven nlp pipeline.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop, LAW ’07,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9460" citStr="Hahn et al., 2007" startWordPosition="1314" endWordPosition="1317"> collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration mechanism of various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of annotation, which also has a unified XML serialization (Hahn et al., 2007). Differently from Heart of Gold’s XSLT-based mechanism, the conversion tools that bridge GATE annotation and UIMA annotation use GrAF as a pivot and are provided as GATE plugins and UIMA modules (Ide and Suderman, 2009). Thus, while a pivot standard annotation model like GrAF seems very promising, popular annotation models like those provided by GATE annotations (see Figure 4) or UIMA annotations (see Figure 4) will continue to exist and evolve for a long time. As a result, more bridge strategies, like the conversion plugin (module) of GATE (UIMA) and the XSLT-based middleware mechanism, will</context>
</contexts>
<marker>Hahn, Buyko, Tomanek, Piao, McNaught, Tsuruoka, Ananiadou, 2007</marker>
<rawString>Udo Hahn, Ekaterina Buyko, Katrin Tomanek, Scott Piao, John McNaught, Yoshimasa Tsuruoka, and Sophia Ananiadou. 2007. An annotation type system for a data-driven nlp pipeline. In Proceedings of the Linguistic Annotation Workshop, LAW ’07, pages 33–40, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Laurent Romary</author>
</authors>
<title>International standard for a linguistic annotation framework.</title>
<date>2004</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>10--3</pages>
<contexts>
<context position="8681" citStr="Ide and Romary, 2004" startWordPosition="1203" endWordPosition="1206">igure 3). Regarding the document format, structure and style, for example, the Text Encoding Initiative (TEI)1 provides one standard for text encoding and interchange, which also enables meta-information description. Concerning the main part (see dashdotted-line part of Figure 3), it is generally referred to as the model of annotation. For example, GATE has its own single unified model of annotation, which is organized in annotation graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration me</context>
</contexts>
<marker>Ide, Romary, 2004</marker>
<rawString>Nancy Ide and Laurent Romary. 2004. International standard for a linguistic annotation framework. Nat. Lang. Eng., 10(3-4):211–225, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Keith Suderman</author>
</authors>
<title>Graf: A graph-based format for linguistic annotations.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop, LAW ’07,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8811" citStr="Ide and Suderman, 2007" startWordPosition="1223" endWordPosition="1226">dard for text encoding and interchange, which also enables meta-information description. Concerning the main part (see dashdotted-line part of Figure 3), it is generally referred to as the model of annotation. For example, GATE has its own single unified model of annotation, which is organized in annotation graphs. The arcs in the graph have a start node and an end node, an identifier, a type and a set of features (Bontcheva et al., 2004). One standardization effort (Ide and Romary, 2004), the Linguistic Annotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide and Suderman, 2007), can bridge various annotation collections. Another standardization effort, the Syntactic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotation framework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration mechanism of various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of annotation, which also ha</context>
<context position="19863" citStr="Ide and Suderman, 2007" startWordPosition="2648" endWordPosition="2651">ation of a NLTK POS Tagger and the standoff ontology of annotation of POS Tagger, and between the standoff ontology of annotation of POS Tagger and the UIMA annotation of Stanford NLP NER will be reused in the NLP application created by other end-users. Our conceptual framework does not exclusively rely on the above interoperability design. Our conceptual framework (see Figure 5) should integrate existing knowledge of various annotation frameworks, for example, the alignment knowledge from the Open Annotation models (Verspoor and Livingston, 2012) and the pivot bridge knowledge from the GrAF (Ide and Suderman, 2007) under the Linguistic Annotation Framework (LAF). Thus, existing pivot conversion solutions and XSLT-based middleware solutions can also be applied. Our interactive ontology mapping design provides a more flexible choice for linguistic experts to build up NLP pipeline applications on top of heterogeneous components, without online help from engineers. Below we present varying levels of online NLP applications, according to what kind of extra support would be needed for composing different NLP components: • Components are interoperable without extra data exchange issues. For example, tools are </context>
</contexts>
<marker>Ide, Suderman, 2007</marker>
<rawString>Nancy Ide and Keith Suderman. 2007. Graf: A graph-based format for linguistic annotations. In Proceedings of the Linguistic Annotation Workshop, LAW ’07, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Ide</author>
<author>Keith Suderman</author>
</authors>
<title>Bridging the gaps: Interoperability for graf, gate, and uima.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP ’09,</booktitle>
<pages>27--34</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9680" citStr="Ide and Suderman, 2009" startWordPosition="1349" endWordPosition="1352"> and designed as the XML serialization for morpho-syntactic annotations. A NLP processing middleware, the Heart of Gold, treats XML standoff annotations for natively XML support, and provides XSLT-based online integration mechanism of various annotation collections (Sch¨afer, 2006). The UIMA specifies a UML-based data model of annotation, which also has a unified XML serialization (Hahn et al., 2007). Differently from Heart of Gold’s XSLT-based mechanism, the conversion tools that bridge GATE annotation and UIMA annotation use GrAF as a pivot and are provided as GATE plugins and UIMA modules (Ide and Suderman, 2009). Thus, while a pivot standard annotation model like GrAF seems very promising, popular annotation models like those provided by GATE annotations (see Figure 4) or UIMA annotations (see Figure 4) will continue to exist and evolve for a long time. As a result, more bridge strategies, like the conversion plugin (module) of GATE (UIMA) and the XSLT-based middleware mechanism, will continue to be necessary. In the following sections, we consider the issue of the continuing availability of such conversion functions, and whether the current realization of those two conversion strategies is sufficien</context>
</contexts>
<marker>Ide, Suderman, 2009</marker>
<rawString>Nancy Ide and Keith Suderman. 2009. Bridging the gaps: Interoperability for graf, gate, and uima. In Proceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP ’09, pages 27–34, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ishida</author>
</authors>
<title>Language grid: an infrastructure for intercultural collaboration.</title>
<date>2006</date>
<booktitle>In Applications and the Internet,</booktitle>
<pages>5--100</pages>
<contexts>
<context position="2157" citStr="Ishida, 2006" startWordPosition="289" endWordPosition="290">nce Solution, etc. Pipelined NLP applications can be built by composing several components; for example, a text analysis application such as “relationship analysis from medical records” can be composed by Sentence Splitter, Tokenizer, POS Tagger, NER, and Coreference Resolution components. In addition to interoperability, the very availability of a component can also play an important role in building online application based on distributed components, especially in tasks such as online testing and judging new NLP techniques by comparing to existing components. For example, the Language Grid (Ishida, 2006) addresses issues relating to accessing components from different locations or providers based on Service-Oriented Architecture (SOAs) models. In this paper, we explore structural, conceptual interoperability, and availability issues, and provide a conceptual framework for building online pipelined NLP applications. The conventional view of structural interoperability is that a common set of data formats and communication protocols should be specified by considering data management, data exchange, and data visualization issues. Data management determines how to access, store and locate sources</context>
<context position="12313" citStr="Ishida, 2006" startWordPosition="1634" endWordPosition="1635">ent&gt; &lt;!-- UIMA --&gt; &lt;xmi:XMI xmlns:xmi=&amp;quot;http://www.omg.org/XMI&amp;quot; xmlns:opennlp= &amp;quot;http:///org/apache/uima/examples/opennlp.ecore&amp;quot; xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot; xmi:version=&amp;quot;2.0&amp;quot;&gt; &lt;cas:Sofa xmlns:cas=&amp;quot;http:///uima/cas.ecore&amp;quot; xmi:id=&amp;quot;1&amp;quot; sofaNum=&amp;quot;1&amp;quot; sofaID=&amp;quot;_InitialView&amp;quot; mimetype=&amp;quot;text&amp;quot; sofaString=&amp;quot;Sonnet.&amp;quot; /&gt; &lt;opennlp:Token xmi:id=&amp;quot;18&amp;quot; sofa=&amp;quot;1&amp;quot; begin=&amp;quot;0&amp;quot; end=&amp;quot;6&amp;quot; posTag=&amp;quot;NNP&amp;quot; /&gt; &lt;cas:View sofa=&amp;quot;1&amp;quot; members=&amp;quot;18&amp;quot;/&gt; &lt;/xmi:XMI&gt; Figure 4: Examples of GATE XML annotation and UIMA XML annotation a promising approach. For example, while the Language Grid infrastructure makes NLP tools highly available (Ishida, 2006), it can still have limitations regarding interoperability issues. Generally, service interfaces can be either operation-oriented which allows flexible operations with simple input/output data, or resource-oriented which allows flexible input/output data with simple operations. The NLP processing services of Language Grid are more or less operation-oriented, and lack a certain structural flexibility for composing with each other. We present a resource-oriented view of NLP tools, which should have universal resource identification for distributed reference, an SQL-like data management, and a li</context>
</contexts>
<marker>Ishida, 2006</marker>
<rawString>T. Ishida. 2006. Language grid: an infrastructure for intercultural collaboration. In Applications and the Internet, 2006. SAINT 2006. International Symposium on, pages 5 pp.–100, Jan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>Nltk: The natural language toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics - Volume 1, ETMTNLP ’02,</booktitle>
<pages>63--70</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1201" citStr="Loper and Bird, 2002" startWordPosition="156" endWordPosition="159"> data management, a unified interface for data exchange, and a light-weight serialization for data visualization. In addition, we propose a semantic mapping-based pipeline composition, which allows experts to interactively exchange data between heterogeneous components. 1 Introduction The recent work on open infrastructures for human language technology (HLT) research and development has stressed the important role that interoperability should play in developing Natural Language Processing (NLP) pipelines. For example, GATE (Cunningham et al., 2002), UIMA (Ferrucci and Lally, 2004), and NLTK (Loper and Bird, 2002) all allow integrating components from different categories based on common XML, or object-based (e.g., Java or Python) data presentation. The major categories of components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer, Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution, etc. Pipelined NLP applications can be built by composing several components; for example, a text analysis application such as “relationship analysis from medical records” can be composed by Sentence Splitter, Tokenizer, POS Tagger, NER, and C</context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. Nltk: The natural language toolkit. In Proceedings of the ACL-02 Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics - Volume 1, ETMTNLP ’02, pages 63–70, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Manaris</author>
</authors>
<title>Natural language processing: A human-computer interaction perspective.</title>
<date>1998</date>
<contexts>
<context position="6523" citStr="Manaris, 1998" startWordPosition="885" endWordPosition="886">xchanged in the open infrastructure consisting of source data information, NLP tools information, and the knowledge that allows the tools to work together. What are the main entity types of data and tools in designing an open infrastructure for online NLP pipeline applications? From an abstract view of how linguistic analysis is related to human knowledge, there are the following: Morphological, Lexical, Syntactic, Semantic, Pragmatic tool classifications; and Utterance, Phoneme, Morpheme, Token, Syntactic Structure, Semantic Interpretation, and Pragmatic Interpretation data classifications. (Manaris, 1998; Pustejovsky and Stubbs, 2013). From a concrete application perspective, where tools are available for concrete text mining for communities such as OpenNLP, Stanford CoreNLP and NLTK, there are classification tools such as Sentence Splitter, Tokenizer, POS Tagger, Phrase Chunker, Shallow Parser, NER, Lemmatizer, Coreference; and data classifications such as Document, Sentence, Annotation, and Feature (Cunningham et al., 2002). Figure 1: A NLP pipeline can be a (sub)-process of an abstract five-step process Morphological Lexical Syntactic Semantic Pragmatic Sentence Splitter Tokenization POS T</context>
</contexts>
<marker>Manaris, 1998</marker>
<rawString>Bill Manaris. 1998. Natural language processing: A human-computer interaction perspective.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Pirr´o</author>
<author>Domenico Talia</author>
</authors>
<title>Ufome: An ontology mapping system with strategy prediction capabilities.</title>
<date>2010</date>
<journal>Data Knowl. Eng.,</journal>
<volume>69</volume>
<issue>5</issue>
<marker>Pirr´o, Talia, 2010</marker>
<rawString>Giuseppe Pirr´o and Domenico Talia. 2010. Ufome: An ontology mapping system with strategy prediction capabilities. Data Knowl. Eng., 69(5):444–471, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Amber Stubbs</author>
</authors>
<title>Natural language annotation for machine learning. O’Reilly</title>
<date>2013</date>
<location>Media, Sebastopol, CA.</location>
<contexts>
<context position="6554" citStr="Pustejovsky and Stubbs, 2013" startWordPosition="887" endWordPosition="890"> open infrastructure consisting of source data information, NLP tools information, and the knowledge that allows the tools to work together. What are the main entity types of data and tools in designing an open infrastructure for online NLP pipeline applications? From an abstract view of how linguistic analysis is related to human knowledge, there are the following: Morphological, Lexical, Syntactic, Semantic, Pragmatic tool classifications; and Utterance, Phoneme, Morpheme, Token, Syntactic Structure, Semantic Interpretation, and Pragmatic Interpretation data classifications. (Manaris, 1998; Pustejovsky and Stubbs, 2013). From a concrete application perspective, where tools are available for concrete text mining for communities such as OpenNLP, Stanford CoreNLP and NLTK, there are classification tools such as Sentence Splitter, Tokenizer, POS Tagger, Phrase Chunker, Shallow Parser, NER, Lemmatizer, Coreference; and data classifications such as Document, Sentence, Annotation, and Feature (Cunningham et al., 2002). Figure 1: A NLP pipeline can be a (sub)-process of an abstract five-step process Morphological Lexical Syntactic Semantic Pragmatic Sentence Splitter Tokenization POS Tagging Noun-phrase chunking Lem</context>
</contexts>
<marker>Pustejovsky, Stubbs, 2013</marker>
<rawString>James Pustejovsky and Amber Stubbs. 2013. Natural language annotation for machine learning. O’Reilly Media, Sebastopol, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Sch¨afer</author>
</authors>
<title>Middleware for creating and combining multi-dimensional nlp markup.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th Workshop on NLP and XML: Multi-Dimensional Markup in Natural Language Processing, NLPXML ’06,</booktitle>
<pages>81--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Sch¨afer, 2006</marker>
<rawString>Ulrich Sch¨afer. 2006. Middleware for creating and combining multi-dimensional nlp markup. In Proceedings of the 5th Workshop on NLP and XML: Multi-Dimensional Markup in Natural Language Processing, NLPXML ’06, pages 81–84, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Verspoor</author>
<author>Kevin Livingston</author>
</authors>
<title>Towards adaptation of linguistic annotations to scholarly annotation formalisms on the semantic web.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixth Linguistic Annotation Workshop, LAW VI ’12,</booktitle>
<pages>75--84</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="19793" citStr="Verspoor and Livingston, 2012" startWordPosition="2636" endWordPosition="2639"> the Stanford NLP NER. This particular semantic mapping between JSON serialization of a NLTK POS Tagger and the standoff ontology of annotation of POS Tagger, and between the standoff ontology of annotation of POS Tagger and the UIMA annotation of Stanford NLP NER will be reused in the NLP application created by other end-users. Our conceptual framework does not exclusively rely on the above interoperability design. Our conceptual framework (see Figure 5) should integrate existing knowledge of various annotation frameworks, for example, the alignment knowledge from the Open Annotation models (Verspoor and Livingston, 2012) and the pivot bridge knowledge from the GrAF (Ide and Suderman, 2007) under the Linguistic Annotation Framework (LAF). Thus, existing pivot conversion solutions and XSLT-based middleware solutions can also be applied. Our interactive ontology mapping design provides a more flexible choice for linguistic experts to build up NLP pipeline applications on top of heterogeneous components, without online help from engineers. Below we present varying levels of online NLP applications, according to what kind of extra support would be needed for composing different NLP components: • Components are int</context>
</contexts>
<marker>Verspoor, Livingston, 2012</marker>
<rawString>Karin Verspoor and Kevin Livingston. 2012. Towards adaptation of linguistic annotations to scholarly annotation formalisms on the semantic web. In Proceedings of the Sixth Linguistic Annotation Workshop, LAW VI ’12, pages 75–84, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jonathan Wright</author>
</authors>
<title>Restful annotation and efficient collaboration.</title>
<date>2014</date>
<booktitle>Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani,</editor>
<location>Asuncion Moreno,</location>
<contexts>
<context position="13914" citStr="Wright, 2014" startWordPosition="1863" endWordPosition="1864">are wrapped into Restful services so that they are operated through HTTP GET protocol, and the XML serialization of UIMA annotation is applied for input and output, each NLP components will have the same interface and data structure. Once an internationalized resource identifier (IRI) is given, all the input and output of tools can be distributed and ubiquitously identified. Moreover, a PUT/GET/POST/DELETE protocol of restful data management is equivalent to an SQL-like CRUD data management interface. For example, an IRI can be defined by a location identifier and the URL of the data service (Wright, 2014). In addition, a lightweight serialization of stand-off annotation can benefit the online visualization of data, which will be easy for experts to read, judge, or edit. For example, the XML serialization of UIMA annotation can be transferred into JSON serialization, which is preferred for online reading or editing. NLP tool services will be available by applying restful wrapping (see Figure 5). However, structural interoperability based on the restful wrapping is not enough for conceptual interoperability. For example, if an OpenNLP tokenizer is wrapped using HTTP GET protocol and GATE annotat</context>
</contexts>
<marker>Wright, 2014</marker>
<rawString>Jonathan Wright. 2014. Restful annotation and efficient collaboration. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland, may. European Language Resources Association (ELRA).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>