<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.620602">
From Natural Language to RDF Graphs with Pregroups
</title>
<author confidence="0.509621">
Antonin Delpeuch
</author>
<note confidence="0.745845">
École Normale Supérieure
45 rue d’Ulm
75005 Paris, France
</note>
<email confidence="0.992994">
antonin.delpeuch@ens.fr
</email>
<sectionHeader confidence="0.994698" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999860736842105">
We define an algorithm translating natural
language sentences to the formal syntax of
RDF, an existential conjunctive logic widely
used on the Semantic Web. Our translation
is based on pregroup grammars, an efficient
type-logical grammatical framework with a
transparent syntax-semantics interface. We in-
troduce a restricted notion of side effects in
the semantic category of finitely generated free
semimodules over {0, 1} to that end. The
translation gives an intensional counterpart to
previous extensional models. We establish
a one-to-one correspondence between exten-
sional models and RDF models such that sat-
isfaction is preserved. Our translation encom-
passes the expressivity of the target language
and supports complex linguistic constructions
like relative clauses and unbounded dependen-
cies.
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99953952173913">
There is a general agreement that Natural Language
Processing has two aspects. One is syntax, rules how
words are put together to form a grammatical string.
The other is semantics, rules how meanings of strings
are computed from the meanings of words. To this we
add a third aspect, namely that semantics must include
rules of logic how to compute the truth of the whole
string from the truth of its parts.
The Resource Description Framework (RDF)
(Hayes and McBride, 2004) is an artificial language
that takes the intuitive form of knowledge graphs. Its
semantics has the expressive power of the fragment of
multisorted first order logic that uses conjunction and
existential quantification only. This restricted expres-
sive power limits the statements of natural language
that can be interpreted as RDF graphs. Typically,
statements with negation words are excluded.
We use pregroup grammars as the linguistic and
mathematical tool to recognise and interpret natu-
ral language strings in RDF. Pregroup Calculus, also
known as Compact Bilinear Logic (Lambek, 1993)
(Lambek, 1999), is a simplification of Lambek’s Syn-
tactic Calculus, (Lambek, 1958). Pregroup grammars
</bodyText>
<note confidence="0.99107725">
Anne Preller
LIRMM
161 rue Ada
34392 Montpellier Cedex 5, France
</note>
<email confidence="0.977424">
preller@lirmm.fr
</email>
<bodyText confidence="0.99988612">
are based on a lexicon like all categorial grammars.
Syntactical analysis consists in the construction of a
proof (derivation) in the calculus.
All semantics proposed so far use functors from
the lexical category of (Preller and Lambek, 2007)
into some symmetric compact closed category. They
include the compositional distributional vector space
models of (Clark et al., 2008), (Kartsaklis et al., 2013)
based on context and the functional logical models of
(Preller, 2012).
We proceed as follows. Recalling that words and
grammatical strings recognised by the grammar are
represented by meaning-morphisms in the lexical cat-
egory, we propose a &amp;quot;syntactic&amp;quot; functor from the latter
into a symmetric monoidal category Cs of ‘morphisms
with side effects’ over the category C of finite dimen-
sional semimodules over the lattice B = {0,1}. The el-
ements of the semimodule S identify with RDF graphs.
The value of the syntactic functor at a statement is the
RDF graph of the statement. The extensional models
of logic are recast as &amp;quot;semantic&amp;quot; functors from the lexi-
cal category to C. We associate to any semantic functor
an RDF interpretation and show that a statement is true
in the semantic functor if and only if the corresponding
RDF graph is true in the RDF interpretation.
</bodyText>
<sectionHeader confidence="0.99504" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<subsectionHeader confidence="0.854706">
2.1 RDF graphs
</subsectionHeader>
<bodyText confidence="0.993397833333333">
RDF is a widely-adopted framework introduced in
(Hayes and McBride, 2004) as a standard for linked
information representation on the Web. Informally, an
RDF graph is a set of labeled links between objects,
which represent statements concerning the linked ob-
jects.
Throughout this article we will simply consider that
they are represented by strings of characters without
spaces, written in a mono-spaced font: the entity John
is denoted by the string John.
A link between two objects is a triple, made of one
entity (the subject of the predicate), a property (the type
of the link, also represented by a string) and a second
entity (the object of the predicate). Graphically, we rep-
resent a triple as a directed property from the subject to
the object, labeled by the predicate.
RDF allows to use nodes without labels, called blank
nodes. Concretely, this means that we can always pick
</bodyText>
<page confidence="0.981216">
55
</page>
<note confidence="0.9918465">
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 55–62,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.904077727272727">
a fresh node, named blank-n where n is some num-
ber, such that this node is not involved in any triple yet.
An example We can represent the sentence John
owns a white boat using a fresh blank node for a white
boat:
John owns blank-1
blank-1 rdf:type boat
blank-1 is_white true
Here, rdf:type is a special RDF predicate indicating
the type of its subject. The graph representing this set
of triples is
</bodyText>
<figure confidence="0.798756">
John blank-1
true boat
</figure>
<figureCaption confidence="0.999831">
Figure 1: A graph with a blank node
</figureCaption>
<bodyText confidence="0.999811384615385">
Recall that our goal is to translate natural language
sentences to graphs. Graphs can indeed be seen as se-
mantic representations of sentences, in the sense that
they can be used to assign a truth value to a sentence,
trough the notion of entailment (Hayes and McBride,
2004).
A graph H is an instance of G when H can be ob-
tained from G by assigning labels to some blank nodes
(possibly none of them). A graph G0 entails another
graph G if an instance of G is a subgraph of G0. With
these definitions, we can define true RDF graphs as the
graphs entailed by some reference graph, storing all the
true facts.
</bodyText>
<subsectionHeader confidence="0.999021">
2.2 Pregroup grammars
</subsectionHeader>
<bodyText confidence="0.94858456">
A pregroup grammar (Lambek, 1999), consists of the
free pregroup C(B) generated by a partially ordered
set B and a lexicon Dg. By ‘free pregroup’ we mean
the free compact closed category C(B) generated by
B following the version given in (Preller and Lambek,
2007)1. The lexicon Dg introduces the monoidal cat-
egory Lg, freely generated by the inequalities and the
lexical morphisms given by the lexicon. Lexical entries
have &amp;quot;formal meanings&amp;quot; in the lexical category, the free
compact closed category generated by B and the mor-
phisms introduced by the words. They are analogue to
the lambda-terms intervening in categorial grammars,
(Steedman, 1996).
The working of pregroup grammars can be described
without explicit use of category theory. The main result
of this section however, the decomposition lemma, in-
vokes properties of the graphs proved in (Preller and
Lambek, 2007).
1Semantics requires more than one morphism between
objects, whereas the partial preorder of the free pregroup of
(Lambek, 1999) confounds all morphisms with identical do-
main and codomain.
We start with the formal definition of a monoidal cat-
egory followed by the condition it must satisfy to be
compact closed.
</bodyText>
<construct confidence="0.73158">
Definition 1. A category C is
</construct>
<listItem confidence="0.9774385">
1. monoidal if there is a bifunctor ⊗ : C × C → C,
a distinguished object I, the unit of ⊗, satisfying
(A ⊗ B) ⊗ C = A ⊗ (B ⊗ C), (f ⊗ g) ⊗ h =
f ⊗ (g ⊗ h) 2
2. compact closed if it is monoidal and there are con-
travariant endofunctors ( )r and ( )`, called right
adjoint and left adjoint, such that for every object
A and every morphism f : A → B there are mor-
phisms ηf : I → Ar ⊗ A, the name of f, and
Ef : A ⊗ Br → I, the coname off, satisfying for
</listItem>
<equation confidence="0.965305428571429">
anyg:B → C
(A ⊗ B)r = Br ⊗ Ar, (A ⊗ B)` = B` ⊗ A`
(Ef ⊗ 1C) ◦ (1A ⊗ ηg) = g ◦ f
(1A* ⊗ Eg) ◦ (ηf ⊗ 1C-) = (f ◦ g)r .
3. symmetric if it is monoidal and there is a natural
isomorphism σAB : A ⊗ B → B ⊗ A such that
σ−1
AB = σBA.
Recall that ⊗ is a bifunctor if and only if the follow-
ing equalities are satisfied for all objects A, B and all
morphisms fi : Ai → Bi, gi : Bi → Ci, i = 1, 2
1A ⊗ 1B = 1A®B
Interchange Law (1)
(f2 ◦ f1) ⊗ (g2 ◦ g1) = (f2 ⊗ g2) ◦ (f1 ⊗ g1)
</equation>
<bodyText confidence="0.9999382">
The morphisms of C(B) and Lg identify with
graphs, which we now describe without invoking cat-
egory theory.
The objects of C(B) are called types. They include
the elements of B, called basic types. For instance, the
set B may include the basic types s for statements, d
for determiners, n for noun phrases, o for direct ob-
jects with corresponding types in relatives clauses r,
nˆ and ˆo. There is only one strict inequality n &lt; o.
Assimilating B to a category, we write iab : a → b
instead of a ≤ b and 1a for iaa. A simple type
is an iterated left adjoint or right adjoint of a basic
type ..., a`` = a(−2), a` = a(−1), a = a(0), ar =
a(1), arr = a(2), .... The iterator of t = a(z) is the
integer z. An arbitrary type is a string of simple types
separated by the symbol ⊗. In particular, the empty
string is a type, denoted I.
The lexicon of a pregroup grammar consists of a set
of pairs word : T where the type T ∈ C(B) captures
the different grammatical roles a word may play. For
</bodyText>
<footnote confidence="0.8944232">
2Strictly speaking, these equalities hold up to natural iso-
morphisms, but the coherence theorem of (Mac Lane, 1971)
makes it possible to replace the isomorphisms by equalities
without loss of generality.
owns
</footnote>
<page confidence="0.79245">
56
</page>
<equation confidence="0.9567632">
instance
proper name : n
transitive verb: nr ® s ® o`
transitive verb : ˆnr ® r ® o`
transitive verb: nr ® ˆor ® r
determiner : d
adjective : dr ® d
countnoun : dr ® n
relpronoun : nr ® n ® r` ® nˆ
relpronoun : nr ® n ® r` ® oˆ
</equation>
<bodyText confidence="0.997673592592592">
A pregroup grammars analyses a string of words by
constructing a graph: choose an entry wi : Ti for each
word wi and align the types in the order of the words.
Place non-crossing oriented underlinks such that the
tail of an underlink is a basic type with an even num-
ber of iterations, say t = a(z), where z = f2n. If
the head is to the left of the tail then it is the left ad-
joint b(z)` = b(z−1), for some basic type b &gt; a. If it
is to the right then its a right adjoint b(z)r = b(z+1).
Complete the graph by repeating the nodes that are not
head or tail of an underlink in a line below and adding
a vertical link between corresponding nodes.
The string is said to be grammatical if exactly one
simple type remains that is not the tail or head of an
underlink and if it is a basic type. The resulting graph
is called a reduction and denotes a unique morphism
r : T1 ® ... ® Tn → b of C(B). More generally, graphs
standing for morphisms align the domain above and the
codomain below.
For instance, the graph below exhibits a reduction to
the sentence type s
john owns a white boat
The following two graphs are reductions to the noun
phrase type n. The first graph corresponds to the case
where the relative pronoun is the object of the verb in
the relative clause whereas it is the subject in the sec-
ond graph
</bodyText>
<figure confidence="0.419129">
a cat that bob hates
a cat that hates bob
</figure>
<equation confidence="0.83807">
d ® dr ® n ® nr ® n ® r` ® nˆ® ˆnr ® r ® o` ® n
e� ?� c�
V
n
</equation>
<bodyText confidence="0.999888">
The meanings of words are also represented by
graphs that correspond to morphisms of the lexical cat-
egory Gg. In fact, every entry w : T in the lexicon
gives rise to a meaning morphism wT : I → T and a
lexical morphism wT represented by the following ori-
ented labelled graphs
</bodyText>
<equation confidence="0.997468375">
T = ar ® b
T = ar ® b ® c`
wT
wT =�
ar ® b ® c`
T = ar ® cr ® b
wT = ��
ar ® cr ® b
</equation>
<bodyText confidence="0.995161666666667">
If T has two factors that are basic types, there is besides
the main lexical morphism wT an auxiliary lexical mor-
phism jT.
</bodyText>
<equation confidence="0.999391">
T = nr ® n ® r` ® d, d = ˆn, oˆ
jd
thatT =
</equation>
<bodyText confidence="0.9881121">
We omit the subscript T if this does not lead to confu-
sion.
The nodes of the meaning graphs are the simple
types of T. They form the lower line of the graph, the
upper line is the empty string I. The corresponding
morphism has domain I and codomain T. An overlink
may have several tails but only one head. The tails of
overlinks are right or left adjoints of basic types, the
head is a basic type3.
The lexical category Gg generated by the lexicon
Dg is the compact closed category freely generated by
B, the symmetry morphisms Qab and the lexical mor-
phisms introduced by Dg.
Strings of words also have meaning(s) in the lex-
ical category. The lexical meaning of a grammati-
cal string word1 ... wordn recognised by the reduction
r : T1 ... Tn → b is, by definition, the composite of
the tensor product of the word meanings and the cho-
sen reduction.
r o (word1T1 ® ... ® wordnTn) : I → b.
The meaning of a composite morphism g o f can be
simplified graphically. Stack the graph of f above the
graph of g and walk the paths of the graph starting at
a node that is not the head of a link until you arrive
at a node that is not the tail of a link. Compose the
labels in the order they are encountered along the path.
Replace the whole path by a single link labelling it by
the composite label of the path. The resulting graph
represents the morphism g o f, (Selinger, 2011).
For instance, the grammatical strings mentioned
</bodyText>
<figure confidence="0.984906818181818">
(n) ® (nr ® s ® o`) ® (d) ® (dr ® d) ® (dr ® n)
;� g� ;� ;�
V
s
d ® dr ® n ® nr ® n ® r` ® oˆ® n ® nr ® ˆor ® r
b�
n
?� ?�
?�:�
V
w
�&amp;quot;
wT =
a
wT = w V
b
ar ® b
?�?�
w
a ® c
❚❚❚ ❥❥❥
wT = wT �
b
c ® a
❚❚❚ ❥❥❥
wT = wT �
b
nr ® n ® r` ®-\d
that
r jd n
that N
� d
n
</figure>
<footnote confidence="0.485084">
3&amp;quot;basic type&amp;quot; is replaced by simple type with an even iter-
ator in the general case
</footnote>
<equation confidence="0.543270333333333">
= wb
wb = w l
b
</equation>
<page confidence="0.941426">
57
</page>
<bodyText confidence="0.924547">
above above simplify to
</bodyText>
<equation confidence="0.987481605263158">
T = ˆnr ⊗ r ⊗ oP
a cat
hater bob
that� �
d ⊗ dr ⊗ n ⊗ nr ⊗ n ⊗ rP ⊗ nˆ ⊗ ˆnr ⊗ r ⊗ oP ⊗ n
�� �� !! �
ee ?? ff
�
n
a cat
bob hater ,
that�
d ⊗ dr⊗ n ⊗ nr⊗ n ⊗ rP ⊗ oˆ⊗ n ⊗ nr⊗ˆor ⊗ r
����!!� ��
?? ?? ddV
??::
n
= that
((cat
a)
◦hateT,◦
◦
⊗ bob)] : I ⊗ I → n
own
(john
white
a))
= own
(1„•
(1„•
(1„•
◦
⊗ (boat◦
◦
◦
⊗ in)◦
⊗ boat)◦
⊗ white))◦(john⊗ a) .
</equation>
<bodyText confidence="0.935194846153846">
&lt; jkl.
In particular, the meaning of the string belongs to
the monoidal category generated by the lexicon
This is a straightforward consequence of the charac-
terisation of morphisms as normal graphs in the free
category, (Preller and Lambek, 2007) and the inter-
change law.
We map lexical morphisms to &amp;quot;unfinished&amp;quot; RDF
triples
lexical morphism RDF triple
noun: d
n ? rdf :type noun
d ? is-adjective true
</bodyText>
<equation confidence="0.989308933333333">
◦(word1⊗ ...⊗ words)= p1◦···◦
◦
⊗ ...⊗ wordim)
jk
→
→
verb : a ⊗ b→ c ? verb ?
determiner : I → d blank ? ?,
? ? blank
propername : I → n propername ? ?,
? ? propername
the lexical meaning of the string satisfies
r
ps,,,
(wordil
</equation>
<bodyText confidence="0.975453818181818">
,
where each pk is either a tensor product of inequalities
of basic types or a tensor product of inequalities and
one property word wordjk. Moreover, k &lt; k&apos; implies
The question marks designate unoccupied positions in
the triple. Node words occupy either the subject or the
object position, unary property words leave only the
subject position open, binary property words occupy
the centre position leaving subject and object position
unoccupied. Finally, the noun phrases a cat that hates
Bob and a cat that Bob hates are respectively translated
</bodyText>
<figure confidence="0.963772782608695">
(3)
owing graphs :
adjective : d
Bob cat
(a) A cat that hates Bob
own white boat
~john � a
(n) ⊗ �nr ⊗ s⊗ oP) ⊗ (d) ⊗ (dr ⊗ ted) (9dr ⊗ n)
�
s
I
boatoredoa
= owno(john®(boatoredoa))
�
s
john �
=
I
n ⊗ o
❚❚❚ ❥❥❥
own V
?? ??
blank-1 blank-1
</figure>
<bodyText confidence="0.930535142857143">
with domain I a node word and an
y other lexical mor-
phism aproperty word.
Lemma 1 (Decomposition). Let word1 ...words
be a grammatical string with lexical morphisms
word1, ... ,words and a reduction r : T1 ... Ts →
b. Then there is an enumeration of the node words
</bodyText>
<equation confidence="0.92436075">
wordil : I → b1, ... , wordim : I → bs,, such that
s
that ◦ hateT ◦ ((cat ◦ a) ⊗ bob)] : I ⊗ I → n
T&apos; = nr⊗ˆor ⊗ r
</equation>
<bodyText confidence="0.9810225">
All unlabelled links in the graph above correspond
to inequalities of basic types. Inserting the strict in-
equalities at the appropriate place and applying the in-
terchan
ge law, we decompose the label into minimal
building blocks that correspond one-to-one to the re-
sources occurring in the RDF graph associated to the
statement. For example,
(2)
The expression after the equality symbol above is a
composite of tensor products the factors of which are
either inequalities between basic objects or lexical mor-
phisms. Only the rightmost tensor product contains
more than one lexical morphism. In fact, all factors
are lexical morphisms with domain I.
The translation of statements to RDF graphs rests on
the existence of this decomposition. Borrowing the ter-
minology of RDF graphs, call any lexical morphism
</bodyText>
<page confidence="0.994506">
58
</page>
<figure confidence="0.857421291666667">
to the foll
Bob cat
(b) A cat that Bob hates
3 The Translation
Let B
+,
be the commutative semiring in
which the addition, +, is the lattice operator
and the
multiplication,
lattice operator
on
The semantic category which hosts the RDF graphs
and our models of grammatical strings is the category C
of finitely generated semimodules over B. Itis compact
closed satisfying AP = A =
for each object A.
Every object A has
basis (ei)i such that
every element v
A can be written uniquely as v =
Ei
where
B. We refer to elements ofA as
</figure>
<figureCaption confidence="0.3323455">
vectors. Morphisms of C are maps that commute with
addition and scalar multiplication.
</figureCaption>
<bodyText confidence="0.5774395">
We interpret RDF graphs as elements of a semimod-
ule S determined
</bodyText>
<equation confidence="0.936418">
=h{0,1},
·i
∨
·, the
∧
{0,1}.
Ar
a‘canonical’
∈
αiei,
αi∈
</equation>
<bodyText confidence="0.996176777777778">
by the RDF vocabulary, see below.
The translation of grammatical strings is given by a
functor from the monoidal category generated by the
lexical morphisms into a category of morphisms with
side effects mapping the decomposition of a grammati-
cal string to a vector of S.
Let L be a set of labels that includes the property
words and a ‘very large’, but finite number n0 of la-
bels blanki, for i = 1,... n04. The other elements
of L are node names and property names of an RDF
vocabulary.
Define N as the semimodule over the semi-ring B
freely generated by L and denote elabel the basis vec-
tor of N corresponding to label ∈ L. We present
RDF triples by basis vectors of S = N ⊗ N ⊗ N and
RDF graphs by sums of basis vectors of S, for instance
ebob ⊗ehate ⊗eblank +eblank ⊗erdf−type ⊗ecat. Hence,
the vector sum models the union of RDF graphs.
We want to interpret the lexical morphisms such that
they construct a triple when applied to an argument and
add it to the vector of S already constructed. Composi-
tion of the category C alone is not powerful enough to
achieve this. We define a new category CS in which
the entity a white boat will be denoted by the pair
(eblank-1, eblank-1 ⊗ erdf:type ⊗ eboat + eblank-1 ⊗ eis-white ⊗
etrue).
Therefore we switch from C to the monoidal cate-
gory CS below in which arrows have two components.
The first component creates the triple and the second
component adds the new triple to the graph as a ‘side
effect’.
Definition 2 (Category with Side Effects). Let
{a1, ... , am} and {b1, ... , bn} be the basis5 of A and
B. For any p ∈ C(A, S), q ∈ C(B, S), define p⊗+q ∈
C(A ⊗ B, S) as the unique linear map satisfying for an
arbitrary basis vector ai ⊗ bj of A ⊗ B
</bodyText>
<equation confidence="0.733406">
(p ⊗+ q) : ai ⊗ bj 7→ p(ai) + q(bj) .
</equation>
<bodyText confidence="0.95254">
The category CS of morphisms with side effects in S
has:
</bodyText>
<listItem confidence="0.997662444444444">
• objects as in C
• morphisms (f, p) : A → B where f ∈ C(A, B),
Ker(f) = {0} and p ∈ C(A, S).
• arrows 1A = (1A, 0).
• an operation ◦ defined by (f, p) ◦ (h, q) = (f ◦ h, p ◦
h + q).
• an operation ⊗ on objects defined as in C
• an operation ⊗ on arrows defined by (f, p) ⊗
(h, q) = (f ⊗ h, p ⊗+ q).
</listItem>
<bodyText confidence="0.965431166666667">
Examples of morphisms in the first component are
the symmetry Q : N ⊗N → N ⊗N, 71, 72 : N ⊗N →
N defined by Q(ai ⊗ bj) = bj ⊗ ai, 71(ai ⊗ bj) = ai
and 72(ai ⊗ bj) = bj.
The new operation ⊗+ introduced above concerns
the second component only. The morphism p ⊗+ q
</bodyText>
<footnote confidence="0.990028">
4it suffices that no exceeds the number of occurrences of
determiners in the set of digitalised documents
5In C, every object has a unique basis: the canonical one.
</footnote>
<figureCaption confidence="0.4769465">
computes at ai ⊗ bj the union of the RDF graphs p(ai)
and q(bj), computed separately by p and q.
</figureCaption>
<bodyText confidence="0.9935875">
As an illustration, consider the following morphisms
of CS
</bodyText>
<equation confidence="0.610548">
mjohn = (ejohn,0), mblanki = (eblanki,0)
</equation>
<bodyText confidence="0.999903">
The arrow of a proper noun consists of the node rep-
resenting this entity, e.g. ejohn, paired with the empty
graph represented by 0 ∈ S. Choosing the empty graph
means that nothing is said about this node. A similar
remark holds for determiners.
</bodyText>
<equation confidence="0.8855675">
mwhite = (1N, 1N ⊗ eis-white ⊗ etrue),
mboat = (1N, 1N ⊗ erdf-type ⊗ eboat)
</equation>
<bodyText confidence="0.99338275">
An adjective or a noun is a morphism that maps a node
word to itself and to the empty slot in the corresponding
triple. As a side effect, it adds this triple to the second
component.
</bodyText>
<equation confidence="0.818594">
mown = (1N ⊗ eown ⊗ 1N, 1N ⊗ eown ⊗ 1N)
</equation>
<bodyText confidence="0.92309075">
A transitive verb is a morphism that maps an ordered
pair of nodes to a triple making the first the subject and
the second the object of the triple.
Compose the morphisms
</bodyText>
<equation confidence="0.996078888888889">
mwhite ◦ mblanki = (eblanki,t1)
t1 = (eblanki ⊗ eis-white ⊗ etrue)
mboat ◦ mwhite ◦ mblanki = (eblanki, t2 + t1)
t2 = (eblanki ⊗ erdf-type ⊗ eboat)
mown ◦ (mjohn ⊗ (mboat ◦ mwhite ◦ mblanki)) =
mown ◦ (ejohn ⊗ eblanki,0 + t2 + t1) =
(ejohn ⊗ eown ⊗ eblanki, t3 + t2 + t1)
t3 = ejohn ⊗ eown ⊗ eblanki
(4)
</equation>
<bodyText confidence="0.882387">
The effect of composition is to create a new triple on
the left of the comma and to store it on the right.
Proposition 1. The category with side effects CS is a
monoidal category.
The proof of this proposition is given in appendix A.
Define a monoidal structure preserving functor F
from the monoidal category generated by the lexical
morphisms to CS thus
</bodyText>
<listItem confidence="0.9998685">
• F(s) = S = N ⊗ N ⊗ N
• F(a) = N if a =6 s //�&amp;quot;
• F(1a) = F(ia b) = F1✓a b) = 1y(a), for all basic
types a, b ∈ B
• F(that : r → n) = (1, 0)
• F(name : I → d) = (ename, 0)
• F(determiner : I → d) = (eblanki, 0)
• F(word : dr ⊗ n) = (1, 1 ⊗ erdf-type ⊗ eword)
• F(word : dr ⊗ d) = (1, 1 ⊗ eis-word ⊗ etrue)
• F(wordnr®s®ol) = (1 ⊗ eword ⊗ 1,1 ⊗ eword ⊗ 1)
</listItem>
<equation confidence="0.883618">
F(wordˆnr®r®ol) = (71, 1 ⊗ eword ⊗ 1)
F(wordnr®ˆor®r) = (72, (1 ⊗ eword ⊗ 1) ◦ Q).
</equation>
<bodyText confidence="0.69927425">
Note that the morphisms in the example above satisfy
mword = F(word). Computation (4) shows that F
maps the lexical meaning of john owns a white boat to
the three RDF triples t1, t2, t3.
</bodyText>
<page confidence="0.996271">
59
</page>
<figure confidence="0.358467">
Lemma 2. Let word1 ... wordn be a statement with
corresponding lexical entries word1 : T1 ... wordn :
Tn and r : T1 ... Tn → s a reduction to the sentence
type. Then second component of
... ⊗ Uim is said to be a selector if for any basis vector
</figure>
<equation confidence="0.903895">
e1 ⊗ ... ⊗ en ∈ U1 ⊗ ... ⊗ Un
q(e1⊗...⊗en) = ei1⊗...⊗eim or q(e1⊗...⊗en) = 0.
F(r ◦ (word, ⊗ ... ⊗ word,,)) =
(f, t1 + ··· + tm) ∈ CS(I,S)
</equation>
<bodyText confidence="0.761683285714286">
is a sum of RDF triples ti ∈ S, for k = 1, ... , m.
Moreover, tk has the form (3) determined by the prop-
erty word wordjk such that the unlabelled nodes are
filled by node words of the statement.
The proof is given in Appendix B.
Definition 3 (RDF Translation). The RDF graph trans-
lating the statement word1 ... wordn with reduction
</bodyText>
<equation confidence="0.630496888888889">
r : T1 ... Tn → s is the second component of F(r ◦
(word, ⊗ ... ⊗ word,,)).
For instance, the translation of the statement John
owns a white boat is
ejohn ⊗ eown ⊗ eblanki + eblanki ⊗ eis-white ⊗ etrue
+ eblanki ⊗ erdf-type ⊗ eboat,
because
F(own ◦ (john ⊗ (boat ◦ white ◦ a))
= mown ◦ (mjohn ⊗ (mboat ◦ mwhite ◦ mblanki)) .
</equation>
<bodyText confidence="0.999984571428571">
The translation algorithm from text to RDF graphs
starts with a parsing algorithm of pregroup grammars
that chooses a type for each word of the statement and
provides a reduction to the sentence type. Next it com-
putes the decomposition of the formal meaning in the
lexical category by ‘yanking’. Finally it computes the
RDF graph by applying the translation functor F to the
decomposition. The parsing algorithm is cubic poly-
nomial in the number of words. Decomposition is lin-
ear, because the number of links is proportional to the
number of words. Finally, translation again is linear,
because the sum of the number of property words and
of the number of node words in the decomposition is
proportional to the number of words.
</bodyText>
<sectionHeader confidence="0.921744" genericHeader="related work">
4 C-Models and RDF Interpretations
</sectionHeader>
<bodyText confidence="0.99983108">
In this section, we establish the connection between the
extensional models of meaning of (Preller, 2012) with
the RDF interpretations of (Hayes, 2004) via the trans-
lation F from natural language to RDF graphs. We
show that a statement is true in an extensional model
if and only if the RDF graph computed by F is true
in the RDF interpretation associated to the extensional
model.
Choose an object U of C, the ‘universe of discourse’
of the fragment of natural language. The basis vectors
of U stand for individuals or concepts. Properties are
represented by maps that test (n-tuples of) entities and
let (part of) them pass if the test succeeds.
Let 1 ≤ i1 &lt; · · · &lt; im ≤ n be a strictly increasing
sequence. A linear map q : U1 ⊗ ... ⊗ Un → Uil ⊗
We say that q selects the i-th factor if m = 1 and i = i1
and that it is a projector if m = n. If the latter is
the case then q is an idempotent and self-adjoint en-
domorphism, hence a ‘property’ in quantum logic, see
(Abramsky and Coecke, 2004).
If the domain V and the codomain Ui1⊗...⊗Uim are
fixed then the selectors are in a one-to-one correspon-
dence with the ‘truth-value’ functions p : A → {&gt;, ⊥}
on the set A of basis vectors of V related by the condi-
tion
</bodyText>
<equation confidence="0.932374">
p(a) = &gt; if and only if q(a) =6 0
</equation>
<bodyText confidence="0.86438025">
for all a ∈ A.
Let v = Ekl=1 ajl be an arbitrary vector of V . A
selector q : V → W is said to be true at v if q(ajl) =6 0,
for l = 1, ... , k.
</bodyText>
<construct confidence="0.733749">
Lemma 3. Selectors are closed under composition and
the tensor product. Every identity is a selector.
Let p : V → W and q : W → X be selectors and
v ∈ V . Then q ◦ p is true at v if and only if p is true at
v and q is true at w = p(v).
</construct>
<bodyText confidence="0.993820166666667">
Proof. The first assertion is straight forward. To show
the second, assume that a is a basis vector for which
(q ◦ p)(a) =6 0. Then p(a) =6 0 because q(0) = 0.
Hence p(a) is a basis vector of W selected by p. The
property now follows for an arbitrary vector from the
definitions.
</bodyText>
<construct confidence="0.868786333333333">
Definition 4. A compact closed structure preserving
functor M : Lg → C is a C-model with universe U if
it satisfies
</construct>
<listItem confidence="0.992136545454545">
• M(s) = U ⊗ U
• M(a) = U for any basic type a =6 s
• M(1a) = M(ia b) = M(ja b) = 1M(a), for all
basic types a, b ∈ B
• M(that) = 1U
• M(wordarob) and M(wordnrosool) are projec-
tors
• M(wordˆnorool) = π1 ◦ M(wordnrosool)
M(wordnroˆoror) = π2 ◦ M(wordnrosool) ◦ Q
• M maps determiners and proper names in the sin-
gular to basis vectors.
</listItem>
<bodyText confidence="0.928844818181818">
The last condition guarantees that the interpretations
of a transitive verb in a statement and in a relative
clause are equal if the relative pronoun is the subject of
the verb in the relative clause and that they differ only
by the symmetry isomorphism if the relative pronoun
is the object.
Definition 5. A statement word1 ... wordn with re-
duction r : T1 ⊗ ... ⊗ Tn → b is true in M if
M(r ◦ (word1 ⊗ ... ⊗ wordn) =6 0.
Truth in a model can be reformulated in terms of se-
lector truth with the help of Lemma 1.
</bodyText>
<page confidence="0.994691">
60
</page>
<bodyText confidence="0.9375655">
Lemma 4. Let p1 o· · ·o pm, o(wordi1 ®...®wordim)
be the decomposition of the formal meaning of the
statement word1 ... wordn. Then M(pl) is a selec-
tor and M(wordi,,) a vector in U, for 1 &lt; l &lt; m&apos;,
1 &lt; k &lt; m.
Moreover, the statement is true in M if and only if
the selector M(pl) is true at M(pl+1)o· · ·oM(pm,)o
(M(wordi1) ® ... ® M(wordim)) for 1 &lt; l &lt; m&apos;.
Proof. M maps the meaning of the string to M(p1) o
··· o M(pm,) o (M(wordi1) ® ... ® M(wordim)).
Note that for k = 1, ... , m&apos; any factor of M(pk) is
the identity of U unless it is M(wordj,,) = qk. Thus
M(pk) is a tensor product of selectors. Hence both
assertions follow from Lemma 3.
Any C-model M defines an RDF interpretation. The
vocabulary consists of the basis vectors elabel E N,
see previous section. The set of property symbols is
given by
</bodyText>
<equation confidence="0.637372">
P = {eis-adjective : adjective E D} U {rdf:type}
U {everb : verb E C}
</equation>
<bodyText confidence="0.634555">
Define an RDF interpretation IM as follows
</bodyText>
<listItem confidence="0.735298333333333">
• set of properties
IP = {M(word) : eword E P} U {rdf:type}
• set of resources
</listItem>
<equation confidence="0.742576">
IR = IP U U U {true}
• mapping IS and its extension to blank nodes
IS(eword) = M(word),
IS(eblanki) = M(determineri)
</equation>
<listItem confidence="0.573703">
• mapping IEXT from IP into the power set of IR x IR
</listItem>
<equation confidence="0.997376666666667">
IEXT(rdf-type) =
{(e, M(noun)) : M(noun) is true at e}
IEXT(IS(eis-adjective)) =
{(e, true) : M(adjective) is true at e}
IEXT(IS(everb)) =
{(e1, e2) : M(verb) is true at e1 ® e2}.
</equation>
<construct confidence="0.522312">
Proposition 2. A statement word1 ... wordn is true in
a C-model M if and only if every triple of its RDF
translation G is true in the RDF interpretation IM
</construct>
<bodyText confidence="0.874339">
The proof is given in Appendix B.
</bodyText>
<sectionHeader confidence="0.999121" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999282">
The modelling of natural language by RDF graphs re-
mains limited by the expressivity of RDF. The latter
goes way beyond the few examples presented here. So
far, we have only considered the extensional branch of
a word. Future work will take advantage of the dis-
tinction between a property and its extension in RDF to
introduce the conceptual branch of a plural, which does
not refer to an extension, e.g Tom likes books, or cap-
ture the difference between Eve and John own a boat
and Eve and John are athletes.
</bodyText>
<sectionHeader confidence="0.995469" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999956333333333">
This work was supported by the École Normale
Supérieure and the LIRMM. The first author wishes to
thank David Naccache, Alain Lecomte, Antoine Amar-
illi, Hugo Vanneuville and both authors the members
of the TEXTE group at the LIRMM for their interest in
the project.
</bodyText>
<sectionHeader confidence="0.995588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994951840909091">
Samson Abramsky and Bob Coecke. 2004. A categor-
ical semantics of quantum protocols. In Proceed-
ings of the 19th Annual IEEE Symposium on Logic
in Computer Science, pages 415–425.
Stephen Clark, Bob Coecke, and Mehrnoosh
Sadrzadeh. 2008. A compositional distribu-
tional model of meaning. In W. Lawless P. Bruza
and J. van Rijsbergen, editors, Proceedings of
Conference on Quantum Interactions. University of
Oxford, College Publications.
Patrick Hayes and Brian McBride. 2004. Rdf seman-
tics. Technical report, Hewlett Packard Labs.
Patrick Hayes. 2004. Rdf semantics. Technical report,
W3C Recommendation, W3C.
Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, Stephen
Pulman, and Bob Coecke, 2013. Reasoning about
Meaning in Natural Language with Compact Closed
Categories and Frobenius Algebras. Cambridge
University Press.
Joachim Lambek. 1958. The mathematics of sen-
tence structure. American Mathematical Monthly,
65:154–170.
Joachim Lambek, 1993. Substructural Logics, chap-
ter From categorial grammar to bilinear logic, pages
207–237. Oxford University Press.
Joachim Lambek. 1999. Type grammar revisited. In
Alain Lecomte, editor, Logical Aspects of Computa-
tional Linguistics, volume 1582 of LNAI, pages 1–
27, Heidelberg. Springer.
Saunders Mac Lane. 1971. Categories for the Working
Mathematician. Springer.
Anne Preller and Joachim Lambek. 2007. Free
compact 2-categories. Mathematical Structures for
Computer Sciences, 17(1):1–32.
Anne Preller, 2012. From Sentence to Concept: Pred-
icate Logic and Quantum Logic in Compact Closed
Categories, pages 00–29. Oxford University Press.
Peter Selinger. 2011. A survey of graphical lan-
guages for monoidal categories. In New Structures
for Physics, volume 813 of Lecture Notes in Physics,
pages 289–233. Springer.
Mark Steedman. 1996. Surface Structure and Inter-
pretation, volume 30 of Linguistic Inquiry Mono-
graph. MIT Press, Cambridge, Massachusetts.
</reference>
<page confidence="0.999275">
61
</page>
<bodyText confidence="0.952483333333333">
A Proof of proposition 1
Note first that composition and the tensor are well de-
fined.
Assume (f, p) : A → B and (g, q) : B → C. Then
q ◦ f : A → S and p : A → S, so q ◦ f + p : A → S.
Therefore (g, q) ◦ (f, p) = (g ◦ f, q ◦ f + p) : A → C
is well defined. Similarly, if (fi, pi) : Ai → Bi for
i = 1, 2 then p1 ⊗+ p2 : A1 ⊗ A2 → S and therefore
(f1 ⊗ f2, p1 ⊗+ p2) : A1 ⊗ A2 → B1 ⊗ B2 as required.
The operation ⊗+ is associative on arrows. Indeed,
let (ai)i, (bj)j and (ck)k be the basis of A, B and C,
respectively. Then for r : C → S
</bodyText>
<equation confidence="0.9944815">
((p ⊗+ q) ⊗+ r)(ai ⊗ bj ⊗ ck)
=(p ⊗+ q)(ai ⊗ bj) + r(ck)
=p(ai) + q(bj) + r(ck)
=(p ⊗+ (q ⊗+ r))(ai ⊗ bj ⊗ ck) .
</equation>
<bodyText confidence="0.998567">
Hence the tensor product on arrows of CS is associative.
To show the interchange law (1), we need a lemma:
Lemma 5. Let p : C → S, q : D → S and f : A →
C, g : B → D with Ker(f) = Ker(g) = {0}. Then
</bodyText>
<equation confidence="0.783242">
(p ⊗+ q) ◦ (f ⊗ g) = (p ◦ f) ⊗+ (q ◦ g)
</equation>
<bodyText confidence="0.97297975">
Indeed, let (ai)i, (bi)i, (ci)i and (di)i be the bases
of A, B, C and D respectively. For all i and j, we
decompose f(ai) on the basis (ci)i and similarly for
g(bj) on (di)i:
</bodyText>
<equation confidence="0.813005">
Xf(ai) = cir and g(bj) = X dis
r s
</equation>
<bodyText confidence="0.70203">
Each family of indices (ir)r and (is)s is non empty,
because Ker(f) = Ker(g) = {0}. Hence,
</bodyText>
<equation confidence="0.99240425">
((p ⊗+ q) ◦ (f ⊗ g))(ai ⊗ bj)
=(p ⊗+ q)(f(ai) ⊗ g(bj))
=(p ⊗+ q)(( X Xcir) ⊗ ( dis))
r s
=(p ⊗+ q)( X cir ⊗ dis)
r,s
X= p(cir) + q(dis)
r,s
X= p(cir) + X q(dis)
r s
=p(f(ai)) + q(g(bj))
=((p ◦ f) ⊗+ (q ◦ g))(ai ⊗ bj)
</equation>
<bodyText confidence="0.999892">
The fifth equality uses the fact that 1 + 1 = 1 and the
sum is non empty. This terminates the proof of the
lemma.
Now let (f1,p1) : A → C, (f2,p2) : C → E,
(g1, q1) : B → D and (g2, q2) : D → F. We show
first the following equality
</bodyText>
<equation confidence="0.99045">
(f1⊗+g1)+(f2⊗+g2) = (f1+f2)⊗+(g1+g2). (5)
</equation>
<bodyText confidence="0.9994415">
Indeed, let (ei)i and (fj)j be the bases of A and B
respectively. Then, for all i and j,
</bodyText>
<equation confidence="0.9999535">
((f1 ⊗+ g1) + (f2 ⊗+ g2))(ei ⊗ fj)
=(f1 ⊗+ g1)(ei ⊗ fj) + (f2 ⊗+ g2)(ei ⊗ fj)
=f1(ei) + g1(fj) + f2(ei) + g2(fj)
=((f1 + f2) ⊗+ (g1 + g2))(ei ⊗ fj) .
</equation>
<bodyText confidence="0.957813333333333">
Finally, the Interchange Law follows from (5) and the
definitions thus
Therefore CS is a monoidal category.
</bodyText>
<subsectionHeader confidence="0.956765">
B Proof of Lemma 2 and Proposition 2
</subsectionHeader>
<bodyText confidence="0.9726192">
Proof. Note that both F and M map inequalities of
basic types to identities, hence also any atom without
a lexical morphism to an identity. Let wordjl be the
property word occurring in pl, say as the kl-th fac-
tor, ql = M(wordjl) and ml = F(wordjl), for
l = 1, ... , m. Then M(pl) = 1U ⊗ ... ql ... ⊗ 1U
and F(pl) = 1N ⊗ ... ml ... ⊗ 1N. Suppose that ei
is a basis vector of U and enodei a basis vector of N
satisfying ei = I(enodei).
Use induction on n−m−l and assume that e1⊗...⊗
</bodyText>
<equation confidence="0.920096">
erl = M(pl+1)◦···◦M(pn−m)◦(M(nodei1)⊗...⊗
M(nodeim)) and (enode1, 0) ⊗ . . . ⊗ (enoderl, 0) =
F(pl+1) ◦ ··· ◦ F(pn−m) ◦ (F(enodei1) ⊗ ... ⊗
</equation>
<bodyText confidence="0.966389526315789">
F(enodeim )).6
Let tl be the triple created when composing F(pl)
with (enode1, 0)⊗. . .⊗(enoderl , 0). We want the show
that tl is true in IM if and only if M(pl) is true at e1 ⊗
... ⊗ erl.
Consider the case where wordjl : d → d. The
other cases are shown similarly. Recall that ml ◦
(enodekl , 0) = (enodekl , tl), with tl = enodekl ⊗
eis-wordjl ⊗ etrue. Hence, F(pl)((enode1, 0) ⊗ . . . ⊗
(enoder,0)) = ((enode1, 0) ⊗ ... (enodekl,tl) ... ⊗
(enoder, 0) = (enode1 ⊗ . . . ⊗ enoder, tl). Then tl
is true in IM if and only if (I(enodekl), true) ∈
IEXT(I(eis-word)) if and only if ql is true at ekl, by
definition of I. On the other hand, 1U ⊗... ql ...⊗1U is
true at e1 ⊗... ekl ...⊗er if and only if ql is true at ekl.
If that is the case then M(pl)(e1 ⊗ ... ekl ... ⊗ er) =
e1 ⊗ ... ekl ... ⊗ er.
60 can be replaced by any vector of S without changing
the proof.
</bodyText>
<equation confidence="0.999968">
((f2, p2) ⊗ (g2,q2)) ◦ ((f1, p1) ⊗ (g1,q1))
=(f2 ⊗ g2, p2 ⊗+ q2) ◦ (f1 ⊗ g1,p1 ⊗+ q1)
=((f2 ⊗ g2) ◦ (f1 ⊗ g1), (p2 ⊗+ q2) ◦ (f1 ⊗ g1) + (p1 ⊗+ q1))
=((f2 ◦ f1) ⊗ (g2 ◦ g1), (p2 ◦ f1) ⊗+ (q2 ◦ g1) + (p1 ⊗+ q1))
=((f2 ◦ f1) ⊗ (g2 ◦ g1),(p2 ◦ f1 + p1) ⊗+ (q2 ◦ g1 + q1))
=(f2 ◦ f1,p2 ◦ f1 + p1) ⊗ (g2 ◦ g1,q2 ◦ g1 + q1)
=((f2,p2) ◦ (f1,p1)) ⊗ ((g2,q2) ◦ (g1,q1)) .
</equation>
<page confidence="0.995167">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.581088">
<title confidence="0.987128">From Natural Language to RDF Graphs with Pregroups</title>
<author confidence="0.856469">Antonin</author>
<affiliation confidence="0.790013">École Normale</affiliation>
<address confidence="0.945967">45 rue 75005 Paris,</address>
<email confidence="0.992952">antonin.delpeuch@ens.fr</email>
<abstract confidence="0.98837675">We define an algorithm translating natural language sentences to the formal syntax of RDF, an existential conjunctive logic widely used on the Semantic Web. Our translation is based on pregroup grammars, an efficient type-logical grammatical framework with a transparent syntax-semantics interface. We introduce a restricted notion of side effects in the semantic category of finitely generated free over that end. The translation gives an intensional counterpart to previous extensional models. We establish a one-to-one correspondence between extensional models and RDF models such that satisfaction is preserved. Our translation encompasses the expressivity of the target language and supports complex linguistic constructions like relative clauses and unbounded dependencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Samson Abramsky</author>
<author>Bob Coecke</author>
</authors>
<title>A categorical semantics of quantum protocols.</title>
<date>2004</date>
<booktitle>In Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science,</booktitle>
<pages>415--425</pages>
<contexts>
<context position="24219" citStr="Abramsky and Coecke, 2004" startWordPosition="4718" endWordPosition="4721">sional model. Choose an object U of C, the ‘universe of discourse’ of the fragment of natural language. The basis vectors of U stand for individuals or concepts. Properties are represented by maps that test (n-tuples of) entities and let (part of) them pass if the test succeeds. Let 1 ≤ i1 &lt; · · · &lt; im ≤ n be a strictly increasing sequence. A linear map q : U1 ⊗ ... ⊗ Un → Uil ⊗ We say that q selects the i-th factor if m = 1 and i = i1 and that it is a projector if m = n. If the latter is the case then q is an idempotent and self-adjoint endomorphism, hence a ‘property’ in quantum logic, see (Abramsky and Coecke, 2004). If the domain V and the codomain Ui1⊗...⊗Uim are fixed then the selectors are in a one-to-one correspondence with the ‘truth-value’ functions p : A → {&gt;, ⊥} on the set A of basis vectors of V related by the condition p(a) = &gt; if and only if q(a) =6 0 for all a ∈ A. Let v = Ekl=1 ajl be an arbitrary vector of V . A selector q : V → W is said to be true at v if q(ajl) =6 0, for l = 1, ... , k. Lemma 3. Selectors are closed under composition and the tensor product. Every identity is a selector. Let p : V → W and q : W → X be selectors and v ∈ V . Then q ◦ p is true at v if and only if p is true</context>
</contexts>
<marker>Abramsky, Coecke, 2004</marker>
<rawString>Samson Abramsky and Bob Coecke. 2004. A categorical semantics of quantum protocols. In Proceedings of the 19th Annual IEEE Symposium on Logic in Computer Science, pages 415–425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>Bob Coecke</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>A compositional distributional model of meaning.</title>
<date>2008</date>
<booktitle>Proceedings of Conference on Quantum Interactions. University of Oxford,</booktitle>
<editor>In W. Lawless P. Bruza and J. van Rijsbergen, editors,</editor>
<publisher>College Publications.</publisher>
<contexts>
<context position="2601" citStr="Clark et al., 2008" startWordPosition="386" endWordPosition="389">ulus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the functional logical models of (Preller, 2012). We proceed as follows. Recalling that words and grammatical strings recognised by the grammar are represented by meaning-morphisms in the lexical category, we propose a &amp;quot;syntactic&amp;quot; functor from the latter into a symmetric monoidal category Cs of ‘morphisms with side effects’ over the category C of finite dimensional semimodules over the lattice B = {0,1}. The elements of the semimodule S identify with RDF graphs. The value of the syntactic functor at a statement is the RDF graph of the statement.</context>
</contexts>
<marker>Clark, Coecke, Sadrzadeh, 2008</marker>
<rawString>Stephen Clark, Bob Coecke, and Mehrnoosh Sadrzadeh. 2008. A compositional distributional model of meaning. In W. Lawless P. Bruza and J. van Rijsbergen, editors, Proceedings of Conference on Quantum Interactions. University of Oxford, College Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hayes</author>
<author>Brian McBride</author>
</authors>
<title>Rdf semantics.</title>
<date>2004</date>
<tech>Technical report,</tech>
<location>Hewlett Packard Labs.</location>
<contexts>
<context position="1449" citStr="Hayes and McBride, 2004" startWordPosition="215" endWordPosition="218">the expressivity of the target language and supports complex linguistic constructions like relative clauses and unbounded dependencies. 1 Introduction There is a general agreement that Natural Language Processing has two aspects. One is syntax, rules how words are put together to form a grammatical string. The other is semantics, rules how meanings of strings are computed from the meanings of words. To this we add a third aspect, namely that semantics must include rules of logic how to compute the truth of the whole string from the truth of its parts. The Resource Description Framework (RDF) (Hayes and McBride, 2004) is an artificial language that takes the intuitive form of knowledge graphs. Its semantics has the expressive power of the fragment of multisorted first order logic that uses conjunction and existential quantification only. This restricted expressive power limits the statements of natural language that can be interpreted as RDF graphs. Typically, statements with negation words are excluded. We use pregroup grammars as the linguistic and mathematical tool to recognise and interpret natural language strings in RDF. Pregroup Calculus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, </context>
<context position="3599" citStr="Hayes and McBride, 2004" startWordPosition="552" endWordPosition="555"> over the category C of finite dimensional semimodules over the lattice B = {0,1}. The elements of the semimodule S identify with RDF graphs. The value of the syntactic functor at a statement is the RDF graph of the statement. The extensional models of logic are recast as &amp;quot;semantic&amp;quot; functors from the lexical category to C. We associate to any semantic functor an RDF interpretation and show that a statement is true in the semantic functor if and only if the corresponding RDF graph is true in the RDF interpretation. 2 Preliminaries 2.1 RDF graphs RDF is a widely-adopted framework introduced in (Hayes and McBride, 2004) as a standard for linked information representation on the Web. Informally, an RDF graph is a set of labeled links between objects, which represent statements concerning the linked objects. Throughout this article we will simply consider that they are represented by strings of characters without spaces, written in a mono-spaced font: the entity John is denoted by the string John. A link between two objects is a triple, made of one entity (the subject of the predicate), a property (the type of the link, also represented by a string) and a second entity (the object of the predicate). Graphicall</context>
<context position="5341" citStr="Hayes and McBride, 2004" startWordPosition="849" endWordPosition="852"> example We can represent the sentence John owns a white boat using a fresh blank node for a white boat: John owns blank-1 blank-1 rdf:type boat blank-1 is_white true Here, rdf:type is a special RDF predicate indicating the type of its subject. The graph representing this set of triples is John blank-1 true boat Figure 1: A graph with a blank node Recall that our goal is to translate natural language sentences to graphs. Graphs can indeed be seen as semantic representations of sentences, in the sense that they can be used to assign a truth value to a sentence, trough the notion of entailment (Hayes and McBride, 2004). A graph H is an instance of G when H can be obtained from G by assigning labels to some blank nodes (possibly none of them). A graph G0 entails another graph G if an instance of G is a subgraph of G0. With these definitions, we can define true RDF graphs as the graphs entailed by some reference graph, storing all the true facts. 2.2 Pregroup grammars A pregroup grammar (Lambek, 1999), consists of the free pregroup C(B) generated by a partially ordered set B and a lexicon Dg. By ‘free pregroup’ we mean the free compact closed category C(B) generated by B following the version given in (Prelle</context>
</contexts>
<marker>Hayes, McBride, 2004</marker>
<rawString>Patrick Hayes and Brian McBride. 2004. Rdf semantics. Technical report, Hewlett Packard Labs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Hayes</author>
</authors>
<title>Rdf semantics.</title>
<date>2004</date>
<tech>Technical report, W3C Recommendation, W3C.</tech>
<contexts>
<context position="23376" citStr="Hayes, 2004" startWordPosition="4549" endWordPosition="4550">y it computes the RDF graph by applying the translation functor F to the decomposition. The parsing algorithm is cubic polynomial in the number of words. Decomposition is linear, because the number of links is proportional to the number of words. Finally, translation again is linear, because the sum of the number of property words and of the number of node words in the decomposition is proportional to the number of words. 4 C-Models and RDF Interpretations In this section, we establish the connection between the extensional models of meaning of (Preller, 2012) with the RDF interpretations of (Hayes, 2004) via the translation F from natural language to RDF graphs. We show that a statement is true in an extensional model if and only if the RDF graph computed by F is true in the RDF interpretation associated to the extensional model. Choose an object U of C, the ‘universe of discourse’ of the fragment of natural language. The basis vectors of U stand for individuals or concepts. Properties are represented by maps that test (n-tuples of) entities and let (part of) them pass if the test succeeds. Let 1 ≤ i1 &lt; · · · &lt; im ≤ n be a strictly increasing sequence. A linear map q : U1 ⊗ ... ⊗ Un → Uil ⊗ W</context>
</contexts>
<marker>Hayes, 2004</marker>
<rawString>Patrick Hayes. 2004. Rdf semantics. Technical report, W3C Recommendation, W3C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitri Kartsaklis</author>
<author>Mehrnoosh Sadrzadeh</author>
<author>Stephen Pulman</author>
<author>Bob Coecke</author>
</authors>
<title>Reasoning about Meaning in Natural Language with Compact Closed Categories and Frobenius Algebras.</title>
<date>2013</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2628" citStr="Kartsaklis et al., 2013" startWordPosition="390" endWordPosition="393">mpact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the functional logical models of (Preller, 2012). We proceed as follows. Recalling that words and grammatical strings recognised by the grammar are represented by meaning-morphisms in the lexical category, we propose a &amp;quot;syntactic&amp;quot; functor from the latter into a symmetric monoidal category Cs of ‘morphisms with side effects’ over the category C of finite dimensional semimodules over the lattice B = {0,1}. The elements of the semimodule S identify with RDF graphs. The value of the syntactic functor at a statement is the RDF graph of the statement. The extensional models of </context>
</contexts>
<marker>Kartsaklis, Sadrzadeh, Pulman, Coecke, 2013</marker>
<rawString>Dimitri Kartsaklis, Mehrnoosh Sadrzadeh, Stephen Pulman, and Bob Coecke, 2013. Reasoning about Meaning in Natural Language with Compact Closed Categories and Frobenius Algebras. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>The mathematics of sentence structure.</title>
<date>1958</date>
<pages>65--154</pages>
<publisher>American Mathematical Monthly,</publisher>
<contexts>
<context position="2122" citStr="Lambek, 1958" startWordPosition="317" endWordPosition="318">knowledge graphs. Its semantics has the expressive power of the fragment of multisorted first order logic that uses conjunction and existential quantification only. This restricted expressive power limits the statements of natural language that can be interpreted as RDF graphs. Typically, statements with negation words are excluded. We use pregroup grammars as the linguistic and mathematical tool to recognise and interpret natural language strings in RDF. Pregroup Calculus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the functional logical models of (Preller, 2012). We proceed as follows.</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Joachim Lambek. 1958. The mathematics of sentence structure. American Mathematical Monthly, 65:154–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>Substructural Logics, chapter From categorial grammar to bilinear logic,</title>
<date>1993</date>
<pages>207--237</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="2039" citStr="Lambek, 1993" startWordPosition="305" endWordPosition="306">ayes and McBride, 2004) is an artificial language that takes the intuitive form of knowledge graphs. Its semantics has the expressive power of the fragment of multisorted first order logic that uses conjunction and existential quantification only. This restricted expressive power limits the statements of natural language that can be interpreted as RDF graphs. Typically, statements with negation words are excluded. We use pregroup grammars as the linguistic and mathematical tool to recognise and interpret natural language strings in RDF. Pregroup Calculus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on c</context>
</contexts>
<marker>Lambek, 1993</marker>
<rawString>Joachim Lambek, 1993. Substructural Logics, chapter From categorial grammar to bilinear logic, pages 207–237. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>Type grammar revisited.</title>
<date>1999</date>
<booktitle>Logical Aspects of Computational Linguistics,</booktitle>
<volume>1582</volume>
<pages>1--27</pages>
<editor>In Alain Lecomte, editor,</editor>
<publisher>Springer.</publisher>
<location>Heidelberg.</location>
<contexts>
<context position="2054" citStr="Lambek, 1999" startWordPosition="307" endWordPosition="308">e, 2004) is an artificial language that takes the intuitive form of knowledge graphs. Its semantics has the expressive power of the fragment of multisorted first order logic that uses conjunction and existential quantification only. This restricted expressive power limits the statements of natural language that can be interpreted as RDF graphs. Typically, statements with negation words are excluded. We use pregroup grammars as the linguistic and mathematical tool to recognise and interpret natural language strings in RDF. Pregroup Calculus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the </context>
<context position="5729" citStr="Lambek, 1999" startWordPosition="925" endWordPosition="926">uage sentences to graphs. Graphs can indeed be seen as semantic representations of sentences, in the sense that they can be used to assign a truth value to a sentence, trough the notion of entailment (Hayes and McBride, 2004). A graph H is an instance of G when H can be obtained from G by assigning labels to some blank nodes (possibly none of them). A graph G0 entails another graph G if an instance of G is a subgraph of G0. With these definitions, we can define true RDF graphs as the graphs entailed by some reference graph, storing all the true facts. 2.2 Pregroup grammars A pregroup grammar (Lambek, 1999), consists of the free pregroup C(B) generated by a partially ordered set B and a lexicon Dg. By ‘free pregroup’ we mean the free compact closed category C(B) generated by B following the version given in (Preller and Lambek, 2007)1. The lexicon Dg introduces the monoidal category Lg, freely generated by the inequalities and the lexical morphisms given by the lexicon. Lexical entries have &amp;quot;formal meanings&amp;quot; in the lexical category, the free compact closed category generated by B and the morphisms introduced by the words. They are analogue to the lambda-terms intervening in categorial grammars, </context>
</contexts>
<marker>Lambek, 1999</marker>
<rawString>Joachim Lambek. 1999. Type grammar revisited. In Alain Lecomte, editor, Logical Aspects of Computational Linguistics, volume 1582 of LNAI, pages 1– 27, Heidelberg. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saunders Mac Lane</author>
</authors>
<title>Categories for the Working Mathematician.</title>
<date>1971</date>
<publisher>Springer.</publisher>
<contexts>
<context position="8932" citStr="Lane, 1971" startWordPosition="1570" endWordPosition="1571">d of a ≤ b and 1a for iaa. A simple type is an iterated left adjoint or right adjoint of a basic type ..., a`` = a(−2), a` = a(−1), a = a(0), ar = a(1), arr = a(2), .... The iterator of t = a(z) is the integer z. An arbitrary type is a string of simple types separated by the symbol ⊗. In particular, the empty string is a type, denoted I. The lexicon of a pregroup grammar consists of a set of pairs word : T where the type T ∈ C(B) captures the different grammatical roles a word may play. For 2Strictly speaking, these equalities hold up to natural isomorphisms, but the coherence theorem of (Mac Lane, 1971) makes it possible to replace the isomorphisms by equalities without loss of generality. owns 56 instance proper name : n transitive verb: nr ® s ® o` transitive verb : ˆnr ® r ® o` transitive verb: nr ® ˆor ® r determiner : d adjective : dr ® d countnoun : dr ® n relpronoun : nr ® n ® r` ® nˆ relpronoun : nr ® n ® r` ® oˆ A pregroup grammars analyses a string of words by constructing a graph: choose an entry wi : Ti for each word wi and align the types in the order of the words. Place non-crossing oriented underlinks such that the tail of an underlink is a basic type with an even number of it</context>
</contexts>
<marker>Lane, 1971</marker>
<rawString>Saunders Mac Lane. 1971. Categories for the Working Mathematician. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Preller</author>
<author>Joachim Lambek</author>
</authors>
<date>2007</date>
<booktitle>Free compact 2-categories. Mathematical Structures for Computer Sciences,</booktitle>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="2466" citStr="Preller and Lambek, 2007" startWordPosition="367" endWordPosition="370">d. We use pregroup grammars as the linguistic and mathematical tool to recognise and interpret natural language strings in RDF. Pregroup Calculus, also known as Compact Bilinear Logic (Lambek, 1993) (Lambek, 1999), is a simplification of Lambek’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the functional logical models of (Preller, 2012). We proceed as follows. Recalling that words and grammatical strings recognised by the grammar are represented by meaning-morphisms in the lexical category, we propose a &amp;quot;syntactic&amp;quot; functor from the latter into a symmetric monoidal category Cs of ‘morphisms with side effects’ over the category C of finite dimensional semimodules over the lattice B = {0,1}. The elem</context>
<context position="5960" citStr="Preller and Lambek, 2007" startWordPosition="963" endWordPosition="966"> 2004). A graph H is an instance of G when H can be obtained from G by assigning labels to some blank nodes (possibly none of them). A graph G0 entails another graph G if an instance of G is a subgraph of G0. With these definitions, we can define true RDF graphs as the graphs entailed by some reference graph, storing all the true facts. 2.2 Pregroup grammars A pregroup grammar (Lambek, 1999), consists of the free pregroup C(B) generated by a partially ordered set B and a lexicon Dg. By ‘free pregroup’ we mean the free compact closed category C(B) generated by B following the version given in (Preller and Lambek, 2007)1. The lexicon Dg introduces the monoidal category Lg, freely generated by the inequalities and the lexical morphisms given by the lexicon. Lexical entries have &amp;quot;formal meanings&amp;quot; in the lexical category, the free compact closed category generated by B and the morphisms introduced by the words. They are analogue to the lambda-terms intervening in categorial grammars, (Steedman, 1996). The working of pregroup grammars can be described without explicit use of category theory. The main result of this section however, the decomposition lemma, invokes properties of the graphs proved in (Preller and </context>
<context position="13596" citStr="Preller and Lambek, 2007" startWordPosition="2609" endWordPosition="2612"> 57 above above simplify to T = ˆnr ⊗ r ⊗ oP a cat hater bob that� � d ⊗ dr ⊗ n ⊗ nr ⊗ n ⊗ rP ⊗ nˆ ⊗ ˆnr ⊗ r ⊗ oP ⊗ n �� �� !! � ee ?? ff � n a cat bob hater , that� d ⊗ dr⊗ n ⊗ nr⊗ n ⊗ rP ⊗ oˆ⊗ n ⊗ nr⊗ˆor ⊗ r ����!!� �� ?? ?? ddV ??:: n = that ((cat a) ◦hateT,◦ ◦ ⊗ bob)] : I ⊗ I → n own (john white a)) = own (1„• (1„• (1„• ◦ ⊗ (boat◦ ◦ ◦ ⊗ in)◦ ⊗ boat)◦ ⊗ white))◦(john⊗ a) . &lt; jkl. In particular, the meaning of the string belongs to the monoidal category generated by the lexicon This is a straightforward consequence of the characterisation of morphisms as normal graphs in the free category, (Preller and Lambek, 2007) and the interchange law. We map lexical morphisms to &amp;quot;unfinished&amp;quot; RDF triples lexical morphism RDF triple noun: d n ? rdf :type noun d ? is-adjective true ◦(word1⊗ ...⊗ words)= p1◦···◦ ◦ ⊗ ...⊗ wordim) jk → → verb : a ⊗ b→ c ? verb ? determiner : I → d blank ? ?, ? ? blank propername : I → n propername ? ?, ? ? propername the lexical meaning of the string satisfies r ps,,, (wordil , where each pk is either a tensor product of inequalities of basic types or a tensor product of inequalities and one property word wordjk. Moreover, k &lt; k&apos; implies The question marks designate unoccupied positions </context>
</contexts>
<marker>Preller, Lambek, 2007</marker>
<rawString>Anne Preller and Joachim Lambek. 2007. Free compact 2-categories. Mathematical Structures for Computer Sciences, 17(1):1–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Preller</author>
</authors>
<title>From Sentence to Concept: Predicate Logic and Quantum Logic in Compact Closed Categories,</title>
<date>2012</date>
<pages>00--29</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="2698" citStr="Preller, 2012" startWordPosition="403" endWordPosition="404">k’s Syntactic Calculus, (Lambek, 1958). Pregroup grammars Anne Preller LIRMM 161 rue Ada 34392 Montpellier Cedex 5, France preller@lirmm.fr are based on a lexicon like all categorial grammars. Syntactical analysis consists in the construction of a proof (derivation) in the calculus. All semantics proposed so far use functors from the lexical category of (Preller and Lambek, 2007) into some symmetric compact closed category. They include the compositional distributional vector space models of (Clark et al., 2008), (Kartsaklis et al., 2013) based on context and the functional logical models of (Preller, 2012). We proceed as follows. Recalling that words and grammatical strings recognised by the grammar are represented by meaning-morphisms in the lexical category, we propose a &amp;quot;syntactic&amp;quot; functor from the latter into a symmetric monoidal category Cs of ‘morphisms with side effects’ over the category C of finite dimensional semimodules over the lattice B = {0,1}. The elements of the semimodule S identify with RDF graphs. The value of the syntactic functor at a statement is the RDF graph of the statement. The extensional models of logic are recast as &amp;quot;semantic&amp;quot; functors from the lexical category to C</context>
<context position="23330" citStr="Preller, 2012" startWordPosition="4542" endWordPosition="4543">ing in the lexical category by ‘yanking’. Finally it computes the RDF graph by applying the translation functor F to the decomposition. The parsing algorithm is cubic polynomial in the number of words. Decomposition is linear, because the number of links is proportional to the number of words. Finally, translation again is linear, because the sum of the number of property words and of the number of node words in the decomposition is proportional to the number of words. 4 C-Models and RDF Interpretations In this section, we establish the connection between the extensional models of meaning of (Preller, 2012) with the RDF interpretations of (Hayes, 2004) via the translation F from natural language to RDF graphs. We show that a statement is true in an extensional model if and only if the RDF graph computed by F is true in the RDF interpretation associated to the extensional model. Choose an object U of C, the ‘universe of discourse’ of the fragment of natural language. The basis vectors of U stand for individuals or concepts. Properties are represented by maps that test (n-tuples of) entities and let (part of) them pass if the test succeeds. Let 1 ≤ i1 &lt; · · · &lt; im ≤ n be a strictly increasing sequ</context>
</contexts>
<marker>Preller, 2012</marker>
<rawString>Anne Preller, 2012. From Sentence to Concept: Predicate Logic and Quantum Logic in Compact Closed Categories, pages 00–29. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Selinger</author>
</authors>
<title>A survey of graphical languages for monoidal categories.</title>
<date>2011</date>
<booktitle>In New Structures for Physics,</booktitle>
<volume>813</volume>
<pages>289--233</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="12562" citStr="Selinger, 2011" startWordPosition="2330" endWordPosition="2331">definition, the composite of the tensor product of the word meanings and the chosen reduction. r o (word1T1 ® ... ® wordnTn) : I → b. The meaning of a composite morphism g o f can be simplified graphically. Stack the graph of f above the graph of g and walk the paths of the graph starting at a node that is not the head of a link until you arrive at a node that is not the tail of a link. Compose the labels in the order they are encountered along the path. Replace the whole path by a single link labelling it by the composite label of the path. The resulting graph represents the morphism g o f, (Selinger, 2011). For instance, the grammatical strings mentioned (n) ® (nr ® s ® o`) ® (d) ® (dr ® d) ® (dr ® n) ;� g� ;� ;� V s d ® dr ® n ® nr ® n ® r` ® oˆ® n ® nr ® ˆor ® r b� n ?� ?� ?�:� V w �&amp;quot; wT = a wT = w V b ar ® b ?�?� w a ® c ❚❚❚ ❥❥❥ wT = wT � b c ® a ❚❚❚ ❥❥❥ wT = wT � b nr ® n ® r` ®-\d that r jd n that N � d n 3&amp;quot;basic type&amp;quot; is replaced by simple type with an even iterator in the general case = wb wb = w l b 57 above above simplify to T = ˆnr ⊗ r ⊗ oP a cat hater bob that� � d ⊗ dr ⊗ n ⊗ nr ⊗ n ⊗ rP ⊗ nˆ ⊗ ˆnr ⊗ r ⊗ oP ⊗ n �� �� !! � ee ?? ff � n a cat bob hater , that� d ⊗ dr⊗ n ⊗ nr⊗ n ⊗ rP ⊗ </context>
</contexts>
<marker>Selinger, 2011</marker>
<rawString>Peter Selinger. 2011. A survey of graphical languages for monoidal categories. In New Structures for Physics, volume 813 of Lecture Notes in Physics, pages 289–233. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Surface Structure and Interpretation,</title>
<date>1996</date>
<volume>30</volume>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6345" citStr="Steedman, 1996" startWordPosition="1024" endWordPosition="1025"> consists of the free pregroup C(B) generated by a partially ordered set B and a lexicon Dg. By ‘free pregroup’ we mean the free compact closed category C(B) generated by B following the version given in (Preller and Lambek, 2007)1. The lexicon Dg introduces the monoidal category Lg, freely generated by the inequalities and the lexical morphisms given by the lexicon. Lexical entries have &amp;quot;formal meanings&amp;quot; in the lexical category, the free compact closed category generated by B and the morphisms introduced by the words. They are analogue to the lambda-terms intervening in categorial grammars, (Steedman, 1996). The working of pregroup grammars can be described without explicit use of category theory. The main result of this section however, the decomposition lemma, invokes properties of the graphs proved in (Preller and Lambek, 2007). 1Semantics requires more than one morphism between objects, whereas the partial preorder of the free pregroup of (Lambek, 1999) confounds all morphisms with identical domain and codomain. We start with the formal definition of a monoidal category followed by the condition it must satisfy to be compact closed. Definition 1. A category C is 1. monoidal if there is a bif</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Mark Steedman. 1996. Surface Structure and Interpretation, volume 30 of Linguistic Inquiry Monograph. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>