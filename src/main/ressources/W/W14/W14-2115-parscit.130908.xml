<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.030036">
<title confidence="0.949216">
Survey in sentiment, polarity and function analysis of citation
</title>
<author confidence="0.576179">
Myriam Hernández A
</author>
<affiliation confidence="0.70369">
Escuela Politécnica Nacional
Facultad de Ingeniería de Sistemas
</affiliation>
<address confidence="0.716156">
Quito, Ecuador
</address>
<email confidence="0.998214">
myriam.hernandez@epn.edu.ec
</email>
<author confidence="0.648915">
José M. Gómez
</author>
<affiliation confidence="0.561105">
Universidad de Alicante
Dpto de Lenguajes y Sistemas Informáticos
</affiliation>
<address confidence="0.69367">
Alicante, España
</address>
<email confidence="0.996512">
jmgomez@ua.es
</email>
<sectionHeader confidence="0.995608" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999656411764706">
In this paper we proposed a survey in
sentiment, polarity and function analysis
of citations. This is an interesting area
that has had an increased development in
recent years but still has plenty of room
for growth and further research. The
amount of scientific information in the
web makes it necessary innovate the
analysis of the influence of the work of
peers and leaders in the scientific com-
munity. We present an overview of gen-
eral concepts, review contributions to the
solution of related problems such as con-
text identification, function and polarity
classification, identify some trends and
suggest possible future research direc-
tions.
</bodyText>
<sectionHeader confidence="0.972592" genericHeader="categories and subject descriptors">
1 Extended abstract
</sectionHeader>
<bodyText confidence="0.999965913793104">
The number of publications in science grows
exponentially each passing year. To understand
the evolution of several topics, researchers and
scientist require locating and accessing available
contributions from among large amounts of
available electronic material that can only be
navigated through citations. Citation analysis is a
way of evaluating the impact of an author, a pub-
lished work or a scientific media.
Sugiyama (2010) established that there are
two types of research in the field of citation
analysis of research papers: citation count to
evaluate the impact (Garfield, 1972) and citation
content analysis (Councill et al., 2008).
The advantages of citation count are the sim-
plicity and the experience accumulated in scien-
tometric applications, but many authors have
pointed out its weakness. One of the limitations
is that the count does not difference between the
weights of high and low impact citing papers.
PageRank (Page et al., 1998) partially solved this
problem with a rating algorithm. Small (1973)
proposed co-citation analysis to supplement the
qualitative method with a similarity measure be-
tween works A and B, counting the number of
documents that cite them.
Recently, this type researchers’ impact meas-
ure has been widely criticized. Bibliometric stud-
ies (Radicchi, 2012) show that incomplete, erro-
neous or controversial papers are most cited.
This can generate perverse incentives for new
researchers who may be tempted to publish alt-
hough its investigation is wrong or not yet com-
plete because this way they will receive higher
number of citations (Marder et al., 2010). In fact,
it also affects the quality of very prestigious
journals such as Nature, Science or Cell because
they know that accepting controversial articles is
very profitable to increase citation numbers.
Moreover, as claimed by Siegel and Baveye
(2010), it is more influential the quantity of arti-
cles than their quality or than the relationship
between papers with a higher number of citations
and the number of citations that, in turn, they
receive (Webster et al., 2009).
Other limitation of this method is that a cita-
tion is interpreted as an author being influenced
by the work of another, without specifying type
of influence (Zhang et al., 2013) which can be
misleading concerning the true impact of a cita-
tion (Young et al., 2008). To better understand
the influence of a scientific work it is advisable
to broaden the range of indicators to take into
account factors like the author&apos;s disposition to-
wards the reference, because, for instance, a crit-
icized quoted work cannot have the same weight
than other that is used as starting point of a re-
search.
</bodyText>
<page confidence="0.964644">
102
</page>
<bodyText confidence="0.986894245283019">
Proceedings of the First Workshop on Argumentation Mining, pages 102–103,
Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics
These problems are added to the growing im-
portance of impact indexes for the researchers’
career. It is becoming more important to correct
these issues and look for more complete metrics
to evaluate researchers’ relevance taking into
account many other “quality” factors, one of
them being the intention of the researcher when
citing the work of others.
Automatic analysis of subjective criteria pre-
sent in a text is known as Sentiment Analysis. It
is part of citation content analysis and is a cur-
rent research topic in the area of natural language
processing in the field of opinion mining and its
scope includes monitoring emotions in fields as
diverse as marketing, political science and eco-
nomics. It is proposed that this type of analysis
be applied in the study of bibliographic citations,
as part of citation content analysis, to detect the
intention and disposition of the citing author to
the cited work, and to give additional infor-
mation to complement the calculation of the es-
timated impact of a publication to enhance its
bibliometric analysis (Jbara and Radev, 2012).
This analysis includes syntactic and semantic
language relationships through speech and natu-
ral language processing and the explicit and im-
plicit linguistic choices in the text to infer cita-
tion function and feelings of the author regarding
the cited work (Zhang et al., 2013).
A combination of a quantitative and qualita-
tive/subjective analysis would give a more com-
plete perspective of the impact of publications in
the scientific community (Jbara et al., 2013).
Some methods for subjective citation analysis
have been proposed by different authors, but they
call for more work to achieve better results in
detection, extraction and handling of citations
content and to characterize in a more accurate
way the profile of scientists and the criticism or
acceptance of their work.
Although work in this specific area has in-
creased in recent years, there are still open prob-
lems that have not been solved and they need to
be investigated. There are not enough open cor-
pus that can be worked in shared form by re-
searchers, there is not a common work frame to
facilitate achieving results that are comparable
with each other in order to reach conclusions
about the efficiency of different techniques. In
this field it is necessary to develop conditions
that allow and motivate collaborative work.
</bodyText>
<sectionHeader confidence="0.991859" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.6708006">
This research work has been partially funded by the
Spanish Government and the European Commission
through the project, ATTOS (TIN2012-38536-C03-
03), LEGOLANG (TIN2012-31224), SAM (FP7-
611312) and FIRST (FP7-287607).
</bodyText>
<sectionHeader confidence="0.541306" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.993499291666667">
Councill, I. G., Giles, C. L., &amp; Kan, M. Y. (2008,
May). ParsCit: an Open-source CRF Reference
String Parsing Package. In LREC.
Garfield, E. (1972, November). Citation analysis as a
tool in journal evaluation. American Association
for the Advancement of Science.
Jbara, A., &amp; Radev, D. (2012, June). Reference scope
identification in citing sentences. In Proceedings of
the 2012 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies (pp. 80-90).
Association for Computational Linguistics.
Jbara, A., Ezra, J., &amp; Radev, D. (2013). Purpose and
Polarity of Citation: Towards NLP-based Biblio-
metrics. In Proceedings of NAACL-HLT (pp. 596-
606).
Marder, E., Kettenmann, H., &amp; Grillner, S. (2010).
Impacting our young. Proceedings of the National
Academy of Sciences, 107(50), 21233-21233.
Page, L., Brin, S., Motwani, R., &amp; Winograd, T.
(1999). The PageRank citation ranking: bringing
order to the web.
Radicchi, F. (2012). In science “there is no bad pub-
licity”: Papers criticized in comments have high
scientific impact. Scientific reports, 2.
Small, H. (1973). Co‐citation in the scientific litera-
ture: A new measure of the relationship between
two documents. Journal of the American Society
for information Science, 24(4), 265-269.
Sugiyama, K., Kumar, T., Kan, M. Y., &amp; Tripathi, R.
C. (2010). Identifying citing sentences in research
papers using supervised learning. In Information
Retrieval &amp; Knowledge Management, (CAMP),
2010 International Conference on (pp. 67-72).
IEEE.
Webster, G. D., Jonason, P. K., &amp; Schember, T. O.
(2009). Hot Topics and Popular Papers in Evolu-
tionary Psychology: Analyses of Title Words and
Citation Counts in Evolution and Human Behavior,
1979-2008. Evolutionary Psychology, 7(3).
Young, N. S., Ioannidis, J. P., &amp; Al-Ubaydli, O.
(2008). Why current publication practices may dis-
tort science. PLoS medicine, 5(10), e201.
Zhang, G., Ding, Y., &amp; Milojević, S. (2013). Citation
content analysis (cca): A framework for syntactic
and semantic analysis of citation content. Journal
of the American Society for Information Science
and Technology, 64(7), 1490-1503.
</reference>
<page confidence="0.999295">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.006204">
<title confidence="0.970453">Survey in sentiment, polarity and function analysis of citation</title>
<author confidence="0.947917">Myriam Hernández</author>
<affiliation confidence="0.824313">Escuela Politécnica Facultad de Ingeniería de</affiliation>
<address confidence="0.767999">Quito, Ecuador</address>
<email confidence="0.976877">myriam.hernandez@epn.edu.ec</email>
<affiliation confidence="0.838792666666667">José M. Universidad de Dpto de Lenguajes y Sistemas</affiliation>
<address confidence="0.979534">Alicante, España</address>
<email confidence="0.97487">jmgomez@ua.es</email>
<abstract confidence="0.999322854961832">In this paper we proposed a survey in sentiment, polarity and function analysis of citations. This is an interesting area that has had an increased development in recent years but still has plenty of room for growth and further research. The amount of scientific information in the web makes it necessary innovate the analysis of the influence of the work of peers and leaders in the scientific community. We present an overview of general concepts, review contributions to the solution of related problems such as context identification, function and polarity classification, identify some trends and suggest possible future research directions. 1 Extended abstract The number of publications in science grows exponentially each passing year. To understand the evolution of several topics, researchers and scientist require locating and accessing available contributions from among large amounts of available electronic material that can only be navigated through citations. Citation analysis is a way of evaluating the impact of an author, a published work or a scientific media. Sugiyama (2010) established that there are two types of research in the field of citation analysis of research papers: citation count to evaluate the impact (Garfield, 1972) and citation content analysis (Councill et al., 2008). The advantages of citation count are the simplicity and the experience accumulated in scientometric applications, but many authors have pointed out its weakness. One of the limitations is that the count does not difference between the weights of high and low impact citing papers. PageRank (Page et al., 1998) partially solved this problem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. type researchers’ impact ure has been widely criticized. Bibliometric studies (Radicchi, 2012) show that incomplete, erroneous or controversial papers are most cited. This can generate perverse incentives for new researchers who may be tempted to publish although its investigation is wrong or not yet complete because this way they will receive higher number of citations (Marder et al., 2010). In fact, it also affects the quality of very prestigious journals such as Nature, Science or Cell because they know that accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articles than their quality or than the relationship between papers with a higher number of citations and the number of citations that, in turn, they receive (Webster et al., 2009). Other limitation of this method is that a citation is interpreted as an author being influenced by the work of another, without specifying type of influence (Zhang et al., 2013) which can be misleading concerning the true impact of a citation (Young et al., 2008). To better understand the influence of a scientific work it is advisable to broaden the range of indicators to take into account factors like the author&apos;s disposition towards the reference, because, for instance, a criticized quoted work cannot have the same weight than other that is used as starting point of a research. 102 of the First Workshop on Argumentation pages Maryland USA, June 26, 2014. Association for Computational Linguistics These problems are added to the growing imof impact for the researchers’ career. It is becoming more important to correct these issues and look for more complete metrics to evaluate researchers’ relevance taking into account many other “quality” factors, one of them being the intention of the researcher when citing the work of others. Automatic analysis of subjective criteria present in a text is known as Sentiment Analysis. It is part of citation content analysis and is a current research topic in the area of natural language processing in the field of opinion mining and its scope includes monitoring emotions in fields as diverse as marketing, political science and economics. It is proposed that this type of analysis be applied in the study of bibliographic citations, as part of citation content analysis, to detect the intention and disposition of the citing author to the cited work, and to give additional information to complement the calculation of the estimated impact of a publication to enhance its bibliometric analysis (Jbara and Radev, 2012). This analysis includes syntactic and semantic language relationships through speech and natural language processing and the explicit and implicit linguistic choices in the text to infer citation function and feelings of the author regarding the cited work (Zhang et al., 2013). A combination of a quantitative and qualitative/subjective analysis would give a more complete perspective of the impact of publications in the scientific community (Jbara et al., 2013). Some methods for subjective citation analysis have been proposed by different authors, but they call for more work to achieve better results in detection, extraction and handling of citations content and to characterize in a more accurate way the profile of scientists and the criticism or acceptance of their work. Although work in this specific area has increased in recent years, there are still open problems that have not been solved and they need to be investigated. There are not enough open corpus that can be worked in shared form by researchers, there is not a common work frame to facilitate achieving results that are comparable with each other in order to reach conclusions about the efficiency of different techniques. In this field it is necessary to develop conditions that allow and motivate collaborative work.</abstract>
<note confidence="0.912159892857143">Acknowledgments This research work has been partially funded by the Spanish Government and the European Commission through the project, ATTOS (TIN2012-38536-C03- 03), LEGOLANG (TIN2012-31224), SAM (FP7- 611312) and FIRST (FP7-287607). Reference Councill, I. G., Giles, C. L., &amp; Kan, M. Y. (2008, May). ParsCit: an Open-source CRF Reference String Parsing Package. In LREC. Garfield, E. (1972, November). Citation analysis as a tool in journal evaluation. American Association for the Advancement of Science. Jbara, A., &amp; Radev, D. (2012, June). Reference scope identification in citing sentences. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 80-90). Association for Computational Linguistics. Jbara, A., Ezra, J., &amp; Radev, D. (2013). Purpose and Polarity of Citation: Towards NLP-based Bibliometrics. In Proceedings of NAACL-HLT (pp. 596- 606). Marder, E., Kettenmann, H., &amp; Grillner, S. (2010). Impacting our young. Proceedings of the National Academy of Sciences, 107(50), 21233-21233. Page, L., Brin, S., Motwani, R., &amp; Winograd, T. (1999). The PageRank citation ranking: bringing</note>
<abstract confidence="0.962228428571429">order to the web. F. (2012). In science “there is no bad licity”: Papers criticized in comments have high scientific impact. Scientific reports, 2. H. (1973). in the scientific literature: A new measure of the relationship between two documents. Journal of the American Society</abstract>
<note confidence="0.8890125">for information Science, 24(4), 265-269. Sugiyama, K., Kumar, T., Kan, M. Y., &amp; Tripathi, R. C. (2010). Identifying citing sentences in research papers using supervised learning. In Information Retrieval &amp; Knowledge Management, (CAMP), 2010 International Conference on (pp. 67-72). IEEE. Webster, G. D., Jonason, P. K., &amp; Schember, T. O. (2009). Hot Topics and Popular Papers in Evolutionary Psychology: Analyses of Title Words and Citation Counts in Evolution and Human Behavior, 1979-2008. Evolutionary Psychology, 7(3). Young, N. S., Ioannidis, J. P., &amp; Al-Ubaydli, O. (2008). Why current publication practices may distort science. PLoS medicine, 5(10), e201. Zhang, G., Ding, Y., &amp; Milojević, S. (2013). Citation</note>
<abstract confidence="0.623157">content analysis (cca): A framework for syntactic and semantic analysis of citation content. Journal of the American Society for Information Science and Technology, 64(7), 1490-1503.</abstract>
<intro confidence="0.612229">103</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I G Councill</author>
<author>C L Giles</author>
<author>M Y Kan</author>
</authors>
<title>ParsCit: an Open-source CRF Reference String Parsing Package.</title>
<date>2008</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="1619" citStr="Councill et al., 2008" startWordPosition="239" endWordPosition="242">ations in science grows exponentially each passing year. To understand the evolution of several topics, researchers and scientist require locating and accessing available contributions from among large amounts of available electronic material that can only be navigated through citations. Citation analysis is a way of evaluating the impact of an author, a published work or a scientific media. Sugiyama (2010) established that there are two types of research in the field of citation analysis of research papers: citation count to evaluate the impact (Garfield, 1972) and citation content analysis (Councill et al., 2008). The advantages of citation count are the simplicity and the experience accumulated in scientometric applications, but many authors have pointed out its weakness. One of the limitations is that the count does not difference between the weights of high and low impact citing papers. PageRank (Page et al., 1998) partially solved this problem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. Recently, this type researchers’ impact measure has bee</context>
</contexts>
<marker>Councill, Giles, Kan, 2008</marker>
<rawString>Councill, I. G., Giles, C. L., &amp; Kan, M. Y. (2008, May). ParsCit: an Open-source CRF Reference String Parsing Package. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Garfield</author>
</authors>
<title>Citation analysis as a tool in journal evaluation. American Association for the Advancement of Science.</title>
<date>1972</date>
<contexts>
<context position="1565" citStr="Garfield, 1972" startWordPosition="233" endWordPosition="234">tions. 1 Extended abstract The number of publications in science grows exponentially each passing year. To understand the evolution of several topics, researchers and scientist require locating and accessing available contributions from among large amounts of available electronic material that can only be navigated through citations. Citation analysis is a way of evaluating the impact of an author, a published work or a scientific media. Sugiyama (2010) established that there are two types of research in the field of citation analysis of research papers: citation count to evaluate the impact (Garfield, 1972) and citation content analysis (Councill et al., 2008). The advantages of citation count are the simplicity and the experience accumulated in scientometric applications, but many authors have pointed out its weakness. One of the limitations is that the count does not difference between the weights of high and low impact citing papers. PageRank (Page et al., 1998) partially solved this problem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. R</context>
</contexts>
<marker>Garfield, 1972</marker>
<rawString>Garfield, E. (1972, November). Citation analysis as a tool in journal evaluation. American Association for the Advancement of Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jbara</author>
<author>D Radev</author>
</authors>
<title>Reference scope identification in citing sentences.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</booktitle>
<pages>80--90</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="4888" citStr="Jbara and Radev, 2012" startWordPosition="773" endWordPosition="776"> citation content analysis and is a current research topic in the area of natural language processing in the field of opinion mining and its scope includes monitoring emotions in fields as diverse as marketing, political science and economics. It is proposed that this type of analysis be applied in the study of bibliographic citations, as part of citation content analysis, to detect the intention and disposition of the citing author to the cited work, and to give additional information to complement the calculation of the estimated impact of a publication to enhance its bibliometric analysis (Jbara and Radev, 2012). This analysis includes syntactic and semantic language relationships through speech and natural language processing and the explicit and implicit linguistic choices in the text to infer citation function and feelings of the author regarding the cited work (Zhang et al., 2013). A combination of a quantitative and qualitative/subjective analysis would give a more complete perspective of the impact of publications in the scientific community (Jbara et al., 2013). Some methods for subjective citation analysis have been proposed by different authors, but they call for more work to achieve better </context>
</contexts>
<marker>Jbara, Radev, 2012</marker>
<rawString>Jbara, A., &amp; Radev, D. (2012, June). Reference scope identification in citing sentences. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 80-90). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jbara</author>
<author>J Ezra</author>
<author>D Radev</author>
</authors>
<title>Purpose and Polarity of Citation: Towards NLP-based Bibliometrics.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT</booktitle>
<pages>596--606</pages>
<contexts>
<context position="5353" citStr="Jbara et al., 2013" startWordPosition="846" endWordPosition="849">additional information to complement the calculation of the estimated impact of a publication to enhance its bibliometric analysis (Jbara and Radev, 2012). This analysis includes syntactic and semantic language relationships through speech and natural language processing and the explicit and implicit linguistic choices in the text to infer citation function and feelings of the author regarding the cited work (Zhang et al., 2013). A combination of a quantitative and qualitative/subjective analysis would give a more complete perspective of the impact of publications in the scientific community (Jbara et al., 2013). Some methods for subjective citation analysis have been proposed by different authors, but they call for more work to achieve better results in detection, extraction and handling of citations content and to characterize in a more accurate way the profile of scientists and the criticism or acceptance of their work. Although work in this specific area has increased in recent years, there are still open problems that have not been solved and they need to be investigated. There are not enough open corpus that can be worked in shared form by researchers, there is not a common work frame to facili</context>
</contexts>
<marker>Jbara, Ezra, Radev, 2013</marker>
<rawString>Jbara, A., Ezra, J., &amp; Radev, D. (2013). Purpose and Polarity of Citation: Towards NLP-based Bibliometrics. In Proceedings of NAACL-HLT (pp. 596-606).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Marder</author>
<author>H Kettenmann</author>
<author>S Grillner</author>
</authors>
<title>Impacting our young.</title>
<date>2010</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>107</volume>
<issue>50</issue>
<pages>21233--21233</pages>
<contexts>
<context position="2577" citStr="Marder et al., 2010" startWordPosition="392" endWordPosition="395">lem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. Recently, this type researchers’ impact measure has been widely criticized. Bibliometric studies (Radicchi, 2012) show that incomplete, erroneous or controversial papers are most cited. This can generate perverse incentives for new researchers who may be tempted to publish although its investigation is wrong or not yet complete because this way they will receive higher number of citations (Marder et al., 2010). In fact, it also affects the quality of very prestigious journals such as Nature, Science or Cell because they know that accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articles than their quality or than the relationship between papers with a higher number of citations and the number of citations that, in turn, they receive (Webster et al., 2009). Other limitation of this method is that a citation is interpreted as an author being influenced by the work of another, with</context>
</contexts>
<marker>Marder, Kettenmann, Grillner, 2010</marker>
<rawString>Marder, E., Kettenmann, H., &amp; Grillner, S. (2010). Impacting our young. Proceedings of the National Academy of Sciences, 107(50), 21233-21233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Page</author>
<author>S Brin</author>
<author>R Motwani</author>
<author>T Winograd</author>
</authors>
<title>The PageRank citation ranking: bringing order to the web.</title>
<date>1999</date>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Page, L., Brin, S., Motwani, R., &amp; Winograd, T. (1999). The PageRank citation ranking: bringing order to the web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Radicchi</author>
</authors>
<title>In science “there is no bad publicity”: Papers criticized in comments have high scientific impact. Scientific reports,</title>
<date>2012</date>
<pages>2</pages>
<contexts>
<context position="2277" citStr="Radicchi, 2012" startWordPosition="344" endWordPosition="345">simplicity and the experience accumulated in scientometric applications, but many authors have pointed out its weakness. One of the limitations is that the count does not difference between the weights of high and low impact citing papers. PageRank (Page et al., 1998) partially solved this problem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. Recently, this type researchers’ impact measure has been widely criticized. Bibliometric studies (Radicchi, 2012) show that incomplete, erroneous or controversial papers are most cited. This can generate perverse incentives for new researchers who may be tempted to publish although its investigation is wrong or not yet complete because this way they will receive higher number of citations (Marder et al., 2010). In fact, it also affects the quality of very prestigious journals such as Nature, Science or Cell because they know that accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articl</context>
</contexts>
<marker>Radicchi, 2012</marker>
<rawString>Radicchi, F. (2012). In science “there is no bad publicity”: Papers criticized in comments have high scientific impact. Scientific reports, 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Small</author>
</authors>
<title>Co‐citation in the scientific literature: A new measure of the relationship between two documents.</title>
<date>1973</date>
<journal>Journal of the American Society for information Science,</journal>
<volume>24</volume>
<issue>4</issue>
<pages>265--269</pages>
<contexts>
<context position="1998" citStr="Small (1973)" startWordPosition="302" endWordPosition="303">edia. Sugiyama (2010) established that there are two types of research in the field of citation analysis of research papers: citation count to evaluate the impact (Garfield, 1972) and citation content analysis (Councill et al., 2008). The advantages of citation count are the simplicity and the experience accumulated in scientometric applications, but many authors have pointed out its weakness. One of the limitations is that the count does not difference between the weights of high and low impact citing papers. PageRank (Page et al., 1998) partially solved this problem with a rating algorithm. Small (1973) proposed co-citation analysis to supplement the qualitative method with a similarity measure between works A and B, counting the number of documents that cite them. Recently, this type researchers’ impact measure has been widely criticized. Bibliometric studies (Radicchi, 2012) show that incomplete, erroneous or controversial papers are most cited. This can generate perverse incentives for new researchers who may be tempted to publish although its investigation is wrong or not yet complete because this way they will receive higher number of citations (Marder et al., 2010). In fact, it also af</context>
</contexts>
<marker>Small, 1973</marker>
<rawString>Small, H. (1973). Co‐citation in the scientific literature: A new measure of the relationship between two documents. Journal of the American Society for information Science, 24(4), 265-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sugiyama</author>
<author>T Kumar</author>
<author>M Y Kan</author>
<author>R C Tripathi</author>
</authors>
<title>Identifying citing sentences in research papers using supervised learning.</title>
<date>2010</date>
<booktitle>In Information Retrieval &amp; Knowledge Management, (CAMP), 2010 International Conference on</booktitle>
<pages>67--72</pages>
<publisher>IEEE.</publisher>
<marker>Sugiyama, Kumar, Kan, Tripathi, 2010</marker>
<rawString>Sugiyama, K., Kumar, T., Kan, M. Y., &amp; Tripathi, R. C. (2010). Identifying citing sentences in research papers using supervised learning. In Information Retrieval &amp; Knowledge Management, (CAMP), 2010 International Conference on (pp. 67-72). IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Webster</author>
<author>P K Jonason</author>
<author>T O Schember</author>
</authors>
<title>Hot Topics and Popular Papers in Evolutionary Psychology: Analyses of Title Words and Citation Counts in Evolution and Human Behavior,</title>
<date>2009</date>
<journal>Evolutionary Psychology,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="3051" citStr="Webster et al., 2009" startWordPosition="469" endWordPosition="472">publish although its investigation is wrong or not yet complete because this way they will receive higher number of citations (Marder et al., 2010). In fact, it also affects the quality of very prestigious journals such as Nature, Science or Cell because they know that accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articles than their quality or than the relationship between papers with a higher number of citations and the number of citations that, in turn, they receive (Webster et al., 2009). Other limitation of this method is that a citation is interpreted as an author being influenced by the work of another, without specifying type of influence (Zhang et al., 2013) which can be misleading concerning the true impact of a citation (Young et al., 2008). To better understand the influence of a scientific work it is advisable to broaden the range of indicators to take into account factors like the author&apos;s disposition towards the reference, because, for instance, a criticized quoted work cannot have the same weight than other that is used as starting point of a research. 102 Proceed</context>
</contexts>
<marker>Webster, Jonason, Schember, 2009</marker>
<rawString>Webster, G. D., Jonason, P. K., &amp; Schember, T. O. (2009). Hot Topics and Popular Papers in Evolutionary Psychology: Analyses of Title Words and Citation Counts in Evolution and Human Behavior, 1979-2008. Evolutionary Psychology, 7(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N S Young</author>
<author>J P Ioannidis</author>
<author>O Al-Ubaydli</author>
</authors>
<title>Why current publication practices may distort science. PLoS medicine,</title>
<date>2008</date>
<volume>5</volume>
<issue>10</issue>
<pages>201</pages>
<contexts>
<context position="3316" citStr="Young et al., 2008" startWordPosition="516" endWordPosition="519">at accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articles than their quality or than the relationship between papers with a higher number of citations and the number of citations that, in turn, they receive (Webster et al., 2009). Other limitation of this method is that a citation is interpreted as an author being influenced by the work of another, without specifying type of influence (Zhang et al., 2013) which can be misleading concerning the true impact of a citation (Young et al., 2008). To better understand the influence of a scientific work it is advisable to broaden the range of indicators to take into account factors like the author&apos;s disposition towards the reference, because, for instance, a criticized quoted work cannot have the same weight than other that is used as starting point of a research. 102 Proceedings of the First Workshop on Argumentation Mining, pages 102–103, Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics These problems are added to the growing importance of impact indexes for the researchers’ career. It is becom</context>
</contexts>
<marker>Young, Ioannidis, Al-Ubaydli, 2008</marker>
<rawString>Young, N. S., Ioannidis, J. P., &amp; Al-Ubaydli, O. (2008). Why current publication practices may distort science. PLoS medicine, 5(10), e201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Zhang</author>
<author>Y Ding</author>
<author>S Milojević</author>
</authors>
<title>Citation content analysis (cca): A framework for syntactic and semantic analysis of citation content.</title>
<date>2013</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>64</volume>
<issue>7</issue>
<pages>1490--1503</pages>
<contexts>
<context position="3230" citStr="Zhang et al., 2013" startWordPosition="500" endWordPosition="503">lity of very prestigious journals such as Nature, Science or Cell because they know that accepting controversial articles is very profitable to increase citation numbers. Moreover, as claimed by Siegel and Baveye (2010), it is more influential the quantity of articles than their quality or than the relationship between papers with a higher number of citations and the number of citations that, in turn, they receive (Webster et al., 2009). Other limitation of this method is that a citation is interpreted as an author being influenced by the work of another, without specifying type of influence (Zhang et al., 2013) which can be misleading concerning the true impact of a citation (Young et al., 2008). To better understand the influence of a scientific work it is advisable to broaden the range of indicators to take into account factors like the author&apos;s disposition towards the reference, because, for instance, a criticized quoted work cannot have the same weight than other that is used as starting point of a research. 102 Proceedings of the First Workshop on Argumentation Mining, pages 102–103, Baltimore, Maryland USA, June 26, 2014. c�2014 Association for Computational Linguistics These problems are adde</context>
<context position="5166" citStr="Zhang et al., 2013" startWordPosition="817" endWordPosition="820">ysis be applied in the study of bibliographic citations, as part of citation content analysis, to detect the intention and disposition of the citing author to the cited work, and to give additional information to complement the calculation of the estimated impact of a publication to enhance its bibliometric analysis (Jbara and Radev, 2012). This analysis includes syntactic and semantic language relationships through speech and natural language processing and the explicit and implicit linguistic choices in the text to infer citation function and feelings of the author regarding the cited work (Zhang et al., 2013). A combination of a quantitative and qualitative/subjective analysis would give a more complete perspective of the impact of publications in the scientific community (Jbara et al., 2013). Some methods for subjective citation analysis have been proposed by different authors, but they call for more work to achieve better results in detection, extraction and handling of citations content and to characterize in a more accurate way the profile of scientists and the criticism or acceptance of their work. Although work in this specific area has increased in recent years, there are still open problem</context>
</contexts>
<marker>Zhang, Ding, Milojević, 2013</marker>
<rawString>Zhang, G., Ding, Y., &amp; Milojević, S. (2013). Citation content analysis (cca): A framework for syntactic and semantic analysis of citation content. Journal of the American Society for Information Science and Technology, 64(7), 1490-1503.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>