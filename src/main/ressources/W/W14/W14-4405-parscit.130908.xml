<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9969095">
A language-independent method for the extraction of RDF verbalization
templates
</title>
<author confidence="0.998826">
Basil Ell
</author>
<affiliation confidence="0.8459475">
Karlsruhe Institute of Technology (KIT)
Karlsruhe, Germany
</affiliation>
<email confidence="0.998326">
basil.ell@kit.edu
</email>
<author confidence="0.995503">
Andreas Harth
</author>
<affiliation confidence="0.8458355">
Karlsruhe Institute of Technology (KIT)
Karlsruhe, Germany
</affiliation>
<email confidence="0.998614">
harth@kit.edu
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954789473684">
With the rise of the Semantic Web more
and more data become available encoded
using the Semantic Web standard RDF.
RDF is faced towards machines: de-
signed to be easily processable by ma-
chines it is difficult to be understood by
casual users. Transforming RDF data into
human-comprehensible text would facil-
itate non-experts to assess this informa-
tion. In this paper we present a language-
independent method for extracting RDF
verbalization templates from a parallel
corpus of text and data. Our method is
based on distant-supervised simultaneous
multi-relation learning and frequent maxi-
mal subgraph pattern mining. We demon-
strate the feasibility of our method on a
parallel corpus of Wikipedia articles and
DBpedia data for English and German.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993880803571429">
Natural Language Generation (NLG) systems re-
quire resources such as templates (in case of
template-based NLG) or rules (in case of rule-
based NLG). Be it template-based or rule-based
systems, these resources limit the variability and
the domain-specificity of the generated natural
language output and manual creation of these re-
sources is tedious work.
We propose a language-independent approach
that induces verbalization templates for RDF
graphs from example data. The approach is
language-independent since it does not rely on
pre-existing language resources such as parsers,
grammars or dictionaries.
Input is a corpus of parallel text and data con-
sisting of a set of documents D and an RDF graph
G, where D and G are related via a set of entities
E where an entity can be described by a document
in D and described by data in G. Output is a set
of templates. Templates consist of a graph pattern
that can be applied to query the graph and of a sen-
tence pattern that is a slotted sentence into which
parts of the query result are inserted. A template
enables verbalization of a subgraph of G as a com-
plete sentence.
An example is shown in Fig. 1.1 The graph pat-
tern GP can be transformed into a SPARQL query
QGP. Querying the data graph G results in the
graph GGP. GGP can be verbalized as an English
(German) sentence Sen (Sde) using the sentence
pattern SPen (SPde).
The approach employs the distant supervision
principle (Craven and Kumlien, 1999; Bunescu
and Mooney, 2007; Carlson et al., 2009; Mintz
et al., 2009; Welty et al., 2010; Hoffmann et al.,
2011; Surdeanu et al., 2012) from relation extrac-
tion: training data is generated automatically by
aligning a database of facts with text; therefore,
no hand-labeled data is required. We apply si-
multaneous multi-relation learning (Carlson et al.,
2009) for text-data alignment and frequent maxi-
mal subgraph pattern mining to observe common-
alities among RDF graph patterns.
Besides the general idea to allow for non-
experts to assess information encoded in RDF, we
envision application of these verbalization tem-
plates in three scenarios:
(1) In query interfaces to semantic databases, ca-
sual users - usually not capable of writing for-
mal queries – specify their information needs
using keywords (Lei et al., 2006; Thomas
et al., 2007; Wang et al., 2008), questions
in free-text or using a controlled language
(Kaufmann et al., 2006; Cimiano et al., 2008;
Wendt et al., 2012; Damljanovic et al., 2012),
or forms (Hunter and Odat, 2011; Mendes
</bodyText>
<footnote confidence="0.985476">
1Further examples and the evaluation material can be
found on our website at http://km.aifb.kit.edu/
sites/bridge-patterns/INLG2014
</footnote>
<page confidence="0.957798">
26
</page>
<note confidence="0.940805">
Proceedings of the 8th International Natural Language Generation Conference, pages 26–34,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.7530088">
Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pattern GP
can be transformed into a SPARQL query QGP. A result of querying the data graph is the RDF graph
GGP with the list of solution mappings µ. This graph can be verbalized as an English sentence Sen using
the English sentence pattern SPen or as a German sentence Sde using the German sentence pattern SPde.
The modifiers, e.g. lcfirst, are explained in Table 1.
</figureCaption>
<figure confidence="0.995990163934426">
GP
GGP
label pubD
?book ?author
author
?book_type Writer
type type
label
label
label pubD label label
Flash L_E_Modesitt
author
„2004“
type type
SFN Writer
?book_label = „Flash (novel)“@en
?book_type_label = „Science fiction novel“@en
?author_label = „L. E. Modesitt“@en
?book_pubD = &amp;quot;2004&amp;quot;
?book = Flash
?author = L_E_Modesitt
?book_type = SFN
µ
?book_label ?book_pubD ?author_label
„Flash (novel)“@en „L. E. Modesitt“@en
?book_type_label
„Flash (Roman)“@de
„Science fiction novel“@en
„Science-Fiction-Roman“@de
„L. E. Modesitt“@de
SELECT
?book_label
?book_type_label
?author_label
?book_pubD
WHERE {
?book :author ?author .
?book :type ?book_type .
?book :label ?book_label .
?book :pubD ?book_pubD .
?author :type :Writer .
?author :label ?author_label .
?book_type :label ?book_type_label .
}
{M(book_label|rm())M} ist ein
{M(book_type_label|lcfirst)M} von
{M(author_label|id)M}, erschienen
{M(book_pubD|id)M}.
QGP
SPen
SPde
Flash is a science fiction novel by
L. E. Modesitt published in 2004.
Sen
Flash ist ein Science-Fiction-Roman
von L.E. Modesitt, erschienen 2004.
Sde
{M(book_label|rm())M} is a
{M(book_type_label|lcfirst)M} by
{M(author_label|id)M} published in
{M(book_pubD|id)M}.
</figure>
<bodyText confidence="0.999058666666667">
et al., 2008). The system queries an RDF
database according to its interpretation of the
input. Query results could be verbalized.
</bodyText>
<listItem confidence="0.615550578947368">
(2) Since the introduction of the Google Knowl-
edge Graph,2 when searching for an entity
such as the city of Karlsruhe via Google, be-
sides the search results shown on the left a
table is displayed on the right which provides
a short description of the entity taken from
Wikipedia. While these descriptions are de-
coupled from data in the knowledge graph
they could be generated automatically.
(3) The collaboratively-edited knowledge base
Wikidata provides machine-readable data
which can be used, e.g., by the Wikipedia.
The Wikidata browsing interface reasonator
currently explores the use of template-based
NLG in order to provide human-readable de-
scriptions of its entities.3 Since the templates
are created manually, currently only for few
types of entities these verbalizations can be
provided.
</listItem>
<footnote confidence="0.999550166666667">
2http://googleblog.blogspot.com/2012/
05/introducing-knowledge-graph-things-
not.html (accessed 2014-03-20)
3See for example the page about Johann Sebastian
Bach:http://tools.wmflabs.org/reasonator/
?q=Q1339 (accessed 2014-03-20)
</footnote>
<subsectionHeader confidence="0.99956">
1.1 Main contributions
</subsectionHeader>
<bodyText confidence="0.999919476190476">
We present an approach to induce RDF verbal-
ization templates from a parallel text-data cor-
pus. (1) The approach is distant-supervised, since
it does not require labeled data but instead auto-
matically aligns a database of facts with text by
performing simultaneous multi-relation learning.
(2) Hypotheses about a sentence’s content are rep-
resented as an RDF graph pattern. Hypotheses
graphs are reduced via frequent maximal subgraph
pattern mining. (3) We introduce RDF verbal-
ization templates consisting of a sentence pattern
which includes modifiers and a graph pattern of
unrestricted size. (4) Our approach does not use
language resources such as parsers or dictionaries
and is thus language independent and (5) does not
depend on a certain ontology or domain. (6) The
feasibility of the approach is validated for English
and German given a large dataset which resulted in
the induction of a large number of templates that
are general in terms of enabling verbalization of
numerous subgraphs in our dataset.
</bodyText>
<subsectionHeader confidence="0.879333">
1.2 Definitions
</subsectionHeader>
<listItem confidence="0.8609655">
• A template is a tuple (sp, gp) where sp is
a sentence pattern and gp is a graph pat-
tern. We denote the set of variables within
a sentence pattern sp as V arSP(sp) and the
</listItem>
<page confidence="0.923011">
27
</page>
<listItem confidence="0.9904230625">
set of variables within a graph pattern gp as
V arGP(gp). A template (sp, gp) is safe if the
set of variables within the sentence pattern
is a subset of the set of variables within the
graph pattern: V arSP(sp) ⊆ V arGP(gp).
• A sentence pattern (SP) is a string that con-
sists of terminals, variables, and modifiers.
Within an SP a (var., mod.) tuple (v, m) is
denoted as {M(v|m)M}. {M( and )M} serve
as delimiters of a (var., mod.) tuple.
• A graph pattern is a set of triples patterns
(s, p, o) where s ∈ U ∪ V, p ∈ U ∪ V, and
o ∈ U ∪ L ∪ V. U is a set of identifiers, L is
a set of literals, and V is a set of variables.
• A modifier m ∈ M is a function applicable
to the value of a variable v - denoted by m(v).
</listItem>
<subsectionHeader confidence="0.868452">
1.3 Template-based NLG
</subsectionHeader>
<bodyText confidence="0.9998167">
A template can be applied for Natural Language
Generation as follows. Given an RDF data
graph G and a template (sp, gp), a SPARQL
SELECT query can be created: SELECT PV
WHERE { gp&apos; }. The list of projection variables
PV is the list of variables v∈V arSP(sp). gp&apos; is
constructed by adding each triple pattern to gp&apos;.
An example of a query (QGP) created from a
graph pattern (GP) is shown in Fig. 1.
Executing a query results in a solution se-
quence4 which is a list of solution mappings
µ:V →T from a set of variables V to a set of RDF
terms T = U∪L. See Fig. 1 for an example of a
solution mapping (µ).
For each non-terminal in sp representing a
variable-modifier tuple (v, m), the modifier m is
applied on µ(v) resulting in m(µ(v)). Finally,
the tuple (v, m), expressed as {M(v|m)M}, is re-
placed in sp with m(µ(v)). After replacing each
such tuple the sentence creation is complete.
</bodyText>
<sectionHeader confidence="0.968422" genericHeader="introduction">
2 Parallel corpus
</sectionHeader>
<bodyText confidence="0.99975175">
Our approach requires a parallel corpus of text and
data and consists of texts that describe entities in
natural language and a data graph that semanti-
cally describes entities.
Formally, the parallel corpus consists of a
set of entities E, a set of documents D, and
an RDF data graph G. An entity can be de-
scribed by a document in a certain language.
</bodyText>
<footnote confidence="0.65472375">
4We adopt the terminology from the SPARQL 1.1
Query Language documentation available at http:
//www.w3.org/TR/2013/REC-sparql11-query-
20130321/.
</footnote>
<bodyText confidence="0.999592736842105">
The relation document ⊆ E×L×D relates an
(entity, language) tuple to a set of documents.
document(e, l) denotes the (potentially empty)
set of documents that describe an entity e∈E in
language l∈L.
G is a set of triples (s, p, o) where s, p∈U, and
o∈U∪L.
Each literal has a datatype, returned by the func-
tion datatype:L→T. Literals of type string can
be language-tagged. The function ll:L→L returns
the language ll(r)∈L for a literal r∈L if it ex-
ists. An entity can have a human-readable form
which is a language-tagged literal. The relation
A⊆E×L×L relates an entity e∈E to a (possibly
empty) set of literals A(e, l)⊆L in language l∈L.
The property p), relates an entity with its label.
Each entity e∈E occurs in the data graph. This
means that G contains a triple (s, p, o) where s=e
or o=e.
</bodyText>
<sectionHeader confidence="0.997624" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.992653">
Our approach consists of six steps:
</bodyText>
<listItem confidence="0.968132103448276">
1. For each entity e ∈ E we collect sentences
from documents about the entity that mention
the entity.
2. For each sentence we align the sentence and
the data graph by iteratively exploring the
vicinity of the entity within the graph. This
leads to a set of identified entities: entities
that are believed to be mentioned within the
sentence; and a set of observations. The sub-
graph of G that consists of all triples that con-
tain an identified entity serves as an hypothe-
sis graph: no fact that is not expressed in the
subgraph is expressed in the sentence.
3. Each (sentence, identified entities, graph)
triple is abstracted by replacing identified lit-
erals in the sentence and in the graph with
variables and by replacing identified entities
in the graph with variables. This step can
lead to multiple distinct (sentence pattern,
graph pattern) tuples for each sentence. This
abstraction enables comparing different sen-
tences that share the same sentence pattern
after abstraction.
4. A set of (sentence pattern, graph patterns) tu-
ples is built for each sentence pattern.
5. For each (sentence pattern, graph patterns)
tuple the set of graph patterns is analyzed re-
garding their commonalities. This is realized
via the frequent and maximal subgraph pat-
</listItem>
<page confidence="0.994428">
28
</page>
<bodyText confidence="0.9706014">
tern extraction (fmSpan) algorithm which re-
sults in a set of graph patterns that are sub-
graph patterns to the input graph patterns.
6. Given the output of this algorithm and the ab-
stracted sentences the templates are created.
</bodyText>
<subsectionHeader confidence="0.999744">
3.1 Sentence collection
</subsectionHeader>
<bodyText confidence="0.988984818181818">
Given a language name l, a set of entities E, a
set of documents D and an ordered list of mod-
ifiers M, for each entity e ∈ E for each docu-
ment d ∈ document(e, l) (which describes e in
language l) the document is split into a set of sen-
tences. For each sentence that has an acceptable
length (measured as the number of characters), for
each label x ∈ A(e, l) and for each string modifier
m ∈ Mstring, we store the (sentence, entity, left,
right, A, matched) tuple if the modified label m(x)
matches the sentence. See Alg. 1.
</bodyText>
<construct confidence="0.415897">
Algorithm 1 Collect example sentences
</construct>
<listItem confidence="0.961494523809524">
1: procedure COLLECT EXAMPLE SENTENCES(l, E, D, M)
2: for each e E E do
3: for each d E document(e, l) E D do
4: for each s E sentences(d, lmin, lmax) do
5: for each x E λ(e, l) do
6: for each m E Mstring do
7: if applicable(m, x) then
8: (left, right, x’) = MatchesLabel(s, x, m, ”str”)
9: if (left, right, x’) =� 0 then
10: Output (s, e, left, right, x, x’, m)
11: Continue with next sentence
Algorithm 2 MatchesLabel
1: procedure MATCHESLABEL(s, x, m, t)
2: if t = ”str” V t =� ”integer” then
3: if length(x) &gt; 4 then
4: if s matches (\W|ˆ)\w{l0, l1}m(x)\w{r0, r1}(\W|$) then
5: return (left, right, matched)
6: else if t = integer then
7: ifs matches (\D|ˆ)m(x)(\D|$) then
8: return (left, right, matched)
9: return 0
</listItem>
<bodyText confidence="0.998913103448276">
In Alg. 2, \W denotes a non-word character
(such as a blank), \D denotes a non-digit, \w de-
notes a word character5 (such as ”x”), \w{a, b}
denotes a sequence of at least a word-characters
and not more than b word characters, l0 and l1 are
the minimum and maximum number of word char-
acters that may appear on the left side of the mod-
ified string m(x) between this string and a non-
word character or the beginning of the sentence
(ˆ). r0 and r1 are the corresponding numbers re-
garding the right side of the modified string. $ de-
notes the end of the sentence. In case of a match,
the string that is matched by \w{l0, l1} is stored
5Note that word- and non-word characters are language-
specific and may be defined for each language individually.
as left, the string that is matched by \w{r0, r1}
is stored as right and the part that matches m(x)
is stored as matched. Note that matched can be
different from m(x) since the application of the
modifier m to the string x can result in a reg-
ular expression that contains information for the
matcher specifying that a part of the string needs
to be matched case-insensitively.
Allowing a certain number of characters to be
added to the left and to the right of a string has
the intention to match even though prefixes and
postfixes are added. For example, this allows to
match ”German” within its plural form ”Germans”
or to match ”magic” within magician.
</bodyText>
<subsectionHeader confidence="0.999794">
3.2 Sentence and data alignment
</subsectionHeader>
<bodyText confidence="0.9583793125">
The sentence and the data graph are aligned by it-
eratively exploring the vicinity of an entity within
the graph. This exploration is described by Alg. 3
which builds a set of observations obs. A member
of this set is a 7-tuple where the first three mem-
bers form a triple (entity, property, literal value),
followed by the strings matched to the left and the
right, the matched string and the modifier. More-
over, the algorithm creates a graph graph ⊆ G
consisting of all triples that contain an identified
entity. Here, an entity e is identified if a modi-
fier m ∈ M exists such that an x ∈ A(e, l) exists
such that the sentence matches m(x). Output is
the original sentence, the set of identified entities,
the set of observations, and the subgraph.
Algorithm 3 Data Collection
</bodyText>
<listItem confidence="0.823760545454546">
1: procedure COLLECTDATA(s, e, lang, left, right, x, x&apos;, m)
2: identified = 0; todo = (e); done = 0;
3: graph= 0; obs = {(e, pl, x, left, right, x&apos;, m)}
4: while todo =� 0 do
5: e F todo.first
6: todo F todo\{e}; done F done U {e}
7: for each (e, p, o) E G do
8: graph F graph U {(e, p, o)}
9: if o is a literal then
10: (l, r, o’, m) = CL(s, o)
11: if (l, r, o&apos;, m) =� 0 then
12: obs F obs U {(e, p, o, l, r, o&apos;, m)}
13: if o = λ(e, lang) then
14: identified F identified U {e}
15: else if o is a URI then
16: if o E� done h o E� todo then
17: todo.add(o)
18: for each (e2, p, e) E G do
19: graph F graph U {(e2, p, e)}
20: if e2 E� done h o E� todo then
21: todo.add(e2)
22: Output (sentence, identified, obs, graph)
</listItem>
<subsectionHeader confidence="0.990267">
3.3 Sentence and graph abstraction
</subsectionHeader>
<bodyText confidence="0.999834">
In the previous step, ambiguities may exist.
For example, given two triples (e1,p1,v) and
</bodyText>
<page confidence="0.993516">
29
</page>
<bodyText confidence="0.979965766666667">
(e2, p2, v) where v is a literal value and the en-
tities e1 and e2 are identified, if the value v is
found in the sentence, then it cannot be resolved
whether the sentence expresses the fact (e1, p1, v)
or (e2, p2, v). Therefore, for each situation where
a value appears in two distinct contexts or where
values overlap (two values overlap if the inter-
vals of their character positions overlap), the sen-
tence and graph pattern is copied and on each copy
another abstraction is performed thus leading to
multiple abstractions per sentence. Alg. 4 iter-
atively creates all sentence abstractions given a
language name l, a sentence S, and a set of ob-
servations obs. The function poss evaluates the
set of observations that are still valid. The func-
tion apply replaces a string in a sentence with
variable and modifier. Thereby, the left and right
parts are added to the modifier. For an obser-
vation (e, p, o,l, r, o0, m) the string concatenation
l+o0+r is replaced with {M(vi|m’)M}. For each
observation a new variable vi is introduced. m0
is a modifier to which the modifiers +l(l) and
+r(r) are appended which denote that certain
strings are added to the left and the right of the
literal. The graph is abstracted by replacing the
triple (e, p, o) with the triple pattern (e, p, v1). Af-
ter completely abstracting a sentence pattern, each
identified entity is replaced by a variable; triples
that do not contain any variable are removed.
Algorithm 4 Sentence abstraction
</bodyText>
<listItem confidence="0.956073266666667">
1: procedure ABSSENTENCE(l, S, obs)
2: P F poss(l, S, obs)
3: if P = 0 then
4: Output(S)
5: else
6: O F overlap(S, P)
7: for each p E P do
8: if p E� O then
9: S F apply(S, p)
10: if O = 0 then
11: Output(S)
12: else
13: for each p E O do
14: S&apos; F apply(S, p)
15: AbsSentence(l, S’, P)
</listItem>
<subsectionHeader confidence="0.948986">
3.4 Grouping
</subsectionHeader>
<bodyText confidence="0.999968166666667">
Given a set of (sp, gp) tuples, for each lan-
guage we build groups of tuples where in each
group the sentence patterns are pairwise equiv-
alent when ignoring modifiers. Sentence pat-
terns spi and spj are equivalent if either they
are identical (spi=spj), or if an injective func-
tion m:V arSP(spi)→V arSP(spj) exists such
that when each variable v in spi is replaced with
m(v), the resulting string sp0i is identical to spj.
For each group the set of graph patterns is used
as input for the algorithm presented in the follow-
ing section.
</bodyText>
<sectionHeader confidence="0.7692505" genericHeader="method">
3.5 Frequent maximal subgraph pattern
extraction
</sectionHeader>
<bodyText confidence="0.999711086956522">
Before we describe the fmSpan algorithm
(fmSpan: Frequent Maximal Subgraph PAttern
extractioN) we need to introduce our notation:
Two graph patterns gpi and gpj are equiv-
alent (gpi=gpj) if an injective function
m:V arGP(gpi)→V arGP(gpj) exists such
that when each variable v in gpi is replaced
with m(v), the resulting graph pattern gp0i is
identical to gpj. A graph pattern gpi is sub-
graph pattern to another graph pattern gpj,
denoted by gpi⊆pgpj, if an injective function
m:V arGP(gpi)→V arGP(gpj) exists such that
when each variable v in gpi is replaced with
m(v), resulting in gp0i, each triple pattern in gp0i is
also a triple pattern in gpj. Given a set of graph
patterns GP={gp1, ..., gpn} and given a graph
pattern x, the coverage of x regarding GP is the
number of graphs in GP to which x is a subgraph
pattern: c(x,GP) := |{gpi ∈ GP|x ⊆p gpi}|.
Given a set of graph patterns I={gp1, ..., gpn},
from the set of all subgraph patterns P=2gp1 ∪...∪
2gpn a set of graph patterns K={gpi, ..., gpj}⊆P
is selected where:
</bodyText>
<listItem confidence="0.980206714285714">
1. for each gpk ∈ K:
(a) c(gpk, I) ≥ min coverage
(b) ¬∃gpl ∈ P : gpk =6 gpl ∧ gpk ⊆p gpl ∧
c(gpl, I) ≥ min coverage
2. ¬∃gpl ∈ P : c(gpl, I) ≥ min coverage ∧
(¬∃gpm ∈ P : ¬(gpm, gpl) ∧ c(gpm, I) ≥
min coverage) ∧ gpl ∈6 K
</listItem>
<bodyText confidence="0.999034666666667">
This means that each member of K is suffi-
ciently frequent (1a) and maximal (2b) and that
every maximal graph pattern is contained in K (2).
</bodyText>
<subsectionHeader confidence="0.990437">
3.6 Template creation
</subsectionHeader>
<bodyText confidence="0.9999842">
For each (sentence pattern, graph patterns) tuple
the frequent maximal subgraph pattern mining is
performed on the group of graph patterns which
results in a set K of subgraph patterns. Each
k ∈ K is pruned with Alg. 5. Thereby, if a vari-
able appears in a high number of triples that do
not contain any other variable, then these triples
are removed. After the pruning each k ∈ K is
then rejected if it is either not safe, not connected,
or, when queried against G returns no results.
</bodyText>
<page confidence="0.985651">
30
</page>
<figure confidence="0.94109025">
Algorithm 5 Graph-pattern pruning
1: procedure PRUNEGRAPHPATTERN(k)
2: for each v E VarcP (k) do
3: T F {(s, p, o) E kJ(s = v ∧ o E� VarcP(k)) V (o = v ∧ s E�
V arcP (k))}
4: if JTJ &gt; maxt then
5: kFk\T
Datatype Modifier Description
</figure>
<bodyText confidence="0.87723775">
xsd:string id Does not change the string.
lcfirst Sets the first char to lower case
if that char is upper case.
ucfirst Sets the first char to upper case
if that char is lower case.
case-i Case-insensitive match
rm() If a string ends with a string
in round braces, e.g. ”Dublin
(Ohio)”, that part is cut off.
-1r Removes the rightmost char.
xsd:gYear YYYY Transforms a year value into a
four-digit representation.
</bodyText>
<table confidence="0.945737777777778">
xsd:integer integer id Does not change the integer.
enInt sep Adds English thousands separa-
tors, e.g., 10,000.
deInt sep Adds German thousands sepa-
rators, e.g., 10.000.
xsd:date enM, D Y Result, e.g., March, 22 2014
enD M Y Result, e.g., 22 March 2014
deM D, Y Result, e.g., M¨arz 22, 2014
deD M Y Result, e.g., 22. M¨arz 2014
</table>
<tableCaption confidence="0.999721">
Table 1: List of modifiers per datatype
</tableCaption>
<sectionHeader confidence="0.997317" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99992">
We created a multilingual (English, German) par-
allel text-data corpus using data from DBpedia6
and documents from the Wikipedia. The graph
G consists of 88, 708,622 triples, the set of doc-
uments D consists of 4,004,478 English docu-
ments and 716,049 German documents. The cor-
pus relations and functions are defined as follows:
</bodyText>
<listItem confidence="0.953743">
• document(e, l) :=
{dJ(e, dbo:abstract, ”d”@l) E G}.
• A(e, l) := {vJ(e, rdfs:label, ”v”@l) E G}
• The datatype of a literal &amp;quot;r&amp;quot;&amp;quot;t&amp;quot; is t.
• The language ll of a literal &amp;quot;d&amp;quot;@l is l.
</listItem>
<bodyText confidence="0.9731385">
The modifiers we used in the experiment are
given in Table 1.7 Application of date and inte-
</bodyText>
<footnote confidence="0.933943375">
6http://wiki.dbpedia.org/Downloads39
We used the files long abstracts en, long abstracts en-
uris de, mappingbased properties en, raw infobox prop-
erties en, article categories en, instance types en, labels en,
labels en uris de, category labels en, and category labels-
en uris de.
7Modifiers are only applied if their application to a literal
modifies that literal. For example, if a string begins with a
</footnote>
<table confidence="0.996733333333333">
groups &gt; 5 templates all groups
en 4569 3816 686,687
de 2130 1250 269,551
</table>
<tableCaption confidence="0.993827">
Table 3: Number of groups with a cardinality &gt; 5,
</tableCaption>
<bodyText confidence="0.979103025">
the number of induced templates and the number
of all groups.
ger modifiers may also depend on the language of
a sentence. On a value a list of modifiers can be
applied. The list of string modifier lists is shown
in Fig. 2. The table also shows how often each list
of modifiers was applied during the abstraction of
English and German sentences.
We created two sets of entities Ee,,, (Ede): those
for which an English (German) document exist
that consists of at least 100 characters. Ee,,, and
Ede contain 3,587,146 and 613,027 entities, re-
spectively. For each entity for each document we
split the text into sentences using the Perl module
Lingua::Sentence8 and discarded sentences that
do not end with a full stop, an exclamation mark,
or a question mark or that were shorter (longer)
than 50 (200) characters. We used the set of string
modifiers presented in Fig. 2 to identify entities via
occurrence of a modified version of their labels in
a sentence. The results are 3, 811, 992 (794, 040)
English (German) sentences.
Abstraction resulted in 3,434,108 (530,766) ab-
stracted English (German) sentences where at
least two entities are identified per sentence.
The group size histogram is displayed in Fig. 2.9
The majority (90%) of all groups of English (Ger-
man) sentences contain between 5 and 164 (5 and
39) sentences.
Table 3 gives for each language the number of
groups that contain more than 5 graph patterns, the
number of templates we induced, and the num-
ber of all groups. Results of the coverage evalu-
ation covt(G) are shown as a histogram in Fig. 3.
It shows that for the majority of the templates a
high number of subgraphs of G can be verbalized,
which means that the templates are not fitted to
only a small number of subgraphs: e.g. for 221
English templates verbalize between 105 and 106
subgraphs, each.
</bodyText>
<footnote confidence="0.883646">
lower case character, then the lcfirst modifier is inapplicable.
8http://search.cpan.org/˜achimru/
Lingua-Sentence-1.05
9We cut off the long tail.
</footnote>
<page confidence="0.999891">
31
</page>
<figure confidence="0.959928222222222">
No Modifier list
(1) id
(2) lcfirst
(3) ucfirst
(4) case-i
(5) rm()
(6) rm(), lcfirst
(7) rm(), ucfirst
(8) rm(), case-i
</figure>
<table confidence="0.990296111111111">
en de No Modifier list en de No Modifier list en de
10,619,509 1,349,922 (9) -1r 42,754 15,025 (17) -1r, -1r, lcfirst 8430 90
141,865 868 (10) -1r, lcfirst 7513 99 (18) -1r, -1r, ucfirst 1020 5
11,018 8 (11) -1r, ucfirst 875 4 (19) -1r, -1r, case-i 733 92
295,593 16,351 (12) -1r, case-i 863 50 (20) rm(), -1r, -1r, lcfirst 0 0
2705 762 (13) rm(), -1r, lcfirst 0 0 (21) rm(), -1r, -1r, ucfirst 0 0
13 0 (14) rm(), -1r, ucfirst 0 0 (22) rm(), -1r, -1r, case-i 66 1
0 0 (15) rm(), -1r, case-i 55 6
50 0 (16) -1r, -1r 39,113 11,632
</table>
<tableCaption confidence="0.998329">
Table 2: List of lists of string modifiers and their number of applications
</tableCaption>
<figure confidence="0.998739256410256">
10000
1000
100
10
1
en-groups
de-groups
5-9
10-14
15-19
20-24
25-29
30-34
35-39
40-44
45-49
50-54
55-59
60-64
65-69
70-74
75-79
80-84
85-89
90-94
95-99
100-104
105-109
110-114
115-119
120-124
125-129
130-134
135-139
140-144
145-149
150-154
155-159
160-164
</figure>
<figureCaption confidence="0.99832">
Figure 2: Histogram depicting how often sentence groups occurred with a particular size
</figureCaption>
<sectionHeader confidence="0.996565" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.997952">
We evaluate the results from the experiment de-
scribed in the previous section along the dimen-
sions coverage, accuracy, syntactic correctness,
and understandability where the latter three are in-
spired by (Lester and Porter, 1997; Mellish and
Dale, 1998; Reiter and Belz, 2009).
Coverage: we define cov(t, G) of a template
t=(sp, gp) regarding a data graph G as the
number of subgraphs of G that can be verbal-
ized with that template i.e. match gp.
Accuracy: is measured in two parts:
1. The extent to which everything that is ex-
pressed in gp is also expressed in sp is mea-
sured for each triple pattern within the graph
pattern on a 4-point scale: (1) The triple pat-
tern is explicitly expressed, (2) The triple pat-
tern is implied, (3) The triple pattern is not
expressed, and (4) Unsure.
2. The extent to which the sp expresses in-
formation that is expr. in gp is measured on
a 4-point scale: (1) Everything is expressed,
</bodyText>
<listItem confidence="0.748359">
(2) Most things are expressed, (3) Some
things are expressed, and (4) Nothing is expr..
</listItem>
<bodyText confidence="0.6963702">
Syntactic correctness: the degree to which the
verb. is syntactically correct, in particu-
lar whether it adheres to English or German
grammar: (1) The verb. is completely synt.
correct. (2) The verb. is almost synt. correct.
</bodyText>
<listItem confidence="0.893546">
(3) The verb. presents some syntactical er-
rors. (4) The verb. is strongly synt. incorrect.
Understandability: Adapted from (Nagao et al.,
1985): (1) The meaning of the verb. is
clear. (2) The meaning of the verb. is clear,
but there are some problems in word usage,
</listItem>
<figureCaption confidence="0.614">
Figure 3: Histogram of the coverage cov(t, G)
and/or style. (3) The basic thrust of the verb.
is clear, but the evaluator is not sure of some
detailed parts because of word usage prob-
lems. (4) The verb. contains many word
usage problems, and the evaluator can only
guess at the meaning. (5) The verb. cannot
be understood at all.
</figureCaption>
<bodyText confidence="0.960580823529412">
We evaluated a random sample of 10 English
and 10 German templates using a group of 6 eval-
uators which are experts in the fields of RDF and
SPARQL and that are proficient in both English
and German. Each template was evaluated by 3
experts, each expert evaluated 10 templates. For
each template we retrieved a maximum of 100
subgraphs that matched the graph pattern, ran-
domly selected 10 subgraphs and verbalized them.
For each template an evaluator was asked to evalu-
ate accuracy given the graph pattern and given the
sentence pattern and, given the list of 10 verbal-
izations, to evaluate each sentence regarding syn-
tactic correctness and understandability.
cov(t, G) of all 5066 templates is shown in
Fig. 3. For example, it shows that there are about
300 templates where each template can be used
</bodyText>
<figure confidence="0.9926501">
350
300
250
200
150
100
50
0
#en
#de
</figure>
<page confidence="0.826161">
32
</page>
<figureCaption confidence="0.9739665">
Figure 4: Evaluation results regarding accuracy,
syntactical correctness, and understandability
</figureCaption>
<bodyText confidence="0.999287444444444">
to verbalize between 104 and 105 subgraphs of
G. Results regarding the remaining dimensions
are shown in Fig. 4. The values of the x-axes
correspond to the scale of the respective dimen-
sion. The majority of the triple patterns are either
explicitly or implicitly expressed in the sentence
pattern. However, some triple patterns are not ex-
pressed in the sentence pattern. Syntactical cor-
rectness and understandability are mostly high.
</bodyText>
<sectionHeader confidence="0.999986" genericHeader="method">
6 Related work
</sectionHeader>
<bodyText confidence="0.999745290909091">
(Welty et al., 2010) present a technique for reading
sentences and producing sets of hypothetical rela-
tions that the sentence may be expressing. Given
a parallel text-data corpus, entities identified as
proper nouns in parsed sentences are replaced with
variables. For each (pattern, set of relations) tu-
ple for each sentence that matches this pattern
it is counted in how many sentences that match
this pattern a certain relation exists between the
two entities identified in the sentence. This leads
to positive weights assigned to patterns. Nega-
tive weights are assigned by applying patterns to
sentences, identifying the entities and assigning a
negative weight to the relation if the relation ex-
pressed by the pattern is not expressed in the data.
In contrast to this approach, our approach 1)
does not require to parse input sentences 2) does
not only regard relations between proper nouns,
3) constrains candidate entities to the vicinity of
already identified entities. Moreover, 4) our ap-
proach takes into account the graph of entities
identified in a sentence (hypothesis graphs) com-
pared to sets of relations and can thus express mul-
tiple relations between entities.
(Duma and Klein, 2013) present an unsuper-
vised approach to NLG template extraction from a
parallel text-data corpus. Similar to our approach,
text and data are aligned by identifying labels of
entities in sentences. The search space is limited
by only allowing to match entities that are directly
linked to the entity a text is about. Sentences are
abstracted by replacing the entity with the name of
the property that links the entity with the entity the
text is about thus limiting the depth of the graph
to 1. Abstracted sentences are parsed and pruned
by removing constituents that could not be aligned
to the database and by removing constituents of
certain classes and then post-processed using man-
ually created rules.
(Gerber and Ngomo, 2011) present an approach
to learning natural language representations of
predicates from a parallel text-data corpus. For
each predicate where a tuple of entities is identi-
fied in a sentence, the predicate’s natural language
representation is the string between the two enti-
ties, e.g. ’s acquisition of for the predi-
cate subsidiary and the sentence Google’s ac-
quisition of Youtube comes as online video is really
starting to hit its stride. The main differences to
our approach are 1) that we do not focus on learn-
ing how a single predicate is expressed but rather
how a graph, consisting of multiple related enti-
ties, can be expressed in natural language and 2)
that a relation between two entities is not only ex-
pressed by the string between two entities.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999932083333333">
We have shown that verbalization templates can
be extracted from a parallel text-data corpus in a
distant-supervised manner – without the need for
pre-existing language resources such as parsers,
grammars or dictionaries – and that applying these
templates for NLG leads to promising results. The
main novelty is the application of frequent max-
imal subgraph pattern mining for the purpose of
analyzing commonalities in sets of hypotheses
graphs. Even though the approach is linguisti-
cally shallow, verbalizations are already syntacti-
cally mostly correct and understandable.
</bodyText>
<sectionHeader confidence="0.997862" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.892394">
The authors acknowledge the support of the Eu-
ropean Commission’s Seventh Framework Pro-
gramme FP7-ICT-2011-7 (XLike, Grant 288342).
</bodyText>
<figure confidence="0.9989694">
Accuracy (1) Accuracy (2)
20
200
15
150
100
10
50
5
0
0
(1) (2) (3) (4) (1) (2) (3) (4)
Syntactical Correctness Understandability
300 300
(1) (2) (3) (4) (1) (2) (3) (4) (5)
en de
en de
200
100
0
200
100
0
en de
en de
</figure>
<page confidence="0.995493">
33
</page>
<sectionHeader confidence="0.998101" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999947528301887">
Razvan Bunescu and Raymond Mooney. 2007. Learn-
ing to extract relations from the web using mini-
mal supervision. In Annual meeting-association for
Computational Linguistics, volume 45, pages 576–
583.
Andrew Carlson, Justin Betteridge, Estevam R Hr-
uschka Jr, and Tom M Mitchell. 2009. Coupling
semi-supervised learning of categories and relations.
In Proceedings of the NAACL HLT 2009 Workshop
on Semi-supervised Learning for Natural Language
Processing, pages 1–9. Association for Computa-
tional Linguistics.
P. Cimiano, P. Haase, J. Heizmann, M. Mantel, and
R. Studer. 2008. Towards portable natural lan-
guage interfaces to knowledge bases–The case of the
ORAKEL system. Data &amp; Knowledge Engineering,
65(2):325–354.
Mark Craven and Johan Kumlien. 1999. Constructing
biological knowledge bases by extracting informa-
tion from text sources. In Thomas Lengauer, Rein-
hard Schneider, Peer Bork, Douglas L. Brutlag, Jan-
ice I. Glasgow, Hans-Werner Mewes, and Ralf Zim-
mer, editors, ISMB, pages 77–86. AAAI.
D. Damljanovic, M. Agatonovic, and H. Cunningham.
2012. FREyA: An interactive way of querying
Linked Data using natural language. In The Seman-
tic Web: ESWC 2011 Workshops, pages 125–138.
Springer.
Daniel Duma and Ewan Klein, 2013. Generating Natu-
ral Language from Linked Data: Unsupervised tem-
plate extraction, pages 83–94. Association for Com-
putational Linguistics, Potsdam, Germany.
Daniel Gerber and A-C Ngonga Ngomo. 2011. Boot-
strapping the linked data web. In 1st Workshop on
Web Scale Knowledge Extraction @ International
Semantic Web Conference, volume 2011.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies-
Volume 1, pages 541–550. Association for Compu-
tational Linguistics.
J. Hunter and S. Odat. 2011. Building a Semantic
Knowledge-base for Painting Conservators. In E-
Science (e-Science), pages 173–180. IEEE.
E. Kaufmann, A. Bernstein, and R. Zumstein. 2006.
Querix: A natural language interface to query on-
tologies based on clarification dialogs. In Inter-
national Semantic Web Conference (ISWC 2006),
pages 980–981.
Yuangui Lei, Victoria Uren, and Enrico Motta. 2006.
SemSearch: A Search Engine for the Semantic Web.
pages 238–245. Springer.
J.C. Lester and B.W. Porter. 1997. Developing and
empirically evaluating robust explanation genera-
tors: The KNIGHT experiments. Comp. Linguistics,
23(1):65–101.
C. Mellish and R. Dale. 1998. Evaluation in the conext
of natural language generation. Computer Speech
and language, 12(4):349–374.
P.N. Mendes, B. McKnight, A.P. Sheth, and J.C.
Kissinger. 2008. TcruziKB: Enabling Complex
Queries for Genomic Data Exploration. In Semantic
Computing, 2008, pages 432–439.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natu-
ral Language Processing of the AFNLP: Volume 2 -
ACL-IJCNLP 09, pages 1003–1011.
Makoto Nagao, Jun-ichi Tsujii, and Jun-ichi Naka-
mura. 1985. The Japanese government project
for machine translation. Computational Linguistics,
11(2-3):91–110.
E. Reiter and A. Belz. 2009. An investigation into the
validity of some metrics for automatically evaluat-
ing natural language generation systems. Computa-
tional Linguistics, 35(4):529–558.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 455–
465. Association for Computational Linguistics.
E. Thomas, J.Z. Pan, and D. Sleeman. 2007. ON-
TOSEARCH2: Searching ontologies semantically.
In Proceedings of the OWLED 2007 Workshop on
OWL: Experiences and Directions, pages 70–72.
H. Wang, T. Tran, P. Haase, T. Penin, Q. Liu, L. Fu, and
Y. Yu. 2008. SearchWebDB: Searching the Billion
Triples. In Billion Triple Challenge at the Interna-
tional Semantic Web Conference (ISWC 2008).
Chris Welty, James Fan, David Gondek, and Andrew
Schlaikjer. 2010. Large scale relation detection.
In Proceedings of the NAACL HLT 2010 First Inter-
national Workshop on Formalisms and Methodology
for Learning by Reading, pages 24–33. Association
for Computational Linguistics.
M. Wendt, M. Gerlach, and H. D¨uwiger. 2012. Lin-
guistic Modeling of Linked Open Data for Ques-
tion Answering. Interacting with Linked Data (ILD
2012), pages 75–86.
</reference>
<page confidence="0.999322">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429854">
<title confidence="0.9951755">A language-independent method for the extraction of RDF verbalization templates</title>
<author confidence="0.993636">Basil</author>
<affiliation confidence="0.999989">Karlsruhe Institute of Technology</affiliation>
<address confidence="0.742885">Karlsruhe,</address>
<email confidence="0.999903">basil.ell@kit.edu</email>
<author confidence="0.894191">Andreas</author>
<affiliation confidence="0.999959">Karlsruhe Institute of Technology</affiliation>
<address confidence="0.712312">Karlsruhe,</address>
<email confidence="0.999925">harth@kit.edu</email>
<abstract confidence="0.9960354">With the rise of the Semantic Web more and more data become available encoded using the Semantic Web standard RDF. RDF is faced towards machines: designed to be easily processable by machines it is difficult to be understood by casual users. Transforming RDF data into human-comprehensible text would facilitate non-experts to assess this information. In this paper we present a languageindependent method for extracting RDF verbalization templates from a parallel corpus of text and data. Our method is based on distant-supervised simultaneous multi-relation learning and frequent maximal subgraph pattern mining. We demonstrate the feasibility of our method on a parallel corpus of Wikipedia articles and DBpedia data for English and German.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>Learning to extract relations from the web using minimal supervision.</title>
<date>2007</date>
<booktitle>In Annual meeting-association for Computational Linguistics,</booktitle>
<volume>45</volume>
<pages>576--583</pages>
<contexts>
<context position="2501" citStr="Bunescu and Mooney, 2007" startWordPosition="402" endWordPosition="405">mplates. Templates consist of a graph pattern that can be applied to query the graph and of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in</context>
</contexts>
<marker>Bunescu, Mooney, 2007</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2007. Learning to extract relations from the web using minimal supervision. In Annual meeting-association for Computational Linguistics, volume 45, pages 576– 583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Coupling semi-supervised learning of categories and relations.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2523" citStr="Carlson et al., 2009" startWordPosition="406" endWordPosition="409"> of a graph pattern that can be applied to query the graph and of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) </context>
</contexts>
<marker>Carlson, Betteridge, Jr, Mitchell, 2009</marker>
<rawString>Andrew Carlson, Justin Betteridge, Estevam R Hruschka Jr, and Tom M Mitchell. 2009. Coupling semi-supervised learning of categories and relations. In Proceedings of the NAACL HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing, pages 1–9. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>P Haase</author>
<author>J Heizmann</author>
<author>M Mantel</author>
<author>R Studer</author>
</authors>
<title>Towards portable natural language interfaces to knowledge bases–The case of the ORAKEL system.</title>
<date>2008</date>
<journal>Data &amp; Knowledge Engineering,</journal>
<volume>65</volume>
<issue>2</issue>
<contexts>
<context position="3434" citStr="Cimiano et al., 2008" startWordPosition="553" endWordPosition="556">arlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pattern GP can be transformed into a SPARQL query QGP. A result of querying the data graph is the RDF g</context>
</contexts>
<marker>Cimiano, Haase, Heizmann, Mantel, Studer, 2008</marker>
<rawString>P. Cimiano, P. Haase, J. Heizmann, M. Mantel, and R. Studer. 2008. Towards portable natural language interfaces to knowledge bases–The case of the ORAKEL system. Data &amp; Knowledge Engineering, 65(2):325–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<pages>77--86</pages>
<editor>In Thomas Lengauer, Reinhard Schneider, Peer Bork, Douglas L. Brutlag, Janice I. Glasgow, Hans-Werner Mewes, and Ralf Zimmer, editors, ISMB,</editor>
<publisher>AAAI.</publisher>
<contexts>
<context position="2475" citStr="Craven and Kumlien, 1999" startWordPosition="398" endWordPosition="401">n G. Output is a set of templates. Templates consist of a graph pattern that can be applied to query the graph and of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these </context>
</contexts>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven and Johan Kumlien. 1999. Constructing biological knowledge bases by extracting information from text sources. In Thomas Lengauer, Reinhard Schneider, Peer Bork, Douglas L. Brutlag, Janice I. Glasgow, Hans-Werner Mewes, and Ralf Zimmer, editors, ISMB, pages 77–86. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Damljanovic</author>
<author>M Agatonovic</author>
<author>H Cunningham</author>
</authors>
<title>FREyA: An interactive way of querying Linked Data using natural language.</title>
<date>2012</date>
<booktitle>In The Semantic Web: ESWC 2011 Workshops,</booktitle>
<pages>125--138</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3481" citStr="Damljanovic et al., 2012" startWordPosition="561" endWordPosition="564">nt and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pattern GP can be transformed into a SPARQL query QGP. A result of querying the data graph is the RDF graph GGP with the list of solution mappings µ. </context>
</contexts>
<marker>Damljanovic, Agatonovic, Cunningham, 2012</marker>
<rawString>D. Damljanovic, M. Agatonovic, and H. Cunningham. 2012. FREyA: An interactive way of querying Linked Data using natural language. In The Semantic Web: ESWC 2011 Workshops, pages 125–138. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Duma</author>
<author>Ewan Klein</author>
</authors>
<title>Generating Natural Language from Linked Data: Unsupervised template extraction,</title>
<date>2013</date>
<booktitle>Association for Computational Linguistics,</booktitle>
<pages>83--94</pages>
<location>Potsdam, Germany.</location>
<contexts>
<context position="30563" citStr="Duma and Klein, 2013" startWordPosition="5302" endWordPosition="5305">plying patterns to sentences, identifying the entities and assigning a negative weight to the relation if the relation expressed by the pattern is not expressed in the data. In contrast to this approach, our approach 1) does not require to parse input sentences 2) does not only regard relations between proper nouns, 3) constrains candidate entities to the vicinity of already identified entities. Moreover, 4) our approach takes into account the graph of entities identified in a sentence (hypothesis graphs) compared to sets of relations and can thus express multiple relations between entities. (Duma and Klein, 2013) present an unsupervised approach to NLG template extraction from a parallel text-data corpus. Similar to our approach, text and data are aligned by identifying labels of entities in sentences. The search space is limited by only allowing to match entities that are directly linked to the entity a text is about. Sentences are abstracted by replacing the entity with the name of the property that links the entity with the entity the text is about thus limiting the depth of the graph to 1. Abstracted sentences are parsed and pruned by removing constituents that could not be aligned to the database</context>
</contexts>
<marker>Duma, Klein, 2013</marker>
<rawString>Daniel Duma and Ewan Klein, 2013. Generating Natural Language from Linked Data: Unsupervised template extraction, pages 83–94. Association for Computational Linguistics, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gerber</author>
<author>A-C Ngonga Ngomo</author>
</authors>
<title>Bootstrapping the linked data web.</title>
<date>2011</date>
<booktitle>In 1st Workshop on Web Scale Knowledge Extraction @ International Semantic Web Conference,</booktitle>
<volume>volume</volume>
<contexts>
<context position="31290" citStr="Gerber and Ngomo, 2011" startWordPosition="5423" endWordPosition="5426">o our approach, text and data are aligned by identifying labels of entities in sentences. The search space is limited by only allowing to match entities that are directly linked to the entity a text is about. Sentences are abstracted by replacing the entity with the name of the property that links the entity with the entity the text is about thus limiting the depth of the graph to 1. Abstracted sentences are parsed and pruned by removing constituents that could not be aligned to the database and by removing constituents of certain classes and then post-processed using manually created rules. (Gerber and Ngomo, 2011) present an approach to learning natural language representations of predicates from a parallel text-data corpus. For each predicate where a tuple of entities is identified in a sentence, the predicate’s natural language representation is the string between the two entities, e.g. ’s acquisition of for the predicate subsidiary and the sentence Google’s acquisition of Youtube comes as online video is really starting to hit its stride. The main differences to our approach are 1) that we do not focus on learning how a single predicate is expressed but rather how a graph, consisting of multiple rel</context>
</contexts>
<marker>Gerber, Ngomo, 2011</marker>
<rawString>Daniel Gerber and A-C Ngonga Ngomo. 2011. Bootstrapping the linked data web. In 1st Workshop on Web Scale Knowledge Extraction @ International Semantic Web Conference, volume 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1,</booktitle>
<pages>541--550</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2586" citStr="Hoffmann et al., 2011" startWordPosition="418" endWordPosition="421"> of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usual</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1, pages 541–550. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hunter</author>
<author>S Odat</author>
</authors>
<title>Building a Semantic Knowledge-base for Painting Conservators. In EScience (e-Science),</title>
<date>2011</date>
<pages>173--180</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="3514" citStr="Hunter and Odat, 2011" startWordPosition="567" endWordPosition="570">ern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pattern GP can be transformed into a SPARQL query QGP. A result of querying the data graph is the RDF graph GGP with the list of solution mappings µ. This graph can be verbalized as a</context>
</contexts>
<marker>Hunter, Odat, 2011</marker>
<rawString>J. Hunter and S. Odat. 2011. Building a Semantic Knowledge-base for Painting Conservators. In EScience (e-Science), pages 173–180. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kaufmann</author>
<author>A Bernstein</author>
<author>R Zumstein</author>
</authors>
<title>Querix: A natural language interface to query ontologies based on clarification dialogs.</title>
<date>2006</date>
<booktitle>In International Semantic Web Conference (ISWC</booktitle>
<pages>980--981</pages>
<contexts>
<context position="3412" citStr="Kaufmann et al., 2006" startWordPosition="549" endWordPosition="552">ti-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pattern GP can be transformed into a SPARQL query QGP. A result of querying the d</context>
</contexts>
<marker>Kaufmann, Bernstein, Zumstein, 2006</marker>
<rawString>E. Kaufmann, A. Bernstein, and R. Zumstein. 2006. Querix: A natural language interface to query ontologies based on clarification dialogs. In International Semantic Web Conference (ISWC 2006), pages 980–981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuangui Lei</author>
<author>Victoria Uren</author>
<author>Enrico Motta</author>
</authors>
<title>SemSearch: A Search Engine for the Semantic Web.</title>
<date>2006</date>
<pages>238--245</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3293" citStr="Lei et al., 2006" startWordPosition="529" endWordPosition="532"> by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP</context>
</contexts>
<marker>Lei, Uren, Motta, 2006</marker>
<rawString>Yuangui Lei, Victoria Uren, and Enrico Motta. 2006. SemSearch: A Search Engine for the Semantic Web. pages 238–245. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Lester</author>
<author>B W Porter</author>
</authors>
<title>Developing and empirically evaluating robust explanation generators: The KNIGHT experiments.</title>
<date>1997</date>
<journal>Comp. Linguistics,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="26379" citStr="Lester and Porter, 1997" startWordPosition="4592" endWordPosition="4595">fiers and their number of applications 10000 1000 100 10 1 en-groups de-groups 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79 80-84 85-89 90-94 95-99 100-104 105-109 110-114 115-119 120-124 125-129 130-134 135-139 140-144 145-149 150-154 155-159 160-164 Figure 2: Histogram depicting how often sentence groups occurred with a particular size 5 Evaluation We evaluate the results from the experiment described in the previous section along the dimensions coverage, accuracy, syntactic correctness, and understandability where the latter three are inspired by (Lester and Porter, 1997; Mellish and Dale, 1998; Reiter and Belz, 2009). Coverage: we define cov(t, G) of a template t=(sp, gp) regarding a data graph G as the number of subgraphs of G that can be verbalized with that template i.e. match gp. Accuracy: is measured in two parts: 1. The extent to which everything that is expressed in gp is also expressed in sp is measured for each triple pattern within the graph pattern on a 4-point scale: (1) The triple pattern is explicitly expressed, (2) The triple pattern is implied, (3) The triple pattern is not expressed, and (4) Unsure. 2. The extent to which the sp expresses in</context>
</contexts>
<marker>Lester, Porter, 1997</marker>
<rawString>J.C. Lester and B.W. Porter. 1997. Developing and empirically evaluating robust explanation generators: The KNIGHT experiments. Comp. Linguistics, 23(1):65–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Mellish</author>
<author>R Dale</author>
</authors>
<title>Evaluation in the conext of natural language generation. Computer Speech and language,</title>
<date>1998</date>
<pages>12--4</pages>
<contexts>
<context position="26403" citStr="Mellish and Dale, 1998" startWordPosition="4596" endWordPosition="4599"> applications 10000 1000 100 10 1 en-groups de-groups 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79 80-84 85-89 90-94 95-99 100-104 105-109 110-114 115-119 120-124 125-129 130-134 135-139 140-144 145-149 150-154 155-159 160-164 Figure 2: Histogram depicting how often sentence groups occurred with a particular size 5 Evaluation We evaluate the results from the experiment described in the previous section along the dimensions coverage, accuracy, syntactic correctness, and understandability where the latter three are inspired by (Lester and Porter, 1997; Mellish and Dale, 1998; Reiter and Belz, 2009). Coverage: we define cov(t, G) of a template t=(sp, gp) regarding a data graph G as the number of subgraphs of G that can be verbalized with that template i.e. match gp. Accuracy: is measured in two parts: 1. The extent to which everything that is expressed in gp is also expressed in sp is measured for each triple pattern within the graph pattern on a 4-point scale: (1) The triple pattern is explicitly expressed, (2) The triple pattern is implied, (3) The triple pattern is not expressed, and (4) Unsure. 2. The extent to which the sp expresses information that is expr. </context>
</contexts>
<marker>Mellish, Dale, 1998</marker>
<rawString>C. Mellish and R. Dale. 1998. Evaluation in the conext of natural language generation. Computer Speech and language, 12(4):349–374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P N Mendes</author>
<author>B McKnight</author>
<author>A P Sheth</author>
<author>J C Kissinger</author>
</authors>
<title>TcruziKB: Enabling Complex Queries for Genomic Data Exploration.</title>
<date>2008</date>
<booktitle>In Semantic Computing,</booktitle>
<pages>432--439</pages>
<marker>Mendes, McKnight, Sheth, Kissinger, 2008</marker>
<rawString>P.N. Mendes, B. McKnight, A.P. Sheth, and J.C. Kissinger. 2008. TcruziKB: Enabling Complex Queries for Genomic Data Exploration. In Semantic Computing, 2008, pages 432–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<contexts>
<context position="2543" citStr="Mintz et al., 2009" startWordPosition="410" endWordPosition="413">at can be applied to query the graph and of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces </context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 -ACL-IJCNLP 09, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Nagao</author>
<author>Jun-ichi Tsujii</author>
<author>Jun-ichi Nakamura</author>
</authors>
<title>The Japanese government project for machine translation.</title>
<date>1985</date>
<journal>Computational Linguistics,</journal>
<pages>11--2</pages>
<contexts>
<context position="27525" citStr="Nagao et al., 1985" startWordPosition="4794" endWordPosition="4797">not expressed, and (4) Unsure. 2. The extent to which the sp expresses information that is expr. in gp is measured on a 4-point scale: (1) Everything is expressed, (2) Most things are expressed, (3) Some things are expressed, and (4) Nothing is expr.. Syntactic correctness: the degree to which the verb. is syntactically correct, in particular whether it adheres to English or German grammar: (1) The verb. is completely synt. correct. (2) The verb. is almost synt. correct. (3) The verb. presents some syntactical errors. (4) The verb. is strongly synt. incorrect. Understandability: Adapted from (Nagao et al., 1985): (1) The meaning of the verb. is clear. (2) The meaning of the verb. is clear, but there are some problems in word usage, Figure 3: Histogram of the coverage cov(t, G) and/or style. (3) The basic thrust of the verb. is clear, but the evaluator is not sure of some detailed parts because of word usage problems. (4) The verb. contains many word usage problems, and the evaluator can only guess at the meaning. (5) The verb. cannot be understood at all. We evaluated a random sample of 10 English and 10 German templates using a group of 6 evaluators which are experts in the fields of RDF and SPARQL </context>
</contexts>
<marker>Nagao, Tsujii, Nakamura, 1985</marker>
<rawString>Makoto Nagao, Jun-ichi Tsujii, and Jun-ichi Nakamura. 1985. The Japanese government project for machine translation. Computational Linguistics, 11(2-3):91–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>A Belz</author>
</authors>
<title>An investigation into the validity of some metrics for automatically evaluating natural language generation systems.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>4</issue>
<contexts>
<context position="26427" citStr="Reiter and Belz, 2009" startWordPosition="4600" endWordPosition="4603"> 100 10 1 en-groups de-groups 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74 75-79 80-84 85-89 90-94 95-99 100-104 105-109 110-114 115-119 120-124 125-129 130-134 135-139 140-144 145-149 150-154 155-159 160-164 Figure 2: Histogram depicting how often sentence groups occurred with a particular size 5 Evaluation We evaluate the results from the experiment described in the previous section along the dimensions coverage, accuracy, syntactic correctness, and understandability where the latter three are inspired by (Lester and Porter, 1997; Mellish and Dale, 1998; Reiter and Belz, 2009). Coverage: we define cov(t, G) of a template t=(sp, gp) regarding a data graph G as the number of subgraphs of G that can be verbalized with that template i.e. match gp. Accuracy: is measured in two parts: 1. The extent to which everything that is expressed in gp is also expressed in sp is measured for each triple pattern within the graph pattern on a 4-point scale: (1) The triple pattern is explicitly expressed, (2) The triple pattern is implied, (3) The triple pattern is not expressed, and (4) Unsure. 2. The extent to which the sp expresses information that is expr. in gp is measured on a 4</context>
</contexts>
<marker>Reiter, Belz, 2009</marker>
<rawString>E. Reiter and A. Belz. 2009. An investigation into the validity of some metrics for automatically evaluating natural language generation systems. Computational Linguistics, 35(4):529–558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>455--465</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2610" citStr="Surdeanu et al., 2012" startWordPosition="422" endWordPosition="425">that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writin</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455– 465. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Thomas</author>
<author>J Z Pan</author>
<author>D Sleeman</author>
</authors>
<title>ONTOSEARCH2: Searching ontologies semantically.</title>
<date>2007</date>
<booktitle>In Proceedings of the OWLED 2007 Workshop on OWL: Experiences and Directions,</booktitle>
<pages>70--72</pages>
<contexts>
<context position="3314" citStr="Thomas et al., 2007" startWordPosition="533" endWordPosition="536">abase of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence patte</context>
</contexts>
<marker>Thomas, Pan, Sleeman, 2007</marker>
<rawString>E. Thomas, J.Z. Pan, and D. Sleeman. 2007. ONTOSEARCH2: Searching ontologies semantically. In Proceedings of the OWLED 2007 Workshop on OWL: Experiences and Directions, pages 70–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Wang</author>
<author>T Tran</author>
<author>P Haase</author>
<author>T Penin</author>
<author>Q Liu</author>
<author>L Fu</author>
<author>Y Yu</author>
</authors>
<title>SearchWebDB: Searching the Billion Triples.</title>
<date>2008</date>
<booktitle>In Billion Triple Challenge at the International Semantic Web Conference (ISWC</booktitle>
<contexts>
<context position="3334" citStr="Wang et al., 2008" startWordPosition="537" endWordPosition="540">ext; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic databases, casual users - usually not capable of writing formal queries – specify their information needs using keywords (Lei et al., 2006; Thomas et al., 2007; Wang et al., 2008), questions in free-text or using a controlled language (Kaufmann et al., 2006; Cimiano et al., 2008; Wendt et al., 2012; Damljanovic et al., 2012), or forms (Hunter and Odat, 2011; Mendes 1Further examples and the evaluation material can be found on our website at http://km.aifb.kit.edu/ sites/bridge-patterns/INLG2014 26 Proceedings of the 8th International Natural Language Generation Conference, pages 26–34, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics Figure 1: A template consists of a graph pattern GP and a sentence pattern SP. The graph pat</context>
</contexts>
<marker>Wang, Tran, Haase, Penin, Liu, Fu, Yu, 2008</marker>
<rawString>H. Wang, T. Tran, P. Haase, T. Penin, Q. Liu, L. Fu, and Y. Yu. 2008. SearchWebDB: Searching the Billion Triples. In Billion Triple Challenge at the International Semantic Web Conference (ISWC 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Welty</author>
<author>James Fan</author>
<author>David Gondek</author>
<author>Andrew Schlaikjer</author>
</authors>
<title>Large scale relation detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading,</booktitle>
<pages>24--33</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2563" citStr="Welty et al., 2010" startWordPosition="414" endWordPosition="417"> query the graph and of a sentence pattern that is a slotted sentence into which parts of the query result are inserted. A template enables verbalization of a subgraph of G as a complete sentence. An example is shown in Fig. 1.1 The graph pattern GP can be transformed into a SPARQL query QGP. Querying the data graph G results in the graph GGP. GGP can be verbalized as an English (German) sentence Sen (Sde) using the sentence pattern SPen (SPde). The approach employs the distant supervision principle (Craven and Kumlien, 1999; Bunescu and Mooney, 2007; Carlson et al., 2009; Mintz et al., 2009; Welty et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) from relation extraction: training data is generated automatically by aligning a database of facts with text; therefore, no hand-labeled data is required. We apply simultaneous multi-relation learning (Carlson et al., 2009) for text-data alignment and frequent maximal subgraph pattern mining to observe commonalities among RDF graph patterns. Besides the general idea to allow for nonexperts to assess information encoded in RDF, we envision application of these verbalization templates in three scenarios: (1) In query interfaces to semantic database</context>
<context position="29383" citStr="Welty et al., 2010" startWordPosition="5113" endWordPosition="5116">e can be used 350 300 250 200 150 100 50 0 #en #de 32 Figure 4: Evaluation results regarding accuracy, syntactical correctness, and understandability to verbalize between 104 and 105 subgraphs of G. Results regarding the remaining dimensions are shown in Fig. 4. The values of the x-axes correspond to the scale of the respective dimension. The majority of the triple patterns are either explicitly or implicitly expressed in the sentence pattern. However, some triple patterns are not expressed in the sentence pattern. Syntactical correctness and understandability are mostly high. 6 Related work (Welty et al., 2010) present a technique for reading sentences and producing sets of hypothetical relations that the sentence may be expressing. Given a parallel text-data corpus, entities identified as proper nouns in parsed sentences are replaced with variables. For each (pattern, set of relations) tuple for each sentence that matches this pattern it is counted in how many sentences that match this pattern a certain relation exists between the two entities identified in the sentence. This leads to positive weights assigned to patterns. Negative weights are assigned by applying patterns to sentences, identifying</context>
</contexts>
<marker>Welty, Fan, Gondek, Schlaikjer, 2010</marker>
<rawString>Chris Welty, James Fan, David Gondek, and Andrew Schlaikjer. 2010. Large scale relation detection. In Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading, pages 24–33. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wendt</author>
<author>M Gerlach</author>
<author>H D¨uwiger</author>
</authors>
<title>Linguistic Modeling of Linked Open Data for Question Answering. Interacting with Linked Data (ILD</title>
<date>2012</date>
<pages>75--86</pages>
<marker>Wendt, Gerlach, D¨uwiger, 2012</marker>
<rawString>M. Wendt, M. Gerlach, and H. D¨uwiger. 2012. Linguistic Modeling of Linked Open Data for Question Answering. Interacting with Linked Data (ILD 2012), pages 75–86.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>