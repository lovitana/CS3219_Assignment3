<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004792">
<title confidence="0.99953">
A Comparative Study of Different Classification Methods for the
Identification of Brazilian Portuguese Multiword Expressions
</title>
<author confidence="0.434841">
Alexsandro Fonseca Fatiha Sadat
</author>
<address confidence="0.9061225">
Universit6 du Québec ˆ Montréal, 201 av. President Kennedy,
Montreal, QC, H2X 3Y7, Canada
</address>
<email confidence="0.998688">
affonseca@gmail.com sadat.fatiha@uqam.ca
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995821">
This paper presents a comparative study of different methods for the identification of multiword
expressions, applied to a Brazilian Portuguese corpus. First, we selected the candidates based on the
frequency of bigrams. Second, we used the linguistic information based on the grammatical classes of
the words forming the bigrams, together with the frequency information in order to compare the
performance of different classification algorithms. The focus of this study is related to different
classification techniques such as support-vector machines (SVM), multi-layer perceptron, naïve
Bayesian nets, decision trees and random forest. Third, we evaluated three different multi-layer
perceptron training functions in the task of classifying different patterns of multiword expressions.
Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of
multiword expression candidates using different association measures.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.974069961538461">
The identification of multiword expressions (MWEs) and their appropriate handling is necessary in
constructing professional tools for language manipulation (Hurskainen, 2008). MWEs are considered
as a very challenging problem for various natural language processing (NLP) applications, such as
machine translation.
There are several definitions of MWE in the scientific literature. Smadja (1993) defines MWE as
an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and
semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously
from the meaning or connotation of its components. Moreover, Sag et al. (2002) defines MWE as an
idiosyncratic interpretation that exceeds the limit of the word (or spaces).
We adopt in this paper a definition similar to the one given by Sag et al. (2002): a MWE is an
expression formed by two or more words, whose meaning can vary from totally dependent to
completely independent of the meaning of its constituent words. Examples of MWEs: “take care”,
“Bill Gates”, “coffee break” and “by the way”.
This study treats only two-word MWEs. We are not considering some common Portuguese MWEs,
such as “tempo de espera” (waiting time, lit.: time of waiting), “dar um tempo” (to have a break, lit.: to
give a time) or “comegar tudo de novo” (restart, lit. start everything of new). However, our experience
and some related work show that we are already covering the majority of MWEs. For their data, for
example, Piao et al. (2003, Section 5) found that 81.88% of the recognized MWEs were bigrams.
Moreover, our focus is in MWE formed by nouns, adjectives, verbs and adverbs. As a consequence,
two-word MWEs formed by prepositions were not considered, such as “de novo” (again, lit. of new),
“ˆ toa” (for nothing), “apesar de” (despite of) or “desde ontem” (since yesterday). In resume, we
evaluated the performance of different classification algorithms and tools for the recognition of two-
word MWEs formed by nouns, adjectives, verbs and adverbs. We intend, in the future, to extend this
study to MWEs formed by words belonging to any grammatical class and having any number of words.
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.977888">
53
</page>
<note confidence="0.985293">
Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62,
Dublin, Ireland, August 24 2014.
</note>
<bodyText confidence="0.999844818181818">
The correct identification of MWEs is important for different NLP applications, such as machine
translation, information retrieval and the semantic web, to which the principle of syntactic or semantic
unit is important (Watrin and Frangois, 2011).
Methods for identifying MWEs rely on statistical measures, especially association measures, such
as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996).
The basic idea behind such measures can be summarized as follows: the higher the association
among the words that appear together in a text, the higher the probability that they constitute a single
semantic unit.
There are other methods, which use linguistic information or hybrid approaches that combine
statistical measures with the linguistic information, such as the grammatical class of each word, the
sense of the composite expression or the syntactic regularities.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999419375">
Dias and Lopes (2005) present a method for the extraction of MWEs based only on statistics with an
application on the Portuguese language. This method consists of a new association measure called
“mutual expectation”. Their method can be applied to extract MWEs formed by two or more words,
contiguous or not. The mutual expectation method is based on the LocalMaxs (Silva and Lopes, 1999)
algorithm. This algorithm deduces that a n-gram is a MWE if the degree of attraction between its
words is greater or equal to the degree of attraction of all its subsets of n-1 words (i.e. all groups of n-1
words contained by the n-gram) and if it is strictly greater than the degree of attraction of all of its
super groups of n+1 words (i.e. all groups of n+1 words containing the n-gram). When the n-gram is a
bigram (n = 2), only the degree of attraction of its super groups of n+1 words is calculated.
Ramisch et al. (2008) analyze the extraction of MWEs based only on statistical information,
comparing three association measures: the mutual information, chi-squared and permutation entropy.
Then they introduce a method called entropy of permutation and insertion (a hybrid approach), that
takes into account linguistic information of the MWE type. Following some patterns, they modify each
original MWE candidate by inserting some types of words in some positions and they test if the new
MWE are still MWE and they try to identify which kind of modification an MWE type accepts or
refuses in a particular language. The new measure is calculated using a formula that combines the
probability of occurrence of the original and of the generated MWE.
Agarwal et al. (2004) present an approach for extracting MWEs in languages with few resources
based on a morphological analyser and a moderate size untagged text corpus. First, they divide the
MWEs in categories. For example, Category-2 is formed by noun-noun, adjective-noun and verb-verb
bigrams. Then they apply a set of rules to identify or eliminate candidates as MWE. Those rules take
into consideration the precedent and/or the next word in the pair and the possible inflections of the
words. After this step, association measures are computed.
Piao et al. (2003) use, what they call, a semantic field annotator. They use a semantic tagger for the
English language called USAS, developed in Lancaster University. This tagger labels words and
expressions in a text using 21 categories. For example, Category-A is used for “general and abstract
terms”, Category-B is used for “the body and the individual”, Category-E is used for “emotion”, etc. A
text labeled with those categories is used to extract the MWE candidates. The differential of this
approach is that the candidates are selected not based only on statistical measures. The problem with
this is that most of the MWEs, about 68% in the work of Piao et al., appear in the text with a low
frequency. As a consequence, most of the methods for extracting MWEs give good precision, but low
recall.
</bodyText>
<sectionHeader confidence="0.986295" genericHeader="method">
3 The Data
</sectionHeader>
<bodyText confidence="0.999862285714286">
The current study used the corpus CETENFolha (Corpus de Extractos de Textos Eletr—nicos
NILC/Folha de S‹o Paulo), available on the website Linguateca Portuguesa (CETENFolha, 2008).
This corpus is composed by excerpts from Brazilian newspaper &amp;quot;Folha de S‹o Paulo&amp;quot;, and contains
over 24 million words. It is part of a project on the automatic processing of the Portuguese (Kinoshita
et al., 2006). As the current stage, we used a small fraction of the corpus, composed by 3,409 excerpts
of text (about 250,000 words). Each excerpt corresponds to individual news, which covers different
areas.
</bodyText>
<page confidence="0.998826">
54
</page>
<sectionHeader confidence="0.91943" genericHeader="method">
4 Comparison of different classification algorithms
</sectionHeader>
<subsectionHeader confidence="0.999867">
4.1 Pre-processing the data
</subsectionHeader>
<bodyText confidence="0.999976965517241">
Before the indexation, some pre-processing methods on the corpus were completed, such as
lemmatization and elimination of stop words (articles, prepositions, conjunctions). In this study, we
are mostly interested in analyzing MWEs formed by nouns, adjectives, adverbs and verbs. And since
those stop words are very common in Portuguese, their elimination reduces considerably the number
of MWE candidates that would not be relevant to this study.
We created two indexes: one formed only of bigrams and the other only by unigrams. Our results
show 49,589 bigrams, with 1,170 having a frequency higher than 3. We selected those 1,170 bigrams
as our MWE candidates. By hand, from the 1,170 candidates, we recognized 447 as being Portuguese
MWEs.
The main criterion used to consider a bigram as a MWE was that the bigram had a sense on its own.
For example: proper names, like “Adelson Barbosa”, “George Bush” and “Belo Horizonte”; support
verb constructions: “tomar cuidado” (to take care), “fazer sentido” (to make sense); expressions
having some idiomatic sense: “abrir m‹o” (to give up, lit. to open hand), “fazer quest‹o” (to insist, to
require [that something be done in a specific way], lit. to make question); fixed expressions: “bens
dur‡veis” (durable goods), “senso comum” (common sense), “curto prazo” (short term). Example of
bigrams not considered as MWE: “Brasil foi” (Brazil was), “apenas dois” (only two), “bomba matou”
(bomb killed), etc.
For each bigram, we found the frequency of its constituent words in the unigram index. Then, we
classified by hand each of the words by their grammatical class: 1 for nouns, 2 for adjectives, 3 for
verbs, 4 for other classes (mostly adverbs and pronouns) and 5 for proper names. This gave us 25
patterns of bigrams: N-N, N-ADJ, N-V, V-N, PN-PN, etc. We decided not to use a POS-tagger, to
ensure that each word would have its grammatical class assigned correctly, creating the most correct
possible training and testing data sets for the classification algorithms.
We then created a matrix of 1,170 lines and five columns. For each line, the first column represents
the frequency of a bigram in the excerpt of text, the second column represents the frequency of the
first bigram’s word, the third column represents the frequency of the second bigram’s word, the fourth
column represents the grammatical class of the first bigram’s word and the fifth column represents the
grammatical class of the second bigram’s word. This matrix was used to evaluate the precision and
recall of different classification algorithms.
</bodyText>
<subsectionHeader confidence="0.96112">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.9833695">
We applied nine different classification algorithms to our data set. The parameters used with each
algorithm are listed below.
Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25.
Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1.
Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100;
iterations = 10; seed = 1.
Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance =
0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of
execution slots = 1; iterations = 10.
KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search
(distance function = Euclidian distance).
SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kernel
type = radial basis function; nu = 0.5; seed = 1.
Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validation
threshold = 500; seed = 0;
Bayesian net: search algorithm = k2 (Cooper and Herskovits, 1992); estimator = simple estimator
(alpha = 0.5).
As we can see in Table 1, the values of precision are very similar for all the algorithms, varying
between 0.830 (random forest) and 0.857 (bagging), with the exception of SVM, which gave a
precision of 0.738. The recall values were between 0.831 and 0.857 (0.655 for SVM).
</bodyText>
<page confidence="0.991712">
55
</page>
<bodyText confidence="0.999821">
We obtained good precision and recall. However, we must consider that the values of recall are
based only on the MWEs present in our reference list, and not in the entire corpus, since we could not
count all the MWEs present in the corpus.
</bodyText>
<table confidence="0.9994666">
Algorithm TP Rate FP Rate Precision Recall
Decision tree 0.853 0.158 0.854 0.853
Random forest 0.831 0.194 0.830 0.831
Ada boost 0.837 0.196 0.836 0.837
Bagging 0.857 0.163 0.857 0.857
KNN – k = 3 0.846 0.171 0.846 0.846
SVM 0.655 0.553 0.738 0.655
M. perceptron 0.852 0.174 0.851 0.852
Naïve B. net 0.836 0.170 0.839 0.836
Bayesian net 0.842 0.170 0.843 0.842
</table>
<tableCaption confidence="0.99992">
Table 1: True-positive rate, false-positive rate, precision and recall for nine classification algorithms.
</tableCaption>
<sectionHeader confidence="0.916619" genericHeader="method">
5 Bigrams patterns classification
</sectionHeader>
<bodyText confidence="0.999949111111111">
We chose one of the algorithms with the best performance (multi-layer perceptron) and we evaluated
it using three different training functions, bayesian regulation back propagation (br), Levenberg-
Marquardt (lm) and scaled conjugate gradient (scg), and compared their performance in the
classification of different patterns of bigrams as MWE. For this comparison we used the patterns that
gave 10 or more samples of MWEs. We had eight patterns that together represent 59% of the
candidate bigrams (689/1,170) and 94% of the MWEs that appear three or more times in the corpus
(420/447). The tables 2.a, 2.b and 2.c show the results. “N” stands for “Noun”, “A” for adjective, “O”
for other classes (mostly adverbs and pronouns) and “PN” for “proper names”.
Analyzing the three tables, we see that we had best results with the patterns N-A (e.g. “agencias
internacionais”, “ajuste fiscal”, “America Latina”) and PN-PN (“Adelson Barbosa”, “Ayrton Senna”,
“Bill Clinton”). The function lm gave the best value for the F1 measure (0.912) for the pattern N-A,
and the function scg gave the best value for the pattern PN-PN (0.931).
In general, we obtained the weakest results with the patterns O-N (e.g. ex-presidente, primeiro
mundo) and A-PN (S‹o Paulo, Nova York). Using the training functions “lm” and “scg”, none of the
10 MWEs belonging to the pattern O-O (apesar disso, al6m disso) was recognized, and none of the 46
MWEs belonging to the pattern O-N was recognized, when using the training function “scg”.
The last line of each table show the total values for the eight patterns, for the three learning
functions. We had the best precision and recall using the “lm” function.
</bodyText>
<table confidence="0.9997114">
Pattern Bigrams MWE TP FP TN FN Prec. Recall F1
N-A 229 193 176 27 9 17 0.867 0.912 0.889
O-N 164 46 14 23 95 32 0.378 0.304 0.337
PN-PN 117 101 94 15 1 7 0.862 0.931 0.895
A-N 53 21 13 3 29 8 0.813 0.619 0.703
O-O 46 10 5 9 27 5 0.357 0.500 0.417
N-PN 34 16 7 9 9 9 0.438 0.438 0.438
N-N 31 20 11 6 5 9 0.647 0.550 0.595
A-PN 15 13 3 1 1 10 0.750 0.231 0.353
All Pat. 689 420 323 93 176 97 0.776 0.769 0.773
</table>
<tableCaption confidence="0.9698395">
Table 2a: Multi-layer perceptron using Bayesian regulation back-propagation as training function:
precision, recall and F-measure in the classification of the most common bigram’s patterns.
</tableCaption>
<page confidence="0.769989">
56
</page>
<table confidence="0.9999156">
Pattern Bigrams MWE TP FP TN FN Prec. Recall F1
N-A 229 193 191 35 1 2 0.845 0.990 0.912
O-N 164 46 11 6 112 35 0.647 0.239 0.349
PN-PN 117 101 101 16 0 0 0.863 1.000 0.927
A-N 53 21 17 4 28 4 0.810 0.810 0.810
O-O 46 10 0 2 34 10 0.000 0.000 0.000
N-PN 34 16 11 5 13 5 0.688 0.688 0.688
N-N 31 20 16 7 4 4 0.696 0.800 0.744
A-PN 15 13 2 2 0 11 0.500 0.154 0.235
All Pat. 689 420 349 77 192 71 0.819 0.831 0.825
</table>
<tableCaption confidence="0.688824">
Table 2b: Multi-layer perceptron using Levenberg-Marquardt as training function: precision, recall
and F-measure in the classification of the most common bigram’s patterns.
</tableCaption>
<table confidence="0.9999511">
Pattern Bigrams MWE TP FP TN FN Prec. Recall F1
N-A 229 193 187 33 3 6 0.850 0.969 0.906
O-N 164 46 0 0 118 46 0.720 0.000 0.000
PN-PN 117 101 101 15 1 0 0.871 1.000 0.931
A-N 53 21 17 10 22 4 0.630 0.810 0.708
O-O 46 10 0 0 36 10 0.783 0.000 0.000
N-PN 34 16 2 7 11 14 0.222 0.125 0.160
N-N 31 20 18 8 3 2 0.692 0.900 0.783
A-PN 15 13 2 1 1 11 0.667 0.154 0.250
All Pat. 689 420 327 74 195 93 0.815 0.779 0.797
</table>
<tableCaption confidence="0.830949">
Table 2c: Multi-layer perceptron using scaled conjugate gradient as training function: precision, recall
and F-measure in the classification of the most common bigram’s patterns.
</tableCaption>
<sectionHeader confidence="0.860721" genericHeader="evaluation">
6 Evaluation of two different tools
</sectionHeader>
<bodyText confidence="0.999072">
Using the same excerpts of our corpus, we proceeded to the evaluation of two different tools for
extracting MWEs from text: MWEtoolkit1 (Ramisch, 2012) and Text-NSP2 (Banerjee and Pedersen,
2003).
</bodyText>
<subsectionHeader confidence="0.977513">
6.1 MWEtoolkit
</subsectionHeader>
<bodyText confidence="0.999865857142857">
Before using this tool, we POS-tagged the corpus using TreeTagger3 (Schmid, 1994), with a
Portuguese parameter file. Then we transformed the tagged corpus to the xml format used by
MWEtoolkit using MWEtoolkit script treetagger2xml.
After generating the index, we defined the patterns file using the following bigrams patterns: N-N,
N-ADJ, N-V, ADJ-ADJ, ADJ-N, ADJ-V, V-V, V-N and V-ADJ. There is not a PN tag for proper
name in TreeTagger, so the proper names were treated as nouns (N). And we decided not to use the
other grammatical classes (adverbs, pronouns, etc.), labeled as “O” in the previous section, because
the only patterns that gave more than 10 MWEs with frequency higher than 3 using those classes were
O-N and O-O, and we did not obtain good values for their classification using the multi-layer
perceptron classification algorithms.
We used those patterns to generate all the bigrams and we obtained 28,738 candidates, with their
frequencies and the frequencies of each word composing the bigram. Then we calculated five different
association measures for each candidate: maximum likelihood estimator (mle), pointwise mutual
information (pmi), Student&apos;s t-test (t), Dice&apos;s coefficient (dice), and log-likelihood (ll).
</bodyText>
<footnote confidence="0.999328">
1 http://mwetoolkit.sourceforge.net/PHITE.php?sitesig=MWE
2 http://search.cpan.org/~tpederse/Text-NSP/
3 http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/
</footnote>
<page confidence="0.999265">
57
</page>
<bodyText confidence="0.995953866666667">
Then we created candidates files ordered by each of these five association measures and we ranked
the n best candidates, n = 50, 100, 500, 1000 and 5000. Finally, we used MWEtoolkit’s automatic
evaluation script to evaluate each of these ranked candidates against our reference file.
The reference file was created with the 447 MWEs selected according to the method described in
Section 4, i. e., all the bigrams that appear three or more times in our corpus and that we manually
considered as a MWE. It is important to note that our reference file does not contain all the MWEs
with two words in the corpus, since we generated more than 49,000 bigrams and we could not evaluate
all of them by hand. Furthermore, the corpus is formed by newspaper texts, treating different subjects,
thus it is more difficult to create a closed set of all possible two-word MWEs. Therefore, our
evaluation is a comparison of how many of the most frequent two-word MWEs in our corpus are
ranked as the n best candidates by each of the association measures.
Table 3 and Figure 1 show the result of our evaluation using the MWEtoolkit. Each number in the
table represents how many of the MWEs in our reference list were found among the n best ranked
candidates. For example, for the “ll” measure, among the 50 best ranked candidates 27 are MWEs that
appear in our reference list.
</bodyText>
<table confidence="0.981274166666667">
dice ll mle pmi t
50 0 27 5 0 11
100 12 55 10 0 31
500 34 152 49 1 105
1000 59 170 87 9 169
5000 161 187 179 94 186
</table>
<tableCaption confidence="0.823007">
Table 3: MWEtoolkit: number of MWEs among the first n-best candidates, ranked by five association
measures.
</tableCaption>
<figureCaption confidence="0.981976">
Figure 1: MWEtoolkit: five association measures performance comparison.
</figureCaption>
<table confidence="0.999901166666667">
ll TP Prec. Recall F1
50 27 0.54 0.06 0.11
100 55 0.55 0.12 0.20
500 152 0.30 0.34 0.32
1000 170 0.17 0.38 0.23
5000 187 0.04 0.41 0.07
</table>
<tableCaption confidence="0.999853">
Table 4: MWEtoolkit: precision, recall and F-measure for the log-likelihood measure.
</tableCaption>
<bodyText confidence="0.990506285714286">
Analyzing the results, we notice that with log-likelihood measure we could find the highest number
of MWEs present in our reference list, for all values of n. Since our reference list is formed by the
most frequent MWEs in the corpus (frequency higher than three), this is an evidence of how suitable
this measure is when the task is to find the most frequent two-word MWEs.
Table 4 presents the results of precision, recall and F-measure for the ll-measure for different
values of n candidates. However, it should be kept in mind that precision and recall here are based on
our reference list, which does not contain all the two-word MWEs in the corpus.
</bodyText>
<figure confidence="0.981184363636364">
200
150
100
50
0
50 100 500 1000 5000
dice
ll
mle
pmi
t
</figure>
<page confidence="0.990056">
58
</page>
<subsectionHeader confidence="0.997707">
6.2 Text-NSP
</subsectionHeader>
<bodyText confidence="0.999287857142857">
Before applying this tool, the only pre-processing performed was to remove the XML tags. The next
step was to define a stop words list file, since we are interested in finding MWEs following the
patterns N-N, N-ADJ, N-V, like in Sections 4 and 5.
We ran the program using the script “count.pl”, giving as parameter the stop words file and the
corpus file, and 2 as n-gram value, meaning that we wanted to generate only bigrams.
The exit file is a list of all bigrams in the corpus, and each line contains a bigram, the frequency of
the bigram, and the frequency of each of the two words forming the bigram.
Using the exit file and the script “statistics.pl” we generated the candidates’ files ranked by four
different association measures: Dice&apos;s coefficient (dice), log-likelihood (ll), pointwise mutual
information (pmi) and Student&apos;s t-test (t). Maximum likelihood estimator is not implemented by Text-
NSP. Then we transformed each of the candidates files to the XML format used by the MWEtoolkit
and we used the MWEtoolkit scripts to create files with the n best candidates (n = 50, 100, 500, 1000
and 5000) and to evaluate each of the files against our reference file. Table 5 and Figure 2 show the
results of those evaluations.
</bodyText>
<table confidence="0.997853666666667">
dice ll pmi t
50 7 31 0 23
100 7 64 0 39
500 8 241 1 180
1000 11 314 4 331
5000 73 382 15 406
</table>
<tableCaption confidence="0.8540645">
Table 5: Text-NSP: number of MWEs among the first n-best candidates, ranked by four association
measures.
</tableCaption>
<figureCaption confidence="0.826963">
Figure 2: Text-NSP: four association measures performance comparison.
</figureCaption>
<table confidence="0.9999385">
ll TP Prec. Recall F1
50 31 0.62 0.07 0.12
100 64 0.64 0.14 0.23
500 241 0.48 0.54 0.51
1000 314 0.31 0.70 0.43
5000 382 0.08 0.85 0.14
</table>
<tableCaption confidence="0.99971">
Table 6: Text-NSP: precision, recall and F-measure for the log-likelihood measure.
</tableCaption>
<bodyText confidence="0.999843142857143">
The results show that for values of n = 50,100, and 500 we obtained the best results using the log-
likelihood measure and for n = 1000 and 5000, Student’s t-test gave the best results.
Comparing with MWEtoolkit, we had better results with Text-NSP for the log-likelihood and the
Student’s t-test measures, and weaker results for the dice and pmi measures.
Table 6 shows the precision, recall and F-measure that we obtained for the log-likelihood measure.
We had very good precision values using the Text-NSP with the log-likelihood measure. For example,
from the 50 best ranked candidates by this measure, 31 were MWEs present in our reference list.
</bodyText>
<figure confidence="0.976847909090909">
400
500
300
200
100
0
50 100 500 1000 5000
dice
ll
pmi
t
</figure>
<page confidence="0.976424">
59
</page>
<subsectionHeader confidence="0.994081">
6.3 Comparison between MWEtoolkit and Text-NSP
</subsectionHeader>
<bodyText confidence="0.991598894736842">
Using the 500 best candidates generated by MWEtoolkit and Text-NSP, ranked by Student’s t-test, we
analyzed by hand those 500 candidates to decide which ones are Brazilian Portuguese MWEs. Table 7
shows the precision given by each of the tools for the first n candidates, n = 50, 100, 150...500.
Text-NSP showed higher precision than MWEtoolkit for all values of n candidates, especially for
the smaller values of n. With MWEtoolkit, the precision was around 40%, while with Text-NSP it
starts with 62% for the first best 50 candidates and decreases to 48% for the first best 500 candidates.
We can suppose that for an application interested in a small number of Brazilian Portuguese MWE
candidates, Text-NSP would be a better choice, and as the number of candidates increases, the
programs tend to have similar performance.
Checking the best ranked candidates generated by MWEtoolkit, we noted that it ranked well some
bigrams formed by a noun + the preposition “a” (the/fem.), a pattern that is common in a Brazilian
Portuguese corpus, but that usually does not form MWEs. This happened, despite not having any
pattern that includes preposition in our patterns’ list, because the POS-tagger used (TreeTagger)
wrongly labelled those “a” prepositions as nouns. The same is true for the pronoun “seu/sua” (his/her),
which was labelled as adjective. This can explain the difference in performance between the tools,
when comparing the implementation of the same association measures.
As in the tests performed in Section 5, the most common patterns of MWE found by both programs
were noun-adjective (e.g. Casa Branca, plano real, Estados Unidos) and proper name-proper name (e.g.
Fernando Henrique, Ayrton Senna, Paulo Maluf).
</bodyText>
<table confidence="0.999689">
n first cand. MWEtoolkit Text-NSP
50 0.34 0.62
100 0.47 0.57
150 0.43 0.55
200 0.41 0.53
250 0.40 0.54
300 0.41 0.53
350 0.37 0.53
400 0.41 0.50
450 0.42 0.52
500 0.40 0.48
</table>
<tableCaption confidence="0.995767">
Table 7: MWEtoolkit and Text-NSP precision for the first n best candidates, using Student’s t-test
association measure.
</tableCaption>
<sectionHeader confidence="0.99053" genericHeader="conclusions">
7 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999953466666667">
We obtained very similar results using different algorithms for the classification of MWEs, with
bagging, decision trees and multi-layer perceptron having a slightly better performance.
Using multi-layer perceptron with three different training functions, we identified the bigram’s
patterns that are better classified as MWE. With the function Levenberg-Marquardt we had better
results in classifying the pattern noun-adjective (the most common in our corpus) and the function
Scaled Conjugate Gradient was the most successful in classifying MWEs following the pattern proper
name-proper name.
The comparison between two programs for automatic extraction of MWEs showed that Text-NSP
had a better precision than MWEtoolkit, especially for smaller number of candidates. As the number
of candidates increases, the difference in performance between the two programs decreases.
It is important to note that MWEtoolkit is more complete, in the sense it implements more
statistical measures, makes the comparison between the output candidates file and a reference list file
and generates a list of candidates having more complete information, including all the statistical
measures of each candidate in the same file, and in a XML format more easily consumable by other
programs.
</bodyText>
<page confidence="0.99465">
60
</page>
<bodyText confidence="0.999978666666667">
As a future work, we intend to perform a similar comparison of tools and classification algorithms
for the extraction of Brazilian Portuguese MWEs, not limiting our candidates to bigrams, but studying
n-grams in general, also allowing noncontiguous n-grams.
</bodyText>
<sectionHeader confidence="0.996137" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999702261904762">
Agarwal, A., Ray, B., Choudhury, M., Sarkar, S., Basu, A.: Automatic Extraction of Multiword Expressions in
Bengali: An Approach for Miserly Resource Scenarios. In: Proceedings of ICON 2004, pp. 165-174.
Macmillan, Basingstoke (2004).
Aha, D. and Kibler, D. (1991). Instance-based learning algorithms. Machine Learning. 6:37-66.
Antunes, S. and Mendes, A. MWE in Portuguese - Proposal for a Typology for Annotation in Running Text.
Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pp. 87–92, Atlanta, Georgia, 13-14
June 2013.
Banerjee, S and Pedersen, T. (2003). The Design, Implementation, and Use of the Ngram Statistic Package. In
Proceedings of th Fourth International Conference on Intelligent Text Processing and Computational
Linguistics, pp. 370-381, Mexico City.
Breiman, L. (2001). Random Forests. Machine Learning. 45(1):5-32.
Breiman , L. (1996). Bagging predictors. Machine Learning. 24(2):123-140.
CETENFolha (Corpus de Extractos de Textos Electr—nicos NILC/Folha de S. Paulo) (2008). Linguateca –
Portugal – www.linguateca.pt/ACDC/
Chang, Chih-Chung and Lin, Chih-Jen (2001). LIBSVM - A Library for Support Vector Machines.
http://www.csie.ntu.edu.tw/~cjlin/libsvm/.
Choueka, Y. (1988). Looking for needles in a haystack or locating interesting collocational expressions in large
textual databases. In RIAO’88, pp. 609–624.
Church, K. W. and Hanks, P (1990). Word Association Norms, Mutual Information and Lexicography.
Computational Linguistics, 16(1):22–29.
Cooper, G. and Herskovits, E. (1992). A Bayesian method for the induction of probabilistic networks from data.
Machine Learning. 9(4):309-347.
Dias, G. H. and Lopes, J.G.P. (2005). Extracg‹o autom‡tica de unidades polilexicais para o portugues. In: A
L’ngua Portuguesa no Computador. S‹o Paulo: Ed. Mercado de Letras.
Freund, Y. and Schapire, R. E (1996). Experiments with a new boosting algorithm. In: Thirteenth International
Conference on Machine Learning, San Francisco, pp. 148-156.
Hendrickx, I., Mendes, A. and Antunes, S. (2010). Proposal for Multi-Word Expression Annotation in Running
Text Portuguese.
Hurskainen, A. (2008). Multiword Expressions and Machine Translation. Technical Reports in Language
Technology Report No 1, 2008 (http://www.njas.helsinki.fi/salama).
Kinoshita, J., Nascimento Salvador, L.D. and Dantas de Menezes, C., E. (2006). CoGrOO: a Brazilian-
Portuguese Grammar Checker based on the CETENFOLHA Corpus. In proceedings of LREC 2006.
http://www.pcs.usp.br/~cogroo/papers/Artigo_LREC_2006.pdf
Piao, S., Rayson, P., Archer, D., Wilson, A., and McEnery, T. (2003). Extracting Multiword Expressions with a
Semantic Tagger. In: Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, at ACL
2003, 41st Annual Meeting of the Association for Computational Linguistics, 2003-07-12, Sapporo, Japan.
Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers.
Ramisch, C. (2012). A generic and open framework for MWE treatment – from acquisition to applications -
Ph.D. Thesis, Universidade Federal do Rio Grande do Sul (UFRGS), Brazil.
Ramisch, C., Schreiner, P., Idiart, M. and Villavicencio, A. (2008). An Evaluation of Methods for the Extraction
of Multiword Expressions, Proceedings of the LREC Workshop Towards a Shared Task for Multiword
Expressions (MWE 2008), Marrakech, Morocco, June, 2008.
</reference>
<page confidence="0.983366">
61
</page>
<reference confidence="0.997616384615385">
Sag, I., Baldwin, T., Bond, F., Copestake, A. and Flickinger, D. (2002). Multiword expressions: A pain in the
neck for NLP. In Proc. of the 3rd CICLing (CICLing-2002), volume 2276/2010 de LNCS, pp. 1–15, Mexico
City, Mexico.
Schmid, Helmut (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of
International Conference on New Methods in Language Processing, Manchester, UK.
Silva, J., and Lopes, G. (1999). A local Maxima Method and a Fair Dispersion Normalization for Extracting
Multiword Units. In 6th Meeting on the Mathematics of Language, pp. 369-381.
Smadja, F. A. (1996). Translating Collocations for Bilingual Lexicons: A Statistical Approach. Association for
Computational Linguistics, 22 (1):1-38.
Smadja, F. A. (1993). Retrieving collocations from text: Xtract. Computational Linguistics., 19(1):143–177.
Watrin, Patrick and Frangois, Tomas (2011). An N-gram frequency database reference to handle MWE
extraction in NLP applications. Proceedings of the Workshop on Multiword Expressions: from Parsing and
Generation to the Real World (MWE 2011), pp. 83–91.
</reference>
<page confidence="0.999176">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860157">
<title confidence="0.999661">A Comparative Study of Different Classification Methods for Identification of Brazilian Portuguese Multiword Expressions</title>
<author confidence="0.981946">Alexsandro Fonseca Fatiha Sadat</author>
<affiliation confidence="0.882918">Universit6 du Québec ˆ Montréal, 201 av. President</affiliation>
<address confidence="0.992146">Montreal, QC, H2X 3Y7, Canada</address>
<email confidence="0.988083">affonseca@gmail.comsadat.fatiha@uqam.ca</email>
<abstract confidence="0.999602909090909">This paper presents a comparative study of different methods for the identification of multiword expressions, applied to a Brazilian Portuguese corpus. First, we selected the candidates based on the frequency of bigrams. Second, we used the linguistic information based on the grammatical classes of the words forming the bigrams, together with the frequency information in order to compare the performance of different classification algorithms. The focus of this study is related to different classification techniques such as support-vector machines (SVM), multi-layer perceptron, naïve Bayesian nets, decision trees and random forest. Third, we evaluated three different multi-layer perceptron training functions in the task of classifying different patterns of multiword expressions. Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Agarwal</author>
<author>B Ray</author>
<author>M Choudhury</author>
<author>S Sarkar</author>
<author>Basu</author>
</authors>
<title>A.: Automatic Extraction of Multiword Expressions in Bengali: An Approach for Miserly Resource Scenarios. In:</title>
<date>2004</date>
<booktitle>Proceedings of ICON 2004,</booktitle>
<pages>165--174</pages>
<publisher>Macmillan,</publisher>
<location>Basingstoke</location>
<contexts>
<context position="6397" citStr="Agarwal et al. (2004)" startWordPosition="976" endWordPosition="979">ion, chi-squared and permutation entropy. Then they introduce a method called entropy of permutation and insertion (a hybrid approach), that takes into account linguistic information of the MWE type. Following some patterns, they modify each original MWE candidate by inserting some types of words in some positions and they test if the new MWE are still MWE and they try to identify which kind of modification an MWE type accepts or refuses in a particular language. The new measure is calculated using a formula that combines the probability of occurrence of the original and of the generated MWE. Agarwal et al. (2004) present an approach for extracting MWEs in languages with few resources based on a morphological analyser and a moderate size untagged text corpus. First, they divide the MWEs in categories. For example, Category-2 is formed by noun-noun, adjective-noun and verb-verb bigrams. Then they apply a set of rules to identify or eliminate candidates as MWE. Those rules take into consideration the precedent and/or the next word in the pair and the possible inflections of the words. After this step, association measures are computed. Piao et al. (2003) use, what they call, a semantic field annotator. T</context>
</contexts>
<marker>Agarwal, Ray, Choudhury, Sarkar, Basu, 2004</marker>
<rawString>Agarwal, A., Ray, B., Choudhury, M., Sarkar, S., Basu, A.: Automatic Extraction of Multiword Expressions in Bengali: An Approach for Miserly Resource Scenarios. In: Proceedings of ICON 2004, pp. 165-174. Macmillan, Basingstoke (2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Aha</author>
<author>D Kibler</author>
</authors>
<title>Instance-based learning algorithms.</title>
<date>1991</date>
<journal>Machine Learning.</journal>
<pages>6--37</pages>
<contexts>
<context position="11669" citStr="Aha and Kibler, 1991" startWordPosition="1834" endWordPosition="1837">gorithms to our data set. The parameters used with each algorithm are listed below. Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25. Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1. Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1. Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kernel type = radial basis function; nu = 0.5; seed = 1. Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validation threshold = 500; seed = 0; Bayesian net: search algorithm = k2 (Cooper and Herskovits, 1992); estimator = simple estimator (alpha = 0.5). As we can see in Table 1, the values of precision are very similar for all the algorithms, varying between 0.830 (rand</context>
</contexts>
<marker>Aha, Kibler, 1991</marker>
<rawString>Aha, D. and Kibler, D. (1991). Instance-based learning algorithms. Machine Learning. 6:37-66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Antunes</author>
<author>A Mendes</author>
</authors>
<title>MWE in Portuguese - Proposal for a Typology for Annotation in Running Text.</title>
<date>2013</date>
<booktitle>Proceedings of the 9th Workshop on Multiword Expressions (MWE</booktitle>
<pages>87--92</pages>
<location>Atlanta,</location>
<marker>Antunes, Mendes, 2013</marker>
<rawString>Antunes, S. and Mendes, A. MWE in Portuguese - Proposal for a Typology for Annotation in Running Text. Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pp. 87–92, Atlanta, Georgia, 13-14 June 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>The Design, Implementation, and Use of the Ngram Statistic Package.</title>
<date>2003</date>
<booktitle>In Proceedings of th Fourth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<pages>370--381</pages>
<location>Mexico City.</location>
<contexts>
<context position="16854" citStr="Banerjee and Pedersen, 2003" startWordPosition="2777" endWordPosition="2780">.630 0.810 0.708 O-O 46 10 0 0 36 10 0.783 0.000 0.000 N-PN 34 16 2 7 11 14 0.222 0.125 0.160 N-N 31 20 18 8 3 2 0.692 0.900 0.783 A-PN 15 13 2 1 1 11 0.667 0.154 0.250 All Pat. 689 420 327 74 195 93 0.815 0.779 0.797 Table 2c: Multi-layer perceptron using scaled conjugate gradient as training function: precision, recall and F-measure in the classification of the most common bigram’s patterns. 6 Evaluation of two different tools Using the same excerpts of our corpus, we proceeded to the evaluation of two different tools for extracting MWEs from text: MWEtoolkit1 (Ramisch, 2012) and Text-NSP2 (Banerjee and Pedersen, 2003). 6.1 MWEtoolkit Before using this tool, we POS-tagged the corpus using TreeTagger3 (Schmid, 1994), with a Portuguese parameter file. Then we transformed the tagged corpus to the xml format used by MWEtoolkit using MWEtoolkit script treetagger2xml. After generating the index, we defined the patterns file using the following bigrams patterns: N-N, N-ADJ, N-V, ADJ-ADJ, ADJ-N, ADJ-V, V-V, V-N and V-ADJ. There is not a PN tag for proper name in TreeTagger, so the proper names were treated as nouns (N). And we decided not to use the other grammatical classes (adverbs, pronouns, etc.), labeled as “O</context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Banerjee, S and Pedersen, T. (2003). The Design, Implementation, and Use of the Ngram Statistic Package. In Proceedings of th Fourth International Conference on Intelligent Text Processing and Computational Linguistics, pp. 370-381, Mexico City.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Breiman</author>
</authors>
<title>Random Forests.</title>
<date>2001</date>
<journal>Machine Learning.</journal>
<booktitle>Machine Learning. 45(1):5-32. Breiman , L.</booktitle>
<pages>24--2</pages>
<contexts>
<context position="11238" citStr="Breiman, 2001" startWordPosition="1753" endWordPosition="1754">equency of the first bigram’s word, the third column represents the frequency of the second bigram’s word, the fourth column represents the grammatical class of the first bigram’s word and the fifth column represents the grammatical class of the second bigram’s word. This matrix was used to evaluate the precision and recall of different classification algorithms. 4.2 Evaluation We applied nine different classification algorithms to our data set. The parameters used with each algorithm are listed below. Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25. Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1. Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1. Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3;</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Breiman, L. (2001). Random Forests. Machine Learning. 45(1):5-32. Breiman , L. (1996). Bagging predictors. Machine Learning. 24(2):123-140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CETENFolha</author>
</authors>
<title>de Extractos de Textos Electr—nicos NILC/Folha de S. Paulo</title>
<date>2008</date>
<booktitle>Linguateca – Portugal – www.linguateca.pt/ACDC/</booktitle>
<contexts>
<context position="7925" citStr="CETENFolha, 2008" startWordPosition="1226" endWordPosition="1227">or “emotion”, etc. A text labeled with those categories is used to extract the MWE candidates. The differential of this approach is that the candidates are selected not based only on statistical measures. The problem with this is that most of the MWEs, about 68% in the work of Piao et al., appear in the text with a low frequency. As a consequence, most of the methods for extracting MWEs give good precision, but low recall. 3 The Data The current study used the corpus CETENFolha (Corpus de Extractos de Textos Eletr—nicos NILC/Folha de S‹o Paulo), available on the website Linguateca Portuguesa (CETENFolha, 2008). This corpus is composed by excerpts from Brazilian newspaper &amp;quot;Folha de S‹o Paulo&amp;quot;, and contains over 24 million words. It is part of a project on the automatic processing of the Portuguese (Kinoshita et al., 2006). As the current stage, we used a small fraction of the corpus, composed by 3,409 excerpts of text (about 250,000 words). Each excerpt corresponds to individual news, which covers different areas. 54 4 Comparison of different classification algorithms 4.1 Pre-processing the data Before the indexation, some pre-processing methods on the corpus were completed, such as lemmatization an</context>
</contexts>
<marker>CETENFolha, 2008</marker>
<rawString>CETENFolha (Corpus de Extractos de Textos Electr—nicos NILC/Folha de S. Paulo) (2008). Linguateca – Portugal – www.linguateca.pt/ACDC/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM - A Library for Support Vector Machines.</title>
<date>2001</date>
<note>http://www.csie.ntu.edu.tw/~cjlin/libsvm/.</note>
<contexts>
<context position="11798" citStr="Chang and Lin, 2001" startWordPosition="1857" endWordPosition="1860">with confidence factor = 0.25. Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1. Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1. Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kernel type = radial basis function; nu = 0.5; seed = 1. Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validation threshold = 500; seed = 0; Bayesian net: search algorithm = k2 (Cooper and Herskovits, 1992); estimator = simple estimator (alpha = 0.5). As we can see in Table 1, the values of precision are very similar for all the algorithms, varying between 0.830 (random forest) and 0.857 (bagging), with the exception of SVM, which gave a precision of 0.738. The recall values were between 0.831 </context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chang, Chih-Chung and Lin, Chih-Jen (2001). LIBSVM - A Library for Support Vector Machines. http://www.csie.ntu.edu.tw/~cjlin/libsvm/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choueka</author>
</authors>
<title>Looking for needles in a haystack or locating interesting collocational expressions in large textual databases.</title>
<date>1988</date>
<booktitle>In RIAO’88,</booktitle>
<pages>609--624</pages>
<contexts>
<context position="1743" citStr="Choueka (1988)" startWordPosition="230" endWordPosition="231">ools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures. 1 Introduction The identification of multiword expressions (MWEs) and their appropriate handling is necessary in constructing professional tools for language manipulation (Hurskainen, 2008). MWEs are considered as a very challenging problem for various natural language processing (NLP) applications, such as machine translation. There are several definitions of MWE in the scientific literature. Smadja (1993) defines MWE as an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously from the meaning or connotation of its components. Moreover, Sag et al. (2002) defines MWE as an idiosyncratic interpretation that exceeds the limit of the word (or spaces). We adopt in this paper a definition similar to the one given by Sag et al. (2002): a MWE is an expression formed by two or more words, whose meaning can vary from totally dependent to completely independent of the meaning of its constituent words. Examples of MWEs: “take care”, “Bill Gates”, “coffe</context>
</contexts>
<marker>Choueka, 1988</marker>
<rawString>Choueka, Y. (1988). Looking for needles in a haystack or locating interesting collocational expressions in large textual databases. In RIAO’88, pp. 609–624.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<date>1990</date>
<journal>Word Association Norms, Mutual Information and Lexicography. Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="4188" citStr="Church and Hanks, 1990" startWordPosition="613" endWordPosition="616">s footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 53 Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62, Dublin, Ireland, August 24 2014. The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (Watrin and Frangois, 2011). Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities. 2 Related Work Dias and Lopes (2005) present a method for the extraction </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K. W. and Hanks, P (1990). Word Association Norms, Mutual Information and Lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Cooper</author>
<author>E Herskovits</author>
</authors>
<title>A Bayesian method for the induction of probabilistic networks from data.</title>
<date>1992</date>
<journal>Machine Learning.</journal>
<pages>9--4</pages>
<contexts>
<context position="12105" citStr="Cooper and Herskovits, 1992" startWordPosition="1915" endWordPosition="1918">number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kernel type = radial basis function; nu = 0.5; seed = 1. Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validation threshold = 500; seed = 0; Bayesian net: search algorithm = k2 (Cooper and Herskovits, 1992); estimator = simple estimator (alpha = 0.5). As we can see in Table 1, the values of precision are very similar for all the algorithms, varying between 0.830 (random forest) and 0.857 (bagging), with the exception of SVM, which gave a precision of 0.738. The recall values were between 0.831 and 0.857 (0.655 for SVM). 55 We obtained good precision and recall. However, we must consider that the values of recall are based only on the MWEs present in our reference list, and not in the entire corpus, since we could not count all the MWEs present in the corpus. Algorithm TP Rate FP Rate Precision R</context>
</contexts>
<marker>Cooper, Herskovits, 1992</marker>
<rawString>Cooper, G. and Herskovits, E. (1992). A Bayesian method for the induction of probabilistic networks from data. Machine Learning. 9(4):309-347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G H Dias</author>
<author>J G P Lopes</author>
</authors>
<title>Extracg‹o autom‡tica de unidades polilexicais para o portugues. In: A L’ngua Portuguesa no Computador. S‹o Paulo: Ed. Mercado de Letras.</title>
<date>2005</date>
<contexts>
<context position="4751" citStr="Dias and Lopes (2005)" startWordPosition="698" endWordPosition="701">sures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities. 2 Related Work Dias and Lopes (2005) present a method for the extraction of MWEs based only on statistics with an application on the Portuguese language. This method consists of a new association measure called “mutual expectation”. Their method can be applied to extract MWEs formed by two or more words, contiguous or not. The mutual expectation method is based on the LocalMaxs (Silva and Lopes, 1999) algorithm. This algorithm deduces that a n-gram is a MWE if the degree of attraction between its words is greater or equal to the degree of attraction of all its subsets of n-1 words (i.e. all groups of n-1 words contained by the n</context>
</contexts>
<marker>Dias, Lopes, 2005</marker>
<rawString>Dias, G. H. and Lopes, J.G.P. (2005). Extracg‹o autom‡tica de unidades polilexicais para o portugues. In: A L’ngua Portuguesa no Computador. S‹o Paulo: Ed. Mercado de Letras.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Freund</author>
<author>R E Schapire</author>
</authors>
<title>Experiments with a new boosting algorithm. In:</title>
<date>1996</date>
<booktitle>Thirteenth International Conference on Machine Learning,</booktitle>
<pages>148--156</pages>
<location>San Francisco,</location>
<contexts>
<context position="11324" citStr="Freund and Schapire, 1996" startWordPosition="1769" endWordPosition="1772">ncy of the second bigram’s word, the fourth column represents the grammatical class of the first bigram’s word and the fifth column represents the grammatical class of the second bigram’s word. This matrix was used to evaluate the precision and recall of different classification algorithms. 4.2 Evaluation We applied nine different classification algorithms to our data set. The parameters used with each algorithm are listed below. Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25. Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1. Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1. Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kernel type = radial basis function; nu = 0.5; seed = 1. Mul</context>
</contexts>
<marker>Freund, Schapire, 1996</marker>
<rawString>Freund, Y. and Schapire, R. E (1996). Experiments with a new boosting algorithm. In: Thirteenth International Conference on Machine Learning, San Francisco, pp. 148-156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Hendrickx</author>
<author>A Mendes</author>
<author>S Antunes</author>
</authors>
<title>Proposal for Multi-Word Expression Annotation in Running Text Portuguese.</title>
<date>2010</date>
<marker>Hendrickx, Mendes, Antunes, 2010</marker>
<rawString>Hendrickx, I., Mendes, A. and Antunes, S. (2010). Proposal for Multi-Word Expression Annotation in Running Text Portuguese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hurskainen</author>
</authors>
<title>Multiword Expressions and Machine Translation. Technical Reports in Language Technology Report No 1,</title>
<date>2008</date>
<contexts>
<context position="1441" citStr="Hurskainen, 2008" startWordPosition="187" endWordPosition="188">s support-vector machines (SVM), multi-layer perceptron, naïve Bayesian nets, decision trees and random forest. Third, we evaluated three different multi-layer perceptron training functions in the task of classifying different patterns of multiword expressions. Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures. 1 Introduction The identification of multiword expressions (MWEs) and their appropriate handling is necessary in constructing professional tools for language manipulation (Hurskainen, 2008). MWEs are considered as a very challenging problem for various natural language processing (NLP) applications, such as machine translation. There are several definitions of MWE in the scientific literature. Smadja (1993) defines MWE as an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously from the meaning or connotation of its components. Moreover, Sag et al. (2002) defines MWE as an idiosyncratic interpretation that exceeds the limit of the word (or spaces</context>
</contexts>
<marker>Hurskainen, 2008</marker>
<rawString>Hurskainen, A. (2008). Multiword Expressions and Machine Translation. Technical Reports in Language Technology Report No 1, 2008 (http://www.njas.helsinki.fi/salama).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kinoshita</author>
<author>Nascimento Salvador</author>
<author>L D</author>
<author>Dantas de Menezes</author>
<author>E C</author>
</authors>
<title>CoGrOO: a BrazilianPortuguese Grammar Checker based on the CETENFOLHA Corpus.</title>
<date>2006</date>
<booktitle>In proceedings of LREC</booktitle>
<note>http://www.pcs.usp.br/~cogroo/papers/Artigo_LREC_2006.pdf</note>
<marker>Kinoshita, Salvador, D, de Menezes, C, 2006</marker>
<rawString>Kinoshita, J., Nascimento Salvador, L.D. and Dantas de Menezes, C., E. (2006). CoGrOO: a BrazilianPortuguese Grammar Checker based on the CETENFOLHA Corpus. In proceedings of LREC 2006. http://www.pcs.usp.br/~cogroo/papers/Artigo_LREC_2006.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Piao</author>
<author>P Rayson</author>
<author>D Archer</author>
<author>A Wilson</author>
<author>T McEnery</author>
</authors>
<title>Extracting Multiword Expressions with a Semantic Tagger. In:</title>
<date>2003</date>
<booktitle>Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, at ACL 2003, 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>2003--07</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2795" citStr="Piao et al. (2003" startWordPosition="407" endWordPosition="410"> whose meaning can vary from totally dependent to completely independent of the meaning of its constituent words. Examples of MWEs: “take care”, “Bill Gates”, “coffee break” and “by the way”. This study treats only two-word MWEs. We are not considering some common Portuguese MWEs, such as “tempo de espera” (waiting time, lit.: time of waiting), “dar um tempo” (to have a break, lit.: to give a time) or “comegar tudo de novo” (restart, lit. start everything of new). However, our experience and some related work show that we are already covering the majority of MWEs. For their data, for example, Piao et al. (2003, Section 5) found that 81.88% of the recognized MWEs were bigrams. Moreover, our focus is in MWE formed by nouns, adjectives, verbs and adverbs. As a consequence, two-word MWEs formed by prepositions were not considered, such as “de novo” (again, lit. of new), “ˆ toa” (for nothing), “apesar de” (despite of) or “desde ontem” (since yesterday). In resume, we evaluated the performance of different classification algorithms and tools for the recognition of twoword MWEs formed by nouns, adjectives, verbs and adverbs. We intend, in the future, to extend this study to MWEs formed by words belonging </context>
<context position="6946" citStr="Piao et al. (2003)" startWordPosition="1063" endWordPosition="1066">rence of the original and of the generated MWE. Agarwal et al. (2004) present an approach for extracting MWEs in languages with few resources based on a morphological analyser and a moderate size untagged text corpus. First, they divide the MWEs in categories. For example, Category-2 is formed by noun-noun, adjective-noun and verb-verb bigrams. Then they apply a set of rules to identify or eliminate candidates as MWE. Those rules take into consideration the precedent and/or the next word in the pair and the possible inflections of the words. After this step, association measures are computed. Piao et al. (2003) use, what they call, a semantic field annotator. They use a semantic tagger for the English language called USAS, developed in Lancaster University. This tagger labels words and expressions in a text using 21 categories. For example, Category-A is used for “general and abstract terms”, Category-B is used for “the body and the individual”, Category-E is used for “emotion”, etc. A text labeled with those categories is used to extract the MWE candidates. The differential of this approach is that the candidates are selected not based only on statistical measures. The problem with this is that mos</context>
</contexts>
<marker>Piao, Rayson, Archer, Wilson, McEnery, 2003</marker>
<rawString>Piao, S., Rayson, P., Archer, D., Wilson, A., and McEnery, T. (2003). Extracting Multiword Expressions with a Semantic Tagger. In: Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, at ACL 2003, 41st Annual Meeting of the Association for Computational Linguistics, 2003-07-12, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publishers.</publisher>
<contexts>
<context position="11177" citStr="Quinlan, 1993" startWordPosition="1744" endWordPosition="1745">m in the excerpt of text, the second column represents the frequency of the first bigram’s word, the third column represents the frequency of the second bigram’s word, the fourth column represents the grammatical class of the first bigram’s word and the fifth column represents the grammatical class of the second bigram’s word. This matrix was used to evaluate the precision and recall of different classification algorithms. 4.2 Evaluation We applied nine different classification algorithms to our data set. The parameters used with each algorithm are listed below. Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25. Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1. Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100; iterations = 10; seed = 1. Bagging (Breiman, 1996): classifier = fast decision tree learner (min. number = 2; min. variance = 0.001; number of folds = 3; seed = 1; max. depth = -1); bag size percent = 100; seed = 1; number of execution slots = 1; iterations = 10. KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search (distance function = Euclidian distance). SVM </context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ramisch</author>
</authors>
<title>A generic and open framework for MWE treatment – from acquisition to applications -Ph.D. Thesis, Universidade Federal do Rio Grande do Sul (UFRGS),</title>
<date>2012</date>
<contexts>
<context position="16810" citStr="Ramisch, 2012" startWordPosition="2773" endWordPosition="2774">0 0.931 A-N 53 21 17 10 22 4 0.630 0.810 0.708 O-O 46 10 0 0 36 10 0.783 0.000 0.000 N-PN 34 16 2 7 11 14 0.222 0.125 0.160 N-N 31 20 18 8 3 2 0.692 0.900 0.783 A-PN 15 13 2 1 1 11 0.667 0.154 0.250 All Pat. 689 420 327 74 195 93 0.815 0.779 0.797 Table 2c: Multi-layer perceptron using scaled conjugate gradient as training function: precision, recall and F-measure in the classification of the most common bigram’s patterns. 6 Evaluation of two different tools Using the same excerpts of our corpus, we proceeded to the evaluation of two different tools for extracting MWEs from text: MWEtoolkit1 (Ramisch, 2012) and Text-NSP2 (Banerjee and Pedersen, 2003). 6.1 MWEtoolkit Before using this tool, we POS-tagged the corpus using TreeTagger3 (Schmid, 1994), with a Portuguese parameter file. Then we transformed the tagged corpus to the xml format used by MWEtoolkit using MWEtoolkit script treetagger2xml. After generating the index, we defined the patterns file using the following bigrams patterns: N-N, N-ADJ, N-V, ADJ-ADJ, ADJ-N, ADJ-V, V-V, V-N and V-ADJ. There is not a PN tag for proper name in TreeTagger, so the proper names were treated as nouns (N). And we decided not to use the other grammatical clas</context>
</contexts>
<marker>Ramisch, 2012</marker>
<rawString>Ramisch, C. (2012). A generic and open framework for MWE treatment – from acquisition to applications -Ph.D. Thesis, Universidade Federal do Rio Grande do Sul (UFRGS), Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ramisch</author>
<author>P Schreiner</author>
<author>M Idiart</author>
<author>A Villavicencio</author>
</authors>
<title>An Evaluation of Methods for the Extraction of Multiword Expressions,</title>
<date>2008</date>
<booktitle>Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="5648" citStr="Ramisch et al. (2008)" startWordPosition="858" endWordPosition="861">uous or not. The mutual expectation method is based on the LocalMaxs (Silva and Lopes, 1999) algorithm. This algorithm deduces that a n-gram is a MWE if the degree of attraction between its words is greater or equal to the degree of attraction of all its subsets of n-1 words (i.e. all groups of n-1 words contained by the n-gram) and if it is strictly greater than the degree of attraction of all of its super groups of n+1 words (i.e. all groups of n+1 words containing the n-gram). When the n-gram is a bigram (n = 2), only the degree of attraction of its super groups of n+1 words is calculated. Ramisch et al. (2008) analyze the extraction of MWEs based only on statistical information, comparing three association measures: the mutual information, chi-squared and permutation entropy. Then they introduce a method called entropy of permutation and insertion (a hybrid approach), that takes into account linguistic information of the MWE type. Following some patterns, they modify each original MWE candidate by inserting some types of words in some positions and they test if the new MWE are still MWE and they try to identify which kind of modification an MWE type accepts or refuses in a particular language. The </context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Ramisch, C., Schreiner, P., Idiart, M. and Villavicencio, A. (2008). An Evaluation of Methods for the Extraction of Multiword Expressions, Proceedings of the LREC Workshop Towards a Shared Task for Multiword Expressions (MWE 2008), Marrakech, Morocco, June, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd CICLing (CICLing-2002),</booktitle>
<volume>2276</volume>
<pages>1--15</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="1948" citStr="Sag et al. (2002)" startWordPosition="260" endWordPosition="263">ropriate handling is necessary in constructing professional tools for language manipulation (Hurskainen, 2008). MWEs are considered as a very challenging problem for various natural language processing (NLP) applications, such as machine translation. There are several definitions of MWE in the scientific literature. Smadja (1993) defines MWE as an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously from the meaning or connotation of its components. Moreover, Sag et al. (2002) defines MWE as an idiosyncratic interpretation that exceeds the limit of the word (or spaces). We adopt in this paper a definition similar to the one given by Sag et al. (2002): a MWE is an expression formed by two or more words, whose meaning can vary from totally dependent to completely independent of the meaning of its constituent words. Examples of MWEs: “take care”, “Bill Gates”, “coffee break” and “by the way”. This study treats only two-word MWEs. We are not considering some common Portuguese MWEs, such as “tempo de espera” (waiting time, lit.: time of waiting), “dar um tempo” (to have</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, I., Baldwin, T., Bond, F., Copestake, A. and Flickinger, D. (2002). Multiword expressions: A pain in the neck for NLP. In Proc. of the 3rd CICLing (CICLing-2002), volume 2276/2010 de LNCS, pp. 1–15, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>Proceedings of International Conference on New Methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="16952" citStr="Schmid, 1994" startWordPosition="2793" endWordPosition="2794">0.692 0.900 0.783 A-PN 15 13 2 1 1 11 0.667 0.154 0.250 All Pat. 689 420 327 74 195 93 0.815 0.779 0.797 Table 2c: Multi-layer perceptron using scaled conjugate gradient as training function: precision, recall and F-measure in the classification of the most common bigram’s patterns. 6 Evaluation of two different tools Using the same excerpts of our corpus, we proceeded to the evaluation of two different tools for extracting MWEs from text: MWEtoolkit1 (Ramisch, 2012) and Text-NSP2 (Banerjee and Pedersen, 2003). 6.1 MWEtoolkit Before using this tool, we POS-tagged the corpus using TreeTagger3 (Schmid, 1994), with a Portuguese parameter file. Then we transformed the tagged corpus to the xml format used by MWEtoolkit using MWEtoolkit script treetagger2xml. After generating the index, we defined the patterns file using the following bigrams patterns: N-N, N-ADJ, N-V, ADJ-ADJ, ADJ-N, ADJ-V, V-V, V-N and V-ADJ. There is not a PN tag for proper name in TreeTagger, so the proper names were treated as nouns (N). And we decided not to use the other grammatical classes (adverbs, pronouns, etc.), labeled as “O” in the previous section, because the only patterns that gave more than 10 MWEs with frequency hi</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Schmid, Helmut (1994). Probabilistic Part-of-Speech Tagging Using Decision Trees. Proceedings of International Conference on New Methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Silva</author>
<author>G Lopes</author>
</authors>
<title>A local Maxima Method and a Fair Dispersion Normalization for Extracting Multiword Units.</title>
<date>1999</date>
<booktitle>In 6th Meeting on the Mathematics of Language,</booktitle>
<pages>369--381</pages>
<contexts>
<context position="5119" citStr="Silva and Lopes, 1999" startWordPosition="758" endWordPosition="761">stic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities. 2 Related Work Dias and Lopes (2005) present a method for the extraction of MWEs based only on statistics with an application on the Portuguese language. This method consists of a new association measure called “mutual expectation”. Their method can be applied to extract MWEs formed by two or more words, contiguous or not. The mutual expectation method is based on the LocalMaxs (Silva and Lopes, 1999) algorithm. This algorithm deduces that a n-gram is a MWE if the degree of attraction between its words is greater or equal to the degree of attraction of all its subsets of n-1 words (i.e. all groups of n-1 words contained by the n-gram) and if it is strictly greater than the degree of attraction of all of its super groups of n+1 words (i.e. all groups of n+1 words containing the n-gram). When the n-gram is a bigram (n = 2), only the degree of attraction of its super groups of n+1 words is calculated. Ramisch et al. (2008) analyze the extraction of MWEs based only on statistical information, </context>
</contexts>
<marker>Silva, Lopes, 1999</marker>
<rawString>Silva, J., and Lopes, G. (1999). A local Maxima Method and a Fair Dispersion Normalization for Extracting Multiword Units. In 6th Meeting on the Mathematics of Language, pp. 369-381.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
</authors>
<title>Translating Collocations for Bilingual Lexicons: A Statistical Approach.</title>
<date>1996</date>
<journal>Association for Computational Linguistics,</journal>
<volume>22</volume>
<pages>1--1</pages>
<contexts>
<context position="4241" citStr="Smadja, 1996" startWordPosition="621" endWordPosition="622">reativecommons.org/licenses/by/4.0/ 53 Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62, Dublin, Ireland, August 24 2014. The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (Watrin and Frangois, 2011). Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each word, the sense of the composite expression or the syntactic regularities. 2 Related Work Dias and Lopes (2005) present a method for the extraction of MWEs based only on statistics with an application </context>
</contexts>
<marker>Smadja, 1996</marker>
<rawString>Smadja, F. A. (1996). Translating Collocations for Bilingual Lexicons: A Statistical Approach. Association for Computational Linguistics, 22 (1):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F A Smadja</author>
</authors>
<title>Retrieving collocations from text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics.,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="1662" citStr="Smadja (1993)" startWordPosition="218" endWordPosition="219">t patterns of multiword expressions. Finally, our study compared two different tools, MWEtoolkit and Text-NSP, for the extraction of multiword expression candidates using different association measures. 1 Introduction The identification of multiword expressions (MWEs) and their appropriate handling is necessary in constructing professional tools for language manipulation (Hurskainen, 2008). MWEs are considered as a very challenging problem for various natural language processing (NLP) applications, such as machine translation. There are several definitions of MWE in the scientific literature. Smadja (1993) defines MWE as an arbitrary and recurrent word combination; while Choueka (1988) defines them as a syntactic and semantic unit whose exact meaning or connotation cannot be derived directly and unambiguously from the meaning or connotation of its components. Moreover, Sag et al. (2002) defines MWE as an idiosyncratic interpretation that exceeds the limit of the word (or spaces). We adopt in this paper a definition similar to the one given by Sag et al. (2002): a MWE is an expression formed by two or more words, whose meaning can vary from totally dependent to completely independent of the mean</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, F. A. (1993). Retrieving collocations from text: Xtract. Computational Linguistics., 19(1):143–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Watrin</author>
<author>Tomas Frangois</author>
</authors>
<title>An N-gram frequency database reference to handle MWE extraction in NLP applications.</title>
<date>2011</date>
<booktitle>Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE</booktitle>
<pages>83--91</pages>
<contexts>
<context position="4043" citStr="Watrin and Frangois, 2011" startWordPosition="594" endWordPosition="597">ss and having any number of words. This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 53 Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 53–62, Dublin, Ireland, August 24 2014. The correct identification of MWEs is important for different NLP applications, such as machine translation, information retrieval and the semantic web, to which the principle of syntactic or semantic unit is important (Watrin and Frangois, 2011). Methods for identifying MWEs rely on statistical measures, especially association measures, such as mutual information (Church and Hanks, 1990), log-likelihood or Dice’s coefficient (Smadja, 1996). The basic idea behind such measures can be summarized as follows: the higher the association among the words that appear together in a text, the higher the probability that they constitute a single semantic unit. There are other methods, which use linguistic information or hybrid approaches that combine statistical measures with the linguistic information, such as the grammatical class of each wor</context>
</contexts>
<marker>Watrin, Frangois, 2011</marker>
<rawString>Watrin, Patrick and Frangois, Tomas (2011). An N-gram frequency database reference to handle MWE extraction in NLP applications. Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pp. 83–91.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>