<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001100">
<title confidence="0.72408">
Dynamic Wordclouds and Vennclouds for Exploratory Data Analysis
</title>
<author confidence="0.995728">
Glen Coppersmith Erin Kelly
</author>
<affiliation confidence="0.9247845">
Human Language Technology Center of Excellence Department of Defense
Johns Hopkins University
</affiliation>
<email confidence="0.993887">
coppersmith@jhu.edu elkelly8@gmail.com
</email>
<sectionHeader confidence="0.994667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99848225">
The wordcloud is a ubiquitous visualiza-
tion of human language, though it falls
short when used for exploratory data anal-
ysis. To address some of these shortcom-
ings, we give the viewer explicit control
over the creation of the wordcloud, allow-
ing them to interact with it in real time–
a dynamic wordcloud. This allows itera-
tive adaptation of the visualization to the
data and inference task at hand. We next
present a principled approach to visualiza-
tion which highlights the similarities and
differences between two sets of documents
– a Venncloud. We make all the visual-
ization code (primarily JavaScript) freely
available.
</bodyText>
<sectionHeader confidence="0.99876" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999678">
A cornerstone of exploratory data analysis is visu-
alization. Tremendous academic effort and engi-
neering expertise has created and refined a myriad
of visualizations available to the data explorer, yet
there still exists a paucity of options for visualizing
language data. While visualizing human language
is a broad subject, we apply Polya’s dictum, and
examine a pair of simpler questions for which we
still lack an answer:
</bodyText>
<listItem confidence="0.991673">
• (1) what is in this corpus of documents?
• (2) what is the relationship between these
two corpora of documents?
</listItem>
<bodyText confidence="0.9998888">
We assert that addressing these two questions is
a step towards creating visualizations of human
language more suitable for exploratory data anal-
ysis. In order to create a meaningful visualiza-
tion, one must understand the inference question
the visualization is meant to inform (i.e., the rea-
son for which (1) is being asked), so the appro-
priate aspects of the data can be highlighted with
the aesthetics of the visualization. Different infer-
ence questions require different aspects to be high-
lighted, so we aim to create a maximally-flexible,
yet simple and intuitive method to enable a user
to explore the relevant aspects of their data, and
adapt the visualization to their task at hand.
The primary contributions of this paper are:
</bodyText>
<listItem confidence="0.985208444444444">
• A visualization of language data tailored for
exploratory data analysis, designed to exam-
ine a single corpus (the dynamic wordcloud)
and to compare two corpora (the Venncloud);
• The framing and analysis of the problem in
terms of the existing psychophysical litera-
ture;
• Distributable JavaScript code, designed to be
simple to use, adapt, and extend.
</listItem>
<bodyText confidence="0.999984272727273">
We base our visualizations on the wordcloud,
which we deconstruct and analyze in §3 and §4.
We then discuss the literature on wordclouds and
relevant psychophysical findings in §5, taking
guidance from the practical and theoretical foun-
dations explored there. We then draw heavily on
similarities to more common and well understood
visualizations to create a more useful version of
the wordcloud. Question (1) is addressed in §7,
and with only a small further expansion described
in §8, an approach to (2) becomes evident.
</bodyText>
<sectionHeader confidence="0.966808" genericHeader="introduction">
2 Motivating Inference Tasks
</sectionHeader>
<bodyText confidence="0.9979165">
Exploratory data analysis on human language en-
compasses a diverse set of language and infer-
ence tasks, so we select the following subset for
their variety. One task in line with question (1)
is getting the general subject of a corpus, high-
lighting content-bearing words. One might want
to examine a collection of social media missives,
too numerous to read individually, perhaps to de-
tect emerging news (Petrovic et al., 2013). Sepa-
rately, author identification (or idiolect analysis)
</bodyText>
<page confidence="0.977904">
22
</page>
<note confidence="0.7902475">
Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29,
Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999605114285714">
attempts attribution of documents (e.g., Shake-
speare’s plays or the Federalist papers) by com-
paring the author’s writing style, focusing on
stylistic and contentless words – for a review see
(Juola, 2006). Further, some linguistic psycho-
metric analysis depends on the relative distribu-
tion of pronouns and other seemingly contentless
words (Coppersmith et al., 2014a; Chung and Pen-
nebaker, 2007).
Each of these questions involves some analy-
sis of unigram statistics, but exactly what analy-
sis differs significantly, thus no single wordcloud
can display all of them. Any static wordcloud is
a single point in a distribution of possible word-
clouds – one way of calculating statistics from the
underlying language and mapping those calcula-
tions to the visual representation. Many such com-
binations and mappings are available, and the opti-
mal wordcloud, like the optimal plot, is a function
of the data and the inference task at hand. Thus,
we enable the wordcloud viewer to adjust the rela-
tionship between the aspects of the data and the
aesthetics of the display, which allows them to
view different points in the distribution of possi-
ble wordclouds. The dynamic wordcloud was im-
plicitly called for in (Rayson and Garside, 2000)
since human expertise (specifically knowledge of
broader contexts and common sense) is needed
to separate meaningful and non-meaningful differ-
ences in wordclouds. We enable this dynamic in-
teraction between human and visualization in real-
time with a simple user interface, requiring only a
modicum more engineering than the creation of a
static wordcloud, though the depth of extra infor-
mation conveyed is significant.
</bodyText>
<sectionHeader confidence="0.981786" genericHeader="method">
3 Wordcloud Aesthetics
</sectionHeader>
<bodyText confidence="0.999920115384616">
We refer to each visual component of the visual-
ization as an aesthetic (ala (Wickham, 2009)) –
each aesthetic can convey some information to the
viewer. For context, the aesthetics of a scatterplot
include the x and y position, color, and size of
each point. Some are best suited for ordinal data
(e.g., font size), while others for categorical data
(e.g., font color).
Ordinal data can be encoded by font size,
the most prominent and noticeable to the viewer
(Bateman et al., 2008). Likewise, the opacity
(transparency) of the word is a prominent and or-
dinal aesthetic. The order in which words are dis-
played can convey a significant amount of infor-
mation as well, but using order in this fashion gen-
erally constrains the use of x and y position.
Categorical data can be encoded by the color
of each word – both the foreground of the word
itself and the background space that surrounds it
(though that bandwidth is severely limited by hu-
man perception). Likewise for font weight (bold-
ness) and font decoration (italics and underlines).
While font face itself could encode a categorical
variable, making comparisons of all the other as-
pects across font faces is likely to be at best unin-
formative and at worst misleading.
</bodyText>
<sectionHeader confidence="0.986257" genericHeader="method">
4 Data Aspects
</sectionHeader>
<bodyText confidence="0.999921270270271">
As the wordcloud has visual aesthetics that we can
control (§3), the data we need to model has aspects
that we want to represent with those aesthetics.
This aspect-to-aesthetic mapping is what makes a
useful and informative visualization, and needs to
be flexible enough to allow it be used for a range
of inference tasks.
For clarity, we define a word (w) as a unique
set of characters and a word token (w) as a sin-
gle usage of a word in a document. We can ob-
serve multiple word tokens (w) of the same word
(w) in a single document (d). For any document d
we represent the term frequency of w as tfd(w).
Similarly, the inverse document frequency of w
as idf(w). A combination of tf and idf is often
used to determine important words in a document
or corpus. We focus on tf and idf here, but this is
just an example of an ordinal value associated with
a word, there are many other such word-ordinal
pairings that are worth exploring (e.g., weights in
a classifier).
The dynamic range (“scaling” in (Wickham,
2009)) also needs to be considered, since the data
has a natural dynamic range – where meaningful
differences can be observed (unsurprisingly, the
definition of meaningful depends on the inference
task). Likewise, each aesthetic has a range of val-
ues for which the users can perceive and differen-
tiate (e.g., words in a font size too small are illeg-
ible, those too large prevent other words from be-
ing displayed; not all differences are perceptible).
Mapping the relevant dynamic range of the data
to the dynamic range of the visualization is at the
heart of a good visualization, but to do this algo-
rithmically for all possible inference tasks remains
a challenge. We, instead, enable the user to adjust
the dynamic range of the visualization explicitly.
</bodyText>
<page confidence="0.998855">
23
</page>
<sectionHeader confidence="0.9684" genericHeader="method">
5 Prior Art
</sectionHeader>
<bodyText confidence="0.999969086956522">
Wordclouds have a mixed history, stemming from
Jim Flanagan’s “Search Referral Zeitgeist”, used
to display aggregate information about websites
linking to his, to its adoption as a visual gim-
mick, to the paradoxical claim that ‘wordclouds
work in practice, but not in theory’ (see (Vi´egas
and Wattenberg, 2008) for more). A number
of wordcloud-generators exist on the web (e.g.,
(Feinberg, 2013; Davies, 2013)), though these
tend towards creating art rather than informative
visualizations. The two cited do allow the user
limited interaction with some of the visual aesthet-
ics, though not of sufficient scope or response time
for general exploratory data analysis.
Enumerating all possible inference tasks involv-
ing the visualization of natural language is impos-
sible, but the prior art does provide empirical data
for some relevant tasks. This further stresses the
importance of allowing the user to interact with
the visualization, since optimizing the visualiza-
tion a priori for all inference tasks simultaneously
is not possible, much like creating a single plot for
all numerical inference tasks is not possible.
</bodyText>
<subsectionHeader confidence="0.994187">
5.1 Psychophysical Analyses
</subsectionHeader>
<bodyText confidence="0.999951314285714">
The quintessential studies on how a wordcloud
is interpreted by humans can be found in (Ri-
vadeneira et al., 2007) and (Bateman et al.,
2008). They both investigated various measures of
impression-forming and recall to determine which
aesthetics conveyed information most effectively
– font size chief among them.
Rivandeneira et al. (Rivadeneira et al., 2007)
also found that word-order was important for im-
pression forming (displaying words from most fre-
quent to least frequent was most effective here),
while displaying words alphabetically was best
when searching for a known word. They also
found that users prefer a search box when search-
ing for something specific and known, and a word-
cloud for exploratory tasks and things unknown.
Bateman et al. (Bateman et al., 2008) examined
the relative utility of other aesthetics to convey in-
formation, finding that font-weight (boldness) and
intensity (opacity) are effective, but not as good
as font-size. Aesthetics such as color, number of
characters or the area covered by the word were
less effective.
Significant research has gone in to the place-
ment of words in the wordcloud (e.g., (Seifert et
al., 2008)), though seemingly little information
can be conveyed by these layouts (Schrammel et
al., 2009). Indeed, (Rivadeneira et al., 2007) in-
dicates that words directly adjacent to the largest
word in the wordcloud had slightly worse recall
than those not-directly-adjacent – in essence, get-
ting the most important words in the center may
be counterproductive. Thus we eschew these algo-
rithms in favor of more interpretable (but perhaps
less aesthetically pleasing) linear ordered layouts.
</bodyText>
<subsectionHeader confidence="0.999279">
5.2 Wordclouds as a tool
</subsectionHeader>
<bodyText confidence="0.99997941025641">
Illustrative investigations of the wordcloud as a
tool for exploratory data analysis are few, but en-
couraging.
In relation to question (1), even static word-
clouds can be useful for this task. Users per-
forming an open-ended search task preferred us-
ing a wordcloud to a search box (Sinclair and
Cardew-Hall, 2008), possibly because the word-
cloud prevented them from having to hypothesize
what might be in the collection before searching
for it. Similarly, wordclouds can be used as a
follow-up display of search results from a query
performed via a standard text search box (Knautz
et al., 2010), providing the user a crude summary
of the results. In both of these cases, a simple
static wordcloud is able to provide some useful
information to the user, though less research has
been done to determine the optimal composition
of the wordcloud. What’s more, the need for a
dynamic interactive wordcloud was made explicit
(Knautz et al., 2010), given the way the users iter-
atively refined their queries and wordclouds.
Question (2) has also been examined. One ap-
proach is to make a set of wordclouds with soft
constraints that the same word appears in roughly
the same position across multiple clouds to fa-
cilitate comparisons (Castella and Sutton, 2013).
Each of these clouds in a wordstorm visualizes a
different collection of documents (e.g., subdivi-
sions via metadata of a larger corpus).
Similarly addressing our second question, Par-
allel Tag Clouds (Collins et al., 2009) allow the
comparison of multiple sets of documents (or dif-
ferent partitions of a corpus). This investigation
provides a theoretically-justified approach to find-
ing ‘the right’ static wordcloud (for a single in-
ference task), though this does depend on some
language-specific resources (e.g., stopword lists
and stemming). Interestingly, they opt for ex-
</bodyText>
<page confidence="0.992266">
24
</page>
<bodyText confidence="0.9997772">
plicit removal of words and outliers that the user
does not wish to have displayed (an exclusion
list), rather than adjusting calculations of the en-
tire cloud to remove them in a principled and fair
manner.
</bodyText>
<subsectionHeader confidence="0.997589">
5.3 Wordclouds and Metadata
</subsectionHeader>
<bodyText confidence="0.999986538461539">
Wordclouds have previously been extended to
convey additional information, though these adap-
tations have been optimized generally for artistic
purposes rather than exploratory data analysis.
Wordclouds can been used to display how lan-
guage interacts with a temporal dimension in (Du-
binko et al., 2007; Cui et al., 2010; Lee et al.,
2010). Dubinko and colleagues created a tag cloud
variant that displays trends in tag usage over time,
coupled with images that have that tag (Dubinko et
al., 2007). An information-theoretic approach to
displaying information changing in time gives rise
to a theoretically grounded approach for display-
ing pointwise tag clouds, and highlighting those
pieces that have changed significantly as com-
pared to a previous time period (Cui et al., 2010).
This can be viewed as measuring the change in
overall language usage over time. In contrast, us-
ing spark lines on each individual word or tag can
convey temporal trends for individual words (Lee
et al., 2010).
Meanwhile, combining tag clouds with geospa-
tial data yields a visualization where words can be
displayed on a map of the world in locations they
are frequently tagged in, labeling famous land-
marks, for example (Slingsby et al., 2007).
</bodyText>
<sectionHeader confidence="0.999069" genericHeader="method">
6 Desiderata
</sectionHeader>
<bodyText confidence="0.999975377358491">
In light of the diverse inference tasks (§2) and
prior art (§5), the following desiderata emerge for
the visualization. These desiderata are explicit
choices, not all of which are ideal for all infer-
ence tasks. Thus, chief among them is the first:
flexibility to allow maximum extensions and mod-
ifications as needed.
Flexible and adjustable in real time: Any sin-
gle static wordcloud is guaranteed to be subopti-
mal for at least some inference tasks, so allowing
the user to adjust the aspect-to-aesthetic mapping
of the wordcloud in real time enables adaptation
of the visualization to the data and inference task
at hand. The statistics described in §4 are relevant
to every language collection (and most inference
tasks), yet there are a number of other ordinal val-
ues to associate a word (e.g., the weight assigned
to it by a classifier). Thus, tf and idf are meant
to be illustrative examples though the visualization
code should generalize well to others.
Though removal of the most frequent words
(stopwords) is useful in many natural language
processing tasks, there are many ways to define
which words fall under this category. Unsurpris-
ingly, the optimal selection of these words can also
depend upon the task at hand (e.g., psychiatric v.
thematic analysis as in §2), so maximum flexibility
and minimum latency are desirable.
Interpretable: An explicit legend is needed to
interpret the differences in visual aesthetics and
what these differences mean with respect to the
underlying data aspects.
Language-Agnostic: We need methods for ex-
ploratory data analysis that work well regard-
less of the language(s) being investigated. This
is crucial for multilingual corpora, yet decidedly
nontrivial. These techniques must be maximally
language-agnostic, relying on only the most rudi-
mentary understanding of the linguistic structure
of the data (e.g., spaces separate words in English,
but not in Chinese), so they can be extended to
many languages easily.
This precludes the use of a fixed set of stop
words for each language examined, since a new set
of stopwords would be required for each language
explored. Alternatively, the set of stopwords can
be dealt with automatically, either by granting the
user the ability to filter out words in the extremes
of the distributions (tf and df alike) through the
use of a weight which penalizes these ubiquitous
or too-rare words. Similarly precluded is the use
of stemming to deal with the many surface forms
of a given root word (e.g., type, typing, typed).
</bodyText>
<sectionHeader confidence="0.996717" genericHeader="method">
7 Dynamic Wordclouds
</sectionHeader>
<bodyText confidence="0.999978833333333">
We address Question (1) and a number of our
desiderata with the addition of explicitly labeled
controls to the static wordcloud display, which al-
lows the user to control the mapping from data
aspects to the visualization aesthetics. We sup-
plement these controls with an explicit explana-
tion of how each aesthetic is affected by each
aspect, so the user can easily read the relevant
mappings, rather than trying to interpret the loca-
tion of the sliders. An example of which is that
“Larger words are those that frequently occur in
the query”, when the aspect tf is mapped to the
</bodyText>
<page confidence="0.990639">
25
</page>
<bodyText confidence="0.998020185185185">
orioles at to for in 13 espn fox leads md ny report star 0 1 1st 2 2012 3 4 5 6 7 ? a about after again against al all amp an and are as
baltimore a game i usa buck chris glove mark move press at back baltimore baseball be beat been best better
and yankees of go 14 gold hamilton jim third birds gonzalez j big birds blue buck but by can can&apos;t card checked chicago come could
on is this vs w/ o&apos;s o september white homers rangers tigers 15 fall day did do don&apos;t down east espn even ever fan fans first for from fuck game
are it win with be i&apos;m yankee sox yard al happen pick blue cc extra m old games get go going gonna good got great gt had has have he here his hit home how i i&apos;m
my you that others new card closer hits tie tied face omg ravens says yahoo city if in inning is it it&apos;s johnson just keep know last lead let&apos;s lets like lol lose love
have just 2 3 up 1 let&apos;s first so all saying second starting stay ass manager players real lt three magic make mark md me mlb more my need new news next
tonight fans but out season we now get sox bout football left sunday sweep goes hey gets wild yanks adam job night no not now o&apos;s of off on one only or orioles others our
an time md series al baseball will about me not news times won&apos;t magic place innings 2013 base gt hr pitching does out over photo pic place play playoff playoffs post postseason rangers
like as 5 playoff lets from over was they if what 4 good no fucking os rain 10 friday outs suck coming makes also check wearing ravens really red report right rt run season see series should since so some
great year day one love back amp fan magic can east playoffs beat gt haha show through god los losing may always being keep 9 hate gotta looks sox sports start still take team than that their them there they think this tied time
red sports rt today do going how last more place team games night blue making posted away free im life we&apos;re weekend call give little bar bring didn&apos;t times to today tomorrow tonight two up vs w/ was watch watching way we well were
doing least look stop thing top where giants long photo record johnson league what when white who why wild will win with won world would yahoo
most thank tv ? please proud walk wish 2012 any end every hell post same yankees yanks year years you your
because many pitch said its new runs everyone excited field finally bullpen let red
yes believe fun made these boys hit into those against mlb race i&apos;ll teams amazing say
w years another people 1st both postseason wait before 8 looking loss him lead man shit
feel inning damn oh 7 baby i&apos;ve again should bad then thanks two wins nice much that&apos;s
winning yankees than gonna playing tickets yeah awesome beat why division lol wow
congrats lost ready lose us big could never even fuck our want since ball ever happy start am
better make run hope think only over he were getting has sports really his u work 6 next won
checked chicago did them some after well best tomorrow watch take their when had too orioles there an
games world need who 0 stadium clinch your been down love don&apos;t way by east or know off play would 4
more o&apos;s it&apos;s no can&apos;t rt playoffs right as still how can back here playoff 1 5 year 3 night watching team do last
one amp got day series home see come great today from like 2 will fan going what pic they about time good lets first
season if get was tonight we not fans let&apos;s all me baseball out now up just so but have be win you that with i&apos;m it are my
others this is washington on vs of w/ go i and
</bodyText>
<figureCaption confidence="0.9989">
Figure 1: Three example settings of the dynamic wordcloud for the same set of tweets containing “Orioles”. Left: 2/24 4:37 size PM
</figureCaption>
<equation confidence="0.519249">
2/24/14 4:36 PM 1 of
reflects tf, sorted by tf; Center: size reflects idf, sorted by idf; Right: size reflects tf*idf, sorted alphabetically.
</equation>
<bodyText confidence="0.992184404255319">
aesthetic font-size (and this description is tied to
the appropriate sliders so it updates as the slid-
ers are changed). The manipulation of the visu-
alization in real time allows us to take advantage
of the human’s adept visual change-detection to
highlight and convey the differences between set-
tings (or a range of settings), even subtle ones.
The data aspects from §4 are precomputed and
mapped to the aesthetics from §3 in a JavaScript
visualization displayed in a standard web browser.
This visualization enables the user to manipulate
the aspect-to-aesthetic mapping via an intuitive
set of sliders and buttons, responsive in real time.
The sliders are roughly segmented into three cat-
egories: those that control which words are dis-
played, those that control how size is calculated,
and those that control how opacity is calculated.
The buttons control the order in which words ap-
pear.
One set of sliders controls which words are
displayed by examining the frequency and rar-
ity of the words. We define the range TFreq =
[tFrFreq
miq, tmax ] as the range of tf values for words to
be displayed (i.e., tf(w) E TFreq). The viewer is
granted a range slider to manipulate both tFre
minq and
tmax
F req to eliminate words from the extremes of the
distribution. Similarly for df and TRarity. Those
words that fall outside TFreq or TRarity are not dis-
played. Importantly, tf is computed from the cur-
rent corpus displayed while df is computed over a
much larger collection (in our running examples,
all the works of Shakespeare or all the tweets for
the last 6 months). Those with high df or high
tf are often stopwords, those with low tf and low
df are often rare, sometimes too rare to get good
estimates of tf or idf (e.g., names).
A second set of sliders controls the mapping be-
tween aspects and aesthetics for each individual
word. Each aesthetic has a weight for the impor-
tance of rarity (&apos;YRarity) and the importance of fre-
quency (&apos;YFreq), corresponding to the current val-
ues of their respective slider (each in the range
[0,1]). For size, we compute a weight attributed
to each data aspect:
</bodyText>
<equation confidence="0.994158">
WFreq(w) = (1 − &apos;YFreq) + &apos;YFreqtf(w)
</equation>
<bodyText confidence="0.993983666666667">
and similarly for Rarity.
In both cases, the aesthetic’s value is computed
via an equation similar to the following:
</bodyText>
<equation confidence="0.815491">
a(w) = WFreq(w)WRarity(w)&apos;YRangeb
</equation>
<bodyText confidence="0.999930857142857">
where a(w) is either font size or opacity, and b
is some base value of the aesthetic (scaled by a
dynamic range slider, &apos;YRange) and the weights for
frequency and rarity of the word. In this manner,
the weights are multiplicative, so interactions be-
tween the variables (e.g., tf*idf) are apparent.
Though unigram statistics are informative, see-
ing the unigrams in context is also important for
many inference tasks. To enable this, we use reser-
voir sampling (Vitter, 1985) to maintain a repre-
sentative sample of the observed occurrences of
each word in context, which the user can view by
clicking on the word in the wordcloud display.
Examples of the dynamic wordcloud in various
settings can be found in Figure 1, using a set of
tweets containing “Orioles”. The left wordcloud
has tf mapped to size, the center with idf mapped
to size, and the right with both high tf and high
idf mapped to size. We only manipulate the size
aesthetic, since the opacity aesthetic is sometimes
hard to interpret in print. To fit the wordclouds
</bodyText>
<page confidence="0.990016">
26
</page>
<bodyText confidence="0.999914">
to the small format, various values for τFreq and
τRarity are employed, and order is varied – the
left is ordered in descending order in terms of fre-
quency, the center is ordered in descending order
in terms of rarity, and the right is in alphabetical
order.
</bodyText>
<sectionHeader confidence="0.987868" genericHeader="method">
8 Vennclouds
</sectionHeader>
<bodyText confidence="0.961098444444444">
Question (2) – “how are these corpora related” re-
quires only a single change to the dynamic sin-
gle wordcloud described in §7. We refer to two
corpora, left and right, which we abbreviate L
and R (perhaps a set of tweets containing “Ori-
oles” for left and those containing “Nationals” for
right as in Figure 2). For the right documents, let
R = {di, ..., dnR} so |R |= nR and let TR be the
total number of tokens in all the documents in R
</bodyText>
<equation confidence="0.9944945">
TR = � |Td|
dER
</equation>
<bodyText confidence="0.999982">
We separate the wordcloud display into three re-
gions, one devoted to words most closely associ-
ated with R, one devoted to words most closely
associated with L, and one for words that should
be associated with both. “Association” here can be
defined in a number of ways, but for the nonce we
define it as the probability of occurrence in that
corpus – essentially term frequency, normalized
by corpus length. Normalizing by length is re-
quired to prevent bias incurred when the corpora
are different sizes (TL =� TR). Specifically, we
define the number of times w occurs in left (tf) as
</bodyText>
<equation confidence="0.970786">
tfL(w) = � T (w, di)
diEL
</equation>
<bodyText confidence="0.99187">
and this quantity normalized by the number of to-
kens in L,
</bodyText>
<equation confidence="0.994362">
tfL(w) = tfL(w)/TL
</equation>
<bodyText confidence="0.999331">
and this quantity as it relates to the term frequency
of this w in both corpora
</bodyText>
<equation confidence="0.997818">
tfL|R(w) = tfL(w) + tfR(w)
</equation>
<bodyText confidence="0.997121571428571">
Each word is only displayed once in the Ven-
ncloud (see Figure 2, so if a word (w) only occurs
in R, it is always present in the right region, and
likewise for L and left. If w is in both L and R,
we examine the proportion of documents in each
that w is in and use this to determine in which re-
gion it should be displayed. In order to deal with
</bodyText>
<figureCaption confidence="0.9688705">
Figure 2: Three example Vennclouds, with tweets contain-
ing “Orioles” on the left, “Nationals” on the right, and com-
mon words in the middle. From top to bottom we allow pro-
gressively larger common clouds. The large common words
make sense – both teams played a Chicago team and made
the playoffs in the time covered by these corpora.
</figureCaption>
<bodyText confidence="0.98163">
the cases where w occurs in approximately similar
proportions of left and right documents, we have
a center region (in the center in Figure 2). We
define a threshold (τCommon) to concretely define
“approximately similar”. Specifically,
</bodyText>
<listItem confidence="0.962723625">
• if tfR(w) = 0, w is displayed in left.
• if tfL(w) = 0, w is displayed in right.
• if tfR(w) &gt; 0 and tfL(w) &gt; 0,
– if tfR|L(w) &gt; tfL|R(w) + τCommon, w
is displayed in right.
– if tfL|R(w) &gt; tfR|L(w) + τCommon, w
is displayed in left.
– Otherwise, w is displayed in center.
</listItem>
<bodyText confidence="0.99893975">
The user is given a slider to control τCommon, al-
lowing them to determine what value of “approx-
imately similar” best fits the data and their task at
hand.
</bodyText>
<sectionHeader confidence="0.911942" genericHeader="method">
9 Anecdotal Evaluation
</sectionHeader>
<bodyText confidence="0.9997765">
We have not yet done a proper psychophysical
evaluation of the utility of dynamic wordclouds
</bodyText>
<equation confidence="0.463604">
tfL(w)
</equation>
<page confidence="0.923264">
27
</page>
<figure confidence="0.992862950617284">
idf filter size controls opacity controls sort by
PQ entities common cloud
legend do not redraw
highlight keywords
tf filter
Words displayed occur at least 22 and at most 6590 times in the query.
Words displayed occur in fewer than 5 and more than 10000 documents in the whole corpus.
Larger words frequently occur in the query and rarely occur in the corpus (TF*IDF). [TF:0.92,IDF:1]
@
2
nationals
Darker words are more frequent in the query (TF). [TF:1]
am
Words are sorted alphabetically.
eball best
come cubs dc did
getting go going got
here home if
know
louis lt marlins me
nationals
na
[X]
nats white sox south carolina 100 to win 450
p
#orioles welcome to red sox nation orioles&apos; and
nationals&apos; fans #sportsroadhouse
ug y
god damn nats just tried to boo in a dc bar almost got
day t
chased out since my sox are out i just want the cards
s ahigton wahi l h
to do well #problems #mlb
ininning into is it it&apos;s its just
6 7 8 9 ? a about
all
amp and another any are as awesome baby back
bar be because been
before being believe better big boys
bring bullpen by call can can&apos;t
checked chicago
could damn day
division do don&apos;t down east end
even ever every everyone excited fan fans feel
tadium
w/
or others
give
field finally first
has have he hell him his
hope how i i&apos;ll i&apos;m im
from fuck
gonna good great had
game games get
for free
1 1st 2012 3 @orioles against al
an at
baltimore beat
birds
blue buck card
espn
gt hit
johnson keep lead magic mark
md
mlb new o&apos;s
[X]
orio
p
red rep
#orioles 5 things the boston red sox can learn from the
sox ports
baltimore orioles oakland a&apos;s bleacher
#sportsroadhouse
tied
i&apos;m at oriole park at camden yards for chicago white
over photo p
sox vs baltimore orioles baltimore md
go o&apos;s @ oriole park at camden yards for boston red
sox vs baltimore orioles w/ 163 others
l
whit
</figure>
<figureCaption confidence="0.998015">
Figure 3: Screenshot of a Venncloud, with controls. The sliders are accessible from the buttons across the top, displaying as
</figureCaption>
<figure confidence="0.655703333333333">
mae may
h my d
a floating window above the wordcloud itself (replacing the current display of the legend). Also note the examples in the lower
</figure>
<bodyText confidence="0.973723411764706">
of ff h on on l
nt iht o
left and right corners, accessed by clicking on a word of interest (in this case “Sox”).
ur ut pitch ay
and Vennclouds for various tasks as
compared to
their static counterparts (and other visualizations).
In part, this is because such an evaluation requires
selection of inference tasks to be examined, pre-
cisely what we do not claim to be able to do. We
leave for future work the creation and evaluation
of a representative sample of such inference tasks.
We strongly believe that the plural of anecdote
is not data – so these anecdotes are intended as
illustrations of use, rather than some data regard-
ing utility. The dynamic wordclouds and Ven-
nclouds were used on data from across the spec-
trum, from tweets to Shakespeare and political
speeches to health-related conversations in devel-
oping nations. In Shakespeare, character and place
names can easily be highlighted with one set of
slider settings (high t f *idf ), while comparisons
of stopwords are made apparent with another (high
t f , no idf ). Emerging from the debates between
Mitt Romney and Barack Obama are the common
themes that they discuss using similar (economics)
and dissimilar language (Obama talks about the
“affordable care act” and Romney calls it “Oba-
macare”). These wordclouds were also used to do
some introspection on the output of classifiers in
sentiment analysis (Mitchell et al., 2013) and men-
tal health research (Coppersmith et al., 2014b) to
expose the linguistic signals that give rise to suc-
cessful (and unsuccessful) classification.
</bodyText>
<sectionHeader confidence="0.989807" genericHeader="conclusions">
10 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.979827272727273">
Exploratory data analysis tools for human lan-
guage data and inference tasks have long lagged
behind their numerical counterparts, and here we
investigate another step towards filling that need.
Rather than determining the optimal wordcloud,
we enable the wordcloud viewer to adapt the visu-
alization to the data and inference task at hand. We
suspect that the pendulum of control has swung
y
too far, and that there is a subset of the possi-
ble control configurations that produce useful and
informative wordclouds. Work is underway to
collect feedback via instrumented dynamic word-
clouds and Vennclouds as they are used for various
inference tasks to address this.
Previous research, logic, and intuition were
used to create this step, though it requires fur-
ther improvement and validation. We provide
anecdotes about the usefulness of these dynamic
wordclouds, but those anecdotes do not provide
sufficient evidence that this method is somehow
more efficient (in terms of human time) than ex-
isting methods. To make such claims, a controlled
human-factors study is required, investigating (for
a particular inference task) how this method af-
fects the job of an exploratory data analyst. In
the meantime, we hope making the code freely
available1 will better enable our fellow researchers
to perform principled exploratory data analysis of
human language content quickly and encourage a
4/24/14 95
deeper understanding of data, within and across
disciplines.
</bodyText>
<sectionHeader confidence="0.998023" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9988285">
We would like to thank Carey Priebe for in-
sightful discussions on exploratory data analysis,
</bodyText>
<footnote confidence="0.999129">
1from https://github.com/Coppersmith/vennclouds
</footnote>
<page confidence="0.998109">
28
</page>
<bodyText confidence="0.9987868">
Aleksander Yelskiy, Jacqueline Aguilar, Kristy
Hollingshead for their analysis, comments, and
improvements on early versions, and Ainsley
R. Coppersmith for permitting this research to
progress in her early months.
</bodyText>
<sectionHeader confidence="0.994302" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999890434343434">
Scott Bateman, Carl Gutwin, and Miguel Nacenta.
2008. Seeing things in the clouds: the effect of vi-
sual features on tag cloud selections. In Proceedings
of the nineteenth ACM conference on Hypertext and
hypermedia, pages 193–202. ACM.
Quim Castella and Charles A. Sutton. 2013. Word
storms: Multiples of word clouds for visual compar-
ison of documents. CoRR, abs/1301.0503.
Cindy Chung and James W Pennebaker. 2007. The
psychological functions of function words. Social
communication, pages 343–359.
Christopher Collins, Fernanda B Viegas, and Martin
Wattenberg. 2009. Parallel tag clouds to explore
and analyze faceted text corpora. In Visual Analyt-
ics Science and Technology, 2009. VAST 2009. IEEE
Symposium on, pages 91–98. IEEE.
Glen Coppersmith, Mark Dredze, and Craig Harman.
2014a. Quantifying mental health signals in twitter.
In Proceedings of ACL Workshop on Computational
Linguistics and Clinical Psychology. Association for
Computational Linguistics.
Glen Coppersmith, Craig Harman, and Mark Dredze.
2014b. Measuring post traumatic stress disorder in
Twitter. In Proceedings of the International AAAI
Conference on Weblogs and Social Media (ICWSM).
Weiwei Cui, Yingcai Wu, Shixia Liu, Furu Wei,
Michelle X Zhou, and Huamin Qu. 2010. Context
preserving dynamic word cloud visualization. In
Pacific Visualization Symposium (PacificVis), 2010
IEEE, pages 121–128. IEEE.
Jason Davies. 2013. Wordcloud generator using d3,
April.
Micah Dubinko, Ravi Kumar, Joseph Magnani, Jas-
mine Novak, Prabhakar Raghavan, and Andrew
Tomkins. 2007. Visualizing tags over time. ACM
Transactions on the Web (TWEB), 1(2):7.
Jason Feinberg. 2013. Wordle, April.
Patrick Juola. 2006. Authorship attribution. Founda-
tions and Trends in information Retrieval, 1(3):233–
334.
Kathrin Knautz, Simone Soubusta, and Wolfgang G
Stock. 2010. Tag clusters as information retrieval
interfaces. In System Sciences (HICSS), 2010 43rd
Hawaii International Conference on, pages 1–10.
IEEE.
Bongshin Lee, Nathalie Henry Riche, Amy K Karl-
son, and Sheelagh Carpendale. 2010. Spark-
clouds: Visualizing trends in tag clouds. Visualiza-
tion and Computer Graphics, IEEE Transactions on,
16(6):1182–1189.
Margaret Mitchell, Jacqueline Aguilar, Theresa Wil-
son, and Benjamin Van Durme. 2013. Open domain
targeted sentiment. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1643–1654. Association for Com-
putational Linguistics.
Saˇsa Petrovic, Miles Osborne, Richard McCreadie,
Craig Macdonald, Iadh Ounis, and Luke Shrimpton.
2013. Can twitter replace newswire for breaking
news. In Seventh International AAAI Conference on
Weblogs and Social Media.
Paul Rayson and Roger Garside. 2000. Comparing
corpora using frequency profiling. In Proceedings
of the workshop on Comparing Corpora, pages 1–6.
Association for Computational Linguistics.
AW Rivadeneira, Daniel M Gruen, Michael J Muller,
and David R Millen. 2007. Getting our head in the
clouds: toward evaluation studies of tagclouds. In
Proceedings of the SIGCHI conference on Human
factors in computing systems, pages 995–998. ACM.
Johann Schrammel, Michael Leitner, and Manfred
Tscheligi. 2009. Semantically structured tag
clouds: an empirical evaluation of clustered presen-
tation approaches. In Proceedings of the 27th inter-
national conference on Human factors in computing
systems, pages 2037–2040. ACM.
Christin Seifert, Barbara Kump, Wolfgang Kienreich,
Gisela Granitzer, and Michael Granitzer. 2008. On
the beauty and usability of tag clouds. In Informa-
tion Visualisation, 2008. IV’08. 12th International
Conference, pages 17–25. IEEE.
James Sinclair and Michael Cardew-Hall. 2008. The
folksonomy tag cloud: when is it useful? Journal of
Information Science, 34(1):15–29.
Aidan Slingsby, Jason Dykes, Jo Wood, and Keith
Clarke. 2007. Interactive tag maps and tag
clouds for the multiscale exploration of large spatio-
temporal datasets. In Information Visualization,
2007. IV’07. 11th International Conference, pages
497–504. IEEE.
Fernanda B Vi´egas and Martin Wattenberg. 2008.
Timelines tag clouds and the case for vernacular vi-
sualization. interactions, 15(4):49–52.
Jeffrey S Vitter. 1985. Random sampling with a reser-
voir. ACM Transactions on Mathematical Software
(TOMS), 11(1):37–57.
Hadley Wickham. 2009. ggplot2: elegant graphics for
data analysis. Springer Publishing Company, Incor-
porated.
</reference>
<page confidence="0.999114">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.846909">
<title confidence="0.999908">Dynamic Wordclouds and Vennclouds for Exploratory Data Analysis</title>
<author confidence="0.999843">Glen Coppersmith Erin Kelly</author>
<affiliation confidence="0.9801395">Human Language Technology Center of Excellence Department of Defense Johns Hopkins University</affiliation>
<email confidence="0.970095">coppersmith@jhu.eduelkelly8@gmail.com</email>
<abstract confidence="0.994207647058824">a ubiquitous visualization of human language, though it falls short when used for exploratory data analysis. To address some of these shortcomings, we give the viewer explicit control over the creation of the wordcloud, allowing them to interact with it in real time– This allows iterative adaptation of the visualization to the data and inference task at hand. We next present a principled approach to visualization which highlights the similarities and differences between two sets of documents a We make all the visualization code (primarily JavaScript) freely available.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Scott Bateman</author>
<author>Carl Gutwin</author>
<author>Miguel Nacenta</author>
</authors>
<title>Seeing things in the clouds: the effect of visual features on tag cloud selections.</title>
<date>2008</date>
<booktitle>In Proceedings of the nineteenth ACM conference on Hypertext and hypermedia,</booktitle>
<pages>193--202</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5892" citStr="Bateman et al., 2008" startWordPosition="934" endWordPosition="937">engineering than the creation of a static wordcloud, though the depth of extra information conveyed is significant. 3 Wordcloud Aesthetics We refer to each visual component of the visualization as an aesthetic (ala (Wickham, 2009)) – each aesthetic can convey some information to the viewer. For context, the aesthetics of a scatterplot include the x and y position, color, and size of each point. Some are best suited for ordinal data (e.g., font size), while others for categorical data (e.g., font color). Ordinal data can be encoded by font size, the most prominent and noticeable to the viewer (Bateman et al., 2008). Likewise, the opacity (transparency) of the word is a prominent and ordinal aesthetic. The order in which words are displayed can convey a significant amount of information as well, but using order in this fashion generally constrains the use of x and y position. Categorical data can be encoded by the color of each word – both the foreground of the word itself and the background space that surrounds it (though that bandwidth is severely limited by human perception). Likewise for font weight (boldness) and font decoration (italics and underlines). While font face itself could encode a categor</context>
<context position="9714" citStr="Bateman et al., 2008" startWordPosition="1580" endWordPosition="1583">Enumerating all possible inference tasks involving the visualization of natural language is impossible, but the prior art does provide empirical data for some relevant tasks. This further stresses the importance of allowing the user to interact with the visualization, since optimizing the visualization a priori for all inference tasks simultaneously is not possible, much like creating a single plot for all numerical inference tasks is not possible. 5.1 Psychophysical Analyses The quintessential studies on how a wordcloud is interpreted by humans can be found in (Rivadeneira et al., 2007) and (Bateman et al., 2008). They both investigated various measures of impression-forming and recall to determine which aesthetics conveyed information most effectively – font size chief among them. Rivandeneira et al. (Rivadeneira et al., 2007) also found that word-order was important for impression forming (displaying words from most frequent to least frequent was most effective here), while displaying words alphabetically was best when searching for a known word. They also found that users prefer a search box when searching for something specific and known, and a wordcloud for exploratory tasks and things unknown. B</context>
</contexts>
<marker>Bateman, Gutwin, Nacenta, 2008</marker>
<rawString>Scott Bateman, Carl Gutwin, and Miguel Nacenta. 2008. Seeing things in the clouds: the effect of visual features on tag cloud selections. In Proceedings of the nineteenth ACM conference on Hypertext and hypermedia, pages 193–202. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quim Castella</author>
<author>Charles A Sutton</author>
</authors>
<title>Word storms: Multiples of word clouds for visual comparison of documents.</title>
<date>2013</date>
<journal>CoRR,</journal>
<pages>1301--0503</pages>
<contexts>
<context position="12493" citStr="Castella and Sutton, 2013" startWordPosition="2028" endWordPosition="2031">mmary of the results. In both of these cases, a simple static wordcloud is able to provide some useful information to the user, though less research has been done to determine the optimal composition of the wordcloud. What’s more, the need for a dynamic interactive wordcloud was made explicit (Knautz et al., 2010), given the way the users iteratively refined their queries and wordclouds. Question (2) has also been examined. One approach is to make a set of wordclouds with soft constraints that the same word appears in roughly the same position across multiple clouds to facilitate comparisons (Castella and Sutton, 2013). Each of these clouds in a wordstorm visualizes a different collection of documents (e.g., subdivisions via metadata of a larger corpus). Similarly addressing our second question, Parallel Tag Clouds (Collins et al., 2009) allow the comparison of multiple sets of documents (or different partitions of a corpus). This investigation provides a theoretically-justified approach to finding ‘the right’ static wordcloud (for a single inference task), though this does depend on some language-specific resources (e.g., stopword lists and stemming). Interestingly, they opt for ex24 plicit removal of word</context>
</contexts>
<marker>Castella, Sutton, 2013</marker>
<rawString>Quim Castella and Charles A. Sutton. 2013. Word storms: Multiples of word clouds for visual comparison of documents. CoRR, abs/1301.0503.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cindy Chung</author>
<author>James W Pennebaker</author>
</authors>
<title>The psychological functions of function words. Social communication,</title>
<date>2007</date>
<pages>343--359</pages>
<contexts>
<context position="4137" citStr="Chung and Pennebaker, 2007" startWordPosition="645" endWordPosition="649">fication (or idiolect analysis) 22 Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29, Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics attempts attribution of documents (e.g., Shakespeare’s plays or the Federalist papers) by comparing the author’s writing style, focusing on stylistic and contentless words – for a review see (Juola, 2006). Further, some linguistic psychometric analysis depends on the relative distribution of pronouns and other seemingly contentless words (Coppersmith et al., 2014a; Chung and Pennebaker, 2007). Each of these questions involves some analysis of unigram statistics, but exactly what analysis differs significantly, thus no single wordcloud can display all of them. Any static wordcloud is a single point in a distribution of possible wordclouds – one way of calculating statistics from the underlying language and mapping those calculations to the visual representation. Many such combinations and mappings are available, and the optimal wordcloud, like the optimal plot, is a function of the data and the inference task at hand. Thus, we enable the wordcloud viewer to adjust the relationship </context>
</contexts>
<marker>Chung, Pennebaker, 2007</marker>
<rawString>Cindy Chung and James W Pennebaker. 2007. The psychological functions of function words. Social communication, pages 343–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Collins</author>
<author>Fernanda B Viegas</author>
<author>Martin Wattenberg</author>
</authors>
<title>Parallel tag clouds to explore and analyze faceted text corpora.</title>
<date>2009</date>
<booktitle>In Visual Analytics Science and Technology,</booktitle>
<pages>91--98</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="12716" citStr="Collins et al., 2009" startWordPosition="2063" endWordPosition="2066">e, the need for a dynamic interactive wordcloud was made explicit (Knautz et al., 2010), given the way the users iteratively refined their queries and wordclouds. Question (2) has also been examined. One approach is to make a set of wordclouds with soft constraints that the same word appears in roughly the same position across multiple clouds to facilitate comparisons (Castella and Sutton, 2013). Each of these clouds in a wordstorm visualizes a different collection of documents (e.g., subdivisions via metadata of a larger corpus). Similarly addressing our second question, Parallel Tag Clouds (Collins et al., 2009) allow the comparison of multiple sets of documents (or different partitions of a corpus). This investigation provides a theoretically-justified approach to finding ‘the right’ static wordcloud (for a single inference task), though this does depend on some language-specific resources (e.g., stopword lists and stemming). Interestingly, they opt for ex24 plicit removal of words and outliers that the user does not wish to have displayed (an exclusion list), rather than adjusting calculations of the entire cloud to remove them in a principled and fair manner. 5.3 Wordclouds and Metadata Wordclouds</context>
</contexts>
<marker>Collins, Viegas, Wattenberg, 2009</marker>
<rawString>Christopher Collins, Fernanda B Viegas, and Martin Wattenberg. 2009. Parallel tag clouds to explore and analyze faceted text corpora. In Visual Analytics Science and Technology, 2009. VAST 2009. IEEE Symposium on, pages 91–98. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glen Coppersmith</author>
<author>Mark Dredze</author>
<author>Craig Harman</author>
</authors>
<title>Quantifying mental health signals in twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL Workshop on Computational Linguistics and Clinical Psychology. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4107" citStr="Coppersmith et al., 2014" startWordPosition="641" endWordPosition="644">. Separately, author identification (or idiolect analysis) 22 Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29, Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics attempts attribution of documents (e.g., Shakespeare’s plays or the Federalist papers) by comparing the author’s writing style, focusing on stylistic and contentless words – for a review see (Juola, 2006). Further, some linguistic psychometric analysis depends on the relative distribution of pronouns and other seemingly contentless words (Coppersmith et al., 2014a; Chung and Pennebaker, 2007). Each of these questions involves some analysis of unigram statistics, but exactly what analysis differs significantly, thus no single wordcloud can display all of them. Any static wordcloud is a single point in a distribution of possible wordclouds – one way of calculating statistics from the underlying language and mapping those calculations to the visual representation. Many such combinations and mappings are available, and the optimal wordcloud, like the optimal plot, is a function of the data and the inference task at hand. Thus, we enable the wordcloud view</context>
<context position="31263" citStr="Coppersmith et al., 2014" startWordPosition="5384" endWordPosition="5387">ions. In Shakespeare, character and place names can easily be highlighted with one set of slider settings (high t f *idf ), while comparisons of stopwords are made apparent with another (high t f , no idf ). Emerging from the debates between Mitt Romney and Barack Obama are the common themes that they discuss using similar (economics) and dissimilar language (Obama talks about the “affordable care act” and Romney calls it “Obamacare”). These wordclouds were also used to do some introspection on the output of classifiers in sentiment analysis (Mitchell et al., 2013) and mental health research (Coppersmith et al., 2014b) to expose the linguistic signals that give rise to successful (and unsuccessful) classification. 10 Conclusions and Future Directions Exploratory data analysis tools for human language data and inference tasks have long lagged behind their numerical counterparts, and here we investigate another step towards filling that need. Rather than determining the optimal wordcloud, we enable the wordcloud viewer to adapt the visualization to the data and inference task at hand. We suspect that the pendulum of control has swung y too far, and that there is a subset of the possible control configuratio</context>
</contexts>
<marker>Coppersmith, Dredze, Harman, 2014</marker>
<rawString>Glen Coppersmith, Mark Dredze, and Craig Harman. 2014a. Quantifying mental health signals in twitter. In Proceedings of ACL Workshop on Computational Linguistics and Clinical Psychology. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glen Coppersmith</author>
<author>Craig Harman</author>
<author>Mark Dredze</author>
</authors>
<title>Measuring post traumatic stress disorder in Twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM).</booktitle>
<contexts>
<context position="4107" citStr="Coppersmith et al., 2014" startWordPosition="641" endWordPosition="644">. Separately, author identification (or idiolect analysis) 22 Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29, Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics attempts attribution of documents (e.g., Shakespeare’s plays or the Federalist papers) by comparing the author’s writing style, focusing on stylistic and contentless words – for a review see (Juola, 2006). Further, some linguistic psychometric analysis depends on the relative distribution of pronouns and other seemingly contentless words (Coppersmith et al., 2014a; Chung and Pennebaker, 2007). Each of these questions involves some analysis of unigram statistics, but exactly what analysis differs significantly, thus no single wordcloud can display all of them. Any static wordcloud is a single point in a distribution of possible wordclouds – one way of calculating statistics from the underlying language and mapping those calculations to the visual representation. Many such combinations and mappings are available, and the optimal wordcloud, like the optimal plot, is a function of the data and the inference task at hand. Thus, we enable the wordcloud view</context>
<context position="31263" citStr="Coppersmith et al., 2014" startWordPosition="5384" endWordPosition="5387">ions. In Shakespeare, character and place names can easily be highlighted with one set of slider settings (high t f *idf ), while comparisons of stopwords are made apparent with another (high t f , no idf ). Emerging from the debates between Mitt Romney and Barack Obama are the common themes that they discuss using similar (economics) and dissimilar language (Obama talks about the “affordable care act” and Romney calls it “Obamacare”). These wordclouds were also used to do some introspection on the output of classifiers in sentiment analysis (Mitchell et al., 2013) and mental health research (Coppersmith et al., 2014b) to expose the linguistic signals that give rise to successful (and unsuccessful) classification. 10 Conclusions and Future Directions Exploratory data analysis tools for human language data and inference tasks have long lagged behind their numerical counterparts, and here we investigate another step towards filling that need. Rather than determining the optimal wordcloud, we enable the wordcloud viewer to adapt the visualization to the data and inference task at hand. We suspect that the pendulum of control has swung y too far, and that there is a subset of the possible control configuratio</context>
</contexts>
<marker>Coppersmith, Harman, Dredze, 2014</marker>
<rawString>Glen Coppersmith, Craig Harman, and Mark Dredze. 2014b. Measuring post traumatic stress disorder in Twitter. In Proceedings of the International AAAI Conference on Weblogs and Social Media (ICWSM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Cui</author>
<author>Yingcai Wu</author>
<author>Shixia Liu</author>
<author>Furu Wei</author>
<author>Michelle X Zhou</author>
<author>Huamin Qu</author>
</authors>
<title>Context preserving dynamic word cloud visualization.</title>
<date>2010</date>
<booktitle>In Pacific Visualization Symposium (PacificVis), 2010 IEEE,</booktitle>
<pages>121--128</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="13624" citStr="Cui et al., 2010" startWordPosition="2205" endWordPosition="2208">stopword lists and stemming). Interestingly, they opt for ex24 plicit removal of words and outliers that the user does not wish to have displayed (an exclusion list), rather than adjusting calculations of the entire cloud to remove them in a principled and fair manner. 5.3 Wordclouds and Metadata Wordclouds have previously been extended to convey additional information, though these adaptations have been optimized generally for artistic purposes rather than exploratory data analysis. Wordclouds can been used to display how language interacts with a temporal dimension in (Dubinko et al., 2007; Cui et al., 2010; Lee et al., 2010). Dubinko and colleagues created a tag cloud variant that displays trends in tag usage over time, coupled with images that have that tag (Dubinko et al., 2007). An information-theoretic approach to displaying information changing in time gives rise to a theoretically grounded approach for displaying pointwise tag clouds, and highlighting those pieces that have changed significantly as compared to a previous time period (Cui et al., 2010). This can be viewed as measuring the change in overall language usage over time. In contrast, using spark lines on each individual word or </context>
</contexts>
<marker>Cui, Wu, Liu, Wei, Zhou, Qu, 2010</marker>
<rawString>Weiwei Cui, Yingcai Wu, Shixia Liu, Furu Wei, Michelle X Zhou, and Huamin Qu. 2010. Context preserving dynamic word cloud visualization. In Pacific Visualization Symposium (PacificVis), 2010 IEEE, pages 121–128. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Davies</author>
</authors>
<title>Wordcloud generator using d3,</title>
<date>2013</date>
<contexts>
<context position="8836" citStr="Davies, 2013" startWordPosition="1445" endWordPosition="1446">sualization, but to do this algorithmically for all possible inference tasks remains a challenge. We, instead, enable the user to adjust the dynamic range of the visualization explicitly. 23 5 Prior Art Wordclouds have a mixed history, stemming from Jim Flanagan’s “Search Referral Zeitgeist”, used to display aggregate information about websites linking to his, to its adoption as a visual gimmick, to the paradoxical claim that ‘wordclouds work in practice, but not in theory’ (see (Vi´egas and Wattenberg, 2008) for more). A number of wordcloud-generators exist on the web (e.g., (Feinberg, 2013; Davies, 2013)), though these tend towards creating art rather than informative visualizations. The two cited do allow the user limited interaction with some of the visual aesthetics, though not of sufficient scope or response time for general exploratory data analysis. Enumerating all possible inference tasks involving the visualization of natural language is impossible, but the prior art does provide empirical data for some relevant tasks. This further stresses the importance of allowing the user to interact with the visualization, since optimizing the visualization a priori for all inference tasks simult</context>
</contexts>
<marker>Davies, 2013</marker>
<rawString>Jason Davies. 2013. Wordcloud generator using d3, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micah Dubinko</author>
<author>Ravi Kumar</author>
<author>Joseph Magnani</author>
<author>Jasmine Novak</author>
<author>Prabhakar Raghavan</author>
<author>Andrew Tomkins</author>
</authors>
<title>Visualizing tags over time.</title>
<date>2007</date>
<journal>ACM Transactions on the Web (TWEB),</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="13606" citStr="Dubinko et al., 2007" startWordPosition="2200" endWordPosition="2204">ific resources (e.g., stopword lists and stemming). Interestingly, they opt for ex24 plicit removal of words and outliers that the user does not wish to have displayed (an exclusion list), rather than adjusting calculations of the entire cloud to remove them in a principled and fair manner. 5.3 Wordclouds and Metadata Wordclouds have previously been extended to convey additional information, though these adaptations have been optimized generally for artistic purposes rather than exploratory data analysis. Wordclouds can been used to display how language interacts with a temporal dimension in (Dubinko et al., 2007; Cui et al., 2010; Lee et al., 2010). Dubinko and colleagues created a tag cloud variant that displays trends in tag usage over time, coupled with images that have that tag (Dubinko et al., 2007). An information-theoretic approach to displaying information changing in time gives rise to a theoretically grounded approach for displaying pointwise tag clouds, and highlighting those pieces that have changed significantly as compared to a previous time period (Cui et al., 2010). This can be viewed as measuring the change in overall language usage over time. In contrast, using spark lines on each i</context>
</contexts>
<marker>Dubinko, Kumar, Magnani, Novak, Raghavan, Tomkins, 2007</marker>
<rawString>Micah Dubinko, Ravi Kumar, Joseph Magnani, Jasmine Novak, Prabhakar Raghavan, and Andrew Tomkins. 2007. Visualizing tags over time. ACM Transactions on the Web (TWEB), 1(2):7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Feinberg</author>
</authors>
<date>2013</date>
<location>Wordle,</location>
<contexts>
<context position="8821" citStr="Feinberg, 2013" startWordPosition="1443" endWordPosition="1444">art of a good visualization, but to do this algorithmically for all possible inference tasks remains a challenge. We, instead, enable the user to adjust the dynamic range of the visualization explicitly. 23 5 Prior Art Wordclouds have a mixed history, stemming from Jim Flanagan’s “Search Referral Zeitgeist”, used to display aggregate information about websites linking to his, to its adoption as a visual gimmick, to the paradoxical claim that ‘wordclouds work in practice, but not in theory’ (see (Vi´egas and Wattenberg, 2008) for more). A number of wordcloud-generators exist on the web (e.g., (Feinberg, 2013; Davies, 2013)), though these tend towards creating art rather than informative visualizations. The two cited do allow the user limited interaction with some of the visual aesthetics, though not of sufficient scope or response time for general exploratory data analysis. Enumerating all possible inference tasks involving the visualization of natural language is impossible, but the prior art does provide empirical data for some relevant tasks. This further stresses the importance of allowing the user to interact with the visualization, since optimizing the visualization a priori for all inferen</context>
</contexts>
<marker>Feinberg, 2013</marker>
<rawString>Jason Feinberg. 2013. Wordle, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Juola</author>
</authors>
<title>Authorship attribution. Foundations and Trends in information Retrieval,</title>
<date>2006</date>
<volume>1</volume>
<issue>3</issue>
<pages>334</pages>
<contexts>
<context position="3946" citStr="Juola, 2006" startWordPosition="620" endWordPosition="621">ght want to examine a collection of social media missives, too numerous to read individually, perhaps to detect emerging news (Petrovic et al., 2013). Separately, author identification (or idiolect analysis) 22 Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29, Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics attempts attribution of documents (e.g., Shakespeare’s plays or the Federalist papers) by comparing the author’s writing style, focusing on stylistic and contentless words – for a review see (Juola, 2006). Further, some linguistic psychometric analysis depends on the relative distribution of pronouns and other seemingly contentless words (Coppersmith et al., 2014a; Chung and Pennebaker, 2007). Each of these questions involves some analysis of unigram statistics, but exactly what analysis differs significantly, thus no single wordcloud can display all of them. Any static wordcloud is a single point in a distribution of possible wordclouds – one way of calculating statistics from the underlying language and mapping those calculations to the visual representation. Many such combinations and mappi</context>
</contexts>
<marker>Juola, 2006</marker>
<rawString>Patrick Juola. 2006. Authorship attribution. Foundations and Trends in information Retrieval, 1(3):233– 334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Knautz</author>
<author>Simone Soubusta</author>
<author>Wolfgang G Stock</author>
</authors>
<title>Tag clusters as information retrieval interfaces.</title>
<date>2010</date>
<booktitle>In System Sciences (HICSS), 2010 43rd Hawaii International Conference on,</booktitle>
<pages>1--10</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="11836" citStr="Knautz et al., 2010" startWordPosition="1918" endWordPosition="1921">. 5.2 Wordclouds as a tool Illustrative investigations of the wordcloud as a tool for exploratory data analysis are few, but encouraging. In relation to question (1), even static wordclouds can be useful for this task. Users performing an open-ended search task preferred using a wordcloud to a search box (Sinclair and Cardew-Hall, 2008), possibly because the wordcloud prevented them from having to hypothesize what might be in the collection before searching for it. Similarly, wordclouds can be used as a follow-up display of search results from a query performed via a standard text search box (Knautz et al., 2010), providing the user a crude summary of the results. In both of these cases, a simple static wordcloud is able to provide some useful information to the user, though less research has been done to determine the optimal composition of the wordcloud. What’s more, the need for a dynamic interactive wordcloud was made explicit (Knautz et al., 2010), given the way the users iteratively refined their queries and wordclouds. Question (2) has also been examined. One approach is to make a set of wordclouds with soft constraints that the same word appears in roughly the same position across multiple clo</context>
</contexts>
<marker>Knautz, Soubusta, Stock, 2010</marker>
<rawString>Kathrin Knautz, Simone Soubusta, and Wolfgang G Stock. 2010. Tag clusters as information retrieval interfaces. In System Sciences (HICSS), 2010 43rd Hawaii International Conference on, pages 1–10. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bongshin Lee</author>
<author>Nathalie Henry Riche</author>
<author>Amy K Karlson</author>
<author>Sheelagh Carpendale</author>
</authors>
<title>Sparkclouds: Visualizing trends in tag clouds. Visualization and Computer Graphics,</title>
<date>2010</date>
<journal>IEEE Transactions on,</journal>
<volume>16</volume>
<issue>6</issue>
<contexts>
<context position="13643" citStr="Lee et al., 2010" startWordPosition="2209" endWordPosition="2212"> stemming). Interestingly, they opt for ex24 plicit removal of words and outliers that the user does not wish to have displayed (an exclusion list), rather than adjusting calculations of the entire cloud to remove them in a principled and fair manner. 5.3 Wordclouds and Metadata Wordclouds have previously been extended to convey additional information, though these adaptations have been optimized generally for artistic purposes rather than exploratory data analysis. Wordclouds can been used to display how language interacts with a temporal dimension in (Dubinko et al., 2007; Cui et al., 2010; Lee et al., 2010). Dubinko and colleagues created a tag cloud variant that displays trends in tag usage over time, coupled with images that have that tag (Dubinko et al., 2007). An information-theoretic approach to displaying information changing in time gives rise to a theoretically grounded approach for displaying pointwise tag clouds, and highlighting those pieces that have changed significantly as compared to a previous time period (Cui et al., 2010). This can be viewed as measuring the change in overall language usage over time. In contrast, using spark lines on each individual word or tag can convey temp</context>
</contexts>
<marker>Lee, Riche, Karlson, Carpendale, 2010</marker>
<rawString>Bongshin Lee, Nathalie Henry Riche, Amy K Karlson, and Sheelagh Carpendale. 2010. Sparkclouds: Visualizing trends in tag clouds. Visualization and Computer Graphics, IEEE Transactions on, 16(6):1182–1189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret Mitchell</author>
<author>Jacqueline Aguilar</author>
<author>Theresa Wilson</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Open domain targeted sentiment.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1643--1654</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Mitchell, Aguilar, Wilson, Van Durme, 2013</marker>
<rawString>Margaret Mitchell, Jacqueline Aguilar, Theresa Wilson, and Benjamin Van Durme. 2013. Open domain targeted sentiment. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1643–1654. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇsa Petrovic</author>
<author>Miles Osborne</author>
<author>Richard McCreadie</author>
<author>Craig Macdonald</author>
<author>Iadh Ounis</author>
<author>Luke Shrimpton</author>
</authors>
<title>Can twitter replace newswire for breaking news.</title>
<date>2013</date>
<booktitle>In Seventh International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="3483" citStr="Petrovic et al., 2013" startWordPosition="553" endWordPosition="556"> a more useful version of the wordcloud. Question (1) is addressed in §7, and with only a small further expansion described in §8, an approach to (2) becomes evident. 2 Motivating Inference Tasks Exploratory data analysis on human language encompasses a diverse set of language and inference tasks, so we select the following subset for their variety. One task in line with question (1) is getting the general subject of a corpus, highlighting content-bearing words. One might want to examine a collection of social media missives, too numerous to read individually, perhaps to detect emerging news (Petrovic et al., 2013). Separately, author identification (or idiolect analysis) 22 Proceedings of the Workshop on Interactive Language Learning, Visualization, and Interfaces, pages 22–29, Baltimore, Maryland, USA, June 27, 2014. @c 2014 Association for Computational Linguistics attempts attribution of documents (e.g., Shakespeare’s plays or the Federalist papers) by comparing the author’s writing style, focusing on stylistic and contentless words – for a review see (Juola, 2006). Further, some linguistic psychometric analysis depends on the relative distribution of pronouns and other seemingly contentless words (</context>
</contexts>
<marker>Petrovic, Osborne, McCreadie, Macdonald, Ounis, Shrimpton, 2013</marker>
<rawString>Saˇsa Petrovic, Miles Osborne, Richard McCreadie, Craig Macdonald, Iadh Ounis, and Luke Shrimpton. 2013. Can twitter replace newswire for breaking news. In Seventh International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Rayson</author>
<author>Roger Garside</author>
</authors>
<title>Comparing corpora using frequency profiling.</title>
<date>2000</date>
<booktitle>In Proceedings of the workshop on Comparing Corpora,</booktitle>
<pages>1--6</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4968" citStr="Rayson and Garside, 2000" startWordPosition="785" endWordPosition="788">int in a distribution of possible wordclouds – one way of calculating statistics from the underlying language and mapping those calculations to the visual representation. Many such combinations and mappings are available, and the optimal wordcloud, like the optimal plot, is a function of the data and the inference task at hand. Thus, we enable the wordcloud viewer to adjust the relationship between the aspects of the data and the aesthetics of the display, which allows them to view different points in the distribution of possible wordclouds. The dynamic wordcloud was implicitly called for in (Rayson and Garside, 2000) since human expertise (specifically knowledge of broader contexts and common sense) is needed to separate meaningful and non-meaningful differences in wordclouds. We enable this dynamic interaction between human and visualization in realtime with a simple user interface, requiring only a modicum more engineering than the creation of a static wordcloud, though the depth of extra information conveyed is significant. 3 Wordcloud Aesthetics We refer to each visual component of the visualization as an aesthetic (ala (Wickham, 2009)) – each aesthetic can convey some information to the viewer. For c</context>
</contexts>
<marker>Rayson, Garside, 2000</marker>
<rawString>Paul Rayson and Roger Garside. 2000. Comparing corpora using frequency profiling. In Proceedings of the workshop on Comparing Corpora, pages 1–6. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AW Rivadeneira</author>
<author>Daniel M Gruen</author>
<author>Michael J Muller</author>
<author>David R Millen</author>
</authors>
<title>Getting our head in the clouds: toward evaluation studies of tagclouds.</title>
<date>2007</date>
<booktitle>In Proceedings of the SIGCHI conference on Human factors in computing systems,</booktitle>
<pages>995--998</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9687" citStr="Rivadeneira et al., 2007" startWordPosition="1574" endWordPosition="1578">ral exploratory data analysis. Enumerating all possible inference tasks involving the visualization of natural language is impossible, but the prior art does provide empirical data for some relevant tasks. This further stresses the importance of allowing the user to interact with the visualization, since optimizing the visualization a priori for all inference tasks simultaneously is not possible, much like creating a single plot for all numerical inference tasks is not possible. 5.1 Psychophysical Analyses The quintessential studies on how a wordcloud is interpreted by humans can be found in (Rivadeneira et al., 2007) and (Bateman et al., 2008). They both investigated various measures of impression-forming and recall to determine which aesthetics conveyed information most effectively – font size chief among them. Rivandeneira et al. (Rivadeneira et al., 2007) also found that word-order was important for impression forming (displaying words from most frequent to least frequent was most effective here), while displaying words alphabetically was best when searching for a known word. They also found that users prefer a search box when searching for something specific and known, and a wordcloud for exploratory </context>
</contexts>
<marker>Rivadeneira, Gruen, Muller, Millen, 2007</marker>
<rawString>AW Rivadeneira, Daniel M Gruen, Michael J Muller, and David R Millen. 2007. Getting our head in the clouds: toward evaluation studies of tagclouds. In Proceedings of the SIGCHI conference on Human factors in computing systems, pages 995–998. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johann Schrammel</author>
<author>Michael Leitner</author>
<author>Manfred Tscheligi</author>
</authors>
<title>Semantically structured tag clouds: an empirical evaluation of clustered presentation approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of the 27th international conference on Human factors in computing systems,</booktitle>
<pages>2037--2040</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="10830" citStr="Schrammel et al., 2009" startWordPosition="1755" endWordPosition="1758">hen searching for something specific and known, and a wordcloud for exploratory tasks and things unknown. Bateman et al. (Bateman et al., 2008) examined the relative utility of other aesthetics to convey information, finding that font-weight (boldness) and intensity (opacity) are effective, but not as good as font-size. Aesthetics such as color, number of characters or the area covered by the word were less effective. Significant research has gone in to the placement of words in the wordcloud (e.g., (Seifert et al., 2008)), though seemingly little information can be conveyed by these layouts (Schrammel et al., 2009). Indeed, (Rivadeneira et al., 2007) indicates that words directly adjacent to the largest word in the wordcloud had slightly worse recall than those not-directly-adjacent – in essence, getting the most important words in the center may be counterproductive. Thus we eschew these algorithms in favor of more interpretable (but perhaps less aesthetically pleasing) linear ordered layouts. 5.2 Wordclouds as a tool Illustrative investigations of the wordcloud as a tool for exploratory data analysis are few, but encouraging. In relation to question (1), even static wordclouds can be useful for this t</context>
</contexts>
<marker>Schrammel, Leitner, Tscheligi, 2009</marker>
<rawString>Johann Schrammel, Michael Leitner, and Manfred Tscheligi. 2009. Semantically structured tag clouds: an empirical evaluation of clustered presentation approaches. In Proceedings of the 27th international conference on Human factors in computing systems, pages 2037–2040. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christin Seifert</author>
<author>Barbara Kump</author>
<author>Wolfgang Kienreich</author>
<author>Gisela Granitzer</author>
<author>Michael Granitzer</author>
</authors>
<title>On the beauty and usability of tag clouds.</title>
<date>2008</date>
<booktitle>In Information Visualisation, 2008. IV’08. 12th International Conference,</booktitle>
<pages>17--25</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="10734" citStr="Seifert et al., 2008" startWordPosition="1741" endWordPosition="1744">lly was best when searching for a known word. They also found that users prefer a search box when searching for something specific and known, and a wordcloud for exploratory tasks and things unknown. Bateman et al. (Bateman et al., 2008) examined the relative utility of other aesthetics to convey information, finding that font-weight (boldness) and intensity (opacity) are effective, but not as good as font-size. Aesthetics such as color, number of characters or the area covered by the word were less effective. Significant research has gone in to the placement of words in the wordcloud (e.g., (Seifert et al., 2008)), though seemingly little information can be conveyed by these layouts (Schrammel et al., 2009). Indeed, (Rivadeneira et al., 2007) indicates that words directly adjacent to the largest word in the wordcloud had slightly worse recall than those not-directly-adjacent – in essence, getting the most important words in the center may be counterproductive. Thus we eschew these algorithms in favor of more interpretable (but perhaps less aesthetically pleasing) linear ordered layouts. 5.2 Wordclouds as a tool Illustrative investigations of the wordcloud as a tool for exploratory data analysis are fe</context>
</contexts>
<marker>Seifert, Kump, Kienreich, Granitzer, Granitzer, 2008</marker>
<rawString>Christin Seifert, Barbara Kump, Wolfgang Kienreich, Gisela Granitzer, and Michael Granitzer. 2008. On the beauty and usability of tag clouds. In Information Visualisation, 2008. IV’08. 12th International Conference, pages 17–25. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Sinclair</author>
<author>Michael Cardew-Hall</author>
</authors>
<title>The folksonomy tag cloud: when is it useful?</title>
<date>2008</date>
<journal>Journal of Information Science,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="11554" citStr="Sinclair and Cardew-Hall, 2008" startWordPosition="1871" endWordPosition="1874">rd in the wordcloud had slightly worse recall than those not-directly-adjacent – in essence, getting the most important words in the center may be counterproductive. Thus we eschew these algorithms in favor of more interpretable (but perhaps less aesthetically pleasing) linear ordered layouts. 5.2 Wordclouds as a tool Illustrative investigations of the wordcloud as a tool for exploratory data analysis are few, but encouraging. In relation to question (1), even static wordclouds can be useful for this task. Users performing an open-ended search task preferred using a wordcloud to a search box (Sinclair and Cardew-Hall, 2008), possibly because the wordcloud prevented them from having to hypothesize what might be in the collection before searching for it. Similarly, wordclouds can be used as a follow-up display of search results from a query performed via a standard text search box (Knautz et al., 2010), providing the user a crude summary of the results. In both of these cases, a simple static wordcloud is able to provide some useful information to the user, though less research has been done to determine the optimal composition of the wordcloud. What’s more, the need for a dynamic interactive wordcloud was made ex</context>
</contexts>
<marker>Sinclair, Cardew-Hall, 2008</marker>
<rawString>James Sinclair and Michael Cardew-Hall. 2008. The folksonomy tag cloud: when is it useful? Journal of Information Science, 34(1):15–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aidan Slingsby</author>
<author>Jason Dykes</author>
<author>Jo Wood</author>
<author>Keith Clarke</author>
</authors>
<title>Interactive tag maps and tag clouds for the multiscale exploration of large spatiotemporal datasets.</title>
<date>2007</date>
<booktitle>In Information Visualization, 2007. IV’07. 11th International Conference,</booktitle>
<pages>497--504</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="14529" citStr="Slingsby et al., 2007" startWordPosition="2354" endWordPosition="2357">lly grounded approach for displaying pointwise tag clouds, and highlighting those pieces that have changed significantly as compared to a previous time period (Cui et al., 2010). This can be viewed as measuring the change in overall language usage over time. In contrast, using spark lines on each individual word or tag can convey temporal trends for individual words (Lee et al., 2010). Meanwhile, combining tag clouds with geospatial data yields a visualization where words can be displayed on a map of the world in locations they are frequently tagged in, labeling famous landmarks, for example (Slingsby et al., 2007). 6 Desiderata In light of the diverse inference tasks (§2) and prior art (§5), the following desiderata emerge for the visualization. These desiderata are explicit choices, not all of which are ideal for all inference tasks. Thus, chief among them is the first: flexibility to allow maximum extensions and modifications as needed. Flexible and adjustable in real time: Any single static wordcloud is guaranteed to be suboptimal for at least some inference tasks, so allowing the user to adjust the aspect-to-aesthetic mapping of the wordcloud in real time enables adaptation of the visualization to </context>
</contexts>
<marker>Slingsby, Dykes, Wood, Clarke, 2007</marker>
<rawString>Aidan Slingsby, Jason Dykes, Jo Wood, and Keith Clarke. 2007. Interactive tag maps and tag clouds for the multiscale exploration of large spatiotemporal datasets. In Information Visualization, 2007. IV’07. 11th International Conference, pages 497–504. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernanda B Vi´egas</author>
<author>Martin Wattenberg</author>
</authors>
<title>Timelines tag clouds and the case for vernacular visualization. interactions,</title>
<date>2008</date>
<pages>15--4</pages>
<marker>Vi´egas, Wattenberg, 2008</marker>
<rawString>Fernanda B Vi´egas and Martin Wattenberg. 2008. Timelines tag clouds and the case for vernacular visualization. interactions, 15(4):49–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey S Vitter</author>
</authors>
<title>Random sampling with a reservoir.</title>
<date>1985</date>
<journal>ACM Transactions on Mathematical Software (TOMS),</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="24180" citStr="Vitter, 1985" startWordPosition="4083" endWordPosition="4084">rly for Rarity. In both cases, the aesthetic’s value is computed via an equation similar to the following: a(w) = WFreq(w)WRarity(w)&apos;YRangeb where a(w) is either font size or opacity, and b is some base value of the aesthetic (scaled by a dynamic range slider, &apos;YRange) and the weights for frequency and rarity of the word. In this manner, the weights are multiplicative, so interactions between the variables (e.g., tf*idf) are apparent. Though unigram statistics are informative, seeing the unigrams in context is also important for many inference tasks. To enable this, we use reservoir sampling (Vitter, 1985) to maintain a representative sample of the observed occurrences of each word in context, which the user can view by clicking on the word in the wordcloud display. Examples of the dynamic wordcloud in various settings can be found in Figure 1, using a set of tweets containing “Orioles”. The left wordcloud has tf mapped to size, the center with idf mapped to size, and the right with both high tf and high idf mapped to size. We only manipulate the size aesthetic, since the opacity aesthetic is sometimes hard to interpret in print. To fit the wordclouds 26 to the small format, various values for </context>
</contexts>
<marker>Vitter, 1985</marker>
<rawString>Jeffrey S Vitter. 1985. Random sampling with a reservoir. ACM Transactions on Mathematical Software (TOMS), 11(1):37–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hadley Wickham</author>
</authors>
<title>ggplot2: elegant graphics for data analysis.</title>
<date>2009</date>
<publisher>Springer Publishing Company, Incorporated.</publisher>
<contexts>
<context position="5501" citStr="Wickham, 2009" startWordPosition="869" endWordPosition="870">ds. The dynamic wordcloud was implicitly called for in (Rayson and Garside, 2000) since human expertise (specifically knowledge of broader contexts and common sense) is needed to separate meaningful and non-meaningful differences in wordclouds. We enable this dynamic interaction between human and visualization in realtime with a simple user interface, requiring only a modicum more engineering than the creation of a static wordcloud, though the depth of extra information conveyed is significant. 3 Wordcloud Aesthetics We refer to each visual component of the visualization as an aesthetic (ala (Wickham, 2009)) – each aesthetic can convey some information to the viewer. For context, the aesthetics of a scatterplot include the x and y position, color, and size of each point. Some are best suited for ordinal data (e.g., font size), while others for categorical data (e.g., font color). Ordinal data can be encoded by font size, the most prominent and noticeable to the viewer (Bateman et al., 2008). Likewise, the opacity (transparency) of the word is a prominent and ordinal aesthetic. The order in which words are displayed can convey a significant amount of information as well, but using order in this f</context>
<context position="7660" citStr="Wickham, 2009" startWordPosition="1253" endWordPosition="1254">oken (w) as a single usage of a word in a document. We can observe multiple word tokens (w) of the same word (w) in a single document (d). For any document d we represent the term frequency of w as tfd(w). Similarly, the inverse document frequency of w as idf(w). A combination of tf and idf is often used to determine important words in a document or corpus. We focus on tf and idf here, but this is just an example of an ordinal value associated with a word, there are many other such word-ordinal pairings that are worth exploring (e.g., weights in a classifier). The dynamic range (“scaling” in (Wickham, 2009)) also needs to be considered, since the data has a natural dynamic range – where meaningful differences can be observed (unsurprisingly, the definition of meaningful depends on the inference task). Likewise, each aesthetic has a range of values for which the users can perceive and differentiate (e.g., words in a font size too small are illegible, those too large prevent other words from being displayed; not all differences are perceptible). Mapping the relevant dynamic range of the data to the dynamic range of the visualization is at the heart of a good visualization, but to do this algorithm</context>
</contexts>
<marker>Wickham, 2009</marker>
<rawString>Hadley Wickham. 2009. ggplot2: elegant graphics for data analysis. Springer Publishing Company, Incorporated.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>