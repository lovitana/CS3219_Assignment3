<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031072">
<title confidence="0.990755">
Disambiguation of Period Characters in Clinical Narratives
</title>
<author confidence="0.996638">
Markus Kreuzthaler and Stefan Schulz
</author>
<affiliation confidence="0.997952">
Institute for Medical Informatics, Statistics and Documentation
Medical University of Graz
</affiliation>
<email confidence="0.966264">
&lt;markus.kreuzthaler,stefan.schulz&gt;@medunigraz.at
</email>
<sectionHeader confidence="0.993018" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998781875">
The period character’s meaning is highly
ambiguous due to the frequency of ab-
breviations that require to be followed
by a period. We have developed a hy-
brid method for period character disam-
biguation and the identification of abbre-
viations, combining rules that explore reg-
ularities in the right context of the pe-
riod with lexicon-based, statistical meth-
ods which scrutinize the preceding token.
The texts under scrutiny are clinical dis-
charge summaries. Both abbreviation de-
tection and sentence delimitation showed
an accuracy of about 93%. An error anal-
ysis demonstrated potential for further im-
provements.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99809394117647">
The full stop, or period character, is ambiguous.
As well as its use as a sentence delimiter, it is often
collocated with abbreviations (“Prof.”), occurs in
numeric expressions (“13.2 mg”), including dates,
and appears in a series of special names such as
Web addresses. Minor variations exist between
languages and dialects (for example the use of the
period as decimal delimiter), and rule variations
exist that guide its collocation with abbreviations.
The character-wise analysis of text can produce a
clear distinction between (i) period characters that
are enclosed between two alphanumeric charac-
ters, and (ii) period characters that are adjacent to
at least one non-alphabetic character. Whereas in
the former case the period character can be consid-
ered an internal part of a token, the latter allows for
two interpretations:
</bodyText>
<listItem confidence="0.999416">
1. Period characters that are mandatorily collo-
cated with abbreviations; and
2. Period characters as sentence delimiters.
</listItem>
<bodyText confidence="0.99150125">
We focus on text produced by physicians at
the point of care, either directly or via dictation.
The sublanguage of clinical narratives is charac-
terized, among other peculiarities such as mis-
spellings, punctuation errors, and incomplete sen-
tences, by the abundance of acronyms and abbre-
viations (Meystre et al., 2008). It is for this reason
that we focus here on the use of the period char-
acter to distinguish between sentence limits and
abbreviations.
A snippet from a medical text illustrates some
typical phenomena:
</bodyText>
<listItem confidence="0.99267225">
3. St.p. TE eines exulz.
sek.knot.SSM (C43.5) li Lab.
majus. Level IV, 2,42 mm
Tumordurchm.
</listItem>
<bodyText confidence="0.999533545454545">
In “3.” the period marks an ordinal num-
ber; “St.p.” is the abbreviation of “Status
post” (state after); “TE” is an acronym de-
rived from “Totale Exzision”. “Exulz.” and
“Tumordurchm.” are ad-hoc abbreviations for
“exulzerierendes” and “Tumordurchmesser” (tu-
mour diameter), respectively. “sek.knot.SSM”
is an ill-formed agglutination of two abbrevia-
tions and one acronym. In correctly formatted
text, they would be separated by spaces (“sek.
knot. SSM”). The abbreviation “sek.” (sec-
ondary) is written in a common lexicalized form,
whereas “knot.” is, once again, an ad-hoc cre-
ation. “SSM” is an acronym for “Superfiziell Spre-
itendes Melanom”. “C43.5” is a code from the
International Classification of Diseases1. “Lab.”
means “Labium”, a common anatomical abbrevi-
ation. “IV” is not an acronym, but a Roman num-
ber. “2,42” is a decimal number, demonstrating
that the comma rather than the period is used as
a decimal separator in German texts. Finally, the
abbreviation “Tumordurchm.” exemplifies that
</bodyText>
<footnote confidence="0.992505">
1http://www.who.int/classifications/icd/en/
</footnote>
<page confidence="0.976163">
96
</page>
<note confidence="0.6930585">
Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (Louhi) @ EACL 2014, pages 96–100,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997428125">
the period can play a double role, viz. to mark an
abbreviation and to conclude a sentence.
In this paper we will describe and evaluate a
methodology that is able to identify and distin-
guish the following: (i) periods that act as sentence
delimiters after ordinary words (such as the period
after “majus”) marked as NSD (normal sentence
delimiter); (ii) periods as abbreviation markers in
the middle of a sentence, marked as MAM (mid-
sentence abbreviation marker), and (iii) periods
that are both abbreviation markers and sentence
delimiters, marked as EAM (end-sentence abbre-
viation marker). From this ternary distinction, two
binary tasks can be derived, viz. the detection of
abbreviations (MAM and EAM), and the detection
of sentence endings (NSD and EAM).
</bodyText>
<sectionHeader confidence="0.983059" genericHeader="introduction">
2 Materials and Methods
</sectionHeader>
<subsectionHeader confidence="0.875384">
2.1 Data
</subsectionHeader>
<bodyText confidence="0.999992814814815">
We used 1,696 discharge summaries extracted and
anonymized from a clinical information system.
They had an average word count of 302, with a
mean of 55 period characters per document. The
texts were divided into a learning set (1.526 doc-
uments) and an evaluation set (170 documents).
Two word lists were created in advance: (i) a med-
ical domain dictionary (MDDict) with a high cov-
erage of domain-specific terms, excluding abbre-
viations, and (ii) a closed-class dictionary (CC-
Dict) containing common, domain-independent
word forms.
For MDDict, words were harvested from
three sources: a free dictionary of contempo-
rary German2, a word list created out of raw
text extracted from a medical dictionary on CD-
ROM (Pschyrembel, 1997), and medical texts and
forum postings from a patient-centered website3.
The final list comprised approximately 1.45 mil-
lion types, which were subsequently indexed with
Lucene4. This dictionary was modified during a
second step by two Web resources containing
German abbreviations5,6. We accumulated about
5,800 acronym and abbreviation tokens, which
were then removed from the Lucene-indexed dic-
tionary, in order to transform MDDict into a re-
source mostly devoid of abbreviations.
</bodyText>
<footnote confidence="0.9996956">
2http://sourceforge.net/projects/germandict/
3http://www.netdoktor.at/
4https://lucene.apache.org/core/
5http://de.wikipedia.org/wiki/Medizinische Abk¨urzungen
6http://de.wiktionary.org/wiki/Kategorie:Abk¨urzung
</footnote>
<figure confidence="0.891516666666667">
Period
, nekrotische Tumorforma
Token Left Punctuation Right Token
Delimiter Token String Token Delimiter
TDel LToken PStr RToken TDel
Left context Right context
</figure>
<figureCaption confidence="0.991101">
Figure 1: Period pattern and zoning of left and
right context.
</figureCaption>
<bodyText confidence="0.999943470588235">
For CCDict we harvested closed-class words
from a German web resource7, i.e. prepositions,
determiners, conjunctions, and pronouns, together
with auxiliary and modal verbs. The purpose of
this was to arrive at a comprehensive list of word
forms that can only be capitalized at the beginning
of a sentence.
Figure 1 shows the pattern used to identify peri-
ods of interest for this study. The right and the left
context were zoned as followed: The string to the
left of the period until the preceding token delim-
iter is the “Left Token” (LToken). The sequence
of spaces, line breaks, or punctuation marks to the
right of the period (“Punctuation String”) is iden-
tified as PStr. The following token, spanning from
the first alphanumeric character to the character
left to the next delimiter, is named RToken.
</bodyText>
<subsectionHeader confidence="0.999281">
2.2 Context evaluation
</subsectionHeader>
<bodyText confidence="0.999996117647059">
The right context is evaluated first (Algorithm
1). It is based on the following assumptions: (i)
Whenever a period terminates a sentence, the first
character in the following token is capitalized. For
a subset of words this can be ascertained by look-
ing up the closed word class dictionary CCDict
(the restriction to “closed classes” is due to the fact
that German nouns are mandatorily capitalized, in-
cluding nominalized adjectives and verbs); (ii) A
sentence can never be split by a line break, there-
fore a period that precedes the break necessarily
marks the end of the previous sentence; (iii) Most
punctuation signs that follow a period strongly in-
dicate that the period character here plays the role
of an abbreviation marker and does not coincide
with an end-of-sentence marker. Only in the case
where a decision could not be achieved using the
</bodyText>
<footnote confidence="0.918707">
7http://www.deutschegrammatik20.de/
</footnote>
<note confidence="0.552072">
Strukturen re.
</note>
<page confidence="0.940284">
97
</page>
<figure confidence="0.926366571428572">
if RToken begins with lower case character
then
→ MAM;
else
if decapitalized RToken matches closed
class token then
→ EAM or NSD;
else
if If PStr contains punctuation
character then
→ MAM;
else
if If PStr contains a line break
then
→ NSD or EAM;
else
→ NSD or MAM or EAM;
end
end
end
end
</figure>
<figureCaption confidence="0.792317">
Algorithm 1: Rule-based decision algorithm for
</figureCaption>
<bodyText confidence="0.835725166666667">
the right context of a period.
algorithm is the left context investigated.
The evaluation of the left context extends the
approach from Kiss and Strunk (2002), who used
the log likelihood ratio (Dunning, 1993) for abbre-
viation detection:
</bodyText>
<equation confidence="0.975472">
logA = −2log(L(H0)/L(HA))
</equation>
<bodyText confidence="0.99934205">
H0 is the hypothesis that the occurrence of a pe-
riod is independent of the preceding word, HA the
hypothesis that it is not independent.
We use four scaling functions S1 – S4. The
period character is symbolized by •; C(word, •)
and C(word, ¬•) describe the co-occurrence fre-
quency counts. The primary logA is modified
by sequential composition. Following Kiss and
Strunk (2002), S1 enhances the initial logA if
C(word, •) is greater than C(word, ¬•). S2
varies from −1 to 1 depending on C(word, •) and
C(word, ¬•). S3 leads to a reduction of logA de-
pending on the length of the preceding word. We
introduced a fourth scaling function S4, which re-
flects the fact that most abbreviations are proper
substrings of the shortened original word (e.g.
“exulz.” = “exulzerierend”), with N being the
sum of all found substring matches in the form
subwordz∗ for every subwordz in subword1 •
subword2 • ... subwordn• in a Lucene search re-
</bodyText>
<equation confidence="0.8831435">
sult.
S4(logA) : logA + N(word, •)
</equation>
<bodyText confidence="0.999111647058824">
This also includes those abbreviations which
have an internal period, such as “St.p”. The reason
why the last scaling function contains an addition,
is to accommodate for cases where C(word, •) &lt;
C(word, ¬•) even when word is an abbreviation.
These cases, for which the weighted logA is nega-
tive, could then nevertheless be pushed to the pos-
itive side in the result of a strong S4.
For the final decision in favor of an abbrevi-
ation, we required that the following two condi-
tions hold: (i) (S1 o S2 o S3 o S4)(logA) &gt; 0;
(ii) the length of the abbreviation candidate was
within the 95% confidence interval, given the sta-
tistical distribution of all abbreviation candidates
that exhibited a significant collocation (p &lt; 0.01),
C(word, •) &gt; C(word, ¬•), and MDDict not
containing word.
</bodyText>
<sectionHeader confidence="0.999942" genericHeader="background">
3 Results
</sectionHeader>
<bodyText confidence="0.999971931034483">
For the evaluation methodology, a gold standard
was created by a random selection of 500 text
frames, centered around a period with its left and
right context (each 60 characters) from the evalu-
ation set. The two authors rated each period in the
center of the snippet as being an NSD, a MAM
or an EAM. A subset of 100 was rated by both
authors in order to compute the inter-rater agree-
ment. We obtained a Cohen’s kappa (Di Euge-
nio and Glass, 2004, Hripcsak and Heitjan, 2002)
of 0.98, when rating both abbreviation vs. non-
abbreviation, and sentence delimiter vs. non sen-
tence delimiter, respectively. Accuracy, true and
false negative rates (Manning et al., 2008), are
computed for the two processing steps in isolation.
This required making some default assumptions
for the cases in which the result was ambiguous.
The assumptions are based on frequency distribu-
tions of the three values in the learning set. The
left context processing detects abbreviations, but
is unable to distinguish between EAM and MAM.
As the frequency of MAM is much higher, this
value is set wherever NSD is discarded. In the pro-
cessing of the right context, the algorithm may fail
to disambiguate between NSD vs. EAM, or even
terminate with any decision (NSD vs. EAM vs.
MAM), cf. Algorithm 1. In the latter case MAM
is set, as this was determined to be the most fre-
quent phenomenon in the learning data (0.53). In
</bodyText>
<page confidence="0.991948">
98
</page>
<bodyText confidence="0.9934112">
the former case, NSD is given preference over
EAM, which has a low frequency in the learn-
ing set (0.03). Table 1 shows accuracy and false
positive / negative rates obtained by left, right and
combined context evaluations.
</bodyText>
<table confidence="0.998766444444444">
Accuracy Fpos Fneg
Abbreviation detection
Left 0.914 0.035 0.136
Right 0.880 0.162 0.051
L &amp; R 0.928 0.060 0.082
Sentence delimitation
Left 0.902 0.107 0.077
Right 0.884 0.014 0.211
L &amp; R 0.934 0.062 0.065
</table>
<tableCaption confidence="0.977298">
Table 1: Abbreviation detection and sentence de-
limitation results.
</tableCaption>
<bodyText confidence="0.999847789473684">
It is remarkable that the combination of both al-
gorithms only produces a moderate gain in accu-
racy. For the minimization of certain false nega-
tives and false positives, it can be advantageous to
consider the right or left context separately. For in-
stance, the right context algorithm alone is better
at minimizing false positive sentence recognitions,
whereas the left context algorithm is better suited
at minimizing cases of false positive abbreviation
detections. Apart from known issues such as the
above mentioned parsing problems, for which the
reader needs to be familiar with the domain and
the style of the documents, the analysis of mis-
classifications revealed several weaknesses: sen-
sitivity to spelling and punctuation errors (espe-
cially missing spaces after periods) and abbrevia-
tions that can also be read as a normal word (e.g.
“Mal.” for “Malignit¨at” or “Mal” (time)), and ab-
breviations that are still present in MDDict.
</bodyText>
<sectionHeader confidence="0.99991" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.9997051">
The detection of short forms (abbreviations,
acronyms) is important due to their frequency in
medical texts (Meystre et al., 2008). Several au-
thors studied their detection, normalization, and
context-dependent mapping to long forms (Xu et
al., 2012). CLEF 2013 (Suominen et al., 2013)
started a task for acronym/abbreviation normal-
ization, using the UMLS8 as target terminology.
An F-Measure of 0.89 was reported by Patrick et
al. (2013). Four different methods for abbrevia-
</bodyText>
<footnote confidence="0.84722">
8http://www.nlm.nih.gov/research/umls/
</footnote>
<bodyText confidence="0.999906947368421">
tion detection were tested by Xu et al. (2007). The
fourth method (a decision tree classifier), which
additionally used features from knowledge re-
sources, performed best with a precision of 91.4%
and a recall of 80.3%. Therefore Wu et al. (2011)
compared machine learning methods for abbrevi-
ation detection. Word formation, vowel combina-
tions, related content from knowledge bases, word
frequency in the overall corpus, and local context
were used as features. The random forest classi-
fier performed best with an F-Measure of 94.8%.
A combination of classifiers lead to the highest
F-Measure of 95.7%. Wu et al. (2012) compared
different clinical natural language processing sys-
tems on handling abbreviations in discharge sum-
maries, resulting in MedLEE performing best with
an F-Score of 0.60. A prototypical system, meet-
ing real-time constraints, is described in Wu et
al. (2013).
</bodyText>
<sectionHeader confidence="0.991282" genericHeader="conclusions">
5 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.9999767">
We have presented and evaluated a method for
disambiguating the period character in German-
language medical narratives. It is a combination
of a simple rule set and a statistical approach
supported by lexicons. Whereas the crafting of
the rule base considers peculiarities of the docu-
ment language, primarily by exploiting language-
specific capitalization rules, the processing of the
external language resources and the statistical
methodology are unsupervised. Given these pa-
rameters, the accuracy values of about 93% for
both abbreviation detection and sentence delin-
eation are satisfactory, especially when one con-
siders that the texts are error laden and highly
compact, which also resulted in large numbers of
ad-hoc abbreviations. We expect that with a lim-
ited training effort this rate can still be raised fur-
ther. We are aware that the described period dis-
ambiguation procedure should be embedded into
an NLP processing pipeline, where it must be pre-
ceded by a cleansing process that identifies “hid-
den” periods and restores the adherence to basic
punctuation rules by inserting white spaces where
necessary. An improved result can facilitate the
creation of a sufficiently large, manually annotated
corpus, which could then be used as the basis for
the application of machine learning methods. Fur-
thermore, the impact of the different modifications
regarding the left context approach must be evalu-
ated in more detail.
</bodyText>
<page confidence="0.997909">
99
</page>
<sectionHeader confidence="0.988923" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999495307692308">
Barbara Di Eugenio and Michael Glass. 2004. The
kappa statistic: A second look. Computational lin-
guistics, 30(1):95–101.
T Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Lin-
guistics, 19(1):61–74.
George Hripcsak and Daniel F Heitjan. 2002. Mea-
suring agreement in medical informatics reliabil-
ity studies. Journal of biomedical informatics,
35(2):99–110.
T Kiss and J Strunk. 2002. Scaled log likelihood ratios
for the detection of abbreviations in text corpora. In
Proceedings of the 19th International Conference on
Computational Linguistics – Volume 2, pages 1–5.
Association for Computational Linguistics.
Christopher D Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to informa-
tion retrieval, volume 1. Cambridge university press
Cambridge.
S M Meystre, GK Savova, KC Kipper-Schuler, and
JF Hurdle. 2008. Extracting information from tex-
tual documents in the electronic health record: a re-
view of recent research. Yearbook of Medical Infor-
matics, 35:128–144.
JD Patrick, L Safari, and Y Ou. 2013.
ShaARe/CLEF eHealth 2013 Normalization of
Acronyms/Abbreviation Challenge. In CLEF 2013
Evaluation Labs and Workshop Abstracts - Working
Notes.
Pschyrembel. 1997. Klinisches W¨orterbuch. CD-
ROM Version 1/97.
Hanna Suominen, Sanna Salanter¨a, Sumithra Velupil-
lai, Wendy W Chapman, Guergana Savova, Noemie
Elhadad, Sameer Pradhan, Brett R South, Danielle L
Mowery, Gareth JF Jones, et al. 2013. Overview
of the share/clef ehealth evaluation lab 2013.
In Information Access Evaluation. Multilinguality,
Multimodality, and Visualization, pages 212–231.
Springer.
Y Wu, ST Rosenbloom, JC Denny, A Miller, S Mani,
Giuse DA, and H Xu. 2011. Detecting abbrevia-
tions in discharge summaries using machine learn-
ing methods. In AMIA Annual Symposium Proceed-
ings, volume 2011, pages 1541–1549.
Y Wu, JC Denny, ST Rosenbloom, RA Miller,
DA Giuse, and H Xu. 2012. A comparative study of
current clinical natural language processing systems
on handling abbreviations in discharge summaries.
In AMIA Annual Symposium Proceedings, volume
2012, pages 997–1003.
Y Wu, JC Denny, ST Rosenbloom, Randolph A Miller,
Dario A Giuse, Min Song, and Hua Xu. 2013. A
prototype application for real-time recognition and
disambiguation of clinical abbreviations. In Proc.
of the 7th International Workshop on Data and Text
Mining in Biomedical Informatics, pages 7–8.
H Xu, PD Stetson, and C Friedman. 2007. A study
of abbreviations in clinical notes. In AMIA Annual
Symposium Proceedings, volume 2007, pages 821–
825.
H Xu, PD Stetson, and C Friedman. 2012. Combin-
ing corpus-derived sense profiles with estimated fre-
quency information to disambiguate clinical abbre-
viations. In AMIA Annual Symposium Proceedings,
volume 2012, pages 1004–1013.
</reference>
<page confidence="0.990749">
100
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.603759">
<title confidence="0.991008">Disambiguation of Period Characters in Clinical Narratives</title>
<author confidence="0.811452">Kreuzthaler</author>
<affiliation confidence="0.9849195">Institute for Medical Informatics, Statistics and Medical University of</affiliation>
<email confidence="0.886245"><markus.kreuzthaler,stefan.schulz>@medunigraz.at</email>
<abstract confidence="0.990826823529412">The period character’s meaning is highly ambiguous due to the frequency of abbreviations that require to be followed by a period. We have developed a hybrid method for period character disambiguation and the identification of abbreviations, combining rules that explore regularities in the right context of the period with lexicon-based, statistical methods which scrutinize the preceding token. The texts under scrutiny are clinical discharge summaries. Both abbreviation detection and sentence delimitation showed an accuracy of about 93%. An error analysis demonstrated potential for further improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Michael Glass</author>
</authors>
<title>The kappa statistic: A second look.</title>
<date>2004</date>
<journal>Computational linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<marker>Di Eugenio, Glass, 2004</marker>
<rawString>Barbara Di Eugenio and Michael Glass. 2004. The kappa statistic: A second look. Computational linguistics, 30(1):95–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="8414" citStr="Dunning, 1993" startWordPosition="1286" endWordPosition="1287">ieved using the 7http://www.deutschegrammatik20.de/ Strukturen re. 97 if RToken begins with lower case character then → MAM; else if decapitalized RToken matches closed class token then → EAM or NSD; else if If PStr contains punctuation character then → MAM; else if If PStr contains a line break then → NSD or EAM; else → NSD or MAM or EAM; end end end end Algorithm 1: Rule-based decision algorithm for the right context of a period. algorithm is the left context investigated. The evaluation of the left context extends the approach from Kiss and Strunk (2002), who used the log likelihood ratio (Dunning, 1993) for abbreviation detection: logA = −2log(L(H0)/L(HA)) H0 is the hypothesis that the occurrence of a period is independent of the preceding word, HA the hypothesis that it is not independent. We use four scaling functions S1 – S4. The period character is symbolized by •; C(word, •) and C(word, ¬•) describe the co-occurrence frequency counts. The primary logA is modified by sequential composition. Following Kiss and Strunk (2002), S1 enhances the initial logA if C(word, •) is greater than C(word, ¬•). S2 varies from −1 to 1 depending on C(word, •) and C(word, ¬•). S3 leads to a reduction of log</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Hripcsak</author>
<author>Daniel F Heitjan</author>
</authors>
<title>Measuring agreement in medical informatics reliability studies.</title>
<date>2002</date>
<journal>Journal of biomedical informatics,</journal>
<volume>35</volume>
<issue>2</issue>
<contexts>
<context position="10700" citStr="Hripcsak and Heitjan, 2002" startWordPosition="1686" endWordPosition="1689">of all abbreviation candidates that exhibited a significant collocation (p &lt; 0.01), C(word, •) &gt; C(word, ¬•), and MDDict not containing word. 3 Results For the evaluation methodology, a gold standard was created by a random selection of 500 text frames, centered around a period with its left and right context (each 60 characters) from the evaluation set. The two authors rated each period in the center of the snippet as being an NSD, a MAM or an EAM. A subset of 100 was rated by both authors in order to compute the inter-rater agreement. We obtained a Cohen’s kappa (Di Eugenio and Glass, 2004, Hripcsak and Heitjan, 2002) of 0.98, when rating both abbreviation vs. nonabbreviation, and sentence delimiter vs. non sentence delimiter, respectively. Accuracy, true and false negative rates (Manning et al., 2008), are computed for the two processing steps in isolation. This required making some default assumptions for the cases in which the result was ambiguous. The assumptions are based on frequency distributions of the three values in the learning set. The left context processing detects abbreviations, but is unable to distinguish between EAM and MAM. As the frequency of MAM is much higher, this value is set wherev</context>
</contexts>
<marker>Hripcsak, Heitjan, 2002</marker>
<rawString>George Hripcsak and Daniel F Heitjan. 2002. Measuring agreement in medical informatics reliability studies. Journal of biomedical informatics, 35(2):99–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kiss</author>
<author>J Strunk</author>
</authors>
<title>Scaled log likelihood ratios for the detection of abbreviations in text corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics –</booktitle>
<volume>2</volume>
<pages>1--5</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8363" citStr="Kiss and Strunk (2002)" startWordPosition="1276" endWordPosition="1279"> marker. Only in the case where a decision could not be achieved using the 7http://www.deutschegrammatik20.de/ Strukturen re. 97 if RToken begins with lower case character then → MAM; else if decapitalized RToken matches closed class token then → EAM or NSD; else if If PStr contains punctuation character then → MAM; else if If PStr contains a line break then → NSD or EAM; else → NSD or MAM or EAM; end end end end Algorithm 1: Rule-based decision algorithm for the right context of a period. algorithm is the left context investigated. The evaluation of the left context extends the approach from Kiss and Strunk (2002), who used the log likelihood ratio (Dunning, 1993) for abbreviation detection: logA = −2log(L(H0)/L(HA)) H0 is the hypothesis that the occurrence of a period is independent of the preceding word, HA the hypothesis that it is not independent. We use four scaling functions S1 – S4. The period character is symbolized by •; C(word, •) and C(word, ¬•) describe the co-occurrence frequency counts. The primary logA is modified by sequential composition. Following Kiss and Strunk (2002), S1 enhances the initial logA if C(word, •) is greater than C(word, ¬•). S2 varies from −1 to 1 depending on C(word,</context>
</contexts>
<marker>Kiss, Strunk, 2002</marker>
<rawString>T Kiss and J Strunk. 2002. Scaled log likelihood ratios for the detection of abbreviations in text corpora. In Proceedings of the 19th International Conference on Computational Linguistics – Volume 2, pages 1–5. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to information retrieval, volume 1. Cambridge university press Cambridge.</title>
<date>2008</date>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to information retrieval, volume 1. Cambridge university press Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Meystre</author>
<author>GK Savova</author>
<author>KC Kipper-Schuler</author>
<author>JF Hurdle</author>
</authors>
<title>Extracting information from textual documents in the electronic health record: a review of recent research.</title>
<date>2008</date>
<journal>Yearbook of Medical Informatics,</journal>
<pages>35--128</pages>
<contexts>
<context position="2141" citStr="Meystre et al., 2008" startWordPosition="316" endWordPosition="319">nt to at least one non-alphabetic character. Whereas in the former case the period character can be considered an internal part of a token, the latter allows for two interpretations: 1. Period characters that are mandatorily collocated with abbreviations; and 2. Period characters as sentence delimiters. We focus on text produced by physicians at the point of care, either directly or via dictation. The sublanguage of clinical narratives is characterized, among other peculiarities such as misspellings, punctuation errors, and incomplete sentences, by the abundance of acronyms and abbreviations (Meystre et al., 2008). It is for this reason that we focus here on the use of the period character to distinguish between sentence limits and abbreviations. A snippet from a medical text illustrates some typical phenomena: 3. St.p. TE eines exulz. sek.knot.SSM (C43.5) li Lab. majus. Level IV, 2,42 mm Tumordurchm. In “3.” the period marks an ordinal number; “St.p.” is the abbreviation of “Status post” (state after); “TE” is an acronym derived from “Totale Exzision”. “Exulz.” and “Tumordurchm.” are ad-hoc abbreviations for “exulzerierendes” and “Tumordurchmesser” (tumour diameter), respectively. “sek.knot.SSM” is an</context>
<context position="13199" citStr="Meystre et al., 2008" startWordPosition="2097" endWordPosition="2100">ons. Apart from known issues such as the above mentioned parsing problems, for which the reader needs to be familiar with the domain and the style of the documents, the analysis of misclassifications revealed several weaknesses: sensitivity to spelling and punctuation errors (especially missing spaces after periods) and abbreviations that can also be read as a normal word (e.g. “Mal.” for “Malignit¨at” or “Mal” (time)), and abbreviations that are still present in MDDict. 4 Related Work The detection of short forms (abbreviations, acronyms) is important due to their frequency in medical texts (Meystre et al., 2008). Several authors studied their detection, normalization, and context-dependent mapping to long forms (Xu et al., 2012). CLEF 2013 (Suominen et al., 2013) started a task for acronym/abbreviation normalization, using the UMLS8 as target terminology. An F-Measure of 0.89 was reported by Patrick et al. (2013). Four different methods for abbrevia8http://www.nlm.nih.gov/research/umls/ tion detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%</context>
</contexts>
<marker>Meystre, Savova, Kipper-Schuler, Hurdle, 2008</marker>
<rawString>S M Meystre, GK Savova, KC Kipper-Schuler, and JF Hurdle. 2008. Extracting information from textual documents in the electronic health record: a review of recent research. Yearbook of Medical Informatics, 35:128–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JD Patrick</author>
<author>L Safari</author>
<author>Y Ou</author>
</authors>
<title>ShaARe/CLEF eHealth 2013 Normalization of Acronyms/Abbreviation Challenge.</title>
<date>2013</date>
<booktitle>In CLEF 2013 Evaluation Labs and Workshop Abstracts - Working Notes.</booktitle>
<contexts>
<context position="13506" citStr="Patrick et al. (2013)" startWordPosition="2144" endWordPosition="2147">r periods) and abbreviations that can also be read as a normal word (e.g. “Mal.” for “Malignit¨at” or “Mal” (time)), and abbreviations that are still present in MDDict. 4 Related Work The detection of short forms (abbreviations, acronyms) is important due to their frequency in medical texts (Meystre et al., 2008). Several authors studied their detection, normalization, and context-dependent mapping to long forms (Xu et al., 2012). CLEF 2013 (Suominen et al., 2013) started a task for acronym/abbreviation normalization, using the UMLS8 as target terminology. An F-Measure of 0.89 was reported by Patrick et al. (2013). Four different methods for abbrevia8http://www.nlm.nih.gov/research/umls/ tion detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%. Therefore Wu et al. (2011) compared machine learning methods for abbreviation detection. Word formation, vowel combinations, related content from knowledge bases, word frequency in the overall corpus, and local context were used as features. The random forest classifier performed best with an F-Measure o</context>
</contexts>
<marker>Patrick, Safari, Ou, 2013</marker>
<rawString>JD Patrick, L Safari, and Y Ou. 2013. ShaARe/CLEF eHealth 2013 Normalization of Acronyms/Abbreviation Challenge. In CLEF 2013 Evaluation Labs and Workshop Abstracts - Working Notes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pschyrembel</author>
</authors>
<title>Klinisches W¨orterbuch.</title>
<date>1997</date>
<journal>CDROM Version</journal>
<volume>1</volume>
<contexts>
<context position="5216" citStr="Pschyrembel, 1997" startWordPosition="795" endWordPosition="796">erage word count of 302, with a mean of 55 period characters per document. The texts were divided into a learning set (1.526 documents) and an evaluation set (170 documents). Two word lists were created in advance: (i) a medical domain dictionary (MDDict) with a high coverage of domain-specific terms, excluding abbreviations, and (ii) a closed-class dictionary (CCDict) containing common, domain-independent word forms. For MDDict, words were harvested from three sources: a free dictionary of contemporary German2, a word list created out of raw text extracted from a medical dictionary on CDROM (Pschyrembel, 1997), and medical texts and forum postings from a patient-centered website3. The final list comprised approximately 1.45 million types, which were subsequently indexed with Lucene4. This dictionary was modified during a second step by two Web resources containing German abbreviations5,6. We accumulated about 5,800 acronym and abbreviation tokens, which were then removed from the Lucene-indexed dictionary, in order to transform MDDict into a resource mostly devoid of abbreviations. 2http://sourceforge.net/projects/germandict/ 3http://www.netdoktor.at/ 4https://lucene.apache.org/core/ 5http://de.wik</context>
</contexts>
<marker>Pschyrembel, 1997</marker>
<rawString>Pschyrembel. 1997. Klinisches W¨orterbuch. CDROM Version 1/97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna Suominen</author>
<author>Sanna Salanter¨a</author>
<author>Sumithra Velupillai</author>
<author>Wendy W Chapman</author>
<author>Guergana Savova</author>
<author>Noemie Elhadad</author>
<author>Sameer Pradhan</author>
<author>Brett R South</author>
<author>Danielle L Mowery</author>
<author>Gareth JF Jones</author>
</authors>
<title>Overview of the share/clef ehealth evaluation lab 2013. In Information Access Evaluation. Multilinguality, Multimodality, and Visualization,</title>
<date>2013</date>
<pages>212--231</pages>
<publisher>Springer.</publisher>
<marker>Suominen, Salanter¨a, Velupillai, Chapman, Savova, Elhadad, Pradhan, South, Mowery, Jones, 2013</marker>
<rawString>Hanna Suominen, Sanna Salanter¨a, Sumithra Velupillai, Wendy W Chapman, Guergana Savova, Noemie Elhadad, Sameer Pradhan, Brett R South, Danielle L Mowery, Gareth JF Jones, et al. 2013. Overview of the share/clef ehealth evaluation lab 2013. In Information Access Evaluation. Multilinguality, Multimodality, and Visualization, pages 212–231. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wu</author>
<author>ST Rosenbloom</author>
<author>JC Denny</author>
<author>A Miller</author>
<author>S Mani</author>
<author>Giuse DA</author>
<author>H Xu</author>
</authors>
<title>Detecting abbreviations in discharge summaries using machine learning methods.</title>
<date>2011</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<volume>volume</volume>
<pages>1541--1549</pages>
<contexts>
<context position="13827" citStr="Wu et al. (2011)" startWordPosition="2191" endWordPosition="2194">thors studied their detection, normalization, and context-dependent mapping to long forms (Xu et al., 2012). CLEF 2013 (Suominen et al., 2013) started a task for acronym/abbreviation normalization, using the UMLS8 as target terminology. An F-Measure of 0.89 was reported by Patrick et al. (2013). Four different methods for abbrevia8http://www.nlm.nih.gov/research/umls/ tion detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%. Therefore Wu et al. (2011) compared machine learning methods for abbreviation detection. Word formation, vowel combinations, related content from knowledge bases, word frequency in the overall corpus, and local context were used as features. The random forest classifier performed best with an F-Measure of 94.8%. A combination of classifiers lead to the highest F-Measure of 95.7%. Wu et al. (2012) compared different clinical natural language processing systems on handling abbreviations in discharge summaries, resulting in MedLEE performing best with an F-Score of 0.60. A prototypical system, meeting real-time constraint</context>
</contexts>
<marker>Wu, Rosenbloom, Denny, Miller, Mani, DA, Xu, 2011</marker>
<rawString>Y Wu, ST Rosenbloom, JC Denny, A Miller, S Mani, Giuse DA, and H Xu. 2011. Detecting abbreviations in discharge summaries using machine learning methods. In AMIA Annual Symposium Proceedings, volume 2011, pages 1541–1549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wu</author>
<author>JC Denny</author>
<author>ST Rosenbloom</author>
<author>RA Miller</author>
<author>DA Giuse</author>
<author>H Xu</author>
</authors>
<title>A comparative study of current clinical natural language processing systems on handling abbreviations in discharge summaries.</title>
<date>2012</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<volume>volume</volume>
<pages>997--1003</pages>
<contexts>
<context position="14200" citStr="Wu et al. (2012)" startWordPosition="2249" endWordPosition="2252">on detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%. Therefore Wu et al. (2011) compared machine learning methods for abbreviation detection. Word formation, vowel combinations, related content from knowledge bases, word frequency in the overall corpus, and local context were used as features. The random forest classifier performed best with an F-Measure of 94.8%. A combination of classifiers lead to the highest F-Measure of 95.7%. Wu et al. (2012) compared different clinical natural language processing systems on handling abbreviations in discharge summaries, resulting in MedLEE performing best with an F-Score of 0.60. A prototypical system, meeting real-time constraints, is described in Wu et al. (2013). 5 Conclusion and Outlook We have presented and evaluated a method for disambiguating the period character in Germanlanguage medical narratives. It is a combination of a simple rule set and a statistical approach supported by lexicons. Whereas the crafting of the rule base considers peculiarities of the document language, primarily by </context>
</contexts>
<marker>Wu, Denny, Rosenbloom, Miller, Giuse, Xu, 2012</marker>
<rawString>Y Wu, JC Denny, ST Rosenbloom, RA Miller, DA Giuse, and H Xu. 2012. A comparative study of current clinical natural language processing systems on handling abbreviations in discharge summaries. In AMIA Annual Symposium Proceedings, volume 2012, pages 997–1003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wu</author>
<author>JC Denny</author>
<author>ST Rosenbloom</author>
<author>Randolph A Miller</author>
<author>Dario A Giuse</author>
<author>Min Song</author>
<author>Hua Xu</author>
</authors>
<title>A prototype application for real-time recognition and disambiguation of clinical abbreviations.</title>
<date>2013</date>
<booktitle>In Proc. of the 7th International Workshop on Data and Text Mining in Biomedical Informatics,</booktitle>
<pages>7--8</pages>
<contexts>
<context position="14462" citStr="Wu et al. (2013)" startWordPosition="2288" endWordPosition="2291">earning methods for abbreviation detection. Word formation, vowel combinations, related content from knowledge bases, word frequency in the overall corpus, and local context were used as features. The random forest classifier performed best with an F-Measure of 94.8%. A combination of classifiers lead to the highest F-Measure of 95.7%. Wu et al. (2012) compared different clinical natural language processing systems on handling abbreviations in discharge summaries, resulting in MedLEE performing best with an F-Score of 0.60. A prototypical system, meeting real-time constraints, is described in Wu et al. (2013). 5 Conclusion and Outlook We have presented and evaluated a method for disambiguating the period character in Germanlanguage medical narratives. It is a combination of a simple rule set and a statistical approach supported by lexicons. Whereas the crafting of the rule base considers peculiarities of the document language, primarily by exploiting languagespecific capitalization rules, the processing of the external language resources and the statistical methodology are unsupervised. Given these parameters, the accuracy values of about 93% for both abbreviation detection and sentence delineatio</context>
</contexts>
<marker>Wu, Denny, Rosenbloom, Miller, Giuse, Song, Xu, 2013</marker>
<rawString>Y Wu, JC Denny, ST Rosenbloom, Randolph A Miller, Dario A Giuse, Min Song, and Hua Xu. 2013. A prototype application for real-time recognition and disambiguation of clinical abbreviations. In Proc. of the 7th International Workshop on Data and Text Mining in Biomedical Informatics, pages 7–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>PD Stetson</author>
<author>C Friedman</author>
</authors>
<title>A study of abbreviations in clinical notes.</title>
<date>2007</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<volume>volume</volume>
<pages>821--825</pages>
<contexts>
<context position="13628" citStr="Xu et al. (2007)" startWordPosition="2159" endWordPosition="2162">iations that are still present in MDDict. 4 Related Work The detection of short forms (abbreviations, acronyms) is important due to their frequency in medical texts (Meystre et al., 2008). Several authors studied their detection, normalization, and context-dependent mapping to long forms (Xu et al., 2012). CLEF 2013 (Suominen et al., 2013) started a task for acronym/abbreviation normalization, using the UMLS8 as target terminology. An F-Measure of 0.89 was reported by Patrick et al. (2013). Four different methods for abbrevia8http://www.nlm.nih.gov/research/umls/ tion detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%. Therefore Wu et al. (2011) compared machine learning methods for abbreviation detection. Word formation, vowel combinations, related content from knowledge bases, word frequency in the overall corpus, and local context were used as features. The random forest classifier performed best with an F-Measure of 94.8%. A combination of classifiers lead to the highest F-Measure of 95.7%. Wu et al. (2012) compared different clinical</context>
</contexts>
<marker>Xu, Stetson, Friedman, 2007</marker>
<rawString>H Xu, PD Stetson, and C Friedman. 2007. A study of abbreviations in clinical notes. In AMIA Annual Symposium Proceedings, volume 2007, pages 821– 825.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Xu</author>
<author>PD Stetson</author>
<author>C Friedman</author>
</authors>
<title>Combining corpus-derived sense profiles with estimated frequency information to disambiguate clinical abbreviations.</title>
<date>2012</date>
<booktitle>In AMIA Annual Symposium Proceedings,</booktitle>
<volume>volume</volume>
<pages>1004--1013</pages>
<contexts>
<context position="13318" citStr="Xu et al., 2012" startWordPosition="2114" endWordPosition="2117">e domain and the style of the documents, the analysis of misclassifications revealed several weaknesses: sensitivity to spelling and punctuation errors (especially missing spaces after periods) and abbreviations that can also be read as a normal word (e.g. “Mal.” for “Malignit¨at” or “Mal” (time)), and abbreviations that are still present in MDDict. 4 Related Work The detection of short forms (abbreviations, acronyms) is important due to their frequency in medical texts (Meystre et al., 2008). Several authors studied their detection, normalization, and context-dependent mapping to long forms (Xu et al., 2012). CLEF 2013 (Suominen et al., 2013) started a task for acronym/abbreviation normalization, using the UMLS8 as target terminology. An F-Measure of 0.89 was reported by Patrick et al. (2013). Four different methods for abbrevia8http://www.nlm.nih.gov/research/umls/ tion detection were tested by Xu et al. (2007). The fourth method (a decision tree classifier), which additionally used features from knowledge resources, performed best with a precision of 91.4% and a recall of 80.3%. Therefore Wu et al. (2011) compared machine learning methods for abbreviation detection. Word formation, vowel combin</context>
</contexts>
<marker>Xu, Stetson, Friedman, 2012</marker>
<rawString>H Xu, PD Stetson, and C Friedman. 2012. Combining corpus-derived sense profiles with estimated frequency information to disambiguate clinical abbreviations. In AMIA Annual Symposium Proceedings, volume 2012, pages 1004–1013.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>