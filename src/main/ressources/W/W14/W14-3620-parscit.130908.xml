<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000712">
<title confidence="0.979249">
GWU-HASP: Hybrid Arabic Spelling and Punctuation Corrector1
</title>
<author confidence="0.996956">
Mohammed Attia, Mohamed Al-Badrashiny, Mona Diab
</author>
<affiliation confidence="0.9796695">
Department of Computer Science
The George Washington University
</affiliation>
<email confidence="0.995753">
{Mohattia;badrashiny;mtdiab}@gwu.edu
</email>
<sectionHeader confidence="0.993819" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999927684210526">
In this paper, we describe our Hybrid Ar-
abic Spelling and Punctuation Corrector
(HASP). HASP was one of the systems
participating in the QALB-2014 Shared
Task on Arabic Error Correction. The
system uses a CRF (Conditional Random
Fields) classifier for correcting punctua-
tion errors, an open-source dictionary (or
word list) for detecting errors and gener-
ating and filtering candidates, an n-gram
language model for selecting the best
candidates, and a set of deterministic
rules for text normalization (such as re-
moving diacritics and kashida and con-
verting Hindi numbers into Arabic nu-
merals). We also experiment with word
alignment for spelling correction at the
character level and report some prelimi-
nary results.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999586357142857">
In this paper we describe our system for Arabic
spelling error detection and correction, Hybrid
Arabic Spelling and Punctuation Corrector
(HASP). We participate with HASP in the
QALB-2014 Shared Task on Arabic Error Cor-
rection (Mohit et al., 2014) as part of the Arabic
Natural Language Processing Workshop (ANLP)
taking place at EMNLP 2014.
The shared task data deals with “errors” in the
general sense which comprise: a) punctuation
errors; b) non-word errors; c) real-word spelling
errors; d) grammatical errors; and, e) orthograph-
ical errors such as elongation (kashida) and
speech effects such as character multiplication
</bodyText>
<footnote confidence="0.97402375">
1 This work was supported by the Defense Advanced
Research Projects Agency (DARPA) Contract No.
HR0011-12-C-0014, BOLT program with subcontract
from Raytheon BBN.
</footnote>
<bodyText confidence="0.999750375">
for emphasis. HASP in its current stage only
handles types (a), (b), and (e) errors. We assume
that the various error types are too distinct to be
treated with the same computational technique.
Therefore, we treat each problem separately, and
for each problem we select the approach that
seems most efficient, and ultimately all compo-
nents are integrated in a single framework.
</bodyText>
<subsectionHeader confidence="0.909">
1.1 Previous Work
</subsectionHeader>
<bodyText confidence="0.99985424">
Detecting spelling errors in typing is one of the
earliest NLP applications, and it has been re-
searched extensively over the years, particularly
for English (Damerau, 1964; Church and Gale,
1991; Kukich, 1992; Brill and Moore, 2000; Van
Delden et al., 2004; Golding, 1995; Golding and
Roth, 1996; Fossati and Di Eugenio, 2007; Islam
in Inkpen, 2009; Han and Baldwin, 2011; Wu et
al., 2013).
The problem of Arabic spelling error correc-
tion has been investigated in a number of papers
(Haddad and Yaseen, 2007; Alfaifi and Atwell,
2012; Hassan et al., 2008; Shaalan et al., 2012;
Attia et al., 2012; Alkanhal et al., 2012).
In our research, we address the spelling error
detection and correction problem with a focus on
non-word errors. Our work is different from pre-
vious work on Arabic in that we cover punctua-
tion errors as well. Furthermore, we fine-tune a
Language Model (LM) disambiguator by adding
probability scores for candidates using forward-
backward tracking, which yielded better results
than the default Viterbi. We also develop a new
and more efficient splitting algorithm for merged
words.
</bodyText>
<sectionHeader confidence="0.892432" genericHeader="introduction">
1.2 Arabic Morphology, Orthography and
Punctuation
</sectionHeader>
<bodyText confidence="0.9996966">
Arabic has a rich and complex morphology as it
applies both concatenative and non-
concatenative morphotactics (Ratcliffe, 1998;
Beesley, 1998; Habash, 2010), yielding a wealth
of morphemes that express various morpho-
</bodyText>
<page confidence="0.962738">
148
</page>
<note confidence="0.8887345">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9974227">
syntactic features, such as tense, person, number,
gender, voice and mood.
Arabic has a large array of orthographic varia-
tions, leading to what is called ‘typographic er-
rors’ or ‘orthographic variations’ (Buckwalter,
2004a), and sometimes referred to as sub-
standard spellings, or spelling soft errors. These
errors are basically related to the possible over-
lap between orthographically similar letters in
three categories: a) the various shapes of ham-
</bodyText>
<figure confidence="0.682834">
a &amp; b
zahs (اﺍ A , � 1 ) taa mar-
</figure>
<bodyText confidence="0.9962793">
boutah and haa ةﺓ p, هﻩ h); and c) yaa and alif
maqsoura (يﻱ y, ىﻯ Y).
Ancient Arabic manuscripts were written in
scriptura continua, meaning running words
without punctuation marks. Punctuation marks
were introduced to Arabic mainly through bor-
rowing from European languages via translation
(Alqinai, 2013). Although punctuation marks in
Arabic are gaining popularity and writers are
becoming more aware of their importance, yet
many writers still do not follow punctuation con-
ventions as strictly and consistently as English
writers. For example, we investigated contempo-
raneous same sized tokenized (simple tokeniza-
tion with separation of punctuation) English and
Modern Standard Arabic Gigaword edited
newswire corpora, we found that 10% of the to-
kens in the English Gigaword corresponded to
punctuation marks, compared to only 3% of the
tokens in the Arabic counterpart.
</bodyText>
<table confidence="0.99951275">
Train. % Dev. %
Word Count 925,643 -- 48,471 --
Total Errors 306,757 33.14 16,659 34.37
Word errors 187,040 60.97 9,878 59.30
Punc. errors 618,886 39.03 6,781 40.70
Split 10,869 3.48 612 3.67
Add_before 99,258 32.36 5,704 34.24
Delete 6,778 2.21 338 2.03
Edit 169,769 55.34 8,914 53.51
Merge 18,267 5.95 994 5.97
Add_after 20 0.01 2 0.01
Move 427 0.14 13 0.08
</table>
<tableCaption confidence="0.999163">
Table 1. Distribution Statistics on Error Types
</tableCaption>
<subsectionHeader confidence="0.996507">
1.3 Data Analysis
</subsectionHeader>
<bodyText confidence="0.9999">
In our work, we use the QALB corpus (Zag-
houani et al. 2014), and the training and devel-
opment set provided in the QALB shared task
(Mohit et. al 2014). The shared task addresses a
large array of errors, and not just typical spelling
</bodyText>
<footnote confidence="0.9571015">
2 In this paper, we use the Buckwalter Transliteration
Scheme as described in www.qamus.com.
</footnote>
<bodyText confidence="0.985539307692308">
errors. For instance, as Table 1 illustrates punc-
tuation errors make up to 40% of all the errors in
the shared task.
For further investigation, we annotated 1,100
words from the development set for error types,
and found that 85% of the word errors (excluding
punctuation marks) are typical spelling errors (or
non-word errors), while 15% are real-word er-
rors, or lexical ambiguities (that is, they are valid
words outside of their context), and they range
between dialectal words, grammatical errors,
semantic errors, speech effects and elongation,
examples shown in Table 2.
</bodyText>
<table confidence="0.999541727272727">
Error Type Example Correction
dialectal cIlaﺑ bhAy هﻩﺬﮭﻬﺑ bh*h
words ‘by this’ [Syrian] ‘by this’ [MSA]
grammatical ﺮﯿﻴﺒﻛ kbyr sﺮﯿﻴﺒﻛ kbyrp
errors ‘big.masc’ ‘big.fem’
semantic qﯿﻴﺗآﺁ |tyh gLﯿﻴﺗآﺁ |typ
errors ‘come to him’ ‘coming’
speech Jlll�A._�l JL&apos;-p
effects AlrjAAAAl ‘men’ AlrjAl ‘men’
elongation ءﺎـﻣدﺩ dm__A&apos; ءﺎﻣدﺩ dmA&apos;
‘blood’ ‘blood’
</table>
<tableCaption confidence="0.999757">
Table 2. Examples of real word errors
</tableCaption>
<sectionHeader confidence="0.947964" genericHeader="method">
2 Our Methodology
</sectionHeader>
<bodyText confidence="0.999673571428571">
Due to the complexity and variability of errors in
the shared task, we treat each problem individu-
ally and use different approaches that prove to be
most appropriate for each problem. We specifi-
cally address three subtypes of errors: ortho-
graphical errors; punctuation errors; and non-
word errors.
</bodyText>
<subsectionHeader confidence="0.989916">
2.1 Orthographical Errors
</subsectionHeader>
<bodyText confidence="0.990178375">
There are many instances in the shared task’s
data that can be treated using simple and straight-
forward conversion via regular expression re-
place rules. We estimate that these instances
cover 10% of the non-punctuation errors in the
development set. In HASP we use deterministic
heuristic rules to normalize the text, including
the following:
</bodyText>
<listItem confidence="0.9972523">
1. Hindi numbers (• f° 9) are converted
into Arabic numerals [0-9] (occurs 495 in the
training data times);
2. Speech effects are removed. For example,
JiiiL-_P AlrjAAAAl ‘men’ is converted to JL--P
AlrjAl. As a general rule letters repeated three
times or more are reduced to one letter (715
times);
3. Elongation or kashida is removed. For ex-
ample, �L-.&apos; dm__A&apos; ‘blood’ is converted to
</listItem>
<page confidence="0.994341">
149
</page>
<bodyText confidence="0.96226775">
ءﺎﻣدﺩ dmA&apos; (906 times);
4. Special character U+06CC, the Farsi yeh: یﯼ
is converted to U+0649, the visually similar
Arabic alif maqsoura ىﻯ Y (293 times).
</bodyText>
<subsectionHeader confidence="0.999359">
2.2 Punctuation Errors
</subsectionHeader>
<bodyText confidence="0.99720775">
Punctuation errors constitute 40% of the errors in
the QALB Arabic data. It is worth noting that by
comparison, punctuation errors only constituted
4% of the English data in CoNLL 2013 Shared
Task on English Grammatical Error Correction
(Ng et al., 2013) and were not evaluated or han-
dled by any participant. In HASP, we focus on 6
punctuation marks: comma, colon, semi-colon,
exclamation mark, question mark and period.
The ‘column’ file in the QALB shared task da-
ta comes preprocessed with the MADAMIRA
morphological analyzer version 04092014-1.0-
beta (Pasha et al., 2014). The features that we
utilize in our punctuation classification experi-
ments are all extracted from the ‘column’ file,
and they are as follows:
</bodyText>
<listItem confidence="0.992713571428571">
(1) The original word, that is the word as it ap-
pears in the text without any further pro-
cessing, (e.g., -).sL= llt$Awr ‘for consulting’);
(2) The tokenized word using the Penn Arabic
Treebank (PATB) tokenization (e.g., لﻝ+
-)�=l l+Alt$Awr);
(3) Kulick POS tag (e.g., IN+DT+NN).
(4) Buckwalter POS tag (e.g., PREP+DET+
NOUN+CASE_DEF_GN) as produced by
MADAMIRA;
(5) Classes to be predicted: colon_after, com-
ma_after, exclmark_after, period_after,
qmark_after, semicolon_after and NA (when
no punctuation marks are used);
</listItem>
<figure confidence="0.905157">
Window Recall Precision F-measure
Size
4 36.24 54.09 43.40
5 37.95 59.61 46.37
6 36.65 59.99 45.50
7 34.50 59.53 43.68
</figure>
<tableCaption confidence="0.976087">
Table 3. Yamcha results on the development set
</tableCaption>
<bodyText confidence="0.999577588235294">
For classification, we experiment with Sup-
port Vector Machines (SVM) as implemented in
Yamcha (Kudo and Matsumoto, 2003) and Con-
ditional Random Field (CRF++) classifiers (Laf-
ferty et al. 2001). In our investigation, we vary
the context window size from 4 to 8 and we use
all 5 features listed for every word in the win-
dow. As Tables 3 and 4 show, we found that
window size 5 gives the best f-score by both
Yamcha and CRF. When we strip clitics from
tokenized tag, reducing it to stems only, the per-
formance of the system improved. Overall CRF
yields significantly higher results using the same
experimental setup. We assume that the perfor-
mance advantage of CRF is a result of the way
words in the context and their features are inter-
connected in a neat grid in the template file.
</bodyText>
<figure confidence="0.57064625">
# Window Recall Precision f-measure
Size
1 4 44.03 74.33 55.31
2 5 44.50 75.49 55.99
3 6 44.22 74.93 55.62
4 7 43.81 75.09 55.34
5 8 43.49 75.41 55.17
6 8* 43.31 75.37 55.00
</figure>
<tableCaption confidence="0.98541">
Table 4. CRF results on the development set
</tableCaption>
<bodyText confidence="0.6940965">
* with full tokens; other experiments use stems
only, i.e., clitics are removed.
</bodyText>
<subsectionHeader confidence="0.962409">
2.3. Non Word Errors
</subsectionHeader>
<bodyText confidence="0.999974857142857">
This type of errors comprises different subtypes:
merges where two or more words are merged
together; splits where a space is inserted within a
single word; or misspelled words (which under-
went substitution, deletion, insertion or transpo-
sition) that should be corrected. We handle these
problems as follows.
</bodyText>
<subsectionHeader confidence="0.736091">
2.3.1. Word Merges
</subsectionHeader>
<bodyText confidence="0.999936708333333">
Merged words are when the space(s) between
two or more words is deleted, such as QUID �A
h&amp;quot;AAlnZAm ‘this system’, which should be اﺍﺬھﮪﮬﻫ
�U!111 h&amp;quot;A AlnZAm. They constitute 3.67% and
3.48% of the error types in the shared task’s de-
velopment and training data, respectively. Attia
et al. (2012) used an algorithm for dealing with
merged words in Arabic, that is, 𝑙 − 3, where l is
the length of a word. For a 7-letter word, their
algorithm generates 4 candidates as it allows on-
ly a single space to be inserted in a string. Their
algorithm, however, is too restricted. By contrast
Alkanhal et al. (2012) developed an algorithm
with more generative power, that is 21-1. Their
algorithm, however, is in practice too general
and leads to a huge fan out. For a 7-letter word, it
generates 64 solutions. We develop a splitting
algorithm by taking into account that the mini-
mum length of words in Arabic is two. Our mod-
ified algorithm is 21-4, which creates an effec-
tive balance between comprehensiveness and
compactness. For the 7-letter word, it generates 8
candidates. However, from Table 5 on merged
words and their gold splits, one would question
</bodyText>
<page confidence="0.990218">
150
</page>
<bodyText confidence="0.98117425">
the feasibility of producing more than two splits
for any given string. Our splitting algorithm is
evaluated in 2.3.3.1.c and compared to Attia et
al.’s (2012) algorithm.
</bodyText>
<table confidence="0.999026428571429">
Development Training
Total Count 631 11,054
1 split 611 10,575
2 splits 15 404
3 splits 3 57
4 splits 1 13
5 splits 1 5
</table>
<tableCaption confidence="0.999382">
Table 5. Merged words and their splits
</tableCaption>
<subsectionHeader confidence="0.608477">
2.3.2. Word Splits
</subsectionHeader>
<bodyText confidence="0.999974611111111">
Beside the problem of merged words, there is
also the problem of split words, where one or
more spaces are inserted within a word, such as
مﻡاﺍ ﻢﺻ Sm Am ‘valve’ (correction is PLﻤﺻ SmAm).
This error constitutes 6% of the shared task’s
both training and development set. We found that
the vast majority of instances of this type of error
involve the clitic conjunction waw “and”, which
should be represented as a word prefix. Among
the 18,267 splits in the training data 15,548 of
them involved the waw, corresponding to
85.12%. Similarly among the 994 splits in the
development data, 760 of them involved the waw
(76.46%).
Therefore, we opted to handle this problem in
our work in a partial and shallow manner using
deterministic rules addressing specifically the
following two phenomena:
</bodyText>
<listItem confidence="0.967661625">
1. Separated conjunction morpheme waw وﻭ w
‘and’ is attached to the succeeding word (oc-
curs 15,915 times in the training data);
2. Literal strings attached to numbers are sepa-
rated with space(s). For example,
“ءﺎﻣدﺩ2000اﺍﺪﯿﻴﮭﻬﺷ” “dmA&apos;2000$hydF” ‘blood of
2000 martyrs’ is converted to “ءﺎﻣدﺩ 2000 اﺍﺪﯿﻴﮭﻬﺷ”
“dmA&apos; 2000 $hydF” (824 times).
</listItem>
<subsectionHeader confidence="0.752075">
2.3.3. Misspelled Word Errors
</subsectionHeader>
<bodyText confidence="0.9996754">
This is more akin to the typical spelling correc-
tion problem where a word has the wrong letters,
rendering it a non-word. We address this prob-
lem using two approaches: Dictionary-LM Cor-
rection, and Alignment Based Correction.
</bodyText>
<sectionHeader confidence="0.963735" genericHeader="method">
2.3.3.1. Dictionary-LM Correction
</sectionHeader>
<bodyText confidence="0.99516125">
Spelling error detection and correction mainly
consists of three phases: a) error detection; b)
candidate generation; and c) error correction, or
best candidate selection.
</bodyText>
<sectionHeader confidence="0.692092" genericHeader="method">
a. Error Detection
</sectionHeader>
<bodyText confidence="0.999600791666667">
For non-word spelling error detection and candi-
date generation we use AraComLex Extended,
an open-source reference dictionary (or word
list) of full-form words. The dictionary is devel-
oped by Attia et al. (2012) through an amalgama-
tion of various resources, such as a wordlist from
the Arabic Gigaword corpus, wordlist generated
from the Buckwalter morphological analyzer,
and AraComLex (Attia et al., 2011), a finite-state
morphological transducer. AraComLex Extended
consists of 9.2M words and, as far as we know,
is the largest wordlist for Arabic reported in the
literature to date.
We enhance the AraComLex Extended dic-
tionary by utilizing the annotated data in the
shared task’s training data. We add 776 new val-
id words to the dictionary and remove 4,810 mis-
spelt words, leading to significant improvement
in the dictionary’s ability to make decisions on
words. Table 6 shows the dictionary’s perfor-
mance on the training and development set in the
shared task as applied only to non-words and
excluding grammatical, semantic and punctua-
tion errors.
</bodyText>
<table confidence="0.933073">
data set R P F
Training 98.84 96.34 97.57
Development 98.72 96.04 97.36
</table>
<tableCaption confidence="0.956202">
Table 6. Results of dictionary error detection
</tableCaption>
<subsectionHeader confidence="0.397341">
b. Candidate Generation
</subsectionHeader>
<bodyText confidence="0.998171857142857">
For candidate generation we use Foma (Hulden,
2009), a finite state compiler that is capable of
producing candidates from a wordlist (compiled
as an FST network) within a certain edit distance
from an error word. Foma allows the ranking of
candidates according to customizable transfor-
mation rules.
</bodyText>
<table confidence="0.99927125">
# Error Type Count Ratio %
أﺃ &gt; typed as اﺍ A 59,507 31.82
Insert 28.945 15.48
إﺇ &lt; typed as اﺍ A 25.392 13.58
Delete 18.246 9.76
ةﺓ p typed as هﻩ h 14.639 7.83
Split 11.419 6.11
يﻱ y typed as ىﻯ Y 6.419 3.43
</table>
<tableCaption confidence="0.998094">
Table 7. Error types in the training set
</tableCaption>
<bodyText confidence="0.9998634">
We develop a re-ranker based on our observa-
tion of the error types in the shared task’s train-
ing data (as shown in Table 7) and examining the
character transformations between the misspelt
words and their gold corrections. Our statistics
</bodyText>
<page confidence="0.996955">
151
</page>
<bodyText confidence="0.999973333333333">
shows that soft errors (or variants as explained in
Section 1.2) account for more than 62% of all
errors in the training data.
in Table 9. As Table 9 shows, the best scores are
obtained by System 1, which is ranked 5th among
the 9 systems participating in the shared task.
</bodyText>
<sectionHeader confidence="0.804572" genericHeader="method">
c. Error Correction
</sectionHeader>
<bodyText confidence="0.999661545454545">
For error correction, namely selecting the best
solution among the list of candidates, we use an
n-gram language model (LM), as implemented in
the SRILM package (Stolcke et al., 2011). We
use the ‘disambig’ tool for selecting candidates
from a map file where erroneous words are pro-
vided with a list of possible corrections. We also
use the ‘ngram’ utility in post-processing for de-
ciding on whether a split-word solution has a
better probability than a single word solution.
Our bigram language model is trained on the Gi-
gaword Corpus 4th edition (Parker et al., 2009).
For the LM disambiguation we use the ‘Ðfb’
option (forward-backward tracking), and we pro-
vide candidates with probability scores. We gen-
erate these probability scores by converting the
edit distance scores produced by the Foma FST
re-ranker explained above. Both of the forward-
backward tracking and the probability scores in
in tandem yield better results than the default
values. We evaluate the performance of our sys-
tem against the gold standard using the Max-
Match (M2) method for evaluating grammatical
error correction by Dahlmeier and Ng (2012).
The best f-score achieved in our system is ob-
tained when we combine the CRF punctuation
classifier (merged with the original punctuations
found in data), knowledge-based normalization
(norm), dictionary-LM disambiguation and split-
1, as shown in Table 8. The option split-1 refers
to using the splitting algorithm 𝑙 − 3 as ex-
plained in Section 2.3.1, while split-2 refers to
using the splitting algorithm 21-4.
</bodyText>
<table confidence="0.9995686">
# Experiment R P F
1 LM+split-1 33.32 73.71 45.89
2 +CRF_punc+split-1 49.74 65.38 56.50
3 + norm+split-1 38.81 69.08 49.70
4 +CRF_punc+norm 54.79 67.65 60.55
+split-1
5 +CRF_punc+norm 53.18 73.15 61.59
+orig_punc+split-1
6 +CRF_punc+norm 53.13 73.01 61.50
+orig_punc+split-2
</table>
<tableCaption confidence="0.99944">
Table 8. LM correction with 3 candidates
</tableCaption>
<bodyText confidence="0.99264675">
In the QALB Shared Task evaluation, we
submit two systems: System 1 is configuration 5
in Table 8, and System 2 corresponds to configu-
ration 6, and the results on the test set are shown
</bodyText>
<table confidence="0.999839333333333">
# Experiment R P F
1 System 1 52.98 75.47 62.25
2 System 2 52.99 75.34 62.22
</table>
<tableCaption confidence="0.9804115">
Table 9. Final official results on the test set pro-
vided by the Shared Task
</tableCaption>
<sectionHeader confidence="0.439643" genericHeader="method">
2.3.3.2. Alignment-Based Correction
</sectionHeader>
<bodyText confidence="0.999570555555555">
We formatted the data for alignment using a
window of 4 words: one word to each side
(forming the contextual boundary) and two
words in the middle. The two words in the mid-
dle are split into characters so that character
transformations can be observed and learned by
the aligner. The alignment tool we use is Giza++
(Och and Ney, 2003). Results are reported in Ta-
ble 10.
</bodyText>
<table confidence="0.99941375">
# Experiment R P F
1 for all error types 36.05 45.13 37.99
2 excluding punc 32.37 54.65 40.66
3 2 + CRF_punc+norm 46.11 62.02 52.90
</table>
<tableCaption confidence="0.999502">
Table 10. Results of character-based alignment
</tableCaption>
<bodyText confidence="0.9997012">
Although these preliminary results from Align-
ment are significantly below results yielded from
the Dictionary-LM approach, we believe that
there are several potential improvements that
need to be explored:
</bodyText>
<listItem confidence="0.996612222222222">
• Using LM on the output of the alignment;
• Determining the type of errors that the
alignment is most successful at handling:
punctuation, grammar, non-words, etc;
• Parsing training data errors with the Diction-
ary-LM disambiguation and retraining, so in-
stead of training data consisting of errors and
gold corrections, it will consist of corrected
errors and gold corrections.
</listItem>
<sectionHeader confidence="0.992607" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.999976666666667">
We have described our system HASP for the au-
tomatic correction of spelling and punctuation
mistakes in Arabic. To our knowledge, this is the
first system to handle punctuation errors. We
utilize and improve on an open-source full-form
dictionary, introduce better algorithm for hand-
ing merged word errors, tune the LM parameters,
and combine the various components together,
leading to cumulative improved results.
</bodyText>
<page confidence="0.996542">
152
</page>
<sectionHeader confidence="0.801303" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991563913461539">
Alfaifi, A., and Atwell, E. (2012) Arabic Learner
Corpora (ALC): a taxonomy of coding errors. In
Proceedings of the 8th International Computing
Conference in Arabic (ICCA 2012), Cairo, Egypt.
Alkanhal, Mohamed I., Mohamed A. Al-Badrashiny,
Mansour M. Alghamdi, and Abdulaziz O. Al-
Qabbany. (2012) Automatic Stochastic Arabic
Spelling Correction With Emphasis on Space In-
sertions and Deletions. IEEE Transactions on Au-
dio, Speech, and Language Processing, Vol. 20,
No. 7, September 2012.
Alqinai, Jamal. (2013) Mediating punctuation in Eng-
lish Arabic translation. Linguistica Atlantica. Vol.
32.
Attia, M., Pecina, P., Tounsi, L., Toral, A., and van
Genabith, J. (2011) An Open-Source Finite State
Morphological Transducer for Modern Standard
Arabic. International Workshop on Finite State
Methods and Natural Language Processing
(FSMNLP). Blois, France.
Attia, Mohammed, Pavel Pecina, Younes Samih,
Khaled Shaalan, Josef van Genabith. 2012. Im-
proved Spelling Error Detection and Correction for
Arabic. COLING 2012, Bumbai, India.
Beesley, Kenneth R. (1998). Arabic Morphology Us-
ing Only Finite-State Operations. In The Workshop
on Computational Approaches to Semitic lan-
guages, Montreal, Quebec, pp. 50–57.
Ben Othmane Zribi, C. and Ben Ahmed, M. (2003)
Efficient Automatic Correction of Misspelled Ara-
bic Words Based on Contextual Information, Lec-
ture Notes in Computer Science, Springer, Vol.
2773, pp.770–777.
Brill, Eric and Moore, Robert C. (2000) An improved
error model for noisy channel spelling correction.
Proceedings of the 38th Annual Meeting of the As-
sociation for Computational Linguistics, Hong
Kong, pp. 286–293.
Brown, P. F., Della Pietra, V. J., de Souza, P. V., Lai,
J. C. and Mercer, R. L. (1992) Class-Based n-gram
Models of Natural Language. Computational Lin-
guistics, 18(4), 467–479.
Buckwalter, T. (2004b) Buckwalter Arabic Morpho-
logical Analyzer (BAMA) Version 2.0. Linguistic
Data Consortium (LDC) catalogue number:
LDC2004L02, ISBN1-58563-324-0.
Buckwalter, Tim. (2004a) Issues in Arabic orthogra-
phy and morphology analysis. Proceedings of the
Workshop on Computational Approaches to Arabic
Script-based Languages. Pages 31-34. Association
for Computational Linguistics Stroudsburg, PA,
USA.
Church, Kenneth W. and William A. Gale. (1991)
Probability scoring for spelling correction. Statis-
tics and Computing, 1, pp. 93–103.
Dahlmeier, Daniel and Ng, Hwee Tou. 2012. Better
evaluation for grammatical error correction. In
Proceedings of NAACL.
Damerau, Fred J. (1964) A Technique for Computer
Detection and Correction of Spelling Errors.
Communications of the ACM, Volum 7, issue 3,
pp. 171–176.
Gao, Jianfeng, Xiaolong Li, Daniel Micol, Chris
Quirk, and Xu Sun. (2010) A large scale ranker-
based system for search query spelling correction.
Proceedings of the 23rd International Conference
on Computational Linguistics (COLING 2010),
pages 358–366, Beijing, China
Golding, Andrew R. A Bayesian Hybrid Method for
Context-sensitive Spelling Correction. In Proceed-
ings of the Third Workshop on Very Large Corpo-
ra. MIT, Cambridge, Massachusetts, USA. 1995,
pp.39–53.
Golding, Andrew R., and Dan Roth. (1996) Applying
Winnow to Context-Sensitive Spelling Correction.
In Proceedings of the Thirteenth International Con-
ference on Machine Learning, Stroudsburg, PA,
USA, pp. 182–190
Habash, Nizar Y. (2010) Introduction to Arabic Natu-
ral Language Processing. Synthesis Lectures on
Human Language Technologies 3.1: 1-187.
Haddad, B., and Yaseen, M. (2007) Detection and
Correction of Non-Words in Arabic: A Hybrid Ap-
proach. International Journal of Computer Pro-
cessing of Oriental Languages. Vol. 20, No. 4.
Han, Bo and Timothy Baldwin. (2011) Lexical Nor-
malisation of Short Text Messages: Makn Sens a
#twitter. Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics,
pages 368–378, Portland, Oregon, June 19-24,
2011
Hassan, A, Noeman, S., and Hassan, H. (2008) Lan-
guage Independent Text Correction using Finite
State Automata. IJCNLP. Hyderabad, India.
Hulden, M. (2009) Foma: a Finite-state compiler and
library. EACL &apos;09 Proceedings of the 12th Confer-
ence of the European Chapter of the Association
for Computational Linguistics. Association for
Computational Linguistics Stroudsburg, PA, USA
Islam, Aminul, Diana Inkpen. (2009) Real-Word
Spelling Correction using Google Web 1T n-gram
with Backoff. International Conference on Natural
Language Processing and Knowledge Engineering,
Dalian, China, pp. 1–8.
</reference>
<page confidence="0.995784">
153
</page>
<reference confidence="0.999320696969697">
Kiraz, G. A. (2001) Computational Nonlinear Mor-
phology: With Emphasis on Semitic Languages.
Cambridge University Press.
Kudo, Taku, Yuji Matsumoto. (2003) Fast Methods
for Kernel-Based Text Analysis. 41st Annual
Meeting of the Association for Computational Lin-
guistics (ACL-2003), Sapporo, Japan.
Kukich, Karen. (1992) Techniques for automatically
correcting words in text. Computing Surveys,
24(4), pp. 377–439.
Lafferty, John, Andrew McCallum, and Fernando
Pereira. (2001) Conditional random fields: Proba-
bilistic models for segmenting and labeling se-
quence data, In Proceedings of the International
Conference on Machine Learning (ICML 2001), ,
MA, USA, pp. 282-289.
Levenshtein, V. I. (1966) Binary codes capable of
correcting deletions, insertions, and reversals. In:
Soviet Physics Doklady, pp. 707-710.
Magdy, W., and Darwish, K. (2006) Arabic OCR er-
ror correction using character segment correction,
language modeling, and shallow morphology.
EMNLP &apos;06 Proceedings of the 2006 Conference
on Empirical Methods in Natural Language Pro-
cessing.
Mohit, Behrang, Alla Rozovskaya, Nizar Habash,
Wajdi Zaghouani, and Ossama Obeid, 2014. The
First QALB Shared Task on Automatic Text Cor-
rection for Arabic. In Proceedings of EMNLP
workshop on Arabic Natural Language Processing.
Doha, Qatar.
Ng, Hwee Tou, Siew Mei Wu, Yuanbin Wu, Christian
Hadiwinoto, and Joel Tetreault. (2013) The
CoNLL-2013 Shared Task on Grammatical Error
Correction. Proceedings of the Seventeenth Con-
ference on Computational Natural Language
Learning: Shared Task, pages 1–12, Sofia, Bulgar-
ia, August 8-9 2013.
Norvig, P. (2009) Natural language corpus data. In
Beautiful Data, edited by Toby Segaran and Jeff
Hammerbacher, pp. 219-“-242. Sebastopol, Ca-
lif.: O&apos;Reilly.
Och, Franz Josef, Hermann Ney. (2003) A Systematic
Comparison of Various Statistical Alignment
Models. In Computational Linguistics, volume 29,
number 1, pp. 19-51 March 2003.
Parker, R., Graff, D., Chen, K., Kong, J., and Maeda,
K. (2009) Arabic Gigaword Fifth Edition. LDC
Catalog No.: LDC2009T30, ISBN: 1-58563-532-4.
Parker, R., Graff, D., Chen, K., Kong, J., and Maeda,
K. (2011) Arabic Gigaword Fifth Edition. LDC
Catalog No.: LDC2011T11, ISBN: 1-58563-595-2.
Pasha, Arfath, Mohamed Al-Badrashiny, Ahmed El
Kholy, Ramy Eskander, Mona Diab, Nizar Habash,
Manoj Pooleery, Owen Rambow, Ryan Roth.
(2014) Madamira: A fast, comprehensive tool for
morphological analysis and disambiguation of Ar-
abic. In Proceedings of the 9th International Con-
ference on Language Resources and Evaluation,
Reykjavik, Iceland.
Ratcliffe, Robert R. (1998) The Broken Plural Prob-
lem in Arabic and Comparative Semitic: Allo-
morphy and Analogy in Non-concatenative Mor-
phology. Amsterdam studies in the theory and his-
tory of linguistic science. Series IV, Current issues
in linguistic theory ; v. 168. Amsterdam ; Philadel-
phia: J. Benjamins.
Roth, R. Rambow, O., Habash, N., Diab, M., and
Rudin, C. (2008) Arabic Morphological Tagging,
Diacritization, and Lemmatization Using Lexeme
Models and Feature Ranking. Proceedings of ACL-
08: HLT, Short Papers, pp. 117–120.
Shaalan, K., Samih, Y., Attia, M., Pecina, P., and van
Genabith, J. (2012) Arabic Word Generation and
Modelling for Spell Checking. Language Re-
sources and Evaluation (LREC). Istanbul, Turkey.
pp. 719–725.
Stolcke, A., Zheng, J., Wang, W., and Abrash, V.
(2011) SRILM at sixteen: Update and outlook. in
Proc. IEEE Automatic Speech Recognition and
Understanding Workshop. Waikoloa, Hawaii.
van Delden, Sebastian, David B. Bracewell, and Fer-
nando Gomez. (2004) Supervised and Unsuper-
vised Automatic Spelling Correction Algorithms.
In proceeding of Information Reuse and Integration
(IRI). Proceedings of the 2004 IEEE International
Conference on Web Services, pp. 530–535.
Wu, Jian-cheng, Hsun-wen Chiu, and Jason S. Chang.
(2013) Integrating Dictionary and Web N-grams
for Chinese Spell Checking. Computational Lin-
guistics and Chinese Language Processing. Vol.
18, No. 4, December 2013, pp. 17–30.
Zaghouani, Wajdi, Behrang Mohit, Nizar Habash,
Ossama Obeid, Nadi Tomeh, Alla Rozovskaya,
Noura Farra, Sarah Alkuhlani, and Kemal Oflazer.
2014. Large Scale Arabic Error Annotation: Guide-
lines and Framework. In Proceedings of the Ninth
International Conference on Language Resources
and Evaluation (LREC’14), Reykjavik, Iceland.
</reference>
<page confidence="0.999771">
154
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944663">
<title confidence="0.99992">Hybrid Arabic Spelling and Punctuation</title>
<author confidence="0.99946">Mohammed Attia</author>
<author confidence="0.99946">Mohamed Al-Badrashiny</author>
<author confidence="0.99946">Mona</author>
<affiliation confidence="0.9997955">Department of Computer The George Washington University</affiliation>
<email confidence="0.979952">{Mohattia;badrashiny;mtdiab}@gwu.edu</email>
<abstract confidence="0.99803395">In this paper, we describe our Hybrid Arabic Spelling and Punctuation Corrector (HASP). HASP was one of the systems participating in the QALB-2014 Shared Task on Arabic Error Correction. The system uses a CRF (Conditional Random Fields) classifier for correcting punctuation errors, an open-source dictionary (or word list) for detecting errors and generating and filtering candidates, an n-gram language model for selecting the best candidates, and a set of deterministic rules for text normalization (such as removing diacritics and kashida and converting Hindi numbers into Arabic numerals). We also experiment with word alignment for spelling correction at the character level and report some preliminary results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Alfaifi</author>
<author>E Atwell</author>
</authors>
<title>Arabic Learner Corpora (ALC): a taxonomy of coding errors.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Computing Conference in Arabic (ICCA 2012),</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="2671" citStr="Alfaifi and Atwell, 2012" startWordPosition="406" endWordPosition="409">ent, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthogr</context>
</contexts>
<marker>Alfaifi, Atwell, 2012</marker>
<rawString>Alfaifi, A., and Atwell, E. (2012) Arabic Learner Corpora (ALC): a taxonomy of coding errors. In Proceedings of the 8th International Computing Conference in Arabic (ICCA 2012), Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed I Alkanhal</author>
<author>Mohamed A Al-Badrashiny</author>
<author>Mansour M Alghamdi</author>
<author>Abdulaziz O AlQabbany</author>
</authors>
<title>Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech, and Language Processing,</journal>
<volume>20</volume>
<contexts>
<context position="2758" citStr="Alkanhal et al., 2012" startWordPosition="422" endWordPosition="425">k Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation Arabic has a rich and complex morphology as it applies both concat</context>
<context position="11478" citStr="Alkanhal et al. (2012)" startWordPosition="1840" endWordPosition="1843"> 2.3.1. Word Merges Merged words are when the space(s) between two or more words is deleted, such as QUID �A h&amp;quot;AAlnZAm ‘this system’, which should be اﺍﺬھﮪﮬﻫ �U!111 h&amp;quot;A AlnZAm. They constitute 3.67% and 3.48% of the error types in the shared task’s development and training data, respectively. Attia et al. (2012) used an algorithm for dealing with merged words in Arabic, that is, 𝑙 − 3, where l is the length of a word. For a 7-letter word, their algorithm generates 4 candidates as it allows only a single space to be inserted in a string. Their algorithm, however, is too restricted. By contrast Alkanhal et al. (2012) developed an algorithm with more generative power, that is 21-1. Their algorithm, however, is in practice too general and leads to a huge fan out. For a 7-letter word, it generates 64 solutions. We develop a splitting algorithm by taking into account that the minimum length of words in Arabic is two. Our modified algorithm is 21-4, which creates an effective balance between comprehensiveness and compactness. For the 7-letter word, it generates 8 candidates. However, from Table 5 on merged words and their gold splits, one would question 150 the feasibility of producing more than two splits for</context>
</contexts>
<marker>Alkanhal, Al-Badrashiny, Alghamdi, AlQabbany, 2012</marker>
<rawString>Alkanhal, Mohamed I., Mohamed A. Al-Badrashiny, Mansour M. Alghamdi, and Abdulaziz O. AlQabbany. (2012) Automatic Stochastic Arabic Spelling Correction With Emphasis on Space Insertions and Deletions. IEEE Transactions on Audio, Speech, and Language Processing, Vol. 20, No. 7, September 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jamal Alqinai</author>
</authors>
<title>Mediating punctuation in English Arabic translation.</title>
<date>2013</date>
<journal>Linguistica Atlantica.</journal>
<volume>32</volume>
<contexts>
<context position="4481" citStr="Alqinai, 2013" startWordPosition="690" endWordPosition="691">r ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to the possible overlap between orthographically similar letters in three categories: a) the various shapes of hama &amp; b zahs (اﺍ A , � 1 ) taa marboutah and haa ةﺓ p, هﻩ h); and c) yaa and alif maqsoura (يﻱ y, ىﻯ Y). Ancient Arabic manuscripts were written in scriptura continua, meaning running words without punctuation marks. Punctuation marks were introduced to Arabic mainly through borrowing from European languages via translation (Alqinai, 2013). Although punctuation marks in Arabic are gaining popularity and writers are becoming more aware of their importance, yet many writers still do not follow punctuation conventions as strictly and consistently as English writers. For example, we investigated contemporaneous same sized tokenized (simple tokenization with separation of punctuation) English and Modern Standard Arabic Gigaword edited newswire corpora, we found that 10% of the tokens in the English Gigaword corresponded to punctuation marks, compared to only 3% of the tokens in the Arabic counterpart. Train. % Dev. % Word Count 925,</context>
</contexts>
<marker>Alqinai, 2013</marker>
<rawString>Alqinai, Jamal. (2013) Mediating punctuation in English Arabic translation. Linguistica Atlantica. Vol. 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Attia</author>
<author>P Pecina</author>
<author>L Tounsi</author>
<author>A Toral</author>
<author>J van Genabith</author>
</authors>
<title>An Open-Source Finite State Morphological Transducer for Modern Standard Arabic.</title>
<date>2011</date>
<booktitle>International Workshop on Finite State Methods and Natural Language Processing (FSMNLP).</booktitle>
<location>Blois, France.</location>
<marker>Attia, Pecina, Tounsi, Toral, van Genabith, 2011</marker>
<rawString>Attia, M., Pecina, P., Tounsi, L., Toral, A., and van Genabith, J. (2011) An Open-Source Finite State Morphological Transducer for Modern Standard Arabic. International Workshop on Finite State Methods and Natural Language Processing (FSMNLP). Blois, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammed Attia</author>
<author>Pavel Pecina</author>
<author>Younes Samih</author>
<author>Khaled Shaalan</author>
<author>Josef van Genabith</author>
</authors>
<title>Improved Spelling Error Detection and Correction for Arabic. COLING</title>
<date>2012</date>
<location>Bumbai, India.</location>
<marker>Attia, Pecina, Samih, Shaalan, van Genabith, 2012</marker>
<rawString>Attia, Mohammed, Pavel Pecina, Younes Samih, Khaled Shaalan, Josef van Genabith. 2012. Improved Spelling Error Detection and Correction for Arabic. COLING 2012, Bumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
</authors>
<title>Arabic Morphology Using Only Finite-State Operations.</title>
<date>1998</date>
<booktitle>In The Workshop on Computational Approaches to Semitic languages,</booktitle>
<pages>50--57</pages>
<location>Montreal, Quebec,</location>
<contexts>
<context position="3432" citStr="Beesley, 1998" startWordPosition="526" endWordPosition="527">d correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation Arabic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to t</context>
</contexts>
<marker>Beesley, 1998</marker>
<rawString>Beesley, Kenneth R. (1998). Arabic Morphology Using Only Finite-State Operations. In The Workshop on Computational Approaches to Semitic languages, Montreal, Quebec, pp. 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Othmane Zribi</author>
<author>C</author>
<author>Ben Ahmed</author>
<author>M</author>
</authors>
<title>Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information,</title>
<date>2003</date>
<journal>Lecture Notes in Computer Science, Springer,</journal>
<volume>2773</volume>
<pages>770--777</pages>
<marker>Zribi, C, Ahmed, M, 2003</marker>
<rawString>Ben Othmane Zribi, C. and Ben Ahmed, M. (2003) Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information, Lecture Notes in Computer Science, Springer, Vol. 2773, pp.770–777.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="2369" citStr="Brill and Moore, 2000" startWordPosition="354" endWordPosition="357">phasis. HASP in its current stage only handles types (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. </context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Brill, Eric and Moore, Robert C. (2000) An improved error model for noisy channel spelling correction. Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, Hong Kong, pp. 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>Della Pietra</author>
<author>V J</author>
<author>P V de Souza</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Class-Based n-gram Models of Natural Language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<pages>467--479</pages>
<marker>Brown, Pietra, J, de Souza, Lai, Mercer, 1992</marker>
<rawString>Brown, P. F., Della Pietra, V. J., de Souza, P. V., Lai, J. C. and Mercer, R. L. (1992) Class-Based n-gram Models of Natural Language. Computational Linguistics, 18(4), 467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer (BAMA) Version 2.0. Linguistic Data Consortium (LDC) catalogue number: LDC2004L02,</title>
<date>2004</date>
<pages>1--58563</pages>
<contexts>
<context position="3912" citStr="Buckwalter, 2004" startWordPosition="595" endWordPosition="596">ic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to the possible overlap between orthographically similar letters in three categories: a) the various shapes of hama &amp; b zahs (اﺍ A , � 1 ) taa marboutah and haa ةﺓ p, هﻩ h); and c) yaa and alif maqsoura (يﻱ y, ىﻯ Y). Ancient Arabic manuscripts were written in scriptura continua, meaning running words without punctuation marks. Punctuation marks were introduced to Arabic mainly through borrowing from European languages via translation (Alqinai, 2013). Although punctuation marks in</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Buckwalter, T. (2004b) Buckwalter Arabic Morphological Analyzer (BAMA) Version 2.0. Linguistic Data Consortium (LDC) catalogue number: LDC2004L02, ISBN1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Issues in Arabic orthography and morphology analysis.</title>
<date>2004</date>
<booktitle>Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages. Pages 31-34. Association for Computational Linguistics</booktitle>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3912" citStr="Buckwalter, 2004" startWordPosition="595" endWordPosition="596">ic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to the possible overlap between orthographically similar letters in three categories: a) the various shapes of hama &amp; b zahs (اﺍ A , � 1 ) taa marboutah and haa ةﺓ p, هﻩ h); and c) yaa and alif maqsoura (يﻱ y, ىﻯ Y). Ancient Arabic manuscripts were written in scriptura continua, meaning running words without punctuation marks. Punctuation marks were introduced to Arabic mainly through borrowing from European languages via translation (Alqinai, 2013). Although punctuation marks in</context>
</contexts>
<marker>Buckwalter, 2004</marker>
<rawString>Buckwalter, Tim. (2004a) Issues in Arabic orthography and morphology analysis. Proceedings of the Workshop on Computational Approaches to Arabic Script-based Languages. Pages 31-34. Association for Computational Linguistics Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>William A Gale</author>
</authors>
<title>Probability scoring for spelling correction.</title>
<date>1991</date>
<journal>Statistics and Computing,</journal>
<volume>1</volume>
<pages>93--103</pages>
<contexts>
<context position="2332" citStr="Church and Gale, 1991" startWordPosition="348" endWordPosition="351">subcontract from Raytheon BBN. for emphasis. HASP in its current stage only handles types (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that </context>
</contexts>
<marker>Church, Gale, 1991</marker>
<rawString>Church, Kenneth W. and William A. Gale. (1991) Probability scoring for spelling correction. Statistics and Computing, 1, pp. 93–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Better evaluation for grammatical error correction.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="17386" citStr="Dahlmeier and Ng (2012)" startWordPosition="2821" endWordPosition="2824">del is trained on the Gigaword Corpus 4th edition (Parker et al., 2009). For the LM disambiguation we use the ‘Ðfb’ option (forward-backward tracking), and we provide candidates with probability scores. We generate these probability scores by converting the edit distance scores produced by the Foma FST re-ranker explained above. Both of the forwardbackward tracking and the probability scores in in tandem yield better results than the default values. We evaluate the performance of our system against the gold standard using the MaxMatch (M2) method for evaluating grammatical error correction by Dahlmeier and Ng (2012). The best f-score achieved in our system is obtained when we combine the CRF punctuation classifier (merged with the original punctuations found in data), knowledge-based normalization (norm), dictionary-LM disambiguation and split1, as shown in Table 8. The option split-1 refers to using the splitting algorithm 𝑙 − 3 as explained in Section 2.3.1, while split-2 refers to using the splitting algorithm 21-4. # Experiment R P F 1 LM+split-1 33.32 73.71 45.89 2 +CRF_punc+split-1 49.74 65.38 56.50 3 + norm+split-1 38.81 69.08 49.70 4 +CRF_punc+norm 54.79 67.65 60.55 +split-1 5 +CRF_punc+norm 53.1</context>
</contexts>
<marker>Dahlmeier, Ng, 2012</marker>
<rawString>Dahlmeier, Daniel and Ng, Hwee Tou. 2012. Better evaluation for grammatical error correction. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred J Damerau</author>
</authors>
<title>A Technique for Computer Detection and Correction of Spelling Errors.</title>
<date>1964</date>
<journal>Communications of the ACM, Volum</journal>
<volume>7</volume>
<pages>171--176</pages>
<contexts>
<context position="2309" citStr="Damerau, 1964" startWordPosition="346" endWordPosition="347">T program with subcontract from Raytheon BBN. for emphasis. HASP in its current stage only handles types (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous </context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>Damerau, Fred J. (1964) A Technique for Computer Detection and Correction of Spelling Errors. Communications of the ACM, Volum 7, issue 3, pp. 171–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Xiaolong Li</author>
<author>Daniel Micol</author>
<author>Chris Quirk</author>
<author>Xu Sun</author>
</authors>
<title>A large scale rankerbased system for search query spelling correction.</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010),</booktitle>
<pages>358--366</pages>
<location>Beijing, China</location>
<marker>Gao, Li, Micol, Quirk, Sun, 2010</marker>
<rawString>Gao, Jianfeng, Xiaolong Li, Daniel Micol, Chris Quirk, and Xu Sun. (2010) A large scale rankerbased system for search query spelling correction. Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), pages 358–366, Beijing, China</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
</authors>
<title>A Bayesian Hybrid Method for Context-sensitive Spelling Correction.</title>
<date>1995</date>
<booktitle>In Proceedings of the Third Workshop on Very Large Corpora. MIT,</booktitle>
<pages>39--53</pages>
<location>Cambridge, Massachusetts, USA.</location>
<contexts>
<context position="2409" citStr="Golding, 1995" startWordPosition="363" endWordPosition="364">ypes (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Mod</context>
</contexts>
<marker>Golding, 1995</marker>
<rawString>Golding, Andrew R. A Bayesian Hybrid Method for Context-sensitive Spelling Correction. In Proceedings of the Third Workshop on Very Large Corpora. MIT, Cambridge, Massachusetts, USA. 1995, pp.39–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>Applying Winnow to Context-Sensitive Spelling Correction.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth International Conference on Machine Learning,</booktitle>
<pages>182--190</pages>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="2433" citStr="Golding and Roth, 1996" startWordPosition="365" endWordPosition="368">and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by</context>
</contexts>
<marker>Golding, Roth, 1996</marker>
<rawString>Golding, Andrew R., and Dan Roth. (1996) Applying Winnow to Context-Sensitive Spelling Correction. In Proceedings of the Thirteenth International Conference on Machine Learning, Stroudsburg, PA, USA, pp. 182–190</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Y Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<journal>Synthesis Lectures on Human Language Technologies</journal>
<volume>3</volume>
<pages>1--187</pages>
<contexts>
<context position="3447" citStr="Habash, 2010" startWordPosition="528" endWordPosition="529">oblem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation Arabic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basically related to the possible ove</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Habash, Nizar Y. (2010) Introduction to Arabic Natural Language Processing. Synthesis Lectures on Human Language Technologies 3.1: 1-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Haddad</author>
<author>M Yaseen</author>
</authors>
<title>Detection and Correction of Non-Words in Arabic: A Hybrid Approach.</title>
<date>2007</date>
<journal>International Journal of Computer Processing of Oriental Languages.</journal>
<volume>20</volume>
<contexts>
<context position="2645" citStr="Haddad and Yaseen, 2007" startWordPosition="402" endWordPosition="405">ch that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 </context>
</contexts>
<marker>Haddad, Yaseen, 2007</marker>
<rawString>Haddad, B., and Yaseen, M. (2007) Detection and Correction of Non-Words in Arabic: A Hybrid Approach. International Journal of Computer Processing of Oriental Languages. Vol. 20, No. 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical Normalisation of Short Text Messages: Makn Sens a #twitter.</title>
<date>2011</date>
<booktitle>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>368--378</pages>
<location>Portland, Oregon,</location>
<contexts>
<context position="2509" citStr="Han and Baldwin, 2011" startWordPosition="378" endWordPosition="381"> treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, wh</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Han, Bo and Timothy Baldwin. (2011) Lexical Normalisation of Short Text Messages: Makn Sens a #twitter. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 368–378, Portland, Oregon, June 19-24, 2011</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hassan</author>
<author>S Noeman</author>
<author>H Hassan</author>
</authors>
<title>Language Independent Text Correction using Finite State Automata.</title>
<date>2008</date>
<location>IJCNLP. Hyderabad, India.</location>
<contexts>
<context position="2692" citStr="Hassan et al., 2008" startWordPosition="410" endWordPosition="413">mponents are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation </context>
</contexts>
<marker>Hassan, Noeman, Hassan, 2008</marker>
<rawString>Hassan, A, Noeman, S., and Hassan, H. (2008) Language Independent Text Correction using Finite State Automata. IJCNLP. Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hulden</author>
</authors>
<title>Foma: a Finite-state compiler and library.</title>
<date>2009</date>
<booktitle>EACL &apos;09 Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics</booktitle>
<location>Stroudsburg, PA, USA</location>
<contexts>
<context position="15232" citStr="Hulden, 2009" startWordPosition="2451" endWordPosition="2452">ilizing the annotated data in the shared task’s training data. We add 776 new valid words to the dictionary and remove 4,810 misspelt words, leading to significant improvement in the dictionary’s ability to make decisions on words. Table 6 shows the dictionary’s performance on the training and development set in the shared task as applied only to non-words and excluding grammatical, semantic and punctuation errors. data set R P F Training 98.84 96.34 97.57 Development 98.72 96.04 97.36 Table 6. Results of dictionary error detection b. Candidate Generation For candidate generation we use Foma (Hulden, 2009), a finite state compiler that is capable of producing candidates from a wordlist (compiled as an FST network) within a certain edit distance from an error word. Foma allows the ranking of candidates according to customizable transformation rules. # Error Type Count Ratio % أﺃ &gt; typed as اﺍ A 59,507 31.82 Insert 28.945 15.48 إﺇ &lt; typed as اﺍ A 25.392 13.58 Delete 18.246 9.76 ةﺓ p typed as هﻩ h 14.639 7.83 Split 11.419 6.11 يﻱ y typed as ىﻯ Y 6.419 3.43 Table 7. Error types in the training set We develop a re-ranker based on our observation of the error types in the shared task’s training data </context>
</contexts>
<marker>Hulden, 2009</marker>
<rawString>Hulden, M. (2009) Foma: a Finite-state compiler and library. EACL &apos;09 Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics Stroudsburg, PA, USA</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aminul Islam</author>
<author>Diana Inkpen</author>
</authors>
<title>Real-Word Spelling Correction using Google Web 1T n-gram with</title>
<date>2009</date>
<booktitle>Backoff. International Conference on Natural Language Processing and Knowledge Engineering,</booktitle>
<pages>1--8</pages>
<location>Dalian, China,</location>
<marker>Islam, Inkpen, 2009</marker>
<rawString>Islam, Aminul, Diana Inkpen. (2009) Real-Word Spelling Correction using Google Web 1T n-gram with Backoff. International Conference on Natural Language Processing and Knowledge Engineering, Dalian, China, pp. 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Kiraz</author>
</authors>
<title>Computational Nonlinear Morphology: With Emphasis on Semitic Languages.</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<marker>Kiraz, 2001</marker>
<rawString>Kiraz, G. A. (2001) Computational Nonlinear Morphology: With Emphasis on Semitic Languages. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast Methods for Kernel-Based Text Analysis.</title>
<date>2003</date>
<booktitle>41st Annual Meeting of the Association for Computational Linguistics (ACL-2003),</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="9567" citStr="Kudo and Matsumoto, 2003" startWordPosition="1497" endWordPosition="1500">c Treebank (PATB) tokenization (e.g., لﻝ+ -)�=l l+Alt$Awr); (3) Kulick POS tag (e.g., IN+DT+NN). (4) Buckwalter POS tag (e.g., PREP+DET+ NOUN+CASE_DEF_GN) as produced by MADAMIRA; (5) Classes to be predicted: colon_after, comma_after, exclmark_after, period_after, qmark_after, semicolon_after and NA (when no punctuation marks are used); Window Recall Precision F-measure Size 4 36.24 54.09 43.40 5 37.95 59.61 46.37 6 36.65 59.99 45.50 7 34.50 59.53 43.68 Table 3. Yamcha results on the development set For classification, we experiment with Support Vector Machines (SVM) as implemented in Yamcha (Kudo and Matsumoto, 2003) and Conditional Random Field (CRF++) classifiers (Lafferty et al. 2001). In our investigation, we vary the context window size from 4 to 8 and we use all 5 features listed for every word in the window. As Tables 3 and 4 show, we found that window size 5 gives the best f-score by both Yamcha and CRF. When we strip clitics from tokenized tag, reducing it to stems only, the performance of the system improved. Overall CRF yields significantly higher results using the same experimental setup. We assume that the performance advantage of CRF is a result of the way words in the context and their feat</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Kudo, Taku, Yuji Matsumoto. (2003) Fast Methods for Kernel-Based Text Analysis. 41st Annual Meeting of the Association for Computational Linguistics (ACL-2003), Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for automatically correcting words in text.</title>
<date>1992</date>
<journal>Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<pages>377--439</pages>
<contexts>
<context position="2346" citStr="Kukich, 1992" startWordPosition="352" endWordPosition="353">on BBN. for emphasis. HASP in its current stage only handles types (a), (b), and (e) errors. We assume that the various error types are too distinct to be treated with the same computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punct</context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Kukich, Karen. (1992) Techniques for automatically correcting words in text. Computing Surveys, 24(4), pp. 377–439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data,</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML</booktitle>
<pages>282--289</pages>
<location>MA, USA,</location>
<contexts>
<context position="9639" citStr="Lafferty et al. 2001" startWordPosition="1508" endWordPosition="1512">ag (e.g., IN+DT+NN). (4) Buckwalter POS tag (e.g., PREP+DET+ NOUN+CASE_DEF_GN) as produced by MADAMIRA; (5) Classes to be predicted: colon_after, comma_after, exclmark_after, period_after, qmark_after, semicolon_after and NA (when no punctuation marks are used); Window Recall Precision F-measure Size 4 36.24 54.09 43.40 5 37.95 59.61 46.37 6 36.65 59.99 45.50 7 34.50 59.53 43.68 Table 3. Yamcha results on the development set For classification, we experiment with Support Vector Machines (SVM) as implemented in Yamcha (Kudo and Matsumoto, 2003) and Conditional Random Field (CRF++) classifiers (Lafferty et al. 2001). In our investigation, we vary the context window size from 4 to 8 and we use all 5 features listed for every word in the window. As Tables 3 and 4 show, we found that window size 5 gives the best f-score by both Yamcha and CRF. When we strip clitics from tokenized tag, reducing it to stems only, the performance of the system improved. Overall CRF yields significantly higher results using the same experimental setup. We assume that the performance advantage of CRF is a result of the way words in the context and their features are interconnected in a neat grid in the template file. # Window Re</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, John, Andrew McCallum, and Fernando Pereira. (2001) Conditional random fields: Probabilistic models for segmenting and labeling sequence data, In Proceedings of the International Conference on Machine Learning (ICML 2001), , MA, USA, pp. 282-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V I Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals. In: Soviet Physics Doklady,</title>
<date>1966</date>
<pages>707--710</pages>
<marker>Levenshtein, 1966</marker>
<rawString>Levenshtein, V. I. (1966) Binary codes capable of correcting deletions, insertions, and reversals. In: Soviet Physics Doklady, pp. 707-710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Magdy</author>
<author>K Darwish</author>
</authors>
<title>Arabic OCR error correction using character segment correction, language modeling, and shallow morphology.</title>
<date>2006</date>
<booktitle>EMNLP &apos;06 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Magdy, Darwish, 2006</marker>
<rawString>Magdy, W., and Darwish, K. (2006) Arabic OCR error correction using character segment correction, language modeling, and shallow morphology. EMNLP &apos;06 Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Alla Rozovskaya</author>
<author>Nizar Habash</author>
<author>Wajdi Zaghouani</author>
<author>Ossama Obeid</author>
</authors>
<date>2014</date>
<booktitle>The First QALB Shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP workshop on Arabic Natural Language Processing.</booktitle>
<location>Doha, Qatar.</location>
<contexts>
<context position="1199" citStr="Mohit et al., 2014" startWordPosition="172" endWordPosition="175">nd filtering candidates, an n-gram language model for selecting the best candidates, and a set of deterministic rules for text normalization (such as removing diacritics and kashida and converting Hindi numbers into Arabic numerals). We also experiment with word alignment for spelling correction at the character level and report some preliminary results. 1 Introduction In this paper we describe our system for Arabic spelling error detection and correction, Hybrid Arabic Spelling and Punctuation Corrector (HASP). We participate with HASP in the QALB-2014 Shared Task on Arabic Error Correction (Mohit et al., 2014) as part of the Arabic Natural Language Processing Workshop (ANLP) taking place at EMNLP 2014. The shared task data deals with “errors” in the general sense which comprise: a) punctuation errors; b) non-word errors; c) real-word spelling errors; d) grammatical errors; and, e) orthographical errors such as elongation (kashida) and speech effects such as character multiplication 1 This work was supported by the Defense Advanced Research Projects Agency (DARPA) Contract No. HR0011-12-C-0014, BOLT program with subcontract from Raytheon BBN. for emphasis. HASP in its current stage only handles type</context>
</contexts>
<marker>Mohit, Rozovskaya, Habash, Zaghouani, Obeid, 2014</marker>
<rawString>Mohit, Behrang, Alla Rozovskaya, Nizar Habash, Wajdi Zaghouani, and Ossama Obeid, 2014. The First QALB Shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP workshop on Arabic Natural Language Processing. Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Siew Mei Wu</author>
<author>Yuanbin Wu</author>
<author>Christian Hadiwinoto</author>
<author>Joel Tetreault</author>
</authors>
<date>2013</date>
<booktitle>The CoNLL-2013 Shared Task on Grammatical Error Correction. Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--12</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="8295" citStr="Ng et al., 2013" startWordPosition="1299" endWordPosition="1302">s a general rule letters repeated three times or more are reduced to one letter (715 times); 3. Elongation or kashida is removed. For example, �L-.&apos; dm__A&apos; ‘blood’ is converted to 149 ءﺎﻣدﺩ dmA&apos; (906 times); 4. Special character U+06CC, the Farsi yeh: یﯼ is converted to U+0649, the visually similar Arabic alif maqsoura ىﻯ Y (293 times). 2.2 Punctuation Errors Punctuation errors constitute 40% of the errors in the QALB Arabic data. It is worth noting that by comparison, punctuation errors only constituted 4% of the English data in CoNLL 2013 Shared Task on English Grammatical Error Correction (Ng et al., 2013) and were not evaluated or handled by any participant. In HASP, we focus on 6 punctuation marks: comma, colon, semi-colon, exclamation mark, question mark and period. The ‘column’ file in the QALB shared task data comes preprocessed with the MADAMIRA morphological analyzer version 04092014-1.0- beta (Pasha et al., 2014). The features that we utilize in our punctuation classification experiments are all extracted from the ‘column’ file, and they are as follows: (1) The original word, that is the word as it appears in the text without any further processing, (e.g., -).sL= llt$Awr ‘for consulting</context>
</contexts>
<marker>Ng, Wu, Wu, Hadiwinoto, Tetreault, 2013</marker>
<rawString>Ng, Hwee Tou, Siew Mei Wu, Yuanbin Wu, Christian Hadiwinoto, and Joel Tetreault. (2013) The CoNLL-2013 Shared Task on Grammatical Error Correction. Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task, pages 1–12, Sofia, Bulgaria, August 8-9 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Norvig</author>
</authors>
<title>Natural language corpus data. In Beautiful Data, edited by Toby Segaran and Jeff Hammerbacher,</title>
<date>2009</date>
<pages>219--242</pages>
<location>Sebastopol, Calif.: O&apos;Reilly.</location>
<marker>Norvig, 2009</marker>
<rawString>Norvig, P. (2009) Natural language corpus data. In Beautiful Data, edited by Toby Segaran and Jeff Hammerbacher, pp. 219-“-242. Sebastopol, Calif.: O&apos;Reilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>29</volume>
<pages>pp.</pages>
<contexts>
<context position="18824" citStr="Och and Ney, 2003" startWordPosition="3063" endWordPosition="3066">ble 8, and System 2 corresponds to configuration 6, and the results on the test set are shown # Experiment R P F 1 System 1 52.98 75.47 62.25 2 System 2 52.99 75.34 62.22 Table 9. Final official results on the test set provided by the Shared Task 2.3.3.2. Alignment-Based Correction We formatted the data for alignment using a window of 4 words: one word to each side (forming the contextual boundary) and two words in the middle. The two words in the middle are split into characters so that character transformations can be observed and learned by the aligner. The alignment tool we use is Giza++ (Och and Ney, 2003). Results are reported in Table 10. # Experiment R P F 1 for all error types 36.05 45.13 37.99 2 excluding punc 32.37 54.65 40.66 3 2 + CRF_punc+norm 46.11 62.02 52.90 Table 10. Results of character-based alignment Although these preliminary results from Alignment are significantly below results yielded from the Dictionary-LM approach, we believe that there are several potential improvements that need to be explored: • Using LM on the output of the alignment; • Determining the type of errors that the alignment is most successful at handling: punctuation, grammar, non-words, etc; • Parsing trai</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Och, Franz Josef, Hermann Ney. (2003) A Systematic Comparison of Various Statistical Alignment Models. In Computational Linguistics, volume 29, number 1, pp. 19-51 March 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parker</author>
<author>D Graff</author>
<author>K Chen</author>
<author>J Kong</author>
<author>K Maeda</author>
</authors>
<date>2009</date>
<booktitle>Arabic Gigaword Fifth Edition. LDC Catalog No.: LDC2009T30, ISBN:</booktitle>
<pages>1--58563</pages>
<contexts>
<context position="16834" citStr="Parker et al., 2009" startWordPosition="2734" endWordPosition="2737">ticipating in the shared task. c. Error Correction For error correction, namely selecting the best solution among the list of candidates, we use an n-gram language model (LM), as implemented in the SRILM package (Stolcke et al., 2011). We use the ‘disambig’ tool for selecting candidates from a map file where erroneous words are provided with a list of possible corrections. We also use the ‘ngram’ utility in post-processing for deciding on whether a split-word solution has a better probability than a single word solution. Our bigram language model is trained on the Gigaword Corpus 4th edition (Parker et al., 2009). For the LM disambiguation we use the ‘Ðfb’ option (forward-backward tracking), and we provide candidates with probability scores. We generate these probability scores by converting the edit distance scores produced by the Foma FST re-ranker explained above. Both of the forwardbackward tracking and the probability scores in in tandem yield better results than the default values. We evaluate the performance of our system against the gold standard using the MaxMatch (M2) method for evaluating grammatical error correction by Dahlmeier and Ng (2012). The best f-score achieved in our system is obt</context>
</contexts>
<marker>Parker, Graff, Chen, Kong, Maeda, 2009</marker>
<rawString>Parker, R., Graff, D., Chen, K., Kong, J., and Maeda, K. (2009) Arabic Gigaword Fifth Edition. LDC Catalog No.: LDC2009T30, ISBN: 1-58563-532-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parker</author>
<author>D Graff</author>
<author>K Chen</author>
<author>J Kong</author>
<author>K Maeda</author>
</authors>
<title>Arabic Gigaword Fifth Edition.</title>
<date>2011</date>
<booktitle>LDC Catalog No.: LDC2011T11, ISBN:</booktitle>
<pages>1--58563</pages>
<marker>Parker, Graff, Chen, Kong, Maeda, 2011</marker>
<rawString>Parker, R., Graff, D., Chen, K., Kong, J., and Maeda, K. (2011) Arabic Gigaword Fifth Edition. LDC Catalog No.: LDC2011T11, ISBN: 1-58563-595-2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of the 9th International Conference on Language Resources and Evaluation,</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Pasha, Al-Badrashiny, El Kholy, Eskander, Diab, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Pasha, Arfath, Mohamed Al-Badrashiny, Ahmed El Kholy, Ramy Eskander, Mona Diab, Nizar Habash, Manoj Pooleery, Owen Rambow, Ryan Roth. (2014) Madamira: A fast, comprehensive tool for morphological analysis and disambiguation of Arabic. In Proceedings of the 9th International Conference on Language Resources and Evaluation, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert R Ratcliffe</author>
</authors>
<title>The Broken Plural Problem in Arabic and Comparative Semitic: Allomorphy and Analogy in Non-concatenative Morphology. Amsterdam studies in the theory and history of linguistic science.</title>
<date>1998</date>
<journal>J. Benjamins.</journal>
<booktitle>Series IV, Current issues in linguistic theory ; v. 168.</booktitle>
<location>Amsterdam ; Philadelphia:</location>
<contexts>
<context position="3417" citStr="Ratcliffe, 1998" startWordPosition="524" endWordPosition="525">rror detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better results than the default Viterbi. We also develop a new and more efficient splitting algorithm for merged words. 1.2 Arabic Morphology, Orthography and Punctuation Arabic has a rich and complex morphology as it applies both concatenative and nonconcatenative morphotactics (Ratcliffe, 1998; Beesley, 1998; Habash, 2010), yielding a wealth of morphemes that express various morpho148 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 148–154, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics syntactic features, such as tense, person, number, gender, voice and mood. Arabic has a large array of orthographic variations, leading to what is called ‘typographic errors’ or ‘orthographic variations’ (Buckwalter, 2004a), and sometimes referred to as substandard spellings, or spelling soft errors. These errors are basical</context>
</contexts>
<marker>Ratcliffe, 1998</marker>
<rawString>Ratcliffe, Robert R. (1998) The Broken Plural Problem in Arabic and Comparative Semitic: Allomorphy and Analogy in Non-concatenative Morphology. Amsterdam studies in the theory and history of linguistic science. Series IV, Current issues in linguistic theory ; v. 168. Amsterdam ; Philadelphia: J. Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rambow Roth</author>
<author>O Habash</author>
<author>N Diab</author>
<author>M</author>
<author>C Rudin</author>
</authors>
<title>Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking.</title>
<date>2008</date>
<booktitle>Proceedings of ACL08: HLT, Short Papers,</booktitle>
<pages>117--120</pages>
<marker>Roth, Habash, Diab, M, Rudin, 2008</marker>
<rawString>Roth, R. Rambow, O., Habash, N., Diab, M., and Rudin, C. (2008) Arabic Morphological Tagging, Diacritization, and Lemmatization Using Lexeme Models and Feature Ranking. Proceedings of ACL08: HLT, Short Papers, pp. 117–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Shaalan</author>
<author>Y Samih</author>
<author>M Attia</author>
<author>P Pecina</author>
<author>J van Genabith</author>
</authors>
<title>Arabic Word Generation and Modelling for Spell Checking. Language Resources and Evaluation (LREC).</title>
<date>2012</date>
<pages>719--725</pages>
<location>Istanbul,</location>
<marker>Shaalan, Samih, Attia, Pecina, van Genabith, 2012</marker>
<rawString>Shaalan, K., Samih, Y., Attia, M., Pecina, P., and van Genabith, J. (2012) Arabic Word Generation and Modelling for Spell Checking. Language Resources and Evaluation (LREC). Istanbul, Turkey. pp. 719–725.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
<author>J Zheng</author>
<author>W Wang</author>
<author>V Abrash</author>
</authors>
<title>SRILM at sixteen: Update and outlook. in</title>
<date>2011</date>
<booktitle>Proc. IEEE Automatic Speech Recognition and Understanding Workshop.</booktitle>
<location>Waikoloa, Hawaii.</location>
<contexts>
<context position="16448" citStr="Stolcke et al., 2011" startWordPosition="2668" endWordPosition="2671">data (as shown in Table 7) and examining the character transformations between the misspelt words and their gold corrections. Our statistics 151 shows that soft errors (or variants as explained in Section 1.2) account for more than 62% of all errors in the training data. in Table 9. As Table 9 shows, the best scores are obtained by System 1, which is ranked 5th among the 9 systems participating in the shared task. c. Error Correction For error correction, namely selecting the best solution among the list of candidates, we use an n-gram language model (LM), as implemented in the SRILM package (Stolcke et al., 2011). We use the ‘disambig’ tool for selecting candidates from a map file where erroneous words are provided with a list of possible corrections. We also use the ‘ngram’ utility in post-processing for deciding on whether a split-word solution has a better probability than a single word solution. Our bigram language model is trained on the Gigaword Corpus 4th edition (Parker et al., 2009). For the LM disambiguation we use the ‘Ðfb’ option (forward-backward tracking), and we provide candidates with probability scores. We generate these probability scores by converting the edit distance scores produc</context>
</contexts>
<marker>Stolcke, Zheng, Wang, Abrash, 2011</marker>
<rawString>Stolcke, A., Zheng, J., Wang, W., and Abrash, V. (2011) SRILM at sixteen: Update and outlook. in Proc. IEEE Automatic Speech Recognition and Understanding Workshop. Waikoloa, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian van Delden</author>
<author>David B Bracewell</author>
<author>Fernando Gomez</author>
</authors>
<title>Supervised and Unsupervised Automatic Spelling Correction Algorithms.</title>
<date>2004</date>
<booktitle>In proceeding of Information Reuse and Integration (IRI). Proceedings of the 2004 IEEE International Conference on Web Services,</booktitle>
<pages>530--535</pages>
<marker>van Delden, Bracewell, Gomez, 2004</marker>
<rawString>van Delden, Sebastian, David B. Bracewell, and Fernando Gomez. (2004) Supervised and Unsupervised Automatic Spelling Correction Algorithms. In proceeding of Information Reuse and Integration (IRI). Proceedings of the 2004 IEEE International Conference on Web Services, pp. 530–535.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-cheng Wu</author>
<author>Hsun-wen Chiu</author>
<author>Jason S Chang</author>
</authors>
<title>Integrating Dictionary and Web N-grams for Chinese Spell Checking.</title>
<date>2013</date>
<journal>Computational Linguistics and Chinese Language Processing.</journal>
<volume>18</volume>
<pages>17--30</pages>
<contexts>
<context position="2527" citStr="Wu et al., 2013" startWordPosition="382" endWordPosition="385">computational technique. Therefore, we treat each problem separately, and for each problem we select the approach that seems most efficient, and ultimately all components are integrated in a single framework. 1.1 Previous Work Detecting spelling errors in typing is one of the earliest NLP applications, and it has been researched extensively over the years, particularly for English (Damerau, 1964; Church and Gale, 1991; Kukich, 1992; Brill and Moore, 2000; Van Delden et al., 2004; Golding, 1995; Golding and Roth, 1996; Fossati and Di Eugenio, 2007; Islam in Inkpen, 2009; Han and Baldwin, 2011; Wu et al., 2013). The problem of Arabic spelling error correction has been investigated in a number of papers (Haddad and Yaseen, 2007; Alfaifi and Atwell, 2012; Hassan et al., 2008; Shaalan et al., 2012; Attia et al., 2012; Alkanhal et al., 2012). In our research, we address the spelling error detection and correction problem with a focus on non-word errors. Our work is different from previous work on Arabic in that we cover punctuation errors as well. Furthermore, we fine-tune a Language Model (LM) disambiguator by adding probability scores for candidates using forwardbackward tracking, which yielded better</context>
</contexts>
<marker>Wu, Chiu, Chang, 2013</marker>
<rawString>Wu, Jian-cheng, Hsun-wen Chiu, and Jason S. Chang. (2013) Integrating Dictionary and Web N-grams for Chinese Spell Checking. Computational Linguistics and Chinese Language Processing. Vol. 18, No. 4, December 2013, pp. 17–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajdi Zaghouani</author>
</authors>
<title>Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Zaghouani, 2014</marker>
<rawString>Zaghouani, Wajdi, Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014. Large Scale Arabic Error Annotation: Guidelines and Framework. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>