<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000085">
<title confidence="0.986081">
Towards a Description of Symbolic Maps
</title>
<author confidence="0.939345">
Daniel Couto Vale
</author>
<affiliation confidence="0.8892745">
SFB/TR8 Spatial Cognition
University of Bremen
</affiliation>
<note confidence="0.40488">
danielvale@uni-bremen.de
</note>
<author confidence="0.7025">
Elisa Vales
</author>
<affiliation confidence="0.7252105">
SFB/TR8 Spatial Cognition
University of Bremen
</affiliation>
<email confidence="0.270755">
evales@uni-bremen.de
</email>
<author confidence="0.631063">
Rumiya Izgalieva
</author>
<affiliation confidence="0.690592">
SFB/TR8 Spatial Cognition
University of Bremen
</affiliation>
<bodyText confidence="0.366479">
rumiya@uni-bremen.de
</bodyText>
<sectionHeader confidence="0.972848" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999642411764706">
Symbolic resources for text synthesis and
text analysis are typically created and stored
separately. In our case, we have a KPML-
resource (Nigel) and a CCG for English. In
this paper, we argue that reversing efficient
resources such as ours cannot in general be
achieved. For this reason, we propose a
symbolic map that can be converted
automatically into both synthesis- and
analysis-oriented resources. We show that
completeness of description can only be
achieved by such a map while efficiency
concerns can only be tackled by the directed
rules of task-oriented resources not because
of the current state of the art, but because
reversing task-oriented symbolic resources is
impossible in principle.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999885755555556">
Currently, symbolic resources guiding text
analysis and text synthesis are created and stored
separately. Several researchers have attempted
to use the same resource for both tasks (Kasper,
1988; Neumann, 1991; Neumann and van
Noord, 1992; Strzalkowski, 1994; O’Donnell,
1994; Pulman, 1995; Klarner, 2005) motivated
by the fact that this would not only be
cognitively more plausible but also allow
translation at a semantic level, integration of
new words from analysis into synthesis,
reduction of costs in engineering as well as
making it easier to share information among
research groups of different fields.
The resources we currently use in human-
robot interaction in English are also separate: a
KPML-resource (Nigel) and a CCG. The
specialty about Nigel and our CCG is that they
share not only the same kind of semantics, but
also the same mapping between symbolic and
semantic structures. Here ‘symbolic structure’ is
understood as KPML’s ‘structure’ and CCG’s
‘sign’, and corresponds to ‘grammatical
constructions’ of cognitive semantics (Lakoff,
1987), to ‘linguistic mediation’ of truth-
reference semantics (Smith and Brogaard,
2003), and to ‘wording’ of systemic functional
linguistics (Matthiessen, 1995; Matthiessen and
Halliday, 1999; Matthiessen and Halliday, 2004;
Halliday and Matthiessen, 2014).
In this paper, we shall review the available
directed rules that constitute the resources in
KPML and OpenCCG and argue that they are
useful in their respective tasks – either synthesis
or analysis, – but are either unsuitable or not
competitive for the inverse task.
Aiming not at reversibility but at reusability,
we propose to create a map between symbolic
and semantic structures that can be compiled
into both synthesis-oriented and analysis-
oriented resources. With this approach, we aim
at separating concerns, so that efficiency can be
tackled by the directed rules of task-oriented
resources and completeness of description by a
less efficient uncompiled shared symbolic map.
</bodyText>
<sectionHeader confidence="0.96024" genericHeader="method">
2 Irreversibility of Current Resources
</sectionHeader>
<bodyText confidence="0.999880064516129">
In computational linguistics, approaches to
text processing can be divided into statistical
and categorial according to the usage of graded
or binary relations between inputs and outputs of
processing. Approaches can also be divided
depending on whether the textual content is a
representation of something else (symbolic) or
whether it is a representation of the text itself
(non-symbolic). In this sense, approaches that
have a semantic structure as input or output are
symbolic and those that make use of a syntactic
tree whose composite-component relations do
not match the ones of semantics are not. The
present work falls into the symbolic subset.
Although our initial attempt is categorial, the
ideas presented here can be used in statistical
approaches as well, provided that these
approaches are symbolic in nature.
Looking from the perspective of the
philosophy of language, in the last 50 years,
computational efforts in categorial symbolic text
processing have converged on one single notion
of a symbolic map. In such a notion, both
symbolic (lexical or grammatical) and semantic
structures play an essential role in deciding
which analytical and synthetic hypotheses are to
be taken further or discarded. On the text
synthesis front, systemic networks were used by
both KOMET and Penman engines as directed
rules for text synthesis. Those engines were later
unified into the KOMET-Penman Multilingual
</bodyText>
<page confidence="0.997869">
83
</page>
<bodyText confidence="0.998456260869565">
Engine (KPML Engine) (Bateman, 1995a;
Bateman, 1995b; Bateman, 1996; Bateman,
1997). On the text analysis front, typed-feature
unification was developed and implemented in
engines for a family of highly lexicalised
grammatical frameworks (HLG). Combinatory
Categorial Grammars (CCG) (Steedman, 1987;
Steedman, 1996; Steedman, 1998; Steedman and
Baldridge, 2011) are a special type of HLG that
reduce the task of text analysis to accepting or
rejecting hypotheses of both symbolic and
semantic composition during functional
unification. KPML and OpenCCG are then only
candidates for consideration because they allow
the implementation of a shared symbolic map.
In other words, a pair of engines that support
such a map is a necessary and sufficient
condition for the reusability scheme we propose.
In the following, we shall review the
grammatical notions embedded in the resources
for KPML and OpenCCG in order to support our
argumentation that reversibility of such directed
resources is not to be achieved.
</bodyText>
<subsectionHeader confidence="0.704832">
2.1 Resources for KPML
</subsectionHeader>
<bodyText confidence="0.999968476923077">
According to the KPML documentation
(Bateman, 1996) and our own inspection of
Nigel, resources for KMPL may contain three
kinds of realisation operations: structural (insert,
conflate, expand), linear (partition, order, order-
at-front, order-at-end), and inter-rank (preselect,
agreement, classify, outclassify, inflectify,
lexify).
Below symbolic structure, textual tokens are
produced by morphological realisation operators
of two kinds: one for selecting token copies
(preselect-substance, preselect-substance-as-
stem, preselect-substance-as-property), and one
for modifying them (morphose).
These realisation operators are bundled in
wording ‘patterns’ that are linked to classes of
wordings (grammatical features). The typology
arising from these classes is used as a network
of options (network of grammatical systems)
among structure kinds. The selection of a
structure kind of a system is done by a decision
tree (chooser). Each decision in the decision tree
is achieved by inspecting (inquiry) a semantic
and lexical specification for a text. The decision
tree contains not only decisions (ask) but also
mappings from lexical/semantic constituents to
functions of symbolic constituents (identify,
copyhub, choose, pledge, termpledge). Values
can be associated with a function (concept,
modification-specification, terms, term).
Finally, there are four ways to produce a
token in KPML. Three of them consist of
selecting a word and selecting its form with a
form class. The actual token production is left to
a morphological component. Two word selection
strategies are: selecting a word grammatically
(lexify, classify, outclassify) and selecting a
word associated with a particular conceptual
value (term-resolve-id). A mapping between
concepts and words is provided either by
concept-word links (annotate-concept) or by
embedding word specifications into what would
otherwise be a pure semantic specification (lex).
A distinct mapping function between the
intersection of form classes and word pattern
indexes is implemented in LISP for every
linguistic resource. At the morphological level, a
token is produced by selecting a token model
and applying any necessary morphological
modifications to it (preselect-substance,
preselect-substance-as-stem, preselect-
substance-as-property, morphose).
Therefore, as with any other categorial text
synthesiser, KPML traverses a network of
options among progressively finer types of
structures and makes choices between different
structure types depending on semantical and
lexical restrictions. Its speciality comes not from
the general approach, but from the amount and
quality of detailed linguistic knowledge applied
to the synthesis of text in Nigel, which makes
Nigel a good option for our applications that
demand natural utterances. This is also the main
reason why so many attempts have been made to
use Nigel for text analysis.
</bodyText>
<subsectionHeader confidence="0.908636">
2.2 Resources for OpenCCG
</subsectionHeader>
<bodyText confidence="0.999111090909091">
OpenCCG, as for any other engine using
chart parsing, relies on the assumption that a
hypothesised structure is only to be considered if
it is part of a structure for the whole input text.
This assumption of syntagmatic holism was first
formulated by Frege (1884) and Wittgenstein
(1921; 1922). Chart parsing with CCGs goes
beyond: both syntagmatic and paradigmatic
holisms are to be enforced, i.e. semantic fitting
is used as a filter for analytical hypotheses as
well. Such a paradigmatic holism was first
formulated by Davidson (1967).
OpenCCG is an engine for analysing texts
with CCGs (Steedman and Baldridge, 2011;
Bozşahin et al., 2005). It classifies word forms
into categories according to their affordances of
combining with other word forms and structures
in the process of building up larger structures
and construing meaning. In this process, the
empty slots of semantic frames, associated with
a word, are filled up by the semantic values of
the structures that the word form combines with.
</bodyText>
<page confidence="0.996899">
84
</page>
<bodyText confidence="0.999888682926829">
Only complete symbolic and semantic structures
that represent the whole text are kept by the text
analyser (although incomplete structures may
also be retrieved for online text processing).
There are two kinds of combinatory
categories: the complete (atomic) does not
combine with any other structure; the
incomplete (complex) has either a frame with
empty slots or is missing word parts, so it
combines with other structures for semantic or
symbolic completion.
Incomplete categories of symbolic structures
are turned into a complete category by the
OpenCCG engine whenever a structure that is
combinable with a preceding or following
structure of a certain kind is preceded or
followed by a structure of this kind. Slashes \, |
and / indicate that a structure of a combinatory
category is combinable with a structure that
respectively precedes it, is adjacent to it, or
follows it. For instance, the structure of saw
holding a two-slot frame in the clause Mary saw
John can be said to belong to the category
Clause\Mention/Mention, because it expects a
complete mention (Mention) of the sensed thing
after it and a complete mention (Mention) of the
senser before it. The resulting structure after
combination is a complete clause (Clause).
In addition, slashes come in four different
generalities: they may allow no composition (⋆),
only harmonic compositions (◇), only crossing
compositions (×) or any composition (•).
The smallest structures in OpenCCG are
word forms. Word forms (morph entries) map a
token pattern (word) to a word id (stem), a
combinatory category tag (pos), the meaning of
the word (class), and a list of form classes (fs-
macros) and slot fillers (lf-macros). This
terminal mapping is equivalent to the map from
grammatical functions to lexical and semantical
structures in KPML.
</bodyText>
<subsectionHeader confidence="0.997846">
2.3 KPML-Analysis and CCG-Synthesis
</subsectionHeader>
<bodyText confidence="0.999951236111111">
Kay (1979; 1985) developed the Functional
Unification Grammar (FUG) and Kasper (1988)
used FUG for exploring text analysis with Nigel.
Analysing a clause took about 1 minute (cur-
rently approx. 500ms assuming 120-times faster
processors) and analysing a complex clause took
several minutes. Kasper concluded grammars
needed to be “tuned” and augmented for the
inverse task, but also that some information
would be superfluous and counterproductive for
either text synthesis or text analysis. Following
Kasper, O’Donnell (1994) reduced the
descriptive complexity of Nigel to create a text
analyser. After this, Henschel (1995; 1997)
attempted to analyse text with the full Nigel
grammatical description again by abstracting an
open-world typology from a systemic network
and compiling the Nigel resource completely for
the first time into a typed-feature-structure
resource. However, the resource was unusable
for practical text analysis. When reviewing these
previous attempts, Bateman (2008) pointed out
that the conception of systemic-functional
resources alone, as it is, cannot support effective
automatic text analysis due to fundamental
theoretical concerns. That is, the paradigmatic
organisation of the systemic-functional approach
raises an enormous search space problem when
used for text analysis because the network does
not have information about which grammatical
feature is relevant for any given text token. If
one uses such a network for analysing text, one
needs to produce a complete set of all possible
intersections of grammatical features in order to
predict all supported analyses, which is the
solution provided by Kasper and by Henschel.
Bateman shows that this is computationally
intractable for the full version of Nigel’s noun
group and Nigel’s clause.
On the CCG side, broad-coverage surface
realisation has also been attempted (White et al.,
2007; Rudnick, 2010). In order for a CCG to
work for text synthesis, it was enriched with a
customised semantics. The resulting search
space was still too large and, for this reason, a
search heuristic was applied using n-grams, pos-
tags, supertags, and semantic values for
evaluation of paths. The realisation achieved
promising scores with a time-limit of 15 seconds
when trained over the CCGBank – a derivation
corpus with the same sentences as the Penn
TreeBank – and tested over the same sentences.
However, the decision of synthesising a text
with a search heuristic is a consequence of the
fact that the used resource does not hold all the
information necessary for a guided search
algorithm for text synthesis. The reason for this
is also of a theoretical nature. Once structural
information is embedded in word forms,
combinatory categories and type changes, it is
impossible to take this information back out of
them and repack it in a network of options
without counting on two essential constructs for
synthesis: on the one side, semantic composition
and semantic paradigms and, on the other side, a
paradigmatic organisation of classes of structure
provided by disjunct unions of structure classes
(systems). CCGs do not and could not, for
efficiency reasons, rely on logical disjunctions,
which are essential for text synthesis.
To make the consequences of this limitation
more clear, let us take an example of how
</bodyText>
<page confidence="0.998655">
85
</page>
<bodyText confidence="0.957632">
combinatory operators are declared in resources
for OpenCCG (abbreviations: C = Clause, M =
Mention, f = Figure, e = Element):
– danced (I danced)
– stopped dancing (I stopped dancing)
– started dancing (I started dancing)
</bodyText>
<equation confidence="0.993683529411765">
(C[mode-2]:f\M:e0) =&gt; (C[mode-¿]:f\M:e0)
@f&lt;hasTense&gt;e1:Past
– am here (I am here)
(C[mode-1]:f\M:e0) =&gt; (C[mode-¿]:f\M:e0)
@f:State(&lt;hasTense&gt;e1:Present)
– am (I am dancing)
am := (C[mode-¿]:f\M:e0)/(C[mode-6]:f\M:e0)
@f:Change(&lt;hasTense&gt;e1:Present)
– will (I will dance)
will := (C[mode-¿]:f\M:e0)/(C[mode-4]:f\M:e0)
@f&lt;hasTense&gt;e1:Future
– stopped (I stopped dancing)
stopped := (C[mode-2]:f\M:e0)/(C[mode-6]:f\M:e0)
@f&lt;hasPhase&gt;e1:Stop
– started (I started dancing)
started := (C[mode-2]:f\M:e0)/(C[mode-6]:f\M:e0)
@f&lt;hasPhase&gt;e1:Start
</equation>
<subsectionHeader confidence="0.860221">
Simplified extract of our CCG-resource
</subsectionHeader>
<bodyText confidence="0.99998076">
The above combinatory categories and type-
changes cover different semantic contributions,
which are not automatically organisable into
systems of symbolic and semantic classes. First,
the resource for OpenCCG does not have the
information that Past, Present, and Future
constitute a semantic disjunction of TENSE and
that Start and Stop belong to a distinct semantic
disjunction of PHASE. Moreover, the resource
does not have the information that finite clauses
have tense and that non-finite clauses do not, so
that it could decide which system to traverse for
each kind of clause. And, finally, we cannot
guarantee that an inspection of the figure type
happens before the selection of 1) the present
auxiliary am in I am dancing representing a
change in the present and 2) the present form am
of the process of Being in I am here (instead I
am being here) representing a present state. This
incapability of grouping contrasting options and
of conditioning and ordering systems within a
network demands a search algorithm with
backtracking. Because of the computational
costs of backtracking, it also demands a search
heuristic as engineering solution.
</bodyText>
<sectionHeader confidence="0.996904" genericHeader="method">
3 Symbolic Map
</sectionHeader>
<bodyText confidence="0.999808076923077">
We acknowledge the unsuitability of task-
oriented resources for the inverse tasks of
synthesis and analysis and shall tackle the issues
of bridging a paradigmatic text synthesis and a
syntagmatic text analysis at a theoretical level.
We propose to describe a symbolic-semantic
map that can be compiled into task-oriented
resources for separate engines (concretely here:
KPML and OpenCCG): a scheme that falls into
the Reusability Scheme A (reversibility type) of
Klarner (2005) (see Figure 1). In our case, this
reusability scheme applies to both grammar and
lexicon.
</bodyText>
<figureCaption confidence="0.996767">
Figure 1. Reusability Scheme
</figureCaption>
<bodyText confidence="0.999928142857143">
In our argumentation, we shall propose a
reformulation of Nigel as a description in OWL
of a symbolic map that supports the proposed
compilation. Moving from specific to general,
we shall point out which mapping strategies can
be used and show that every descriptive region
of Nigel is representable in such a map.
</bodyText>
<subsectionHeader confidence="0.995648">
3.1 Sketch
</subsectionHeader>
<bodyText confidence="0.999958689655172">
Bateman (2008) has sketched how an
automatic text analysis with systemic-functional
theory (&apos;systemic parse&apos;) needs to look. It needs
a functional description for sequences of text
tokens, including the necessary information both
for assigning grammatical features to structures
and for identifying composites on a sequence of
constituents. Such a symbolic map, we shall see,
needs to account for the systemic-functional
trinocular view of symbolic systems: from
above, from below and from around. Moreover,
it also needs to account for two different
affordances required for a classification of
structures: one that organises disjoint classes as
a system of grammatical features for text
synthesis and another that organises the same
disjunctions as restrictions for the combination
of incomplete structures in text analysis. The
former organisation moves all information of
structure into the grammatical network, whereas
the latter organisation moves it into word forms.
In the reusability scheme of our new
resource, we keep the structural information out
of the systemic network and out of the word
forms. It is stored in a symbolic map that allows
us to pack it into the two task-oriented
resources, i.e. into the systemic network for text
synthesis and into word forms/type changes for
text analysis. We have chosen to represent this
</bodyText>
<page confidence="0.984513">
86
</page>
<bodyText confidence="0.999599">
information in Description Logic (OWL-DL)
since both the typology embedded in a systemic
network for KPML and the typology of features
in the types file for OpenCCG can be derived
from such descriptions.
</bodyText>
<subsectionHeader confidence="0.995688">
3.2 Trinocular View
</subsectionHeader>
<bodyText confidence="0.999871">
When classifying symbolic units, we not
only conceive of them as patterns for
recognition and for expression (from below), but
also as bricks for building up a whole with given
parts and for selecting parts for a planned whole
(from around), and also as devices for
construing meaning and for realising it (from
above). Therefore, all classes of symbols in our
symbolic map will be defined based on their
affordances as patterns, bricks, and devices. So
our approach is different from that of Henschel
(1995; 1997) not only in the fact that we will not
extract a typology in description logic from a
systemic network (in fact, we will do the
opposite), but also in the fact that each structure
will be specified in our description as three
particulars: one classified from above, one from
around, and one from below. The classification
from above is convertible into KPML-inquiries,
the classification from around is convertible to
preselectable grammatical features in KPML,
and the classification from below is related to
groups of realisation statements in KPML. The
definitions of brick classes and of pattern classes
are responsible for their functions as meaning-
making devices (see Figure 2). In the following,
we discuss how these concepts are
operationalised for CCG.
</bodyText>
<figureCaption confidence="0.998881">
Figure 2. Description of Clause in Protégé
</figureCaption>
<subsectionHeader confidence="0.998805">
3.3 Word vs Form vs Copy
</subsectionHeader>
<bodyText confidence="0.999911176470588">
Moving bottom up in the creation of a
descriptive theory, we define a token as a
segment of text that matches a continuous
pattern (of phonemes or graphemes) suitable for
both recognition or expression.
Looking from above, a choice of tokens in a
token sequence such as helpedÉout in he helped
me out represents one single semantic value and
is here understood as corresponding to a single
word, namely HelpOut.
Looking from around, a word form – that of
which a text token is a copy – is defined as
composing a particular word and belonging to a
particular form class. For the word HelpOut,
there are two tokens and therefore two forms,
one of them being that of helped and the other
one being that of out in he helped me out.
</bodyText>
<subsectionHeader confidence="0.992253">
3.4 Pattern vs Brick vs Device
</subsectionHeader>
<bodyText confidence="0.999972105263158">
At the leaves of the semantic dependency
structure are the semantic values of words and at
the corresponding leaves of the symbolic
structure are not words, but the forms of words.
In this sense, a particular word form is related to
three notions: 1) a particular pattern that is used
for recognising and producing tokens (copy), 2)
a device for realising and construing meaning
(word), and 3) a brick for construing larger
symbolic structures (form). At this point, we
have a triplicity of composition. While a brick is
part of a larger symbolic structure, its semantic
value is part of a larger semantic structure and
its physical pattern is recognisable or
produceable in a larger text. In KPML, a
semantic structure is specified externally and the
correspondence between symbolic and semantic
compositionality is guaranteed by the restriction
of attaching either the same semantic structure
or parts of it to the parts of its corresponding
symbolic structure. In OpenCCG, the same
compositionality is guaranteed by applying the
λ-function of an incomplete constituent to the
values of complete constituents (category
application) or by composing the λ-functions of
two chained incomplete constituents
(combinatory rules).
Moreover, symbolic compositionality is
linear in nature. As reflected in both KPML and
OpenCCG, the position of symbolic constituents
may be fixed in relation to other constituents
while the semantic constituents cannot. For
instance, the position of nice in relation to day in
have a nice day is typically realised with the
operation “order Epithet:nice Classifier:day” in
KPML while it is embedded in the word
categories “nice:Classifier/Classifier” and
“day:Classifier” in OpenCCG.
</bodyText>
<sectionHeader confidence="0.987487" genericHeader="method">
4 Target: Nigel coverage
</sectionHeader>
<bodyText confidence="0.999812666666667">
We shall propose a map for every structure
class covered by Nigel by tackling the
theoretical issues.
</bodyText>
<subsectionHeader confidence="0.718791">
4.1 Terms
</subsectionHeader>
<bodyText confidence="0.991387">
In Nigel, form classes are used for selecting
particular forms of a word while in a CCG they
are used for limiting the applicability of the
category of a matched token. Usually the form
</bodyText>
<page confidence="0.99765">
87
</page>
<bodyText confidence="0.997725777777778">
selection and its applicability are related to
either role or agreement restrictions.
In the Nigel grammar, some word classes are
defined for automatically creating tokens from
the stem of a word such as the verb classes “es-
ed” for verbs such as wish (wishes, wished). For
indicating the existence of irregular patterns,
there are word classes such as “irr”. There are
also word classes which are used for controlling
the selection of a token index based on a set of
form classes (or inflectional features) such as
“inflectable”, “noun”, and “verb”. All of these
word classes together belong to morphology
because they are meant to guide the selection of
token models and their modifications into the
patterns to print out or recognise. With such
classes, Nigel is able to reduce the description of
a word to a short code such as the following:
</bodyText>
<figure confidence="0.996736285714286">
&lt;Word id=“Arrive”&gt;
&lt;Class name=“Process” /&gt;
&lt;Class name=“EndingWith-e-es-ed-ing” /&gt;
&lt;SampleMap&gt;
&lt;Sample name=“stem” value=“arrive” /&gt;
&lt;/SampleMap&gt;
&lt;/Word&gt;
</figure>
<figureCaption confidence="0.800308">
Sample 1. Word Arrive
</figureCaption>
<bodyText confidence="0.999906954545454">
We store the classes of copies, forms, and
words in a lexical ontology together with their
relations. In this way, we are able to generate the
same systemic network for the rank of word in
KPML and, at the same time, all word forms and
word form classes for OpenCCG.
In addition, there are word classes used as
criteria for selecting words in Nigel. These are
the grammatical – or closed-class – words. For
them, there is a number of different selecting
criteria which are better explained at the ranks
where these selections are made (clause, phrase,
or group).
In CCG, the morphological entries are not
words, but forms. As in KPML, forms have a
word identifier (stem), inflectional/agreement
classes (macros), they have an attribute for form
applicability (pos) and may have an additional
semantic value in case of lexical words (class).
Therefore, the word exemplified in Sample 1,
can be compiled via ontological reasoning into
the following structure:
</bodyText>
<table confidence="0.151936444444444">
&lt;entry word=“arrive” stem=“Arrive” class=“Arrive”
macros=“@mode-1 @mention-1 @base @Arrive” /&gt;
&lt;entry word=“arrives” stem=“Arrive” class=“Arrive”
macros=“@mode-1 @mention-2 @base @Arrive” /&gt;
&lt;entry word=“arrive” stem=“Arrive” class=“Arrive”
macros=“@mode-1 @mention-3 @base @Arrive” /&gt;
&lt;entry word=“arrived” stem=“Arrive” class=“Arrive”
macros=“@mode-2 @mention-1 @base @Arrive” /&gt;
[É]
</table>
<tableCaption confidence="0.218411">
Sample 2. Forms of Word Arrive in CCG
</tableCaption>
<bodyText confidence="0.999883666666667">
A sample word ontology and the java code
for generating resources can be found at https://
github.com/DanielCoutoVale/SymbolicMap.
</bodyText>
<subsectionHeader confidence="0.973099">
4.2 Composites
</subsectionHeader>
<bodyText confidence="0.999605628571429">
In the beginning of every traversal of the
systemic network, a symbolic structure is
classified either as a clause, a group or phrase, a
word or a morpheme. By listing all preselectable
classes, we came to the conclusion that there is a
fine-grained rank region that includes not only
clauses, phrases, groups, and words, but
subtypes of these. Clauses are either complexes
or simplexes, either dependent or independent.
Phrases and groups can be either a nominal
group, a quantity group, a quality group, an
adverbial group or a prepositional phrase. These
subtypes can have further specifications that we
shall call here, for simplification, clause mode
and noun group case. At this point, below the
preselectable classes, it is possible to propose a
composite structure whose further specification
is exclusively semantical and lexical in nature
and whose fitting is governed exclusively by the
compositionality of the semantic structure. This
possibility was also noticed by Henschel in her
final remarks (Henschel, 1997).
At this point of the traversal, for each
particular class of structure, there is a semantic
correspondent. Sequences are realised by clause
complexes, Figures by clause simplexes,
Elements by phrases and groups. Subtypes of
Elements are realised by subtypes of phrases and
groups: Circumstances by prepositional phrases
and adverbial groups, Things by noun groups,
Qualities by adjectival groups, Quantities by
quantity groups. Finally, Elements have two
other subtypes: Processes and Modalities, which
occupy respectively the heads of clauses and
phrases (see Figure 3).
</bodyText>
<figureCaption confidence="0.982707">
Figure 3. OntoGraf of Clause in Protégé
</figureCaption>
<bodyText confidence="0.999921571428571">
Since we need to allow changing the type of
complete structures into combinable constituents
of larger structures during text analysis, a
description of symbolic systems must store more
information than Nigel at this point. How these
type-changes are achieved shall be explained in
the following.
</bodyText>
<subsectionHeader confidence="0.997138">
4.3 Adjuncts
</subsectionHeader>
<bodyText confidence="0.9989225">
Type changing in OpenCCG provides a way
to implement the separation between pattern,
brick, and device. For instance, this operator
allows us to create simple rules for very
</bodyText>
<page confidence="0.997382">
88
</page>
<bodyText confidence="0.999070636363636">
(Qualification/Qualifier) and nice (Qualifier) to
result in the complete structure of very nice
(Qualification). Then, by adding the possibility
of changing the type Qualification into
Classifier/Classifier, we are able to turn the
category of this symbolic structure into an
adjunct for the classifier wine (Classifier) in this
is a very nice wine. At the same time, we still
allow it to be a complement of the process is
(Clause\Mention/Qualification) in this wine is
very nice.
</bodyText>
<subsectionHeader confidence="0.999664">
4.4 Grammatical Word Selection
</subsectionHeader>
<bodyText confidence="0.999997647058823">
In addition to the currently defined semantic
elements, the semantic specification of Nigel
also contains properties for answering semantic
queries. These semantic queries embed a
typology of deictics, of tense, and of phase
inside of the systemic network. In order to
embed these typologies into word forms, the
semantic types must be moved to the semantic
ontology. For instance, the meaning of the in
KPML is that it is a ‘nonselective’, ‘nontypic’,
‘nominal’, and ‘specific’ instantiation of a
‘class’ of ‘non-interactants’. The grammatical
feature of the is a subtype of all these other
features. During text analysis, the can be
assigned the corresponding grammatical feature
while the supertypes of this feature can be
inferred with an ontology after the analysis.
</bodyText>
<subsectionHeader confidence="0.995163">
4.5 Specification
</subsectionHeader>
<bodyText confidence="0.999785352941176">
In Nigel, there are systems whose features
are realised either by selecting a unit/form class
or by creating a head/tail structure. Tense is an
example of this. On the one hand, positive future
is realised by adding will (T0-head) and
selecting the infinitive form for the head of the
remaining verbal group (T0-tail) such as make in
it will make sense. On the other hand, positive
present is realised by selecting the present form
for the head of the verbal group (T0-atom) such
as makes in it makes sense. Therefore, for each
region in each rank that creates a specification
of clauses, phrases, or groups, we need to have
either a head-tail structure or an atom for
KPML. The respective corresponding structures
for OpenCCG would be an incomplete category
or a type-change.
</bodyText>
<subsectionHeader confidence="0.987801">
4.6 Complements
</subsectionHeader>
<bodyText confidence="0.999881545454545">
Circumstance complements such as of Mary
in in front of Mary create no new challenges for
description. Figure complements, on the other
hand, do. The clause, as the representation of a
figure (state or event), is a symbolic structure
whose constituents represent the elements of a
semantic figure. Nigel adds the representative
functions of clause constituents in the traversal
of a figure typology. Each level of the typology
decides whether a semantic role is present or not
in the figure and therefore if a constituent must
have the function of such a role. Roles include
those of actor, actee, senser, sensum, sayer,
target, verbiage, carrier, attribute, identified,
identifier among others. Semantic roles and their
presence for a given figure type are stored
outside the system in a separate typology
(GUM-3) (Bateman et al., 2010). The
correspondent of the transitivity region in
OpenCCG would be the mapping of logical
variables to the diamond modes of a figure node
as specified in the XML below:
</bodyText>
<figure confidence="0.94185225">
&lt;satop nomvar=“SimpleAction”&gt;
&lt;diamond mode=“hasProcess”&gt;
&lt;nomvar name=“Process”/&gt;
&lt;/diamond&gt;
&lt;diamond mode=“hasActor”&gt;
&lt;nomvar name=“Actor”/&gt;
&lt;/diamond&gt;
&lt;/satop&gt;
</figure>
<subsectionHeader confidence="0.677822">
Sample 3. Logical Form in OpenCCG
</subsectionHeader>
<bodyText confidence="0.999930823529412">
Which process words can be used in each
figure type need not be defined in KPML
because both the figure type (SimpleAction,
AffectingAction, etc.) and the process type
(Running, Jumping, Singing, Seeing, etc.) are
defined in the semantic specification that is
passed to KPML as an input for text synthesis.
This mapping from process types to figure types
is necessary in OpenCCG and, therefore,
process words need to be assigned process types
so that SimpleActionProcesses are associated
with a derivation family that has a medium/
actor, and so that AffectingActionProcesses are
associated with a derivation family that has an
agent/actor and a medium/goal, and so on. The
whole set of rules involving transitivity can be
automatically derived from a typology of figures
both for KPML and for OpenCCG that includes
such process classes.
In addition, in KPML, voice is implemented
by mapping the transitive functions described
above (actor, actee, recipient, senser, sensum,
sayer, target...) to a smaller set of ergative
functions (agent, medium, beneficiary). For
example, the clause the duke gave my aunt the
teapot has the duke as actor, my aunt as recipient
and the teapot as goal in the transitive structure
and the duke as agent, my aunt as beneficiary,
and the teapot as medium in the ergative
structure. For each figure type, there is a
mapping of specific transitive functions to
ergative functions. The ergative functions are the
ones that get mapped to the subject, the direct(-
object) and the indirect(-object) functions
</bodyText>
<page confidence="0.999297">
89
</page>
<bodyText confidence="0.999947434782609">
depending on the voice (agent-receptive voice,
medium-receptive voice, and beneficiary-
receptive voice). To implement a similar voice
construct in OpenCCG, we propose a strategy of
moving the mapping of transitive-ergative
functions to a secondary step of reasoning after
text analysis (example in https://github.com/
DanielCoutoVale/SymbolicMap). After doing
this, the actual voice structure can be
implemented with categories such as Clause
\Mention/Mention/Mention/Process for the
auxiliary word was in the teapot was given by
the duke to my aunt and with the type changing
rule Process –&gt; Clause\Mention/Mention/
Mention applied to the Process gave in the duke
gave my aunt a teapot. Which category or rule
to apply depends on the ergative functions of
each figure type – e.g. figures with a medium
and no agent do not have a “passive” form.
Culmination – the choice between the teapot
was given my aunt by the duke and the teapot
was given by the duke to my aunt – was realised
in OpenCCG together with voice.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.998458466666667">
For evaluation, we targeted the only real
challenge in the relation between Nigel and our
CCG (clause complements) by creating a simple
symbolic map with two ranks (clause and
mention), with three figure types, three voices
and two culminations (complements). This
resource was compiled into a systemic network
and into combinatory categories and type
change rules successfully. Text synthesis and
text analysis work as intended, that is,
algorithmically without backtracking. For
instance, the automatically generated CCG gives
the correct standard analysis for the duke gave
my aunt the teapot according to SFG as seen in
the Table 1:
</bodyText>
<table confidence="0.981529333333333">
the duke gave my aunt the teapot
Actor Process Recipient Goal
Agent Beneficiary Medium
</table>
<tableCaption confidence="0.998076">
Table 1. Analysis for the duke as subject
</tableCaption>
<bodyText confidence="0.999922777777778">
For utterances such as my aunt was given the
teapot by the duke see Tables 2-3, two
hypotheses of analysis are given by CCG. Both
analyses are correct if only symbolic and
semantic compositionality is taken into account.
An analysis, according to which the teapot
receives someone’s aunt (Table 3), can only be
discarded when knowledge about the world (and
not about language) is applied.
</bodyText>
<table confidence="0.9935325">
my aunt was given the teapot by the
duke
Recipient Process Goal Actor
Beneficiary Medium Agent
</table>
<tableCaption confidence="0.994845">
Table 2. Analysis 1 for my aunt as subject
</tableCaption>
<table confidence="0.999465">
my aunt was given the teapot by the
duke
Goal Process Recipient Actor
Medium Beneficiary Agent
</table>
<tableCaption confidence="0.999818">
Table 3. Analysis 2 for my aunt as subject
</tableCaption>
<bodyText confidence="0.9999097">
The compilation speed for OpenCCG word
forms is very slow: one second per word form
on a computer with 2.6 Ghz processor. The
compilation of OpenCCG combinatory
categories, type changing rules, KPML lexicon
and network, on the other hand, is efficient.
Once compiled, the speed of text analysis is that
of a regular hand-written resource for OpenCCG
and is equivalent in size and quality through
code inspection.
</bodyText>
<sectionHeader confidence="0.999233" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999966904761905">
In this paper, we have shown that task-
oriented resources for KPML and OpenCCG do
not contain the necessary information for doing
the inverse task and that their directed rules
cannot encode the information that is necessary
for the resources to become reversible.
Therefore, we have adopted a third strategy
of creating a completely descriptive map
between symbolic and semantic structures that
can be compiled into a systemic network and
into combinatory categories and type changing
rules.
Our evaluation has shown that the approach
is sound and is able to solve previously
identified issues on a theoretical level. However,
we are still unsure about the amount of
engineering resources that would be needed in
order to complete the same coverage of Nigel
within such a paradigm. Nevertheless, from the
pilot study undertaken, the approach appears
promising.
</bodyText>
<sectionHeader confidence="0.996505" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.94440625">
We gratefully acknowledge the support of
the Deutsche Forschungsgemeinschaft (DFG)
through the Collaborative Research Center SFB/
TR8 Spatial Cognition.
</bodyText>
<page confidence="0.996637">
90
</page>
<sectionHeader confidence="0.990299" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999623079207921">
John A. Bateman. 1995a. Basic technology for
multilingual theory and practise: the KPML
development enviroment. In Proceedings of the
Workshop on Multilingual Text Generation
IJCAI-95, pages 1–12. Montreal.
John A. Bateman. 1995b. KPML: the KOMET-
Penman Multilingual Linguistic Resource
Development Environment. In Proceedings of
the Fifth European Workshop on Natural
Language Generation, pages 219–222. Leiden.
John A. Bateman. 1996. KPML Development
Environment. GMD-Forschungszentrum
Informationstechnik GmbH, Sankt Augustin.
John A. Bateman. 1997. Enabling technology for
multilingual natural language generation: the
KPML development environment. Natural
Language Engineering, 3(1):15–55.
John A. Bateman. 2008. Systemic-functional
linguistics and the notion of linguistic structure:
unanswered questions, new possibilities.
Meaning in context implementing intelligent
applications of language studies, pages 24–58.
Continuum, London/New York.
John A. Bateman, Joana Hois, Robert Ross, and
Thora Tenbrink. 2010. A linguistic ontology of
space for natural language processing. Artificial
Intelligence, 174(14):1027–1071.
Cem Bozşahin, Geert-Jan Kruijff, and Michael
White. 2005. Specifying Grammars for
OpenCCG: A Rough Guide. Retrieved from
http://www.metu.edu.tr/~bozsahin/nli/ceng563/
link/grammars-rough-guide.pdf
Donald Davidson. 1967. Truth and Meaning.
Synthese, 17(1):304–323.
Friedrich Ludwig Gottlob Frege. 1884. Grundlagen
der Arithmetik: eine logisch mathematische
Untersuchung fiber den Begriff der Zahl.
Wilhelm Köbner, Breslau.
Michael A.K. Halliday and Christian M.I.M.
Matthiessen. 2014. Halliday&apos;s Introduction to
Functional Grammar, 4th edition. Routledge,
London/New York.
Renate Henschel. 1995. Traversing the Labyrinth of
Feature Logics for a Declarative Implementation
of Large Scale Systemic Grammars. Retrieved
from http://www.elsnet.org/publications/clnlp95
Renate Henschel. 1997. Compiling Systemic
Grammar into Feature Logic Systems. Retrieved
from http://citeseerx.ist.psu.edu/viewdoc/
download?doi=10.1.1.52.3153&amp;rep=rep1
&amp;type=pdf
Robert T. Kasper. 1988. An experimental parser for
systemic grammars. In Proceedings of the
Twelfth International Conference on
Computational Linguistics, pages 309–312,
Budapest.
Martin Kay. 1979. Functional Grammar. In
Proceedings of the Berkeley Linguistics Society.
pages 142–158, Berkeley.
JP Martin Kay. 1985. Parsing in functional
unification grammar. Natural Language Parsing.
Cambridge University Press, Cambridge, UK.
Martin Klarner. 2005. Reversibility and re-usability
of resources in NLG and natural language dialog
systems. In Proceedings of the Tenth European
Workshop on Natural Language Generation,
pages 185-190. Aberdeen.
George Lakoff. 1987. Women, fire and dangerous
things: what categories reveal about the mind.
University of Chicago Press, Chicago.
Christian M.I.M. Matthiessen. 1995.
Lexicogrammatical cartography: english
systems. International Language Sciences
Publishers, Tokyo.
Christian M.I.M. Matthiessen and Michael A.K.
Halliday. 1999. Construing experience through
meaning: a language-based approach to
cognition. Continuum, London/New York.
Christian M.I.M. Matthiessen and Michael A.K.
Halliday. 2004. An introduction to functional
grammar, 3rd edition. Oxford University Press,
New York.
GŸnter Neumann. 1991. A bidirectional model for
natural language processing. In Proceedings of
the Fifth Conference on European chapter of the
Association for Computational Linguistics, pages
245–250, Berlin.
GŸnter Neumann and Gertjan van Noord. 1992. Self-
monitoring with reversible grammars. In
Proceedings of the Fourteenth International
Conference on Computational Linguistics, pages
700–706, Nantes.
Michael O&apos;Donnell. 1994. Sentence analysis and
generation: a systemic perspective. Ph.D. thesis,
University of Sydney, Sydney.
Stephen G. Pulman. 1995. Review of Reversible
Grammar in Natural Language Processing. In
Computational Linguistics, 21:269–271.
Alex Rudnick. 2010. Review: realization with CCG.
Retrieved from http://www.cs.indiana.edu/
~alexr/nonpubs/alexr-ccg-generation.pdf
</reference>
<page confidence="0.9827">
91
</page>
<reference confidence="0.9999204375">
Barry Smith and Berit Brogaard. 2003. A Unified
Theory of Truth and Reference. Logique et
Analyse, 43:1Ð46.
Mark Steedman. 1987. Combinatory grammars and
parasitic gaps. Natural Language and Linguistic
Theory, 5(3):403Ð439.
Mark Steedman. 1996. A very short introduction to
CCG. Retrieved from http://www.inf.ed.ac.uk/
teaching/courses/nlg/readings/ccgintro.pdf
Mark Steedman. 1998. Categorial Grammar. The
MIT Encyclopedia of Cognitive Sciences, pages
1Ð9. MIT Press, Cambridge, MA.
Mark Steedman and Jason Baldridge. 2011.
Combinatory Categorial Grammar. Non-
Transformational Syntax, pages 181–224.
Blackwell, Oxford, UK.
Tomek Strzalkowski. 1994. Reversible Grammar.
Reversible Grammar in Natural Language
Processing, pages xiiiÐxxi. Springer Science
+Business Media, Dordrecht.
Michael White, Rajakrishnan Rajkumar, and Scott
Martin. 2007. Towards broad coverage surface
realization with CCG. In Proceedings of the
Workshop on Using Corpora for NLG Language
Generation and Machine Translation, pages
22-30, Brighton.
Lugwig Josef Johann Wittgenstein. 1921. Logisch-
Philosophische Abhandlung. Annalen der
Naturphilosophie, 14:185-262.
Lugwig Josef Johann Wittgenstein. 1922. Tractatus
Logico-Philosophicus. Kegan Paul, Trench
Trubner &amp; Co, London.
</reference>
<page confidence="0.996026">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.102516">
<title confidence="0.999947">Towards a Description of Symbolic Maps</title>
<author confidence="0.998418">Daniel Couto</author>
<affiliation confidence="0.9002905">SFB/TR8 Spatial University of</affiliation>
<email confidence="0.888045">danielvale@uni-bremen.de</email>
<author confidence="0.680772">Elisa</author>
<affiliation confidence="0.7721835">SFB/TR8 Spatial University of</affiliation>
<email confidence="0.938645">evales@uni-bremen.de</email>
<author confidence="0.469815">Rumiya</author>
<affiliation confidence="0.84299">SFB/TR8 Spatial University of</affiliation>
<email confidence="0.962365">rumiya@uni-bremen.de</email>
<abstract confidence="0.999378333333333">Symbolic resources for text synthesis and text analysis are typically created and stored separately. In our case, we have a KPMLresource (Nigel) and a CCG for English. In this paper, we argue that reversing efficient resources such as ours cannot in general be achieved. For this reason, we propose a symbolic map that can be converted automatically into both synthesisand analysis-oriented resources. We show that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>Basic technology for multilingual theory and practise: the KPML development enviroment.</title>
<date>1995</date>
<booktitle>In Proceedings of the Workshop on Multilingual Text Generation IJCAI-95,</booktitle>
<pages>1--12</pages>
<publisher>Montreal.</publisher>
<contexts>
<context position="4510" citStr="Bateman, 1995" startWordPosition="676" endWordPosition="677">e perspective of the philosophy of language, in the last 50 years, computational efforts in categorial symbolic text processing have converged on one single notion of a symbolic map. In such a notion, both symbolic (lexical or grammatical) and semantic structures play an essential role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation o</context>
</contexts>
<marker>Bateman, 1995</marker>
<rawString>John A. Bateman. 1995a. Basic technology for multilingual theory and practise: the KPML development enviroment. In Proceedings of the Workshop on Multilingual Text Generation IJCAI-95, pages 1–12. Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>KPML: the KOMETPenman Multilingual Linguistic Resource Development Environment.</title>
<date>1995</date>
<booktitle>In Proceedings of the Fifth European Workshop on Natural Language Generation,</booktitle>
<pages>219--222</pages>
<location>Leiden.</location>
<contexts>
<context position="4510" citStr="Bateman, 1995" startWordPosition="676" endWordPosition="677">e perspective of the philosophy of language, in the last 50 years, computational efforts in categorial symbolic text processing have converged on one single notion of a symbolic map. In such a notion, both symbolic (lexical or grammatical) and semantic structures play an essential role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation o</context>
</contexts>
<marker>Bateman, 1995</marker>
<rawString>John A. Bateman. 1995b. KPML: the KOMETPenman Multilingual Linguistic Resource Development Environment. In Proceedings of the Fifth European Workshop on Natural Language Generation, pages 219–222. Leiden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>KPML Development Environment. GMD-Forschungszentrum Informationstechnik GmbH, Sankt Augustin.</title>
<date>1996</date>
<contexts>
<context position="4542" citStr="Bateman, 1996" startWordPosition="680" endWordPosition="681">of language, in the last 50 years, computational efforts in categorial symbolic text processing have converged on one single notion of a symbolic map. In such a notion, both symbolic (lexical or grammatical) and semantic structures play an essential role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In othe</context>
</contexts>
<marker>Bateman, 1996</marker>
<rawString>John A. Bateman. 1996. KPML Development Environment. GMD-Forschungszentrum Informationstechnik GmbH, Sankt Augustin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>Enabling technology for multilingual natural language generation: the KPML development environment.</title>
<date>1997</date>
<journal>Natural Language Engineering,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="4558" citStr="Bateman, 1997" startWordPosition="682" endWordPosition="683"> the last 50 years, computational efforts in categorial symbolic text processing have converged on one single notion of a symbolic map. In such a notion, both symbolic (lexical or grammatical) and semantic structures play an essential role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In other words, a pair </context>
</contexts>
<marker>Bateman, 1997</marker>
<rawString>John A. Bateman. 1997. Enabling technology for multilingual natural language generation: the KPML development environment. Natural Language Engineering, 3(1):15–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
</authors>
<title>Systemic-functional linguistics and the notion of linguistic structure: unanswered questions, new possibilities. Meaning in context implementing intelligent applications of language studies,</title>
<date>2008</date>
<pages>24--58</pages>
<publisher>Continuum,</publisher>
<location>London/New York.</location>
<contexts>
<context position="12258" citStr="Bateman (2008)" startWordPosition="1832" endWordPosition="1833">also that some information would be superfluous and counterproductive for either text synthesis or text analysis. Following Kasper, O’Donnell (1994) reduced the descriptive complexity of Nigel to create a text analyser. After this, Henschel (1995; 1997) attempted to analyse text with the full Nigel grammatical description again by abstracting an open-world typology from a systemic network and compiling the Nigel resource completely for the first time into a typed-feature-structure resource. However, the resource was unusable for practical text analysis. When reviewing these previous attempts, Bateman (2008) pointed out that the conception of systemic-functional resources alone, as it is, cannot support effective automatic text analysis due to fundamental theoretical concerns. That is, the paradigmatic organisation of the systemic-functional approach raises an enormous search space problem when used for text analysis because the network does not have information about which grammatical feature is relevant for any given text token. If one uses such a network for analysing text, one needs to produce a complete set of all possible intersections of grammatical features in order to predict all support</context>
<context position="17475" citStr="Bateman (2008)" startWordPosition="2626" endWordPosition="2627">sources for separate engines (concretely here: KPML and OpenCCG): a scheme that falls into the Reusability Scheme A (reversibility type) of Klarner (2005) (see Figure 1). In our case, this reusability scheme applies to both grammar and lexicon. Figure 1. Reusability Scheme In our argumentation, we shall propose a reformulation of Nigel as a description in OWL of a symbolic map that supports the proposed compilation. Moving from specific to general, we shall point out which mapping strategies can be used and show that every descriptive region of Nigel is representable in such a map. 3.1 Sketch Bateman (2008) has sketched how an automatic text analysis with systemic-functional theory (&apos;systemic parse&apos;) needs to look. It needs a functional description for sequences of text tokens, including the necessary information both for assigning grammatical features to structures and for identifying composites on a sequence of constituents. Such a symbolic map, we shall see, needs to account for the systemic-functional trinocular view of symbolic systems: from above, from below and from around. Moreover, it also needs to account for two different affordances required for a classification of structures: one th</context>
</contexts>
<marker>Bateman, 2008</marker>
<rawString>John A. Bateman. 2008. Systemic-functional linguistics and the notion of linguistic structure: unanswered questions, new possibilities. Meaning in context implementing intelligent applications of language studies, pages 24–58. Continuum, London/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
<author>Joana Hois</author>
<author>Robert Ross</author>
<author>Thora Tenbrink</author>
</authors>
<title>A linguistic ontology of space for natural language processing.</title>
<date>2010</date>
<journal>Artificial Intelligence,</journal>
<volume>174</volume>
<issue>14</issue>
<contexts>
<context position="30777" citStr="Bateman et al., 2010" startWordPosition="4723" endWordPosition="4726">ymbolic structure whose constituents represent the elements of a semantic figure. Nigel adds the representative functions of clause constituents in the traversal of a figure typology. Each level of the typology decides whether a semantic role is present or not in the figure and therefore if a constituent must have the function of such a role. Roles include those of actor, actee, senser, sensum, sayer, target, verbiage, carrier, attribute, identified, identifier among others. Semantic roles and their presence for a given figure type are stored outside the system in a separate typology (GUM-3) (Bateman et al., 2010). The correspondent of the transitivity region in OpenCCG would be the mapping of logical variables to the diamond modes of a figure node as specified in the XML below: &lt;satop nomvar=“SimpleAction”&gt; &lt;diamond mode=“hasProcess”&gt; &lt;nomvar name=“Process”/&gt; &lt;/diamond&gt; &lt;diamond mode=“hasActor”&gt; &lt;nomvar name=“Actor”/&gt; &lt;/diamond&gt; &lt;/satop&gt; Sample 3. Logical Form in OpenCCG Which process words can be used in each figure type need not be defined in KPML because both the figure type (SimpleAction, AffectingAction, etc.) and the process type (Running, Jumping, Singing, Seeing, etc.) are defined in the seman</context>
</contexts>
<marker>Bateman, Hois, Ross, Tenbrink, 2010</marker>
<rawString>John A. Bateman, Joana Hois, Robert Ross, and Thora Tenbrink. 2010. A linguistic ontology of space for natural language processing. Artificial Intelligence, 174(14):1027–1071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cem Bozşahin</author>
<author>Geert-Jan Kruijff</author>
<author>Michael White</author>
</authors>
<title>Specifying Grammars for OpenCCG: A Rough Guide. Retrieved from http://www.metu.edu.tr/~bozsahin/nli/ceng563/ link/grammars-rough-guide.pdf</title>
<date>2005</date>
<contexts>
<context position="9063" citStr="Bozşahin et al., 2005" startWordPosition="1336" endWordPosition="1339">ther engine using chart parsing, relies on the assumption that a hypothesised structure is only to be considered if it is part of a structure for the whole input text. This assumption of syntagmatic holism was first formulated by Frege (1884) and Wittgenstein (1921; 1922). Chart parsing with CCGs goes beyond: both syntagmatic and paradigmatic holisms are to be enforced, i.e. semantic fitting is used as a filter for analytical hypotheses as well. Such a paradigmatic holism was first formulated by Davidson (1967). OpenCCG is an engine for analysing texts with CCGs (Steedman and Baldridge, 2011; Bozşahin et al., 2005). It classifies word forms into categories according to their affordances of combining with other word forms and structures in the process of building up larger structures and construing meaning. In this process, the empty slots of semantic frames, associated with a word, are filled up by the semantic values of the structures that the word form combines with. 84 Only complete symbolic and semantic structures that represent the whole text are kept by the text analyser (although incomplete structures may also be retrieved for online text processing). There are two kinds of combinatory categories</context>
</contexts>
<marker>Bozşahin, Kruijff, White, 2005</marker>
<rawString>Cem Bozşahin, Geert-Jan Kruijff, and Michael White. 2005. Specifying Grammars for OpenCCG: A Rough Guide. Retrieved from http://www.metu.edu.tr/~bozsahin/nli/ceng563/ link/grammars-rough-guide.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Davidson</author>
</authors>
<date>1967</date>
<journal>Truth and Meaning. Synthese,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="8957" citStr="Davidson (1967)" startWordPosition="1321" endWordPosition="1322">mpts have been made to use Nigel for text analysis. 2.2 Resources for OpenCCG OpenCCG, as for any other engine using chart parsing, relies on the assumption that a hypothesised structure is only to be considered if it is part of a structure for the whole input text. This assumption of syntagmatic holism was first formulated by Frege (1884) and Wittgenstein (1921; 1922). Chart parsing with CCGs goes beyond: both syntagmatic and paradigmatic holisms are to be enforced, i.e. semantic fitting is used as a filter for analytical hypotheses as well. Such a paradigmatic holism was first formulated by Davidson (1967). OpenCCG is an engine for analysing texts with CCGs (Steedman and Baldridge, 2011; Bozşahin et al., 2005). It classifies word forms into categories according to their affordances of combining with other word forms and structures in the process of building up larger structures and construing meaning. In this process, the empty slots of semantic frames, associated with a word, are filled up by the semantic values of the structures that the word form combines with. 84 Only complete symbolic and semantic structures that represent the whole text are kept by the text analyser (although incomplete s</context>
</contexts>
<marker>Davidson, 1967</marker>
<rawString>Donald Davidson. 1967. Truth and Meaning. Synthese, 17(1):304–323.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Friedrich Ludwig</author>
</authors>
<title>Gottlob Frege. 1884. Grundlagen der Arithmetik: eine logisch mathematische Untersuchung fiber den Begriff der Zahl. Wilhelm Köbner,</title>
<location>Breslau.</location>
<marker>Ludwig, </marker>
<rawString>Friedrich Ludwig Gottlob Frege. 1884. Grundlagen der Arithmetik: eine logisch mathematische Untersuchung fiber den Begriff der Zahl. Wilhelm Köbner, Breslau.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>Christian M I M Matthiessen</author>
</authors>
<title>Halliday&apos;s Introduction to Functional Grammar, 4th edition.</title>
<date>2014</date>
<location>Routledge, London/New York.</location>
<contexts>
<context position="2332" citStr="Halliday and Matthiessen, 2014" startWordPosition="337" endWordPosition="340">are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map between symbolic and semantic structures that can be compiled into both synthesis-oriented and analysisoriented resources. With this approach, we aim at separating concerns, so that efficiency can be tackled by the directed rules of task-oriented resource</context>
</contexts>
<marker>Halliday, Matthiessen, 2014</marker>
<rawString>Michael A.K. Halliday and Christian M.I.M. Matthiessen. 2014. Halliday&apos;s Introduction to Functional Grammar, 4th edition. Routledge, London/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renate Henschel</author>
</authors>
<title>Traversing the Labyrinth of Feature Logics for a Declarative Implementation of Large Scale Systemic Grammars. Retrieved from http://www.elsnet.org/publications/clnlp95</title>
<date>1995</date>
<contexts>
<context position="11890" citStr="Henschel (1995" startWordPosition="1781" endWordPosition="1782">; 1985) developed the Functional Unification Grammar (FUG) and Kasper (1988) used FUG for exploring text analysis with Nigel. Analysing a clause took about 1 minute (currently approx. 500ms assuming 120-times faster processors) and analysing a complex clause took several minutes. Kasper concluded grammars needed to be “tuned” and augmented for the inverse task, but also that some information would be superfluous and counterproductive for either text synthesis or text analysis. Following Kasper, O’Donnell (1994) reduced the descriptive complexity of Nigel to create a text analyser. After this, Henschel (1995; 1997) attempted to analyse text with the full Nigel grammatical description again by abstracting an open-world typology from a systemic network and compiling the Nigel resource completely for the first time into a typed-feature-structure resource. However, the resource was unusable for practical text analysis. When reviewing these previous attempts, Bateman (2008) pointed out that the conception of systemic-functional resources alone, as it is, cannot support effective automatic text analysis due to fundamental theoretical concerns. That is, the paradigmatic organisation of the systemic-func</context>
<context position="19536" citStr="Henschel (1995" startWordPosition="2951" endWordPosition="2952">ology of features in the types file for OpenCCG can be derived from such descriptions. 3.2 Trinocular View When classifying symbolic units, we not only conceive of them as patterns for recognition and for expression (from below), but also as bricks for building up a whole with given parts and for selecting parts for a planned whole (from around), and also as devices for construing meaning and for realising it (from above). Therefore, all classes of symbols in our symbolic map will be defined based on their affordances as patterns, bricks, and devices. So our approach is different from that of Henschel (1995; 1997) not only in the fact that we will not extract a typology in description logic from a systemic network (in fact, we will do the opposite), but also in the fact that each structure will be specified in our description as three particulars: one classified from above, one from around, and one from below. The classification from above is convertible into KPML-inquiries, the classification from around is convertible to preselectable grammatical features in KPML, and the classification from below is related to groups of realisation statements in KPML. The definitions of brick classes and of p</context>
</contexts>
<marker>Henschel, 1995</marker>
<rawString>Renate Henschel. 1995. Traversing the Labyrinth of Feature Logics for a Declarative Implementation of Large Scale Systemic Grammars. Retrieved from http://www.elsnet.org/publications/clnlp95</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renate Henschel</author>
</authors>
<title>Compiling Systemic Grammar into Feature Logic Systems.</title>
<date>1997</date>
<note>Retrieved from http://citeseerx.ist.psu.edu/viewdoc/ download?doi=10.1.1.52.3153&amp;rep=rep1 &amp;type=pdf</note>
<contexts>
<context position="26744" citStr="Henschel, 1997" startWordPosition="4090" endWordPosition="4091">dependent. Phrases and groups can be either a nominal group, a quantity group, a quality group, an adverbial group or a prepositional phrase. These subtypes can have further specifications that we shall call here, for simplification, clause mode and noun group case. At this point, below the preselectable classes, it is possible to propose a composite structure whose further specification is exclusively semantical and lexical in nature and whose fitting is governed exclusively by the compositionality of the semantic structure. This possibility was also noticed by Henschel in her final remarks (Henschel, 1997). At this point of the traversal, for each particular class of structure, there is a semantic correspondent. Sequences are realised by clause complexes, Figures by clause simplexes, Elements by phrases and groups. Subtypes of Elements are realised by subtypes of phrases and groups: Circumstances by prepositional phrases and adverbial groups, Things by noun groups, Qualities by adjectival groups, Quantities by quantity groups. Finally, Elements have two other subtypes: Processes and Modalities, which occupy respectively the heads of clauses and phrases (see Figure 3). Figure 3. OntoGraf of Clau</context>
</contexts>
<marker>Henschel, 1997</marker>
<rawString>Renate Henschel. 1997. Compiling Systemic Grammar into Feature Logic Systems. Retrieved from http://citeseerx.ist.psu.edu/viewdoc/ download?doi=10.1.1.52.3153&amp;rep=rep1 &amp;type=pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert T Kasper</author>
</authors>
<title>An experimental parser for systemic grammars.</title>
<date>1988</date>
<booktitle>In Proceedings of the Twelfth International Conference on Computational Linguistics,</booktitle>
<pages>309--312</pages>
<location>Budapest.</location>
<contexts>
<context position="1215" citStr="Kasper, 1988" startWordPosition="174" endWordPosition="175"> symbolic map that can be converted automatically into both synthesis- and analysis-oriented resources. We show that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle. 1 Introduction Currently, symbolic resources guiding text analysis and text synthesis are created and stored separately. Several researchers have attempted to use the same resource for both tasks (Kasper, 1988; Neumann, 1991; Neumann and van Noord, 1992; Strzalkowski, 1994; O’Donnell, 1994; Pulman, 1995; Klarner, 2005) motivated by the fact that this would not only be cognitively more plausible but also allow translation at a semantic level, integration of new words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not</context>
<context position="11352" citStr="Kasper (1988)" startWordPosition="1701" endWordPosition="1702">low no composition (⋆), only harmonic compositions (◇), only crossing compositions (×) or any composition (•). The smallest structures in OpenCCG are word forms. Word forms (morph entries) map a token pattern (word) to a word id (stem), a combinatory category tag (pos), the meaning of the word (class), and a list of form classes (fsmacros) and slot fillers (lf-macros). This terminal mapping is equivalent to the map from grammatical functions to lexical and semantical structures in KPML. 2.3 KPML-Analysis and CCG-Synthesis Kay (1979; 1985) developed the Functional Unification Grammar (FUG) and Kasper (1988) used FUG for exploring text analysis with Nigel. Analysing a clause took about 1 minute (currently approx. 500ms assuming 120-times faster processors) and analysing a complex clause took several minutes. Kasper concluded grammars needed to be “tuned” and augmented for the inverse task, but also that some information would be superfluous and counterproductive for either text synthesis or text analysis. Following Kasper, O’Donnell (1994) reduced the descriptive complexity of Nigel to create a text analyser. After this, Henschel (1995; 1997) attempted to analyse text with the full Nigel grammati</context>
</contexts>
<marker>Kasper, 1988</marker>
<rawString>Robert T. Kasper. 1988. An experimental parser for systemic grammars. In Proceedings of the Twelfth International Conference on Computational Linguistics, pages 309–312, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional Grammar.</title>
<date>1979</date>
<booktitle>In Proceedings of the Berkeley Linguistics Society.</booktitle>
<pages>142--158</pages>
<location>Berkeley.</location>
<contexts>
<context position="11276" citStr="Kay (1979" startWordPosition="1691" endWordPosition="1692">). In addition, slashes come in four different generalities: they may allow no composition (⋆), only harmonic compositions (◇), only crossing compositions (×) or any composition (•). The smallest structures in OpenCCG are word forms. Word forms (morph entries) map a token pattern (word) to a word id (stem), a combinatory category tag (pos), the meaning of the word (class), and a list of form classes (fsmacros) and slot fillers (lf-macros). This terminal mapping is equivalent to the map from grammatical functions to lexical and semantical structures in KPML. 2.3 KPML-Analysis and CCG-Synthesis Kay (1979; 1985) developed the Functional Unification Grammar (FUG) and Kasper (1988) used FUG for exploring text analysis with Nigel. Analysing a clause took about 1 minute (currently approx. 500ms assuming 120-times faster processors) and analysing a complex clause took several minutes. Kasper concluded grammars needed to be “tuned” and augmented for the inverse task, but also that some information would be superfluous and counterproductive for either text synthesis or text analysis. Following Kasper, O’Donnell (1994) reduced the descriptive complexity of Nigel to create a text analyser. After this, </context>
</contexts>
<marker>Kay, 1979</marker>
<rawString>Martin Kay. 1979. Functional Grammar. In Proceedings of the Berkeley Linguistics Society. pages 142–158, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JP Martin Kay</author>
</authors>
<title>Parsing in functional unification grammar. Natural Language Parsing.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Kay, 1985</marker>
<rawString>JP Martin Kay. 1985. Parsing in functional unification grammar. Natural Language Parsing. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Klarner</author>
</authors>
<title>Reversibility and re-usability of resources in NLG and natural language dialog systems.</title>
<date>2005</date>
<booktitle>In Proceedings of the Tenth European Workshop on Natural Language Generation,</booktitle>
<pages>185--190</pages>
<location>Aberdeen.</location>
<contexts>
<context position="1326" citStr="Klarner, 2005" startWordPosition="189" endWordPosition="190">ow that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle. 1 Introduction Currently, symbolic resources guiding text analysis and text synthesis are created and stored separately. Several researchers have attempted to use the same resource for both tasks (Kasper, 1988; Neumann, 1991; Neumann and van Noord, 1992; Strzalkowski, 1994; O’Donnell, 1994; Pulman, 1995; Klarner, 2005) motivated by the fact that this would not only be cognitively more plausible but also allow translation at a semantic level, integration of new words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘sym</context>
<context position="17015" citStr="Klarner (2005)" startWordPosition="2550" endWordPosition="2551">ktracking. Because of the computational costs of backtracking, it also demands a search heuristic as engineering solution. 3 Symbolic Map We acknowledge the unsuitability of taskoriented resources for the inverse tasks of synthesis and analysis and shall tackle the issues of bridging a paradigmatic text synthesis and a syntagmatic text analysis at a theoretical level. We propose to describe a symbolic-semantic map that can be compiled into task-oriented resources for separate engines (concretely here: KPML and OpenCCG): a scheme that falls into the Reusability Scheme A (reversibility type) of Klarner (2005) (see Figure 1). In our case, this reusability scheme applies to both grammar and lexicon. Figure 1. Reusability Scheme In our argumentation, we shall propose a reformulation of Nigel as a description in OWL of a symbolic map that supports the proposed compilation. Moving from specific to general, we shall point out which mapping strategies can be used and show that every descriptive region of Nigel is representable in such a map. 3.1 Sketch Bateman (2008) has sketched how an automatic text analysis with systemic-functional theory (&apos;systemic parse&apos;) needs to look. It needs a functional descrip</context>
</contexts>
<marker>Klarner, 2005</marker>
<rawString>Martin Klarner. 2005. Reversibility and re-usability of resources in NLG and natural language dialog systems. In Proceedings of the Tenth European Workshop on Natural Language Generation, pages 185-190. Aberdeen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Women, fire and dangerous things: what categories reveal about the mind.</title>
<date>1987</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="2081" citStr="Lakoff, 1987" startWordPosition="307" endWordPosition="308">ew words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map betw</context>
</contexts>
<marker>Lakoff, 1987</marker>
<rawString>George Lakoff. 1987. Women, fire and dangerous things: what categories reveal about the mind. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M I M Matthiessen</author>
</authors>
<title>Lexicogrammatical cartography: english systems.</title>
<date>1995</date>
<booktitle>International Language Sciences Publishers,</booktitle>
<location>Tokyo.</location>
<contexts>
<context position="2235" citStr="Matthiessen, 1995" startWordPosition="327" endWordPosition="328">ferent fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map between symbolic and semantic structures that can be compiled into both synthesis-oriented and analysisoriented resources. With this approach, we aim at separ</context>
</contexts>
<marker>Matthiessen, 1995</marker>
<rawString>Christian M.I.M. Matthiessen. 1995. Lexicogrammatical cartography: english systems. International Language Sciences Publishers, Tokyo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M I M Matthiessen</author>
<author>Michael A K Halliday</author>
</authors>
<title>Construing experience through meaning: a language-based approach to cognition. Continuum,</title>
<date>1999</date>
<location>London/New York.</location>
<contexts>
<context position="2267" citStr="Matthiessen and Halliday, 1999" startWordPosition="329" endWordPosition="332">resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map between symbolic and semantic structures that can be compiled into both synthesis-oriented and analysisoriented resources. With this approach, we aim at separating concerns, so that efficien</context>
</contexts>
<marker>Matthiessen, Halliday, 1999</marker>
<rawString>Christian M.I.M. Matthiessen and Michael A.K. Halliday. 1999. Construing experience through meaning: a language-based approach to cognition. Continuum, London/New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M I M Matthiessen</author>
<author>Michael A K Halliday</author>
</authors>
<title>An introduction to functional grammar, 3rd edition.</title>
<date>2004</date>
<publisher>Oxford University Press,</publisher>
<location>New York.</location>
<contexts>
<context position="2299" citStr="Matthiessen and Halliday, 2004" startWordPosition="333" endWordPosition="336">manrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map between symbolic and semantic structures that can be compiled into both synthesis-oriented and analysisoriented resources. With this approach, we aim at separating concerns, so that efficiency can be tackled by the directe</context>
</contexts>
<marker>Matthiessen, Halliday, 2004</marker>
<rawString>Christian M.I.M. Matthiessen and Michael A.K. Halliday. 2004. An introduction to functional grammar, 3rd edition. Oxford University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GŸnter Neumann</author>
</authors>
<title>A bidirectional model for natural language processing.</title>
<date>1991</date>
<booktitle>In Proceedings of the Fifth Conference on European chapter of the Association for Computational Linguistics,</booktitle>
<pages>245--250</pages>
<location>Berlin.</location>
<contexts>
<context position="1230" citStr="Neumann, 1991" startWordPosition="176" endWordPosition="177">that can be converted automatically into both synthesis- and analysis-oriented resources. We show that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle. 1 Introduction Currently, symbolic resources guiding text analysis and text synthesis are created and stored separately. Several researchers have attempted to use the same resource for both tasks (Kasper, 1988; Neumann, 1991; Neumann and van Noord, 1992; Strzalkowski, 1994; O’Donnell, 1994; Pulman, 1995; Klarner, 2005) motivated by the fact that this would not only be cognitively more plausible but also allow translation at a semantic level, integration of new words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same </context>
</contexts>
<marker>Neumann, 1991</marker>
<rawString>GŸnter Neumann. 1991. A bidirectional model for natural language processing. In Proceedings of the Fifth Conference on European chapter of the Association for Computational Linguistics, pages 245–250, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>GŸnter Neumann</author>
<author>Gertjan van Noord</author>
</authors>
<title>Selfmonitoring with reversible grammars.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics,</booktitle>
<pages>700--706</pages>
<location>Nantes.</location>
<marker>Neumann, van Noord, 1992</marker>
<rawString>GŸnter Neumann and Gertjan van Noord. 1992. Selfmonitoring with reversible grammars. In Proceedings of the Fourteenth International Conference on Computational Linguistics, pages 700–706, Nantes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael O&apos;Donnell</author>
</authors>
<title>Sentence analysis and generation: a systemic perspective.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sydney, Sydney.</institution>
<marker>O&apos;Donnell, 1994</marker>
<rawString>Michael O&apos;Donnell. 1994. Sentence analysis and generation: a systemic perspective. Ph.D. thesis, University of Sydney, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>Review of Reversible Grammar</title>
<date>1995</date>
<booktitle>in Natural Language Processing. In Computational Linguistics,</booktitle>
<pages>21--269</pages>
<contexts>
<context position="1310" citStr="Pulman, 1995" startWordPosition="187" endWordPosition="188">sources. We show that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle. 1 Introduction Currently, symbolic resources guiding text analysis and text synthesis are created and stored separately. Several researchers have attempted to use the same resource for both tasks (Kasper, 1988; Neumann, 1991; Neumann and van Noord, 1992; Strzalkowski, 1994; O’Donnell, 1994; Pulman, 1995; Klarner, 2005) motivated by the fact that this would not only be cognitively more plausible but also allow translation at a semantic level, integration of new words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic struc</context>
</contexts>
<marker>Pulman, 1995</marker>
<rawString>Stephen G. Pulman. 1995. Review of Reversible Grammar in Natural Language Processing. In Computational Linguistics, 21:269–271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Rudnick</author>
</authors>
<title>Review: realization with CCG.</title>
<date>2010</date>
<note>Retrieved from http://www.cs.indiana.edu/ ~alexr/nonpubs/alexr-ccg-generation.pdf</note>
<contexts>
<context position="13158" citStr="Rudnick, 2010" startWordPosition="1968" endWordPosition="1969">m when used for text analysis because the network does not have information about which grammatical feature is relevant for any given text token. If one uses such a network for analysing text, one needs to produce a complete set of all possible intersections of grammatical features in order to predict all supported analyses, which is the solution provided by Kasper and by Henschel. Bateman shows that this is computationally intractable for the full version of Nigel’s noun group and Nigel’s clause. On the CCG side, broad-coverage surface realisation has also been attempted (White et al., 2007; Rudnick, 2010). In order for a CCG to work for text synthesis, it was enriched with a customised semantics. The resulting search space was still too large and, for this reason, a search heuristic was applied using n-grams, postags, supertags, and semantic values for evaluation of paths. The realisation achieved promising scores with a time-limit of 15 seconds when trained over the CCGBank – a derivation corpus with the same sentences as the Penn TreeBank – and tested over the same sentences. However, the decision of synthesising a text with a search heuristic is a consequence of the fact that the used resou</context>
</contexts>
<marker>Rudnick, 2010</marker>
<rawString>Alex Rudnick. 2010. Review: realization with CCG. Retrieved from http://www.cs.indiana.edu/ ~alexr/nonpubs/alexr-ccg-generation.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Smith</author>
<author>Berit Brogaard</author>
</authors>
<title>A Unified Theory of Truth and Reference. Logique et Analyse,</title>
<date>2003</date>
<contexts>
<context position="2163" citStr="Smith and Brogaard, 2003" startWordPosition="316" endWordPosition="319">ng as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping between symbolic and semantic structures. Here ‘symbolic structure’ is understood as KPML’s ‘structure’ and CCG’s ‘sign’, and corresponds to ‘grammatical constructions’ of cognitive semantics (Lakoff, 1987), to ‘linguistic mediation’ of truthreference semantics (Smith and Brogaard, 2003), and to ‘wording’ of systemic functional linguistics (Matthiessen, 1995; Matthiessen and Halliday, 1999; Matthiessen and Halliday, 2004; Halliday and Matthiessen, 2014). In this paper, we shall review the available directed rules that constitute the resources in KPML and OpenCCG and argue that they are useful in their respective tasks – either synthesis or analysis, – but are either unsuitable or not competitive for the inverse task. Aiming not at reversibility but at reusability, we propose to create a map between symbolic and semantic structures that can be compiled into both synthesis-orie</context>
</contexts>
<marker>Smith, Brogaard, 2003</marker>
<rawString>Barry Smith and Berit Brogaard. 2003. A Unified Theory of Truth and Reference. Logique et Analyse, 43:1Ð46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Combinatory grammars and parasitic gaps.</title>
<date>1987</date>
<journal>Natural Language and Linguistic Theory,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="4773" citStr="Steedman, 1987" startWordPosition="710" endWordPosition="711">s play an essential role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In other words, a pair of engines that support such a map is a necessary and sufficient condition for the reusability scheme we propose. In the following, we shall review the grammatical notions embedded in the resources for KPML and Open</context>
</contexts>
<marker>Steedman, 1987</marker>
<rawString>Mark Steedman. 1987. Combinatory grammars and parasitic gaps. Natural Language and Linguistic Theory, 5(3):403Ð439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>A very short introduction to CCG.</title>
<date>1996</date>
<note>Retrieved from http://www.inf.ed.ac.uk/ teaching/courses/nlg/readings/ccgintro.pdf</note>
<contexts>
<context position="4789" citStr="Steedman, 1996" startWordPosition="712" endWordPosition="713">ial role in deciding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In other words, a pair of engines that support such a map is a necessary and sufficient condition for the reusability scheme we propose. In the following, we shall review the grammatical notions embedded in the resources for KPML and OpenCCG in order to </context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Mark Steedman. 1996. A very short introduction to CCG. Retrieved from http://www.inf.ed.ac.uk/ teaching/courses/nlg/readings/ccgintro.pdf</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Categorial Grammar. The MIT Encyclopedia of Cognitive Sciences,</title>
<date>1998</date>
<pages>1--9</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4805" citStr="Steedman, 1998" startWordPosition="714" endWordPosition="715">ding which analytical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In other words, a pair of engines that support such a map is a necessary and sufficient condition for the reusability scheme we propose. In the following, we shall review the grammatical notions embedded in the resources for KPML and OpenCCG in order to support our argu</context>
</contexts>
<marker>Steedman, 1998</marker>
<rawString>Mark Steedman. 1998. Categorial Grammar. The MIT Encyclopedia of Cognitive Sciences, pages 1Ð9. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Jason Baldridge</author>
</authors>
<title>Combinatory Categorial Grammar. NonTransformational Syntax,</title>
<date>2011</date>
<pages>181--224</pages>
<publisher>Blackwell,</publisher>
<location>Oxford, UK.</location>
<contexts>
<context position="4836" citStr="Steedman and Baldridge, 2011" startWordPosition="716" endWordPosition="719">tical and synthetic hypotheses are to be taken further or discarded. On the text synthesis front, systemic networks were used by both KOMET and Penman engines as directed rules for text synthesis. Those engines were later unified into the KOMET-Penman Multilingual 83 Engine (KPML Engine) (Bateman, 1995a; Bateman, 1995b; Bateman, 1996; Bateman, 1997). On the text analysis front, typed-feature unification was developed and implemented in engines for a family of highly lexicalised grammatical frameworks (HLG). Combinatory Categorial Grammars (CCG) (Steedman, 1987; Steedman, 1996; Steedman, 1998; Steedman and Baldridge, 2011) are a special type of HLG that reduce the task of text analysis to accepting or rejecting hypotheses of both symbolic and semantic composition during functional unification. KPML and OpenCCG are then only candidates for consideration because they allow the implementation of a shared symbolic map. In other words, a pair of engines that support such a map is a necessary and sufficient condition for the reusability scheme we propose. In the following, we shall review the grammatical notions embedded in the resources for KPML and OpenCCG in order to support our argumentation that reversibility of</context>
<context position="9039" citStr="Steedman and Baldridge, 2011" startWordPosition="1332" endWordPosition="1335"> OpenCCG OpenCCG, as for any other engine using chart parsing, relies on the assumption that a hypothesised structure is only to be considered if it is part of a structure for the whole input text. This assumption of syntagmatic holism was first formulated by Frege (1884) and Wittgenstein (1921; 1922). Chart parsing with CCGs goes beyond: both syntagmatic and paradigmatic holisms are to be enforced, i.e. semantic fitting is used as a filter for analytical hypotheses as well. Such a paradigmatic holism was first formulated by Davidson (1967). OpenCCG is an engine for analysing texts with CCGs (Steedman and Baldridge, 2011; Bozşahin et al., 2005). It classifies word forms into categories according to their affordances of combining with other word forms and structures in the process of building up larger structures and construing meaning. In this process, the empty slots of semantic frames, associated with a word, are filled up by the semantic values of the structures that the word form combines with. 84 Only complete symbolic and semantic structures that represent the whole text are kept by the text analyser (although incomplete structures may also be retrieved for online text processing). There are two kinds o</context>
</contexts>
<marker>Steedman, Baldridge, 2011</marker>
<rawString>Mark Steedman and Jason Baldridge. 2011. Combinatory Categorial Grammar. NonTransformational Syntax, pages 181–224. Blackwell, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomek Strzalkowski</author>
</authors>
<title>Reversible Grammar. Reversible Grammar</title>
<date>1994</date>
<booktitle>in Natural Language Processing,</booktitle>
<pages>pages xiiiÐxxi.</pages>
<publisher>Springer Science +Business</publisher>
<location>Media, Dordrecht.</location>
<contexts>
<context position="1279" citStr="Strzalkowski, 1994" startWordPosition="183" endWordPosition="184">h synthesis- and analysis-oriented resources. We show that completeness of description can only be achieved by such a map while efficiency concerns can only be tackled by the directed rules of task-oriented resources not because of the current state of the art, but because reversing task-oriented symbolic resources is impossible in principle. 1 Introduction Currently, symbolic resources guiding text analysis and text synthesis are created and stored separately. Several researchers have attempted to use the same resource for both tasks (Kasper, 1988; Neumann, 1991; Neumann and van Noord, 1992; Strzalkowski, 1994; O’Donnell, 1994; Pulman, 1995; Klarner, 2005) motivated by the fact that this would not only be cognitively more plausible but also allow translation at a semantic level, integration of new words from analysis into synthesis, reduction of costs in engineering as well as making it easier to share information among research groups of different fields. The resources we currently use in humanrobot interaction in English are also separate: a KPML-resource (Nigel) and a CCG. The specialty about Nigel and our CCG is that they share not only the same kind of semantics, but also the same mapping betw</context>
</contexts>
<marker>Strzalkowski, 1994</marker>
<rawString>Tomek Strzalkowski. 1994. Reversible Grammar. Reversible Grammar in Natural Language Processing, pages xiiiÐxxi. Springer Science +Business Media, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
<author>Rajakrishnan Rajkumar</author>
<author>Scott Martin</author>
</authors>
<title>Towards broad coverage surface realization with CCG.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Using Corpora for NLG Language Generation and Machine Translation,</booktitle>
<pages>22--30</pages>
<location>Brighton.</location>
<contexts>
<context position="13142" citStr="White et al., 2007" startWordPosition="1964" endWordPosition="1967"> search space problem when used for text analysis because the network does not have information about which grammatical feature is relevant for any given text token. If one uses such a network for analysing text, one needs to produce a complete set of all possible intersections of grammatical features in order to predict all supported analyses, which is the solution provided by Kasper and by Henschel. Bateman shows that this is computationally intractable for the full version of Nigel’s noun group and Nigel’s clause. On the CCG side, broad-coverage surface realisation has also been attempted (White et al., 2007; Rudnick, 2010). In order for a CCG to work for text synthesis, it was enriched with a customised semantics. The resulting search space was still too large and, for this reason, a search heuristic was applied using n-grams, postags, supertags, and semantic values for evaluation of paths. The realisation achieved promising scores with a time-limit of 15 seconds when trained over the CCGBank – a derivation corpus with the same sentences as the Penn TreeBank – and tested over the same sentences. However, the decision of synthesising a text with a search heuristic is a consequence of the fact tha</context>
</contexts>
<marker>White, Rajkumar, Martin, 2007</marker>
<rawString>Michael White, Rajakrishnan Rajkumar, and Scott Martin. 2007. Towards broad coverage surface realization with CCG. In Proceedings of the Workshop on Using Corpora for NLG Language Generation and Machine Translation, pages 22-30, Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lugwig Josef Johann Wittgenstein</author>
</authors>
<date>1921</date>
<booktitle>LogischPhilosophische Abhandlung. Annalen der Naturphilosophie,</booktitle>
<pages>14--185</pages>
<contexts>
<context position="8706" citStr="Wittgenstein (1921" startWordPosition="1282" endWordPosition="1283">neral approach, but from the amount and quality of detailed linguistic knowledge applied to the synthesis of text in Nigel, which makes Nigel a good option for our applications that demand natural utterances. This is also the main reason why so many attempts have been made to use Nigel for text analysis. 2.2 Resources for OpenCCG OpenCCG, as for any other engine using chart parsing, relies on the assumption that a hypothesised structure is only to be considered if it is part of a structure for the whole input text. This assumption of syntagmatic holism was first formulated by Frege (1884) and Wittgenstein (1921; 1922). Chart parsing with CCGs goes beyond: both syntagmatic and paradigmatic holisms are to be enforced, i.e. semantic fitting is used as a filter for analytical hypotheses as well. Such a paradigmatic holism was first formulated by Davidson (1967). OpenCCG is an engine for analysing texts with CCGs (Steedman and Baldridge, 2011; Bozşahin et al., 2005). It classifies word forms into categories according to their affordances of combining with other word forms and structures in the process of building up larger structures and construing meaning. In this process, the empty slots of semantic fr</context>
</contexts>
<marker>Wittgenstein, 1921</marker>
<rawString>Lugwig Josef Johann Wittgenstein. 1921. LogischPhilosophische Abhandlung. Annalen der Naturphilosophie, 14:185-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lugwig Josef Johann Wittgenstein</author>
</authors>
<title>Tractatus Logico-Philosophicus. Kegan Paul, Trench Trubner</title>
<date>1922</date>
<publisher>Co,</publisher>
<location>London.</location>
<marker>Wittgenstein, 1922</marker>
<rawString>Lugwig Josef Johann Wittgenstein. 1922. Tractatus Logico-Philosophicus. Kegan Paul, Trench Trubner &amp; Co, London.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>