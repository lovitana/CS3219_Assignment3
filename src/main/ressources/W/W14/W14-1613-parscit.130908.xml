<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003743">
<title confidence="0.9981045">
Distributed Word Representation Learning for Cross-Lingual
Dependency Parsing
</title>
<author confidence="0.995814">
Min Xiao and Yuhong Guo
</author>
<affiliation confidence="0.9986425">
Department of Computer and Information Sciences
Temple University
</affiliation>
<address confidence="0.549474">
Philadelphia, PA 19122, USA
</address>
<email confidence="0.999623">
{minxiao,yuhong}@temple.edu
</email>
<sectionHeader confidence="0.9974" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999923607142857">
This paper proposes to learn language-
independent word representations to ad-
dress cross-lingual dependency parsing,
which aims to predict the dependency
parsing trees for sentences in the target
language by training a dependency parser
with labeled sentences from a source lan-
guage. We first combine all sentences
from both languages to induce real-valued
distributed representation of words under
a deep neural network architecture, which
is expected to capture semantic similari-
ties of words not only within the same lan-
guage but also across different languages.
We then use the induced interlingual word
representation as augmenting features to
train a delexicalized dependency parser on
labeled sentences in the source language
and apply it to the target sentences. To in-
vestigate the effectiveness of the proposed
technique, extensive experiments are con-
ducted on cross-lingual dependency pars-
ing tasks with nine different languages.
The experimental results demonstrate the
superior cross-lingual generalizability of
the word representation induced by the
proposed approach, comparing to alterna-
tive comparison methods.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932392156863">
With the rapid development of linguistic resources
and tools in multiple languages, it is very im-
portant to develop cross-lingual natural language
processing (NLP) systems. Cross-lingual depen-
dency parsing is the task of inferring dependency
trees for observed sentences in a target language
where there are few or no labeled training sen-
tences by using a dependency parser trained on
a large amount of sentences with annotated de-
pendency trees in a source language (Durrett et
al., 2012; McDonald et al., 2011; Zhao et al.,
2009). Cross-lingual dependency parsing is pop-
ularly studied in natural language processing area
as it can greatly reduce the expensive manual an-
notation effort in the target language by exploit-
ing the dependency annotations from a source lan-
guage (Durrett et al., 2012; McDonald et al., 2011;
T¨ackstr¨om et al., 2012).
One fundamental challenge of cross-lingual de-
pendency parsing stems from the word-level rep-
resentation divergence across languages. Since
sentences in different languages are expressed
using different vocabularies, if we train a de-
pendency parser on the word-level features of
sentences from a source language, it will fail
to parse the sentences in a different target lan-
guage. A variety of work in the literature has at-
tempted to bridge the word-level representation di-
vergence across languages. One intuitive method
delexicalizes the dependency parser by replac-
ing the language-specific word-level features with
language-independent features such as universal
part-of-speech tags (Petrov et al., 2012). With the
universal POS tag features, this method provides
a possible way to transfer dependency parsing in-
formation from the source language to the target
language and has demonstrated some good empir-
ical results (McDonald et al., 2011). However, the
number of universal POS tags is small, which lim-
its their discriminative capacity as input features
for dependency parsing. A few other works hence
propose to improve the delexicalized system by
learning more effective cross-lingual features such
as bilingual word clusters (T¨ackstr¨om et al., 2012)
and other interlingual representations (Durrett et
al., 2012).
In this paper, we propose to address cross-
lingual dependency parsing by learning distributed
interlingual word representations using a deep
neural network architecture. We first combine
all the sentences from two language domains and
</bodyText>
<page confidence="0.987408">
119
</page>
<note confidence="0.688186">
Proceedings of the Eighteenth Conference on Computational Language Learning, pages 119–129,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9997225">
build cross language word connections based on
Wikitionary, which works as a free bilingual dic-
tionary. Then by exploiting a deep learning archi-
tecture, we learn real-valued dense feature vectors
for the words in the given sentences as the high-
level interlingual representations, which capture
semantic similarities across languages. Finally, we
use the induced distributed word representation as
augmenting features to train a delexicalized de-
pendency parser on the annotated sentences in the
source language and applied it on the sentences in
the target language. In order to evaluate the pro-
posed cross-lingual learning technique, we con-
duct extensive experiments on eight cross-lingual
dependency parsing tasks with nine different lan-
guages. The experimental results demonstrate the
efficacy of the proposed approach in transferring
dependency parsers across languages, comparing
to other methods.
The remainder of the paper is organized as fol-
lows. Section 2 reviews related work. Section
3 describes the main approach of cross-lingual
word representation learning with deep neural net-
works and cross-lingual dependency parsing with
induced interlingual features. Section 4 presents
the empirical study on eight cross language depen-
dency parsing tasks. We then conclude the paper
in Section 5.
</bodyText>
<sectionHeader confidence="0.99993" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999841083333333">
Previous works developed in the literature have
tackled cross-lingual dependency parsing by us-
ing cross-lingual annotation projection methods,
multilingual model learning methods, and cross-
lingual representation learning methods.
Cross-lingual annotation projection methods
use parallel sentences to project the annotations
from the source language side to the target lan-
guage side and then train dependency parsers on
the target data with projected annotations (Hwa
et al., 2005; Liu et al., 2013; Smith and Eis-
ner, 2009; Zhao et al., 2009). For cross-lingual
annotation projection methods, both the word
alignment training step and the annotation pro-
jection step can introduce errors or noise. Thus
much work developed in the literature has fo-
cused on designing robust projection algorithms
such as graph-based projection with label prop-
agations (Das and Petrov, 2011), improving pro-
jection performance by using auxiliary resources
such as Wikipedia metadata (Kim and Lee, 2012)
or WordNet (Khapra et al., 2010), or boosting pro-
jection performance by heuristically modifying or
correcting the projected annotations (Hwa et al.,
2005; Kim et al., 2010). Some work has also
proposed to project the discrete dependency arc
instances instead of treebank as the training set
(Liu et al., 2013). Moreover, besides cross-lingual
dependency parsing, cross-lingual annotation pro-
jection methods have also demonstrated success
in various other sequence labeling tasks includ-
ing POS tagging (Das and Petrov, 2011; Yarowsky
and Ngai, 2001), relation extraction (Kim et al.,
2012), named entity recognition (Kim et al., 2010;
Kim and Lee, 2012), constituent syntax parsing
(Jiang et al., 2011), and word sense disambigua-
tion (Khapra et al., 2010).
Multilingual model learning methods train
cross-lingual dependency parsers with parameter
constraints obtained from parallel data (Liu et al.,
2013; Ganchev et al., 2009) or linguistic knowl-
edges (Naseem et al., 2010; Naseem et al., 2012).
Among these methods, some proposed to train
a joint dependency parsing system with parame-
ters shared across the dependency parsing models
in individual languages (Liu et al., 2013). Other
works used posterior regularization techniques to
encode the linguistic constraints in learning de-
pendency parsing models (Ganchev et al., 2009;
Naseem et al., 2010; Naseem et al., 2012). The
linguistic constraints may either come from man-
ually constructed universal dependency parsing
rules (Naseem et al., 2010) or manually specified
typological features (Naseem et al., 2012), or be
learned from parallel sentences (Ganchev et al.,
2009). Besides cross-lingual dependency parsing,
multilingual model learning methods have also
achieved good empirical results for other multilin-
gual NLP tasks, including named entity recogni-
tion (Burkett et al., 2010; Che et al., 2013; Wang
and Manning, 2014), syntactic parsing (Burkett
et al., 2010), semantic role labeling (Zhuang and
Zong, 2010; Kozhevnikov and Titov, 2012), and
word sense disambiguation (Guo and Diab, 2010).
Cross-lingual representation learning methods
induce language-independent features to bridge
the cross-lingual difference in the original word-
level representation space and build connections
across different languages. They train a depen-
dency parser in the induced representation space
by exploiting labeled data from the source lan-
guage and apply it in the target language (Dur-
</bodyText>
<page confidence="0.99105">
120
</page>
<bodyText confidence="0.999967953125">
rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang
et al., 2012). A variety of auxiliary resources
have been used to induce interlingual features, in-
cluding bilingual lexicon (Durrett et al., 2012),
and unlabeled parallel sentences (T¨ackstr¨om et al.,
2013). Based on different learning mechanisms
(whether or not using labeled data) for induc-
ing language-independent features, cross-lingual
representation learning methods can be cate-
gorized into unsupervised representation learn-
ing (T¨ackstr¨om et al., 2013) and supervised
representation learning (Durrett et al., 2012).
The language-independent features include bilin-
gual word clusters (T¨ackstr¨om et al., 2012),
language-independent projection features (Durrett
et al., 2012), and automatically induced language-
independent POS tags (Zhang et al., 2012). Be-
sides cross-lingual dependency parsing, in the lit-
erature cross-lingual representation learning meth-
ods have also demonstrated efficacy in different
NLP applications such as cross language named
entity recognition (T¨ackstr¨om et al., 2012) and
cross language semantic role labeling (Titov and
Klementiev, 2012). Our work shares similarity
with these cross-lingual representation learning
methods on inducing new language-independent
features, but differs from them in that we learn
cross-lingual word embeddings. Though multilin-
gual word embeddings have been employed in the
literature, they are developed for other NLP tasks
such as cross-lingual sentiment analysis (Klemen-
tiev et al., 2012), and machine translation (Zou
et al., 2013). Moreover, the method in (Klemen-
tiev et al., 2012) requires parallel sentences with
observed word-level alignments, and the method
in (Zou et al., 2013) first learns language-specific
word embeddings in each language separately
and then transforms representations from one lan-
guage to another language with machine trans-
lation alignments, while we jointly learn cross-
lingual word embeddings in the two languages by
only exploiting a small set of bilingual word pairs.
From the perspective of applying deep networks
in natural language processing systems, there are
a number of works in the literature (Collobert and
Weston, 2008; Collobert et al., 2011; Henderson,
2004; Socher et al., 2011; Titov and Henderson,
2010; Turian et al., 2010). Socher et al. (2011) ap-
plied recursive autoencoders to address sentence-
level sentiment classification problems. Collobert
and Weston (2008) and Collobert et al. (2011)
employed a deep learning framework for jointly
multi-task learning and empirically evaluated it
with four NLP tasks, including part-of-speech tag-
ging, chunking, named entity recognition, and se-
mantic role labeling. Henderson (2004) proposed
discriminative training methods for learning a neu-
ral network statistical parser. Titov and Hender-
son (2010) extended the incremental sigmoid Be-
lief networks (Titov and Henderson, 2007) to a
generative latent variable model for dependency
parsing. Turian et al. (2010) employed neural net-
works to induce word representations for sequence
labeling tasks such as named entity recognition.
</bodyText>
<sectionHeader confidence="0.907204" genericHeader="method">
3 Cross-Lingual Dependency Parsing
with Word Representation Learning
</sectionHeader>
<bodyText confidence="0.999918">
In this work, we aim to tackle cross-lingual depen-
dency parsing by learning language-independent
distributed word representations with deep neural
networks. We first build connections across lan-
guages using free bilingual dictionaries. Then we
introduce the deep neural network framework for
cross-lingual word representation learning and de-
scribe how to employ the induced dense word em-
beddings for cross-lingual dependency parsing.
</bodyText>
<subsectionHeader confidence="0.998906">
3.1 Building Cross Language Connections
</subsectionHeader>
<bodyText confidence="0.999998826086956">
To induce cross-lingual word representations, we
first need to build connections between the source
and target languages. In this work, we produce
such connections by finding cross-lingual word
pairs using the Wikitionary1, which works as free
bilingual dictionaries between language pairs.
Specifically, we first constructed a source lan-
guage dictionary with all words that appeared in
the sentences from the source language domain
and translate these words to the target language
using the Wikitionary. Then we filtered the pro-
duced word-to-word translations by dropping the
ones where either the same source language word
has multiple different word translations in the tar-
get language or the same target language word
corresponds to multiple different source language
words. We further dropped the word pairs where
the translated word in the target language does not
appear in the given sentences in the target lan-
guage domain. After the processing, we have a set
of one-to-one bilingual word pairs to build con-
nections between the two language domains. Fi-
nally, we built a unified bilingual vocabulary V
</bodyText>
<footnote confidence="0.99677">
1http://en.wikitionary.org
</footnote>
<page confidence="0.993394">
121
</page>
<figureCaption confidence="0.994093">
Figure 1: The architecture of the deep neural net-
</figureCaption>
<bodyText confidence="0.995386285714286">
work for learning cross-lingual word representa-
tions. Each word wi from the training sample x
is mapped to an interlingual representation vector
R(wi) through the embedding matrix R.
with words from all sentences of the two language
domains. For each one-to-one bilingual word pair
we constructed, we assume the two words have
equivalent semantic meaning and map them to the
same entry in V . Next we will learn a distributed
vector representation for each entry of the bilin-
gual vocabulary V using deep neural networks.
By sharing the same representation vectors, the
constructed bilingual word pairs will serve as the
bridge across languages.
</bodyText>
<subsectionHeader confidence="0.966433">
3.2 Interlingual Word Representation
Learning with Deep Neural Networks
</subsectionHeader>
<bodyText confidence="0.999988935483871">
Given the constructed bilingual vocabulary V with
v entries, we will learn a latent word embedding
matrix R E Rkxv over the sentences in the two
language domains by using a deep neural network
model. This embedding matrix will map each
word w in the vocabulary V into a real valued rep-
resentation vector R(w) with length k. For each
bilingual pair of words that are mapped into the
same entry of V , they will be mapped into the
same vector in R as well. Following the strat-
egy of (Collobert et al., 2011), we construct a
simple two-class classification problem over the
given sentences. We use the sub-sentences with
fixed window size c constructed from the given
sentences in the two language domains as posi-
tive samples and construct the negative samples by
replacing the middle word of each positive sub-
sentence with a random word from V . We then
train a deep neural network for this two-class clas-
sification problem, while simultaneously learning
the latent embedding matrix R.
The deep neural network architecture is given
in Figure 1. The bottom layer of the deep archi-
tecture is the input layer, which takes a sequence
of word tokens, x = w1, w2, ... , wc, with a fixed
window size c as the input instance. Then we map
each word wi in this sequence to an embedding
vector R(wi) by treating the bilingual embedding
matrix R as a look-up table. The embedding vec-
tors of the sequence of words x will be concate-
nated into a long vector R(x) E Rck such that
</bodyText>
<equation confidence="0.999899">
R(x) = [R(w1); R(w2); ... ; R(wc)]. (1)
</equation>
<bodyText confidence="0.998488833333333">
R(x) will then be used as input for the hidden
layer above it. The deep neural network has mul-
tiple hidden layers. The first hidden layer applies
a nonlinear hyperbolic tangent activation function
over the linear transformation of its input vector
R(x), such that
</bodyText>
<equation confidence="0.99058">
H1(x) = tanh (W1 x R(x) + b1) (2)
</equation>
<bodyText confidence="0.9995823">
where W1 E Rh1xck is the weight parameter
matrix, b1 E Rh1 is the bias parameter vector,
H1(x) E Rh1 is the output vector, and h1 is the
number of hidden units in the first hidden layer.
Similarly, each of the other hidden layers takes the
previous layer’s output as its input and performs
a nonlinear transformation to produce an output
vector. For example, for the i-th hidden layer, we
used Hi_1(x) as its input and Hi(x) as its output
such that
</bodyText>
<equation confidence="0.989976">
Hi(x) = tanh (Wi x Hi_1(x) + bi) (3)
</equation>
<bodyText confidence="0.999988285714286">
where Wi E Rhixhi−1 is the weight parameter ma-
trix and bi is the bias parameter vector for the i-
th hidden layer; hi denotes the number of hidden
units of the i-th hidden layer.
Given t hidden layers, the output representation
of the last layer will then be used to generate a
final score value for the prediction task, such that
</bodyText>
<equation confidence="0.99925">
s(x) = θ x Ht(x) + u (4)
</equation>
<page confidence="0.959847">
122
</page>
<bodyText confidence="0.9999935">
where 0 E Rh, is the weight parameter vector and
u is the bias parameter for the output layer.
In summary, the model parameters of the deep
neural network architecture include the look-up ta-
ble R, the parameters {Wi, bi}ti=1 for the hidden
layers, and the output layer parameters (0, u).
</bodyText>
<subsectionHeader confidence="0.999411">
3.3 The Training Procedure
</subsectionHeader>
<bodyText confidence="0.999987214285714">
The model parameters of the deep network archi-
tecture are learned by training a two-class classifi-
cation model over the the constructed positive and
negative samples. Let D = {xi, ˆxi}Ni=1 denote
the constructed training set, where xi is a positive
sample and ˆxi is a negative sample constructed by
replacing the middle word of xi with a random
word from V . It is desirable for the model to pro-
duce an output score s(xi) that is much larger than
the score s(ˆxi) for each pair of training instances.
Thus we perform training to maximize the separa-
tion margins between the pairs of scores over pos-
itive and negative samples under a hinge loss; that
is we minimize the following training loss
</bodyText>
<equation confidence="0.99614525">
�N max(0, 1 − s(xi) + s(ˆxi)) (5)
1
J(D) = N
i=1
</equation>
<bodyText confidence="0.9997382">
We perform a random initialization over the
look-up table and weight model parameters, and
set all the bias model parameters to zeros. Then we
use a stochastic gradient descent (Bottou, 1991)
algorithm to perform optimization.
</bodyText>
<subsectionHeader confidence="0.991376">
3.4 Cross-Lingual Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999814863636364">
The training of deep network model above will
produce a word embedding matrix R for all words
in the two language domains. Moreover, by hav-
ing each translated bilingual pair of words shar-
ing the same representation vector in R in the
training process, the embedding matrix R is ex-
pected to capture consistent and comparable se-
mantic meanings across languages, and provide a
language-independent and distributed representa-
tion for each word in the bilingual dictionary V .
Given R, for each sentence x = w1, w2, ... , wn
from the two language domains, we retrieved the
representation vector R(wi) for each word wi.
Moreover, we further delexicalized the sentence
by replacing the sequence of language-specific
words with a sequence of universal POS tags
(Petrov et al., 2012). Finally we train a delexical-
ized dependency parser on the labeled sentences
in the source language based on the universal POS
tag features and the learned distributed features.
and apply it to perform dependency parsing on the
sentences in the target language domain.
</bodyText>
<sectionHeader confidence="0.99968" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999951">
We empirically evaluated the proposed cross-
lingual word representation learning for cross-
lingual dependency parsing. In this section, we
present the experimental setup and the results.
</bodyText>
<subsectionHeader confidence="0.930944">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.9999805">
We used the dataset from the CoNLL shared task
(Buchholz and Marsi, 2006; Nivre et al., 2007) for
cross-lingual dependency parsing. We conducted
experiments with the following nine languages:
English (EN), Danish (DA), German (DE), Greek
(EL), Spanish (ES), Italian (IT), Dutch (NL), Por-
tuguese (PT) and Swedish (SV). For each lan-
guage, there is a separate training set and a test set.
We used English, which usually has more labeled
resources, as the source language, while treat-
ing the others as target languages. We thus con-
structed eight cross-lingual dependency parsing
tasks (EN2DA, EN2DE, EN2EL, EN2ES, EN2IT,
EN2NL, EN2PT, EN2SV), one for each of the
eight target languages. For example, the task
EI2DA means that we used Danish (DA) as the
target language while using English (EI) as the
source language. For each cross language de-
pendency parsing task, we first performed repre-
sentation learning and then conducted dependency
parsing training and test.
In this dataset, each sentence is labeled with
gold standard part-of-speech tags. To produce
delexicalized cross-lingual dependency parsers,
we mapped these language-specific part-of-speech
tags into twelve universal POS tags (Petrov et al.,
2012): ADJ (adjectives), ADP (prepositions or
postpositions), ADV (adverbs), CONJ (conjunc-
tions), DET (determiners), NOUN (nouns), NUM
(numerals), PRON (pronouns), PRT (particles),
PUNC (punctuation marks), VERB (verbs) and X
(for others).
</bodyText>
<subsectionHeader confidence="0.987688">
4.2 Representation Learning
</subsectionHeader>
<bodyText confidence="0.999987833333333">
For each language pair, we produced a set of one-
to-one bilingual word pairs using Wikitionary to
build cross language connections. The numbers
of bilingual word pairs produced for all the eight
language pairs and the numbers of words in each
language are given in Table 1.
</bodyText>
<page confidence="0.999094">
123
</page>
<tableCaption confidence="0.8950675">
Table 1: The number of words in each language and the number of selected bilingual word pairs for each
of the eight language pairs.
</tableCaption>
<table confidence="0.999967111111111">
Language Pairs # Source Words # Target Words # Bilingual Word Pairs
English vs Danish 26599 17934 1140
English vs Dutch 26599 27829 2976
English vs German 26599 69336 1905
English vs Greek 26599 13318 869
English vs Italian 26599 13523 2347
English vs Portuguese 26599 27782 2408
English vs Spanish 26599 16465 2910
English vs Swedish 26599 19072 1779
</table>
<tableCaption confidence="0.97339">
Table 2: The feature templates used for the cross-lingual dependency parsing. dir denotes the direction
</tableCaption>
<bodyText confidence="0.5164555">
of the dependency relationship, which has two values {left, right}. dist denotes the distance between
the head word and the dependent word, which has five values {1, 2, 3-5, 6-10, 11+}.
</bodyText>
<table confidence="0.999572888888889">
Feature Template Feature Description
UPO5(wh) the head word’s universal POS tag
UPO5(wd) the dependent word’s universal POS tag
UPO5(wh, wd) the universal POS tag pair of the head and dependent word
R(wh) the head word’s distributed representation
R(wd) the dependent word’s distributed representation
dir&amp;UPO5 conjunction features related to the dependency direction
dist&amp;UPO5 conjunction features related to the dependency distance
dir&amp;dist&amp;UPO5 conjunction features related to the dependency direction and distance
</table>
<bodyText confidence="0.995341565217391">
To perform distributed cross-lingual representa-
tion learning using the proposed deep network ar-
chitecture, we first constructed the two-class train-
ing dataset from all the sentences (training and
test sentences) of the two language domains. This
requires the creation of sub-sentences with fixed
window size c from the given sentences. We used
window size c = 5 in the experiments. For ex-
ample, for a given sentence “I visited New York
.” , we can produce a number of sub-sentences,
including “&lt;PAD&gt; &lt;S&gt; I visited New”, “&lt;S&gt; I
visited New York”, “I visited New York .”, “vis-
ited New York. &lt;/S&gt;”, and “New York. &lt;/S&gt;
&lt;PAD&gt;”, where &lt;PAD&gt; is special token to fill
the length requirement. Negative samples are con-
structed by simply replace the middle word of each
sub-sentence with a random word.
With the constructed training data, we then per-
formed training over the deep neural network. We
used 3 hidden layers with 100 hidden units in
each layer, considering the model capacity and the
training effort. The dimension k of the embedding
word vectors in R is set as 200.
</bodyText>
<subsectionHeader confidence="0.999163">
4.3 Cross-lingual Dependency Parsing
</subsectionHeader>
<bodyText confidence="0.999862222222222">
We used the MSTParser (McDonald et al., 2005a;
McDonald et al., 2005b) as the basic dependency
parsing model. MSTParser uses spanning tree
algorithms to seek for the candidate dependency
trees and employs an online large margin train-
ing optimization algorithm. MSTParser is widely
used in the literature for dependency parsing tasks
and has demonstrated good empirical results in the
CoNLL shared tasks on multilingual dependency
parsing (Buchholz and Marsi, 2006; Nivre et al.,
2007). For this dependency parsing model, there
are a few parameters to be set: the number of max-
imum iterations for the perceptron training, and
the number of best-k dependency tree candidates.
We set the number of iterations to be 10 and only
considered the best-1 dependency tree candidate.
For the proposed cross-lingual dependency
parsing approach, we used both the delexi-
</bodyText>
<page confidence="0.999382">
124
</page>
<tableCaption confidence="0.974313">
Table 3: Test performance in terms of UAS (unlabeled attachment score) on the eight cross-lingual
dependency parsing tasks. A denotes the improvements of each method over the Baseline method.
</tableCaption>
<table confidence="0.9990847">
Tasks Baseline Proj A Proposed A X-lingual
EN2DA 36.53 41.25 4.72 42.56 6.03 38.70
EN2DE 46.24 49.15 2.91 49.54 3.30 50.70
EN2EL 61.53 62.36 0.83 62.96 1.43 63.00
EN2ES 52.05 54.54 2.49 55.72 3.67 62.90
EN2IT 56.37 57.71 1.34 59.05 2.68 68.80
EN2NL 61.96 64.41 2.45 65.13 3.17 54.30
EN2PT 68.68 71.47 2.79 72.38 3.70 71.00
EN2SV 57.79 60.99 3.20 61.88 4.09 56.90
Average 55.14 57.74 2.60 58.90 3.51 58.29
</table>
<bodyText confidence="0.998601064516129">
calized universal POS tag based features and
the language-independent word features produced
from the deep learning as input features for the
MSTParser. The set of universal POS tag based
feature templates is given in Table 2. For each
dependency relationship between a head word wh
and a dependent word wd, a set of features can
be produced from the feature templates in Ta-
ble 2, which can be further augmented by R(wh)
and R(wd). We compared our proposed approach
(Proposed) with three other methods, Baseline,
Proj and X-lingual. The Baseline method uses a
delexicalized MSTParser based only on the uni-
versal POS tag features. The Proj method is devel-
oped in (Durrett et al., 2012), which uses a bilin-
gual dictionary to learn cross-lingual features and
then uses them as augmenting features to train a
delexicalized MSTParser. The X-lingual method
uses unlabeled parallel sentences to learn cross-
lingual word clusters and used them as augment-
ing features to train a delexicalized MSTParser
(T¨ackstr¨om et al., 2012). All parsers except X-
lingual are trained on the labeled sentences in the
source language domain and tested on the test
sentences in the target language domain in the
given dataset. The performance is measured using
the standard unlabeled attachment score (UAS).
The X-lingual method uses different auxiliary re-
sources (parallel sentences), and we hence directly
cited the results reported in (T¨ackstr¨om et al.,
2012) on the same dataset.
</bodyText>
<subsectionHeader confidence="0.780886">
4.4 Results and Discussions
</subsectionHeader>
<bodyText confidence="0.992616222222222">
We reported the empirical comparison results in
terms of unlabeled attachment score (UAS) in Ta-
ble 3. We can see that the Baseline method per-
Table 4: Statistic differences. For each task, we
report the percentage of sentences in the test data
from the target language which share the same se-
quence of universal POS tags with some sentences
in the source language but with different depen-
dency trees.
</bodyText>
<table confidence="0.997117888888889">
Target Language Sentence Difference
Danish 0.31%
Dutch 1.81%
German 1.40%
Greek 1.20%
Italian 2.40%
Portuguese 1.04%
Spanish 0.97%
Swedish 2.31%
</table>
<bodyText confidence="0.999790222222222">
forms poorly across all the tasks. The average un-
labeled attachment score for this approach across
all the eight tasks is very low (about 55.14), which
suggests that the twelve universal POS tags are far
from enough to produce a good cross-lingual de-
pendency parser. Considering the small number
of universal POS tags, its limited discriminative
capacity as input features for dependency pars-
ing is understandable. To further verify this, we
calculated the percentage of sentences in the test
data which share the same sequence of universal
POS tags with a training sentence in the source
language but have different dependency parsing
structures. The values for the eight tasks are pre-
sented in Table 4. The non-trivial values reported
verified the universal POS tags’ drawback on lack-
ing discriminative capacity.
By relexicalizing the delexicalized MSTParser
</bodyText>
<page confidence="0.997319">
125
</page>
<bodyText confidence="0.999965357142857">
via augmenting the POS tag sequences with
learned interlingual features, both the Proj method
and the proposed method overcome the draw-
back of using solely universal POS tags and pro-
duce significant improvements over the Baseline
method across all the tasks. Moreover, the pro-
posed method consistently outperforms both Base-
line and Proj for all the eight tasks. By exploit-
ing only free bilingual dictionaries, the proposed
method achieves similar average performance to
the X-lingual method which requires additional
parallel sentences. All these results demonstrated
the efficacy of our word representation learning
method for cross-lingual dependency parsing.
</bodyText>
<subsectionHeader confidence="0.992813">
4.5 Impact of Labeled Training Data in
Target Language
</subsectionHeader>
<bodyText confidence="0.999991136363636">
In the experiments above, all the labeled sen-
tences for dependency parsing training are from
the source language. We wonder how much bene-
fit we can get if there are a small number of labeled
sentences in the target language as well. To answer
this question, we conducted experiments by using
a small number (Et) of labeled sentences in the
target language domain together with the labeled
sentences in the source language domain to train
cross-lingual dependency parsers. Again the per-
formance of the parsers are evaluated on the test
sentences in the target language. We tested a few
different Et values with Et E {500,1000,1500}.
We reported the unlabeled attachment score for all
the eight cross-lingual dependency parsing tasks
in Figure 2. We can see that the Baseline method
still performs poorly across the range of different
setting for all the eight tasks. The Proj method
and the proposed method again consistently out-
perform the baseline method across all the tasks,
while the proposed method achieves the best re-
sults across all the eight tasks.
</bodyText>
<subsectionHeader confidence="0.995789">
4.6 Impact of the Number of Bilingual Word
Pairs
</subsectionHeader>
<bodyText confidence="0.99990624137931">
For the eight language pairs, we have reported
the numbers of words in each language domain
and the numbers of selected bilingual word pairs
in Table 1. Next we investigated how the num-
ber of word pairs affects the performance of the
proposed cross-lingual dependency parsing. With
the selected full set of bilingual word pairs in
Table 1, we random selected m% of them with
m E {50, 75,100} to conduct experiments. Note
when m = 50, we only used 435 word pairs for
the EN2EL (English vs. Greek) task, which is
1.6% of the number of source words and 3.3% of
the number of target words. The results are re-
ported in Figure 3. We can see that by reducing the
number of bilingual word pairs, the performance
of the proposed cross-lingual dependency parsing
method degrades on all tasks. This is reasonable
since the word pairs serve as the pivots for learn-
ing cross-lingual word embeddings. Nevertheless,
by preserving 75% of the selected word pairs, the
proposed approach can still outperform the Proj
method across all the tasks. Even with only 50%
of the word pairs, our method still outperforms
the Proj method on most tasks. These results sug-
gest that the proposed cross-lingual word embed-
ding method only requires a reasonable amount of
bilingual word pairs to effectively transfer a de-
pendency parser from the source language to the
target language.
</bodyText>
<equation confidence="0.6404">
UAS vs # of Bilingual Word Pairs
EN2DA EN2DE EN2EL EN2ES EN2IT EN2NL EN2PT EN2SV
Task
</equation>
<figureCaption confidence="0.967501666666667">
Figure 3: Test performance in terms of UAS (unla-
beled attachment score) in the target language with
different numbers of bilingual word pairs.
</figureCaption>
<sectionHeader confidence="0.993377" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999864083333333">
In this paper, we proposed to automatically learn
language-independent features within a deep neu-
ral network architecture to address cross-lingual
dependency parsing problems. We first con-
structed a set of bilingual word pairs with Wiki-
tionary, which serve as the pivots in the bilingual
vocabulary for building connections across lan-
guages. We then conducted distributed word rep-
resentation learning by training a constructed aux-
iliary classifier using deep neural networks, which
induced a real-valued embedding vector for each
word of the bilingual vocabulary to capture con-
</bodyText>
<figure confidence="0.979875636363636">
UAS
45
40
75
70
65
60
55
50
Proj Proposed−50% Proposed−75% Proposed−100%
126
EN2DA EN2DE EN2EL
0 500 1000 1500
0 500 1000 1500 0 500 1000 1500 0 500 1000 1500
0 500 1000 1500
0 500 1000 1500
Labeled target training data
Labeled target training data
Labeled target training data
Labeled target training data Labeled target training data Labeled target training data
EN2ES
EN2IT
EN2ES EN2IT
0 500 1000 1500
0 500 1000 1500 0 500 1000 1500
0 500 1000 1500
Labeled target training data
Labeled target training data
Labeled target training data Labeled target training data
EN2NL
EN2PT
EN2SV
EN2NL EN2PT EN2SV
</figure>
<figureCaption confidence="0.995824">
Figure 2: Unlabeled attachment score (UAS) on the test sentences in the target language by using differ-
ent number of additional labeled training sentences in the target language.
</figureCaption>
<figure confidence="0.985519705263158">
64
43
42
41
50
63.5
49
63
62.5
UAS
48
47
UAS
61.5
62
38
61
37
36
35
46
Baseline
Proj
Proposed
45
Baseline
Proj
Proposed
60.5
60
Baseline
Proj
Proposed
40
39
60
56
59
55
UAS
58
57
52
51
56
Baseline
Proj
Proposed
55
Baseline
Proj
Proposed
UAS
54
53
66
73
62
65
72
61
64
71
63
UAS
70
UAS
60
59
62
61
60
0 500 1000 1500
Labeled target training data
69
Baseline
Proj
Proposed
0 500 1000 1500
Labeled target training data
58
Baseline
Proj
Proposed
0 500 1000 1500
Labeled target training data
68
67
57
56
Baseline
Proj
Proposed
UAS
UAS
</figure>
<bodyText confidence="0.9997238">
sistent semantic similarities for words in the two
language domains. The distributed word embed-
ding vectors were then used to augment the uni-
versal POS tags to train cross-lingual dependency
parsers. We empirically evaluated the proposed
method on eight cross-lingual dependency parsing
tasks between eight language pairs. The experi-
mental results demonstrated the effectiveness of
the proposed method, comparing to other cross-
lingual dependency parsing methods.
</bodyText>
<sectionHeader confidence="0.999239" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.980958444444444">
L. Bottou. 1991. Stochastic gradient learning in neural
networks. In Proceedings ofIeuro-Iˆımes.
S. Buchholz and E. Marsi. 2006. Conll-x shared task
on multilingual dependency parsing. In Proceedings
of the Conference on Computational Iatural Lan-
guage Learning (CoILL).
D. Burkett, S. Petrov, J. Blitzer, and D. Klein. 2010.
Learning better monolingual models with unanno-
tated bilingual text. In Proceedings of the Confer-
ence on Computational Iatural Language Learning
(CoILL).
W. Che, M. Wang, C. Manning, and T. Liu. 2013.
Named entity recognition with bilingual constraints.
In Proceedings of Conference of the Iorth American
Chapter of the Association for Computational Lin-
guistics: Human Language Technologies (IAACL).
R. Collobert and J. Weston. 2008. A unified architec-
ture for natural language processing: Deep neural
</reference>
<page confidence="0.989018">
127
</page>
<reference confidence="0.997658805555556">
networks with multitask learning. In Proceedings of
the International Conference on Machine Learning
(ICML).
R. Collobert, J. Weston, L. Bottou, M. Karlen,
K. Kavukcuoglu, and P. Kuksa. 2011. Natural lan-
guage processing (almost) from scratch. Journal
of Machine Learning Research (JMLR), 12:2493–
2537.
D. Das and S. Petrov. 2011. Unsupervised part-of-
speech tagging with bilingual graph-based projec-
tions. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies (ACL).
G. Durrett, A. Pauls, and D. Klein. 2012. Syntactic
transfer using a bilingual lexicon. In Proceedings of
the Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Nat-
ural Language Learning (EMNLP-CoNLL).
K. Ganchev, J. Gillenwater, and B. Taskar. 2009. De-
pendency grammar induction via bitext projection
constraints. In Proceedings of the Joint Conference
of the Annual Meeting of the ACL and the Interna-
tional Joint Conference on Natural Language Pro-
cessing of the AFNLP (ACL-IJCNLP).
W. Guo and M. Diab. 2010. Combining orthogonal
monolingual and multilingual sources of evidence
for all words wsd. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
J. Henderson. 2004. Discriminative training of a neu-
ral network statistical parser. In Proceedings of the
Annual Meeting of the Association for Computa-
tional Linguistics (ACL).
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
O. Kolak. 2005. Bootstrapping parsers via syntactic
projection across parallel texts. Natural Language
Engineering, 11:11–311.
W. Jiang, Q. Liu, and Y. L¨u. 2011. Relaxed cross-
lingual projection of constituent syntax. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing (EMNLP).
M. Khapra, S. Sohoney, A. Kulkarni, and P. Bhat-
tacharyya. 2010. Value for money: Balancing an-
notation effort, lexicon building and accuracy for
multilingual wsd. In Proceedings of the Inter-
national Conference on Computational Linguistics
(COLING).
S. Kim and G. Lee. 2012. A graph-based cross-
lingual projection approach for weakly supervised
relation extraction. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
S. Kim, M. Jeong, J. Lee, and G. Lee. 2010. A cross-
lingual annotation projection approach for relation
detection. In Proceedings of the International Con-
ference on Computational Linguistics (COLING).
S. Kim, K. Toutanova, and H. Yu. 2012. Multilin-
gual named entity recognition using parallel data
and metadata from wikipedia. In Proceedings of
the Annual Meeting of the Association for Compu-
tational Linguistics (ACL).
A. Klementiev, I. Titov, and B. Bhattarai. 2012. In-
ducing crosslingual distributed representations of
words. In Proceedings of the International Confer-
ence on Computational Linguistics (COLING).
M. Kozhevnikov and I. Titov. 2012. Cross-lingual
bootstrapping for semantic role labeling. In Pro-
ceedings of the NIPS Workshop on Crosslingual
Technologies (XLITE).
K. Liu, Y. L¨u, W. Jiang, and Q. Liu. 2013. Bilingually-
guided monolingual dependency parsing grammar
induction. In Proceedings of the Conference on An-
nual Meeting of the Association for Computational
Linguistics (ACL).
R. McDonald, K. Crammer, and F. Pereira. 2005a. On-
line large-margin training of dependency parsers. In
Proceedings of the Annual Meeting on Association
for Computational Linguistics (ACL).
R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc.
2005b. Non-projective dependency parsing using
spanning tree algorithms. In Proceedings of the
Conference on Human Language Technology and
Empirical Methods in Natural Language Processing
(HLT-EMNLP).
R. McDonald, S. Petrov, and K. Hall. 2011.
Multi-source transfer of delexicalized dependency
parsers. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP).
T. Naseem, H. Chen, R. Barzilay, and M. Johnson.
2010. Using universal linguistic knowledge to guide
grammar induction. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP).
T. Naseem, R. Barzilay, and A. Globerson. 2012. Se-
lective sharing for multilingual dependency parsing.
In Proceedings of the Annual Meeting of the Associ-
ation for Computational Linguistics (ACL).
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The conll 2007
shared task on dependency parsing. In Proceed-
ings of the Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL).
S. Petrov, D. Das, and R. McDonald. 2012. A univer-
sal part-of-speech tagset. In Proceedings of the In-
ternational Conference on Language Resources and
Evaluation (LREC).
</reference>
<page confidence="0.975948">
128
</page>
<reference confidence="0.999759577464789">
D. Smith and J. Eisner. 2009. Parser adaptation and
projection with quasi-synchronous grammar fea-
tures. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP).
R. Socher, J. Pennington, E. Huang, A. Ng, and
C. Manning. 2011. Semi-supervised recursive au-
toencoders for predicting sentiment distributions. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP).
O. T¨ackstr¨om, R. McDonald, and J. Uszkoreit. 2012.
Cross-lingual word clusters for direct transfer of lin-
guistic structure. In Proceedings of the Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies (NAACL).
O. T¨ackstr¨om, R. McDonald, and J. Nivre. 2013.
Target language adaptation of discriminative trans-
fer parsers. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies (NAACL).
I. Titov and J. Henderson. 2007. Constituent parsing
with incremental sigmoid belief networks. In Pro-
ceedings of the Annual Meeting of the Association
for Computational Linguistics (ACL).
I. Titov and J. Henderson. 2010. A latent variable
model for generative dependency parsing. In Pro-
ceedings of the International Conference on Parsing
Technology (IWPT).
I. Titov and A. Klementiev. 2012. Crosslingual induc-
tion of semantic roles. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
J. Turian, L. Ratinov, and Y. Bengio. 2010. Word rep-
resentations: a simple and general method for semi-
supervised learning. In Proceedings of the Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
M. Wang and C. Manning. 2014. Cross-
lingual pseudo-projected expectation regularization
for weakly supervised learning. Transactions of the
Association for Computational Linguistics (TACL),
2:55–66.
D. Yarowsky and G. Ngai. 2001. Inducing multilin-
gual pos taggers and np bracketers via robust pro-
jection across aligned corpora. In Proceedings of the
Meeting of the North American Chapter of the Asso-
ciation for Computational Linguistics on Language
Technologies (NAACL).
Y. Zhang, R. Reichart, R. Barzilay, and A. Glober-
son. 2012. Learning to map into a universal pos
tagset. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL).
H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross
language dependency parsing using a bilingual lex-
icon. In Proceedings of the Joint Conference of the
Annual Meeting of the ACL and the International
Joint Conference on Natural Language Processing
of the AFNLP (ACL-IJCNLP).
T. Zhuang and C. Zong. 2010. Joint inference for bilin-
gual semantic role labeling. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP).
W. Zou, R. Socher, D. Cer, and C. Manning. 2013.
Bilingual word embeddings for phrase-based ma-
chine translation. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP).
</reference>
<page confidence="0.998553">
129
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.584752">
<title confidence="0.995658">Distributed Word Representation Learning for Dependency Parsing</title>
<author confidence="0.986212">Xiao</author>
<affiliation confidence="0.997985">Department of Computer and Information</affiliation>
<address confidence="0.802627">Temple Philadelphia, PA 19122,</address>
<abstract confidence="0.998965448275862">This paper proposes to learn languageindependent word representations to address cross-lingual dependency parsing, which aims to predict the dependency parsing trees for sentences in the target language by training a dependency parser with labeled sentences from a source language. We first combine all sentences from both languages to induce real-valued distributed representation of words under a deep neural network architecture, which is expected to capture semantic similarities of words not only within the same language but also across different languages. We then use the induced interlingual word representation as augmenting features to train a delexicalized dependency parser on labeled sentences in the source language and apply it to the target sentences. To investigate the effectiveness of the proposed technique, extensive experiments are conducted on cross-lingual dependency parsing tasks with nine different languages. The experimental results demonstrate the superior cross-lingual generalizability of the word representation induced by the proposed approach, comparing to alternative comparison methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Bottou</author>
</authors>
<title>Stochastic gradient learning in neural networks.</title>
<date>1991</date>
<booktitle>In Proceedings ofIeuro-Iˆımes.</booktitle>
<contexts>
<context position="18120" citStr="Bottou, 1991" startWordPosition="2802" endWordPosition="2803"> word of xi with a random word from V . It is desirable for the model to produce an output score s(xi) that is much larger than the score s(ˆxi) for each pair of training instances. Thus we perform training to maximize the separation margins between the pairs of scores over positive and negative samples under a hinge loss; that is we minimize the following training loss �N max(0, 1 − s(xi) + s(ˆxi)) (5) 1 J(D) = N i=1 We perform a random initialization over the look-up table and weight model parameters, and set all the bias model parameters to zeros. Then we use a stochastic gradient descent (Bottou, 1991) algorithm to perform optimization. 3.4 Cross-Lingual Dependency Parsing The training of deep network model above will produce a word embedding matrix R for all words in the two language domains. Moreover, by having each translated bilingual pair of words sharing the same representation vector in R in the training process, the embedding matrix R is expected to capture consistent and comparable semantic meanings across languages, and provide a language-independent and distributed representation for each word in the bilingual dictionary V . Given R, for each sentence x = w1, w2, ... , wn from th</context>
</contexts>
<marker>Bottou, 1991</marker>
<rawString>L. Bottou. 1991. Stochastic gradient learning in neural networks. In Proceedings ofIeuro-Iˆımes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Computational Iatural Language Learning (CoILL).</booktitle>
<contexts>
<context position="19520" citStr="Buchholz and Marsi, 2006" startWordPosition="3023" endWordPosition="3026">cific words with a sequence of universal POS tags (Petrov et al., 2012). Finally we train a delexicalized dependency parser on the labeled sentences in the source language based on the universal POS tag features and the learned distributed features. and apply it to perform dependency parsing on the sentences in the target language domain. 4 Experiments We empirically evaluated the proposed crosslingual word representation learning for crosslingual dependency parsing. In this section, we present the experimental setup and the results. 4.1 Dataset We used the dataset from the CoNLL shared task (Buchholz and Marsi, 2006; Nivre et al., 2007) for cross-lingual dependency parsing. We conducted experiments with the following nine languages: English (EN), Danish (DA), German (DE), Greek (EL), Spanish (ES), Italian (IT), Dutch (NL), Portuguese (PT) and Swedish (SV). For each language, there is a separate training set and a test set. We used English, which usually has more labeled resources, as the source language, while treating the others as target languages. We thus constructed eight cross-lingual dependency parsing tasks (EN2DA, EN2DE, EN2EL, EN2ES, EN2IT, EN2NL, EN2PT, EN2SV), one for each of the eight target </context>
<context position="24059" citStr="Buchholz and Marsi, 2006" startWordPosition="3734" endWordPosition="3737">, considering the model capacity and the training effort. The dimension k of the embedding word vectors in R is set as 200. 4.3 Cross-lingual Dependency Parsing We used the MSTParser (McDonald et al., 2005a; McDonald et al., 2005b) as the basic dependency parsing model. MSTParser uses spanning tree algorithms to seek for the candidate dependency trees and employs an online large margin training optimization algorithm. MSTParser is widely used in the literature for dependency parsing tasks and has demonstrated good empirical results in the CoNLL shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). For this dependency parsing model, there are a few parameters to be set: the number of maximum iterations for the perceptron training, and the number of best-k dependency tree candidates. We set the number of iterations to be 10 and only considered the best-1 dependency tree candidate. For the proposed cross-lingual dependency parsing approach, we used both the delexi124 Table 3: Test performance in terms of UAS (unlabeled attachment score) on the eight cross-lingual dependency parsing tasks. A denotes the improvements of each method over the Baseline method. Tasks Basel</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of the Conference on Computational Iatural Language Learning (CoILL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Burkett</author>
<author>S Petrov</author>
<author>J Blitzer</author>
<author>D Klein</author>
</authors>
<title>Learning better monolingual models with unannotated bilingual text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Iatural Language Learning (CoILL).</booktitle>
<contexts>
<context position="8092" citStr="Burkett et al., 2010" startWordPosition="1188" endWordPosition="1191">ion techniques to encode the linguistic constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 re</context>
</contexts>
<marker>Burkett, Petrov, Blitzer, Klein, 2010</marker>
<rawString>D. Burkett, S. Petrov, J. Blitzer, and D. Klein. 2010. Learning better monolingual models with unannotated bilingual text. In Proceedings of the Conference on Computational Iatural Language Learning (CoILL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Che</author>
<author>M Wang</author>
<author>C Manning</author>
<author>T Liu</author>
</authors>
<title>Named entity recognition with bilingual constraints.</title>
<date>2013</date>
<booktitle>In Proceedings of Conference of the Iorth American Chapter of the Association for Computational Linguistics: Human Language Technologies (IAACL).</booktitle>
<contexts>
<context position="8110" citStr="Che et al., 2013" startWordPosition="1192" endWordPosition="1195">de the linguistic constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T</context>
</contexts>
<marker>Che, Wang, Manning, Liu, 2013</marker>
<rawString>W. Che, M. Wang, C. Manning, and T. Liu. 2013. Named entity recognition with bilingual constraints. In Proceedings of Conference of the Iorth American Chapter of the Association for Computational Linguistics: Human Language Technologies (IAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>J Weston</author>
</authors>
<title>A unified architecture for natural language processing: Deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="10870" citStr="Collobert and Weston, 2008" startWordPosition="1586" endWordPosition="1589">oreover, the method in (Klementiev et al., 2012) requires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical pars</context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>R. Collobert and J. Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Collobert</author>
<author>J Weston</author>
<author>L Bottou</author>
<author>M Karlen</author>
<author>K Kavukcuoglu</author>
<author>P Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research (JMLR),</journal>
<volume>12</volume>
<pages>2537</pages>
<contexts>
<context position="10894" citStr="Collobert et al., 2011" startWordPosition="1590" endWordPosition="1593">entiev et al., 2012) requires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson </context>
<context position="14733" citStr="Collobert et al., 2011" startWordPosition="2184" endWordPosition="2187">rs will serve as the bridge across languages. 3.2 Interlingual Word Representation Learning with Deep Neural Networks Given the constructed bilingual vocabulary V with v entries, we will learn a latent word embedding matrix R E Rkxv over the sentences in the two language domains by using a deep neural network model. This embedding matrix will map each word w in the vocabulary V into a real valued representation vector R(w) with length k. For each bilingual pair of words that are mapped into the same entry of V , they will be mapped into the same vector in R as well. Following the strategy of (Collobert et al., 2011), we construct a simple two-class classification problem over the given sentences. We use the sub-sentences with fixed window size c constructed from the given sentences in the two language domains as positive samples and construct the negative samples by replacing the middle word of each positive subsentence with a random word from V . We then train a deep neural network for this two-class classification problem, while simultaneously learning the latent embedding matrix R. The deep neural network architecture is given in Figure 1. The bottom layer of the deep architecture is the input layer, </context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research (JMLR), 12:2493– 2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Das</author>
<author>S Petrov</author>
</authors>
<title>Unsupervised part-ofspeech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL).</booktitle>
<contexts>
<context position="6145" citStr="Das and Petrov, 2011" startWordPosition="899" endWordPosition="902">ation projection methods use parallel sentences to project the annotations from the source language side to the target language side and then train dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including </context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>D. Das and S. Petrov. 2011. Unsupervised part-ofspeech tagging with bilingual graph-based projections. In Proceedings of the Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Durrett</author>
<author>A Pauls</author>
<author>D Klein</author>
</authors>
<title>Syntactic transfer using a bilingual lexicon.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="1860" citStr="Durrett et al., 2012" startWordPosition="266" endWordPosition="269">alizability of the word representation induced by the proposed approach, comparing to alternative comparison methods. 1 Introduction With the rapid development of linguistic resources and tools in multiple languages, it is very important to develop cross-lingual natural language processing (NLP) systems. Cross-lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training sentences by using a dependency parser trained on a large amount of sentences with annotated dependency trees in a source language (Durrett et al., 2012; McDonald et al., 2011; Zhao et al., 2009). Cross-lingual dependency parsing is popularly studied in natural language processing area as it can greatly reduce the expensive manual annotation effort in the target language by exploiting the dependency annotations from a source language (Durrett et al., 2012; McDonald et al., 2011; T¨ackstr¨om et al., 2012). One fundamental challenge of cross-lingual dependency parsing stems from the word-level representation divergence across languages. Since sentences in different languages are expressed using different vocabularies, if we train a dependency p</context>
<context position="3538" citStr="Durrett et al., 2012" startWordPosition="519" endWordPosition="522"> 2012). With the universal POS tag features, this method provides a possible way to transfer dependency parsing information from the source language to the target language and has demonstrated some good empirical results (McDonald et al., 2011). However, the number of universal POS tags is small, which limits their discriminative capacity as input features for dependency parsing. A few other works hence propose to improve the delexicalized system by learning more effective cross-lingual features such as bilingual word clusters (T¨ackstr¨om et al., 2012) and other interlingual representations (Durrett et al., 2012). In this paper, we propose to address crosslingual dependency parsing by learning distributed interlingual word representations using a deep neural network architecture. We first combine all the sentences from two language domains and 119 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 119–129, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics build cross language word connections based on Wikitionary, which works as a free bilingual dictionary. Then by exploiting a deep learning architecture, we learn real-valued den</context>
<context position="8887" citStr="Durrett et al., 2012" startWordPosition="1307" endWordPosition="1310">ense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang et al., 2012). A variety of auxiliary resources have been used to induce interlingual features, including bilingual lexicon (Durrett et al., 2012), and unlabeled parallel sentences (T¨ackstr¨om et al., 2013). Based on different learning mechanisms (whether or not using labeled data) for inducing language-independent features, cross-lingual representation learning methods can be categorized into unsupervised representation learning (T¨ackstr¨om et al., 2013) and supervised representation learning (Durrett et al., 2012). The language-independent features include bilingual word clusters (T¨ackstr¨om et al., 2012), language-independent projection features (Durrett et al., 2012), and automatically induced languageindependent POS tags (Zhang </context>
<context position="25737" citStr="Durrett et al., 2012" startWordPosition="4013" endWordPosition="4016">endent word features produced from the deep learning as input features for the MSTParser. The set of universal POS tag based feature templates is given in Table 2. For each dependency relationship between a head word wh and a dependent word wd, a set of features can be produced from the feature templates in Table 2, which can be further augmented by R(wh) and R(wd). We compared our proposed approach (Proposed) with three other methods, Baseline, Proj and X-lingual. The Baseline method uses a delexicalized MSTParser based only on the universal POS tag features. The Proj method is developed in (Durrett et al., 2012), which uses a bilingual dictionary to learn cross-lingual features and then uses them as augmenting features to train a delexicalized MSTParser. The X-lingual method uses unlabeled parallel sentences to learn crosslingual word clusters and used them as augmenting features to train a delexicalized MSTParser (T¨ackstr¨om et al., 2012). All parsers except Xlingual are trained on the labeled sentences in the source language domain and tested on the test sentences in the target language domain in the given dataset. The performance is measured using the standard unlabeled attachment score (UAS). Th</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>G. Durrett, A. Pauls, and D. Klein. 2012. Syntactic transfer using a bilingual lexicon. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Gillenwater</author>
<author>B Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP).</booktitle>
<contexts>
<context position="7182" citStr="Ganchev et al., 2009" startWordPosition="1053" endWordPosition="1056">013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual model learning methods train cross-lingual dependency parsers with parameter constraints obtained from parallel data (Liu et al., 2013; Ganchev et al., 2009) or linguistic knowledges (Naseem et al., 2010; Naseem et al., 2012). Among these methods, some proposed to train a joint dependency parsing system with parameters shared across the dependency parsing models in individual languages (Liu et al., 2013). Other works used posterior regularization techniques to encode the linguistic constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typolo</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>K. Ganchev, J. Gillenwater, and B. Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Guo</author>
<author>M Diab</author>
</authors>
<title>Combining orthogonal monolingual and multilingual sources of evidence for all words wsd.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="8306" citStr="Guo and Diab, 2010" startWordPosition="1221" endWordPosition="1224">nstructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang et al., 2012). A variety of auxiliary resources have been used to induce interlingual features, including bilingual lexicon (Durrett et al., 2012), and unlabeled par</context>
</contexts>
<marker>Guo, Diab, 2010</marker>
<rawString>W. Guo and M. Diab. 2010. Combining orthogonal monolingual and multilingual sources of evidence for all words wsd. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Henderson</author>
</authors>
<title>Discriminative training of a neural network statistical parser.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="10911" citStr="Henderson, 2004" startWordPosition="1594" endWordPosition="1595">uires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson (2010) extended t</context>
</contexts>
<marker>Henderson, 2004</marker>
<rawString>J. Henderson. 2004. Discriminative training of a neural network statistical parser. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering,</title>
<date>2005</date>
<pages>11--11</pages>
<contexts>
<context position="5754" citStr="Hwa et al., 2005" startWordPosition="837" endWordPosition="840">4 presents the empirical study on eight cross language dependency parsing tasks. We then conclude the paper in Section 5. 2 Related Work Previous works developed in the literature have tackled cross-lingual dependency parsing by using cross-lingual annotation projection methods, multilingual model learning methods, and crosslingual representation learning methods. Cross-lingual annotation projection methods use parallel sentences to project the annotations from the source language side to the target language side and then train dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11:11–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Jiang</author>
<author>Q Liu</author>
<author>Y L¨u</author>
</authors>
<title>Relaxed crosslingual projection of constituent syntax.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<marker>Jiang, Liu, L¨u, 2011</marker>
<rawString>W. Jiang, Q. Liu, and Y. L¨u. 2011. Relaxed crosslingual projection of constituent syntax. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Khapra</author>
<author>S Sohoney</author>
<author>A Kulkarni</author>
<author>P Bhattacharyya</author>
</authors>
<title>Value for money: Balancing annotation effort, lexicon building and accuracy for multilingual wsd.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="6288" citStr="Khapra et al., 2010" startWordPosition="921" endWordPosition="924">ain dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010</context>
</contexts>
<marker>Khapra, Sohoney, Kulkarni, Bhattacharyya, 2010</marker>
<rawString>M. Khapra, S. Sohoney, A. Kulkarni, and P. Bhattacharyya. 2010. Value for money: Balancing annotation effort, lexicon building and accuracy for multilingual wsd. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>G Lee</author>
</authors>
<title>A graph-based crosslingual projection approach for weakly supervised relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="6255" citStr="Kim and Lee, 2012" startWordPosition="915" endWordPosition="918">arget language side and then train dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named ent</context>
</contexts>
<marker>Kim, Lee, 2012</marker>
<rawString>S. Kim and G. Lee. 2012. A graph-based crosslingual projection approach for weakly supervised relation extraction. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>M Jeong</author>
<author>J Lee</author>
<author>G Lee</author>
</authors>
<title>A crosslingual annotation projection approach for relation detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="6428" citStr="Kim et al., 2010" startWordPosition="942" endWordPosition="945">2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual mod</context>
</contexts>
<marker>Kim, Jeong, Lee, Lee, 2010</marker>
<rawString>S. Kim, M. Jeong, J. Lee, and G. Lee. 2010. A crosslingual annotation projection approach for relation detection. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>K Toutanova</author>
<author>H Yu</author>
</authors>
<title>Multilingual named entity recognition using parallel data and metadata from wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="6844" citStr="Kim et al., 2012" startWordPosition="1003" endWordPosition="1006">metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual model learning methods train cross-lingual dependency parsers with parameter constraints obtained from parallel data (Liu et al., 2013; Ganchev et al., 2009) or linguistic knowledges (Naseem et al., 2010; Naseem et al., 2012). Among these methods, some proposed to train a joint dependency parsing system with parameters shared across the dependency parsing models in individual languages (Liu et al., 2013). Other work</context>
</contexts>
<marker>Kim, Toutanova, Yu, 2012</marker>
<rawString>S. Kim, K. Toutanova, and H. Yu. 2012. Multilingual named entity recognition using parallel data and metadata from wikipedia. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>I Titov</author>
<author>B Bhattarai</author>
</authors>
<title>Inducing crosslingual distributed representations of words.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="10197" citStr="Klementiev et al., 2012" startWordPosition="1482" endWordPosition="1486">al representation learning methods have also demonstrated efficacy in different NLP applications such as cross language named entity recognition (T¨ackstr¨om et al., 2012) and cross language semantic role labeling (Titov and Klementiev, 2012). Our work shares similarity with these cross-lingual representation learning methods on inducing new language-independent features, but differs from them in that we learn cross-lingual word embeddings. Though multilingual word embeddings have been employed in the literature, they are developed for other NLP tasks such as cross-lingual sentiment analysis (Klementiev et al., 2012), and machine translation (Zou et al., 2013). Moreover, the method in (Klementiev et al., 2012) requires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, </context>
</contexts>
<marker>Klementiev, Titov, Bhattarai, 2012</marker>
<rawString>A. Klementiev, I. Titov, and B. Bhattarai. 2012. Inducing crosslingual distributed representations of words. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kozhevnikov</author>
<author>I Titov</author>
</authors>
<title>Cross-lingual bootstrapping for semantic role labeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the NIPS Workshop on Crosslingual Technologies (XLITE).</booktitle>
<contexts>
<context position="8254" citStr="Kozhevnikov and Titov, 2012" startWordPosition="1213" endWordPosition="1216">. The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang et al., 2012). A variety of auxiliary resources have been used to induce interlingual features, including bilingu</context>
</contexts>
<marker>Kozhevnikov, Titov, 2012</marker>
<rawString>M. Kozhevnikov and I. Titov. 2012. Cross-lingual bootstrapping for semantic role labeling. In Proceedings of the NIPS Workshop on Crosslingual Technologies (XLITE).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Liu</author>
<author>Y L¨u</author>
<author>W Jiang</author>
<author>Q Liu</author>
</authors>
<title>Bilinguallyguided monolingual dependency parsing grammar induction.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Liu, L¨u, Jiang, Liu, 2013</marker>
<rawString>K. Liu, Y. L¨u, W. Jiang, and Q. Liu. 2013. Bilinguallyguided monolingual dependency parsing grammar induction. In Proceedings of the Conference on Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="23640" citStr="McDonald et al., 2005" startWordPosition="3672" endWordPosition="3675">sited New York”, “I visited New York .”, “visited New York. &lt;/S&gt;”, and “New York. &lt;/S&gt; &lt;PAD&gt;”, where &lt;PAD&gt; is special token to fill the length requirement. Negative samples are constructed by simply replace the middle word of each sub-sentence with a random word. With the constructed training data, we then performed training over the deep neural network. We used 3 hidden layers with 100 hidden units in each layer, considering the model capacity and the training effort. The dimension k of the embedding word vectors in R is set as 200. 4.3 Cross-lingual Dependency Parsing We used the MSTParser (McDonald et al., 2005a; McDonald et al., 2005b) as the basic dependency parsing model. MSTParser uses spanning tree algorithms to seek for the candidate dependency trees and employs an online large margin training optimization algorithm. MSTParser is widely used in the literature for dependency parsing tasks and has demonstrated good empirical results in the CoNLL shared tasks on multilingual dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). For this dependency parsing model, there are a few parameters to be set: the number of maximum iterations for the perceptron training, and the number of best-</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005a. Online large-margin training of dependency parsers. In Proceedings of the Annual Meeting on Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajiˇc</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP).</booktitle>
<marker>McDonald, Pereira, Ribarov, Hajiˇc, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajiˇc. 2005b. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (HLT-EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>S Petrov</author>
<author>K Hall</author>
</authors>
<title>Multi-source transfer of delexicalized dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1883" citStr="McDonald et al., 2011" startWordPosition="270" endWordPosition="273">d representation induced by the proposed approach, comparing to alternative comparison methods. 1 Introduction With the rapid development of linguistic resources and tools in multiple languages, it is very important to develop cross-lingual natural language processing (NLP) systems. Cross-lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training sentences by using a dependency parser trained on a large amount of sentences with annotated dependency trees in a source language (Durrett et al., 2012; McDonald et al., 2011; Zhao et al., 2009). Cross-lingual dependency parsing is popularly studied in natural language processing area as it can greatly reduce the expensive manual annotation effort in the target language by exploiting the dependency annotations from a source language (Durrett et al., 2012; McDonald et al., 2011; T¨ackstr¨om et al., 2012). One fundamental challenge of cross-lingual dependency parsing stems from the word-level representation divergence across languages. Since sentences in different languages are expressed using different vocabularies, if we train a dependency parser on the word-level</context>
<context position="3161" citStr="McDonald et al., 2011" startWordPosition="464" endWordPosition="467">ail to parse the sentences in a different target language. A variety of work in the literature has attempted to bridge the word-level representation divergence across languages. One intuitive method delexicalizes the dependency parser by replacing the language-specific word-level features with language-independent features such as universal part-of-speech tags (Petrov et al., 2012). With the universal POS tag features, this method provides a possible way to transfer dependency parsing information from the source language to the target language and has demonstrated some good empirical results (McDonald et al., 2011). However, the number of universal POS tags is small, which limits their discriminative capacity as input features for dependency parsing. A few other works hence propose to improve the delexicalized system by learning more effective cross-lingual features such as bilingual word clusters (T¨ackstr¨om et al., 2012) and other interlingual representations (Durrett et al., 2012). In this paper, we propose to address crosslingual dependency parsing by learning distributed interlingual word representations using a deep neural network architecture. We first combine all the sentences from two language</context>
</contexts>
<marker>McDonald, Petrov, Hall, 2011</marker>
<rawString>R. McDonald, S. Petrov, and K. Hall. 2011. Multi-source transfer of delexicalized dependency parsers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Naseem</author>
<author>H Chen</author>
<author>R Barzilay</author>
<author>M Johnson</author>
</authors>
<title>Using universal linguistic knowledge to guide grammar induction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="7228" citStr="Naseem et al., 2010" startWordPosition="1061" endWordPosition="1064"> parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual model learning methods train cross-lingual dependency parsers with parameter constraints obtained from parallel data (Liu et al., 2013; Ganchev et al., 2009) or linguistic knowledges (Naseem et al., 2010; Naseem et al., 2012). Among these methods, some proposed to train a joint dependency parsing system with parameters shared across the dependency parsing models in individual languages (Liu et al., 2013). Other works used posterior regularization techniques to encode the linguistic constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be le</context>
</contexts>
<marker>Naseem, Chen, Barzilay, Johnson, 2010</marker>
<rawString>T. Naseem, H. Chen, R. Barzilay, and M. Johnson. 2010. Using universal linguistic knowledge to guide grammar induction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Naseem</author>
<author>R Barzilay</author>
<author>A Globerson</author>
</authors>
<title>Selective sharing for multilingual dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="7250" citStr="Naseem et al., 2012" startWordPosition="1065" endWordPosition="1068">al annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual model learning methods train cross-lingual dependency parsers with parameter constraints obtained from parallel data (Liu et al., 2013; Ganchev et al., 2009) or linguistic knowledges (Naseem et al., 2010; Naseem et al., 2012). Among these methods, some proposed to train a joint dependency parsing system with parameters shared across the dependency parsing models in individual languages (Liu et al., 2013). Other works used posterior regularization techniques to encode the linguistic constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel se</context>
</contexts>
<marker>Naseem, Barzilay, Globerson, 2012</marker>
<rawString>T. Naseem, R. Barzilay, and A. Globerson. 2012. Selective sharing for multilingual dependency parsing. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The conll</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The conll 2007 shared task on dependency parsing. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="2923" citStr="Petrov et al., 2012" startWordPosition="426" endWordPosition="429">vel representation divergence across languages. Since sentences in different languages are expressed using different vocabularies, if we train a dependency parser on the word-level features of sentences from a source language, it will fail to parse the sentences in a different target language. A variety of work in the literature has attempted to bridge the word-level representation divergence across languages. One intuitive method delexicalizes the dependency parser by replacing the language-specific word-level features with language-independent features such as universal part-of-speech tags (Petrov et al., 2012). With the universal POS tag features, this method provides a possible way to transfer dependency parsing information from the source language to the target language and has demonstrated some good empirical results (McDonald et al., 2011). However, the number of universal POS tags is small, which limits their discriminative capacity as input features for dependency parsing. A few other works hence propose to improve the delexicalized system by learning more effective cross-lingual features such as bilingual word clusters (T¨ackstr¨om et al., 2012) and other interlingual representations (Durret</context>
<context position="18967" citStr="Petrov et al., 2012" startWordPosition="2937" endWordPosition="2940">ated bilingual pair of words sharing the same representation vector in R in the training process, the embedding matrix R is expected to capture consistent and comparable semantic meanings across languages, and provide a language-independent and distributed representation for each word in the bilingual dictionary V . Given R, for each sentence x = w1, w2, ... , wn from the two language domains, we retrieved the representation vector R(wi) for each word wi. Moreover, we further delexicalized the sentence by replacing the sequence of language-specific words with a sequence of universal POS tags (Petrov et al., 2012). Finally we train a delexicalized dependency parser on the labeled sentences in the source language based on the universal POS tag features and the learned distributed features. and apply it to perform dependency parsing on the sentences in the target language domain. 4 Experiments We empirically evaluated the proposed crosslingual word representation learning for crosslingual dependency parsing. In this section, we present the experimental setup and the results. 4.1 Dataset We used the dataset from the CoNLL shared task (Buchholz and Marsi, 2006; Nivre et al., 2007) for cross-lingual depende</context>
<context position="20658" citStr="Petrov et al., 2012" startWordPosition="3197" endWordPosition="3200">N2DE, EN2EL, EN2ES, EN2IT, EN2NL, EN2PT, EN2SV), one for each of the eight target languages. For example, the task EI2DA means that we used Danish (DA) as the target language while using English (EI) as the source language. For each cross language dependency parsing task, we first performed representation learning and then conducted dependency parsing training and test. In this dataset, each sentence is labeled with gold standard part-of-speech tags. To produce delexicalized cross-lingual dependency parsers, we mapped these language-specific part-of-speech tags into twelve universal POS tags (Petrov et al., 2012): ADJ (adjectives), ADP (prepositions or postpositions), ADV (adverbs), CONJ (conjunctions), DET (determiners), NOUN (nouns), NUM (numerals), PRON (pronouns), PRT (particles), PUNC (punctuation marks), VERB (verbs) and X (for others). 4.2 Representation Learning For each language pair, we produced a set of oneto-one bilingual word pairs using Wikitionary to build cross language connections. The numbers of bilingual word pairs produced for all the eight language pairs and the numbers of words in each language are given in Table 1. 123 Table 1: The number of words in each language and the number</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2012. A universal part-of-speech tagset. In Proceedings of the International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Smith</author>
<author>J Eisner</author>
</authors>
<title>Parser adaptation and projection with quasi-synchronous grammar features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5796" citStr="Smith and Eisner, 2009" startWordPosition="845" endWordPosition="849">ght cross language dependency parsing tasks. We then conclude the paper in Section 5. 2 Related Work Previous works developed in the literature have tackled cross-lingual dependency parsing by using cross-lingual annotation projection methods, multilingual model learning methods, and crosslingual representation learning methods. Cross-lingual annotation projection methods use parallel sentences to project the annotations from the source language side to the target language side and then train dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa</context>
</contexts>
<marker>Smith, Eisner, 2009</marker>
<rawString>D. Smith and J. Eisner. 2009. Parser adaptation and projection with quasi-synchronous grammar features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Socher</author>
<author>J Pennington</author>
<author>E Huang</author>
<author>A Ng</author>
<author>C Manning</author>
</authors>
<title>Semi-supervised recursive autoencoders for predicting sentiment distributions.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="10932" citStr="Socher et al., 2011" startWordPosition="1596" endWordPosition="1599">ntences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson (2010) extended the incremental sigmoi</context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>R. Socher, J. Pennington, E. Huang, A. Ng, and C. Manning. 2011. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O T¨ackstr¨om</author>
<author>R McDonald</author>
<author>J Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL).</booktitle>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>O. T¨ackstr¨om, R. McDonald, and J. Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O T¨ackstr¨om</author>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Target language adaptation of discriminative transfer parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL).</booktitle>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>O. T¨ackstr¨om, R. McDonald, and J. Nivre. 2013. Target language adaptation of discriminative transfer parsers. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>Constituent parsing with incremental sigmoid belief networks.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="11577" citStr="Titov and Henderson, 2007" startWordPosition="1688" endWordPosition="1691">on, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson (2010) extended the incremental sigmoid Belief networks (Titov and Henderson, 2007) to a generative latent variable model for dependency parsing. Turian et al. (2010) employed neural networks to induce word representations for sequence labeling tasks such as named entity recognition. 3 Cross-Lingual Dependency Parsing with Word Representation Learning In this work, we aim to tackle cross-lingual dependency parsing by learning language-independent distributed word representations with deep neural networks. We first build connections across languages using free bilingual dictionaries. Then we introduce the deep neural network framework for cross-lingual word representation lea</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>I. Titov and J. Henderson. 2007. Constituent parsing with incremental sigmoid belief networks. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>J Henderson</author>
</authors>
<title>A latent variable model for generative dependency parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Parsing Technology (IWPT).</booktitle>
<contexts>
<context position="10959" citStr="Titov and Henderson, 2010" startWordPosition="1600" endWordPosition="1603"> word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson (2010) extended the incremental sigmoid Belief networks (Titov an</context>
</contexts>
<marker>Titov, Henderson, 2010</marker>
<rawString>I. Titov and J. Henderson. 2010. A latent variable model for generative dependency parsing. In Proceedings of the International Conference on Parsing Technology (IWPT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>A Klementiev</author>
</authors>
<title>Crosslingual induction of semantic roles.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9815" citStr="Titov and Klementiev, 2012" startWordPosition="1429" endWordPosition="1432"> et al., 2013) and supervised representation learning (Durrett et al., 2012). The language-independent features include bilingual word clusters (T¨ackstr¨om et al., 2012), language-independent projection features (Durrett et al., 2012), and automatically induced languageindependent POS tags (Zhang et al., 2012). Besides cross-lingual dependency parsing, in the literature cross-lingual representation learning methods have also demonstrated efficacy in different NLP applications such as cross language named entity recognition (T¨ackstr¨om et al., 2012) and cross language semantic role labeling (Titov and Klementiev, 2012). Our work shares similarity with these cross-lingual representation learning methods on inducing new language-independent features, but differs from them in that we learn cross-lingual word embeddings. Though multilingual word embeddings have been employed in the literature, they are developed for other NLP tasks such as cross-lingual sentiment analysis (Klementiev et al., 2012), and machine translation (Zou et al., 2013). Moreover, the method in (Klementiev et al., 2012) requires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns languag</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>I. Titov and A. Klementiev. 2012. Crosslingual induction of semantic roles. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Turian</author>
<author>L Ratinov</author>
<author>Y Bengio</author>
</authors>
<title>Word representations: a simple and general method for semisupervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="10981" citStr="Turian et al., 2010" startWordPosition="1604" endWordPosition="1607"> the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literature (Collobert and Weston, 2008; Collobert et al., 2011; Henderson, 2004; Socher et al., 2011; Titov and Henderson, 2010; Turian et al., 2010). Socher et al. (2011) applied recursive autoencoders to address sentencelevel sentiment classification problems. Collobert and Weston (2008) and Collobert et al. (2011) employed a deep learning framework for jointly multi-task learning and empirically evaluated it with four NLP tasks, including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. Henderson (2004) proposed discriminative training methods for learning a neural network statistical parser. Titov and Henderson (2010) extended the incremental sigmoid Belief networks (Titov and Henderson, 2007) to </context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>J. Turian, L. Ratinov, and Y. Bengio. 2010. Word representations: a simple and general method for semisupervised learning. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wang</author>
<author>C Manning</author>
</authors>
<title>Crosslingual pseudo-projected expectation regularization for weakly supervised learning.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics (TACL),</journal>
<pages>2--55</pages>
<contexts>
<context position="8135" citStr="Wang and Manning, 2014" startWordPosition="1196" endWordPosition="1199">constraints in learning dependency parsing models (Ganchev et al., 2009; Naseem et al., 2010; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; </context>
</contexts>
<marker>Wang, Manning, 2014</marker>
<rawString>M. Wang and C. Manning. 2014. Crosslingual pseudo-projected expectation regularization for weakly supervised learning. Transactions of the Association for Computational Linguistics (TACL), 2:55–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
</authors>
<title>Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies (NAACL).</booktitle>
<contexts>
<context position="6804" citStr="Yarowsky and Ngai, 2001" startWordPosition="997" endWordPosition="1000">by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim et al., 2010). Some work has also proposed to project the discrete dependency arc instances instead of treebank as the training set (Liu et al., 2013). Moreover, besides cross-lingual dependency parsing, cross-lingual annotation projection methods have also demonstrated success in various other sequence labeling tasks including POS tagging (Das and Petrov, 2011; Yarowsky and Ngai, 2001), relation extraction (Kim et al., 2012), named entity recognition (Kim et al., 2010; Kim and Lee, 2012), constituent syntax parsing (Jiang et al., 2011), and word sense disambiguation (Khapra et al., 2010). Multilingual model learning methods train cross-lingual dependency parsers with parameter constraints obtained from parallel data (Liu et al., 2013; Ganchev et al., 2009) or linguistic knowledges (Naseem et al., 2010; Naseem et al., 2012). Among these methods, some proposed to train a joint dependency parsing system with parameters shared across the dependency parsing models in individual </context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>D. Yarowsky and G. Ngai. 2001. Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora. In Proceedings of the Meeting of the North American Chapter of the Association for Computational Linguistics on Language Technologies (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>R Reichart</author>
<author>R Barzilay</author>
<author>A Globerson</author>
</authors>
<title>Learning to map into a universal pos tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="8754" citStr="Zhang et al., 2012" startWordPosition="1287" endWordPosition="1290">, syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang et al., 2012). A variety of auxiliary resources have been used to induce interlingual features, including bilingual lexicon (Durrett et al., 2012), and unlabeled parallel sentences (T¨ackstr¨om et al., 2013). Based on different learning mechanisms (whether or not using labeled data) for inducing language-independent features, cross-lingual representation learning methods can be categorized into unsupervised representation learning (T¨ackstr¨om et al., 2013) and supervised representation learning (Durrett et al., 2012). The language-independent features include bilingual word clusters (T¨ackstr¨om et al., 2</context>
</contexts>
<marker>Zhang, Reichart, Barzilay, Globerson, 2012</marker>
<rawString>Y. Zhang, R. Reichart, R. Barzilay, and A. Globerson. 2012. Learning to map into a universal pos tagset. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhao</author>
<author>Y Song</author>
<author>C Kit</author>
<author>G Zhou</author>
</authors>
<title>Cross language dependency parsing using a bilingual lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP).</booktitle>
<contexts>
<context position="1903" citStr="Zhao et al., 2009" startWordPosition="274" endWordPosition="277">d by the proposed approach, comparing to alternative comparison methods. 1 Introduction With the rapid development of linguistic resources and tools in multiple languages, it is very important to develop cross-lingual natural language processing (NLP) systems. Cross-lingual dependency parsing is the task of inferring dependency trees for observed sentences in a target language where there are few or no labeled training sentences by using a dependency parser trained on a large amount of sentences with annotated dependency trees in a source language (Durrett et al., 2012; McDonald et al., 2011; Zhao et al., 2009). Cross-lingual dependency parsing is popularly studied in natural language processing area as it can greatly reduce the expensive manual annotation effort in the target language by exploiting the dependency annotations from a source language (Durrett et al., 2012; McDonald et al., 2011; T¨ackstr¨om et al., 2012). One fundamental challenge of cross-lingual dependency parsing stems from the word-level representation divergence across languages. Since sentences in different languages are expressed using different vocabularies, if we train a dependency parser on the word-level features of sentenc</context>
<context position="5816" citStr="Zhao et al., 2009" startWordPosition="850" endWordPosition="853">dency parsing tasks. We then conclude the paper in Section 5. 2 Related Work Previous works developed in the literature have tackled cross-lingual dependency parsing by using cross-lingual annotation projection methods, multilingual model learning methods, and crosslingual representation learning methods. Cross-lingual annotation projection methods use parallel sentences to project the annotations from the source language side to the target language side and then train dependency parsers on the target data with projected annotations (Hwa et al., 2005; Liu et al., 2013; Smith and Eisner, 2009; Zhao et al., 2009). For cross-lingual annotation projection methods, both the word alignment training step and the annotation projection step can introduce errors or noise. Thus much work developed in the literature has focused on designing robust projection algorithms such as graph-based projection with label propagations (Das and Petrov, 2011), improving projection performance by using auxiliary resources such as Wikipedia metadata (Kim and Lee, 2012) or WordNet (Khapra et al., 2010), or boosting projection performance by heuristically modifying or correcting the projected annotations (Hwa et al., 2005; Kim e</context>
</contexts>
<marker>Zhao, Song, Kit, Zhou, 2009</marker>
<rawString>H. Zhao, Y. Song, C. Kit, and G. Zhou. 2009. Cross language dependency parsing using a bilingual lexicon. In Proceedings of the Joint Conference of the Annual Meeting of the ACL and the International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Zhuang</author>
<author>C Zong</author>
</authors>
<title>Joint inference for bilingual semantic role labeling.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="8224" citStr="Zhuang and Zong, 2010" startWordPosition="1209" endWordPosition="1212">0; Naseem et al., 2012). The linguistic constraints may either come from manually constructed universal dependency parsing rules (Naseem et al., 2010) or manually specified typological features (Naseem et al., 2012), or be learned from parallel sentences (Ganchev et al., 2009). Besides cross-lingual dependency parsing, multilingual model learning methods have also achieved good empirical results for other multilingual NLP tasks, including named entity recognition (Burkett et al., 2010; Che et al., 2013; Wang and Manning, 2014), syntactic parsing (Burkett et al., 2010), semantic role labeling (Zhuang and Zong, 2010; Kozhevnikov and Titov, 2012), and word sense disambiguation (Guo and Diab, 2010). Cross-lingual representation learning methods induce language-independent features to bridge the cross-lingual difference in the original wordlevel representation space and build connections across different languages. They train a dependency parser in the induced representation space by exploiting labeled data from the source language and apply it in the target language (Dur120 rett et al., 2012; T¨ackstr¨om et al., 2012; Zhang et al., 2012). A variety of auxiliary resources have been used to induce interlingu</context>
</contexts>
<marker>Zhuang, Zong, 2010</marker>
<rawString>T. Zhuang and C. Zong. 2010. Joint inference for bilingual semantic role labeling. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Zou</author>
<author>R Socher</author>
<author>D Cer</author>
<author>C Manning</author>
</authors>
<title>Bilingual word embeddings for phrase-based machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="10241" citStr="Zou et al., 2013" startWordPosition="1490" endWordPosition="1493">trated efficacy in different NLP applications such as cross language named entity recognition (T¨ackstr¨om et al., 2012) and cross language semantic role labeling (Titov and Klementiev, 2012). Our work shares similarity with these cross-lingual representation learning methods on inducing new language-independent features, but differs from them in that we learn cross-lingual word embeddings. Though multilingual word embeddings have been employed in the literature, they are developed for other NLP tasks such as cross-lingual sentiment analysis (Klementiev et al., 2012), and machine translation (Zou et al., 2013). Moreover, the method in (Klementiev et al., 2012) requires parallel sentences with observed word-level alignments, and the method in (Zou et al., 2013) first learns language-specific word embeddings in each language separately and then transforms representations from one language to another language with machine translation alignments, while we jointly learn crosslingual word embeddings in the two languages by only exploiting a small set of bilingual word pairs. From the perspective of applying deep networks in natural language processing systems, there are a number of works in the literatur</context>
</contexts>
<marker>Zou, Socher, Cer, Manning, 2013</marker>
<rawString>W. Zou, R. Socher, D. Cer, and C. Manning. 2013. Bilingual word embeddings for phrase-based machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>