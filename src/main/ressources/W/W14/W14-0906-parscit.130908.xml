<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005780">
<title confidence="0.998147">
From Speaker Identification to Affective Analysis:
A Multi-Step System for Analyzing Children’s Stories
</title>
<author confidence="0.982303">
Elias Iosif∗ and Taniya Mishra†
</author>
<affiliation confidence="0.963385">
∗ School of ECE, Technical University of Crete, Chania 73100, Greece
</affiliation>
<address confidence="0.571849">
† AT&amp;T Labs, 33 Thomas Street, New York, NY 10007, USA
</address>
<email confidence="0.996354">
iosife@telecom.tuc.gr, taniya@research.att.com
</email>
<sectionHeader confidence="0.995586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989523809524">
We propose a multi-step system for the
analysis of children’s stories that is in-
tended to be part of a larger text-to-speech-
based storytelling system. A hybrid ap-
proach is adopted, where pattern-based
and statistical methods are used along with
utilization of external knowledge sources.
This system performs the following story
analysis tasks: identification of charac-
ters in each story; attribution of quotes
to specific story characters; identification
of character age, gender and other salient
personality attributes; and finally, affective
analysis of the quoted material. The differ-
ent types of analyses were evaluated using
several datasets. For the quote attribution,
as well as for the gender and age estima-
tion, substantial improvement over base-
line was realized, whereas results for per-
sonality attribute estimation and valence
estimation are more modest.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999826836734694">
Children love listening to stories. Listening to
stories — read or narrated — has been shown
to be positively correlated with children’s linguis-
tic and intellectual development (Natsiopoulou et
al., 2006). Shared story reading with parents or
teachers helps children to learn about vocabulary,
syntax and phonology, and to develop narrative
comprehension and awareness of the concepts of
print, all of which are linked to developing reading
and writing skills (National Early Literacy Panel
2008). While acknowledging that the parental
role in storytelling is irreplaceable, we consider
text-to-speech (TTS) enabled storytelling systems
(Rusko et al., 2013; Zhang et al., 2003; Theune
et al., 2006) to be aligned with the class of child-
oriented applications that aim to aid learning.
For a TTS-based digital storytelling system to
successfully create an experience as engaging as
human storytelling, the underlying speech synthe-
sis system has to narrate the story in a “story-
telling speech style” (Theune et al., 2006), gen-
erate dialogs uttered by different characters using
synthetic voices appropriate for each character’s
gender, age and personality (Greene et al., 2012),
and express quotes demonstrating emotions such
as sadness, fear, happiness, anger and surprise
(Alm, 2008) with realistic expression (Murray and
Arnott, 2008). However, before any of the afore-
mentioned requirements — all related to speech
generation — can be met, the text of the story has
to be analyzed to identify which portions of the
text should be rendered by the narrator and which
by each of the characters in the story, who are the
different characters in the story, what is each char-
acter’s gender, age, or other salient personality at-
tributes that may influence the voice assigned to
that character, and what is the expressed affect in
each of the character quotes.
Each of these text analysis tasks has been ap-
proached in past work (as described in our Re-
lated Works section). However, there appears to
be no single story analysis system that performs
all four of these tasks, which can be pipelined with
one of the many currently available text-to-speech
systems to build a TTS-based storyteller system.
Without such a story analysis system, it will not be
possible to develop an engaging and lively digital
storyteller system, despite the prevalence of sev-
eral mature TTS systems.
</bodyText>
<page confidence="0.984205">
40
</page>
<note confidence="0.990799">
Proceedings of the 3rd Workshop on Computational Linguistics for Literature (CLfL) @ EACL 2014, pages 40–49,
Gothenburg, Sweden, April 27, 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99993564516129">
In this paper, we present a multi-step text analy-
sis system for analyzing children’s stories that per-
forms all four analysis tasks: (i) Character Identi-
fication, i.e., identifying the different characters in
the story, (ii) Quote Attribution, i.e., identifying
which portions of the text should be rendered by
the narrator versus by particular characters in the
story, (iii) Character Attribute Identification, i.e.,
identifying each character’s gender, age, or salient
personality attributes that may influence the voice
that the speech synthesis system assigns to each
character, and (iv) Affective Analysis, i.e., esti-
mating the affect of the character quotes.
This story analysis system was developed to
be part of a larger TTS-based storyteller system
aimed at children. As a result, the data used for
developing the computational models or rules in
each step of our system were obtained from chil-
dren’s stories. A majority of children’s stories
are short. They often contain multiple characters,
each with different personalities, genders, age,
ethnicities, etc., with some characters even be-
ing anthropomorphic, e.g., the singing candlestick
or the talking teapot. In addition, there are sev-
eral prototypical templates characterizing the main
characters in the story (Rusko et al., 2013). How-
ever, character development is limited in these sto-
ries due to the shorter length of text. Overall,
children’s stories can be regarded as a parsimo-
nious yet fertile framework for developing compu-
tational models for literature analysis in general.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999983710144928">
Elson and McKeown (2010) used rule-based and
statistical learning approaches to identify candi-
date characters and attribute each quote to the most
likely speaker. Two broad approaches for the iden-
tification of story characters were followed: (i)
named entity recognition, and (ii) identification
of character nominals, e.g., “her grandma”, using
syntactic patterns. A long list of heuristics for
character identification is proposed in (Mamede
and Chaleira, 2004). He et al. (2013) use a su-
pervised machine learning approach to address the
same problem, though many of their preliminary
steps and input features are similar to those used in
(Elson and McKeown, 2010). Our character iden-
tification and quote attribution is based on syntac-
tic and heuristic rules that is motivated by each of
these works.
There are two interesting sub-problems related
to quote attribution. First is the problem of iden-
tifying anaphoric speakers, i.e., in the utterance
“Hello”, he said, which character is referred to by
the pronoun he? This problem is addressed in (El-
son and McKeown, 2010) and (He et al., 2013) but
not in (Mamede and Chaleira, 2004). The second
problem is resolving utterance chains with implicit
speakers. Elson and McKeown (2010) describe
and address two basic types of utterance chains: (i)
one-character chains, and (ii) intertwined chains.
In these chains of utterances, the speaker is not
explicitly mentioned because the author relies on
the shared understanding with the reader that adja-
cent pieces of quoted speech are not independent
(Zhang et al., 2003; Elson and McKeown, 2010).
They are either a continuation of the same charac-
ter’s speech (one-character chains) or a dialogue
between the two characters (intertwined chains).
In (Zhang et al., 2003), the quote-identification
module detects whether a piece of quoted speech
is a new quote (NEW), spoken by a speaker dif-
ferent from the previous speaker, or a continuation
quote (CONT) spoken by the same speaker as that
of the previous quote. He et al. (2013) also iden-
tified similar chains of utterances and addressed
their attribution to characters using a model-based
approach. In this work, we address both sub-
problems, namely, anaphoric speaker and implicit
speaker identification.
Cabral et al. (2006) have shown that assign-
ing an appropriate voice for a character in a digi-
tal storyteller system is significant for understand-
ing a story, perceiving affective content, perceiv-
ing the voice as credible, and overall listener sat-
isfaction. Greene et al. (2012) have shown that
the appropriateness of the voice assigned to a syn-
thetic character is strongly related to knowing the
gender, age and other salient personality attributes
of the character. Given this, we have developed
rule-based, machine-learning-based and resource-
based approaches for estimation of character gen-
der, age and salient personality attributes. In con-
trast, the majority of past works on the analysis of
children stories for TTS-based storytelling is lim-
ited to the attribution of quotes to speakers, though
studies that focused on anaphoric speaker iden-
tification have also approached character gender
estimation such as (Elson and McKeown, 2010)
and (He et al., 2013). The utilization of available
resources containing associations between person
names and gender was followed in (Elson and
</bodyText>
<page confidence="0.998896">
41
</page>
<bodyText confidence="0.999793279069768">
McKeown, 2010). In (He et al., 2013), associ-
ations between characters and their gender were
performed using anaphora rules (Mitkov, 2002).
There is of course a significant body of work
from other research areas that are related to the
estimation of character attributes, similar to what
we have attempted in our work. Several shal-
low linguistic features were proposed in (Schler
et al., 2006) for gender identification, applied to
the identification of users in social media. Several
socio-linguistic features were proposed in (Rao et
al., 2010) for estimating the age and gender of
Twitter users. The identification of personality at-
tributes from text is often motivated by psycho-
logical models. In (Celli, 2012), a list of linguis-
tic features were used for the creation of character
models in terms of the the Big Five personality di-
mensions (Norman, 1963).
Analysis of text to estimate affect or sentiment
is a relatively recent research topic that has at-
tracted great interest, as reflected by a series of
shared evaluation tasks, e.g., analysis of news
headlines (Strapparava and Mihalcea, 2007) and
tweets (Nakov et al., 2013). Relevant applications
deal with numerous domains such as blogs (Balog
et al., 2006), news stories (Lloyd et al., 2005), and
product reviews (Hu and Liu, 2004). In (Turney
and Littman, 2002), the affective ratings of un-
known words were predicted using the affective
ratings for a small set of words (seeds) and the se-
mantic relatedness between the unknown and the
seed words. An example of sentence-level analy-
sis was proposed in (Malandrakis et al., 2013). In
(Alm et al., 2005) and (Alm, 2008), linguistic fea-
tures were used for affect analysis in fairy tales. In
our work, we employ a feature set similar to that
in (Alm et al., 2005). We deal with the prediction
of three basic affective labels which are adequate
for the intended application (i.e., storytelling sys-
tem), while in (Alm, 2008) more fine-grained pre-
dictions are considered.
The integration of various types of analysis con-
stitutes the distinguishing character of our work.
</bodyText>
<sectionHeader confidence="0.79369" genericHeader="method">
3 Overview of System Architecture
</sectionHeader>
<bodyText confidence="0.985324857142857">
The system consists of several sub-systems that
are linked in a pipeline. The input to the system
is simply the text of a story with no additional
annotation. The story analysis is performed se-
quentially, with each sub-system extracting spe-
cific information needed to perform the four anal-
ysis tasks laid out in this paper.
</bodyText>
<subsectionHeader confidence="0.998222">
3.1 Linguistic Preprocessing
</subsectionHeader>
<bodyText confidence="0.999991615384615">
The first step is linguistic pre-processing of the
stories. This includes (i) tokenization, (ii) sen-
tence splitting and identification of paragraph
boundaries, (iii) part-of-speech (POS) tagging,
(iv) lemmatization, (v) named entity recognition,
(vi) dependency parsing, and (vii) co-reference
analysis. These sub-tasks — except task (ii) —
were performed using the Stanford CoreNLP suite
of tools (CoreNLP, 2014). Sentence splitting and
identification of paragraph boundaries was per-
formed using a splitter developed by Piao (2014).
Linguistic information extracted by this analysis is
exploited by the subsequent parts of the pipeline.
</bodyText>
<subsectionHeader confidence="0.999762">
3.2 Identification of Story Characters
</subsectionHeader>
<bodyText confidence="0.999958970588235">
The second step is identifying candidate charac-
ters (i.e., entities) that appear in the stories under
analysis. A story character is not necessarily a
story speaker. A character may appear in the story
but may not have any quote associated with him
and hence, is not a speaker. Characters in chil-
dren’s stories can either be human or non-human
entities, i.e., animals and non-living objects, ex-
hibiting anthropomorphic traits. The interactions
among characters can either be human-to-human
or human-to-non-human interactions.
We used two approaches for identifying story
characters motivated by (Elson and McKeown,
2010): 1) named entity recognition was used for
identifying proper names, e.g., “Hansel”, 2) a
set of part-of-speech patterns was used for the
extraction of human and non-human characters
that were not represented by proper names, e.g.,
“wolf”. The used patterns are: 1) (DT|CD)
(NN|NNS), 2) DT JJ (NN|NNS), 3) NN POS
(NN|NNS), and 4) PRP$ JJ (NN|NNS).
These POS-based patterns are quite generic, al-
lowing for the creation of large sets of characters.
In order to restrict the characters, world knowl-
edge was incorporated through the use of Word-
Net (Fellbaum, 2005). A similar approach was
also followed in (Elson and McKeown, 2010). For
each candidate character the hierarchy of its hy-
pernyms was traversed up to the root. Regarding
polysemous characters the first two senses were
considered. A character was retained if any of its
hypernyms was found to fall into certain types of
WordNet concepts: person, animal, plant, artifact,
spiritual being, physical entity.
</bodyText>
<page confidence="0.995019">
42
</page>
<subsectionHeader confidence="0.8120025">
3.3 Quote Attribution &amp; Speaker
Identification
</subsectionHeader>
<bodyText confidence="0.999630888888889">
Here the goal is to attribute (or assign) each quote
to a specific story character from the set identified
in the previous step. The identification of quotes
in the story is based on a simple pattern-based ap-
proach: the quote boundaries are signified by the
respective symbols, e.g., “ and ”. The pattern is
applied at the sentence level.
The quotes are not modeled as NEW/CONT as
in (Zhang et al., 2003), however, we adopt a more
sophisticated approach for the quote attribution.
Three types of attribution are possible in our sys-
tem: 1) explicit mention of speakers, e.g., “Done!”
said Hans, merrily, 2) anaphoric mention of speak-
ers, e.g., “How happy am I!” cried he, 3) sequence
of quotes, e.g., “And where did you get the pig?”
... “I gave a horse for it.”. In the first type of attri-
bution, the speaker is explicitly mentioned in the
vicinity of the quote. This is also true for the sec-
ond type, however, a pronominal anaphora is used
to refer to the the speaker. The first two attribution
types are characterized by the presence of “within-
quote” (e.g., “Done!”) and “out-of-quote” (e.g.,
“said Hans, merrily.”) content. This is not the
case for the third attribution type for which only
“in-quote” content is available. We refer to such
quotes as “pure” quotes. Each attribution type is
detailed below.
Preliminary filtering of characters. Before
quote-attribution is performed, the list of story
characters is pruned by identifying the characters
that are “passively” associated with speech verbs
(SV). This is applied at the sentence level. Some
examples of speech verbs are: said, responds, sing,
etc. For instance, in “... Hans was told ... ”,
“Hans” is a passive character. The passive char-
acters were identified via the following relations
extracted by dependency parsing: nsubjpass
(passive nominal subject) and pobj (object of a
preposition). Given a sentence that includes one
or more quotes, the respective passive characters
were not considered as candidate speakers. Some
other criteria for pruning of list of characters to
identify candidate speakers are presented in Sec-
tion 4.2 (see the three schemes for Tasks 1-2).
Explicit mention of speakers. Several syntac-
tic patterns were applied to associate quotes with
explicit mention of speakers in their vicinity to
characters from the pruned list of story charac-
ters. These patterns were developed around SV.
In the example above, “Hans” is associated with
the quote “Done!” via the SV “said”. Variations
of the following basic patterns (Elson and McKe-
own, 2010) were used: 1) QT SV CH, 2) QT CH
SV, and 3) CH SV QT, where QT denotes a quote
boundary and CH stands for a story character. For
example, a variation of the first pattern is QT SV
the? CH, where ? stands for zero or one oc-
currence of “the”.
A limitation of the aforementioned patterns
is that they capture associations when the CH
and SV occur in close textual distance. As
a result, distant associations are missed, e.g.,
“Hans stood looking on for a while, and at last
said, “ You must ...””. In order to address
this distant association issue, we examined the
collapsed-ccprocessed-dependencies
output besides the basic-dependencies out-
put of the Stanford CoreNLP dependency engine
(de Marneffe and Manning, 2012). The former
captures more distant relations compared to
the latter. We specifically extract the character
reference CH either from the dependency relation
nsubj, which links a speech verb SV with a CH
that is the syntactic subject of a clause, or from the
dependency relation dobj, which links a SV with
a CH that is the direct object of the speech verb,
across a conjunct (e.g., and). A similar approach
was used in (He et al., 2013).
Anaphoric mention of speakers. The same
procedure was followed as in the case of the ex-
plicit mentions of speakers described above. The
difference is that CH included the following pro-
nouns: “he”, “she”, “they”, “himself”, “herself”,
and “themselves”. After associating a pronoun
with a quote, the quote was attributed to a story
character via co-reference resolution. This was
done using the co-reference analysis performed
by CoreNLP. If a pronominal anaphora was not
resolved by the CoreNLP analysis, the follow-
ing heuristic was adopted. The previous n para-
graphs1 were searched and the pronoun under in-
vestigation was mapped to the closest (in terms
of textual proximity) story character that had the
same gender as the pronoun (see Section 3.4.1 re-
garding gender estimation). During the paragraph
search, anaphoric mentions were also taken into
consideration followed by co-reference resolution.
Despite the above approaches, it is possible to
have non-attributed quotes. In such cases, the fol-
</bodyText>
<footnote confidence="0.991642">
1For the reported results n was set to 5.
</footnote>
<page confidence="0.999661">
43
</page>
<bodyText confidence="0.984618603773585">
lowing procedure is followed for those story sen-
tences that: (i) do not constitute “pure” quotes
(i.e., consist of “in-quote” and “out-of-quote” con-
tent), and (ii) include at least one “out-of-quote”
SV: 1) all the characters (as well as pronouns) that
occur within the “out-of-quote” content are aggre-
gated and serve as valid candidates for attribution,
2) if multiple characters and pronouns exist, then
they are mapped (if possible) via co-reference res-
olution in order to narrow down the list of attri-
bution candidates, and 3) the quote is attributed
to the nearest quote character (or pronoun). For
the computation of the textual distance both quote
boundaries (i.e., start and end) are considered. If
the quote is attributed to a pronoun that was not
mapped to any character, then co-reference reso-
lution is applied.
Sequence of “pure” quotes. Sentences that
are “pure” quotes (i.e., include “in-quote” con-
tent only) are not attributed to any story charac-
ter via the last two attribution methods. “Pure”
quotes are attributed as follows: The sentences
are parsed sequentially starting from the begin-
ning of the story. Each time a character is encoun-
tered within a sentence, it is pushed into a “bag-
of-characters”. This is done until a non-attributed
“pure” quote is found. At this point we assume
that the candidate speakers for the current (and
next) “pure” quote are included within the “bag-
of-characters”. This is based on the hypothesis
that the author “introduces” the speakers before
their utterances. The subsequent “pure” quotes are
examined in order to spot any included characters.
Such characters are regarded as “good” candidates
enabling the pruning of the list of candidate speak-
ers. The goal is to end up with exactly two candi-
date speakers for a back and forth dialogue. Then,
the initiating speaker is identified by taking into
account the order of names mentioned within the
quote. Then, the quote attribution is performed in
an alternating fashion. For example, consider a
sequence of four non-attributed “pure” quotes and
a bag of two2 candidate speakers, si and sj. If si
was identified as the initiating speaker, then the 1st
and the 3th quote are attributed to it, while the 2nd
and the 4th quote are attributed to sj. Finally, the
“bag-of-characters” is reset, and the same process
is repeated for the rest of the story.
Identification of speakers. The speakers for a
2If more than two candidates exist, then the system gives
ambiguous attributions, i.e., multiple speakers for one quote.
given story are identified by selecting those char-
acters that were attributed at least one quote.
</bodyText>
<subsectionHeader confidence="0.95752">
3.4 Gender, Age and Personality Attributes
</subsectionHeader>
<bodyText confidence="0.999931333333333">
The next three steps in our system involve estima-
tion of the (i) gender, (ii) age, and (iii) personality
attributes for the identified speakers.
</bodyText>
<subsubsectionHeader confidence="0.493681">
3.4.1 Gender Estimation
</subsubsectionHeader>
<bodyText confidence="0.999953131578947">
We used a hybrid approach for estimating the gen-
der of the story characters. This is applied to char-
acters (rather than only speakers) because the gen-
der information is exploited during the attribution
of quotes (see Section 3.3). The characterization
“hybrid” refers to the fusion of two different types
of information: (i) linguistic information extracted
from the story under analysis, and (ii) information
taken from external resources that do not depend
on the analyzed story. Regarding the story-specific
information, the associations between characters
and third person pronouns (identified via anaphora
resolution) were counted. The counts were used in
order to estimate the gender probability.
The story-independent resources that we used
are: (a) the U.S. Social Security Administration
baby name database (Security, 2014), in which
person names are linked with gender and (b) a
large name-gender association list developed us-
ing a corpus-based bootstrapping approach, which
even included the estimated gender for non-person
entities (Bergsma and Lin, 2006). For each entity
included in (b) a numerical estimate is provided
for each gender. As in the case of story-specific in-
formation, those estimates were utilized for com-
puting the gender probability. Using the above in-
formation the following procedure was followed
for each character: The external resource (a) was
used when the character name occurred in it. Oth-
erwise, the information from the external resource
(b) and the story-specific information was taken
into account. If the speaker was covered by both
types of information, the respective gender prob-
abilities were compared and the gender was esti-
mated to be the one corresponding to the high-
est probability. If the character was not covered
by the story-specific information, the external re-
source (b) was used.
</bodyText>
<subsectionHeader confidence="0.868565">
3.4.2 Age Estimation
</subsectionHeader>
<bodyText confidence="0.965304333333333">
We used a machine-learning based approach for
age estimation. The used features are presented in
Table 1, while they were extracted from speaker
</bodyText>
<page confidence="0.997836">
44
</page>
<bodyText confidence="0.75829325">
people use reflect their personality, and the latter
can be estimated by these linguistic features.
quotes, based on the assumption that speakers of
different ages use language differently. The
</bodyText>
<figure confidence="0.781362454545454">
No. Description
1 count of . , ;
2 count of ,
3 count of !
4 count of 1st person singular pronouns
5 count of negative particles
6 count of numbers
7 count of prepositions
8 count of pronouns
9 count of ?
10 count of tokens longer than 6 letters
11 count of 1st pers. (sing. &amp; plur.) pronouns
12 count of quote tokens
13 count of 1st person plural pronouns
14 count of 2nd person singular pronouns
15 count of quote positive words
16 count of quote negative words
17 count of nouns
18 count of verbs
19 count of adjectives
20 count of adverbs
21 up to 3-grams extracted from quote
</figure>
<tableCaption confidence="0.993397">
Table 1: Common feature set.
</tableCaption>
<bodyText confidence="0.9998840625">
development of this feature set was inspired by
(Celli, 2012) and (Alm et al., 2005). All fea-
tures were extracted from the lemmatized form of
quotes. Also, all feature counts (except Feature
21) were normalized by Feature 12. For com-
puting the counts of positive and negative words
(Feature 15 and 16) we used the General Inquirer
database (Stone et al., 1966). Feature 21 stands
for n-grams (up to 3-grams) extracted from the
speaker quotes. Two different schemes were fol-
lowed for extracting this feature: (i) using the
quote as-is, i.e., its lexical form, and (ii) using the
part-of-speech tags of quote. So, two slightly dif-
ferent feature sets were defined: 1) “lex”: No.1-20
+ lexical form for No.21, 2) “pos”: No.1-20 + POS
tags for No.21
</bodyText>
<subsectionHeader confidence="0.965617">
3.4.3 Estimation of Personality Attributes
</subsectionHeader>
<bodyText confidence="0.999985666666667">
A machine-learning based approach was also used
for personality attribute estimation. For estimat-
ing the personality attributes of story speakers, the
linguistic feature set (see Table 1) used in the task
for age estimation was used again. Again our ap-
proach was based on the assumption that words
</bodyText>
<subsectionHeader confidence="0.976051">
3.5 Affective Analysis
</subsectionHeader>
<bodyText confidence="0.999947">
The last step of our system is the estimation of
the affective content of stories. The analysis is
performed for each identified quote. The features
presented in Table 1 are extracted for each quote
and affect is estimated using a machine-learning
model, based on the assumption that such features
serve as cues for revealing the underlying affective
content (Alm et al., 2005; Alm, 2008).
</bodyText>
<sectionHeader confidence="0.997259" genericHeader="evaluation">
4 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.9998152">
Here we present the experimental evaluation of
our system in performing the following tasks: 1)
speaker-to-quote attribution, 2) gender estimation,
3) age estimation, 4) identification of personality
attributes, and 5) affective analysis of stories.
</bodyText>
<subsectionHeader confidence="0.97516">
4.1 Datasets Used
</subsectionHeader>
<bodyText confidence="0.9655575">
The datasets used for our experiments along with
the related tasks are presented in Table 2.
</bodyText>
<table confidence="0.9990275">
No. Task Type of dataset
1 Quote attribution STORIES
2 Gender estimation STORIES
3 Age estimation QUOTES(1,2)
4 Personality attrib. QUOTES(3,4)
5 Affective analysis STORY-AFFECT
</table>
<tableCaption confidence="0.999657">
Table 2: Experiment datasets and related tasks.
</tableCaption>
<bodyText confidence="0.999840866666667">
Tasks 1-2. For the first two tasks (quote-to-
speaker attribution, and gender estimation) we
used a dataset (STORIES) consisting of 17 chil-
dren stories selected from Project Gutenberg3.
This set of stories includes 98 unique speakers
with 554 quotes assigned to them. The average
number of sentences and quotes per story is 61.8
and 32.5, respectively. The average sentence and
quote length is 30.4 and 29.0 tokens, respectively.
Each speaker was attributed 5.7 quotes on aver-
age. Ground truth annotation, which involved as-
signing quotes to speakers and labeling gender,
was performed by one4 annotator. The follow-
ing ground truth labels were used to mark gender:
“male”, “female”, and “plural”.
</bodyText>
<footnote confidence="0.994107">
3www.telecom.tuc.gr/˜iosife/chst.html
4Due to the limited ambiguity of the task, the availability
of a single annotator was considered acceptable.
</footnote>
<page confidence="0.999297">
45
</page>
<bodyText confidence="0.999554764705883">
Task 3. Evaluation of the age estimation task was
performed with respect to two different (propri-
etary) datasets QUOTES1 and QUOTES2. These
datasets consisted of individual quotes assigned to
popular children’s story characters. The dataset
QUOTES1 consisted of 6361 quotes assigned to
69 unique speakers. The average quote length
equals 7.6 tokens, while each speaker was at-
tributed 141.4 quotes on average. The dataset
QUOTES2 consisted of 23605 quotes assigned to
262 unique speakers. The average quote length
equals 8.3 tokens, while each speaker was at-
tributed 142.6 quotes on average. For ground truth
annotation, four annotators were employed. The
annotators were asked to use the following age
labels: “child” (0–15 years old), “young adult”
(16–35 y.o.), “middle-aged” (36–55 y.o.), and “el-
derly” (56– y.o.). The age of each character was
inferred by the annotators either based on personal
knowledge of these stories or by consulting pub-
licly available sources online. The inter-annotator
agreement equals to 70%.
Task 4. To evaluate system performance on Task
4, two datasets QUOTES3 and QUOTES4, con-
sisting of individual quotes assigned to popular
children’s story characters, were used. The set
QUOTES3 consisted of 68 individual characters
and QUOTES4 consisted of 328 individual charac-
ters. The ground truth assignment, assigning each
character with personality attributes, was extracted
from a free, public collaborative wiki (Wiki,
2014). Since the wiki format allows people to add
or edit information, we considered the personality
attributes extracted from this wiki to be the aver-
age “crowd’s opinion” of these characters. Of the
open-ended list of attributes that were used to de-
scribe the characters, in this task we attempted to
extract the following salient personality attributes:
“beautiful”, “brave”, “cowardly”, “evil”, “feisty”,
“greedy”, “handsome”, “kind”, “loving”, “loyal”,
“motherly”, “optimistic”, “spunky”, “sweet”, and
“wise”. The pseudo-attribute “none” was used
when a character was not described with any of
those aforementioned attributes.
Task 5. An annotated dataset, referred to as
STORY-AFFECT in this paper, consisting of 176
stories was used. Each story sentence (regard-
less if quotes were included or not) was anno-
tated regarding primary emotions and mood us-
ing the following labels: “angry” (AN), “dis-
gusted” (DI), “fearful” (FE), “happy” (HA), “neu-
tral” (NE), “sad” (SA), “positive surprise” (SU+),
and “negative surprise” (SU−). Overall, two anno-
tators were employed, while each annotator pro-
vided two annotations: one for emotion and one
for mood. More details about this dataset are pro-
vided in (Alm, 2008).
Instead of using the aforementioned emo-
tions/moods as annotated, we adopted a 3-class
scheme for sentence affect (valence): “negative”,
“neutral”, and “positive”. In order to align the
existing annotations to our three-class scheme the
following mapping5 was adopted: (i) AN, DI, FE,
SA were mapped to negative affect, (ii) NE was
mapped to neutral affect, and (iii) HA was mapped
to positive affect. Given the proposed mapping,
we retained those sentences (in total 11018) that
exhibited at least 75% annotation agreement.
</bodyText>
<subsectionHeader confidence="0.994947">
4.2 Evaluation Results
</subsectionHeader>
<bodyText confidence="0.99980025">
The evaluation results for the aforementioned
tasks are presented below.
Tasks 1-2. The quote-to-speaker attribution was
evaluated in terms of precision (ATp), while the
estimation of speakers’ gender was evaluated in
terms of precision (Gp) and recall (Gr). Note that
Gp includes both types of errors: (i) erroneous age
estimation, and (ii) estimations for story charac-
ters that are not true speakers. In order to exclude
the second type of error, the precision of gender
estimation was also computed for only the true
story speaker identified by the system (G′p). For
</bodyText>
<table confidence="0.99542175">
Speaker filter. ATp Gp Gr G′p
Baseline 0.010 0.333
10 stories (subset of dataset)
Scheme 1 0.833 0.780 0.672 0.929
Scheme 2 0.868 0.710 0.759 0.917
Scheme 3 0.835 0.710 0.759 0.917
17 stories (full dataset)
Scheme 2 0.845 0.688 0.733 0.892
</table>
<tableCaption confidence="0.999875">
Table 3: Quote attribution and gender estimation.
</tableCaption>
<bodyText confidence="0.998858428571428">
a subset of the STORIES dataset that included 10
stories, the following schemes were used for filter-
ing of candidate speakers: (i) Scheme 1: all speak-
ers linked with speech verbs, (ii) Scheme 2: speak-
ers, who are persons or animals or spiritual entities
according to their first WordNet sense, linked with
speech verbs , and (iii) Scheme 3: as Scheme 2,
</bodyText>
<footnote confidence="0.762801">
5SU+/− were excluded for simplicity.
</footnote>
<page confidence="0.999034">
46
</page>
<bodyText confidence="0.9752654375">
but the first two WordNet senses were considered.
For the full STORIES dataset (17 stories) Scheme
2 was used. The results are presented in Table 3 in-
cluding the weighted averages of precision and re-
call. Using random guesses, the baseline precision
is 0.010 and 0.333 for quote-to-speaker attribution
and gender estimation, respectively. For the subset
of 10 stories, the highest speaker-to-quote attribu-
tion attribution is obtained by Scheme 2. When
this scheme is applied over the entire dataset, sub-
stantially high6 precision (0.892) is achieved in the
estimation of gender of true story speakers.
Task 3. For the estimation of age using quote-
based features, a boosting approach was fol-
lowed using BoosTexter (Schapire and Singer,
2000). For evaluation, 10-fold cross valida-
</bodyText>
<table confidence="0.997217333333333">
Dataset Relaxed Exact
lex pos lex pos
Baseline 0.625 0.250
QUOTES1 0.869 0.883 0.445 0.373
QUOTES2 0.877 0.831 0.450 0.435
BOTH 0.886 0.858 0.464 0.383
</table>
<tableCaption confidence="0.999811">
Table 4: Age estimation: average accuracy.
</tableCaption>
<bodyText confidence="0.99857675">
tion (10FCV) was used for the QUOTES1 and
QUOTES2 datasets for the “lex” and “pos” fea-
ture sets. The results are reported in Table 4 in
terms of average classification accuracy. In this
table, BOTH refers to the datasets QUOTES1 and
QUOTES2 combined together. The evaluation
was performed according to two schemes: (i) “re-
laxed match”: the prediction is considered as cor-
rect even if it deviates one class from the true one,
e.g., “child” and “middle-aged” considered as cor-
rect for “young adult”, and (ii) “exact match”: the
prediction should exactly match the true label. The
relaxed scheme was motivated by the nature of in-
tended application (storytelling system) for which
such errors are tolerable. For the exact match
scheme, the obtained performance is higher7 than
the baseline (random guess) that equals to 0.250.
The accuracy for the relaxed scheme is quite high,
i.e., greater than 0.85 for almost all cases. On aver-
age, the “lex” feature set appears to yield slightly
higher performance than the “pos” set.
Task 4. The personality attributes were estimated
using BoosTexter fed with the “lex” feature set.
10FCV was used for evaluation, while the aver-
</bodyText>
<footnote confidence="0.963229">
6Statistically significant at 95% lev. (t-test wrt baseline).
7Statistically significant at 95% lev. (t-test wrt baseline).
</footnote>
<bodyText confidence="0.9998262">
age accuracy was computed by taking into account
the top five attributes predicted for each charac-
ter. The baseline accuracy equals 0.31 given that
random guesses are used. Moderate performance
was achieved for the QUOTES3 and QUOTES4
datasets, 0.426 and 0.411, respectively.
Task 5. The affect of story sentences was esti-
mated via BoosTexter using the “lex” and “pos”
feature sets. As in the previous two tasks 10FCV
was applied for evaluation purposes. Using ran-
dom guesses, the baseline accuracy is 0.33. The
average accuracy for the “lex” and “pos” feature
sets is 0.838 and 0.658, respectively8. It is clear
that the use of the “lex” set outperforms the results
yielded by the “pos” set.
</bodyText>
<sectionHeader confidence="0.998745" genericHeader="conclusions">
5 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999988290322581">
In this paper, we described the development of a
multi-step system aimed for story analysis with
particular emphasis on analyzing children’s sto-
ries. The core idea was the integration of sev-
eral systems into a single pipelined system. The
proposed methodology has a strong hybrid char-
acter in that it employs different approaches that
range from pattern-based to machine learning-
based to the incorporation of external knowledge
resources. Going beyond the usual task of works
in this genre, i.e., speaker-to-quote attribution, the
proposed system also supports the estimation of
speaker-oriented attributes and affect estimation.
Very promising results were obtained for quote at-
tribution and estimation of speaker gender, as well
as for age assuming an application-depended error
tolerance. The estimation of personality attributes
and the affective analysis of story sentences re-
main open research problems, while the results are
more modest especially for the former task.
In the next phase of our work, we hope to im-
prove and generalize each individual component
of the proposed system. The most challenging as-
pects of the system, dealing with personality at-
tributes and affective analysis, will be further in-
vestigated. Towards this task, psychological mod-
els, e.g., the Big Five model, can provide useful
theoretical and empirical findings. Last but not
least, the proposed system will be evaluated within
the framework of a digital storytelling application
including metrics related with user experience.
</bodyText>
<footnote confidence="0.757717">
8Statistically significant at 90% lev. (t-test wrt baseline).
</footnote>
<page confidence="0.999268">
47
</page>
<sectionHeader confidence="0.990284" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999830771428571">
C. O. Alm, D. Roth, and R. Sproat. 2005. Emotions
from text: Machine learning for text-based emotion
prediction. In Proc. of Conference on Human Lan-
guage Technology and Empirical Methods in Natu-
ral Language Processing, pages 579–586.
C. O. Alm. 2008. Affect in Text and Speech. Ph.D.
thesis, University of Illinois at Urbana-Champaign.
K. Balog, G. Mishne, and M. de Rijke. 2006. Why
are they excited? identifying and explaining spikes
in blog mood levels. In Proc. 11th Conference of the
European Chapter of the Association for Computa-
tional Linguistics, pages 207–210.
S. Bergsma and D. Lin. 2006. Bootstrapping path-
based pronoun resolution. In Proc. of Conference
on Computational Lingustics /Association for Com-
putational Linguistics, pages 33–40.
J. Cabral, L. Oliveira, G. Raimundo, and A. Paiva.
2006. What voice do we expect from a synthetic
character? In Proceedings of SPECOM, pages 536–
539.
F. Celli. 2012. Unsupervised personality recognition
for social network sites. In Proc. of Sixth Interna-
tional Conference on Digital Society.
CoreNLP. 2014. Stanford CoreNLP tool.
http://nlp.stanford.edu/software/
corenlp.shtml.
M.-C. de Marneffe and C. D. Manning. 2012. Stanford
typed dependencies manual.
D. K. Elson and K. R. McKeown. 2010. Automatic
attribution of quoted speech in literary narrative. In
Proc. of Twenty-Fourth AAAI Conference on Artifi-
cial Intelligence.
C. Fellbaum. 2005. Wordnet and wordnets. In
K. Brown et al., editor, Encyclopedia of Language
and Linguistics, pages 665–670. Oxford: Elsevier.
E. Greene, T. Mishra, P. Haffner, and A. Conkie. 2012.
Predicting character-appropriate voices for a TTS-
based storyteller system. In Proc. ofInterspeech.
H. He, D. Barbosa, and G. Kondrak. 2013. Identifica-
tion of speakers in novels. In Proc. of 51st Annual
Meeting of the Association for Computational Lin-
guistics, pages 1312–1320.
M. Hu and B. Liu. 2004. Mining and summarizing
customer reviews. In Proc. of Conference on Knowl-
edge Discovery and Data Mining, KDD ’04, pages
168–177.
L. Lloyd, D. Kechagias, and S. Skiena. 2005. Lydia:
A system for large-scale news analysis. In Proc.
SPIRE, number 3772 in Lecture Notes in Computer
Science, pages 161–166.
N. Malandrakis, A. Potamianos, E. Iosif, and
S. Narayanan. 2013. Distributional semantic
models for affective text analysis. IEEE Transac-
tions on Audio, Speech, and Language Processing,
21(11):2379–2392.
N. Mamede and P. Chaleira. 2004. Character identifi-
cation in children stories. In J. Vicedo, P. Martnez-
Barco, R. Muoz, and M. Saiz Noeda, editors, Ad-
vances in Natural Language Processing, volume
3230 of Lecture Notes in Computer Science, pages
82–90. Springer Berlin Heidelberg.
R. Mitkov. 2002. Anaphora Resolution. Longman.
I. R. Murray and J. L. Arnott. 2008. Applying an anal-
ysis of acted vocal emotions to improve the simu-
lation of synthetic speech. Computer Speech and
Language, 22(2):107–129.
P. Nakov, S. Rosenthal, Z. Kozareva, V. Stoyanov,
A. Ritter, and T. Wilson. 2013. Semeval 2013 task
2: Sentiment analysis in twitter. In Proc. of Second
Joint Conference on Lexical and Computational Se-
mantics (*SEM), Seventh International Workshop on
Semantic Evaluation, pages 312–320.
T. Natsiopoulou, M. Souliotis, and A. G. Kyridis.
2006. Narrating and reading folktales and pic-
ture books: storytelling techniques and approaches
with preschool children. Early Childhood Re-
search and Practice, 8(1). Retrieved on Jan 13th,
2014 from http://ecrp.uiuc.edu/v8n1/
natsiopoulou.html.
T. W. Norman. 1963. Toward an adequate taxonomy of
personality attributes: Replicated factor structure in
peer nomination personality rating. Journal of Ab-
normal and Social Psychology, 66:574–583.
S. Piao. 2014. Sentence splitting pro-
gram. http://text0.mib.man.ac.uk:
8080/scottpiao/sent_detector.
D. Rao, D. Yarowsky, A. Shreevats, and M. Gupta.
2010. Classifying latent user attributes in twitter. In
Proc. of the 2nd International Workshop on Search
and Mining User-generated Contents, pages 37–44.
M. Rusko, M. Trnka, S. Darjaa, and J. Hamar. 2013.
The dramatic piece reader for the blind and visu-
ally impaired. In Proc. of 4th Workshop on Speech
and Language Processing for Assistive Technolo-
gies, pages 83–91.
R. E. Schapire and Y. Singer. 2000. Boostexter: A
boosting-based system for text categorization. Ma-
chine. Learning, 39(2-3):135–168.
J. Schler, M. Koppel, S. Argamon, and J. W. Pen-
nebaker. 2006. Effects of age and gender on blog-
ging. In Proc. ofAAAI Spring Symposium: Compu-
tational Approaches to Analyzing Weblogs.
Social Security. 2014. U.S. social security adminis-
tration baby name database. http://www.ssa.
gov/OACT/babynames/limits.html.
</reference>
<page confidence="0.983661">
48
</page>
<reference confidence="0.998024210526316">
P. J. Stone, D. C. Dunphy, M. S. Smith, and D. M.
Ogilvie. 1966. The General Inquirer: A Computer
Approach to Content Analysis. MIT Press.
C. Strapparava and R. Mihalcea. 2007. Semeval 2007
task 14: Affective text. In Proc. SemEval, pages 70–
74.
M. Theune, K. Meijs, and D. Heylen. 2006. Gener-
ating expressive speech for storytelling applications.
In IEEE Transactions on Audio, Speech and Lan-
guage Processing, pages 1137–1144.
P. Turney and M. L. Littman. 2002. Unsupervised
learning of semantic orientation from a hundred-
billion-word corpus (technical report erc-1094).
Disney Wiki. 2014. Description of Disney char-
acters. http://disney.wikia.com/wiki/
Category:Disney_characters#.
J. Y. Zhang, A. W. Black, and R. Sproat. 2003. Iden-
tifying speakers in children’s stories for speech syn-
thesis. InProc. ofInterspeech.
</reference>
<page confidence="0.999545">
49
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.469632">
<title confidence="0.9928">From Speaker Identification to Affective A Multi-Step System for Analyzing Children’s Stories</title>
<author confidence="0.865378">Taniya</author>
<affiliation confidence="0.492985">of ECE, Technical University of Crete, Chania 73100,</affiliation>
<address confidence="0.991846">Labs, 33 Thomas Street, New York, NY 10007,</address>
<email confidence="0.998156">iosife@telecom.tuc.gr,taniya@research.att.com</email>
<abstract confidence="0.999612409090909">We propose a multi-step system for the analysis of children’s stories that is intended to be part of a larger text-to-speechbased storytelling system. A hybrid approach is adopted, where pattern-based and statistical methods are used along with utilization of external knowledge sources. This system performs the following story analysis tasks: identification of characters in each story; attribution of quotes to specific story characters; identification of character age, gender and other salient personality attributes; and finally, affective analysis of the quoted material. The different types of analyses were evaluated using several datasets. For the quote attribution, as well as for the gender and age estimation, substantial improvement over baseline was realized, whereas results for personality attribute estimation and valence estimation are more modest.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C O Alm</author>
<author>D Roth</author>
<author>R Sproat</author>
</authors>
<title>Emotions from text: Machine learning for text-based emotion prediction.</title>
<date>2005</date>
<booktitle>In Proc. of Conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>579--586</pages>
<contexts>
<context position="10279" citStr="Alm et al., 2005" startWordPosition="1602" endWordPosition="1605">by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate for the intended application (i.e., storytelling system), while in (Alm, 2008) more fine-grained predictions are considered. The integration of various types of analysis constitutes the distinguishing character of our work. 3 Overview of System Architecture The system consists of several sub-systems that are linked in a pipeline. The input to the system is si</context>
<context position="23892" citStr="Alm et al., 2005" startWordPosition="3812" endWordPosition="3815">son singular pronouns 5 count of negative particles 6 count of numbers 7 count of prepositions 8 count of pronouns 9 count of ? 10 count of tokens longer than 6 letters 11 count of 1st pers. (sing. &amp; plur.) pronouns 12 count of quote tokens 13 count of 1st person plural pronouns 14 count of 2nd person singular pronouns 15 count of quote positive words 16 count of quote negative words 17 count of nouns 18 count of verbs 19 count of adjectives 20 count of adverbs 21 up to 3-grams extracted from quote Table 1: Common feature set. development of this feature set was inspired by (Celli, 2012) and (Alm et al., 2005). All features were extracted from the lemmatized form of quotes. Also, all feature counts (except Feature 21) were normalized by Feature 12. For computing the counts of positive and negative words (Feature 15 and 16) we used the General Inquirer database (Stone et al., 1966). Feature 21 stands for n-grams (up to 3-grams) extracted from the speaker quotes. Two different schemes were followed for extracting this feature: (i) using the quote as-is, i.e., its lexical form, and (ii) using the part-of-speech tags of quote. So, two slightly different feature sets were defined: 1) “lex”: No.1-20 + le</context>
<context position="25293" citStr="Alm et al., 2005" startWordPosition="4042" endWordPosition="4045">ion. For estimating the personality attributes of story speakers, the linguistic feature set (see Table 1) used in the task for age estimation was used again. Again our approach was based on the assumption that words 3.5 Affective Analysis The last step of our system is the estimation of the affective content of stories. The analysis is performed for each identified quote. The features presented in Table 1 are extracted for each quote and affect is estimated using a machine-learning model, based on the assumption that such features serve as cues for revealing the underlying affective content (Alm et al., 2005; Alm, 2008). 4 Experiments and Evaluation Here we present the experimental evaluation of our system in performing the following tasks: 1) speaker-to-quote attribution, 2) gender estimation, 3) age estimation, 4) identification of personality attributes, and 5) affective analysis of stories. 4.1 Datasets Used The datasets used for our experiments along with the related tasks are presented in Table 2. No. Task Type of dataset 1 Quote attribution STORIES 2 Gender estimation STORIES 3 Age estimation QUOTES(1,2) 4 Personality attrib. QUOTES(3,4) 5 Affective analysis STORY-AFFECT Table 2: Experimen</context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>C. O. Alm, D. Roth, and R. Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction. In Proc. of Conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 579–586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C O Alm</author>
</authors>
<title>Affect in Text and Speech.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Illinois at Urbana-Champaign.</institution>
<contexts>
<context position="2481" citStr="Alm, 2008" startWordPosition="366" endWordPosition="367">2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, anger and surprise (Alm, 2008) with realistic expression (Murray and Arnott, 2008). However, before any of the aforementioned requirements — all related to speech generation — can be met, the text of the story has to be analyzed to identify which portions of the text should be rendered by the narrator and which by each of the characters in the story, who are the different characters in the story, what is each character’s gender, age, or other salient personality attributes that may influence the voice assigned to that character, and what is the expressed affect in each of the character quotes. Each of these text analysis t</context>
<context position="10295" citStr="Alm, 2008" startWordPosition="1607" endWordPosition="1608">valuation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate for the intended application (i.e., storytelling system), while in (Alm, 2008) more fine-grained predictions are considered. The integration of various types of analysis constitutes the distinguishing character of our work. 3 Overview of System Architecture The system consists of several sub-systems that are linked in a pipeline. The input to the system is simply the text of</context>
<context position="25305" citStr="Alm, 2008" startWordPosition="4046" endWordPosition="4047">g the personality attributes of story speakers, the linguistic feature set (see Table 1) used in the task for age estimation was used again. Again our approach was based on the assumption that words 3.5 Affective Analysis The last step of our system is the estimation of the affective content of stories. The analysis is performed for each identified quote. The features presented in Table 1 are extracted for each quote and affect is estimated using a machine-learning model, based on the assumption that such features serve as cues for revealing the underlying affective content (Alm et al., 2005; Alm, 2008). 4 Experiments and Evaluation Here we present the experimental evaluation of our system in performing the following tasks: 1) speaker-to-quote attribution, 2) gender estimation, 3) age estimation, 4) identification of personality attributes, and 5) affective analysis of stories. 4.1 Datasets Used The datasets used for our experiments along with the related tasks are presented in Table 2. No. Task Type of dataset 1 Quote attribution STORIES 2 Gender estimation STORIES 3 Age estimation QUOTES(1,2) 4 Personality attrib. QUOTES(3,4) 5 Affective analysis STORY-AFFECT Table 2: Experiment datasets a</context>
<context position="29426" citStr="Alm, 2008" startWordPosition="4667" endWordPosition="4668">hose aforementioned attributes. Task 5. An annotated dataset, referred to as STORY-AFFECT in this paper, consisting of 176 stories was used. Each story sentence (regardless if quotes were included or not) was annotated regarding primary emotions and mood using the following labels: “angry” (AN), “disgusted” (DI), “fearful” (FE), “happy” (HA), “neutral” (NE), “sad” (SA), “positive surprise” (SU+), and “negative surprise” (SU−). Overall, two annotators were employed, while each annotator provided two annotations: one for emotion and one for mood. More details about this dataset are provided in (Alm, 2008). Instead of using the aforementioned emotions/moods as annotated, we adopted a 3-class scheme for sentence affect (valence): “negative”, “neutral”, and “positive”. In order to align the existing annotations to our three-class scheme the following mapping5 was adopted: (i) AN, DI, FE, SA were mapped to negative affect, (ii) NE was mapped to neutral affect, and (iii) HA was mapped to positive affect. Given the proposed mapping, we retained those sentences (in total 11018) that exhibited at least 75% annotation agreement. 4.2 Evaluation Results The evaluation results for the aforementioned tasks</context>
</contexts>
<marker>Alm, 2008</marker>
<rawString>C. O. Alm. 2008. Affect in Text and Speech. Ph.D. thesis, University of Illinois at Urbana-Champaign.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Balog</author>
<author>G Mishne</author>
<author>M de Rijke</author>
</authors>
<title>Why are they excited? identifying and explaining spikes in blog mood levels.</title>
<date>2006</date>
<booktitle>In Proc. 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>207--210</pages>
<marker>Balog, Mishne, de Rijke, 2006</marker>
<rawString>K. Balog, G. Mishne, and M. de Rijke. 2006. Why are they excited? identifying and explaining spikes in blog mood levels. In Proc. 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 207–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>D Lin</author>
</authors>
<title>Bootstrapping pathbased pronoun resolution.</title>
<date>2006</date>
<booktitle>In Proc. of Conference on Computational Lingustics /Association for Computational Linguistics,</booktitle>
<pages>33--40</pages>
<contexts>
<context position="22064" citStr="Bergsma and Lin, 2006" startWordPosition="3496" endWordPosition="3499">do not depend on the analyzed story. Regarding the story-specific information, the associations between characters and third person pronouns (identified via anaphora resolution) were counted. The counts were used in order to estimate the gender probability. The story-independent resources that we used are: (a) the U.S. Social Security Administration baby name database (Security, 2014), in which person names are linked with gender and (b) a large name-gender association list developed using a corpus-based bootstrapping approach, which even included the estimated gender for non-person entities (Bergsma and Lin, 2006). For each entity included in (b) a numerical estimate is provided for each gender. As in the case of story-specific information, those estimates were utilized for computing the gender probability. Using the above information the following procedure was followed for each character: The external resource (a) was used when the character name occurred in it. Otherwise, the information from the external resource (b) and the story-specific information was taken into account. If the speaker was covered by both types of information, the respective gender probabilities were compared and the gender was</context>
</contexts>
<marker>Bergsma, Lin, 2006</marker>
<rawString>S. Bergsma and D. Lin. 2006. Bootstrapping pathbased pronoun resolution. In Proc. of Conference on Computational Lingustics /Association for Computational Linguistics, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cabral</author>
<author>L Oliveira</author>
<author>G Raimundo</author>
<author>A Paiva</author>
</authors>
<title>What voice do we expect from a synthetic character?</title>
<date>2006</date>
<booktitle>In Proceedings of SPECOM,</booktitle>
<pages>536--539</pages>
<contexts>
<context position="7599" citStr="Cabral et al. (2006)" startWordPosition="1173" endWordPosition="1176">ech (one-character chains) or a dialogue between the two characters (intertwined chains). In (Zhang et al., 2003), the quote-identification module detects whether a piece of quoted speech is a new quote (NEW), spoken by a speaker different from the previous speaker, or a continuation quote (CONT) spoken by the same speaker as that of the previous quote. He et al. (2013) also identified similar chains of utterances and addressed their attribution to characters using a model-based approach. In this work, we address both subproblems, namely, anaphoric speaker and implicit speaker identification. Cabral et al. (2006) have shown that assigning an appropriate voice for a character in a digital storyteller system is significant for understanding a story, perceiving affective content, perceiving the voice as credible, and overall listener satisfaction. Greene et al. (2012) have shown that the appropriateness of the voice assigned to a synthetic character is strongly related to knowing the gender, age and other salient personality attributes of the character. Given this, we have developed rule-based, machine-learning-based and resourcebased approaches for estimation of character gender, age and salient persona</context>
</contexts>
<marker>Cabral, Oliveira, Raimundo, Paiva, 2006</marker>
<rawString>J. Cabral, L. Oliveira, G. Raimundo, and A. Paiva. 2006. What voice do we expect from a synthetic character? In Proceedings of SPECOM, pages 536– 539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Celli</author>
</authors>
<title>Unsupervised personality recognition for social network sites.</title>
<date>2012</date>
<booktitle>In Proc. of Sixth International Conference on Digital Society.</booktitle>
<contexts>
<context position="9380" citStr="Celli, 2012" startWordPosition="1453" endWordPosition="1454"> using anaphora rules (Mitkov, 2002). There is of course a significant body of work from other research areas that are related to the estimation of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification of users in social media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Litt</context>
<context position="23869" citStr="Celli, 2012" startWordPosition="3809" endWordPosition="3810">4 count of 1st person singular pronouns 5 count of negative particles 6 count of numbers 7 count of prepositions 8 count of pronouns 9 count of ? 10 count of tokens longer than 6 letters 11 count of 1st pers. (sing. &amp; plur.) pronouns 12 count of quote tokens 13 count of 1st person plural pronouns 14 count of 2nd person singular pronouns 15 count of quote positive words 16 count of quote negative words 17 count of nouns 18 count of verbs 19 count of adjectives 20 count of adverbs 21 up to 3-grams extracted from quote Table 1: Common feature set. development of this feature set was inspired by (Celli, 2012) and (Alm et al., 2005). All features were extracted from the lemmatized form of quotes. Also, all feature counts (except Feature 21) were normalized by Feature 12. For computing the counts of positive and negative words (Feature 15 and 16) we used the General Inquirer database (Stone et al., 1966). Feature 21 stands for n-grams (up to 3-grams) extracted from the speaker quotes. Two different schemes were followed for extracting this feature: (i) using the quote as-is, i.e., its lexical form, and (ii) using the part-of-speech tags of quote. So, two slightly different feature sets were defined:</context>
</contexts>
<marker>Celli, 2012</marker>
<rawString>F. Celli. 2012. Unsupervised personality recognition for social network sites. In Proc. of Sixth International Conference on Digital Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CoreNLP</author>
</authors>
<title>Stanford CoreNLP tool.</title>
<date>2014</date>
<note>http://nlp.stanford.edu/software/ corenlp.shtml.</note>
<contexts>
<context position="11542" citStr="CoreNLP, 2014" startWordPosition="1800" endWordPosition="1801">ation. The story analysis is performed sequentially, with each sub-system extracting specific information needed to perform the four analysis tasks laid out in this paper. 3.1 Linguistic Preprocessing The first step is linguistic pre-processing of the stories. This includes (i) tokenization, (ii) sentence splitting and identification of paragraph boundaries, (iii) part-of-speech (POS) tagging, (iv) lemmatization, (v) named entity recognition, (vi) dependency parsing, and (vii) co-reference analysis. These sub-tasks — except task (ii) — were performed using the Stanford CoreNLP suite of tools (CoreNLP, 2014). Sentence splitting and identification of paragraph boundaries was performed using a splitter developed by Piao (2014). Linguistic information extracted by this analysis is exploited by the subsequent parts of the pipeline. 3.2 Identification of Story Characters The second step is identifying candidate characters (i.e., entities) that appear in the stories under analysis. A story character is not necessarily a story speaker. A character may appear in the story but may not have any quote associated with him and hence, is not a speaker. Characters in children’s stories can either be human or no</context>
</contexts>
<marker>CoreNLP, 2014</marker>
<rawString>CoreNLP. 2014. Stanford CoreNLP tool. http://nlp.stanford.edu/software/ corenlp.shtml.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C de Marneffe</author>
<author>C D Manning</author>
</authors>
<date>2012</date>
<note>Stanford typed dependencies manual.</note>
<marker>de Marneffe, Manning, 2012</marker>
<rawString>M.-C. de Marneffe and C. D. Manning. 2012. Stanford typed dependencies manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Elson</author>
<author>K R McKeown</author>
</authors>
<title>Automatic attribution of quoted speech in literary narrative.</title>
<date>2010</date>
<booktitle>In Proc. of Twenty-Fourth AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="5352" citStr="Elson and McKeown (2010)" startWordPosition="818" endWordPosition="821"> They often contain multiple characters, each with different personalities, genders, age, ethnicities, etc., with some characters even being anthropomorphic, e.g., the singing candlestick or the talking teapot. In addition, there are several prototypical templates characterizing the main characters in the story (Rusko et al., 2013). However, character development is limited in these stories due to the shorter length of text. Overall, children’s stories can be regarded as a parsimonious yet fertile framework for developing computational models for literature analysis in general. 2 Related Work Elson and McKeown (2010) used rule-based and statistical learning approaches to identify candidate characters and attribute each quote to the most likely speaker. Two broad approaches for the identification of story characters were followed: (i) named entity recognition, and (ii) identification of character nominals, e.g., “her grandma”, using syntactic patterns. A long list of heuristics for character identification is proposed in (Mamede and Chaleira, 2004). He et al. (2013) use a supervised machine learning approach to address the same problem, though many of their preliminary steps and input features are similar </context>
<context position="6919" citStr="Elson and McKeown, 2010" startWordPosition="1065" endWordPosition="1068">, which character is referred to by the pronoun he? This problem is addressed in (Elson and McKeown, 2010) and (He et al., 2013) but not in (Mamede and Chaleira, 2004). The second problem is resolving utterance chains with implicit speakers. Elson and McKeown (2010) describe and address two basic types of utterance chains: (i) one-character chains, and (ii) intertwined chains. In these chains of utterances, the speaker is not explicitly mentioned because the author relies on the shared understanding with the reader that adjacent pieces of quoted speech are not independent (Zhang et al., 2003; Elson and McKeown, 2010). They are either a continuation of the same character’s speech (one-character chains) or a dialogue between the two characters (intertwined chains). In (Zhang et al., 2003), the quote-identification module detects whether a piece of quoted speech is a new quote (NEW), spoken by a speaker different from the previous speaker, or a continuation quote (CONT) spoken by the same speaker as that of the previous quote. He et al. (2013) also identified similar chains of utterances and addressed their attribution to characters using a model-based approach. In this work, we address both subproblems, nam</context>
<context position="8518" citStr="Elson and McKeown, 2010" startWordPosition="1315" endWordPosition="1318">f the voice assigned to a synthetic character is strongly related to knowing the gender, age and other salient personality attributes of the character. Given this, we have developed rule-based, machine-learning-based and resourcebased approaches for estimation of character gender, age and salient personality attributes. In contrast, the majority of past works on the analysis of children stories for TTS-based storytelling is limited to the attribution of quotes to speakers, though studies that focused on anaphoric speaker identification have also approached character gender estimation such as (Elson and McKeown, 2010) and (He et al., 2013). The utilization of available resources containing associations between person names and gender was followed in (Elson and 41 McKeown, 2010). In (He et al., 2013), associations between characters and their gender were performed using anaphora rules (Mitkov, 2002). There is of course a significant body of work from other research areas that are related to the estimation of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification o</context>
<context position="12426" citStr="Elson and McKeown, 2010" startWordPosition="1929" endWordPosition="1932">ers The second step is identifying candidate characters (i.e., entities) that appear in the stories under analysis. A story character is not necessarily a story speaker. A character may appear in the story but may not have any quote associated with him and hence, is not a speaker. Characters in children’s stories can either be human or non-human entities, i.e., animals and non-living objects, exhibiting anthropomorphic traits. The interactions among characters can either be human-to-human or human-to-non-human interactions. We used two approaches for identifying story characters motivated by (Elson and McKeown, 2010): 1) named entity recognition was used for identifying proper names, e.g., “Hansel”, 2) a set of part-of-speech patterns was used for the extraction of human and non-human characters that were not represented by proper names, e.g., “wolf”. The used patterns are: 1) (DT|CD) (NN|NNS), 2) DT JJ (NN|NNS), 3) NN POS (NN|NNS), and 4) PRP$ JJ (NN|NNS). These POS-based patterns are quite generic, allowing for the creation of large sets of characters. In order to restrict the characters, world knowledge was incorporated through the use of WordNet (Fellbaum, 2005). A similar approach was also followed i</context>
<context position="15970" citStr="Elson and McKeown, 2010" startWordPosition="2507" endWordPosition="2511">, the respective passive characters were not considered as candidate speakers. Some other criteria for pruning of list of characters to identify candidate speakers are presented in Section 4.2 (see the three schemes for Tasks 1-2). Explicit mention of speakers. Several syntactic patterns were applied to associate quotes with explicit mention of speakers in their vicinity to characters from the pruned list of story characters. These patterns were developed around SV. In the example above, “Hans” is associated with the quote “Done!” via the SV “said”. Variations of the following basic patterns (Elson and McKeown, 2010) were used: 1) QT SV CH, 2) QT CH SV, and 3) CH SV QT, where QT denotes a quote boundary and CH stands for a story character. For example, a variation of the first pattern is QT SV the? CH, where ? stands for zero or one occurrence of “the”. A limitation of the aforementioned patterns is that they capture associations when the CH and SV occur in close textual distance. As a result, distant associations are missed, e.g., “Hans stood looking on for a while, and at last said, “ You must ...””. In order to address this distant association issue, we examined the collapsed-ccprocessed-dependencies o</context>
</contexts>
<marker>Elson, McKeown, 2010</marker>
<rawString>D. K. Elson and K. R. McKeown. 2010. Automatic attribution of quoted speech in literary narrative. In Proc. of Twenty-Fourth AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>Wordnet and wordnets. In</title>
<date>2005</date>
<booktitle>Encyclopedia of Language and Linguistics,</booktitle>
<pages>665--670</pages>
<editor>K. Brown et al., editor,</editor>
<publisher>Elsevier.</publisher>
<location>Oxford:</location>
<contexts>
<context position="12986" citStr="Fellbaum, 2005" startWordPosition="2023" endWordPosition="2024">story characters motivated by (Elson and McKeown, 2010): 1) named entity recognition was used for identifying proper names, e.g., “Hansel”, 2) a set of part-of-speech patterns was used for the extraction of human and non-human characters that were not represented by proper names, e.g., “wolf”. The used patterns are: 1) (DT|CD) (NN|NNS), 2) DT JJ (NN|NNS), 3) NN POS (NN|NNS), and 4) PRP$ JJ (NN|NNS). These POS-based patterns are quite generic, allowing for the creation of large sets of characters. In order to restrict the characters, world knowledge was incorporated through the use of WordNet (Fellbaum, 2005). A similar approach was also followed in (Elson and McKeown, 2010). For each candidate character the hierarchy of its hypernyms was traversed up to the root. Regarding polysemous characters the first two senses were considered. A character was retained if any of its hypernyms was found to fall into certain types of WordNet concepts: person, animal, plant, artifact, spiritual being, physical entity. 42 3.3 Quote Attribution &amp; Speaker Identification Here the goal is to attribute (or assign) each quote to a specific story character from the set identified in the previous step. The identification</context>
</contexts>
<marker>Fellbaum, 2005</marker>
<rawString>C. Fellbaum. 2005. Wordnet and wordnets. In K. Brown et al., editor, Encyclopedia of Language and Linguistics, pages 665–670. Oxford: Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Greene</author>
<author>T Mishra</author>
<author>P Haffner</author>
<author>A Conkie</author>
</authors>
<title>Predicting character-appropriate voices for a TTSbased storyteller system.</title>
<date>2012</date>
<booktitle>In Proc. ofInterspeech.</booktitle>
<contexts>
<context position="2373" citStr="Greene et al., 2012" startWordPosition="349" endWordPosition="352">ng is irreplaceable, we consider text-to-speech (TTS) enabled storytelling systems (Rusko et al., 2013; Zhang et al., 2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, anger and surprise (Alm, 2008) with realistic expression (Murray and Arnott, 2008). However, before any of the aforementioned requirements — all related to speech generation — can be met, the text of the story has to be analyzed to identify which portions of the text should be rendered by the narrator and which by each of the characters in the story, who are the different characters in the story, what is each character’s gender, age, or other salient personality attributes that may influence the voice assigned to tha</context>
<context position="7856" citStr="Greene et al. (2012)" startWordPosition="1215" endWordPosition="1218"> speaker, or a continuation quote (CONT) spoken by the same speaker as that of the previous quote. He et al. (2013) also identified similar chains of utterances and addressed their attribution to characters using a model-based approach. In this work, we address both subproblems, namely, anaphoric speaker and implicit speaker identification. Cabral et al. (2006) have shown that assigning an appropriate voice for a character in a digital storyteller system is significant for understanding a story, perceiving affective content, perceiving the voice as credible, and overall listener satisfaction. Greene et al. (2012) have shown that the appropriateness of the voice assigned to a synthetic character is strongly related to knowing the gender, age and other salient personality attributes of the character. Given this, we have developed rule-based, machine-learning-based and resourcebased approaches for estimation of character gender, age and salient personality attributes. In contrast, the majority of past works on the analysis of children stories for TTS-based storytelling is limited to the attribution of quotes to speakers, though studies that focused on anaphoric speaker identification have also approached</context>
</contexts>
<marker>Greene, Mishra, Haffner, Conkie, 2012</marker>
<rawString>E. Greene, T. Mishra, P. Haffner, and A. Conkie. 2012. Predicting character-appropriate voices for a TTSbased storyteller system. In Proc. ofInterspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H He</author>
<author>D Barbosa</author>
<author>G Kondrak</author>
</authors>
<title>Identification of speakers in novels.</title>
<date>2013</date>
<booktitle>In Proc. of 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1312--1320</pages>
<contexts>
<context position="5809" citStr="He et al. (2013)" startWordPosition="885" endWordPosition="888">egarded as a parsimonious yet fertile framework for developing computational models for literature analysis in general. 2 Related Work Elson and McKeown (2010) used rule-based and statistical learning approaches to identify candidate characters and attribute each quote to the most likely speaker. Two broad approaches for the identification of story characters were followed: (i) named entity recognition, and (ii) identification of character nominals, e.g., “her grandma”, using syntactic patterns. A long list of heuristics for character identification is proposed in (Mamede and Chaleira, 2004). He et al. (2013) use a supervised machine learning approach to address the same problem, though many of their preliminary steps and input features are similar to those used in (Elson and McKeown, 2010). Our character identification and quote attribution is based on syntactic and heuristic rules that is motivated by each of these works. There are two interesting sub-problems related to quote attribution. First is the problem of identifying anaphoric speakers, i.e., in the utterance “Hello”, he said, which character is referred to by the pronoun he? This problem is addressed in (Elson and McKeown, 2010) and (He</context>
<context position="7351" citStr="He et al. (2013)" startWordPosition="1137" endWordPosition="1140"> mentioned because the author relies on the shared understanding with the reader that adjacent pieces of quoted speech are not independent (Zhang et al., 2003; Elson and McKeown, 2010). They are either a continuation of the same character’s speech (one-character chains) or a dialogue between the two characters (intertwined chains). In (Zhang et al., 2003), the quote-identification module detects whether a piece of quoted speech is a new quote (NEW), spoken by a speaker different from the previous speaker, or a continuation quote (CONT) spoken by the same speaker as that of the previous quote. He et al. (2013) also identified similar chains of utterances and addressed their attribution to characters using a model-based approach. In this work, we address both subproblems, namely, anaphoric speaker and implicit speaker identification. Cabral et al. (2006) have shown that assigning an appropriate voice for a character in a digital storyteller system is significant for understanding a story, perceiving affective content, perceiving the voice as credible, and overall listener satisfaction. Greene et al. (2012) have shown that the appropriateness of the voice assigned to a synthetic character is strongly</context>
<context position="8703" citStr="He et al., 2013" startWordPosition="1345" endWordPosition="1348"> machine-learning-based and resourcebased approaches for estimation of character gender, age and salient personality attributes. In contrast, the majority of past works on the analysis of children stories for TTS-based storytelling is limited to the attribution of quotes to speakers, though studies that focused on anaphoric speaker identification have also approached character gender estimation such as (Elson and McKeown, 2010) and (He et al., 2013). The utilization of available resources containing associations between person names and gender was followed in (Elson and 41 McKeown, 2010). In (He et al., 2013), associations between characters and their gender were performed using anaphora rules (Mitkov, 2002). There is of course a significant body of work from other research areas that are related to the estimation of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification of users in social media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attr</context>
<context position="17122" citStr="He et al., 2013" startWordPosition="2710" endWordPosition="2713">tion issue, we examined the collapsed-ccprocessed-dependencies output besides the basic-dependencies output of the Stanford CoreNLP dependency engine (de Marneffe and Manning, 2012). The former captures more distant relations compared to the latter. We specifically extract the character reference CH either from the dependency relation nsubj, which links a speech verb SV with a CH that is the syntactic subject of a clause, or from the dependency relation dobj, which links a SV with a CH that is the direct object of the speech verb, across a conjunct (e.g., and). A similar approach was used in (He et al., 2013). Anaphoric mention of speakers. The same procedure was followed as in the case of the explicit mentions of speakers described above. The difference is that CH included the following pronouns: “he”, “she”, “they”, “himself”, “herself”, and “themselves”. After associating a pronoun with a quote, the quote was attributed to a story character via co-reference resolution. This was done using the co-reference analysis performed by CoreNLP. If a pronominal anaphora was not resolved by the CoreNLP analysis, the following heuristic was adopted. The previous n paragraphs1 were searched and the pronoun </context>
</contexts>
<marker>He, Barbosa, Kondrak, 2013</marker>
<rawString>H. He, D. Barbosa, and G. Kondrak. 2013. Identification of speakers in novels. In Proc. of 51st Annual Meeting of the Association for Computational Linguistics, pages 1312–1320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proc. of Conference on Knowledge Discovery and Data Mining, KDD ’04,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="9959" citStr="Hu and Liu, 2004" startWordPosition="1547" endWordPosition="1550">psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate for the intended application (i.e., story</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. In Proc. of Conference on Knowledge Discovery and Data Mining, KDD ’04, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lloyd</author>
<author>D Kechagias</author>
<author>S Skiena</author>
</authors>
<title>Lydia: A system for large-scale news analysis.</title>
<date>2005</date>
<booktitle>In Proc. SPIRE, number 3772 in Lecture Notes in Computer Science,</booktitle>
<pages>161--166</pages>
<contexts>
<context position="9919" citStr="Lloyd et al., 2005" startWordPosition="1540" endWordPosition="1543">ttributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate f</context>
</contexts>
<marker>Lloyd, Kechagias, Skiena, 2005</marker>
<rawString>L. Lloyd, D. Kechagias, and S. Skiena. 2005. Lydia: A system for large-scale news analysis. In Proc. SPIRE, number 3772 in Lecture Notes in Computer Science, pages 161–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Malandrakis</author>
<author>A Potamianos</author>
<author>E Iosif</author>
<author>S Narayanan</author>
</authors>
<title>Distributional semantic models for affective text analysis.</title>
<date>2013</date>
<journal>IEEE Transactions on Audio, Speech, and Language Processing,</journal>
<volume>21</volume>
<issue>11</issue>
<contexts>
<context position="10256" citStr="Malandrakis et al., 2013" startWordPosition="1597" endWordPosition="1600">d great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate for the intended application (i.e., storytelling system), while in (Alm, 2008) more fine-grained predictions are considered. The integration of various types of analysis constitutes the distinguishing character of our work. 3 Overview of System Architecture The system consists of several sub-systems that are linked in a pipeline. The in</context>
</contexts>
<marker>Malandrakis, Potamianos, Iosif, Narayanan, 2013</marker>
<rawString>N. Malandrakis, A. Potamianos, E. Iosif, and S. Narayanan. 2013. Distributional semantic models for affective text analysis. IEEE Transactions on Audio, Speech, and Language Processing, 21(11):2379–2392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Mamede</author>
<author>P Chaleira</author>
</authors>
<title>Character identification in children stories. In</title>
<date>2004</date>
<booktitle>Advances in Natural Language Processing,</booktitle>
<volume>3230</volume>
<pages>82--90</pages>
<editor>J. Vicedo, P. MartnezBarco, R. Muoz, and M. Saiz Noeda, editors,</editor>
<publisher>Springer</publisher>
<contexts>
<context position="5791" citStr="Mamede and Chaleira, 2004" startWordPosition="881" endWordPosition="884"> children’s stories can be regarded as a parsimonious yet fertile framework for developing computational models for literature analysis in general. 2 Related Work Elson and McKeown (2010) used rule-based and statistical learning approaches to identify candidate characters and attribute each quote to the most likely speaker. Two broad approaches for the identification of story characters were followed: (i) named entity recognition, and (ii) identification of character nominals, e.g., “her grandma”, using syntactic patterns. A long list of heuristics for character identification is proposed in (Mamede and Chaleira, 2004). He et al. (2013) use a supervised machine learning approach to address the same problem, though many of their preliminary steps and input features are similar to those used in (Elson and McKeown, 2010). Our character identification and quote attribution is based on syntactic and heuristic rules that is motivated by each of these works. There are two interesting sub-problems related to quote attribution. First is the problem of identifying anaphoric speakers, i.e., in the utterance “Hello”, he said, which character is referred to by the pronoun he? This problem is addressed in (Elson and McKe</context>
</contexts>
<marker>Mamede, Chaleira, 2004</marker>
<rawString>N. Mamede and P. Chaleira. 2004. Character identification in children stories. In J. Vicedo, P. MartnezBarco, R. Muoz, and M. Saiz Noeda, editors, Advances in Natural Language Processing, volume 3230 of Lecture Notes in Computer Science, pages 82–90. Springer Berlin Heidelberg. R. Mitkov. 2002. Anaphora Resolution. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I R Murray</author>
<author>J L Arnott</author>
</authors>
<title>Applying an analysis of acted vocal emotions to improve the simulation of synthetic speech.</title>
<date>2008</date>
<journal>Computer Speech and Language,</journal>
<volume>22</volume>
<issue>2</issue>
<contexts>
<context position="2533" citStr="Murray and Arnott, 2008" startWordPosition="371" endWordPosition="374">ed with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, anger and surprise (Alm, 2008) with realistic expression (Murray and Arnott, 2008). However, before any of the aforementioned requirements — all related to speech generation — can be met, the text of the story has to be analyzed to identify which portions of the text should be rendered by the narrator and which by each of the characters in the story, who are the different characters in the story, what is each character’s gender, age, or other salient personality attributes that may influence the voice assigned to that character, and what is the expressed affect in each of the character quotes. Each of these text analysis tasks has been approached in past work (as described </context>
</contexts>
<marker>Murray, Arnott, 2008</marker>
<rawString>I. R. Murray and J. L. Arnott. 2008. Applying an analysis of acted vocal emotions to improve the simulation of synthetic speech. Computer Speech and Language, 22(2):107–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Nakov</author>
<author>S Rosenthal</author>
<author>Z Kozareva</author>
<author>V Stoyanov</author>
<author>A Ritter</author>
<author>T Wilson</author>
</authors>
<title>Semeval</title>
<date>2013</date>
<booktitle>In Proc. of Second Joint Conference on Lexical and Computational Semantics (*SEM), Seventh International Workshop on Semantic Evaluation,</booktitle>
<pages>312--320</pages>
<contexts>
<context position="9799" citStr="Nakov et al., 2013" startWordPosition="1521" endWordPosition="1524">e proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set</context>
</contexts>
<marker>Nakov, Rosenthal, Kozareva, Stoyanov, Ritter, Wilson, 2013</marker>
<rawString>P. Nakov, S. Rosenthal, Z. Kozareva, V. Stoyanov, A. Ritter, and T. Wilson. 2013. Semeval 2013 task 2: Sentiment analysis in twitter. In Proc. of Second Joint Conference on Lexical and Computational Semantics (*SEM), Seventh International Workshop on Semantic Evaluation, pages 312–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Natsiopoulou</author>
<author>M Souliotis</author>
<author>A G Kyridis</author>
</authors>
<title>Narrating and reading folktales and picture books: storytelling techniques and approaches with preschool children.</title>
<date>2006</date>
<booktitle>Early Childhood Research and Practice, 8(1). Retrieved on</booktitle>
<note>from http://ecrp.uiuc.edu/v8n1/ natsiopoulou.html.</note>
<contexts>
<context position="1403" citStr="Natsiopoulou et al., 2006" startWordPosition="202" endWordPosition="205">aracter age, gender and other salient personality attributes; and finally, affective analysis of the quoted material. The different types of analyses were evaluated using several datasets. For the quote attribution, as well as for the gender and age estimation, substantial improvement over baseline was realized, whereas results for personality attribute estimation and valence estimation are more modest. 1 Introduction Children love listening to stories. Listening to stories — read or narrated — has been shown to be positively correlated with children’s linguistic and intellectual development (Natsiopoulou et al., 2006). Shared story reading with parents or teachers helps children to learn about vocabulary, syntax and phonology, and to develop narrative comprehension and awareness of the concepts of print, all of which are linked to developing reading and writing skills (National Early Literacy Panel 2008). While acknowledging that the parental role in storytelling is irreplaceable, we consider text-to-speech (TTS) enabled storytelling systems (Rusko et al., 2013; Zhang et al., 2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digi</context>
</contexts>
<marker>Natsiopoulou, Souliotis, Kyridis, 2006</marker>
<rawString>T. Natsiopoulou, M. Souliotis, and A. G. Kyridis. 2006. Narrating and reading folktales and picture books: storytelling techniques and approaches with preschool children. Early Childhood Research and Practice, 8(1). Retrieved on Jan 13th, 2014 from http://ecrp.uiuc.edu/v8n1/ natsiopoulou.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T W Norman</author>
</authors>
<title>Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating.</title>
<date>1963</date>
<journal>Journal of Abnormal and Social Psychology,</journal>
<pages>66--574</pages>
<contexts>
<context position="9525" citStr="Norman, 1963" startWordPosition="1479" endWordPosition="1480"> of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification of users in social media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic r</context>
</contexts>
<marker>Norman, 1963</marker>
<rawString>T. W. Norman. 1963. Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating. Journal of Abnormal and Social Psychology, 66:574–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Piao</author>
</authors>
<title>Sentence splitting program.</title>
<date>2014</date>
<note>http://text0.mib.man.ac.uk: 8080/scottpiao/sent_detector.</note>
<contexts>
<context position="11661" citStr="Piao (2014)" startWordPosition="1817" endWordPosition="1818">m the four analysis tasks laid out in this paper. 3.1 Linguistic Preprocessing The first step is linguistic pre-processing of the stories. This includes (i) tokenization, (ii) sentence splitting and identification of paragraph boundaries, (iii) part-of-speech (POS) tagging, (iv) lemmatization, (v) named entity recognition, (vi) dependency parsing, and (vii) co-reference analysis. These sub-tasks — except task (ii) — were performed using the Stanford CoreNLP suite of tools (CoreNLP, 2014). Sentence splitting and identification of paragraph boundaries was performed using a splitter developed by Piao (2014). Linguistic information extracted by this analysis is exploited by the subsequent parts of the pipeline. 3.2 Identification of Story Characters The second step is identifying candidate characters (i.e., entities) that appear in the stories under analysis. A story character is not necessarily a story speaker. A character may appear in the story but may not have any quote associated with him and hence, is not a speaker. Characters in children’s stories can either be human or non-human entities, i.e., animals and non-living objects, exhibiting anthropomorphic traits. The interactions among chara</context>
</contexts>
<marker>Piao, 2014</marker>
<rawString>S. Piao. 2014. Sentence splitting program. http://text0.mib.man.ac.uk: 8080/scottpiao/sent_detector.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Rao</author>
<author>D Yarowsky</author>
<author>A Shreevats</author>
<author>M Gupta</author>
</authors>
<title>Classifying latent user attributes in twitter.</title>
<date>2010</date>
<booktitle>In Proc. of the 2nd International Workshop on Search and Mining User-generated Contents,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="9212" citStr="Rao et al., 2010" startWordPosition="1424" endWordPosition="1427">ociations between person names and gender was followed in (Elson and 41 McKeown, 2010). In (He et al., 2013), associations between characters and their gender were performed using anaphora rules (Mitkov, 2002). There is of course a significant body of work from other research areas that are related to the estimation of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification of users in social media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant ap</context>
</contexts>
<marker>Rao, Yarowsky, Shreevats, Gupta, 2010</marker>
<rawString>D. Rao, D. Yarowsky, A. Shreevats, and M. Gupta. 2010. Classifying latent user attributes in twitter. In Proc. of the 2nd International Workshop on Search and Mining User-generated Contents, pages 37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rusko</author>
<author>M Trnka</author>
<author>S Darjaa</author>
<author>J Hamar</author>
</authors>
<title>The dramatic piece reader for the blind and visually impaired.</title>
<date>2013</date>
<booktitle>In Proc. of 4th Workshop on Speech and Language Processing for Assistive Technologies,</booktitle>
<pages>83--91</pages>
<contexts>
<context position="1855" citStr="Rusko et al., 2013" startWordPosition="267" endWordPosition="270">stening to stories — read or narrated — has been shown to be positively correlated with children’s linguistic and intellectual development (Natsiopoulou et al., 2006). Shared story reading with parents or teachers helps children to learn about vocabulary, syntax and phonology, and to develop narrative comprehension and awareness of the concepts of print, all of which are linked to developing reading and writing skills (National Early Literacy Panel 2008). While acknowledging that the parental role in storytelling is irreplaceable, we consider text-to-speech (TTS) enabled storytelling systems (Rusko et al., 2013; Zhang et al., 2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, ange</context>
<context position="5061" citStr="Rusko et al., 2013" startWordPosition="771" endWordPosition="774">analysis system was developed to be part of a larger TTS-based storyteller system aimed at children. As a result, the data used for developing the computational models or rules in each step of our system were obtained from children’s stories. A majority of children’s stories are short. They often contain multiple characters, each with different personalities, genders, age, ethnicities, etc., with some characters even being anthropomorphic, e.g., the singing candlestick or the talking teapot. In addition, there are several prototypical templates characterizing the main characters in the story (Rusko et al., 2013). However, character development is limited in these stories due to the shorter length of text. Overall, children’s stories can be regarded as a parsimonious yet fertile framework for developing computational models for literature analysis in general. 2 Related Work Elson and McKeown (2010) used rule-based and statistical learning approaches to identify candidate characters and attribute each quote to the most likely speaker. Two broad approaches for the identification of story characters were followed: (i) named entity recognition, and (ii) identification of character nominals, e.g., “her gra</context>
</contexts>
<marker>Rusko, Trnka, Darjaa, Hamar, 2013</marker>
<rawString>M. Rusko, M. Trnka, S. Darjaa, and J. Hamar. 2013. The dramatic piece reader for the blind and visually impaired. In Proc. of 4th Workshop on Speech and Language Processing for Assistive Technologies, pages 83–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Schapire</author>
<author>Y Singer</author>
</authors>
<title>Boostexter: A boosting-based system for text categorization.</title>
<date>2000</date>
<journal>Machine. Learning,</journal>
<pages>39--2</pages>
<contexts>
<context position="31969" citStr="Schapire and Singer, 2000" startWordPosition="5075" endWordPosition="5078"> results are presented in Table 3 including the weighted averages of precision and recall. Using random guesses, the baseline precision is 0.010 and 0.333 for quote-to-speaker attribution and gender estimation, respectively. For the subset of 10 stories, the highest speaker-to-quote attribution attribution is obtained by Scheme 2. When this scheme is applied over the entire dataset, substantially high6 precision (0.892) is achieved in the estimation of gender of true story speakers. Task 3. For the estimation of age using quotebased features, a boosting approach was followed using BoosTexter (Schapire and Singer, 2000). For evaluation, 10-fold cross validaDataset Relaxed Exact lex pos lex pos Baseline 0.625 0.250 QUOTES1 0.869 0.883 0.445 0.373 QUOTES2 0.877 0.831 0.450 0.435 BOTH 0.886 0.858 0.464 0.383 Table 4: Age estimation: average accuracy. tion (10FCV) was used for the QUOTES1 and QUOTES2 datasets for the “lex” and “pos” feature sets. The results are reported in Table 4 in terms of average classification accuracy. In this table, BOTH refers to the datasets QUOTES1 and QUOTES2 combined together. The evaluation was performed according to two schemes: (i) “relaxed match”: the prediction is considered as</context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>R. E. Schapire and Y. Singer. 2000. Boostexter: A boosting-based system for text categorization. Machine. Learning, 39(2-3):135–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schler</author>
<author>M Koppel</author>
<author>S Argamon</author>
<author>J W Pennebaker</author>
</authors>
<title>Effects of age and gender on blogging.</title>
<date>2006</date>
<booktitle>In Proc. ofAAAI Spring Symposium: Computational Approaches to Analyzing Weblogs.</booktitle>
<contexts>
<context position="9059" citStr="Schler et al., 2006" startWordPosition="1402" endWordPosition="1405">e also approached character gender estimation such as (Elson and McKeown, 2010) and (He et al., 2013). The utilization of available resources containing associations between person names and gender was followed in (Elson and 41 McKeown, 2010). In (He et al., 2013), associations between characters and their gender were performed using anaphora rules (Mitkov, 2002). There is of course a significant body of work from other research areas that are related to the estimation of character attributes, similar to what we have attempted in our work. Several shallow linguistic features were proposed in (Schler et al., 2006) for gender identification, applied to the identification of users in social media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflect</context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>J. Schler, M. Koppel, S. Argamon, and J. W. Pennebaker. 2006. Effects of age and gender on blogging. In Proc. ofAAAI Spring Symposium: Computational Approaches to Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Social Security</author>
</authors>
<title>U.S. social security administration baby name database.</title>
<date>2014</date>
<note>http://www.ssa. gov/OACT/babynames/limits.html.</note>
<contexts>
<context position="21829" citStr="Security, 2014" startWordPosition="3463" endWordPosition="3464">Section 3.3). The characterization “hybrid” refers to the fusion of two different types of information: (i) linguistic information extracted from the story under analysis, and (ii) information taken from external resources that do not depend on the analyzed story. Regarding the story-specific information, the associations between characters and third person pronouns (identified via anaphora resolution) were counted. The counts were used in order to estimate the gender probability. The story-independent resources that we used are: (a) the U.S. Social Security Administration baby name database (Security, 2014), in which person names are linked with gender and (b) a large name-gender association list developed using a corpus-based bootstrapping approach, which even included the estimated gender for non-person entities (Bergsma and Lin, 2006). For each entity included in (b) a numerical estimate is provided for each gender. As in the case of story-specific information, those estimates were utilized for computing the gender probability. Using the above information the following procedure was followed for each character: The external resource (a) was used when the character name occurred in it. Otherwi</context>
</contexts>
<marker>Security, 2014</marker>
<rawString>Social Security. 2014. U.S. social security administration baby name database. http://www.ssa. gov/OACT/babynames/limits.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Stone</author>
<author>D C Dunphy</author>
<author>M S Smith</author>
<author>D M Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="24168" citStr="Stone et al., 1966" startWordPosition="3859" endWordPosition="3862">nouns 14 count of 2nd person singular pronouns 15 count of quote positive words 16 count of quote negative words 17 count of nouns 18 count of verbs 19 count of adjectives 20 count of adverbs 21 up to 3-grams extracted from quote Table 1: Common feature set. development of this feature set was inspired by (Celli, 2012) and (Alm et al., 2005). All features were extracted from the lemmatized form of quotes. Also, all feature counts (except Feature 21) were normalized by Feature 12. For computing the counts of positive and negative words (Feature 15 and 16) we used the General Inquirer database (Stone et al., 1966). Feature 21 stands for n-grams (up to 3-grams) extracted from the speaker quotes. Two different schemes were followed for extracting this feature: (i) using the quote as-is, i.e., its lexical form, and (ii) using the part-of-speech tags of quote. So, two slightly different feature sets were defined: 1) “lex”: No.1-20 + lexical form for No.21, 2) “pos”: No.1-20 + POS tags for No.21 3.4.3 Estimation of Personality Attributes A machine-learning based approach was also used for personality attribute estimation. For estimating the personality attributes of story speakers, the linguistic feature se</context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>P. J. Stone, D. C. Dunphy, M. S. Smith, and D. M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>R Mihalcea</author>
</authors>
<title>Semeval</title>
<date>2007</date>
<booktitle>In Proc. SemEval,</booktitle>
<pages>70--74</pages>
<contexts>
<context position="9767" citStr="Strapparava and Mihalcea, 2007" startWordPosition="1515" endWordPosition="1518">media. Several socio-linguistic features were proposed in (Rao et al., 2010) for estimating the age and gender of Twitter users. The identification of personality attributes from text is often motivated by psychological models. In (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In o</context>
</contexts>
<marker>Strapparava, Mihalcea, 2007</marker>
<rawString>C. Strapparava and R. Mihalcea. 2007. Semeval 2007 task 14: Affective text. In Proc. SemEval, pages 70– 74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Theune</author>
<author>K Meijs</author>
<author>D Heylen</author>
</authors>
<title>Generating expressive speech for storytelling applications.</title>
<date>2006</date>
<booktitle>In IEEE Transactions on Audio, Speech and Language Processing,</booktitle>
<pages>1137--1144</pages>
<contexts>
<context position="1897" citStr="Theune et al., 2006" startWordPosition="275" endWordPosition="278">has been shown to be positively correlated with children’s linguistic and intellectual development (Natsiopoulou et al., 2006). Shared story reading with parents or teachers helps children to learn about vocabulary, syntax and phonology, and to develop narrative comprehension and awareness of the concepts of print, all of which are linked to developing reading and writing skills (National Early Literacy Panel 2008). While acknowledging that the parental role in storytelling is irreplaceable, we consider text-to-speech (TTS) enabled storytelling systems (Rusko et al., 2013; Zhang et al., 2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, anger and surprise (Alm, 2008) with realistic </context>
</contexts>
<marker>Theune, Meijs, Heylen, 2006</marker>
<rawString>M. Theune, K. Meijs, and D. Heylen. 2006. Generating expressive speech for storytelling applications. In IEEE Transactions on Audio, Speech and Language Processing, pages 1137–1144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
<author>M L Littman</author>
</authors>
<title>Unsupervised learning of semantic orientation from a hundredbillion-word corpus (technical report erc-1094).</title>
<date>2002</date>
<contexts>
<context position="9990" citStr="Turney and Littman, 2002" startWordPosition="1552" endWordPosition="1555">n (Celli, 2012), a list of linguistic features were used for the creation of character models in terms of the the Big Five personality dimensions (Norman, 1963). Analysis of text to estimate affect or sentiment is a relatively recent research topic that has attracted great interest, as reflected by a series of shared evaluation tasks, e.g., analysis of news headlines (Strapparava and Mihalcea, 2007) and tweets (Nakov et al., 2013). Relevant applications deal with numerous domains such as blogs (Balog et al., 2006), news stories (Lloyd et al., 2005), and product reviews (Hu and Liu, 2004). In (Turney and Littman, 2002), the affective ratings of unknown words were predicted using the affective ratings for a small set of words (seeds) and the semantic relatedness between the unknown and the seed words. An example of sentence-level analysis was proposed in (Malandrakis et al., 2013). In (Alm et al., 2005) and (Alm, 2008), linguistic features were used for affect analysis in fairy tales. In our work, we employ a feature set similar to that in (Alm et al., 2005). We deal with the prediction of three basic affective labels which are adequate for the intended application (i.e., storytelling system), while in (Alm,</context>
</contexts>
<marker>Turney, Littman, 2002</marker>
<rawString>P. Turney and M. L. Littman. 2002. Unsupervised learning of semantic orientation from a hundredbillion-word corpus (technical report erc-1094).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Disney Wiki</author>
</authors>
<title>Description of Disney characters.</title>
<date>2014</date>
<note>http://disney.wikia.com/wiki/ Category:Disney_characters#.</note>
<contexts>
<context position="28221" citStr="Wiki, 2014" startWordPosition="4484" endWordPosition="4485"> was inferred by the annotators either based on personal knowledge of these stories or by consulting publicly available sources online. The inter-annotator agreement equals to 70%. Task 4. To evaluate system performance on Task 4, two datasets QUOTES3 and QUOTES4, consisting of individual quotes assigned to popular children’s story characters, were used. The set QUOTES3 consisted of 68 individual characters and QUOTES4 consisted of 328 individual characters. The ground truth assignment, assigning each character with personality attributes, was extracted from a free, public collaborative wiki (Wiki, 2014). Since the wiki format allows people to add or edit information, we considered the personality attributes extracted from this wiki to be the average “crowd’s opinion” of these characters. Of the open-ended list of attributes that were used to describe the characters, in this task we attempted to extract the following salient personality attributes: “beautiful”, “brave”, “cowardly”, “evil”, “feisty”, “greedy”, “handsome”, “kind”, “loving”, “loyal”, “motherly”, “optimistic”, “spunky”, “sweet”, and “wise”. The pseudo-attribute “none” was used when a character was not described with any of those </context>
</contexts>
<marker>Wiki, 2014</marker>
<rawString>Disney Wiki. 2014. Description of Disney characters. http://disney.wikia.com/wiki/ Category:Disney_characters#.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Y Zhang</author>
<author>A W Black</author>
<author>R Sproat</author>
</authors>
<title>Identifying speakers in children’s stories for speech synthesis.</title>
<date>2003</date>
<tech>InProc. ofInterspeech.</tech>
<contexts>
<context position="1875" citStr="Zhang et al., 2003" startWordPosition="271" endWordPosition="274"> read or narrated — has been shown to be positively correlated with children’s linguistic and intellectual development (Natsiopoulou et al., 2006). Shared story reading with parents or teachers helps children to learn about vocabulary, syntax and phonology, and to develop narrative comprehension and awareness of the concepts of print, all of which are linked to developing reading and writing skills (National Early Literacy Panel 2008). While acknowledging that the parental role in storytelling is irreplaceable, we consider text-to-speech (TTS) enabled storytelling systems (Rusko et al., 2013; Zhang et al., 2003; Theune et al., 2006) to be aligned with the class of childoriented applications that aim to aid learning. For a TTS-based digital storytelling system to successfully create an experience as engaging as human storytelling, the underlying speech synthesis system has to narrate the story in a “storytelling speech style” (Theune et al., 2006), generate dialogs uttered by different characters using synthetic voices appropriate for each character’s gender, age and personality (Greene et al., 2012), and express quotes demonstrating emotions such as sadness, fear, happiness, anger and surprise (Alm,</context>
<context position="6893" citStr="Zhang et al., 2003" startWordPosition="1061" endWordPosition="1064">nce “Hello”, he said, which character is referred to by the pronoun he? This problem is addressed in (Elson and McKeown, 2010) and (He et al., 2013) but not in (Mamede and Chaleira, 2004). The second problem is resolving utterance chains with implicit speakers. Elson and McKeown (2010) describe and address two basic types of utterance chains: (i) one-character chains, and (ii) intertwined chains. In these chains of utterances, the speaker is not explicitly mentioned because the author relies on the shared understanding with the reader that adjacent pieces of quoted speech are not independent (Zhang et al., 2003; Elson and McKeown, 2010). They are either a continuation of the same character’s speech (one-character chains) or a dialogue between the two characters (intertwined chains). In (Zhang et al., 2003), the quote-identification module detects whether a piece of quoted speech is a new quote (NEW), spoken by a speaker different from the previous speaker, or a continuation quote (CONT) spoken by the same speaker as that of the previous quote. He et al. (2013) also identified similar chains of utterances and addressed their attribution to characters using a model-based approach. In this work, we add</context>
<context position="13843" citStr="Zhang et al., 2003" startWordPosition="2163" endWordPosition="2166">er was retained if any of its hypernyms was found to fall into certain types of WordNet concepts: person, animal, plant, artifact, spiritual being, physical entity. 42 3.3 Quote Attribution &amp; Speaker Identification Here the goal is to attribute (or assign) each quote to a specific story character from the set identified in the previous step. The identification of quotes in the story is based on a simple pattern-based approach: the quote boundaries are signified by the respective symbols, e.g., “ and ”. The pattern is applied at the sentence level. The quotes are not modeled as NEW/CONT as in (Zhang et al., 2003), however, we adopt a more sophisticated approach for the quote attribution. Three types of attribution are possible in our system: 1) explicit mention of speakers, e.g., “Done!” said Hans, merrily, 2) anaphoric mention of speakers, e.g., “How happy am I!” cried he, 3) sequence of quotes, e.g., “And where did you get the pig?” ... “I gave a horse for it.”. In the first type of attribution, the speaker is explicitly mentioned in the vicinity of the quote. This is also true for the second type, however, a pronominal anaphora is used to refer to the the speaker. The first two attribution types ar</context>
</contexts>
<marker>Zhang, Black, Sproat, 2003</marker>
<rawString>J. Y. Zhang, A. W. Black, and R. Sproat. 2003. Identifying speakers in children’s stories for speech synthesis. InProc. ofInterspeech.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>