<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006519">
<title confidence="0.981193">
The Case for Empiricism (With and Without Statistics)
</title>
<author confidence="0.871491">
Kenneth Church
</author>
<address confidence="0.837941">
1101 Kitchawan Road
Yorktown Heights, NY 10589
USA
</address>
<email confidence="0.991353">
Kenneth.Ward.Church@gmail.com
</email>
<sectionHeader confidence="0.993718" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998404642857143">
These days we tend to use terms like empirical
and statistical as if they are interchangeable, but
it wasn’t always this way, and probably for good
reason. In A Pendulum Swung Too Far (Church,
2011), I argued that graduate programs should
make room for both Empiricism and Rational-
ism. We don’t know which trends will dominate
the field tomorrow, but it is a good bet that it
won’t be what’s hot today. We should prepare
the next generation of students for all possible
futures, or at least all probable futures. This pa-
per argues for a diverse interpretation of Empiri-
cism, one that makes room for everything from
Humanities to Engineering (and then some).
</bodyText>
<figureCaption confidence="0.893666">
Figure 1: Lily Wong Fillmore (standing) and
Charles (Chuck) Fillmore
</figureCaption>
<sectionHeader confidence="0.919028" genericHeader="method">
1 Lifetime Achievement Award (LTA)
</sectionHeader>
<bodyText confidence="0.999943690476191">
Since the purpose of this workshop is to cele-
brate Charles (Chuck) Fillmore, I would like to
take this opportunity to summarize some of the
points that I made in my introduction to Chuck’s
LTA talk at ACL-2012.
I had the rather unusual opportunity to see his
talk (a few times) before writing my introduction
because Chuck video-taped his talk in advance.1
I knew that he was unable to make the trip, but I
had not appreciated just how serious the situation
was. I found out well after the fact that the LTA
meant a lot to him, so much so that he postponed
an operation that he probably shouldn’t have
postponed (over his doctor’s objection), so that
he would be able to answer live questions via
Skype after the showing of his video tape.
I started my introduction by crediting Lily
Wong Fillmore, who understood just how much
Chuck wanted to be with us in Korea, but also,
just how impossible that was. Let me take this
opportunity to thank her once again for her con-
tributions to the video (technical lighting, edit-
ing, encouragement and so much more).
For many of us in my generation, C4C,
Chuck’s “The Case for Case” (Fillmore, 1968)
was the introduction to a world beyond Rational-
ism and Chomsky. This was especially the case
for me, since I was studying at MIT, where we
learned many things (but not Empiricism).
After watching Chuck’s video remarks, I was
struck by just how nice he was. He had nice
things to say about everyone from Noam Chom-
sky to Roger Schank. But I was also struck by
just how difficult it was for Chuck to explain
how important C4C was (or even what it said
and why it mattered). To make sure that the in-
ternational audience wasn’t misled by his up-
bringing and his self-deprecating humor, I
showed a page of “Minnesota Nice” stereotypes,
while reminding the audience that stereotypes
aren’t nice, but as stereotypes go, these stereo-
types are about as nice as they get.
</bodyText>
<footnote confidence="0.976554">
1 The video is available online at
https://framenet.icsi.berkeley.edu/fndrupal/node/5489.
</footnote>
<page confidence="0.988554">
6
</page>
<subsubsectionHeader confidence="0.380459">
Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 6–9,
</subsubsectionHeader>
<bodyText confidence="0.971545166666667">
Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics
Chuck, of course, is too nice to mention that
Fillmore (1967) had 6000 citations in Google
Scholar as of ACL-2012.2 He also didn’t men-
tion that he has another half dozen papers with
1000 or more citations including an ACL paper
on FrameNet (Baker et al, 1998).3
I encouraged the audience to read C4C. Not
only is it an example of a great linguistic argu-
ment, but it also demonstrates a strong command
of the classic literature as well as linguistic facts.
Our field is too “silo”-ed. We tend to cite recent
papers by our friends, with too little discussion
of seminal papers, fields beyond our own, and
other types of evidence that go beyond the usual
suspects. We could use more “Minnesota Nice.”
I then spent a few slides trying to connect the
dots between Chuck’s work and practical engi-
neering apps, suggesting a connection between
morphology and Message Understanding Con-
ference (MUC)-like tasks. We tend to think too
much about parsing (question 1), though ques-
tion 2 is more important for tasks such as infor-
mation extraction and semantic role labeling.
</bodyText>
<listItem confidence="0.996203">
1. What is the NP (and the VP) under S?
2. Who did what to whom?
</listItem>
<figureCaption confidence="0.7691675">
Figure 2: An example of information extraction
in commercial practice.
</figureCaption>
<bodyText confidence="0.990993230769231">
Context-Free Grammars are attractive for lan-
guages with more word order and less morphol-
ogy (such as English), but Case Grammar may
be more appropriate for languages with more
morphology and less word order (such as Latin,
Greek &amp; Japanese). I then gave a short (over-
simplified) tutorial on Latin and Japanese gram-
mar, suggesting a connection between Latin cas-
es (e.g., nominative, accusative, ablative, etc.)
and Japanese function words (e.g., the subject
2 Citations tend to increase over time, especially for
important papers like Fillmore (1967), which has
more than 7000 citations as of April 2014.
</bodyText>
<footnote confidence="0.669366">
3 See framenet.icsi.berkeley.edu for more recent pub-
lications such as Ruppenhofer et al (2006).
</footnote>
<bodyText confidence="0.995976333333333">
marker ga and the direct object marker wo, etc.).
From there, I mentioned a few historical connec-
tions
</bodyText>
<listItem confidence="0.999953">
• Case Grammar 4 Frames 4 FrameNet
• Valency4 4 Scripts (Roger Schank)
• Chuck 4 Sue Atkins (Lexicography)
</listItem>
<bodyText confidence="0.9842728">
The verb “give,” for example, requires three
arguments: Jones (agent) gave money (object) to
the school (beneficiary). In Latin, these argu-
ments are associated with different cases (nomi-
native, accusative, etc.). Under the frame view,
similar facts are captured with a commercial
transaction frame, which connects arguments
across verbs such as: buy, sell, cost and spend.5
Lexicographers such as Sue Atkins use patterns
such as:
</bodyText>
<listItem confidence="0.9971805">
• Risk &lt;valued object&gt; for &lt;situation&gt; |
&lt;purpose&gt;  |&lt;beneficiary&gt;  |&lt;motivation&gt;
</listItem>
<bodyText confidence="0.517511333333333">
to address similar alternations. My colleague
Patrick Hanks uses a similar pattern to motivate
our work on using statistics to find collocations:
</bodyText>
<listItem confidence="0.99845">
• Save &lt;good thing&gt; from &lt;bad situation&gt;
</listItem>
<bodyText confidence="0.75873">
Lexicographers use patterns like this to account
for examples such as:
</bodyText>
<listItem confidence="0.997882666666667">
• Save whales from extinction
• Ready to risk everything for what he be-
lieves.
</listItem>
<bodyText confidence="0.992312">
where we can’t swap the arguments:
</bodyText>
<listItem confidence="0.998111">
• *Save extinction from whales
</listItem>
<bodyText confidence="0.999793333333333">
The challenge for the next generation is to move
this discussion from lexicography and general
linguistics to computational linguistics. Which
of these representations are most appropriate for
practical NLP apps? Should we focus on part of
speech tagging statistics, word order or frames
</bodyText>
<footnote confidence="0.99666775">
4 http://en.wikipedia.org/wiki/Valency_(linguistics)
5 For more discussion of this table, see www.uni-
stuttgart.de/ linguistik/ sfb732/ files/
hamm framesemantics.pdf
</footnote>
<table confidence="0.980618">
VERB BUYER GOODS SELLER MONEY PLACE
buy subject object from for at
sell to subject object at
cost indirect on object at
spend object
subject
</table>
<page confidence="0.999001">
7
</page>
<bodyText confidence="0.999261075">
(typical predicate-argument relations and collo-
cations)?
Do corpus-based lexicography methods scale
up? Are they too manually intensive? If so,
could we use machine learning methods to speed
up manual methods? Just as statistical parsers
learn phrase structure rules such as S  NP VP,
we may soon expect machine learning systems to
learn valency, collocations and typical predicate-
argument relations.
How large do the corpora have to be to learn
what? When can we expect to learn frames? In
the 1980s, corpora were about 1 million words
(Brown Corpus). That was large enough to make
a list of common content words, and to train part
of speech taggers. A decade later, we had 100
million word corpora such as the British National
Corpus. This was large enough to see associa-
tions between common predicates and function
words such as “save” + “from.” Since then, with
the web, data has become more and more availa-
ble. Corpus growth may well be indexed to the
price of disks (improving about 1000x per dec-
ade). Coming soon, we can expect 1M2 word
corpora. (Google may already be there.) That
should be large enough to see associations of
pairs of content words (collocations). At that
point, machine learning methods should be able
to learn many of the patterns that lexicographers
have been talking about such as: risk valued ob-
ject for purpose.
We should train the next generation with the
technical engineering skills so they will be able
to take advantage of the opportunities, but more
importantly, we should encourage the next gen-
eration to read the seminal papers in a broad
range of disciplines so the next generation will
know about lots of interesting linguistic patterns
that will, hopefully, show up in the output of
their machine learning systems.
</bodyText>
<sectionHeader confidence="0.966558" genericHeader="method">
2 Empirical / Corpus-Based Traditions
</sectionHeader>
<bodyText confidence="0.999927888888889">
As mentioned above, there is a direct connection
between Fillmore and Corpus-Based Lexicogra-
phers such as Sue Atkins (Fillmore and Atkins,
1992). Corpus-based work has a long tradition
in lexicography, linguistics, psychology and
computer science, much of which is documented
in the Newsletter of the International Computer
Archive of Modern English (ICAME).6 Accord-
ing to Wikipedia,7 ICAME was co-founded by
</bodyText>
<page confidence="0.948374">
6
</page>
<footnote confidence="0.725658">
http://icame.uib.no/archives/No_1_ICAME_News.pdf
7 http://en.wikipedia.org/wiki/W. Nelson Francis
</footnote>
<bodyText confidence="0.998542642857143">
Nelson Francis, who is perhaps best known for
his collaboration with Henry Kučera on the
Brown Corpus.8 The Brown Corpus dates back
to the 1960s, though the standard reference was
published two decades later (Francis and Kučera,
1982).
The Brown Corpus has been extremely influ-
ential across a wide range of fields. According
to Google Scholar, the Brown Corpus has more
than 3000 citations. Many of these references
have been extremely influential themselves in a
number of different fields. At least9 ten of these
references have at least 2000 citations in at least
five fields:
</bodyText>
<listItem confidence="0.993795375">
• Information Retrieval (Baeza-Yates and
Ribeiro-Neto, 1999),
• Lexicography (Miller, 1995),
• Sociolinguistics (Biber, 1991),
• Psychology (MacWhinney, 2000)
• Computational Linguistics (Marcus et al,
1993; Jurafsky and Martin, 2000; Church
and Hanks, 1990; Resnik, 1995)
</listItem>
<bodyText confidence="0.99571368">
All of this work is empirical, though much of
it is not all that statistical. The Brown Corpus
and corpus-based methods have been particularly
influential in the Humanities, but less so in other
fields such as Machine Learning and Statistics. I
remember giving talks at top engineering univer-
sities and being surprised, when reporting exper-
iments based on the Brown Corpus, that it was
still necessary in the late 1990s to explain what
the Brown Corpus was, as well as the research
direction that it represented. While many of the-
se top universities were beginning to warm up to
statistical methods and machine learning, there
has always been less awareness of empiricism
and less sympathy for the research direction.
These days, I fear that the situation has not im-
proved all that much. In fact, there may be even
less room than ever for empirical work (unless it
is statistical).
It is ironic how much the field has changed
(and how little it has changed). Back in the early
1990s, it was difficult to publish papers that di-
gressed from the strict rationalist tradition that
dominated the field at the time. We created the
Workshop on Very Large Corpora (WVLC
</bodyText>
<footnote confidence="0.98788725">
8 http://en.wikipedia.org/wiki/Brown_Corpus
9 Google Scholar is an amazing resource, but not per-
fect. There is at least one error of omission: Manning
and SchUtze (1999).
</footnote>
<page confidence="0.998053">
8
</page>
<bodyText confidence="0.999974595238095">
evolved into EMNLP) to make room for a little
work of a different kind. But over the years, the
differences between the main ACL conference
and EMNLP have largely disappeared, and the
similarities between EMNLP and ICAME have
also largely disappeared. While it is nice to see
the field come together as it has, it is a shame
that these days, it is still difficult to publish a
paper that digresses from the strict norms that
dominate the field today, just as it used to be dif-
ficult years ago to publish papers that digressed
from the strict norms that dominated the field at
the time. Ironically, the names of our meetings
no longer make much sense. There is less dis-
cussion than there used to be of the E-word in
EMNLP and the C-word in WVLC.
One of the more bitter sweet moments at a
WVLC/EMNLP meeting was the invited talk by
Kučera and Francis at WVLC-1995,10 which
happened to be held at MIT. Just a few years
earlier, it would have been unimaginable that
such a talk could have been so appreciated at
MIT of all places, given so many years of such
hostility to all things empirical.
Their talk was the first and last time that I re-
member a standing ovation at WVLC/EMNLP,
mostly because of their contributions to the field,
but also because they both stood up for the hour
during their talk, even though they were well
past retirement (and standing wasn’t easy, espe-
cially for Francis).
Unfortunately, while there was widespread
appreciation for their accomplishments, it was
difficult for them to appreciate what we were
doing. I couldn’t help but notice that Henry was
trying his best to read other papers in the
WVLC-1995 program (including one of mine),
but they didn’t make much sense to him. It was
already clear then that the field had taken a hard
turn away from the Humanities (and C4C and
FrameNet) toward where we are today (more
Statistical than Empirical).
</bodyText>
<sectionHeader confidence="0.99929" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.999837714285714">
Fads come and fads go, but seminal papers such
as “Case for Case” are here to stay. As men-
tioned above, we should train the next generation
with the technical engineering skills to take ad-
vantage of the opportunities, but more important-
ly, we should encourage the next generation to
read seminal papers in a broad range of disci-
</bodyText>
<footnote confidence="0.9308855">
10 http://aclweb.org/anthology//W/W95/W95-
0100.pdf
</footnote>
<bodyText confidence="0.984091333333333">
plines so they know about lots of interesting lin-
guistic patterns that will, hopefully, show up in
the output of their machine learning systems.
</bodyText>
<sectionHeader confidence="0.98961" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999788239130434">
Ricardo Baeza-Yates and Berthier Ribeiro-Neto.1999.
Modern information retrieval. Vol. 463. ACM
Press, New York, NY, USA.
Collin F. Baker, Charles J. Fillmore, and John B.
Lowe. 1998. “The berkeley framenet project,”
ACL.
Douglas Biber. 1991. Variation across speech and
writing. Cambridge University Press.
Kenneth Church. 2011. A pendulum swung too far,
Linguistic Issues in Language Technology, 6(5).
Kenneth Church and Patrick Hanks. 1990 &amp;quot;Word as-
sociation norms, mutual information, and lexicog-
raphy.&amp;quot; Computational linguistics 16(1): 22-29
Charles J. Fillmore. 1968. “The Case for Case.” In
Bach and Harms (Ed.): Universals in Linguistic
Theory. Holt, Rinehart, and Winston, New York,
NY, USA, pp. 1-88.
Charles J. Fillmore and Beryl TS Atkins. 1992. “To-
ward a frame-based lexicon: The semantics of
RISK and its neighbors.” Frames, fields, and con-
trasts, pp. 75-102, Lawrence Erlbaum Associates,
Hillsdale, NJ, USA.
W. Nelson Francis and Henry Kučera. 1982 Frequen-
cy analysis of English usage. Houghton Mifflin,
Boston, MA, USA.
Dan Jurafsky and James H. Martin. 2000 Speech &amp;
Language Processing. Pearson Education India.
Brian MacWhinney. 2000. The CHILDES Project:
The database. Vol. 2. Psychology Press.
Christopher D. Manning and Hinrich Schütze.
1999. Foundations of statistical natural language
processing. MIT Press. Cambridge, MA, USA.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. &amp;quot;Building a large anno-
tated corpus of English: The Penn Tree-
bank.&amp;quot; Computational linguistics 19(2): 313-330.
George A. Miller. 1995. &amp;quot;WordNet: a lexical database
for English.&amp;quot; Communications of the ACM 38(11):
39-41.
Philip Resnik. 1995. &amp;quot;Using information content to
evaluate semantic similarity in a taxonomy.&amp;quot; arXiv
preprint cmp-lg/9511007
Josef Ruppenhofer, Michael Ellsworth, Miriam RL
Petruck, Christopher R. Johnson, and Jan
Scheffczyk. 2006. FrameNet II: Extended theory
and practice. framenet.icsi.berkeley.edu
</reference>
<page confidence="0.997094">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.095057">
<title confidence="0.99824">The Case for Empiricism (With and Without Statistics)</title>
<author confidence="0.939248">Kenneth</author>
<address confidence="0.718675333333333">1101 Kitchawan Yorktown Heights, NY USA</address>
<email confidence="0.998263">Kenneth.Ward.Church@gmail.com</email>
<abstract confidence="0.983041866666667">days we tend to use terms like if they are interchangeable, but it wasn’t always this way, and probably for good In Pendulum Swung Too Far 2011), I argued that graduate programs should make room for both Empiricism and Rationalism. We don’t know which trends will dominate the field tomorrow, but it is a good bet that it won’t be what’s hot today. We should prepare the next generation of students for all possible futures, or at least all probable futures. This paper argues for a diverse interpretation of Empiricism, one that makes room for everything from Humanities to Engineering (and then some).</abstract>
<note confidence="0.5039475">Figure 1: Lily Wong Fillmore (standing) and Charles (Chuck) Fillmore 1 Lifetime Achievement Award (LTA) Since the purpose of this workshop is to celebrate Charles (Chuck) Fillmore, I would like to take this opportunity to summarize some of the</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Ricardo Baeza-Yates</author>
<author>Berthier Ribeiro-Neto 1999</author>
</authors>
<title>Modern information retrieval.</title>
<volume>463</volume>
<publisher>ACM Press,</publisher>
<location>New York, NY, USA.</location>
<marker>Baeza-Yates, 1999, </marker>
<rawString>Ricardo Baeza-Yates and Berthier Ribeiro-Neto.1999. Modern information retrieval. Vol. 463. ACM Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project,”</title>
<date>1998</date>
<publisher>ACL.</publisher>
<contexts>
<context position="3361" citStr="Baker et al, 1998" startWordPosition="570" endWordPosition="573">ice, but as stereotypes go, these stereotypes are about as nice as they get. 1 The video is available online at https://framenet.icsi.berkeley.edu/fndrupal/node/5489. 6 Proceedings of Frame Semantics in NLP: A Workshop in Honor of Chuck Fillmore (1929–2014), pages 6–9, Baltimore, Maryland USA, June 27, 2014. c�2014 Association for Computational Linguistics Chuck, of course, is too nice to mention that Fillmore (1967) had 6000 citations in Google Scholar as of ACL-2012.2 He also didn’t mention that he has another half dozen papers with 1000 or more citations including an ACL paper on FrameNet (Baker et al, 1998).3 I encouraged the audience to read C4C. Not only is it an example of a great linguistic argument, but it also demonstrates a strong command of the classic literature as well as linguistic facts. Our field is too “silo”-ed. We tend to cite recent papers by our friends, with too little discussion of seminal papers, fields beyond our own, and other types of evidence that go beyond the usual suspects. We could use more “Minnesota Nice.” I then spent a few slides trying to connect the dots between Chuck’s work and practical engineering apps, suggesting a connection between morphology and Message </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. “The berkeley framenet project,” ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>Variation across speech and writing.</title>
<date>1991</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="9730" citStr="Biber, 1991" startWordPosition="1586" endWordPosition="1587">n Corpus.8 The Brown Corpus dates back to the 1960s, though the standard reference was published two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus</context>
</contexts>
<marker>Biber, 1991</marker>
<rawString>Douglas Biber. 1991. Variation across speech and writing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
</authors>
<title>A pendulum swung too far,</title>
<date>2011</date>
<journal>Linguistic Issues in Language Technology,</journal>
<volume>6</volume>
<issue>5</issue>
<marker>Church, 2011</marker>
<rawString>Kenneth Church. 2011. A pendulum swung too far, Linguistic Issues in Language Technology, 6(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.&amp;quot;</title>
<date>1990</date>
<journal>Computational linguistics</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="9862" citStr="Church and Hanks, 1990" startWordPosition="1603" endWordPosition="1606">s and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus was, as well as the research direction that it represented. While many of these top universities were beginning to warm up to stati</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Church and Patrick Hanks. 1990 &amp;quot;Word association norms, mutual information, and lexicography.&amp;quot; Computational linguistics 16(1): 22-29</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>The Case for Case.” In Bach and Harms (Ed.): Universals in Linguistic Theory.</title>
<date>1968</date>
<pages>1--88</pages>
<location>Holt, Rinehart, and Winston, New York, NY, USA,</location>
<contexts>
<context position="2059" citStr="Fillmore, 1968" startWordPosition="352" endWordPosition="353">him, so much so that he postponed an operation that he probably shouldn’t have postponed (over his doctor’s objection), so that he would be able to answer live questions via Skype after the showing of his video tape. I started my introduction by crediting Lily Wong Fillmore, who understood just how much Chuck wanted to be with us in Korea, but also, just how impossible that was. Let me take this opportunity to thank her once again for her contributions to the video (technical lighting, editing, encouragement and so much more). For many of us in my generation, C4C, Chuck’s “The Case for Case” (Fillmore, 1968) was the introduction to a world beyond Rationalism and Chomsky. This was especially the case for me, since I was studying at MIT, where we learned many things (but not Empiricism). After watching Chuck’s video remarks, I was struck by just how nice he was. He had nice things to say about everyone from Noam Chomsky to Roger Schank. But I was also struck by just how difficult it was for Chuck to explain how important C4C was (or even what it said and why it mattered). To make sure that the international audience wasn’t misled by his upbringing and his self-deprecating humor, I showed a page of </context>
</contexts>
<marker>Fillmore, 1968</marker>
<rawString>Charles J. Fillmore. 1968. “The Case for Case.” In Bach and Harms (Ed.): Universals in Linguistic Theory. Holt, Rinehart, and Winston, New York, NY, USA, pp. 1-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Beryl TS Atkins</author>
</authors>
<title>Toward a frame-based lexicon: The semantics of RISK and its neighbors.” Frames, fields, and contrasts,</title>
<date>1992</date>
<pages>75--102</pages>
<location>Lawrence</location>
<contexts>
<context position="8660" citStr="Fillmore and Atkins, 1992" startWordPosition="1430" endWordPosition="1433">sk valued object for purpose. We should train the next generation with the technical engineering skills so they will be able to take advantage of the opportunities, but more importantly, we should encourage the next generation to read the seminal papers in a broad range of disciplines so the next generation will know about lots of interesting linguistic patterns that will, hopefully, show up in the output of their machine learning systems. 2 Empirical / Corpus-Based Traditions As mentioned above, there is a direct connection between Fillmore and Corpus-Based Lexicographers such as Sue Atkins (Fillmore and Atkins, 1992). Corpus-based work has a long tradition in lexicography, linguistics, psychology and computer science, much of which is documented in the Newsletter of the International Computer Archive of Modern English (ICAME).6 According to Wikipedia,7 ICAME was co-founded by 6 http://icame.uib.no/archives/No_1_ICAME_News.pdf 7 http://en.wikipedia.org/wiki/W. Nelson Francis Nelson Francis, who is perhaps best known for his collaboration with Henry Kučera on the Brown Corpus.8 The Brown Corpus dates back to the 1960s, though the standard reference was published two decades later (Francis and Kučera, 1982).</context>
</contexts>
<marker>Fillmore, Atkins, 1992</marker>
<rawString>Charles J. Fillmore and Beryl TS Atkins. 1992. “Toward a frame-based lexicon: The semantics of RISK and its neighbors.” Frames, fields, and contrasts, pp. 75-102, Lawrence Erlbaum Associates, Hillsdale, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kučera</author>
</authors>
<title>Frequency analysis of English usage.</title>
<date>1982</date>
<location>Houghton Mifflin, Boston, MA, USA.</location>
<contexts>
<context position="9259" citStr="Francis and Kučera, 1982" startWordPosition="1512" endWordPosition="1515">Fillmore and Atkins, 1992). Corpus-based work has a long tradition in lexicography, linguistics, psychology and computer science, much of which is documented in the Newsletter of the International Computer Archive of Modern English (ICAME).6 According to Wikipedia,7 ICAME was co-founded by 6 http://icame.uib.no/archives/No_1_ICAME_News.pdf 7 http://en.wikipedia.org/wiki/W. Nelson Francis Nelson Francis, who is perhaps best known for his collaboration with Henry Kučera on the Brown Corpus.8 The Brown Corpus dates back to the 1960s, though the standard reference was published two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1</context>
</contexts>
<marker>Francis, Kučera, 1982</marker>
<rawString>W. Nelson Francis and Henry Kučera. 1982 Frequency analysis of English usage. Houghton Mifflin, Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech &amp; Language Processing.</title>
<date>2000</date>
<publisher>Pearson Education</publisher>
<contexts>
<context position="9838" citStr="Jurafsky and Martin, 2000" startWordPosition="1599" endWordPosition="1602">d two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus was, as well as the research direction that it represented. While many of these top universities were begin</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Dan Jurafsky and James H. Martin. 2000 Speech &amp; Language Processing. Pearson Education India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
</authors>
<title>The CHILDES Project: The database.</title>
<date>2000</date>
<volume>2</volume>
<publisher>Psychology Press.</publisher>
<contexts>
<context position="9763" citStr="MacWhinney, 2000" startWordPosition="1590" endWordPosition="1591">dates back to the 1960s, though the standard reference was published two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus was, as well as the research dir</context>
</contexts>
<marker>MacWhinney, 2000</marker>
<rawString>Brian MacWhinney. 2000. The CHILDES Project: The database. Vol. 2. Psychology Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schütze</author>
</authors>
<title>Foundations of statistical natural language processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA, USA.</location>
<marker>Manning, Schütze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schütze. 1999. Foundations of statistical natural language processing. MIT Press. Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank.&amp;quot;</title>
<date>1993</date>
<journal>Computational linguistics</journal>
<volume>19</volume>
<issue>2</issue>
<pages>313--330</pages>
<contexts>
<context position="9811" citStr="Marcus et al, 1993" startWordPosition="1595" endWordPosition="1598">ference was published two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus was, as well as the research direction that it represented. While many of these </context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. &amp;quot;Building a large annotated corpus of English: The Penn Treebank.&amp;quot; Computational linguistics 19(2): 313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: a lexical database for English.&amp;quot;</title>
<date>1995</date>
<journal>Communications of the ACM</journal>
<volume>38</volume>
<issue>11</issue>
<pages>39--41</pages>
<contexts>
<context position="9696" citStr="Miller, 1995" startWordPosition="1582" endWordPosition="1583">ation with Henry Kučera on the Brown Corpus.8 The Brown Corpus dates back to the 1960s, though the standard reference was published two decades later (Francis and Kučera, 1982). The Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. &amp;quot;WordNet: a lexical database for English.&amp;quot; Communications of the ACM 38(11): 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity in a taxonomy.&amp;quot; arXiv preprint cmp-lg/9511007</title>
<date>1995</date>
<contexts>
<context position="9877" citStr="Resnik, 1995" startWordPosition="1607" endWordPosition="1608"> Brown Corpus has been extremely influential across a wide range of fields. According to Google Scholar, the Brown Corpus has more than 3000 citations. Many of these references have been extremely influential themselves in a number of different fields. At least9 ten of these references have at least 2000 citations in at least five fields: • Information Retrieval (Baeza-Yates and Ribeiro-Neto, 1999), • Lexicography (Miller, 1995), • Sociolinguistics (Biber, 1991), • Psychology (MacWhinney, 2000) • Computational Linguistics (Marcus et al, 1993; Jurafsky and Martin, 2000; Church and Hanks, 1990; Resnik, 1995) All of this work is empirical, though much of it is not all that statistical. The Brown Corpus and corpus-based methods have been particularly influential in the Humanities, but less so in other fields such as Machine Learning and Statistics. I remember giving talks at top engineering universities and being surprised, when reporting experiments based on the Brown Corpus, that it was still necessary in the late 1990s to explain what the Brown Corpus was, as well as the research direction that it represented. While many of these top universities were beginning to warm up to statistical methods </context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. &amp;quot;Using information content to evaluate semantic similarity in a taxonomy.&amp;quot; arXiv preprint cmp-lg/9511007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Michael Ellsworth</author>
<author>Miriam RL Petruck</author>
<author>Christopher R Johnson</author>
<author>Jan Scheffczyk</author>
</authors>
<title>FrameNet II: Extended theory and practice. framenet.icsi.berkeley.edu</title>
<date>2006</date>
<contexts>
<context position="4997" citStr="Ruppenhofer et al (2006)" startWordPosition="843" endWordPosition="846">d less morphology (such as English), but Case Grammar may be more appropriate for languages with more morphology and less word order (such as Latin, Greek &amp; Japanese). I then gave a short (oversimplified) tutorial on Latin and Japanese grammar, suggesting a connection between Latin cases (e.g., nominative, accusative, ablative, etc.) and Japanese function words (e.g., the subject 2 Citations tend to increase over time, especially for important papers like Fillmore (1967), which has more than 7000 citations as of April 2014. 3 See framenet.icsi.berkeley.edu for more recent publications such as Ruppenhofer et al (2006). marker ga and the direct object marker wo, etc.). From there, I mentioned a few historical connections • Case Grammar 4 Frames 4 FrameNet • Valency4 4 Scripts (Roger Schank) • Chuck 4 Sue Atkins (Lexicography) The verb “give,” for example, requires three arguments: Jones (agent) gave money (object) to the school (beneficiary). In Latin, these arguments are associated with different cases (nominative, accusative, etc.). Under the frame view, similar facts are captured with a commercial transaction frame, which connects arguments across verbs such as: buy, sell, cost and spend.5 Lexicographers</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, Scheffczyk, 2006</marker>
<rawString>Josef Ruppenhofer, Michael Ellsworth, Miriam RL Petruck, Christopher R. Johnson, and Jan Scheffczyk. 2006. FrameNet II: Extended theory and practice. framenet.icsi.berkeley.edu</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>