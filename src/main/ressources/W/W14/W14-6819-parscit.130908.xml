<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003692">
<title confidence="0.989109">
An Introduction to BLCU Personal Attributes Extraction System
</title>
<author confidence="0.966694">
Dong YU, Cheng YU, Gongbo TANG, Qin QU, Chunhua LIU, Yue TIAN, Jing YI
</author>
<affiliation confidence="0.7723635">
College of Information Science, Beijing Language and Cultural University
Beijing 10083, China
</affiliation>
<email confidence="0.971681">
yudong_blcu@126.com
</email>
<sectionHeader confidence="0.99336" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999972">
We describe our methods for share task
of personal attributes extraction. We di-
vide all 25 attributes into several catego-
ries and propose 4 kinds of pipelines to
carry out value extraction. There are two
stages in the process. The first stage uses
CRF model or regular expression based
extractor to produce initial answers. In
the second stage, we propose two me-
thods to filter out mistake answers: pro-
tagonist dependency relationship based
filter and attribute keywords based filter.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.956678230769231">
In this paper, we describe the BLCU-PAE sys-
tem for CIPS-SIGHAN 2014 bakeoffs. The Per-
sonal Attributes Extraction (PAE) in Chinese
Text Task is designed to extract person specific
attributes, like date of birth and death, family
relationships, education, title etc. from unstruc-
tured Chinese texts. The corresponding tech-
niques play an important role in information ex-
traction, event tracking, entity disambiguation
and other related research areas.
In the task, the incomplete attributes of a tar-
get person are defined as Slots, i.e. the extracted
attribute value need to be filled into these slots.
There are 3 kinds of slots, name slots, value slots
and string slots, in which only entity name, num-
ber/time and string can be filled in. Single-value
slots have only one correct answer while list-
value slots have a set of answers. There are total-
ly 25 attributes need to be extracted, as shown in
Table 1.
Slot filling task has been one of shared tasks in
the TAC KBP workshop [Ji and Grishman, 2011]
science 2009. In this area, earlier systems gener-
ally use one main pipeline that contains 3 stages:
document retrieval, answer extraction, and an-
swer combination. Supervised learning normally
leads to a reasonably good performance. Both
bootstrapping and rule based pattern matching
with trigger words are used in [Li, et al., 2013].
Active learning techniques are also used in the
task [Chen, et al, 2010]. UNED system introduc-
es a graph structure to solve the problem [ Garri-
do, et al., 2013]. CMUML uses distant supervi-
sion and CRF-based structured prediction for
producing the final answers [Kisiel, et al., 2013].
Up to now, slot filling remains a very challeng-
ing task; most of the shortfall reflects inadequa-
cies in the answer extraction stage.
Type Attribute
Single city_of _birth, city_of_death, coun-
slots try_of_birth, country_of_death,
State_or_province_of_birth,
State_or_province_of_death,
date_of_birth, date_of_death,
cause_of_death, age
alternative_name, children, ci-
ties_of_residence, coun-
tries_of_residence , parents, oth-
er_family, member_of, siblings, em-
List ployee_of, spouses, school_attended,
slots religion, charges, titles,
state_or_province_of_residence
</bodyText>
<tableCaption confidence="0.993047">
Table 1: List of all attributes
</tableCaption>
<bodyText confidence="0.998949846153846">
Our system uses a mixture framework consists
of supervised learning and rule based extractor
and human knowledge database. We divide 25
attributes into several groups. Each group uses a
specific combination of methods for value ex-
traction. Protagonist dependency relationship and
key words of attribute are used to filter out sus-
picious values.
The rest of the paper is organized as follows.
Section 2 gives an overview of our system. Sec-
tion 3 describes models and methods used in the
system in detail. Section 4 gives evaluation re-
sults and analysis.
</bodyText>
<page confidence="0.943614">
120
</page>
<note confidence="0.8389205">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 120–125,
Wuhan, China, 20-21 October 2014
</note>
<sectionHeader confidence="0.98717" genericHeader="introduction">
2 Overview
</sectionHeader>
<bodyText confidence="0.999916444444445">
At a high level, our PAE system takes a doc-
ument d as input, and produces a set of attributes,
each of which contains a specific type t and a
value v. The whole process makes use of a large
count of annotated biography corpus collected
from BaiduBaike1 and Chinese Wikipedia2. Both
supervised machine learning and human de-
signed rules are used for attributes extraction,
describes in subsection 2.1.
</bodyText>
<subsectionHeader confidence="0.975818">
2.1 The framework
</subsectionHeader>
<bodyText confidence="0.999693111111111">
In order to explore various knowledge of person
attribute, a large number of biography web pages
are collected and divided into sentences. For
each attribute, we select a certain number of sen-
tences that contain attribute value, label the posi-
tion of each value as training data. Meanwhile,
attribute value context words are used as key-
words for attribute extraction. Figure 1 is the
overall framework of our system.
</bodyText>
<figure confidence="0.333798">
Post process
Answer set generation
</figure>
<figureCaption confidence="0.999076">
Figure 1: Framework of the system
</figureCaption>
<bodyText confidence="0.994958">
As shown in Figure 1, the PAE process con-
tains 4 stages:
</bodyText>
<listItem confidence="0.9999605">
• Pre-process stage,
• First step extraction,
• Results refine stage,
• Post-process stage.
</listItem>
<bodyText confidence="0.995346">
In the pre-process stage, we divide a test doc-
ument into sentences, and then carry out a NLP-
pipeline on each sentence. Conversely, the post-
</bodyText>
<footnote confidence="0.998606">
1 http://www.baike.baidu.com/
2 http://zh.wikipedia.org
</footnote>
<bodyText confidence="0.999672">
process stage needs to combine all values ex-
tracted from these sentences and produce a final
answer set. We will describe both stages in detail
in Section 3.
In the first step of extraction, two kinds of ex-
tractors are proposed. The first one is CRF ex-
tractor. For an attribute, if its context features are
obviously difference from others and it has a
number of labeled sentences, then attribute ex-
traction can be seen as a sequence labeling prob-
lem and CRF model can be used to solve it.
Otherwise, if two or more attributes have simi-
lar context, they will have similar features, so
CRF cannot distinguish one from another. For
example, attributes of Data of birth and Date of
death often appear together in biographies. Data
sparse is another obstacle of using CRF, as
attribute of “Religion” only has dozens of sam-
ples. In this situation, regular expression is a bet-
ter and more direct way for attribute extraction.
Both CRF and regular expression make mis-
takes during extraction. In our test, there are
mainly two kinds of errors:
</bodyText>
<listItem confidence="0.9997725">
• Protagonist mismatch,
• Error values caused by models.
</listItem>
<bodyText confidence="0.9979695">
So results refine stage is required. In our system,
dependency parser is used to filter out values that
not related to the protagonist of test document.
Keywords of attributes are collected and used to
filter out error values. We will describe these
methods in detail in section 3.
</bodyText>
<subsectionHeader confidence="0.999853">
2.2 Categories of Attributes
</subsectionHeader>
<bodyText confidence="0.999931318181818">
The task needs to extract 25 attributes and
some of them vary widely from others. Build a
model for each attribute can be very consume. So
we classify all attributes into several categories,
and adopt different extraction pipelines. There
are 4 kinds of extraction pipelines in our system.
Attribute categories and their extraction pipeline
are shown in Table 2.
We train CRF models for attributes related to
name entities, such as places, organizations,
names. Attributes of city_of_birth, coun-
try_of_birth, and state_or_province_of_birth are
all place extraction problem, so we train a same
CRF model for these attributes. So do place of
death and residence.
For attributes that are considered unsuitable
for CRF, we use rule based regular expression to
extract answers in the first step extraction, in-
cluding date of birth and death and religion.
For attributes that highly related to person,
protagonist dependency between person and val-
ues can effectively find out error answers. For
</bodyText>
<figure confidence="0.998729538461539">
biography Test document
pages
Pre-process
Annotated
data
Keywords
sets
Results refine
Protagonist Keywords
dependency of atrributes
First step extraction
CRF Extractor Regular expression
Extractor
</figure>
<page confidence="0.985646">
121
</page>
<bodyText confidence="0.97917675">
other attributes, for instance titles, member_of,
cause_of_death. Other attributes use key words
concluded from the training data to refine the
answers.
</bodyText>
<table confidence="0.999800705882353">
Extraction pipelines Attribute Categories
CRF only alternate_names
CRF + age,
protagonist cause_of_death,
dependency charges,
employee_of,
member_of,
titles,
places of death,
places of birth,
places of residence
Regular expression religion
only
Regular expression + date_of_birth,
keywords date_of_death,
schools_attended,
family relationships
</table>
<tableCaption confidence="0.983356">
Table 2: Attribute Categories
</tableCaption>
<subsectionHeader confidence="0.980837">
2.3 Resource and toolkits used
</subsectionHeader>
<bodyText confidence="0.999822764705882">
We collected more than 40k biographies pages
from BaiduBaike and about 6k biographies pages
from WikiPedia. The original webpage is very
noisy, so we did not use all data for training but
select good samples as training data.
We mainly used two toolkits for NLP pipeline,
including Chinese word segmentation, POS tag-
ging, NER and dependency parsing: SWJTU
Yebol3 Chinese word segmentation toolkit and
LTP-Cloud4[Che, et al., 2010]. The segmentation
accuracy of Yebol can achieve 99.8% and it also
used to label time string, place, person name etc. .
LTP-Cloud is a cloud based Chinese analysis
system that provides dependency parsing, POS
tagging and semantic parsing services.
We use CRF++5 toolkit to train CRF based ex-
tractor.
</bodyText>
<subsectionHeader confidence="0.993573">
2.4 Data annotation
</subsectionHeader>
<bodyText confidence="0.9986922">
We annotate start and end of attribute values
in sentence level according to the task guideline.
Here is an example for employee_of : “08 年 7 月
4 日离职【新浪】加入【盛大文学】,任
CEO。” We annotate each category a data set
</bodyText>
<footnote confidence="0.998186">
3 http://ics.swjtu.edu.cn/
4 http://www.ltp-cloud.com/
5 http://sourceforge.jp/projects/sfnet_crfpp/
</footnote>
<bodyText confidence="0.999735285714286">
individually. As we used rule-based methods for
extraction, such as children, parents, religion, etc,
we just summarized their samples and features
from training data, and did not annotate them one
by one. Finally, we annotate about 25K of posi-
tive examples and equal number of negative ex-
amples for CRF based extractors.
</bodyText>
<sectionHeader confidence="0.991306" genericHeader="method">
3 Methods and models
</sectionHeader>
<subsectionHeader confidence="0.998608">
3.1 Pre-process
</subsectionHeader>
<bodyText confidence="0.999068">
We adopt a NLP pipeline for each document.
Workflow is shown in Figure 2.
</bodyText>
<figure confidence="0.995832666666667">
Test document
Sentence segmentation
Word segmentation and POS tag
Name entity recognition
Dependency parsing
Sentence set
</figure>
<figureCaption confidence="0.999956">
Figure 2: Workflow of pre-process
</figureCaption>
<bodyText confidence="0.998963375">
Pre-process stage is carried out on both train
biographies and test documents. We use punctua-
tion to split a document into sentences. Name
entity recognition includes time string, person
name, place and organization. Dependency pars-
ing is used to find connections between any two
words. Pre-process produces a set of sentences
all related to document protagonist.
</bodyText>
<subsectionHeader confidence="0.99346">
3.2 CRF models training
</subsectionHeader>
<bodyText confidence="0.9997126875">
As mentioned in 2.2, we totally train 10 CRF
models. For each model, we use corresponding
set of annotated sentences as positive samples,
where all values of specific attribute are labeled.
Additionally, in order to enhance the model, we
also select equal number of negative samples
without the attribute. Both positive and negative
samples are used for training CRF model.
We use general feature template during train-
ing process, mainly include context words and
POS tags of context words. The number of train-
ing samples for each model is listed in Table 3.
At prediction time, sentences of test document
are segmented into word, and tokenized into
CRF format, and then the model can tag out all
predicted values for the attribute.
</bodyText>
<page confidence="0.998682">
122
</page>
<tableCaption confidence="0.999785">
Table 3: The statistic of annotations
</tableCaption>
<subsectionHeader confidence="0.971348">
3.3 Protagonist dependency based filter
</subsectionHeader>
<bodyText confidence="0.999373205128205">
CRF based attribute extractor can effectively
recognize the existence of attributes in a test sen-
tence and can label out value positions. However,
in PAE task, we only need to extract attributes
belongs to the protagonist of a test document.
For sentences that refers to more than one person,
match extracted values with the protagonist can
be very difficult. For example, in sentence “他的
妹妹 Isobel 因肺炎去世,卡罗瑟斯与妻子
Helen 前 往 ”,“ 肺 炎 (pneumonia)” is not
Cause_of_death of protagonist “卡罗瑟斯” but
his sister, while CRF always recognize it as a
value.
Dependence relationship can help filter out
mismatch values. For a test sentence, dependen-
cy parsing can convert it into a tree, in which
nodes are words. Relationship between any two
words can be described by a connected path in
the tree. The method is described as follows.
In our test, for each attribute value extracted
by CRF or regular expression, we find its head
verb and the closest person name in a same sub
tree, if the person is protagonist, then we believe
that the value is valid. Otherwise, we filter out
the value. If test sentence does not have any per-
son or reference, we keep all extracted results by
default. Figure X shows an instance of the idea.
Sentence “何雨春,著名画家,1957 年出生
于 大 连 。 ” involves a title “ 画 家 ” and a
place_of_birth “大连” and a person “何雨春” .
As shown in Figure 3, two values are dominated
by the same verb “出生”, the person also in the
same sub tree, so both values are available.
On the contrary, in the last instance, the value
“肺炎” is dominated by verb “去世”, the closest
person dominated by the same verb is “Isobel”,
while protagonist “卡罗瑟斯” is dominated by
verb “前往”, so the value is filtered out. As
shown in Figure 4.
</bodyText>
<figureCaption confidence="0.988005">
Figure 3: A positive example
</figureCaption>
<figure confidence="0.97659825">
Root
肺炎
(cause of death) Isobel
(person name)
</figure>
<figureCaption confidence="0.999958">
Figure 4: A negative example
</figureCaption>
<bodyText confidence="0.999963125">
In the third instance, “真德秀是南宋后期与
魏了翁齐名的理学家。”, there are two persons
“真德秀” and “魏了翁”, and a title “理学家”.
Literally, 魏了翁 is closer to the title than 真德
秀, but in dependency tree, 真德秀 and 理学家
are dominated by same verb “是” while 魏了翁
is dominated by verb “齐名”, so we think the
value “理学家” refers to 真德秀.
</bodyText>
<subsectionHeader confidence="0.979438">
3.4 Keywords based filter
</subsectionHeader>
<bodyText confidence="0.999308384615385">
Another type of mistakes in our system is
caused by defect of models, for example, in
“2005.11-2006.1 双 流 县 中和 镇 人民 政府 工
作 , ”, the system incorrectly labels
“2005.11” as date_of_birth in the first step. We
find that contexts of this kind of error values are
obviously different from right ones. So high fre-
quency context words of attributes can help filter
out error values.
The method firstly collects all context words
of positive samples of a specific attribute, select
a set of words with high frequency as keywords.
At test time, we require that there is at least one
</bodyText>
<figure confidence="0.839299739130435">
Model Positive Negative
Examples Examples
age 513 464
places of birth 10717 1533
places of death 733 1216
places of residence 2194 705
cause_of_death 2122 184
charges 353 939
employee_of 1678 2383
member_of 2330 396
titles
alternate_names
2626 281
1230
692
因
前往
v.
妹妹
去世
v.
卡罗瑟斯
(protagonist)
</figure>
<page confidence="0.997238">
123
</page>
<bodyText confidence="0.997238888888889">
keyword in context of extracted value. Otherwise,
the extracted value will be abandoned.
Key words based filter can effectively im-
prove accuracy of CRF model. However, it has
influence on recall rate. In our system, we collect
keywords and used for extracting 5 kinds of fa-
milial relationships, schools attended, alternate
names, date of death and birth. Table 4 gives
some of keywords we used in our system.
</bodyText>
<table confidence="0.998478875">
Attribute Keywords
Schools_a 毕JL; 读; 学习; 培训; 肄JL;
ttended 考 入; 深造; 获得; 学位
siblings R; 哥; C; 妹; 弟
spouse 妻; 老婆; AIM妇; 爱人; 未M
夫; 老公; 丈夫;
Date_of_ 逝; 牺牲; 卒; 身亡; 去世;
death 薨; 死; 辞世; 病故; 殁
</table>
<tableCaption confidence="0.838941">
Tabel 4: Examples of attribute keywords
</tableCaption>
<subsectionHeader confidence="0.952143">
3.5 Rule and knowledge based methods
</subsectionHeader>
<bodyText confidence="0.9999626">
Rule based extractor is designed by using reg-
ular expression. We use this method in the first
step of extraction in date_of_birth, date_of_
death, and religion. The first two have very simi-
lar contexts so we cannot use CRF to distinguish
between them. For the last one, the number of
training samples is too small to train a CRF
model.
In addition to above methods, human know-
ledge is also involved in the system, including:
</bodyText>
<listItem confidence="0.999944333333333">
• Country-state/province database,
• Family relationship database,
• Religion database.
</listItem>
<bodyText confidence="0.999932142857143">
As mentioned in 2.2, we train 3 CRF models
that can label out birth place, death place and
residence place in a test document, regardless
level of places. However the PAE task needs to
recognize city, state/province and country of
places in detail. So we collect a database that
contains all countries and most of
states/provinces, and divide extracted place sting
into different levels, place that is not in database
is regarded as city.
Similarly, all family relationships and all reli-
gions are also collected. Both databases are used
for designing regular expressions and results re-
fine to produce more accurate values.
</bodyText>
<subsectionHeader confidence="0.991753">
3.6 Post-process and answer generation
</subsectionHeader>
<bodyText confidence="0.99997525">
The whole PAE process is done in sentence
level and it produces a collect of labeled sen-
tences, one sentence has only one kind of
attribute.
In the post-process stage, we need to combine
all extracted values together and compute offset
of position for each value in original document to
generate final XML format answer set. In which
all values are written as a record that contain
name of protagonist, original document file name,
attribute name, attribute values and attribute val-
ue offset in the document.
</bodyText>
<sectionHeader confidence="0.999874" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.997058">
4.1 Evaluation matrices
</subsectionHeader>
<bodyText confidence="0.99998875">
The PAE task takes the same evaluation me-
trics adopted in the slot filling of TAC KBP. For
single attributes, system score is computed by (1),
where we set NumCorrect to 1.0 when it is zero.
</bodyText>
<figure confidence="0.89874825">
NumCorrect
NumSingleSlot
Score E ListSlotYalue 2
1&apos;St — NumListSlots ( )
</figure>
<bodyText confidence="0.916756538461538">
For list attributes, system score is computed by
(2), in which ListSlotYalue is defined by (3),
Where Fβ = 2 (to weight precision over recall),
IP = instance precision and IR = instance recall .
Also we set ListSlotYalue to 0.0, when both IP
and IR are zero. System performance is finally
evaluated by (4), that is the average of single
attributes evaluation score and list attributes
evaluation score.
SFvalue _ � (Scoresingle + Scorelist) (4)
an
string_begin
d string_end are ignored.
</bodyText>
<subsectionHeader confidence="0.962938">
4.2 Evaluation results
</subsectionHeader>
<bodyText confidence="0.820201666666667">
shows that multi-value attri
butes is more difficult
to extract.
</bodyText>
<figure confidence="0.993339090909091">
ListSlotYalue
_
(
F � +1)*IP*IR
F * (IP + IR)
�
2
(3)
2
Scoresingle _
(1)
</figure>
<bodyText confidence="0.999208923076923">
In the evaluation, both the lenient evaluation
and strict evaluation are performed. In the strict
evaluation, all instance attributes are compared
to the answers while in the lenient evaluation, the
offset
In evaluation, there are totally 90 test persons
and 233 test documents. Table 5 shows the eval-
uation results of our system and the best perfor-
mance system.
In general, there is still a big gap between our
system and the best one. In our system, perfor-
mances of lenient and strict results are similar.
Single score is obviously better than list score,
</bodyText>
<page confidence="0.993354">
124
</page>
<table confidence="0.999835833333333">
Evaluation Single List SF
Score Score Value
Lenient (best) 0.6710 0.3438 0.5074
Lenient (ours) 0.4286 0.1888 0.3087
Strict (best) 0.6450 0.3340 0.4895
Strict (ours) 0.4113 0.1739 0.2926
</table>
<tableCaption confidence="0.714181">
Table5: The evaluation results
</tableCaption>
<subsectionHeader confidence="0.991659">
4.3 Analysis
</subsectionHeader>
<bodyText confidence="0.999992375">
Our system still has a lot room for improve-
ments. The first one is to make better use of con-
text in phase level other than sentence level. In
our own test, we get more than 0.7 IP score in
sentence attributes extraction. However, when it
comes to document level, relevance between sen-
tences are more important. In this situation, ana-
phora resolution and entity link can help to im-
prove the performance of system.
In our system, most of values are extracted
based on supervised learning. It is a great chal-
lenge for data pre-process and annotation. Boot-
strapping style methods can help mining more
samples, and active learning framework can be a
more effective method to obtain a higher know-
ledge coverage rate.
</bodyText>
<sectionHeader confidence="0.99617" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.962646">
The research work is partially funded by the
Natural Science Foundation of China (No.
61300081, 61170162), and the Fundamental Re-
search Funds for the Central Universities in
BLCU (No. 14YJ03005).
</bodyText>
<sectionHeader confidence="0.963762" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.999803074074074">
Heng Ji and Raslfph Grishman. 2011. Knowledge
Base Population: Successful Approaches and Chal-
lenges. Proc. 49th Annual Meeting Assn. Computa-
tional Linguistics.
Yan Li, Yichang Zhang, Doyu Li, Xin Tong, Jianlong
Wang, Naiche Zuo, Ying Wang, Weiran Xu,
Guang Chen, Jun Guo. 2013. PRIS at Knowledge
Base Population 2013. Proc. TAC 2013 Workshop.
Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li,
Wen-Pin Lin, Matthew Snover, Javier Artiles, Ma-
rissa Passantino and Heng Ji. 2010. CUNYB-
LENDER TAC-KBP2010 Entity Linking and Slot
Filling System Description. Proc. TAC 2010 Work-
shop.
Guillermo Garrido, Anselmo Peñas and Bernardo
Cabaleiro. 2013. UNED Slot Filling and Temporal
Slot Filling systems at TAC KBP 2013. System de-
scription. Proc. TAC 2013 Workshop.
Bryan Kisiel, Justin Betteridge, Matt Gardner, Jayant
Krishnamurthy, Ndapa Nakashole, Mehdi Samadi,
Partha Talukdar, Derry Wijaya, Tom Mitchell.
2013. CMUML System for KBP 2013 Slot Filling.
Proc. TAC 2013 Workshop.
Wanxiang Che, Zhenghua Li, Ting Liu. LTP: A Chi-
nese Language Technology Platform. In Proceed-
ings of the Coling 2010:Demonstrations. 2010,
pp13-16, Beijing, China.
</reference>
<page confidence="0.998498">
125
</page>
</variant>
</algorithm>

<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Raslfph Grishman</author>
</authors>
<title>Knowledge Base Population: Successful Approaches and Challenges.</title>
<date>2011</date>
<booktitle>Proc. 49th Annual Meeting Assn. Computational Linguistics.</booktitle>
<contexts>
<context position="1755" citStr="Ji and Grishman, 2011" startWordPosition="282" endWordPosition="285">vent tracking, entity disambiguation and other related research areas. In the task, the incomplete attributes of a target person are defined as Slots, i.e. the extracted attribute value need to be filled into these slots. There are 3 kinds of slots, name slots, value slots and string slots, in which only entity name, number/time and string can be filled in. Single-value slots have only one correct answer while listvalue slots have a set of answers. There are totally 25 attributes need to be extracted, as shown in Table 1. Slot filling task has been one of shared tasks in the TAC KBP workshop [Ji and Grishman, 2011] science 2009. In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination. Supervised learning normally leads to a reasonably good performance. Both bootstrapping and rule based pattern matching with trigger words are used in [Li, et al., 2013]. Active learning techniques are also used in the task [Chen, et al, 2010]. UNED system introduces a graph structure to solve the problem [ Garrido, et al., 2013]. CMUML uses distant supervision and CRF-based structured prediction for producing the final answers [Ki</context>
</contexts>
<marker>Ji, Grishman, 2011</marker>
<rawString>Heng Ji and Raslfph Grishman. 2011. Knowledge Base Population: Successful Approaches and Challenges. Proc. 49th Annual Meeting Assn. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Li</author>
<author>Yichang Zhang</author>
<author>Doyu Li</author>
</authors>
<title>Xin Tong, Jianlong Wang, Naiche Zuo, Ying Wang,</title>
<date>2013</date>
<booktitle>PRIS at Knowledge Base Population 2013. Proc. TAC 2013 Workshop.</booktitle>
<location>Weiran Xu, Guang Chen,</location>
<contexts>
<context position="2088" citStr="Li, et al., 2013" startWordPosition="333" endWordPosition="336">ing can be filled in. Single-value slots have only one correct answer while listvalue slots have a set of answers. There are totally 25 attributes need to be extracted, as shown in Table 1. Slot filling task has been one of shared tasks in the TAC KBP workshop [Ji and Grishman, 2011] science 2009. In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination. Supervised learning normally leads to a reasonably good performance. Both bootstrapping and rule based pattern matching with trigger words are used in [Li, et al., 2013]. Active learning techniques are also used in the task [Chen, et al, 2010]. UNED system introduces a graph structure to solve the problem [ Garrido, et al., 2013]. CMUML uses distant supervision and CRF-based structured prediction for producing the final answers [Kisiel, et al., 2013]. Up to now, slot filling remains a very challenging task; most of the shortfall reflects inadequacies in the answer extraction stage. Type Attribute Single city_of _birth, city_of_death, counslots try_of_birth, country_of_death, State_or_province_of_birth, State_or_province_of_death, date_of_birth, date_of_death</context>
</contexts>
<marker>Li, Zhang, Li, 2013</marker>
<rawString>Yan Li, Yichang Zhang, Doyu Li, Xin Tong, Jianlong Wang, Naiche Zuo, Ying Wang, Weiran Xu, Guang Chen, Jun Guo. 2013. PRIS at Knowledge Base Population 2013. Proc. TAC 2013 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Suzanne Tamang</author>
<author>Adam Lee</author>
<author>Xiang Li</author>
<author>Wen-Pin Lin</author>
<author>Matthew Snover</author>
<author>Javier Artiles</author>
<author>Marissa Passantino</author>
<author>Heng Ji</author>
</authors>
<date>2010</date>
<booktitle>CUNYBLENDER TAC-KBP2010 Entity Linking and Slot Filling System Description. Proc. TAC 2010 Workshop.</booktitle>
<contexts>
<context position="2162" citStr="Chen, et al, 2010" startWordPosition="346" endWordPosition="349">le listvalue slots have a set of answers. There are totally 25 attributes need to be extracted, as shown in Table 1. Slot filling task has been one of shared tasks in the TAC KBP workshop [Ji and Grishman, 2011] science 2009. In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination. Supervised learning normally leads to a reasonably good performance. Both bootstrapping and rule based pattern matching with trigger words are used in [Li, et al., 2013]. Active learning techniques are also used in the task [Chen, et al, 2010]. UNED system introduces a graph structure to solve the problem [ Garrido, et al., 2013]. CMUML uses distant supervision and CRF-based structured prediction for producing the final answers [Kisiel, et al., 2013]. Up to now, slot filling remains a very challenging task; most of the shortfall reflects inadequacies in the answer extraction stage. Type Attribute Single city_of _birth, city_of_death, counslots try_of_birth, country_of_death, State_or_province_of_birth, State_or_province_of_death, date_of_birth, date_of_death, cause_of_death, age alternative_name, children, cities_of_residence, cou</context>
</contexts>
<marker>Chen, Tamang, Lee, Li, Lin, Snover, Artiles, Passantino, Ji, 2010</marker>
<rawString>Zheng Chen, Suzanne Tamang, Adam Lee, Xiang Li, Wen-Pin Lin, Matthew Snover, Javier Artiles, Marissa Passantino and Heng Ji. 2010. CUNYBLENDER TAC-KBP2010 Entity Linking and Slot Filling System Description. Proc. TAC 2010 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guillermo Garrido</author>
<author>Anselmo Peñas</author>
<author>Bernardo Cabaleiro</author>
</authors>
<title>UNED Slot Filling and Temporal Slot Filling systems at TAC KBP 2013. System description.</title>
<date>2013</date>
<booktitle>Proc. TAC 2013 Workshop.</booktitle>
<contexts>
<context position="2250" citStr="Garrido, et al., 2013" startWordPosition="362" endWordPosition="366"> extracted, as shown in Table 1. Slot filling task has been one of shared tasks in the TAC KBP workshop [Ji and Grishman, 2011] science 2009. In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination. Supervised learning normally leads to a reasonably good performance. Both bootstrapping and rule based pattern matching with trigger words are used in [Li, et al., 2013]. Active learning techniques are also used in the task [Chen, et al, 2010]. UNED system introduces a graph structure to solve the problem [ Garrido, et al., 2013]. CMUML uses distant supervision and CRF-based structured prediction for producing the final answers [Kisiel, et al., 2013]. Up to now, slot filling remains a very challenging task; most of the shortfall reflects inadequacies in the answer extraction stage. Type Attribute Single city_of _birth, city_of_death, counslots try_of_birth, country_of_death, State_or_province_of_birth, State_or_province_of_death, date_of_birth, date_of_death, cause_of_death, age alternative_name, children, cities_of_residence, countries_of_residence , parents, other_family, member_of, siblings, emList ployee_of, spou</context>
</contexts>
<marker>Garrido, Peñas, Cabaleiro, 2013</marker>
<rawString>Guillermo Garrido, Anselmo Peñas and Bernardo Cabaleiro. 2013. UNED Slot Filling and Temporal Slot Filling systems at TAC KBP 2013. System description. Proc. TAC 2013 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryan Kisiel</author>
<author>Justin Betteridge</author>
<author>Matt Gardner</author>
<author>Jayant Krishnamurthy</author>
</authors>
<title>Ndapa Nakashole, Mehdi Samadi, Partha Talukdar,</title>
<date>2013</date>
<booktitle>CMUML System for KBP 2013 Slot Filling. Proc. TAC 2013 Workshop.</booktitle>
<location>Derry Wijaya, Tom Mitchell.</location>
<contexts>
<context position="2373" citStr="Kisiel, et al., 2013" startWordPosition="381" endWordPosition="384">11] science 2009. In this area, earlier systems generally use one main pipeline that contains 3 stages: document retrieval, answer extraction, and answer combination. Supervised learning normally leads to a reasonably good performance. Both bootstrapping and rule based pattern matching with trigger words are used in [Li, et al., 2013]. Active learning techniques are also used in the task [Chen, et al, 2010]. UNED system introduces a graph structure to solve the problem [ Garrido, et al., 2013]. CMUML uses distant supervision and CRF-based structured prediction for producing the final answers [Kisiel, et al., 2013]. Up to now, slot filling remains a very challenging task; most of the shortfall reflects inadequacies in the answer extraction stage. Type Attribute Single city_of _birth, city_of_death, counslots try_of_birth, country_of_death, State_or_province_of_birth, State_or_province_of_death, date_of_birth, date_of_death, cause_of_death, age alternative_name, children, cities_of_residence, countries_of_residence , parents, other_family, member_of, siblings, emList ployee_of, spouses, school_attended, slots religion, charges, titles, state_or_province_of_residence Table 1: List of all attributes Our s</context>
</contexts>
<marker>Kisiel, Betteridge, Gardner, Krishnamurthy, 2013</marker>
<rawString>Bryan Kisiel, Justin Betteridge, Matt Gardner, Jayant Krishnamurthy, Ndapa Nakashole, Mehdi Samadi, Partha Talukdar, Derry Wijaya, Tom Mitchell. 2013. CMUML System for KBP 2013 Slot Filling. Proc. TAC 2013 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
</authors>
<title>Zhenghua Li, Ting Liu. LTP: A Chinese Language Technology Platform.</title>
<date>2010</date>
<booktitle>In Proceedings of the Coling 2010:Demonstrations.</booktitle>
<pages>13--16</pages>
<location>Beijing, China.</location>
<marker>Che, 2010</marker>
<rawString>Wanxiang Che, Zhenghua Li, Ting Liu. LTP: A Chinese Language Technology Platform. In Proceedings of the Coling 2010:Demonstrations. 2010, pp13-16, Beijing, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>