<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025833">
<title confidence="0.998326">
Situationally Aware In-Car Information Presentation
Using Incremental Speech Generation: Safer, and More Effective
</title>
<author confidence="0.990981">
Spyros Kousidis1, Casey Kennington1 2, Timo Baumann4, Hendrik Buschmeier23,
Stefan Kopp2 3, and David Schlangen1
</author>
<affiliation confidence="0.9864385">
1Dialogue Systems Group, 2CITEC, 3Sociable Agents Group – Bielefeld University
4Department of Informatics, Natural Language Systems Division – University of Hamburg
</affiliation>
<email confidence="0.760613">
spyros.kousidis@uni-bielefeld.de
</email>
<sectionHeader confidence="0.988074" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999872722222222">
Holding non-co-located conversations
while driving is dangerous (Horrey and
Wickens, 2006; Strayer et al., 2006),
much more so than conversations with
physically present, “situated” interlocutors
(Drews et al., 2004). In-car dialogue
systems typically resemble non-co-located
conversations more, and share their
negative impact (Strayer et al., 2013). We
implemented and tested a simple strategy
for making in-car dialogue systems aware
of the driving situation, by giving them
the capability to interrupt themselves
when a dangerous situation is detected,
and resume when over. We show that this
improves both driving performance and
recall of system-presented information,
compared to a non-adaptive strategy.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.967119761904762">
Imagine you are driving on a relatively free high-
way at a constant speed and you are talking with the
person next to you. Suddenly, you need to overtake
another car. This requires more attention from you;
you check the mirrors before you change lanes, and
again before you change back. Plausibly, an attent-
ive passenger would have noticed your attention
being focused more on the driving, and reacted to
this by interrupting their conversational contribu-
tion, resuming when back on the original lane.
Using a driving simulation setup, we implemen-
ted a dialogue system that realises this strategy. By
employing incremental output generation, the sys-
tem can interrupt and flexibly resume its output.
We tested the system using a variation of a stand-
ard driving task, and found that it improved both
driving performance and recall, as compared to a
non-adaptive baseline system.
Figure 1: Overview of our system setup: human
controls actions of a virtual car; events are sent to
DM, which controls the speech output.
</bodyText>
<sectionHeader confidence="0.998007" genericHeader="method">
2 The Setup
</sectionHeader>
<subsectionHeader confidence="0.999717">
2.1 The Situated In-Car System
</subsectionHeader>
<bodyText confidence="0.999892909090909">
Figure 1 shows an overview of our system setup,
with its main components: a) the driving simulator
that presents via computer graphics the driving task
to the user; b) the dialogue system, that presents,
via voice output, information to the user (here, cal-
endar entries).
Driving Simulation For the driving simulator,
we used the OpenDS Toolkit,1 connected to a steer-
ing wheel and a board with an acceleration and
brake pedal, using standard video game hardware.
We developed our own simple driving scenarios
(derived from the “ReactionTest” task, which is dis-
tributed together with OpenDS) that specified the
driving task and timing of the concurrent speech,
as described below. We modified OpenDS to pass
real-time data (e.g. car position/velocity/events in
the simulation, such as a gate becoming visible
or a lane change) using the mint.tools architec-
ture (Kousidis et al., 2013). In addition, we have
bridged INPROTK (Baumann and Schlangen, 2012)
with mint.tools via the Robotics Service Bus (RSB,
Wienke and Wrede (2011)) framework.
</bodyText>
<footnote confidence="0.992718">
1http://www.opends.eu/
</footnote>
<page confidence="0.984581">
68
</page>
<note confidence="0.8642605">
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 68–72,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.878676">
Figure 2: Driver’s view during experiment. The
green signal on the signal-bridge indicates the tar-
get lane.
</figureCaption>
<bodyText confidence="0.9978495">
Dialogue System Using INPROTK, we imple-
mented a simple dialogue system. The notion of
“dialogue” is used with some liberty here: the user
did not interact directly with the system but rather
indirectly (and non-intentionally) via driving ac-
tions. Nevertheless, we used the same modularisa-
tion as in more typical dialogue systems by using a
dialoge management (DM) component that controls
the system actions based on the user actions. We
integrated OpenDial (Lison, 2012) as the DM into
INPROTK,2 though we only used it to make simple,
deterministic decisions (there was no learned dia-
logue policy) based on the state of the simulator
(see below). We used the incremental output gen-
eration capabilities of INPROTK, as described in
(Buschmeier et al., 2012).
</bodyText>
<sectionHeader confidence="0.998443" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.9999670625">
We evaluated the adaptation strategy in a driving
simulation setup, where subjects performed a 30
minute, simulated drive along a straight, five-lane
road, during which they were occasionally faced
with two types of additional tasks: a lane-change
task and a memory task, which aim to measure the
driving performance and the driver’s ability to pay
attention to speech while driving, respectively. The
two tasks occured in isolation or simultaneoulsy.
The Lane-Change Task The driving task we
used is a variant of the well-known lane-change
task (LCT), which is standardised in (ISO, 2010):
It requires the driver to react to a green light posi-
tioned on a signal gate above the road (see Figure 2).
The driver (otherwise instructed to remain in the
middle lane) must move to the lane indicated by
</bodyText>
<footnote confidence="0.8704495">
2OpenDial can be found at http://opendial.
googlecode.com/.
</footnote>
<tableCaption confidence="0.999362">
Table 1: Experiment conditions.
</tableCaption>
<table confidence="0.8796824">
Lane Change Presentation mode Abbreviation
Yes CONTROL CONTROL_LANE
Yes ADAPTIVE ADAPTIVE_LANE
Yes NO_TALK NO_TALK_LANE
No CONTROL CONTROL_EMPTY
</table>
<bodyText confidence="0.998066555555556">
the green light, remain there until a tone is sounded,
and then return again to the middle lane. OpenDS
gives a success or fail result to this task depending
on whether the target lane was reached within 10
seconds (if at all) and the car was in the middle lane
when the signal became visible. We also added a
speed constraint: the car maintained 40 km/h when
the pedal was not pressed, with a top speed of 70
km/h when fully pressed. During a Lane-change,
the driver was to maintain a speed of 60 km/h, thus
adding to the cognitive load.
The Memory Task We tested the attention of
the drivers to the generated speech using a simple
true-false memory task. The DM generated utter-
ances such as “am Samstag den siebzehnten Mai
12 Uhr 15 bis 14 Uhr 15 hast du ‘gemeinsam Essen
im Westend mit Martin’” (on Saturday the 17th
of May from 12:15–14:15 you are meeting Mar-
tin for Lunch). Each utterance had 5 information
tokens: day, time, activity, location and partner,
spoken by a female voice. After utterance comple-
tion, and while no driving distraction occurred, a
confirmation question was asked by a male voice,
e.g. “Richtig oder Falsch? – Freitag” (Right or
wrong? – Friday). The subject was then required
to answer true or false by pressing one of two re-
spective buttons on the steering wheel. The token
of the confirmation question was chosen randomly,
although tokens near the beginning of the utterance
(day and time) were given a higher probability of
occurrence. The starting time of the utterance re-
lative to the gate was varied randomly between 3
and 6 seconds before visibility. Figure 3 gives a
schematic overview of the task and describes the
strategy we implemented for interrupting and re-
suming speech, triggered by the driving situation.
</bodyText>
<subsectionHeader confidence="0.992332">
3.1 Conditions
</subsectionHeader>
<bodyText confidence="0.9998726">
Table 1 shows the 4 experiment conditions, de-
noting if a lane change was signalled, and what
presentation strategy was used. Each condition ap-
peared exactly 11 times in the scenario, for a total
of 44 episodes. The order of episodes was randomly
</bodyText>
<page confidence="0.985252">
69
</page>
<figure confidence="0.953684666666667">
CONTROL am Samstag den siebzehnten Mai um 12 Uhr hast du ‘Besprechung mit Peter’
ADAPTIVE am Samstag den siebzehn- den siebzehnten Mai É
t1 t2 gate suc lane t3
</figure>
<figureCaption confidence="0.676815">
Figure 3: Top view of driving task: as the car moves to the right over time, speech begins at t1, the gate with
the lane-change indicator becomes visible at t2, where in the adaptive version speech pauses. Successful
lane change is detected at suc; successful change back to the middle lane is detected at lane, and resumes.
(If no change back is detected, the interruption times out at t3). All red-dotted lines denote events sent
from OpenDS to the Dialogue Manager.
</figureCaption>
<bodyText confidence="0.874446666666667">
generated for each subject. With this design, sub- Table 2: Subjects’ Table 3: Subjects’ system
jects perceive conditions to be entirely random. judgement of task preference.
difficulty.
</bodyText>
<figure confidence="0.9913494">
0
1
2
3
4
</figure>
<subsectionHeader confidence="0.99342">
3.2 Dependent Variables
</subsectionHeader>
<bodyText confidence="0.999981555555556">
The dependent variables for the Memory task
are (a) whether the subject’s answer was correct
(true/false), and (b) the response delay, which is
the time from the end of the clarification ques-
tion to the time the true or false button was
pressed. For the driving task, the dependent vari-
ables are the OpenDS performance measurements
success/failure (as defined above) and reaction time
(time to reach the target lane).
</bodyText>
<subsectionHeader confidence="0.991734">
3.3 Procedure
</subsectionHeader>
<bodyText confidence="0.999661">
After signing a consent form, subjects were led into
the experiment room, where seat position and audio
level were adjusted, and were given written instruc-
tions. Next, the OpenDS scenario was initiated. The
scenario started with 10 successive lane-change sig-
nal gates without speech, for driving training. An
experimenter provided feedback during training
while the subjects familiarized themselves with the
driving task. Following the training gates came a
clearly-marked “START” gate, signifying the be-
ginning of the experiment to the subjects (at this
point, the experimenter left). There was a “FINISH”
gate at the end of the scenario. The whole stretch of
road was 23 km and took approximately 30 minutes
to complete. After the driving task, the subjects
were given a questionnaire, which asked them to
identify the information presentation strategies and
assign a preference.
</bodyText>
<table confidence="0.996675">
Diff. Freq. Preference Freq.
4 (easy) 8 ADAPTIVE 3
3 7 CONTROL 9
2 1 Neither 5
1 (hard) 1
</table>
<sectionHeader confidence="0.999671" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999727523809524">
In total, 17 subjects (8 male, 9 female, aged 19-
36) participated in the study. All of the subjects
were native German speakers affiliated with AN-
ONYMIZED University. As reported in the post-test
questionnaire, all held a driving license, two had
previous experience with driving simulators and
only one had previous experience with spoken dia-
logue systems. Table 2 shows the subjects’ assess-
ment of difficulty, while Table 3 shows their prefer-
ence between the different strategies. Most subjects
found the task relatively easy and either prefer the
speech not to adapt or have no preference.
Memory task The overall percentages of correct
answers to the system’s recall questions (across all
subjects) are shown in Table 4. We see that the sub-
jects’ performance in this task is considerably bet-
ter when the system adapts to the driving situation
(ADAPTIVE_LANE condition) rather than speaking
through the lane change (CONTROL_LANE con-
dition). In fact, the performance in the ADAPT-
IVE_LANE condition is closer to the control upper
</bodyText>
<page confidence="0.999216">
70
</page>
<tableCaption confidence="0.9664495">
Table 4: Performance in memory task per condi-
tion.
</tableCaption>
<table confidence="0.99925725">
Condition Percentage
CONTROL_EMPTY 169/180 (93.9 %)
ADAPTIVE_LANE 156/172 (90.7 %)
CONTROL_LANE 150/178 (84.3 %)
</table>
<tableCaption confidence="0.980566">
Table 5: Success in driving task per condition (as
reported by OpenDS).
</tableCaption>
<table confidence="0.933727">
Condition Success
NOTALK_LANE 175/185 (94.6%)
ADAPTIVE_LANE 165/174 (94.8%)
CONTROL_LANE 165/180 (91.7%)
</table>
<bodyText confidence="0.995058657142857">
bound (CONTROL_EMPTY condition). We tested
significance of the results using a generalized lin-
ear mixed model with CONDITION and SUBJECT
as factors, which yields a p-value of 0.027 when
compared against a null model in which only SUB-
JECT is a factor. No significant effects of between-
subjects factors gender, difficulty or preference
were found. In addition, the within-subject variable
time did not have any significant effect (subjects do
not improve in the memory task with time).
The average response delay (from the end of
the recall question to the button press) per condi-
tion across all subjects is shown in Figure 4. Sub-
jects reply slower to the recall questions in the
CONTROL_LANE condition, while their perform-
ance in the ADAPTIVE_LANE condition is indis-
tinguishable from the CONTROL_EMPTY condi-
tion (in which there is no distraction). Addition-
ally, there is a general decreasing trend of response
delay with time, which means that users get ac-
quainted with the task (type of information, format
of question) over time. Both factors (condition
and time) are significant (repeated measures AN-
OVA, 2x2 factorial design, Fcondition = 3.858, p =
0.0359,Ftime = 4.672, p = 0.00662). No significant
effects were found for any of the between-subject
factors (gender, difficulty, preference).
Driving task The success rate in the lane-change
task per condition is shown in Table 5. Here too
we find that the performance is lower in the CON-
TROL_LANE condition, while ADAPTIVE_LANE
does not seem to affect driving performance, when
compared to the NOTALK_LANE condition. The
effect is significant (p = 0.01231) using the same
GLMM approach and factors as above.
</bodyText>
<figure confidence="0.8450195">
ADAPTIVE_LANE CONTROL_EMPTY CONTROL_LANE
Condition
</figure>
<figureCaption confidence="0.9800455">
Figure 4: User answer response delay under three
conditions.
</figureCaption>
<sectionHeader confidence="0.989274" genericHeader="conclusions">
5 Discussion, Conclusions, Future Work
</sectionHeader>
<bodyText confidence="0.99905921875">
We have developed and tested a driving simula-
tion scenario where information is presented by a
spoken dialogue system. Our system has the unique
ability (compared to today’s commercial systems)
to adapt its speech to the driving situation: it in-
terrupts itself when a dangerous situation occurs
and later resumes with an appropriate continuation.
Using this strategy, information presentation had
no impact on driving, and dangerous situations no
impact on information recall. In contrast, a system
that blindly spoke while the driver was distracted
by the lane-change task resulted in worse perform-
ance in both tasks: subjects made more errors in
the memory task and also failed more of the lane-
change tasks, which could prove dangerous in a
real situation.
Interestingly, very few of the subjects preferred
the adaptive version of the system in the post-task
questionnaire. Among the reasons that they gave
for this was their inability to control the interrup-
tions/resumptions of the system. We plan to ad-
dress the issue of control by allowing future ver-
sions of our system to accept user signals, such as
speech or head gestures; it will be interesting to see
whether this will impact driving performance or not.
Further, more sophisticated presentation strategies
(e.g., controlling the complexity of the generated
language in accordance to the driving situation) can
be tested in this framework.
Acknowledgments This research was partly sup-
ported by the Deutsche Forschungsgemeinschaft
(DFG) in the CRC 673 “Alignment in Communic-
</bodyText>
<figure confidence="0.9916754">
4000
User Response Delay (ms)
3500
3000
2500
2000
1500
1000
500
0
</figure>
<page confidence="0.994774">
71
</page>
<bodyText confidence="0.999981666666667">
ation” and the Center of Excellence in “Cognit-
ive Interaction Technology” (CITEC). The authors
would like to thank Oliver Eckmeier and Michael
Bartholdt for helping implement the system setup,
as well as Gerdis Anderson and Fabian Wohlge-
muth for assisting as experimenters.
</bodyText>
<sectionHeader confidence="0.998546" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999459659574468">
Timo Baumann and David Schlangen. 2012. The In-
proTK 2012 release. In NAACL-HLT Workshop on
Future directions and needs in the Spoken Dialog
Community: Tools and Data (SDCTD 2012), pages
29–32, Montréal, Canada.
Hendrik Buschmeier, Timo Baumann, Benjamin
Dosch, Stefan Kopp, and David Schlangen. 2012.
Combining incremental language generation and in-
cremental speech synthesis for adaptive information
presentation. In Proceedings of the 13th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue, pages 295–303, Seoul, South Korea.
Frank A. Drews, Monisha Pasupathi, and David L.
Strayer. 2004. Passenger and cell-phone conver-
sations in simulated driving. In Proceedings of the
48th Annual Meeting of the Human Factors and Er-
gonomics Society, pages 2210–2212, New Orleans,
USA.
William J. Horrey and Christopher D. Wickens. 2006.
Examining the impact of cell phone conversations
on driving using meta-analytic techniques. Human
Factors, 48:196–205.
ISO. 2010. Road vehicles – Ergonomic aspects of
transport information and control systems – Simu-
lated lane change test to assess in-vehicle second-
ary task demand. ISO 26022:2010, Geneva, Switzer-
land.
Spyros Kousidis, Thies Pfeiffer, and David Schlangen.
2013. MINT.tools: Tools and adaptors supporting
acquisition, annotation and analysis of multimodal
corpora. In Interspeech 2013, Lyon, France. ISCA.
Pierre Lison. 2012. Probabilistic dialogue models with
prior domain knowledge. In Proceedings of the 13th
Annual Meeting of the Special Interest Group on Dis-
course and Dialogue, pages 179–188, Seoul, South
Korea.
David L Strayer, Frank A Drews, and Dennis J Crouch.
2006. A comparison of the cell phone driver and the
drunk driver. Human Factors, 48:381–91.
David L Strayer, Joel M Cooper, Jonna Turrill, James
Coleman, and Nate Medeiros. 2013. Measuring
cognitive distraction in the automobile. Technical
report, AAA Foundation for Traffice Safety.
J Wienke and S Wrede. 2011. A middleware for col-
laborative research in experimental robotics. In Sys-
tem Integration (SII), 2011 IEEE/SICEInternational
Symposium on, pages 1183–1190.
</reference>
<page confidence="0.998723">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.228227">
<title confidence="0.9560625">Situationally Aware In-Car Information Using Incremental Speech Generation: Safer, and More Effective</title>
<affiliation confidence="0.570444">Systems Group, Agents Group – Bielefeld of Informatics, Natural Language Systems Division – University of</affiliation>
<email confidence="0.867041">spyros.kousidis@uni-bielefeld.de</email>
<abstract confidence="0.990206210526316">Holding non-co-located conversations while driving is dangerous (Horrey and Wickens, 2006; Strayer et al., 2006), much more so than conversations with physically present, “situated” interlocutors (Drews et al., 2004). In-car dialogue systems typically resemble non-co-located conversations more, and share their negative impact (Strayer et al., 2013). We implemented and tested a simple strategy for making in-car dialogue systems aware of the driving situation, by giving them the capability to interrupt themselves when a dangerous situation is detected, and resume when over. We show that this improves both driving performance and recall of system-presented information, compared to a non-adaptive strategy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timo Baumann</author>
<author>David Schlangen</author>
</authors>
<title>The InproTK 2012 release.</title>
<date>2012</date>
<booktitle>In NAACL-HLT Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data (SDCTD 2012),</booktitle>
<pages>29--32</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="3170" citStr="Baumann and Schlangen, 2012" startWordPosition="475" endWordPosition="478">ed the OpenDS Toolkit,1 connected to a steering wheel and a board with an acceleration and brake pedal, using standard video game hardware. We developed our own simple driving scenarios (derived from the “ReactionTest” task, which is distributed together with OpenDS) that specified the driving task and timing of the concurrent speech, as described below. We modified OpenDS to pass real-time data (e.g. car position/velocity/events in the simulation, such as a gate becoming visible or a lane change) using the mint.tools architecture (Kousidis et al., 2013). In addition, we have bridged INPROTK (Baumann and Schlangen, 2012) with mint.tools via the Robotics Service Bus (RSB, Wienke and Wrede (2011)) framework. 1http://www.opends.eu/ 68 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 68–72, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 2: Driver’s view during experiment. The green signal on the signal-bridge indicates the target lane. Dialogue System Using INPROTK, we implemented a simple dialogue system. The notion of “dialogue” is used with some liberty here: the user did not interact directly with the system but rather indirectly (an</context>
</contexts>
<marker>Baumann, Schlangen, 2012</marker>
<rawString>Timo Baumann and David Schlangen. 2012. The InproTK 2012 release. In NAACL-HLT Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data (SDCTD 2012), pages 29–32, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hendrik Buschmeier</author>
<author>Timo Baumann</author>
<author>Benjamin Dosch</author>
<author>Stefan Kopp</author>
<author>David Schlangen</author>
</authors>
<title>Combining incremental language generation and incremental speech synthesis for adaptive information presentation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>295--303</pages>
<location>Seoul, South</location>
<contexts>
<context position="4320" citStr="Buschmeier et al., 2012" startWordPosition="654" endWordPosition="657">e user did not interact directly with the system but rather indirectly (and non-intentionally) via driving actions. Nevertheless, we used the same modularisation as in more typical dialogue systems by using a dialoge management (DM) component that controls the system actions based on the user actions. We integrated OpenDial (Lison, 2012) as the DM into INPROTK,2 though we only used it to make simple, deterministic decisions (there was no learned dialogue policy) based on the state of the simulator (see below). We used the incremental output generation capabilities of INPROTK, as described in (Buschmeier et al., 2012). 3 Experiment We evaluated the adaptation strategy in a driving simulation setup, where subjects performed a 30 minute, simulated drive along a straight, five-lane road, during which they were occasionally faced with two types of additional tasks: a lane-change task and a memory task, which aim to measure the driving performance and the driver’s ability to pay attention to speech while driving, respectively. The two tasks occured in isolation or simultaneoulsy. The Lane-Change Task The driving task we used is a variant of the well-known lane-change task (LCT), which is standardised in (ISO, 2</context>
</contexts>
<marker>Buschmeier, Baumann, Dosch, Kopp, Schlangen, 2012</marker>
<rawString>Hendrik Buschmeier, Timo Baumann, Benjamin Dosch, Stefan Kopp, and David Schlangen. 2012. Combining incremental language generation and incremental speech synthesis for adaptive information presentation. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 295–303, Seoul, South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank A Drews</author>
<author>Monisha Pasupathi</author>
<author>David L Strayer</author>
</authors>
<title>Passenger and cell-phone conversations in simulated driving.</title>
<date>2004</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Human Factors and Ergonomics Society,</booktitle>
<pages>2210--2212</pages>
<location>New Orleans, USA.</location>
<contexts>
<context position="651" citStr="Drews et al., 2004" startWordPosition="76" endWordPosition="79">mation Presentation Using Incremental Speech Generation: Safer, and More Effective Spyros Kousidis1, Casey Kennington1 2, Timo Baumann4, Hendrik Buschmeier23, Stefan Kopp2 3, and David Schlangen1 1Dialogue Systems Group, 2CITEC, 3Sociable Agents Group – Bielefeld University 4Department of Informatics, Natural Language Systems Division – University of Hamburg spyros.kousidis@uni-bielefeld.de Abstract Holding non-co-located conversations while driving is dangerous (Horrey and Wickens, 2006; Strayer et al., 2006), much more so than conversations with physically present, “situated” interlocutors (Drews et al., 2004). In-car dialogue systems typically resemble non-co-located conversations more, and share their negative impact (Strayer et al., 2013). We implemented and tested a simple strategy for making in-car dialogue systems aware of the driving situation, by giving them the capability to interrupt themselves when a dangerous situation is detected, and resume when over. We show that this improves both driving performance and recall of system-presented information, compared to a non-adaptive strategy. 1 Introduction Imagine you are driving on a relatively free highway at a constant speed and you are talk</context>
</contexts>
<marker>Drews, Pasupathi, Strayer, 2004</marker>
<rawString>Frank A. Drews, Monisha Pasupathi, and David L. Strayer. 2004. Passenger and cell-phone conversations in simulated driving. In Proceedings of the 48th Annual Meeting of the Human Factors and Ergonomics Society, pages 2210–2212, New Orleans, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Horrey</author>
<author>Christopher D Wickens</author>
</authors>
<title>Examining the impact of cell phone conversations on driving using meta-analytic techniques. Human Factors,</title>
<date>2006</date>
<pages>48--196</pages>
<marker>Horrey, Wickens, 2006</marker>
<rawString>William J. Horrey and Christopher D. Wickens. 2006. Examining the impact of cell phone conversations on driving using meta-analytic techniques. Human Factors, 48:196–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ISO</author>
</authors>
<title>Road vehicles – Ergonomic aspects of transport information and control systems – Simulated lane change test to assess in-vehicle secondary task demand. ISO 26022:2010,</title>
<date>2010</date>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="4924" citStr="ISO, 2010" startWordPosition="750" endWordPosition="751"> 2012). 3 Experiment We evaluated the adaptation strategy in a driving simulation setup, where subjects performed a 30 minute, simulated drive along a straight, five-lane road, during which they were occasionally faced with two types of additional tasks: a lane-change task and a memory task, which aim to measure the driving performance and the driver’s ability to pay attention to speech while driving, respectively. The two tasks occured in isolation or simultaneoulsy. The Lane-Change Task The driving task we used is a variant of the well-known lane-change task (LCT), which is standardised in (ISO, 2010): It requires the driver to react to a green light positioned on a signal gate above the road (see Figure 2). The driver (otherwise instructed to remain in the middle lane) must move to the lane indicated by 2OpenDial can be found at http://opendial. googlecode.com/. Table 1: Experiment conditions. Lane Change Presentation mode Abbreviation Yes CONTROL CONTROL_LANE Yes ADAPTIVE ADAPTIVE_LANE Yes NO_TALK NO_TALK_LANE No CONTROL CONTROL_EMPTY the green light, remain there until a tone is sounded, and then return again to the middle lane. OpenDS gives a success or fail result to this task dependi</context>
</contexts>
<marker>ISO, 2010</marker>
<rawString>ISO. 2010. Road vehicles – Ergonomic aspects of transport information and control systems – Simulated lane change test to assess in-vehicle secondary task demand. ISO 26022:2010, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Kousidis</author>
<author>Thies Pfeiffer</author>
<author>David Schlangen</author>
</authors>
<title>MINT.tools: Tools and adaptors supporting acquisition, annotation and analysis of multimodal corpora.</title>
<date>2013</date>
<booktitle>In Interspeech 2013,</booktitle>
<location>Lyon, France. ISCA.</location>
<contexts>
<context position="3102" citStr="Kousidis et al., 2013" startWordPosition="465" endWordPosition="468"> entries). Driving Simulation For the driving simulator, we used the OpenDS Toolkit,1 connected to a steering wheel and a board with an acceleration and brake pedal, using standard video game hardware. We developed our own simple driving scenarios (derived from the “ReactionTest” task, which is distributed together with OpenDS) that specified the driving task and timing of the concurrent speech, as described below. We modified OpenDS to pass real-time data (e.g. car position/velocity/events in the simulation, such as a gate becoming visible or a lane change) using the mint.tools architecture (Kousidis et al., 2013). In addition, we have bridged INPROTK (Baumann and Schlangen, 2012) with mint.tools via the Robotics Service Bus (RSB, Wienke and Wrede (2011)) framework. 1http://www.opends.eu/ 68 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 68–72, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 2: Driver’s view during experiment. The green signal on the signal-bridge indicates the target lane. Dialogue System Using INPROTK, we implemented a simple dialogue system. The notion of “dialogue” is used with some liberty here: the user</context>
</contexts>
<marker>Kousidis, Pfeiffer, Schlangen, 2013</marker>
<rawString>Spyros Kousidis, Thies Pfeiffer, and David Schlangen. 2013. MINT.tools: Tools and adaptors supporting acquisition, annotation and analysis of multimodal corpora. In Interspeech 2013, Lyon, France. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Lison</author>
</authors>
<title>Probabilistic dialogue models with prior domain knowledge.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>179--188</pages>
<location>Seoul, South</location>
<contexts>
<context position="4035" citStr="Lison, 2012" startWordPosition="608" endWordPosition="609">ion for Computational Linguistics Figure 2: Driver’s view during experiment. The green signal on the signal-bridge indicates the target lane. Dialogue System Using INPROTK, we implemented a simple dialogue system. The notion of “dialogue” is used with some liberty here: the user did not interact directly with the system but rather indirectly (and non-intentionally) via driving actions. Nevertheless, we used the same modularisation as in more typical dialogue systems by using a dialoge management (DM) component that controls the system actions based on the user actions. We integrated OpenDial (Lison, 2012) as the DM into INPROTK,2 though we only used it to make simple, deterministic decisions (there was no learned dialogue policy) based on the state of the simulator (see below). We used the incremental output generation capabilities of INPROTK, as described in (Buschmeier et al., 2012). 3 Experiment We evaluated the adaptation strategy in a driving simulation setup, where subjects performed a 30 minute, simulated drive along a straight, five-lane road, during which they were occasionally faced with two types of additional tasks: a lane-change task and a memory task, which aim to measure the dri</context>
</contexts>
<marker>Lison, 2012</marker>
<rawString>Pierre Lison. 2012. Probabilistic dialogue models with prior domain knowledge. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 179–188, Seoul, South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Strayer</author>
<author>Frank A Drews</author>
<author>Dennis J Crouch</author>
</authors>
<title>A comparison of the cell phone driver and the drunk driver. Human Factors,</title>
<date>2006</date>
<pages>48--381</pages>
<marker>Strayer, Drews, Crouch, 2006</marker>
<rawString>David L Strayer, Frank A Drews, and Dennis J Crouch. 2006. A comparison of the cell phone driver and the drunk driver. Human Factors, 48:381–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Strayer</author>
<author>Joel M Cooper</author>
<author>Jonna Turrill</author>
<author>James Coleman</author>
<author>Nate Medeiros</author>
</authors>
<title>Measuring cognitive distraction in the automobile. Technical report, AAA Foundation for Traffice Safety.</title>
<date>2013</date>
<contexts>
<context position="785" citStr="Strayer et al., 2013" startWordPosition="93" endWordPosition="96">nn4, Hendrik Buschmeier23, Stefan Kopp2 3, and David Schlangen1 1Dialogue Systems Group, 2CITEC, 3Sociable Agents Group – Bielefeld University 4Department of Informatics, Natural Language Systems Division – University of Hamburg spyros.kousidis@uni-bielefeld.de Abstract Holding non-co-located conversations while driving is dangerous (Horrey and Wickens, 2006; Strayer et al., 2006), much more so than conversations with physically present, “situated” interlocutors (Drews et al., 2004). In-car dialogue systems typically resemble non-co-located conversations more, and share their negative impact (Strayer et al., 2013). We implemented and tested a simple strategy for making in-car dialogue systems aware of the driving situation, by giving them the capability to interrupt themselves when a dangerous situation is detected, and resume when over. We show that this improves both driving performance and recall of system-presented information, compared to a non-adaptive strategy. 1 Introduction Imagine you are driving on a relatively free highway at a constant speed and you are talking with the person next to you. Suddenly, you need to overtake another car. This requires more attention from you; you check the mirr</context>
</contexts>
<marker>Strayer, Cooper, Turrill, Coleman, Medeiros, 2013</marker>
<rawString>David L Strayer, Joel M Cooper, Jonna Turrill, James Coleman, and Nate Medeiros. 2013. Measuring cognitive distraction in the automobile. Technical report, AAA Foundation for Traffice Safety.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wienke</author>
<author>S Wrede</author>
</authors>
<title>A middleware for collaborative research in experimental robotics.</title>
<date>2011</date>
<booktitle>In System Integration (SII), 2011 IEEE/SICEInternational Symposium on,</booktitle>
<pages>1183--1190</pages>
<contexts>
<context position="3245" citStr="Wienke and Wrede (2011)" startWordPosition="487" endWordPosition="490">ration and brake pedal, using standard video game hardware. We developed our own simple driving scenarios (derived from the “ReactionTest” task, which is distributed together with OpenDS) that specified the driving task and timing of the concurrent speech, as described below. We modified OpenDS to pass real-time data (e.g. car position/velocity/events in the simulation, such as a gate becoming visible or a lane change) using the mint.tools architecture (Kousidis et al., 2013). In addition, we have bridged INPROTK (Baumann and Schlangen, 2012) with mint.tools via the Robotics Service Bus (RSB, Wienke and Wrede (2011)) framework. 1http://www.opends.eu/ 68 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 68–72, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 2: Driver’s view during experiment. The green signal on the signal-bridge indicates the target lane. Dialogue System Using INPROTK, we implemented a simple dialogue system. The notion of “dialogue” is used with some liberty here: the user did not interact directly with the system but rather indirectly (and non-intentionally) via driving actions. Nevertheless, we used the same mo</context>
</contexts>
<marker>Wienke, Wrede, 2011</marker>
<rawString>J Wienke and S Wrede. 2011. A middleware for collaborative research in experimental robotics. In System Integration (SII), 2011 IEEE/SICEInternational Symposium on, pages 1183–1190.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>