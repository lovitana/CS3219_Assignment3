<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999127">
Exploiting Language Variants Via Grammar Parsing Having
Morphologically Rich Information
</title>
<author confidence="0.736591">
Qaiser Abbas
</author>
<affiliation confidence="0.6211415">
Fachbereich Sprachwissenschaft
Universit¨at Konstanz
</affiliation>
<address confidence="0.646767">
78457 Konstanz, Germany
</address>
<email confidence="0.865963">
qaiser.abbas@uni-konstanz.de
</email>
<sectionHeader confidence="0.995495" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99993552631579">
In this paper, the development and evalua-
tion of the Urdu parser is presented along
with the comparison of existing resources
for the language variants Urdu/Hindi. This
parser was given a linguistically rich
grammar extracted from a treebank. This
context free grammar with sufficient en-
coded information is comparable with the
state of the art parsing requirements for
morphologically rich and closely related
language variants Urdu/Hindi. The ex-
tended parsing model and the linguisti-
cally rich grammar together provide us
promising parsing results for both the lan-
guage variants. The parser gives 87% of
f-score, which outperforms the multi-path
shift-reduce parser for Urdu and a simple
Hindi dependency parser with 4.8% and
22% increase in recall, respectively.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998877593220339">
An Urdu invariant of Hindavi came into existence
during the muslim rule from 1206 AD to 1858
AD (Khan, 2006). They used Persian/Urdu script
for Urdu in contrast to the Devanagari script for
Hindavi. The informal versions of the two lan-
guage variants are quite similar, in fact so sim-
ilar that they can really be called dialects of a
same language. Loose examples would be how a
Spanish speaker could comprehend Portuguese or
Swedish speaker could comprehend Norwegian.
However the formal version of the two languages
will be much more different as Urdu vocabulary is
influenced heavily from Persian, Arabic and Turk-
ish whilst the emphasis in Hindi is on Sanskrit.
Urdu became a literary language after existence of
an increasing number of literature during the 18th
and the 19th century (McLane, 1970). Urdu/Hindi
is the national language of Pakistan and an official
language in India. According to a report by the
SIL Ethnologue (Lewis, 2013), Urdu/Hindi has
456.2 million speakers in the whole world.
Getting state of the art parsing results for mor-
phologically rich languages (MRLs) is a challenge
to date. According to Tsarfaty et al. (2010; 2013),
without proper handling of morphological entities
in the sentences, promising results for MRLs can
not be achieved. Complex morphosyntactic in-
teractions may impose constraints, which lead to
explicit encoding of such information. The best
broad coverage and robust parsers to date have
grammars extracted from treebanks and the depth
of information encoded in an annotation corre-
lates with the parsing performance (Tsarfaty et al.,
2013).
To fulfill the encoding of information in an
annotation, a treebank for Urdu known as the
URDU.KON-TB treebank with sufficient encoded
information at morphological, POS, syntactic and
functional level was constructed (Abbas, 2012).
Its annotation was found reliable according to the
Krippendorffs α values achieved in (Abbas, 2014)
but its reliability or the suitability for machine
learning (ML) can be evaluated with the develop-
ment of an Urdu parser presented in Section 3. A
context free grammar (CFG) is extracted from the
URDU.KON-TB treebank computationally. The
development procedure and the depth of encoded
information in the grammar is presented in Section
2. The grammar is then given to an extended dy-
namic programming parsing model known as the
Earley parsing algorithm (Earley, 1970). The ex-
tended parsing model for Urdu is then called as
the Urdu parser and given in Section 3. This al-
gorithm is language independent and is capable
to parse the MRLs like the CKY (Cocke-Kasami-
Younger) parsing algorithm as advocated in (Tsar-
faty et al., 2013) and (Abbas et al., 2009). Issues
faced during the parsing are discussed in Section
4. By applying a rich grammar along with the ex-
</bodyText>
<page confidence="0.975486">
36
</page>
<note confidence="0.666493">
Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36–46,
October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999889166666667">
tended parsing model, promising results obtained
are discussed in Section 5. Conclusions along with
the future directions are presented in Section 6.
Similarly, the related work of language variants is
described in Section 1.1, which set a path towards
the construction of the Urdu parser.
</bodyText>
<sectionHeader confidence="0.667761" genericHeader="introduction">
1.1 Related Work
</sectionHeader>
<bodyText confidence="0.99998885">
In the Urdu ParGram project (Butt and King,
2007), the XLE1 parser is in use. The encoding
of LFG grammar in XLE interface is not a sim-
ple task. Such a grammar can be encoded only
by those persons who have expertise in theoreti-
cal linguistics as well. The team of the ParGram
project has made a tremendous effort in this re-
gard. This project of Urdu LFG grammar develop-
ment is still in progress and the parser evaluation
results are not available yet. Similarly, the parser
for evaluation of the NU-FAST treebank (Abbas
et al., 2009) used a built in utility available in the
inference engine of the Prolog to parse the Urdu
sentences. This utility can only be used if you
have a definite clause grammar (DCG) or proba-
bilistic definite clause grammar (PDCG). In this
work, a parser was not designed but a built-in pro-
log parser was used, due to which it was not con-
sidered to be the candidate for comparison.
A simple dependency parser for Hindi was de-
veloped by Bharati et al. (2009). The parser used
a grammar oriented approach, which was designed
on the basis of Paninian grammatical model (Be-
gum et al., 2008; Bharati et al., 1995). The annota-
tion scheme was designed on the basis of chunks,
intra-chunks and karakas2. This scheme (Be-
gum et al., 2008) of dependency structure (DS)
is different from the annotation scheme (Abbas,
2012; Abbas, 2014) of phrase structure (PS) and
the hyper dependency structure (HDS) of the
URDU.KON-TB treebank along with the different
data sets used. As compared to phrase/constituent
structure, the dependency structure lacks in infor-
mation at non-terminal nodes (Bharati et al., 2008)
and often the information at POS level. This infor-
mation can also be provided at dependency anno-
tation but people are stick to the standard norms.
The Hindi treebank is rich in functional informa-
tion as compared to morphological, POS and syn-
tactical information. Due to differences in the de-
</bodyText>
<footnote confidence="0.99316475">
1http://www2.parc.com/isl/groups/nltt/xle/
2Karakas are the syntactico-semantic relations between
the verbs and other related constituents in a sentence (Bharati
et al., 1996)
</footnote>
<bodyText confidence="0.999968714285715">
signs of the simple dependency parser for Hindi
and the Urdu parser, only performance results are
compared and presented in Section 5.
Ali and Hussain used the MaltParser with its de-
fault settings in Urdu dependency parser (Ali and
Hussain, 2010). When somebody performs ex-
periments with MaltParser with its default settings
then such evaluation results are advised not to be
compared according to MaltParser license.3 The
same exercise for parsing Hindi was performed
in (Agrawal et al., 2013), but it was clearly men-
tioned in the work that MaltParser was used for
error detection in the annotation of Hindi/Urdu
treebank (HUTB).4 Similarly, the Urdu sentences
were parsed in (Bhat et al., 2012b) using the same
MaltParser. The experiments were performed to
identify the parsing issues of Urdu and a devel-
opment of parser was not claimed. Moreover,
these data-driven systems are highly criticized on
a given set of annotated corpus because they are
not able to observe all morphological variants of a
word form from it (Tsarfaty et al., 2013).
A multi-path shift-reduce parsing algorithm was
proposed in (Jiang et al., 2009) for Chinese. Later
on, this algorithm was used for Urdu parsing by
Mukhtar et al. (2012b). A probabilistic context
free grammar (PCFG) developed in (Mukhtar et
al., 2011) was given to the multi-path shift-reduce
Urdu parsing model. A multi-path shift-reduce
parser for Urdu has some limitations. It takes a
POS tagged sentence as input and is not able to
parse sentences without the POS tagging. The
stack used has a fixed memory size, which is not
reliable and it can overflow during the parsing
of long sentences. A PCFG used in this parsing
model is ambiguous (Mukhtar et al., 2012a). Both
the fixed memory size and the ambiguous gram-
mar can resist the parsing of long sentences,thats
why the parser could not parse the sentences
with length more than 10 words (Mukhtar et al.,
2012b). In this work, the results were not evalu-
ated properly by using some measure e.g. PAR-
SEVAL. A number of 74 sentences having length
not more than 10 words were parsed successfully
from 100 sentences, which were then quoted as a
74% of accuracy. The raw corpus used in the de-
velopment of this parser is partially the same as
compared to the Urdu parser (Section 3). A com-
parative study made is detailed in Section 5.
</bodyText>
<footnote confidence="0.9994315">
3http://www.maltparser.org/
4http://faculty.washington.edu/fxia/treebank/
</footnote>
<page confidence="0.999524">
37
</page>
<figureCaption confidence="0.999679">
Figure 1: A verb V example from the URDU.KON-TB treebank
</figureCaption>
<sectionHeader confidence="0.992029" genericHeader="method">
2 Setup
</sectionHeader>
<bodyText confidence="0.999552061224489">
The URDU.KON-TB treebank having phrase
structure (PS) and the hyper dependency struc-
ture (HDS) annotation with rich encoded informa-
tion (Abbas, 2012; Abbas, 2014) is used for the
training of the Urdu parser discussed in Section 3.
The treebank has a semi-semantic POS (SSP) tag
set, a semi-semantic syntactic (SSS) tag set and a
functional (F) tag set. The morphological infor-
mation in the labeling of the parsers lexicon can
be explained by discussing the POS tag set of the
URDU.KON-TB treebank.
The SSP tag set hierarchy has 22 main tag cate-
gories which are divided into sub-categories based
on morphology and semantics. In Figure 1, an ex-
ample of only a verb V is given. A dot ‘.’ symbol
is used for the representation of morphology and
semantics at POS level. In Figure 1, the hierarchy
of tag labels for verb V is divided into three lev-
els of depth. The first level contains only one la-
bel to distinguish a verb V from other POS labels.
The second level contains 11 subcategories of V
to represent different morphological or functional
forms e.g. V.COP (V as a copula verb (Abbas and
Raza, 2014)), V.IMPERF (V has an imperfective
form (Butt and Rizvi, 2010; Butt and Ramchand,
2001)), V.INF (V has an infinitive form (Butt,
1993; Abbas and Nabi Khan, 2009)), etc. The
third level contains further 25 subcategories to rep-
resent the morphological information in depth e.g.
V.COP.IMPERF (copula verb has an imperfective
form), V.COP.PERF (copula verb has a perfective
form), V.COP.ROOT (copula verb has a ROOT
form), V.COP.PAST (copula verb has a past tense),
V.LIGHT.PAST (light verb has a past tense (Butt
and Rizvi, 2010; Butt, 2003)), etc. These types of
combinations are also possible in case of an auxil-
iary verb as described in (Abbas, 2014). This short
discussion is about the idea of morphological and
functional information encoded at POS level. This
lexical information can be passed up to the syn-
tactical level because the lexical items have some
relationship with other lexical items in a sentence.
The detail of syntactic (SSS) and functional (F) tag
sets can be seen in (Abbas, 2012).
A stack based extraction Algorithm 1 was de-
signed to extract a context free grammar (CFG)
from the URDU.KON-TB treebank. The CFG ob-
tained is then given to the Urdu parser (Section 3)
for sentence parsing.
</bodyText>
<sectionHeader confidence="0.977414" genericHeader="method">
3 Urdu Parser
</sectionHeader>
<bodyText confidence="0.99995615">
The URDU.KON-TB treebank is a manually an-
notated set of 1400 parsed sentences, which were
then recorded in a text file on a computer in the
form of 1400 bracketed sentences. Initial twenty
bracketed-sentences from each hundred were sep-
arated in another text file, whose total 280 sen-
tences were then used for the development of a
test suite. The test suite was further divided into
two halves representing test data and held out data
resulting in 140 sentences in each half.
The held out data was used in the development
of the Urdu parser, while the test data was used for
the evaluation of results after the completion of the
Urdu parser. From the first residual text file with
1120 bracketed sentences, a context free grammar
(CFG) was extracted using a stack based extrac-
tion module given in Algorithm 1. The CFG was
then processed by the Urdu parser to produce a
grammar database with unique productions. Dur-
ing this process, production type (TYPE) labeling
</bodyText>
<page confidence="0.998501">
38
</page>
<bodyText confidence="0.9993325">
as lexical (L) and non-lexical (NL) at the end of
each production was done. The productions hav-
ing only the lexical items at their right hand side
(RHS) were labelled as L and the productions con-
taining non-lexical items on their RHS only were
labelled as NL. The purpose of this labeling is to
provide an already processed mechanism, through
which the Urdu parser can identify a production
type L or NL speedily without checking it thor-
oughly.
</bodyText>
<listItem confidence="0.954664115384615">
Algorithm 1 A CFG extraction algorithm
Input: A input and an empty output file
1: (Sentence, Top, Counter) ← 0
2: Read:InputString
3: while InputString =6 Input.EOF() do D Loop until end of file
4: if InputString = $ then
5: Print: + + Sentence
6: Read: InputString D Read a string from an input file
7: Write: \n \n D Writing two newlines in output file
8: (Stack[0], StrArray[0]) ← ∅ D Initializing stack and array
9: (Top, Counter) ← 0 D Initializing stack and array variables
10: end if
11: if InputString =6 ”)” then
12: Stack[Top] ← InputString; Top + +
13: else D When ’)’ comes
14: Top − −
15: while Stack[Top] =6 ”(” do
16: StrArray[Counter] = Stack[Top]
17: Stack[Top] = ∅; Counter + +; Top − −
18: end while
19: Counter − −
20: Stack[Top] = StrArray[Counter]
21: Top + + and Check = Counter
22: while Counter ≥ 0 do
23: if Counter = Check then
24: Write: StrArray[Counter]
</listItem>
<equation confidence="0.722658">
StrArray[Counter] = ∅
</equation>
<listItem confidence="0.966747222222222">
25: else
26: Write: StrArray[Counter] + ””;
StrArray[Counter] = ∅
27: end if
28: Counter − −
29: end while
30: Write: \n; Counter = 0 D In output file
31: end if
32: Read: InputString D Read a string from an input file
</listItem>
<subsectionHeader confidence="0.376793">
33: end while
</subsectionHeader>
<bodyText confidence="0.976749413793104">
Output: An output file having complete CFG productions for each sentence
Without handling the issues discussed in Sec-
tion 4, the Earley’s algorithm simply was not
able to provide the state of the art evaluation re-
sults for Urdu. These issues caused the pars-
ing discontinuities, due to which extensions are
made on the basic algorithm. The extended ver-
sion of the Urdu parser is depicted in Algorithm
2. The grammar database of the Urdu parser
has three fields in the form of a left hand side
(LHS), a RHS and a TYPE. After taking a sen-
tence as input, variables are initialized along with
a starting value of the chart as ROOT @ S. In
place of a dot symbol ‘•’ used in the Earley al-
gorithm, here an ‘@’ symbol is used because
the dot symbol is extensively used in the hier-
archal annotation of the URDU.KON-TB tree-
bank, from which the grammar productions are
extracted. The working of the algorithm is simi-
lar to the Earley’s algorithm except the modifica-
tions in the PREDICTOR(), SCANNER() and
a COMPLETER() presented in Sections 4.1, 4.2
and 4.7, respectively. Besides these some addi-
tional functions are introduced like an EDITOR()
for an automatic editing of discontinuous parses,
a BUILDER() for building the parse trees and
a BACKPOINTER() for calculating the back-
pointers.
Algorithm 2 Urdu Parser
</bodyText>
<listItem confidence="0.959101333333333">
1: function URDU-PARSER(grammar)
2: Input: Sentence D reading a sentence
3: (id, fi, fj, fid) ← 0
4: chart[0].add(“id”, “ROOT @ S”, “0,0”, “ ”, “Seed”)
5: for i ← 0 to LENGTH(sentence[]) do
6: scannerFlag ← false, id ← 1
7: Print: chart[i] → (StateId, Rule, @Position, BackPointer, Op-
eration)
8: for j ← 0 to ChartSize[i] do D Loop for chart entries
9: currentRule ← chart[i].getRule(j).split(” ”)
10: (tempString, index) ←(string-after-@, @Position) in
currentRule
</listItem>
<figure confidence="0.665551888888889">
11: if tempString = “ ” then
12: call COMPLETER() D calling completer procedure
13: else
14: rs ← All grammar rules with LHS = tempString
15: if rs.next() =6 false then D checking rs is not empty
16: call PREDICTOR() D calling predictor procedure
17: else
18: call SCANNER()
19: end if
20: end if
21: if scannerFlag=false &amp; j+1=chartSize[i] &amp;
i 6=LENGTH(sentence[]) then
22: call EDITOR()
23: end if
24: end for
25: end for
26: call BUILDER()
27: end function
</figure>
<subsectionHeader confidence="0.310427">
During processing of
</subsectionHeader>
<bodyText confidence="0.992837714285715">
COMPLETER(), PREDICTOR() and
SCANNER(), some sort of parsing disconti-
nuities can happen. To check these types of
phenomena, an EDITOR() will come into an ac-
tion and it will remove all the faulty states and the
charts causing discontinuity up to a right choice of
parsing as discussed in Section 4.6. At the end of
external loop, the generated parsed-solutions have
been stored in the form of the charts with entries,
but not in the form of parsed trees. To represent
parsed solutions in the form of bracketed parsed
trees, a BUILDER() function will be executed,
which will construct the parsed trees of solutions
by manipulating the back-pointers calculated in
the COMPLETER() function. The BUILDER()
is able to display all parsed solutions of a given
sentence as discussed in Section 4.4 and then the
Algorithm 2 for the Urdu parser is exited with
the complete generation of charts and bracketed
parsed trees. The algorithms called by the Urdu
→;
</bodyText>
<page confidence="0.995451">
39
</page>
<bodyText confidence="0.9961585">
parser are discussed briefly in Section 4 along
with their issues.
</bodyText>
<sectionHeader confidence="0.902617" genericHeader="method">
4 Issues Analysis and Their Evaluation
Through Extensions
</sectionHeader>
<subsectionHeader confidence="0.999095">
4.1 Eliminating L Type Useless Predictions
</subsectionHeader>
<bodyText confidence="0.999977974358974">
Earley’s Predictor() adds useless productions in
charts which causes the Urdu parser to end up with
a discontinuous parse for a given sentence. Sup-
pose, the current token to be parsed in an input
sentence is a proper noun uAg ‘Khan’ and there is
a NL type production NP → @ N.PROP N.PROP
residing in the current chart of the parser, where
N.PROP is the tag for proper noun. The ‘@’
symbol before a non-terminal on the RHS of the
production is the case of predictor and the non-
extended PREDICTOR() adds all the available L
type productions of N.PROP into the chart from
the grammar, even they are not required. Only
the relevant production N.PROP → @ vAg has
to be added in the chart. This addition of irrele-
vant/useless productions is also true for other lex-
ical items e.g. adjectives, personal pronouns, case
markers, etc. These useless additions cause the
wastage of time and increase the chance of mis-
leading direction towards a discontinuous parse.
To resolve this issue, the PREDICTOR() of the
existing Earley’s Algorithm is modified in the
Urdu parser as follows.
When the main parsing Algorithm 2 calls the
extended PREDICTOR() then it checks the type
of production either as NL or L in contrast of the
Earley algorithm. The handling of NL type pro-
ductions is same but in dealing of L type of pro-
ductions, the PREDICTOR() is introduced with
another condition, which enforces the predictor to
add only the relevant productions into the respec-
tive charts. It matches the token at the RHS of
the predicted-production with the current token in
an input sentence. This condition eliminates the
limited possibility of misleading direction towards
the discontinuous state. The wastage-time factor
is reduced to O(n) after the removal of irrelevant
matching, where n is the number of tokens in an
input sentence.
</bodyText>
<subsectionHeader confidence="0.942118">
4.2 Irrelevant POS Selection
</subsectionHeader>
<bodyText confidence="0.9784278">
In the Earley’s parsing algorithm, the
Scanner() only matches the RHS of the
L type production with the current token in a
given sentence and causes a selection of L type
production with the wrong POS. For example, the
verb ÿïf ‘is’ has different tags in the grammar. It
can act as an auxiliary in a sentence with present
tense e.g. VAUX.PRES → ÿï . It can behave as
f
a copula verb e.g. V.COP.PRES → ÿï and it can
f
also act as a main verb e.g. V.PRES → ÿïf . This
concept of having more than one tag is true for
other lexical items. So, if this L type production
VAUX.PRES → @ ÿïf is existed in a current chart
as right candidate then the Scanner() of the
Earley algorithm can select other available pro-
ductions from the grammar due to a check on the
RHS only. This can cause the wrong solution or a
discontinuous state during the parsing. To remove
this issue, the Scanner() is extended in the
same way as was done with the PREDICTOR()
in Section 4.1. At this level, this solution solves
the issue described below, but it is completed in
Section 4.6.
When the SCANNER() is called, it extracts a
relevant L type production from the grammar af-
ter matching the LHS and the RHS completely. It
adds only the true L type production in a new chart
after checking three additional conditions. At first,
it checks that the chart number is not exceeding the
length of a sentence. At second, it checks that the
token in the current processing L type production
is equal to the current token in a given sentence.
After that if the scannerFlag is false, then the
new entry of the matched L type production is
added into the new chart. During this process, the
scannerFlag is set to a true value along with
a record of some variables fi, fj, and fid,
which will be used in the EDITOR() discussed
in Section 4.6. By introducing this modification,
the possibility of wrong selection of the produc-
tion from the grammar is abandoned. An issue
related to this problem is still remained, which is
addressed and resolved in Section 4.6.
</bodyText>
<subsectionHeader confidence="0.992951">
4.3 Back-Pointers Calculation
</subsectionHeader>
<bodyText confidence="0.9999191">
Earley parsing algorithm is a generator or a rec-
ognizer and hence can not produce the parse trees
or the bracketed trees. To produce the parse trees
or the bracketed trees, an unimplemented idea of
back-pointers by Earley (1968) is implemented
and presented in Algorithm 3. To understand the
calculation of the back pointers, a sentence given
in example 1 is parsed from the Urdu parser. The
charts generated through the Urdu parser are de-
picted in Figure 2. Only the relevant states are dis-
</bodyText>
<page confidence="0.980363">
40
</page>
<bodyText confidence="0.8852605">
1: function BACKPOINTER(previousRule, dummy@Position, i, char
2:backPointer← “”
played as can be inferred from the non-sequential
values of the STATEID column. The column
DOT-POSITION is basically the position of ‘@’
in productions.
</bodyText>
<figure confidence="0.864655426229508">
Algorithm 3 Back Pointer
(l + “-” +
chart[l].getStateId(m) +“ ”+backPointer)
15: dummy@P = chart[l].get@Position(m).split(”,”)
D getting ‘@’ position
16: l ← dummy@P[0] D updating loop counter l
17: l ← l + 1
18: tempIndex ← tempIndex-1
19: NT ← previousRule[tempIndex]
20: break
21: else
22: cRule.clear()
23: end if
24: end for
25: else
26: break
27: end if
28: end for
29: end function
Algorithm 4 Builder
1: function BUILDER(Sentence[], chartSize[], chart[])
2: num=0, chartN = LENGTH(Sentence[])
3: for count ← chartSize[LENGTH(Sentence[]]-1 to 0 step -1
do
4: dummystr ←“S” and rule
chart[chartN].getRule(count).split(“ ”)
5: if rule[0] = dummystr then
6: num = num + 1
�ize, char&amp;.add(chartN+“-”+chart[chartN].getStateId(count))
end if
9: end for
10: tree[] ← new BTree[num]
11: for i ← 0 to SIZE(bp)-1 do
12: tree[i].build(bp.get(i), chart) D building tree with pointers
13: end for
14: for i ←0 to SIZE(bp)-1 do
15: tree[i].prepare(chart)
16: end for
17: for i ←0 to SIZE(bp)-1 do D loop for displaying all parsed trees
18: bracketedSentenceLength ← tree[i].getSize() and
left ← 0
19: if bracketedSentenceLength &gt; 0 then
20: Print : Bracketed Parse Tree “+(i+1)+” of “+SIZE(bp)+”
21: for j ←0 to bracketedSentenceLength-1 do
22: if tree[i].getString(j) = “(” then
23: left = left + 1 and Print : newline
24: for tab ←0 to left-1 do
25: Print : eight spaces
26: end for
27: Print : tree[i].getString(j)
28: else if tree [i].getString(j) = “)” then
29: left = left − 1 and Print : tree[i].getString(j)
30: else
31: Print : space+tree[i].getString(j)+space
32: end if
33: end for
34: end if
35: end for
36: end function
←
←
</figure>
<equation confidence="0.691550285714286">
(1) ÿïøPðQå�• àAîfE� úæêK.Q»&apos; A¿ à@
f
un kA zikr bHI yahAN
their/P.PERS of/CM reference/N also/PT.INTF here/ADV.SPT
zarUrI hE
essential/ADJ.MNR is/V.COP.PRES
‘Their reference is also essential here’
</equation>
<bodyText confidence="0.999913">
The COMPLETER() calls the Algorithm 3 of
BACKPOINTER() to calculate the values of the
back-pointers. For example, during the process-
ing of a production KP.POSS P.PERS @ CM
at STATEID 3 in chart 1 of Figure 2, a pro-
cessed non-terminal P.PERS before the ‘@’ in
the RHS of the production is located in the
chart 1 at 0th position. The located “1-0” value
of the backPointer is then displayed by the
COMPLETER() in the same state of the chart.
The rest of the back pointers are calculated in the
same way. These back-pointers are further used
in building the bracketed parse trees discussed in
Sections 4.4 and 4.7.
</bodyText>
<subsectionHeader confidence="0.999534">
4.4 Building Bracketed Parse Trees
</subsectionHeader>
<bodyText confidence="0.999979875">
The possible bracketed parse trees are evaluated
and displayed by the BUILDER() function dis-
played in Algorithm 4. Both the BUILDER() and
the BACKPOINTER() contribute to shift our Al-
gorithm 2 from a generator to a parser in contrast
of the Earley’s algorithm. After displaying chart
entries in Figure 2 for a sentence given in exam-
ple 1, the Urdu parser calls the BUILDER(). At
first, it locates all the solution productions from
the last chart and stores their back-pointers in a
list e.g. “8-1” value for the solution production
ROOT S @ in the last chart of Figure 2. A user
defined method build() is called then. This
method builds an unformatted intermediate brack-
eted parse tree with the interlinked back-pointers
from the chart states and reveals the leaf nodes
</bodyText>
<equation confidence="0.7562685">
only as ( 8-1 ( 4-1 ( 2-2 ( 1-0 ) ( 2-0 A¿ ) ) ( 3-0 Q»�X )
( 4-0 úæêK. ) ) ( 5-1 ( 5-0 àAî_) ) ( 6-1 ( 6-0 øPðQå;• ) ) ( 7-1
f
( 7-0 ÿïf ) ) ( 8-0 . ) ). This intermediate parse tree can
</equation>
<bodyText confidence="0.961793428571429">
be understood well by looking at the given back-
pointers in the respective chart states.
Another user defined method prepare() pre-
pares the intermediate parse tree into a com-
plete unformatted parse tree as ( S ( NP.NOM-SUB
( KP.POSS ( P.PERS 0@) ( CM A¿) ) ( NQ»�X) ( PT.INTF úæêK.
) ) (ADVP-SPT-MODF (ADV.SPT àAîE� ) ) ( ADJP-MNR-
</bodyText>
<listItem confidence="0.970135166666667">
3: tempIndex ← previousRule.indexOf(“@”)
4: tempIndex ← tempIndex-1 D subtracting index
5: NT ← previousRule.get(tempIndex)
6: k ← dummy@Position[0]
7: for l ← i to k step -1 do D loop for backward backpointers
8: if tempIndex &gt; 0 then
9: form ← 0 to chartSize[l]-1 do
10: pString ← chart[l].getRule(m).split(“ ”)
11: cRule.add(pString[]) D store pString in cRule
12: tIndex ← cRule.indexOf(“@”)
13: if (NT = cRule[0]) &amp; (tIndex+1 = SIZE(cRule)) then
14: backPointer
</listItem>
<page confidence="0.676374">
f
41
</page>
<figureCaption confidence="0.998368">
Figure 2: A back-pointer calculation example of the Urdu parser
</figureCaption>
<bodyText confidence="0.9322285">
PLINK ( ADJ.MNR øPðQå`• ) ) ( VCMAIN ( V.COP.PRES
ÿïf ) ) ( M.S . ) ) . This prepare() method only re-
places the back-pointers with the LHS of the rele-
vant productions. Finally, the bracketed parse tree
is displayed in a formatted way as depicted in Fig-
ure 3.
</bodyText>
<figureCaption confidence="0.977375">
Figure 3: An output of the BUILDER() method
</figureCaption>
<subsectionHeader confidence="0.934216">
4.5 Empty Productions
</subsectionHeader>
<bodyText confidence="0.999967454545454">
Empty productions are divided into two cate-
gories. The first one is related to diacritic produc-
tions and the second one is related to non-diacritic
productions. It can cause the discontinuity during
the parsing because the lexical item may or may
not present for both the categories in a given sen-
tence. Only the first category of diacritic produc-
tions is discussed here to provide an idea about the
issues related to empty productions.
In modern Urdu, the diacritics may or may not
appear in the text e.g. uA�J�k� H @ AbE h2ayAt ‘The
</bodyText>
<equation confidence="0.468086">
s &amp;quot;
</equation>
<bodyText confidence="0.994921142857143">
water of life’ and AJ.K�Q��®�K taqrIban ‘almost’. The
first example is related to compound words and
the second one is an independent word. The zErE-
Iz3Afat (a diacritic for addition) under the last let-
ter H.~ b of the first word in the first example is
still in use in the modern Urdu writing. Similar
is the case of tanwin (a diacritic for final post-
</bodyText>
<subsectionHeader confidence="0.520354">
s
</subsectionHeader>
<bodyText confidence="0.9819663">
nasalization) on the last letter @ a in the second
example. There are also other diacritics in use as
well e.g. zEr, zabar, pEsh, taSdId, etc.
In the grammar of the Urdu parser, a DIA
tag is used to represent the diacritics e.g. DIA
→ *, where ‘*’ represents the absence of a di-
acritic or an empty production. During parsing,
a compound word may or may not appear with
a diacritic e.g.íºÓQ Sehr makkah ‘The city of
f
</bodyText>
<page confidence="0.998065">
42
</page>
<bodyText confidence="0.999950829787234">
Makkah’. This example has two words QîfD�... Sehr
‘city’ and the íºÓ makkah ‘Makkah’, but the dia-
critic is absent between the two words. In such
cases, its presence is by default understood by the
native speakers. The production extracted from
the grammar to handle this compound word is
the NP-SPT —* @ N.SPT DIA N.PROP.SPT. Af-
ter processing of the first word Sehr/N.SPT by
the SCANNER(), the production becomes NP-
SPT —* N.SPT @ DIA N.PROP.SPT. Now, the
PREDICTOR() deals this DIA empty produc-
tion implicitly by moving the ‘@’ ahead and
adds the updated production NP-SPT —* N.SPT
DIA @ N.PROP.SPT in the same chart. Sim-
ilarly, the second word makkah/N.PROP.SPT is
processed by the SCANNER() and the production
final state becomes like this NP-SPT —* N.SPT
DIA N.PROP.SPT @. The problem with this so-
lution adopted from (Aycock and Horspool, 2002)
is that it performs the transaction silently with the
compound words and also with the non-compound
words at such positions where it is not needed. For
example, If this is the case as discussed then the
solution is perfect, but in the case of the non com-
pound words, if two independent wordsQêÃgHar
‘The house’ and íºÓ makkah ‘Makkah’ appear in
the same position like compound words e.g. ÿïf álu
íºÓ QêÃ gHar makkah mEN hE ‘The house is in
Makkah’, then this solution can not identify the
context and it applies the transaction in the same
way due to the same POS tagging of gHar and the
Sehr. This solution causes frequent discontinuity
during the parsing and its property of self deci-
sion at the irrelevant places makes the things more
worse.
Due to high frequency of the DIA produc-
tions in the grammar, the proposed solution (Ay-
cock and Horspool, 2002) was implemented in
the PREDICTOR() but the results found were not
promising. So, an explicit method to represent the
absent value has been chosen, through which an
asterisk ‘*’ is usually typed in a given sentence to
represent the absence of the diacritics, arguments,
lexical items, etc. At present, due to this explicit
approach, the Urdu parser is jelling with the gram-
mar without any issue related to empty produc-
tions.
</bodyText>
<subsectionHeader confidence="0.993996">
4.6 Lexical Dynamic Behavior
</subsectionHeader>
<bodyText confidence="0.99594043902439">
The issue is related to a class of words which
has the following attributes like the homonym,
homograph, homophone, heteronym and the pol-
ysemes. A strict definition is considered to these
attributes, that means at least the words have the
same spelling. The case of homonym words in a
strict sense is discussed here and the same concept
is applicable on other attributes as well.
For example, the word ú» kI is a homonym in
Urdu. It can behave in two ways e.g. a pos-
sessive case marker and a verb. Being a posses-
sive case marker, it contains a possessive meaning
‘of’ in 2. On the other hand, it contains a mean-
ing of ‘did’ in 3. In the grammar, this word has
different POS tags as a case marker (CM), a per-
fective verb (V.PERF) and a perfective light verb
(V.LIGHT.PERF). Suppose the word ‘kI’ actually
comes as a V.PERF at the end of a given sen-
tence. For its processing, the Scanner() can
pick up the wrong choice with the CM and the
V.LIGHT.PERF, if these choices are available in
the current chart at earlier positions as compared
to the right choice. Due to this wrong selection,
the relevant productions of a verb will not be com-
pleted in the next chart and the parser will go into
the discontinuous state. To address this issue, the
Scanner() of the Earley algorithm is modified,
which records the failed state in variables fi, fj
and fid. These failed states are then utilized by
the EDITOR() in Algorithm 5, which is called
by the Urdu parser to heal this discontinuous state.
The failed chart and the states are deleted first. Af-
ter skipping the wrong choice e.g. the CM —* ú»in
a chart, the next choice from available homonyms
is selected and tried to parse. In this way, the next
choice V.PERF —* ú» is located and the ith and
jth loop variables of the Urdu parser are set to that
choice for further processing. Continuing in this
way, the parser finally gets a direction towards the
optimal solution.
Algorithm 5 Editor
</bodyText>
<listItem confidence="0.735701352941176">
1: function EDITOR(i, id, fi, fj, fid, chart, chartSize)
2: Drop and re-initialize chart[i + 1]
3: for z ← i to fi+1 step -1 do
4: Drop and re-initialize chart[z]
5: end for
6: rule ← chart[fi].getRule(fj).split(“ ”) D splitting rule with space
7: for z ← 0 to chartSize[fi]-1 do
8: temprule ← chart[fi].getRule(z).split(“ ”)
9: if temprule[2] = rule[2] then
10: if !(temprule[0] = rule[0]) then
11: j ← z − 1, i ← fi, id ← z
12: break
13: end if
14: end if
15: end for
16: end function
(2) H. A�J» ú» AJ�Ëñk.
</listItem>
<page confidence="0.999502">
43
</page>
<figure confidence="0.919413428571429">
jUlIA=kI kitAb
Julia.Fem.Sg=Poss book.Fem.Sg
‘The book of Julia’
(3) C� � uL� SLI ��I
us=nE Ek bAt kI hE
he.Sg=Erg a talk.Fem.Sg do.Perf.Sg be.Pres.Sg
‘He did a talk’
</figure>
<subsectionHeader confidence="0.991819">
4.7 Subordinate Clause Limitations
</subsectionHeader>
<bodyText confidence="0.999990857142857">
Basically, the issue is related to conjuncted
sub-sentences or the subordinate clause, when
the number of conjuncted sub-sentences becomes
greater than one. The issue does not appear
often and it is related to the NL type productions,
specially the conjuncted sub-sentences denoted
by SBAR as below. A sentence of 23 tokens
with two conjuncted sub-sentences highlighted
with the SBAR is an evidence of this issue.
During the processing of a production for the
sentence marker M.S → - @ in the last (23rd)
chart, the order of the complete productions
should be as follows. The ‘@’ at the end rep-
resents the complete status of the productions.
</bodyText>
<equation confidence="0.988234166666667">
M.S → - @
SBAR → C.SBORD NP.NOM-SUB SBAR
ADVP-MNR-MODF NP.NOM-MNR-OBJ
VCMAIN M.S @
S → KP-INST-MODF KP.DAT-SUB NP.NOM-OBJ
VCMAIN SBAR @
</equation>
<bodyText confidence="0.999285333333333">
But, unfortunately, the parser went into a dis-
continuous state during the processing of the last
chart with the following productions.
</bodyText>
<table confidence="0.875849">
M.S → - @
SBAR → C.SBORD NP.NOM-SUB SBAR
ADVP-MNR-MODF
NP.NOM-MNR-OBJ VCMAIN M.S @
SBAR → C.SBORD NP.NOM-SUB SBAR @
ADVP-MNR-MODF
NP.NOM-MNR-OBJ VCMAIN M.S
ADVP-MNR-MODF → @ ADV.MNR
</table>
<bodyText confidence="0.998928264705882">
Up to completion of the first SBAR → ... @
production, the parser performed well. Then
Completer() went back to search another
production which contained an incomplete non-
terminal SBAR having ‘@’ before it e.g. @
SBAR. The Completer() made a fault there
in chart 12 in the presence of wrong choices at
higher precedence. It found an incomplete SBAR
production. After moving the ‘@’ forward, it
added the updated production in the last chart
as can be seen in the given productions. After-
wards, the PREDICTOR() became activated by
seeing the ‘@’ before the ADVP-MNR-MODF
and the parser went into a wrong direction. To
resolve this issue, it is needed to allow the Ear-
ley’s Completer() to go back further until a
successful parse. The description of the extended
Completer() is as follows.
When the Urdu parser called the
COMPLETER(), it first sets the
completerCheck flag to false, which will
be used to back track a right choice among
the NL type productions. After calculating
the back-pointers, the updated production
entry is then added and printed by setting
the completerCheck to true. If the
completerCheck is found to be true and
the chart number is less than the length of a
sentence then a solution has been found and
there is no need to go back. However, if the
completerCheck is found to be true and the
chart number is greater or equal to the length of a
sentence then the COMPLETER() is allowed to
back track by setting its flag to its default value.
</bodyText>
<sectionHeader confidence="0.999988" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999979677419355">
The division of training and test data is discussed
in Section 3. To make the test data more valu-
able and reliable for results, the beginning ten sen-
tences from each hundred of 1400 sentences of the
URDU.KON-TB treebank were selected. The test
data so contained 140 sentences in all. In test data,
the minimum, average and the maximum length
is found to be 5, 13.73 and 46 words per sentence.
All items which can exists in a normal text are con-
sidered e.g. punctuation, null elements, diacrit-
ics, headings, regard titles, Hadees (the statements
of prophets), antecedents and anaphors within a
sentence, and others except the unknown words,
which will be dealt in future. The PARSEVAL
measures are used to evaluate the results. The
PARSEVAL measures are calculated in two ways
which are depicted in Table 1.
At first, the values as per columns headings in
Table 1 are calculated on the basis of constituents
for each individual sentence. Then these values
are stored in a text file with these headings. The
values existed in each column of the text file are
summed up and then divided by the total number
of 140 values in each column. The results thus ob-
tained are recorded in a row A-1 of Table 1 on av-
erage basis. Similarly, all the values in the Length,
Matched, Gold and the Test columns are summed
up individually from that text file and their sums
are recorded as can be seen in row T-2 of the table.
Their respective results for the Precision, Recall,
F-score and the Crossing Brackets are calculated
</bodyText>
<page confidence="0.997858">
44
</page>
<table confidence="0.509518333333333">
Sentences Length Matched Gold Test Precision Recall F-score Crossing
A-1 140 13.73 17 22 18 0.952 0.811 0.848 2
T-2 140 1922 2449 3107 2531 0.968 0.788 0.869 329
</table>
<tableCaption confidence="0.999767">
Table 1: Evaluation results of the Urdu parser
</tableCaption>
<bodyText confidence="0.999880288888889">
from these sums, which is a standard method of
calculation.
The Urdu parser outperforms the simple Hindi
dependency parser by Bharati et al. (2009) with
an additional recall of 22%. In (Bharati et al.,
2009), only precision and recall percentages are
given. Thats why only the precision and recall
percentages of labeled attachment (LA) are com-
pared. For chunks, intra-chunks and karakas, the
precision percentages of LA (LA-P) achieved by
the simple Hindi dependency parser are 82.3%,
71.2% and 74.1%, respectively. The average of
these LA-P percentages is 75.9%, which is 20.9%
less precision than the Urdu parser in row T-2.
Similarly, Hindi dependency parser achieved LA
recalls in case of chunks, intra-chunks and karakas
as 65.4%, 58.2% and 46.7% respectively. The av-
erage of these percentages is calculated as 56.8%,
which is now the final LA recall percentage of the
Hindi dependency parser. For comparison, the re-
call percentage of the Urdu parser used is men-
tioned in row T-2 as 78.8%. The values obtained
for the language variant parsers concludes that the
Urdu parser outperforms the simple Hindi depen-
dency parser with 22% increase in recall.
Multi-path shift-reduce parser (Mukhtar et al.,
2012b) for Urdu parsed 74 sentences successfully
out of 100 and it was then reported as a 74% of ac-
curacy. This evaluation is very weak because the
successful parsed sentences were not compared
with the gold standard. Recall is a value obtained
through dividing the Matched constituents with
the constituents available in the Gold data. As re-
call percentage in our case is 78.8%, so we can
say that the Urdu parser beats the multi-path shift-
reduce parser with a 4.8% increase in recall. On
the other hand, from the first 100 sentences of the
test data, the Urdu parser provides 89 sentences
with parsed solutions. Comparatively, the Urdu
parser has 15% more accuracy than the Multi-path
shift-reduce parser, but the parsed solutions were
not compared with the Gold data. So, by consider-
ing the safe side, we can repeat our argument that
the Urdu parser beats the multi-path shift-reduce
parser with a 4.8% increase in recall.
</bodyText>
<sectionHeader confidence="0.999142" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999989590909091">
The extended Urdu parser with rich encoded in-
formation in the form of a grammar is a state of
the art parsing candidate for morphologically rich
language variant Urdu. After removal of issues,
the output of the parser is so directed, speedy and
refined in a sense that no extra or the irrelevant L
type productions can be introduced by the Urdu
parser. It is really hard now that the Urdu parser
will select a wrong choice of production. If it hap-
pens then the Urdu parser has a tendency to correct
itself automatically. These all features enables the
Urdu parser comparable or better than the state of
the art in the domain of both the language vari-
ants. Urdu parser can help the linguists analyze the
Urdu sentences computationally and can be useful
in Urdu language processing and machine learn-
ing domains. By using this parser, the limited size
of the URDU.KON-TB treebank can also be in-
creased. This can be done after getting the partial
parsed trees of unknown sentences. These partial
parsed trees can be corrected and then imported
into the URDU.KON-TB treebank.
</bodyText>
<sectionHeader confidence="0.978151" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.99995575">
I would like to express my sincere gratitude to my
Supervisor Prof. Dr. Miriam Butt for her moti-
vation, enthusiasm, and immense knowledge. Her
guidance helped me in all the time of this work.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9993666">
Qaiser Abbas and A Nabi Khan. 2009. Lexical Func-
tional Grammar For Urdu Modal Verbs. In Emerg-
ing Technologies, 2009. ICET 2009. International
Conference on, pages 7–12. IEEE.
Qaiser Abbas and Ghulam Raza. 2014. A Com-
putational Classification Of Urdu Dynamic Copula
Verb. International Journal of Computer Applica-
tions, 85(10):1–12, January.
Qaiser Abbas, Nayyara Karamat, and Sadia Niazi.
2009. Development Of Tree-Bank Based Prob-
abilistic Grammar For Urdu Language. Interna-
tional Journal of Electrical &amp; Computer Science,
9(09):231–235.
Qaiser Abbas. 2012. Building A Hierarchical An-
notated Corpus Of Urdu: The URDU.KON-TB
</reference>
<page confidence="0.984113">
45
</page>
<reference confidence="0.999873238095238">
Treebank. Lecture Notes in Computer Science,
7181(1):66–79.
Qaiser Abbas. 2014. Semi-Semantic Part Of Speech
Annotation And Evaluation. In Proceedings of 8th
ACL Linguistic Annotation Workshop, pages 75–81,
Dublin, Ireland. Association for Computational Lin-
guistics.
Bhasha Agrawal, Rahul Agarwal, Samar Husain, and
Dipti M Sharma. 2013. An Automatic Approach
To Treebank Error Detection Using A Dependency
Parser. In Computational Linguistics and Intelligent
Text Processing, pages 294–303. Springer.
Wajid Ali and Sarmad Hussain. 2010. Urdu Depen-
dency Parser: A Data-Driven Approach. In Pro-
ceedings of Conference on Language and Technol-
ogy (CLT10).
John Aycock and R Nigel Horspool. 2002. Practical
Earley Parsing. The Computer Journal, 45(6):620–
630.
Rafiya Begum, Samar Husain, Arun Dhwaj,
Dipti Misra Sharma, Lakshmi Bai, and Rajeev
Sangal. 2008. Dependency Annotation Scheme For
Indian Languages. In IJCNLP, pages 721–726.
Akshar Bharati, Vineet Chaitanya, Rajeev Sangal,
and KV Ramakrishnamacharyulu. 1995. Natu-
ral Language Processing: A Paninian Perspective.
Prentice-Hall of India New Delhi.
Akshar Bharati, Medhavi Bhatia, Vineet Chaitanya,
and Rajeev Sangal. 1996. Paninian Grammar
Framework Applied To English. Technical report,
Technical Report TRCS-96-238, CSE, IIT Kanpur.
Akshar Bharati, Samar Husain, Dipti Misra Sharma,
and Rajeev Sangal. 2008. A Two-Stage Constraint
Based Dependency Parser For Free Word Order Lan-
guages. In Proceedings of the COLIPS Interna-
tional Conference on Asian Language Processing
2008 (IALP).
Akshar Bharati, Mridul Gupta, Vineet Yadav, Karthik
Gali, and Dipti Misra Sharma. 2009. Simple Parser
For Indian Languages In A Dependency Framework.
In Proceedings of the Third Linguistic Annotation
Workshop, pages 162–165. Association for Compu-
tational Linguistics.
Riyaz Ahmad Bhat, Sambhav Jain, and Dipti Misra
Sharma. 2012b. Experiments On Dependency Pars-
ing Of Urdu. In In Proceedings of The 11th Interna-
tional Workshop on Treebanks and Linguistic Theo-
ries (TLT11).
Miriam Butt and Tracy Holloway King. 2007. Urdu
In A Parallel Grammar Development Environment.
Language Resources and Evaluation, 41(2):191–
207.
Miriam Butt and Gillian Ramchand. 2001. Complex
Aspectual Structure In Hindi/Urdu. M. Liakata, B.
Jensen, &amp; D. Maillat, Eds, pages 1–30.
Miriam Butt and Jafar Rizvi. 2010. Tense And Aspect
In Urdu. Layers of Aspect. Stanford: CSLI Publica-
tions.
Miriam Butt. 1993. Hindi-Urdu Infinitives As NPs.
South Asian Language Review: Special Issue on
Studies in Hindi-Urdu, 3(1):51–72.
Miriam Butt. 2003. The Light Verb Jungle. In Work-
shop on Multi-Verb Constructions.
Jay Clark Earley. 1968. An Efficient Context-Free
Parsing Algorithm. Ph.D. thesis, Carnegie Mellon
University, Pittsburgh, PA, USA. AAI6907901.
Jay Earley. 1970. An Efficient Context-Free Parsing
Algorithm. Communications of the ACM, 13(2):94–
102.
Wenbin Jiang, Hao Xiong, and Qun Liu. 2009. Mu-
tipath Shift-Reduce Parsing With Online Training.
CIPS-ParsEval-2009 shared task.
Abdul Jamil Khan. 2006. Urdu/Hindi: An Artificial
Divide: African Heritage, Mesopotamian Roots, In-
dian Culture &amp; Britiah Colonialism. Algora Pub.
Gary F. Simons &amp; Charles D. Fennig Lewis, M. Paul.
2013. Ethnologue: Languages Of The World, 17th
Edition. Dallas: SIL International.
John R McLane. 1970. The Political Awakening In
India. Prentice Hall.
Neelam Mukhtar, Mohammad Abid Khan, and Fa-
tima Tuz Zuhra. 2011. Probabilistic Context Free
Grammar For Urdu. Linguistic and Literature Re-
view, 1(1):86–94.
Neelam Mukhtar, Mohammad Abid Khan, and Fa-
tima Tuz Zuhra. 2012a. Algorithm For Developing
Urdu Probabilistic Parser. International journal of
Electrical and Computer Sciences, 12(3):57–66.
Neelam Mukhtar, Mohammad Abid Khan, Fatima Tuz
Zuhra, and Nadia Chiragh. 2012b. Implementation
Of Urdu Probabilistic Parser. International Journal
of Computational Linguistics (IJCL), 3(1):12–20.
Reut Tsarfaty, Djam´e Seddah, Yoav Goldberg, Sandra
Kuebler, Marie Candito, Jennifer Foster, Yannick
Versley, Ines Rehbein, and Lamia Tounsi. 2010.
Statistical Parsing Of Morphologically Rich Lan-
guages (SPMRL): What, How And Whither. In Pro-
ceedings of the NAACL HLT 2010 First Workshop
on Statistical Parsing of Morphologically-Rich Lan-
guages, pages 1–12. Association for Computational
Linguistics.
Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and
Joakim Nivre. 2013. Parsing Morphologically
Rich Languages: Introduction To The Special Issue.
Computational Linguistics, 39(1):15–22.
</reference>
<page confidence="0.999613">
46
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.194857">
<title confidence="0.727834333333333">Exploiting Language Variants Via Grammar Parsing Morphologically Rich Information Qaiser</title>
<author confidence="0.280496">Fachbereich</author>
<affiliation confidence="0.915345">Universit¨at</affiliation>
<address confidence="0.981874">78457 Konstanz,</address>
<email confidence="0.999259">qaiser.abbas@uni-konstanz.de</email>
<abstract confidence="0.99222075">In this paper, the development and evaluation of the Urdu parser is presented along with the comparison of existing resources for the language variants Urdu/Hindi. This parser was given a linguistically rich grammar extracted from a treebank. This context free grammar with sufficient encoded information is comparable with the state of the art parsing requirements for morphologically rich and closely related language variants Urdu/Hindi. The extended parsing model and the linguistically rich grammar together provide us promising parsing results for both the language variants. The parser gives 87% of f-score, which outperforms the multi-path shift-reduce parser for Urdu and a simple Hindi dependency parser with 4.8% and 22% increase in recall, respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Qaiser Abbas</author>
<author>A Nabi Khan</author>
</authors>
<title>Lexical Functional Grammar For Urdu Modal Verbs.</title>
<date>2009</date>
<booktitle>In Emerging Technologies,</booktitle>
<pages>7--12</pages>
<publisher>IEEE.</publisher>
<marker>Abbas, Khan, 2009</marker>
<rawString>Qaiser Abbas and A Nabi Khan. 2009. Lexical Functional Grammar For Urdu Modal Verbs. In Emerging Technologies, 2009. ICET 2009. International Conference on, pages 7–12. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qaiser Abbas</author>
<author>Ghulam Raza</author>
</authors>
<title>A Computational Classification Of Urdu Dynamic Copula Verb.</title>
<date>2014</date>
<journal>International Journal of Computer Applications,</journal>
<volume>85</volume>
<issue>10</issue>
<contexts>
<context position="9932" citStr="Abbas and Raza, 2014" startWordPosition="1613" endWordPosition="1616">.KON-TB treebank. The SSP tag set hierarchy has 22 main tag categories which are divided into sub-categories based on morphology and semantics. In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semantics at POS level. In Figure 1, the hierarchy of tag labels for verb V is divided into three levels of depth. The first level contains only one label to distinguish a verb V from other POS labels. The second level contains 11 subcategories of V to represent different morphological or functional forms e.g. V.COP (V as a copula verb (Abbas and Raza, 2014)), V.IMPERF (V has an imperfective form (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case </context>
</contexts>
<marker>Abbas, Raza, 2014</marker>
<rawString>Qaiser Abbas and Ghulam Raza. 2014. A Computational Classification Of Urdu Dynamic Copula Verb. International Journal of Computer Applications, 85(10):1–12, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qaiser Abbas</author>
<author>Nayyara Karamat</author>
<author>Sadia Niazi</author>
</authors>
<title>Development Of Tree-Bank Based Probabilistic Grammar For Urdu Language.</title>
<date>2009</date>
<journal>International Journal of Electrical &amp; Computer Science,</journal>
<volume>9</volume>
<issue>09</issue>
<contexts>
<context position="3673" citStr="Abbas et al., 2009" startWordPosition="567" endWordPosition="570">n Section 3. A context free grammar (CFG) is extracted from the URDU.KON-TB treebank computationally. The development procedure and the depth of encoded information in the grammar is presented in Section 2. The grammar is then given to an extended dynamic programming parsing model known as the Earley parsing algorithm (Earley, 1970). The extended parsing model for Urdu is then called as the Urdu parser and given in Section 3. This algorithm is language independent and is capable to parse the MRLs like the CKY (Cocke-KasamiYounger) parsing algorithm as advocated in (Tsarfaty et al., 2013) and (Abbas et al., 2009). Issues faced during the parsing are discussed in Section 4. By applying a rich grammar along with the ex36 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36–46, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics tended parsing model, promising results obtained are discussed in Section 5. Conclusions along with the future directions are presented in Section 6. Similarly, the related work of language variants is described in Section 1.1, which set a path towards the construction of the Urdu parser. 1.1 Related Work In</context>
</contexts>
<marker>Abbas, Karamat, Niazi, 2009</marker>
<rawString>Qaiser Abbas, Nayyara Karamat, and Sadia Niazi. 2009. Development Of Tree-Bank Based Probabilistic Grammar For Urdu Language. International Journal of Electrical &amp; Computer Science, 9(09):231–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qaiser Abbas</author>
</authors>
<title>Building A Hierarchical Annotated Corpus Of Urdu: The URDU.KON-TB Treebank.</title>
<date>2012</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>7181</volume>
<issue>1</issue>
<contexts>
<context position="2820" citStr="Abbas, 2012" startWordPosition="427" endWordPosition="428">sentences, promising results for MRLs can not be achieved. Complex morphosyntactic interactions may impose constraints, which lead to explicit encoding of such information. The best broad coverage and robust parsers to date have grammars extracted from treebanks and the depth of information encoded in an annotation correlates with the parsing performance (Tsarfaty et al., 2013). To fulfill the encoding of information in an annotation, a treebank for Urdu known as the URDU.KON-TB treebank with sufficient encoded information at morphological, POS, syntactic and functional level was constructed (Abbas, 2012). Its annotation was found reliable according to the Krippendorffs α values achieved in (Abbas, 2014) but its reliability or the suitability for machine learning (ML) can be evaluated with the development of an Urdu parser presented in Section 3. A context free grammar (CFG) is extracted from the URDU.KON-TB treebank computationally. The development procedure and the depth of encoded information in the grammar is presented in Section 2. The grammar is then given to an extended dynamic programming parsing model known as the Earley parsing algorithm (Earley, 1970). The extended parsing model for</context>
<context position="5607" citStr="Abbas, 2012" startWordPosition="899" endWordPosition="900"> definite clause grammar (PDCG). In this work, a parser was not designed but a built-in prolog parser was used, due to which it was not considered to be the candidate for comparison. A simple dependency parser for Hindi was developed by Bharati et al. (2009). The parser used a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependency annotation but people are stick to the standard norms. The Hindi treebank is rich in functional information as compared to morphological, POS and syntactical information. Due to differences in the de1http://www2.parc.com/i</context>
<context position="8979" citStr="Abbas, 2012" startWordPosition="1443" endWordPosition="1444">number of 74 sentences having length not more than 10 words were parsed successfully from 100 sentences, which were then quoted as a 74% of accuracy. The raw corpus used in the development of this parser is partially the same as compared to the Urdu parser (Section 3). A comparative study made is detailed in Section 5. 3http://www.maltparser.org/ 4http://faculty.washington.edu/fxia/treebank/ 37 Figure 1: A verb V example from the URDU.KON-TB treebank 2 Setup The URDU.KON-TB treebank having phrase structure (PS) and the hyper dependency structure (HDS) annotation with rich encoded information (Abbas, 2012; Abbas, 2014) is used for the training of the Urdu parser discussed in Section 3. The treebank has a semi-semantic POS (SSP) tag set, a semi-semantic syntactic (SSS) tag set and a functional (F) tag set. The morphological information in the labeling of the parsers lexicon can be explained by discussing the POS tag set of the URDU.KON-TB treebank. The SSP tag set hierarchy has 22 main tag categories which are divided into sub-categories based on morphology and semantics. In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semanti</context>
<context position="10932" citStr="Abbas, 2012" startWordPosition="1778" endWordPosition="1779">(copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This short discussion is about the idea of morphological and functional information encoded at POS level. This lexical information can be passed up to the syntactical level because the lexical items have some relationship with other lexical items in a sentence. The detail of syntactic (SSS) and functional (F) tag sets can be seen in (Abbas, 2012). A stack based extraction Algorithm 1 was designed to extract a context free grammar (CFG) from the URDU.KON-TB treebank. The CFG obtained is then given to the Urdu parser (Section 3) for sentence parsing. 3 Urdu Parser The URDU.KON-TB treebank is a manually annotated set of 1400 parsed sentences, which were then recorded in a text file on a computer in the form of 1400 bracketed sentences. Initial twenty bracketed-sentences from each hundred were separated in another text file, whose total 280 sentences were then used for the development of a test suite. The test suite was further divided in</context>
</contexts>
<marker>Abbas, 2012</marker>
<rawString>Qaiser Abbas. 2012. Building A Hierarchical Annotated Corpus Of Urdu: The URDU.KON-TB Treebank. Lecture Notes in Computer Science, 7181(1):66–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qaiser Abbas</author>
</authors>
<title>Semi-Semantic Part Of Speech Annotation And Evaluation.</title>
<date>2014</date>
<booktitle>In Proceedings of 8th ACL Linguistic Annotation Workshop,</booktitle>
<pages>75--81</pages>
<location>Dublin,</location>
<contexts>
<context position="2921" citStr="Abbas, 2014" startWordPosition="442" endWordPosition="443">mpose constraints, which lead to explicit encoding of such information. The best broad coverage and robust parsers to date have grammars extracted from treebanks and the depth of information encoded in an annotation correlates with the parsing performance (Tsarfaty et al., 2013). To fulfill the encoding of information in an annotation, a treebank for Urdu known as the URDU.KON-TB treebank with sufficient encoded information at morphological, POS, syntactic and functional level was constructed (Abbas, 2012). Its annotation was found reliable according to the Krippendorffs α values achieved in (Abbas, 2014) but its reliability or the suitability for machine learning (ML) can be evaluated with the development of an Urdu parser presented in Section 3. A context free grammar (CFG) is extracted from the URDU.KON-TB treebank computationally. The development procedure and the depth of encoded information in the grammar is presented in Section 2. The grammar is then given to an extended dynamic programming parsing model known as the Earley parsing algorithm (Earley, 1970). The extended parsing model for Urdu is then called as the Urdu parser and given in Section 3. This algorithm is language independen</context>
<context position="5621" citStr="Abbas, 2014" startWordPosition="901" endWordPosition="902">use grammar (PDCG). In this work, a parser was not designed but a built-in prolog parser was used, due to which it was not considered to be the candidate for comparison. A simple dependency parser for Hindi was developed by Bharati et al. (2009). The parser used a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependency annotation but people are stick to the standard norms. The Hindi treebank is rich in functional information as compared to morphological, POS and syntactical information. Due to differences in the de1http://www2.parc.com/isl/groups/nltt</context>
<context position="8993" citStr="Abbas, 2014" startWordPosition="1445" endWordPosition="1446">sentences having length not more than 10 words were parsed successfully from 100 sentences, which were then quoted as a 74% of accuracy. The raw corpus used in the development of this parser is partially the same as compared to the Urdu parser (Section 3). A comparative study made is detailed in Section 5. 3http://www.maltparser.org/ 4http://faculty.washington.edu/fxia/treebank/ 37 Figure 1: A verb V example from the URDU.KON-TB treebank 2 Setup The URDU.KON-TB treebank having phrase structure (PS) and the hyper dependency structure (HDS) annotation with rich encoded information (Abbas, 2012; Abbas, 2014) is used for the training of the Urdu parser discussed in Section 3. The treebank has a semi-semantic POS (SSP) tag set, a semi-semantic syntactic (SSS) tag set and a functional (F) tag set. The morphological information in the labeling of the parsers lexicon can be explained by discussing the POS tag set of the URDU.KON-TB treebank. The SSP tag set hierarchy has 22 main tag categories which are divided into sub-categories based on morphology and semantics. In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semantics at POS leve</context>
<context position="10582" citStr="Abbas, 2014" startWordPosition="1720" endWordPosition="1721">m (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This short discussion is about the idea of morphological and functional information encoded at POS level. This lexical information can be passed up to the syntactical level because the lexical items have some relationship with other lexical items in a sentence. The detail of syntactic (SSS) and functional (F) tag sets can be seen in (Abbas, 2012). A stack based extraction Algorithm 1 was designed to extract a context free grammar (CFG) from the URDU.KON-TB treebank. The CFG obtained is then given to the Urdu parser (Section 3) for sentence parsing. 3 Urdu Parser The URDU.KON-TB treebank is a</context>
</contexts>
<marker>Abbas, 2014</marker>
<rawString>Qaiser Abbas. 2014. Semi-Semantic Part Of Speech Annotation And Evaluation. In Proceedings of 8th ACL Linguistic Annotation Workshop, pages 75–81, Dublin, Ireland. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bhasha Agrawal</author>
<author>Rahul Agarwal</author>
<author>Samar Husain</author>
<author>Dipti M Sharma</author>
</authors>
<title>An Automatic Approach To Treebank Error Detection Using A Dependency Parser.</title>
<date>2013</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>294--303</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6854" citStr="Agrawal et al., 2013" startWordPosition="1088" endWordPosition="1091">as are the syntactico-semantic relations between the verbs and other related constituents in a sentence (Bharati et al., 1996) signs of the simple dependency parser for Hindi and the Urdu parser, only performance results are compared and presented in Section 5. Ali and Hussain used the MaltParser with its default settings in Urdu dependency parser (Ali and Hussain, 2010). When somebody performs experiments with MaltParser with its default settings then such evaluation results are advised not to be compared according to MaltParser license.3 The same exercise for parsing Hindi was performed in (Agrawal et al., 2013), but it was clearly mentioned in the work that MaltParser was used for error detection in the annotation of Hindi/Urdu treebank (HUTB).4 Similarly, the Urdu sentences were parsed in (Bhat et al., 2012b) using the same MaltParser. The experiments were performed to identify the parsing issues of Urdu and a development of parser was not claimed. Moreover, these data-driven systems are highly criticized on a given set of annotated corpus because they are not able to observe all morphological variants of a word form from it (Tsarfaty et al., 2013). A multi-path shift-reduce parsing algorithm was p</context>
</contexts>
<marker>Agrawal, Agarwal, Husain, Sharma, 2013</marker>
<rawString>Bhasha Agrawal, Rahul Agarwal, Samar Husain, and Dipti M Sharma. 2013. An Automatic Approach To Treebank Error Detection Using A Dependency Parser. In Computational Linguistics and Intelligent Text Processing, pages 294–303. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajid Ali</author>
<author>Sarmad Hussain</author>
</authors>
<title>Urdu Dependency Parser: A Data-Driven Approach.</title>
<date>2010</date>
<booktitle>In Proceedings of Conference on Language and Technology (CLT10).</booktitle>
<contexts>
<context position="6606" citStr="Ali and Hussain, 2010" startWordPosition="1050" endWordPosition="1053"> annotation but people are stick to the standard norms. The Hindi treebank is rich in functional information as compared to morphological, POS and syntactical information. Due to differences in the de1http://www2.parc.com/isl/groups/nltt/xle/ 2Karakas are the syntactico-semantic relations between the verbs and other related constituents in a sentence (Bharati et al., 1996) signs of the simple dependency parser for Hindi and the Urdu parser, only performance results are compared and presented in Section 5. Ali and Hussain used the MaltParser with its default settings in Urdu dependency parser (Ali and Hussain, 2010). When somebody performs experiments with MaltParser with its default settings then such evaluation results are advised not to be compared according to MaltParser license.3 The same exercise for parsing Hindi was performed in (Agrawal et al., 2013), but it was clearly mentioned in the work that MaltParser was used for error detection in the annotation of Hindi/Urdu treebank (HUTB).4 Similarly, the Urdu sentences were parsed in (Bhat et al., 2012b) using the same MaltParser. The experiments were performed to identify the parsing issues of Urdu and a development of parser was not claimed. Moreov</context>
</contexts>
<marker>Ali, Hussain, 2010</marker>
<rawString>Wajid Ali and Sarmad Hussain. 2010. Urdu Dependency Parser: A Data-Driven Approach. In Proceedings of Conference on Language and Technology (CLT10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Aycock</author>
<author>R Nigel Horspool</author>
</authors>
<date>2002</date>
<journal>Practical Earley Parsing. The Computer Journal,</journal>
<volume>45</volume>
<issue>6</issue>
<pages>630</pages>
<contexts>
<context position="28470" citStr="Aycock and Horspool, 2002" startWordPosition="4854" endWordPosition="4857">duction extracted from the grammar to handle this compound word is the NP-SPT —* @ N.SPT DIA N.PROP.SPT. After processing of the first word Sehr/N.SPT by the SCANNER(), the production becomes NPSPT —* N.SPT @ DIA N.PROP.SPT. Now, the PREDICTOR() deals this DIA empty production implicitly by moving the ‘@’ ahead and adds the updated production NP-SPT —* N.SPT DIA @ N.PROP.SPT in the same chart. Similarly, the second word makkah/N.PROP.SPT is processed by the SCANNER() and the production final state becomes like this NP-SPT —* N.SPT DIA N.PROP.SPT @. The problem with this solution adopted from (Aycock and Horspool, 2002) is that it performs the transaction silently with the compound words and also with the non-compound words at such positions where it is not needed. For example, If this is the case as discussed then the solution is perfect, but in the case of the non compound words, if two independent wordsQêÃgHar ‘The house’ and íºÓ makkah ‘Makkah’ appear in the same position like compound words e.g. ÿïf álu íºÓ QêÃ gHar makkah mEN hE ‘The house is in Makkah’, then this solution can not identify the context and it applies the transaction in the same way due to the same POS tagging of gHar and the Sehr. This </context>
</contexts>
<marker>Aycock, Horspool, 2002</marker>
<rawString>John Aycock and R Nigel Horspool. 2002. Practical Earley Parsing. The Computer Journal, 45(6):620– 630.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafiya Begum</author>
<author>Samar Husain</author>
<author>Arun Dhwaj</author>
<author>Dipti Misra Sharma</author>
<author>Lakshmi Bai</author>
<author>Rajeev Sangal</author>
</authors>
<title>Dependency Annotation Scheme For Indian Languages. In</title>
<date>2008</date>
<booktitle>IJCNLP,</booktitle>
<pages>721--726</pages>
<contexts>
<context position="5382" citStr="Begum et al., 2008" startWordPosition="859" endWordPosition="863">he NU-FAST treebank (Abbas et al., 2009) used a built in utility available in the inference engine of the Prolog to parse the Urdu sentences. This utility can only be used if you have a definite clause grammar (DCG) or probabilistic definite clause grammar (PDCG). In this work, a parser was not designed but a built-in prolog parser was used, due to which it was not considered to be the candidate for comparison. A simple dependency parser for Hindi was developed by Bharati et al. (2009). The parser used a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependen</context>
</contexts>
<marker>Begum, Husain, Dhwaj, Sharma, Bai, Sangal, 2008</marker>
<rawString>Rafiya Begum, Samar Husain, Arun Dhwaj, Dipti Misra Sharma, Lakshmi Bai, and Rajeev Sangal. 2008. Dependency Annotation Scheme For Indian Languages. In IJCNLP, pages 721–726.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Vineet Chaitanya</author>
<author>Rajeev Sangal</author>
<author>KV Ramakrishnamacharyulu</author>
</authors>
<title>Natural Language Processing: A Paninian Perspective. Prentice-Hall of India</title>
<date>1995</date>
<location>New Delhi.</location>
<contexts>
<context position="5405" citStr="Bharati et al., 1995" startWordPosition="864" endWordPosition="867">(Abbas et al., 2009) used a built in utility available in the inference engine of the Prolog to parse the Urdu sentences. This utility can only be used if you have a definite clause grammar (DCG) or probabilistic definite clause grammar (PDCG). In this work, a parser was not designed but a built-in prolog parser was used, due to which it was not considered to be the candidate for comparison. A simple dependency parser for Hindi was developed by Bharati et al. (2009). The parser used a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependency annotation but peopl</context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, Ramakrishnamacharyulu, 1995</marker>
<rawString>Akshar Bharati, Vineet Chaitanya, Rajeev Sangal, and KV Ramakrishnamacharyulu. 1995. Natural Language Processing: A Paninian Perspective. Prentice-Hall of India New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Medhavi Bhatia</author>
<author>Vineet Chaitanya</author>
<author>Rajeev Sangal</author>
</authors>
<title>Paninian Grammar Framework Applied To English.</title>
<date>1996</date>
<tech>Technical report, Technical Report TRCS-96-238, CSE, IIT Kanpur.</tech>
<contexts>
<context position="6359" citStr="Bharati et al., 1996" startWordPosition="1009" endWordPosition="1012">nt data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependency annotation but people are stick to the standard norms. The Hindi treebank is rich in functional information as compared to morphological, POS and syntactical information. Due to differences in the de1http://www2.parc.com/isl/groups/nltt/xle/ 2Karakas are the syntactico-semantic relations between the verbs and other related constituents in a sentence (Bharati et al., 1996) signs of the simple dependency parser for Hindi and the Urdu parser, only performance results are compared and presented in Section 5. Ali and Hussain used the MaltParser with its default settings in Urdu dependency parser (Ali and Hussain, 2010). When somebody performs experiments with MaltParser with its default settings then such evaluation results are advised not to be compared according to MaltParser license.3 The same exercise for parsing Hindi was performed in (Agrawal et al., 2013), but it was clearly mentioned in the work that MaltParser was used for error detection in the annotation</context>
</contexts>
<marker>Bharati, Bhatia, Chaitanya, Sangal, 1996</marker>
<rawString>Akshar Bharati, Medhavi Bhatia, Vineet Chaitanya, and Rajeev Sangal. 1996. Paninian Grammar Framework Applied To English. Technical report, Technical Report TRCS-96-238, CSE, IIT Kanpur.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Samar Husain</author>
<author>Dipti Misra Sharma</author>
<author>Rajeev Sangal</author>
</authors>
<title>A Two-Stage Constraint Based Dependency Parser For Free Word Order Languages.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLIPS International Conference on Asian Language Processing</booktitle>
<contexts>
<context position="5892" citStr="Bharati et al., 2008" startWordPosition="939" endWordPosition="942"> a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non-terminal nodes (Bharati et al., 2008) and often the information at POS level. This information can also be provided at dependency annotation but people are stick to the standard norms. The Hindi treebank is rich in functional information as compared to morphological, POS and syntactical information. Due to differences in the de1http://www2.parc.com/isl/groups/nltt/xle/ 2Karakas are the syntactico-semantic relations between the verbs and other related constituents in a sentence (Bharati et al., 1996) signs of the simple dependency parser for Hindi and the Urdu parser, only performance results are compared and presented in Section </context>
</contexts>
<marker>Bharati, Husain, Sharma, Sangal, 2008</marker>
<rawString>Akshar Bharati, Samar Husain, Dipti Misra Sharma, and Rajeev Sangal. 2008. A Two-Stage Constraint Based Dependency Parser For Free Word Order Languages. In Proceedings of the COLIPS International Conference on Asian Language Processing 2008 (IALP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akshar Bharati</author>
<author>Mridul Gupta</author>
<author>Vineet Yadav</author>
<author>Karthik Gali</author>
<author>Dipti Misra Sharma</author>
</authors>
<title>Simple Parser For Indian Languages In A Dependency Framework.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop,</booktitle>
<pages>162--165</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5254" citStr="Bharati et al. (2009)" startWordPosition="838" endWordPosition="841">development is still in progress and the parser evaluation results are not available yet. Similarly, the parser for evaluation of the NU-FAST treebank (Abbas et al., 2009) used a built in utility available in the inference engine of the Prolog to parse the Urdu sentences. This utility can only be used if you have a definite clause grammar (DCG) or probabilistic definite clause grammar (PDCG). In this work, a parser was not designed but a built-in prolog parser was used, due to which it was not considered to be the candidate for comparison. A simple dependency parser for Hindi was developed by Bharati et al. (2009). The parser used a grammar oriented approach, which was designed on the basis of Paninian grammatical model (Begum et al., 2008; Bharati et al., 1995). The annotation scheme was designed on the basis of chunks, intra-chunks and karakas2. This scheme (Begum et al., 2008) of dependency structure (DS) is different from the annotation scheme (Abbas, 2012; Abbas, 2014) of phrase structure (PS) and the hyper dependency structure (HDS) of the URDU.KON-TB treebank along with the different data sets used. As compared to phrase/constituent structure, the dependency structure lacks in information at non</context>
<context position="36864" citStr="Bharati et al. (2009)" startWordPosition="6331" endWordPosition="6334">he Length, Matched, Gold and the Test columns are summed up individually from that text file and their sums are recorded as can be seen in row T-2 of the table. Their respective results for the Precision, Recall, F-score and the Crossing Brackets are calculated 44 Sentences Length Matched Gold Test Precision Recall F-score Crossing A-1 140 13.73 17 22 18 0.952 0.811 0.848 2 T-2 140 1922 2449 3107 2531 0.968 0.788 0.869 329 Table 1: Evaluation results of the Urdu parser from these sums, which is a standard method of calculation. The Urdu parser outperforms the simple Hindi dependency parser by Bharati et al. (2009) with an additional recall of 22%. In (Bharati et al., 2009), only precision and recall percentages are given. Thats why only the precision and recall percentages of labeled attachment (LA) are compared. For chunks, intra-chunks and karakas, the precision percentages of LA (LA-P) achieved by the simple Hindi dependency parser are 82.3%, 71.2% and 74.1%, respectively. The average of these LA-P percentages is 75.9%, which is 20.9% less precision than the Urdu parser in row T-2. Similarly, Hindi dependency parser achieved LA recalls in case of chunks, intra-chunks and karakas as 65.4%, 58.2% and </context>
</contexts>
<marker>Bharati, Gupta, Yadav, Gali, Sharma, 2009</marker>
<rawString>Akshar Bharati, Mridul Gupta, Vineet Yadav, Karthik Gali, and Dipti Misra Sharma. 2009. Simple Parser For Indian Languages In A Dependency Framework. In Proceedings of the Third Linguistic Annotation Workshop, pages 162–165. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Riyaz Ahmad Bhat</author>
<author>Sambhav Jain</author>
<author>Dipti Misra Sharma</author>
</authors>
<title>Experiments On Dependency Parsing Of Urdu. In</title>
<date>2012</date>
<booktitle>In Proceedings of The 11th International Workshop on Treebanks and Linguistic Theories (TLT11).</booktitle>
<contexts>
<context position="7055" citStr="Bhat et al., 2012" startWordPosition="1122" endWordPosition="1125">ormance results are compared and presented in Section 5. Ali and Hussain used the MaltParser with its default settings in Urdu dependency parser (Ali and Hussain, 2010). When somebody performs experiments with MaltParser with its default settings then such evaluation results are advised not to be compared according to MaltParser license.3 The same exercise for parsing Hindi was performed in (Agrawal et al., 2013), but it was clearly mentioned in the work that MaltParser was used for error detection in the annotation of Hindi/Urdu treebank (HUTB).4 Similarly, the Urdu sentences were parsed in (Bhat et al., 2012b) using the same MaltParser. The experiments were performed to identify the parsing issues of Urdu and a development of parser was not claimed. Moreover, these data-driven systems are highly criticized on a given set of annotated corpus because they are not able to observe all morphological variants of a word form from it (Tsarfaty et al., 2013). A multi-path shift-reduce parsing algorithm was proposed in (Jiang et al., 2009) for Chinese. Later on, this algorithm was used for Urdu parsing by Mukhtar et al. (2012b). A probabilistic context free grammar (PCFG) developed in (Mukhtar et al., 2011</context>
</contexts>
<marker>Bhat, Jain, Sharma, 2012</marker>
<rawString>Riyaz Ahmad Bhat, Sambhav Jain, and Dipti Misra Sharma. 2012b. Experiments On Dependency Parsing Of Urdu. In In Proceedings of The 11th International Workshop on Treebanks and Linguistic Theories (TLT11).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Tracy Holloway King</author>
</authors>
<title>Urdu In A Parallel Grammar Development Environment. Language Resources and Evaluation,</title>
<date>2007</date>
<volume>41</volume>
<issue>2</issue>
<pages>207</pages>
<contexts>
<context position="4320" citStr="Butt and King, 2007" startWordPosition="667" endWordPosition="670">arsing are discussed in Section 4. By applying a rich grammar along with the ex36 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36–46, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics tended parsing model, promising results obtained are discussed in Section 5. Conclusions along with the future directions are presented in Section 6. Similarly, the related work of language variants is described in Section 1.1, which set a path towards the construction of the Urdu parser. 1.1 Related Work In the Urdu ParGram project (Butt and King, 2007), the XLE1 parser is in use. The encoding of LFG grammar in XLE interface is not a simple task. Such a grammar can be encoded only by those persons who have expertise in theoretical linguistics as well. The team of the ParGram project has made a tremendous effort in this regard. This project of Urdu LFG grammar development is still in progress and the parser evaluation results are not available yet. Similarly, the parser for evaluation of the NU-FAST treebank (Abbas et al., 2009) used a built in utility available in the inference engine of the Prolog to parse the Urdu sentences. This utility c</context>
</contexts>
<marker>Butt, King, 2007</marker>
<rawString>Miriam Butt and Tracy Holloway King. 2007. Urdu In A Parallel Grammar Development Environment. Language Resources and Evaluation, 41(2):191– 207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Gillian Ramchand</author>
</authors>
<title>Complex Aspectual Structure In</title>
<date>2001</date>
<pages>1--30</pages>
<contexts>
<context position="10019" citStr="Butt and Ramchand, 2001" startWordPosition="1627" endWordPosition="1630">ided into sub-categories based on morphology and semantics. In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semantics at POS level. In Figure 1, the hierarchy of tag labels for verb V is divided into three levels of depth. The first level contains only one label to distinguish a verb V from other POS labels. The second level contains 11 subcategories of V to represent different morphological or functional forms e.g. V.COP (V as a copula verb (Abbas and Raza, 2014)), V.IMPERF (V has an imperfective form (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This short discussion is about the </context>
</contexts>
<marker>Butt, Ramchand, 2001</marker>
<rawString>Miriam Butt and Gillian Ramchand. 2001. Complex Aspectual Structure In Hindi/Urdu. M. Liakata, B. Jensen, &amp; D. Maillat, Eds, pages 1–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Jafar Rizvi</author>
</authors>
<title>Tense And Aspect In Urdu. Layers of Aspect.</title>
<date>2010</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford:</location>
<contexts>
<context position="9993" citStr="Butt and Rizvi, 2010" startWordPosition="1623" endWordPosition="1626">tegories which are divided into sub-categories based on morphology and semantics. In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semantics at POS level. In Figure 1, the hierarchy of tag labels for verb V is divided into three levels of depth. The first level contains only one label to distinguish a verb V from other POS labels. The second level contains 11 subcategories of V to represent different morphological or functional forms e.g. V.COP (V as a copula verb (Abbas and Raza, 2014)), V.IMPERF (V has an imperfective form (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This shor</context>
</contexts>
<marker>Butt, Rizvi, 2010</marker>
<rawString>Miriam Butt and Jafar Rizvi. 2010. Tense And Aspect In Urdu. Layers of Aspect. Stanford: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
</authors>
<title>Hindi-Urdu Infinitives As NPs.</title>
<date>1993</date>
<journal>South Asian Language Review: Special Issue on Studies in Hindi-Urdu,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="10065" citStr="Butt, 1993" startWordPosition="1637" endWordPosition="1638">In Figure 1, an example of only a verb V is given. A dot ‘.’ symbol is used for the representation of morphology and semantics at POS level. In Figure 1, the hierarchy of tag labels for verb V is divided into three levels of depth. The first level contains only one label to distinguish a verb V from other POS labels. The second level contains 11 subcategories of V to represent different morphological or functional forms e.g. V.COP (V as a copula verb (Abbas and Raza, 2014)), V.IMPERF (V has an imperfective form (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This short discussion is about the idea of morphological and functional informati</context>
</contexts>
<marker>Butt, 1993</marker>
<rawString>Miriam Butt. 1993. Hindi-Urdu Infinitives As NPs. South Asian Language Review: Special Issue on Studies in Hindi-Urdu, 3(1):51–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
</authors>
<title>The Light Verb Jungle.</title>
<date>2003</date>
<booktitle>In Workshop on Multi-Verb Constructions.</booktitle>
<contexts>
<context position="10470" citStr="Butt, 2003" startWordPosition="1700" endWordPosition="1701">or functional forms e.g. V.COP (V as a copula verb (Abbas and Raza, 2014)), V.IMPERF (V has an imperfective form (Butt and Rizvi, 2010; Butt and Ramchand, 2001)), V.INF (V has an infinitive form (Butt, 1993; Abbas and Nabi Khan, 2009)), etc. The third level contains further 25 subcategories to represent the morphological information in depth e.g. V.COP.IMPERF (copula verb has an imperfective form), V.COP.PERF (copula verb has a perfective form), V.COP.ROOT (copula verb has a ROOT form), V.COP.PAST (copula verb has a past tense), V.LIGHT.PAST (light verb has a past tense (Butt and Rizvi, 2010; Butt, 2003)), etc. These types of combinations are also possible in case of an auxiliary verb as described in (Abbas, 2014). This short discussion is about the idea of morphological and functional information encoded at POS level. This lexical information can be passed up to the syntactical level because the lexical items have some relationship with other lexical items in a sentence. The detail of syntactic (SSS) and functional (F) tag sets can be seen in (Abbas, 2012). A stack based extraction Algorithm 1 was designed to extract a context free grammar (CFG) from the URDU.KON-TB treebank. The CFG obtaine</context>
</contexts>
<marker>Butt, 2003</marker>
<rawString>Miriam Butt. 2003. The Light Verb Jungle. In Workshop on Multi-Verb Constructions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Clark Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm.</title>
<date>1968</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="21189" citStr="Earley (1968)" startWordPosition="3580" endWordPosition="3581"> set to a true value along with a record of some variables fi, fj, and fid, which will be used in the EDITOR() discussed in Section 4.6. By introducing this modification, the possibility of wrong selection of the production from the grammar is abandoned. An issue related to this problem is still remained, which is addressed and resolved in Section 4.6. 4.3 Back-Pointers Calculation Earley parsing algorithm is a generator or a recognizer and hence can not produce the parse trees or the bracketed trees. To produce the parse trees or the bracketed trees, an unimplemented idea of back-pointers by Earley (1968) is implemented and presented in Algorithm 3. To understand the calculation of the back pointers, a sentence given in example 1 is parsed from the Urdu parser. The charts generated through the Urdu parser are depicted in Figure 2. Only the relevant states are dis40 1: function BACKPOINTER(previousRule, dummy@Position, i, char 2:backPointer← “” played as can be inferred from the non-sequential values of the STATEID column. The column DOT-POSITION is basically the position of ‘@’ in productions. Algorithm 3 Back Pointer (l + “-” + chart[l].getStateId(m) +“ ”+backPointer) 15: dummy@P = chart[l].g</context>
</contexts>
<marker>Earley, 1968</marker>
<rawString>Jay Clark Earley. 1968. An Efficient Context-Free Parsing Algorithm. Ph.D. thesis, Carnegie Mellon University, Pittsburgh, PA, USA. AAI6907901.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<volume>13</volume>
<issue>2</issue>
<pages>102</pages>
<contexts>
<context position="3388" citStr="Earley, 1970" startWordPosition="517" endWordPosition="518">unctional level was constructed (Abbas, 2012). Its annotation was found reliable according to the Krippendorffs α values achieved in (Abbas, 2014) but its reliability or the suitability for machine learning (ML) can be evaluated with the development of an Urdu parser presented in Section 3. A context free grammar (CFG) is extracted from the URDU.KON-TB treebank computationally. The development procedure and the depth of encoded information in the grammar is presented in Section 2. The grammar is then given to an extended dynamic programming parsing model known as the Earley parsing algorithm (Earley, 1970). The extended parsing model for Urdu is then called as the Urdu parser and given in Section 3. This algorithm is language independent and is capable to parse the MRLs like the CKY (Cocke-KasamiYounger) parsing algorithm as advocated in (Tsarfaty et al., 2013) and (Abbas et al., 2009). Issues faced during the parsing are discussed in Section 4. By applying a rich grammar along with the ex36 Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 36–46, October 29, 2014, Doha, Qatar. (c 2014 Association for Computational Linguistics tended parsing model, pr</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Jay Earley. 1970. An Efficient Context-Free Parsing Algorithm. Communications of the ACM, 13(2):94– 102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Hao Xiong</author>
<author>Qun Liu</author>
</authors>
<title>Mutipath Shift-Reduce Parsing With Online Training. CIPS-ParsEval-2009 shared task.</title>
<date>2009</date>
<contexts>
<context position="7485" citStr="Jiang et al., 2009" startWordPosition="1192" endWordPosition="1195"> clearly mentioned in the work that MaltParser was used for error detection in the annotation of Hindi/Urdu treebank (HUTB).4 Similarly, the Urdu sentences were parsed in (Bhat et al., 2012b) using the same MaltParser. The experiments were performed to identify the parsing issues of Urdu and a development of parser was not claimed. Moreover, these data-driven systems are highly criticized on a given set of annotated corpus because they are not able to observe all morphological variants of a word form from it (Tsarfaty et al., 2013). A multi-path shift-reduce parsing algorithm was proposed in (Jiang et al., 2009) for Chinese. Later on, this algorithm was used for Urdu parsing by Mukhtar et al. (2012b). A probabilistic context free grammar (PCFG) developed in (Mukhtar et al., 2011) was given to the multi-path shift-reduce Urdu parsing model. A multi-path shift-reduce parser for Urdu has some limitations. It takes a POS tagged sentence as input and is not able to parse sentences without the POS tagging. The stack used has a fixed memory size, which is not reliable and it can overflow during the parsing of long sentences. A PCFG used in this parsing model is ambiguous (Mukhtar et al., 2012a). Both the fi</context>
</contexts>
<marker>Jiang, Xiong, Liu, 2009</marker>
<rawString>Wenbin Jiang, Hao Xiong, and Qun Liu. 2009. Mutipath Shift-Reduce Parsing With Online Training. CIPS-ParsEval-2009 shared task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abdul Jamil Khan</author>
</authors>
<title>Urdu/Hindi: An Artificial Divide: African Heritage, Mesopotamian Roots, Indian Culture &amp; Britiah Colonialism. Algora Pub.</title>
<date>2006</date>
<contexts>
<context position="1106" citStr="Khan, 2006" startWordPosition="158" endWordPosition="159">icient encoded information is comparable with the state of the art parsing requirements for morphologically rich and closely related language variants Urdu/Hindi. The extended parsing model and the linguistically rich grammar together provide us promising parsing results for both the language variants. The parser gives 87% of f-score, which outperforms the multi-path shift-reduce parser for Urdu and a simple Hindi dependency parser with 4.8% and 22% increase in recall, respectively. 1 Introduction An Urdu invariant of Hindavi came into existence during the muslim rule from 1206 AD to 1858 AD (Khan, 2006). They used Persian/Urdu script for Urdu in contrast to the Devanagari script for Hindavi. The informal versions of the two language variants are quite similar, in fact so similar that they can really be called dialects of a same language. Loose examples would be how a Spanish speaker could comprehend Portuguese or Swedish speaker could comprehend Norwegian. However the formal version of the two languages will be much more different as Urdu vocabulary is influenced heavily from Persian, Arabic and Turkish whilst the emphasis in Hindi is on Sanskrit. Urdu became a literary language after existe</context>
</contexts>
<marker>Khan, 2006</marker>
<rawString>Abdul Jamil Khan. 2006. Urdu/Hindi: An Artificial Divide: African Heritage, Mesopotamian Roots, Indian Culture &amp; Britiah Colonialism. Algora Pub.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary F Simons</author>
<author>Charles D Fennig Lewis</author>
<author>M Paul</author>
</authors>
<date>2013</date>
<booktitle>Ethnologue: Languages Of The World, 17th Edition.</booktitle>
<publisher>SIL International.</publisher>
<location>Dallas:</location>
<marker>Simons, Lewis, Paul, 2013</marker>
<rawString>Gary F. Simons &amp; Charles D. Fennig Lewis, M. Paul. 2013. Ethnologue: Languages Of The World, 17th Edition. Dallas: SIL International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John R McLane</author>
</authors>
<title>The Political Awakening In India.</title>
<date>1970</date>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="1799" citStr="McLane, 1970" startWordPosition="272" endWordPosition="273">r Hindavi. The informal versions of the two language variants are quite similar, in fact so similar that they can really be called dialects of a same language. Loose examples would be how a Spanish speaker could comprehend Portuguese or Swedish speaker could comprehend Norwegian. However the formal version of the two languages will be much more different as Urdu vocabulary is influenced heavily from Persian, Arabic and Turkish whilst the emphasis in Hindi is on Sanskrit. Urdu became a literary language after existence of an increasing number of literature during the 18th and the 19th century (McLane, 1970). Urdu/Hindi is the national language of Pakistan and an official language in India. According to a report by the SIL Ethnologue (Lewis, 2013), Urdu/Hindi has 456.2 million speakers in the whole world. Getting state of the art parsing results for morphologically rich languages (MRLs) is a challenge to date. According to Tsarfaty et al. (2010; 2013), without proper handling of morphological entities in the sentences, promising results for MRLs can not be achieved. Complex morphosyntactic interactions may impose constraints, which lead to explicit encoding of such information. The best broad cov</context>
</contexts>
<marker>McLane, 1970</marker>
<rawString>John R McLane. 1970. The Political Awakening In India. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neelam Mukhtar</author>
</authors>
<title>Mohammad Abid Khan, and Fatima Tuz Zuhra.</title>
<date>2011</date>
<marker>Mukhtar, 2011</marker>
<rawString>Neelam Mukhtar, Mohammad Abid Khan, and Fatima Tuz Zuhra. 2011. Probabilistic Context Free Grammar For Urdu. Linguistic and Literature Review, 1(1):86–94.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Neelam Mukhtar</author>
</authors>
<title>Mohammad Abid Khan, and Fatima Tuz Zuhra.</title>
<booktitle>2012a. Algorithm For Developing Urdu Probabilistic Parser. International journal of Electrical and Computer Sciences,</booktitle>
<pages>12--3</pages>
<marker>Mukhtar, </marker>
<rawString>Neelam Mukhtar, Mohammad Abid Khan, and Fatima Tuz Zuhra. 2012a. Algorithm For Developing Urdu Probabilistic Parser. International journal of Electrical and Computer Sciences, 12(3):57–66.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Neelam Mukhtar</author>
</authors>
<title>Mohammad Abid Khan, Fatima Tuz Zuhra, and Nadia Chiragh.</title>
<booktitle>2012b. Implementation Of Urdu Probabilistic Parser. International Journal of Computational Linguistics (IJCL),</booktitle>
<pages>3--1</pages>
<marker>Mukhtar, </marker>
<rawString>Neelam Mukhtar, Mohammad Abid Khan, Fatima Tuz Zuhra, and Nadia Chiragh. 2012b. Implementation Of Urdu Probabilistic Parser. International Journal of Computational Linguistics (IJCL), 3(1):12–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djam´e Seddah</author>
<author>Yoav Goldberg</author>
<author>Sandra Kuebler</author>
<author>Marie Candito</author>
<author>Jennifer Foster</author>
<author>Yannick Versley</author>
<author>Ines Rehbein</author>
<author>Lamia Tounsi</author>
</authors>
<title>Statistical Parsing Of Morphologically Rich Languages (SPMRL): What, How And Whither.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2142" citStr="Tsarfaty et al. (2010" startWordPosition="326" endWordPosition="329">e much more different as Urdu vocabulary is influenced heavily from Persian, Arabic and Turkish whilst the emphasis in Hindi is on Sanskrit. Urdu became a literary language after existence of an increasing number of literature during the 18th and the 19th century (McLane, 1970). Urdu/Hindi is the national language of Pakistan and an official language in India. According to a report by the SIL Ethnologue (Lewis, 2013), Urdu/Hindi has 456.2 million speakers in the whole world. Getting state of the art parsing results for morphologically rich languages (MRLs) is a challenge to date. According to Tsarfaty et al. (2010; 2013), without proper handling of morphological entities in the sentences, promising results for MRLs can not be achieved. Complex morphosyntactic interactions may impose constraints, which lead to explicit encoding of such information. The best broad coverage and robust parsers to date have grammars extracted from treebanks and the depth of information encoded in an annotation correlates with the parsing performance (Tsarfaty et al., 2013). To fulfill the encoding of information in an annotation, a treebank for Urdu known as the URDU.KON-TB treebank with sufficient encoded information at mo</context>
</contexts>
<marker>Tsarfaty, Seddah, Goldberg, Kuebler, Candito, Foster, Versley, Rehbein, Tounsi, 2010</marker>
<rawString>Reut Tsarfaty, Djam´e Seddah, Yoav Goldberg, Sandra Kuebler, Marie Candito, Jennifer Foster, Yannick Versley, Ines Rehbein, and Lamia Tounsi. 2010. Statistical Parsing Of Morphologically Rich Languages (SPMRL): What, How And Whither. In Proceedings of the NAACL HLT 2010 First Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 1–12. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
<author>Djam´e Seddah</author>
<author>Sandra K¨ubler</author>
<author>Joakim Nivre</author>
</authors>
<title>Parsing Morphologically Rich Languages: Introduction To The Special Issue.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>1</issue>
<marker>Tsarfaty, Seddah, K¨ubler, Nivre, 2013</marker>
<rawString>Reut Tsarfaty, Djam´e Seddah, Sandra K¨ubler, and Joakim Nivre. 2013. Parsing Morphologically Rich Languages: Introduction To The Special Issue. Computational Linguistics, 39(1):15–22.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>