<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001621">
<title confidence="0.992158">
Online Word Alignment for Online Adaptive Machine Translation
</title>
<author confidence="0.629583">
M. Amin Farajian
</author>
<affiliation confidence="0.7857175">
FBK-irst,
University of Trento
</affiliation>
<address confidence="0.60893">
Trento, Italy
</address>
<email confidence="0.996665">
farajian@fbk.eu
</email>
<author confidence="0.929741">
Nicola Bertoldi
</author>
<affiliation confidence="0.83311">
FBK-irst
</affiliation>
<address confidence="0.814116">
Trento, Italy
</address>
<email confidence="0.978803">
bertoldi@fbk.eu
</email>
<author confidence="0.737586">
Marcello Federico
</author>
<affiliation confidence="0.66151">
FBK-irst
</affiliation>
<address confidence="0.789168">
Trento, Italy
</address>
<email confidence="0.974096">
federico@fbk.eu
</email>
<sectionHeader confidence="0.993068" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908740740741">
A hot task in the Computer Assisted
Translation scenario is the integration of
Machine Translation (MT) systems that
adapt sentence after sentence to the post-
edits made by the translators. A main
role in the MT online adaptation process is
played by the information extracted from
source and post-edited sentences, which
in turn depends on the quality of the
word alignment between them. In fact,
this step is particularly crucial when the
user corrects the MT output with words
for which the system has no prior infor-
mation. In this paper, we first discuss
the application of popular state-of-the-art
word aligners to this scenario and reveal
their poor performance in aligning un-
known words. Then, we propose a fast
procedure to refine their outputs and to
get more reliable and accurate alignments
for unknown words. We evaluate our
enhanced word-aligner on three language
pairs, namely English-Italian, English-
French, and English-Spanish, showing a
consistent improvement in aligning un-
known words up to 10% absolute F-
measure.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999969078431373">
In the adaptive MT the goal is to let the MT system
take as soon and as much as possible advantage of
user feedback, in order to learn from corrections
and to hence avoid repeating the same mistakes in
future sentences.
A typical application scenario is the usage by
a professional translator of a Computer Assisted
Translation (CAT) tool enhanced with a SMT sys-
tem. For each input sentence, first the translator
receives one or more translation suggestions from
either a Translation Memory or a SMT system,
then (s)he chooses which suggestion is more use-
ful, and finally (s)he creates an approved transla-
tion by post-editing. The pair of input sentence
and post-edit is a valuable feedback to improve the
quality of next suggestions. While the sentence
pair is trivially added to the Translation Memory,
how to exploit it for improving the SMT system is
far to be a solved problem, but rather is a hot and
quite recent topic in the MT community.
In online MT adaptation specific issues have to
be addressed, which distinguish it from the more
standard and investigated task of domain adapta-
tion. First of all, the SMT system should adapt
very quickly, because the time between two con-
secutive requests are usually short, and very pre-
cisely, because the translator is annoyed by cor-
recting the same error several time. Then, a crucial
point is which and how information is extracted
from the feedback, and how it is exploited to up-
date the SMT system. Finally, model updating re-
lies on a little feedback consisting of just one sen-
tence pair.
In this work we focus on the word alignment
task which is the first and most important step in
extracting information from the given source and
its corresponding post-edit. In particular, we are
interested in the cases where the given sentence
pairs contain new words, for which no prior infor-
mation is available. This is an important and chal-
lenging problem in the online scenario, in which
the user interacts with the system and expects that
it learns from the previous corrections and does
not repeat the same errors again and again.
Unfortunately, state-of-the-art word-aligners
show poor generalization capability and are prone
to errors when infrequent or new words occur in
the sentence pair. Word alignment errors at this
stage could cause the extraction of wrong phrase
pairs, i.e. wrong translation alternatives, which
can lead in producing wrong translations for those
</bodyText>
<page confidence="0.986369">
84
</page>
<note confidence="0.9608185">
Workshop on Humans and Computer-assisted Translation, pages 84–92,
Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9990335">
words, if they appear in the following sentences.
Our investigation focuses on how to quickly
build a highly precise word alignment from a
source sentence and its translation. Moreover, we
are interested in improving the word alignment of
unknown terms, i.e. not present in the training
data, because they are one of the most important
source of errors in model updating.
Although we are working in the online MT
adaptation framework, our proposal is worthwhile
per se; indeed, having an improved and fast word
aligner can be useful for other interesting tasks,
like for instance terminology extraction, transla-
tion error detection, and pivot translation.
In Section 2 we report on some recent ap-
proaches aiming at improving word alignment. In
Section 3, we describe three widely used toolk-
its, highlight their pros and cons in the online
MT adaptation scenario, and compare their per-
formance in aligning unknown terms. In Section 4
we propose a standalone module which refines the
word alignment of unknown words; moreover, we
present an enhanced faster implementation of the
best performing word aligner, to make it usable in
the online scenario. In Section 5 we show exper-
imental results of this module on three different
languages. Finally, we draw some final comments
in Section 6.
</bodyText>
<sectionHeader confidence="0.998045" genericHeader="introduction">
2 Related works
</sectionHeader>
<bodyText confidence="0.999986305555556">
Hardt et al. (2010) presented an incremental re-
training method which simulates the procedure
of learning from post-edited MT outputs (refer-
ences), in a real time fashion. By dividing the
learning task into word alignment and phrase ex-
traction tasks, and replacing the standard word-
alignment module, which is a variation of EM
algorithm (Och and Ney, 2003), with a greedy
search algorithm, they attempt to find a quick ap-
proximation of the word alignments of the newly
translated sentence. They also use some heuris-
tics to improve the obtained alignments, without
supporting it with some proofs or even providing
some experimental results. Furthermore, the run-
ning time of this approach is not discussed, and it
is not clear how effective this approach is in online
scenarios.
Blain et al. (2012) have recently studied the
problem of incremental learning from post-editing
data, with minimum computational complexity
and acceptable quality. They use the MT out-
put (hypothesis) as a pivot to find the word align-
ments between the source sentence and its corre-
sponding reference. Similarly to (Hardt and Elm-
ing, 2010), once the word alignment between the
source and post-edit sentence pair is generated,
they use the standard phrase extraction method
to extract the parallel phrase pairs. This work
is based on an implicit assumption that MT out-
put is reliable enough to make a bridge between
source and reference. However, in the real world
this is not always true. The post-editor sometimes
makes a lot of changes in the MT output, or even
translates the entire sentence from scratch, which
makes the post-edit very different from the auto-
matic translation. Moreover, in the presence of
new words in the source sentence, the MT system
either does not produce any translation for the new
word, or directly copies it in the output. Due to
the above two reasons, there will be missing align-
ments between the automatic translation and post-
edit, which ultimately results in incomplete paths
from source to post-edit. But, the goal here is to
accurately align the known words, as well as learn-
ing the alignments of the new words, which is not
feasible by this approach.
In order to improve the quality of the word
alignments McCarley et al. (2011) proposed a
trainable correction model which given a sentence
pair and their corresponding automatically pro-
duced word alignment, it tries to fix the wrong
alignment links. Similar to the hill-climbing ap-
proach used in IBM models 3-5 (Brown et al.,
1993), this approach iteratively performs small
modifications in each step, based on the changes
of the previous step. However, the use of addi-
tional sources of knowledge, such as POS tags of
the words and their neighbours, helps the system
to take more accurate decisions. But, requiring
manual word alignments for learning the align-
ment moves makes this approach only applicable
for a limited number of language pairs for which
manual aligned gold references are available.
Tomeh et al. (2010) introduced a supervised
discriminative word alignment model for produc-
ing higher quality word alignments, which is
trained on a manually aligned training corpus. To
reduce the search space of the word aligner, they
propose to provide the system with a set of au-
tomatic word alignments and consider the union
of these alignments as the possible search space.
This transforms the word alignment process into
</bodyText>
<page confidence="0.999518">
85
</page>
<bodyText confidence="0.992863326530612">
the alignment refinement task in which given a set 3.1 Evaluation Measures
of automatic word alignments, the system tries to A word aligner is usually evaluated in terms of
find the best word alignment points. Similar to Precision, Recall, and F-measure (or shortly F),
(McCarley et al., 2011), this approach relies on the which are defined as follows (Fraser and Marcu,
manually annotated training corpora which is not 2007):
available for most of the language pairs.
3 Word Alignment
Word alignment is the task of finding the corre-
spondence among the words of a sentence pair
(Figure 1). From a mathematical point of view,
it is a relation among the words, because any word
in a sentence can be mapped into zero, one or
more words of the other, and vice-versa; in other
words, any kind of link is allowed, namely one-to-
one, many-to-one, many-to-many, as well as leav-
ing words unaligned. So called IBM models 1-5
(Brown et al., 1993) as well as the HMM-based
alignment models (Vogel et al., 1996), and their
variations are extensively studied and widely used
for this task. They are directional alignment mod-
els, because permit only many-to-one links; but
often the alignments in the two opposite directions
are combined in a so-called symmetrized align-
ment, which is obtained by intersection, union or
other smart combination.
Nowadays, word-aligners are mostly employed
in an intermediate step of the training procedure
of a SMT system; In this step, the training cor-
pus is word aligned as a side effect of the es-
timation of the alignment models by means of
the Expectation-Maximization algorithm. For this
task, they perform sufficiently well, because the
training data are often very large, and the limited
amount of alignment errors do not have strong im-
pact on the estimation of the translation model.
Instead, the already trained word-aligners are
rarely applied for aligning new sentence pairs. In
this task their performance are often not satisfac-
tory, due to their poor generalization capability;
they are especially prone to errors when infrequent
or new words occur in the sentence pair.
This is the actual task to be accomplished in the
online adaptive scenario: as soon as a new source
and post-edited sentence pair is available, it has
to be word aligned quickly and precisely. In this
scenario, the sentence pair likely does not belong
to the training corpus, hence might contain infre-
quent or new words, for which the aligner has little
or no prior information.
</bodyText>
<table confidence="0.632841333333333">
Precision = |AnP|
|A |, Recall = |S|
|A � S|
1
F − measure = α 1−α
Precision + Recall
</table>
<bodyText confidence="0.994678159090909">
where A is the set of automatically computed
alignments, and S and P refer to the sure (un-
ambiguous) and possible (ambiguous) manual
alignments; note that S C P. In this paper, α is
set to 0.5 for all the experiments, in order to have
a balance between Precision and Recall.
In this paper we are mainly interested how the
word-aligner performs on the unknown words;
hence, we define a version of Precision, Recall,
and F metrics focused on the oov-alignment only,
i.e. the alignments for which either the source or
the target word is not included in the training cor-
pus. The subscript all identifies the standard met-
rics; the subscript oov identifies their oov-based
versions.
In Figure 1 we show manual and automatic
word alignments between an English-Italian sen-
tence pair. A sure alignment, like are-sono, is rep-
resented by a solid line, and a possible alignment,
like than-ai, by a dash line. An oov-alignment,
like that linking the unknown English word de-
ployable to the Italian word attivabili, is identi-
fied by a dotted line. According to this example,
Precision and Recall will be about 0.85 (=11/13)
and 0.91 (=10/11), respectively, and the corre-
sponding F is hence about 0.88. Focusing on the
oov-alignment only, Precisionoo„ is 1.00 (=1/1),
Recalloo„ is 0.50 (=1/2), and Foo„ is 0.67.
3.2 Evaluation Benchmark
In this paper, we compare word-alignment perfor-
mance of three word-aligners introduced in Sec-
tion 3.3 on three distinct tasks, namely English-
Italian, English-French, and English-Spanish; the
training corpora, common to all word-aligners, are
subset of the JRC-legal corpus1 (Steinberger et
al., ), of the Europarl corpus V7.0 (Koehn, 2005),
and of the Hansard parallel corpus2, respectively.
86 1langtech.jrc.it/JRC-Acquis.html
2www.isi.edu/natural-language/
download/hansard/index.html
financial assistance mechanisms are less rapidly deployable than conventional budgetary mechanisms
i meccanismi di assistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi di bilancio convenzionali
financial assistance mechanisms are less rapidly deployable than conventional budgetary mechanisms
i meccanismi di assistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi di bilancio convenzionali
</bodyText>
<figureCaption confidence="0.95173875">
Figure 1: Example of manual (above) and automatic (below) word alignments between an English-Italian
sentence pair. Sure and possible alignments are identified by solid and dash lines, respectively, and the
oov-alignments by a dotted line. The OOV words, like deployable (English) and finanziaria (Italian), are
printed in italics.
</figureCaption>
<bodyText confidence="0.992365">
Statistics of the three training corpora are reported
in Table 1.
</bodyText>
<table confidence="0.99558925">
En-It En-Fr En-Es
Segments 940K 1.1M 713K
Tokenssrc 19.8M 19.8M 19.8M
Tokenstrg 20.3M 23.3M 20.4M
</table>
<tableCaption confidence="0.994986">
Table 1: Statistics of the training corpora
</tableCaption>
<bodyText confidence="0.99342185">
for English-Italian, English-French, and English-
Spanish tasks.
Three evaluation data sets are also available,
which belong to the same domains of the cor-
responding training corpora. The English-Italian
test set was built by two professional translators
by correcting an automatically produced word-
alignment. The English-French test set is the man-
ually aligned parallel corpus introduced in (Och
and Ney, 2000)3. The English-Spanish test set was
provided by (Lambert et al., 2005)4. Statistics of
the three test sets are reported in Table 2.
To have a better understanding of the behavior
of the word aligners on the unknown words, we
created new test sets with an increasing ratio of the
unknown words (oov-rate), for each task. Starting
from each of the original test set, we replaced an
increasing portion of randomly chosen words by
strings which do not exist in the training corpus;
the oov-noise artificially introduced ranges from
</bodyText>
<footnote confidence="0.98165525">
3www.cse.unt.edu/˜rada/wpt/data/
English-French.test.tar.gz
4www.computing.dcu.ie/˜plambert/data/
epps-alignref.html
</footnote>
<table confidence="0.868596571428571">
En-It En-Fr En-Es
Segments 200 484 500
Tokenssrc 6,773 7,681 14,652
Tokenstrg 7,430 8,482 15,516
oov-ratesrc 0.90 0.27 0.35
oov-ratetrg 0.84 0.34 0.32
#alignment 7,380 19,220 21,442
</table>
<tableCaption confidence="0.851747">
Table 2: Staticts of the test corpora for English-
</tableCaption>
<bodyText confidence="0.997976173913043">
Italian, English-French, and English-Spanish
tasks. oov-ratesrc and oov-ratetrg are the ratio of
the new words in the source and target side of the
test corpus, respectively.
1% to 50%. For each value of the artificial oov-
noise (m = 1, ..., 50), we randomly selected m%
words in both the source and target side indepen-
dently, and replaced them by artificially created
strings. For selecting the words to be replaced
by artificially created strings, we do not differenti-
ate between the known and unknown words; hence
the actual oov-rate in the test corpus, used in the
plots, might be slightly larger.
To further make sure that the random selection
of the words does not affect the systems, for each
oov-noise we created 10 different test corpora and
reported the averaged results. One might think of
other approaches for introducing oov-noise, such
as replacing singletons or low-frequency words
which have more potential to be unknown, instead
of randomly selection of the words. But in this pa-
per we decided to follow the random selection of
the words.
</bodyText>
<page confidence="0.994266">
87
</page>
<subsectionHeader confidence="0.998944">
3.3 State-of-the-art Word Aligners
</subsectionHeader>
<bodyText confidence="0.947792661016949">
We consider three widely-used word aligners,
namely berkeley, fast-align, and mgiza++. We
analyze their performance in aligning an held-out
test corpora; in particular, we compare their capa-
bility in handling the unknown words. For a fair
comparison, all aligners are trained on the same
training corpora described in Section 3.2.
berkeley aligner (Liang et al., 2006) applies the
co-training approach for training the IBM model
1 and HMM. We trained berkeley aligner using
5 iterations of model 1 followed by 5 iterations
of HMM. When applied to new sentence pairs,
the system produces bi-directional symmetrized
alignment.
fast-align is a recently developed unsuper-
vised word aligner that uses a log-linear re-
parametrization of IBM model 2 for training the
word alignment models (Dyer et al., 2013). We
exploited the default configuration with 5 itera-
tions for training. As the system is directional, we
trained two systems (source-to-target and target-
to-source). When applied to new sentence pairs,
we first produced the two directional alignments,
and then combined them into a symmetrized align-
ment by using the grow-diag-final-and heuristic
(Och and Ney, 2003).
mgiza++ (Gao and Vogel, 2008) and its an-
cestors, i.e. giza, and giza++, implement all the
IBM models and HMM based alignment models.
mgiza++ is a multithreaded version of giza++,
which enables an efficient use of multi-core plat-
forms. We trained the system using the follow-
ing configuration for model iterations: 15h53343.
mgiza++ also produces directional alignment;
hence, we followed the same protocol to create a
symmetrize alignment of sentence pairs as we did
for fast-align.
Differently from berkeley and fast-align,
mgiza++ somehow adapts its models when
applied to new sentence pairs. According to
the so-called “forced alignment”, it essentially
proceeds with the training procedure on these
new data starting from pre-trained and pre-loaded
models, and produces the alignment as a by-
product. In preliminary experiments, we observed
that performing 3 iterations of model 4 is the
best configuration for mgiza++ to align the new
sentence pairs.
These word aligners are designed to work in of-
fline mode; they load the models and align the
whole set of available input data in one shot. How-
ever, in the online scenario where a single sen-
tence pair is provided at a time, they need to reload
the models every time which is very expensive in
terms of I/O operations. In this paper we first
were interested in measuring the quality of the
word aligners to select the best one. Therefore,
we mimic the online modality by forcing them to
align one sentence pair at a time.
</bodyText>
<table confidence="0.999952428571429">
Precision Recall F-measure
all oov all oov all oov
English-Italian
fast-align 82.6 33.3 82.8 19.6 82.7 24.7
berkeley 91.9 – 81.0 – 86.1 –
mgiza++ 86.2 84.6 89.4 30.8 87.8 45.2
English-French
fast-align 81.5 47.2 91.8 19.5 86.3 27.6
berkeley 87.9 – 92.9 – 90.3 –
mgiza++ 89.0 88.2 96.0 17.2 92.4 28.8
English-Spanish
fast-align 81.5 31.3 71.8 12.7 76.3 18.1
berkeley 88.7 – 71.2 – 79.0 –
mgiza++ 89.2 95.5 80.6 35.6 84.7 51.9
</table>
<tableCaption confidence="0.999148">
Table 3: Comparison of different widely-used
</tableCaption>
<bodyText confidence="0.981785535714286">
word aligners in terms of precision, recall, and F-
measure on English-Italian, English-French, and
English-Spanish language pairs. Columns all re-
port the evaluation performed on all alignments,
while columns oov the evaluation performed on
the oov-alignments.
The three word aligners were evaluated on the
three tasks introduced in Section 3.2. Table 3
shows their performance on the full set of align-
ments (all) and on the subset of oov-alignments
(oov) in terms of Precision, Recall, and F-measure.
The figures show that all aligners perform well on
the whole test corpus. mgiza++ is definitely su-
perior to fast-align; it also outperforms berkeley
in terms of F-measure, but they are comparable in
terms of Precision.
Unfortunately, the quality of the word align-
ments produced for the new words is quite poor for
all systems. mgiza++ outperforms the other align-
ers in all the language pairs on oov-alignments,
and in particular it achieves a very high preci-
sion. On the contrary, berkeley aligner always fails
to detect out-of-vocabulary words; its precision is
hence undefined, and consequently its F-measure.
To our knowledge of the system, this behavior is
expected because of the joint alignment approach
used in berkeley which produces an alignment be-
tween two terms if both the directional models
</bodyText>
<page confidence="0.990414">
88
</page>
<figure confidence="0.999422734939759">
English-French
0.5 1 2 4 8 16 32
OOV rate
mgiza
Berkeley
fast-align
English-Spanish
0.5 1 2 4 8 16 32
OOV rate
berke
mgiza
fast-alignley
F-measure 90
80
70
60
50
40
30
F-measure 90
80
70
60
50
40
30
0.5 1 2 4 8 16 32 0.5 1 2 4 8 16 32
OOV rate OOV rate
F-measure-oov
50
45
40
35
30
25
20
15
10
English-French
mgiza
fast-align
F-measure-oov
50
45
40
35
30
25
20
15
10
English-Spanish
mgiza
fast-align
English-Italian
F-measure
90
80
70
60
50
40
30
1 2 4 8 16 32
OOV rate
mgiza
berkeley
fast-align
F-measure-oov
50
45
40
35
30
25
20
15
10
English-Italian
mgiza
fast-align
1 2 4 8 16 32
OOV rate
</figure>
<figureCaption confidence="0.991387333333333">
Figure 2: Performance in terms of standard F-measure (above) and oov-based F-measure (below) of the
word aligners on test sets with increasing oov-rate, for all language pairs. The oov-based F-measure for
berkeley is not reported because it is undefined.
</figureCaption>
<bodyText confidence="0.9972291">
agree, and this hardly occurs for unknown words.
To further investigate the behavior of the word
aligners on the unknown words, we evaluated their
performance on the artificially created test sets,
described in Section 3.2. The performance of the
word aligners in terms of standard and oov-based
F-measure is shown in Figure 2. As expected, the
overall F-measure decreases by introducing un-
known words. mgiza++ is more accurate than the
other aligners up to oov-rate of 16%.
We observe that mgiza++ outperforms the oth-
ers in terms of the oov-based F-measure on
the English-Italian and English-Spanish language
pairs up to oov-noise of 32% and 16%, respec-
tively. fast-align instead performs better in the
English-French task. fast-align always show a
better quality when the oov-rate is very high.
oov-based F-measure is not reported for berke-
ley because this aligner is not able to detect oov-
alignments as explained above.
</bodyText>
<sectionHeader confidence="0.985709" genericHeader="method">
4 Enhancement to Word Alignment
</sectionHeader>
<subsectionHeader confidence="0.999496">
4.1 Refinement of oov-alignments
</subsectionHeader>
<bodyText confidence="0.999982212121212">
To address the problem of unaligned new words,
we present a novel approach, in which the word
alignments of the source and target segment pair
are induced in two-steps. First, a standard word
aligner is applied; most of the words in the source
and target sentence pair will be aligned, but most
of the unknown words will not. It is worth men-
tioning that aligning unknown words in this step
depends on the quality of the employed word
aligner. Once the alignments are computed and
symmetrized (if required), phrase extraction pro-
cedure is applied to extract all valid phrase-pairs.
Note that un-aligned words are included in the ex-
tracted phrase pairs, if their surrounding words are
aligned.
It has been shown that inclusion of un-aligned
words in the phrase-pairs, generally, has neg-
ative effects on the translation quality and can
produce errors in the translation output (Zhang
et al., 2009). Nevertheless, the overlap among
phrase-pairs, which contain un-aligned unknown
words, can be considered as a valuable source
of knowledge for inducing the correct alignment
of these words. To get their alignments from
the extracted phrase-pairs we follow an approach
similar to (Espl´a-Gomis et al., 2012) in which
the word alignment probabilities are determined
by the alignment strength measure. Given the
source and target segments (S = {s1,... , sl}
and T = {t1, ... , sm}), and the set of extracted
parallel phrase-pairs (Φ), the alignment strength
Ai,j(S, T, Φ) of the si and tj can be calculated as
follows:
</bodyText>
<equation confidence="0.9639938">
�
Ai,j(S, T, Φ) =
(σ,τ)∈D
� 1 if si ∈ σ and tj ∈ τ
cover(i, j, σ, τ) = 0 otherwise
</equation>
<bodyText confidence="0.826744">
where |σ |and |τ |are the source and target
lengths (in words) of the phrase pair (σ, τ).
cover(i, j, σ, τ)
|σ|.|τ|
</bodyText>
<page confidence="0.995982">
89
</page>
<bodyText confidence="0.998448693877551">
cover(i, j, Q, τ) simply spots whether the word-
pair (si, tj) is covered by the phrase pair (Q, τ).
The alignment strengths are then used to pro-
duce the a directional source-to-target word align-
ments; si is aligned to tj if Ai,j &gt; 0 and Ai,j ≥
Ai,k, bk E [1, T ]. One-to-many alignment is
allowed in cases that multiple target words have
equal probabilities to be aligned to i-th source
word (Ai,j = Ai,k). The directional word align-
ments are then symmetrized.
The new set of symmetrized alignments can be
used in different ways: (i) as a replacement of the
initial word alignments as in (Espl´a-Gomis et al.,
2012), or (ii) as additional alignment points to be
added to the initial set. According to a prelim-
inary investigation, we choose the latter option:
only a subset of the new word alignments is used
for updating the initial alignments. More specifi-
cally, we add only the alignments of the new words
which are not already aligned.
Moreover, our approach differs from that pro-
posed by Espl´a-Gomis et al. (2012) in the proce-
dure to collect the original set of phrase pairs from
the source and target sentence pair. They rely on
the external sources of information such as online
machine translation systems (e.g. Google Trans-
late, and Microsoft Translator). Communicating
with external MT systems imposes some delays
to the pipeline, which is not desired for the on-
line scenario. Furthermore, the words that are not
known by the machine translation systems are not
covered by any phrase-pair, hence the refinement
module is not able to align them.
We instead employ the phrase-extract software5
provided by the Moses toolkit, which relies on the
alignment information of the given sentence pair,
and allows the inclusion of un-aligned unknown
words in the extracted phrase pairs; hence, the re-
finement module has the potential to find the cor-
rect alignment for those words.
Note that there is no constraint on the word
alignment and phrase extraction modules used in
the first step, hence, any word aligner and phrase
extractor can be used for computing the initial
alignments and extracting the parallel phrase pairs
from the given sentence pairs. But, since the out-
puts of the first aligner make the ground for obtain-
ing the alignments of the second level, they need
to be highly accurate and precise.
</bodyText>
<footnote confidence="0.974019">
5The “grow-diag-final-and” heuristic was set for the sym-
metrization.
</footnote>
<subsectionHeader confidence="0.917985">
4.2 onlineMgiza++
</subsectionHeader>
<bodyText confidence="0.999987892857143">
The experiments to compare state-of-the-art word
aligners, reported and discussed in Section 3, are
carried out offline. This is because the aforemen-
tioned word aligners are not designed to work on-
line, and need to load the models every time re-
ceives a new sentence pair. Loading the models is
very time consuming, and depending on the size
of the models might take several minutes, which
is not desired for the online scenario.
To overcome this problem, we decided to im-
plement an online version of mgiza++ which
provides the best performance as shown in Sec-
tion 3.3. This new version, called onlineM-
giza++, works in client-server mode. It con-
sists of two main modules mgizaServer and mgiza-
Client. mgizaServer is responsible for computing
the alignment of the given sentence pairs. To avoid
unnecessary I/O operations, mgizaServer loads all
the required models once at the beginning of the
alignment session, and releases them at the end.
mgizaClient communicates with the client appli-
cations through the standard I/O channel.
In our final experiments we observed some
unexpected differences between the results of
mgiza++ and onlineMgiza++. Therefore, we do
not present the results of onlineMgiza++ in this
paper. However, we expect the two systems pro-
duce the same results.
</bodyText>
<sectionHeader confidence="0.991242" genericHeader="method">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999778">
In this section we evaluate the effectiveness of
the proposed refinement module. Each consid-
ered word aligner was equipped by our refinement
module, and compared to its corresponding base-
line. Figure 3 shows the oov-based F-measure
achieved by the baseline and enhanced word align-
ers on all test sets and all tasks. We observe that
the refinement module consistently improves the
F-measure of all aligners on all language pairs;
The improvement for mgiza++ are big (up to
10%) for very low oov-rates and decreases when
the oov-rate increases; the same but smaller be-
havior is observed for fast-align. This is due to the
fact that by inserting more oov words into the test
sets the systems are able to produce less accurate
alignment points, which leads in lower contextual
information (i.e. smaller number of overlapping
phrase-pairs) for aligning the unknown words. In-
terestingly, the refinement module applied to the
berkeley output permits the correct detection of
</bodyText>
<page confidence="0.978521">
90
</page>
<figure confidence="0.999792705882353">
English-French English-Spanish
0.5 1 2 4 8 16 32 0.5 1 2 4 8 16 32
OOV rate OOV rate
F-measure-oov
80
70
60
50
40
30
20
10
0
mgiza + enh
berkeley + enh
fast-align + enh
mgiza
fast-align
F-measure-oov
80
70
60
50
40
30
20
10
0
mgiza + enh
berkeley + enh
fast-align + enh
mgiza
fast-align
English-Italian
F-measure-oov
80
70
60
50
40
30
20
10
0
mgiza + enh
berkeley + enh
fast-align + enh
mgiza
fast-align
1 2 4 8 16 32
OOV rate
</figure>
<figureCaption confidence="0.981633666666667">
Figure 3: Performance in terms of oov-based F-measure of the baseline and enhanced word aligners on
test sets with increasing oov rate, for all language pairs. The oov-based F-measure for berkeley is not
reported because it is undefined.
</figureCaption>
<figure confidence="0.999744911764706">
English-Italian
mgiza + enh
berkeley + enh
fast-align + enh
1 2 4 8 16 32
OOV rate
English-French
0.5 1 2 4 8 16 32
OOV rate
Delta F-measure 2
1.5
1
0.5
0
Delta F-measure 2
1.5
1
0.5
0
mgiza + enh
berkeley + enh
fast-align + enh
English-Spanish
Delta F-measure
0.5
1.5
2
0
1
mgiza + enh
berkeley + enh
fast-align + enh
0.5 1 2 4 8 16 32
OOV rate
</figure>
<figureCaption confidence="0.916421">
Figure 4: Difference of performance in terms of standard F-measure of the enhanced word aligners from
their corresponding baselines on test sets with increasing OOV rate, for all language pairs.
</figureCaption>
<bodyText confidence="0.998391545454545">
many oov-alignments, which the baseline system
can not find most of them.
Furthermore, Figure 4 reports the F-measure
differences achieved by the enhanced word-
aligners from their corresponding baselines on the
full data sets. The refinement module slightly
but consistently improves the overall F-measure as
well, especially for high oov-rates. The highest
improvement is achieved by the enhanced berke-
ley aligner, mainly because its baseline performs
worse in this condition.
</bodyText>
<sectionHeader confidence="0.999257" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999521172413793">
In this paper we discussed the need of having a fast
and reliable online word aligner in the online adap-
tive MT scenario that is able to accurately align
the new words. The quality of three state-of-the-
art word aligners, namely berkeley, mgiza++, and
fast-align, were evaluated on this task in terms of
Precision, Recall, and F-measure. For this purpose
we created a benchmark in which an increasing
amount of the words of the test corpus are ran-
domly replaced by new words in order to augment
the oov-rate. The results show that the quality of
the aligners on new words is quite low, and sug-
gest that new models are required to effectively ad-
dress this task. As a first step, we proposed a fast
and language independent procedure for aligning
the unknown words which refines any given au-
tomatic word alignment. The results show that
the proposed approach significantly increases the
word alignment quality of the new words.
In future we plan to evaluate our approach in an
end-to-end evaluation to measure its effect on the
final translation. We also plan to investigate the
exploitation of additional features such as linguis-
tic and syntactic information in order to further
improve the quality of the word alignment mod-
els as well as the proposed refinement procedure.
However, this requires other policies of introduc-
ing new words, rather than just randomly selecting
the words and replacing them by artificial strings.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999715666666667">
This work was supported by the MateCat project,
which is funded by the EC under the 7th Frame-
work Programme.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999454857142857">
F. Blain, H. Schwenk, and J. Senellart. 2012. In-
cremental adaptation using translation information
and post-editing analysis. In International Work-
shop on Spoken Language Translation, pages 234–
241, Hong-Kong (China).
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
</reference>
<page confidence="0.984108">
91
</page>
<reference confidence="0.998714486842105">
mathematics of statistical machine translation: Pa-
rameter estimation. Computational Linguistics,
19(2):263–312.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of ibm model 2. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 644–648, Atlanta,
Georgia, June. Association for Computational Lin-
guistics.
Miquel Espl´a-Gomis, Felipe S´anchez-Martinez, and
Mikel L. Forcada. 2012. A simple approach to use
bilingual information sources for word alignment.
Procesamiento del Lenguaje Natural, (49):93–100.
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine trans-
lation. Comput. Linguist., 33(3):293–303.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ’08, pages 49–
57, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Daniel Hardt and Jakob Elming. 2010. Incremental
re-training for post-editing smt. In 9th Conference
of the Association for Machine Translation in the
Americas (AMTA), Denver, United States.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
Tenth Machine Translation Summit (MT Summit X),
pages 79–86, Phuket, Thailand.
Patrik Lambert, Adri`a de Gispert, Rafael E. Banchs,
and Jos´e B. Mari˜no. 2005. Guidelines for word
alignment evaluation and manual alignment. Lan-
guage Resources and Evaluation, 39(4):267–285.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreent. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Main
Conference, pages 104–111, New York City, USA,
June. Association for Computational Linguistics.
J. Scott McCarley, Abraham Ittycheriah, Salim
Roukos, Bing Xiang, and Jian-ming Xu. 2011. A
correction model for word alignments. In Proceed-
ings of the Conference on Empirical Methods in Nat-
ural Language Processing, EMNLP ’11, pages 889–
898, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
Franz Josef Och and Hermann Ney. 2000. Improved
statistical alignment models. In Proceedings of the
38th Annual Meeting of the Association of Compu-
tational Linguistics (ACL).
F.J. Och and H. Ney. 2003. A systematic comparison
of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Tomaˇz Erjavec, Dan Tufis¸, and
D´aniel Varga. The jrc-acquis: A multilingual
aligned parallel corpus with 20+ languages. In In
Proceedings of the 5th International Conference on
Language Resources and Evaluation (LREC), pages
2142–2147, Genoa, Italy.
Nadi Tomeh, Alexandre Allauzen, Guillaume Wis-
niewski, and Franois Yvon. 2010. Refining word
alignment with discriminative training. In Proceed-
ings of the ninth Conference of the Association for
Machine Translation in the America (AMTA).
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
word alignment in statistical translation. In Pro-
ceedings of COLING, pages 836–841, Copenhagen,
Denmark.
Yuqi Zhang, Evgeny Matusov, and Hermann Ney.
2009. Are unaligned words important for machine
translation? In Conference of the European As-
sociation for Machine Translation, pages 226–233,
Barcelona, Spain.
</reference>
<page confidence="0.996018">
92
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.349034">
<title confidence="0.999964">Online Word Alignment for Online Adaptive Machine Translation</title>
<author confidence="0.999985">M Amin</author>
<affiliation confidence="0.942064">University of Trento,</affiliation>
<email confidence="0.996717">farajian@fbk.eu</email>
<author confidence="0.910157">Nicola</author>
<affiliation confidence="0.592216">Trento,</affiliation>
<email confidence="0.997273">bertoldi@fbk.eu</email>
<author confidence="0.943321">Marcello</author>
<affiliation confidence="0.88942">Trento,</affiliation>
<email confidence="0.999129">federico@fbk.eu</email>
<abstract confidence="0.993283464285714">A hot task in the Computer Assisted Translation scenario is the integration of Machine Translation (MT) systems that adapt sentence after sentence to the postedits made by the translators. A main role in the MT online adaptation process is played by the information extracted from source and post-edited sentences, which in turn depends on the quality of the word alignment between them. In fact, this step is particularly crucial when the user corrects the MT output with words for which the system has no prior information. In this paper, we first discuss the application of popular state-of-the-art word aligners to this scenario and reveal their poor performance in aligning unknown words. Then, we propose a fast procedure to refine their outputs and to get more reliable and accurate alignments for unknown words. We evaluate our enhanced word-aligner on three language pairs, namely English-Italian, English- French, and English-Spanish, showing a consistent improvement in aligning unknown words up to 10% absolute Fmeasure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Blain</author>
<author>H Schwenk</author>
<author>J Senellart</author>
</authors>
<title>Incremental adaptation using translation information and post-editing analysis.</title>
<date>2012</date>
<booktitle>In International Workshop on Spoken Language Translation,</booktitle>
<pages>234--241</pages>
<location>Hong-Kong</location>
<contexts>
<context position="5981" citStr="Blain et al. (2012)" startWordPosition="965" endWordPosition="968">viding the learning task into word alignment and phrase extraction tasks, and replacing the standard wordalignment module, which is a variation of EM algorithm (Och and Ney, 2003), with a greedy search algorithm, they attempt to find a quick approximation of the word alignments of the newly translated sentence. They also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT output (hypothesis) as a pivot to find the word alignments between the source sentence and its corresponding reference. Similarly to (Hardt and Elming, 2010), once the word alignment between the source and post-edit sentence pair is generated, they use the standard phrase extraction method to extract the parallel phrase pairs. This work is based on an implicit assumption that MT output is reliable enough to make a bridge between source</context>
</contexts>
<marker>Blain, Schwenk, Senellart, 2012</marker>
<rawString>F. Blain, H. Schwenk, and J. Senellart. 2012. Incremental adaptation using translation information and post-editing analysis. In International Workshop on Spoken Language Translation, pages 234– 241, Hong-Kong (China).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="7679" citStr="Brown et al., 1993" startWordPosition="1249" endWordPosition="1252">ssing alignments between the automatic translation and postedit, which ultimately results in incomplete paths from source to post-edit. But, the goal here is to accurately align the known words, as well as learning the alignments of the new words, which is not feasible by this approach. In order to improve the quality of the word alignments McCarley et al. (2011) proposed a trainable correction model which given a sentence pair and their corresponding automatically produced word alignment, it tries to fix the wrong alignment links. Similar to the hill-climbing approach used in IBM models 3-5 (Brown et al., 1993), this approach iteratively performs small modifications in each step, based on the changes of the previous step. However, the use of additional sources of knowledge, such as POS tags of the words and their neighbours, helps the system to take more accurate decisions. But, requiring manual word alignments for learning the alignment moves makes this approach only applicable for a limited number of language pairs for which manual aligned gold references are available. Tomeh et al. (2010) introduced a supervised discriminative word alignment model for producing higher quality word alignments, whi</context>
<context position="9513" citStr="Brown et al., 1993" startWordPosition="1555" endWordPosition="1558"> on the which are defined as follows (Fraser and Marcu, manually annotated training corpora which is not 2007): available for most of the language pairs. 3 Word Alignment Word alignment is the task of finding the correspondence among the words of a sentence pair (Figure 1). From a mathematical point of view, it is a relation among the words, because any word in a sentence can be mapped into zero, one or more words of the other, and vice-versa; in other words, any kind of link is allowed, namely one-toone, many-to-one, many-to-many, as well as leaving words unaligned. So called IBM models 1-5 (Brown et al., 1993) as well as the HMM-based alignment models (Vogel et al., 1996), and their variations are extensively studied and widely used for this task. They are directional alignment models, because permit only many-to-one links; but often the alignments in the two opposite directions are combined in a so-called symmetrized alignment, which is obtained by intersection, union or other smart combination. Nowadays, word-aligners are mostly employed in an intermediate step of the training procedure of a SMT system; In this step, the training corpus is word aligned as a side effect of the estimation of the al</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of ibm model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>644--648</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="17111" citStr="Dyer et al., 2013" startWordPosition="2739" endWordPosition="2742">eir capability in handling the unknown words. For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner (Liang et al., 2006) applies the co-training approach for training the IBM model 1 and HMM. We trained berkeley aligner using 5 iterations of model 1 followed by 5 iterations of HMM. When applied to new sentence pairs, the system produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). When applied to new sentence pairs, we first produced the two directional alignments, and then combined them into a symmetrized alignment by using the grow-diag-final-and heuristic (Och and Ney, 2003). mgiza++ (Gao and Vogel, 2008) and its ancestors, i.e. giza, and giza++, implement all the IBM models and HMM based alignment models. mgiza++ is a multithreaded version of giza++, which enables an efficient use of multi-core platform</context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013. A simple, fast, and effective reparameterization of ibm model 2. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 644–648, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miquel Espl´a-Gomis</author>
<author>Felipe S´anchez-Martinez</author>
<author>Mikel L Forcada</author>
</authors>
<title>A simple approach to use bilingual information sources for word alignment. Procesamiento del Lenguaje Natural,</title>
<date>2012</date>
<marker>Espl´a-Gomis, S´anchez-Martinez, Forcada, 2012</marker>
<rawString>Miquel Espl´a-Gomis, Felipe S´anchez-Martinez, and Mikel L. Forcada. 2012. A simple approach to use bilingual information sources for word alignment. Procesamiento del Lenguaje Natural, (49):93–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>3</issue>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Comput. Linguist., 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="17508" citStr="Gao and Vogel, 2008" startWordPosition="2799" endWordPosition="2802"> produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). When applied to new sentence pairs, we first produced the two directional alignments, and then combined them into a symmetrized alignment by using the grow-diag-final-and heuristic (Och and Ney, 2003). mgiza++ (Gao and Vogel, 2008) and its ancestors, i.e. giza, and giza++, implement all the IBM models and HMM based alignment models. mgiza++ is a multithreaded version of giza++, which enables an efficient use of multi-core platforms. We trained the system using the following configuration for model iterations: 15h53343. mgiza++ also produces directional alignment; hence, we followed the same protocol to create a symmetrize alignment of sentence pairs as we did for fast-align. Differently from berkeley and fast-align, mgiza++ somehow adapts its models when applied to new sentence pairs. According to the so-called “forced </context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08, pages 49– 57, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
<author>Jakob Elming</author>
</authors>
<title>Incremental re-training for post-editing smt.</title>
<date>2010</date>
<booktitle>In 9th Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>Denver, United States.</location>
<contexts>
<context position="6299" citStr="Hardt and Elming, 2010" startWordPosition="1014" endWordPosition="1018">hey also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT output (hypothesis) as a pivot to find the word alignments between the source sentence and its corresponding reference. Similarly to (Hardt and Elming, 2010), once the word alignment between the source and post-edit sentence pair is generated, they use the standard phrase extraction method to extract the parallel phrase pairs. This work is based on an implicit assumption that MT output is reliable enough to make a bridge between source and reference. However, in the real world this is not always true. The post-editor sometimes makes a lot of changes in the MT output, or even translates the entire sentence from scratch, which makes the post-edit very different from the automatic translation. Moreover, in the presence of new words in the source sent</context>
</contexts>
<marker>Hardt, Elming, 2010</marker>
<rawString>Daniel Hardt and Jakob Elming. 2010. Incremental re-training for post-editing smt. In 9th Conference of the Association for Machine Translation in the Americas (AMTA), Denver, United States.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Tenth Machine Translation Summit (MT Summit X),</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="12805" citStr="Koehn, 2005" startWordPosition="2103" endWordPosition="2104">is example, Precision and Recall will be about 0.85 (=11/13) and 0.91 (=10/11), respectively, and the corresponding F is hence about 0.88. Focusing on the oov-alignment only, Precisionoo„ is 1.00 (=1/1), Recalloo„ is 0.50 (=1/2), and Foo„ is 0.67. 3.2 Evaluation Benchmark In this paper, we compare word-alignment performance of three word-aligners introduced in Section 3.3 on three distinct tasks, namely EnglishItalian, English-French, and English-Spanish; the training corpora, common to all word-aligners, are subset of the JRC-legal corpus1 (Steinberger et al., ), of the Europarl corpus V7.0 (Koehn, 2005), and of the Hansard parallel corpus2, respectively. 86 1langtech.jrc.it/JRC-Acquis.html 2www.isi.edu/natural-language/ download/hansard/index.html financial assistance mechanisms are less rapidly deployable than conventional budgetary mechanisms i meccanismi di assistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi di bilancio convenzionali financial assistance mechanisms are less rapidly deployable than conventional budgetary mechanisms i meccanismi di assistenza finanziaria sono attivabili meno rapidamente rispetto ai meccanismi di bilancio convenzionali Figure 1: Ex</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of the Tenth Machine Translation Summit (MT Summit X), pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrik Lambert</author>
<author>Adri`a de Gispert</author>
<author>Rafael E Banchs</author>
<author>Jos´e B Mari˜no</author>
</authors>
<title>Guidelines for word alignment evaluation and manual alignment.</title>
<date>2005</date>
<journal>Language Resources and Evaluation,</journal>
<volume>39</volume>
<issue>4</issue>
<marker>Lambert, de Gispert, Banchs, Mari˜no, 2005</marker>
<rawString>Patrik Lambert, Adri`a de Gispert, Rafael E. Banchs, and Jos´e B. Mari˜no. 2005. Guidelines for word alignment evaluation and manual alignment. Language Resources and Evaluation, 39(4):267–285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreent.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>104--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="16679" citStr="Liang et al., 2006" startWordPosition="2670" endWordPosition="2673">, such as replacing singletons or low-frequency words which have more potential to be unknown, instead of randomly selection of the words. But in this paper we decided to follow the random selection of the words. 87 3.3 State-of-the-art Word Aligners We consider three widely-used word aligners, namely berkeley, fast-align, and mgiza++. We analyze their performance in aligning an held-out test corpora; in particular, we compare their capability in handling the unknown words. For a fair comparison, all aligners are trained on the same training corpora described in Section 3.2. berkeley aligner (Liang et al., 2006) applies the co-training approach for training the IBM model 1 and HMM. We trained berkeley aligner using 5 iterations of model 1 followed by 5 iterations of HMM. When applied to new sentence pairs, the system produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). Wh</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreent. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 104–111, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Scott McCarley</author>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
<author>Bing Xiang</author>
<author>Jian-ming Xu</author>
</authors>
<title>A correction model for word alignments.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>889--898</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7425" citStr="McCarley et al. (2011)" startWordPosition="1208" endWordPosition="1211">ferent from the automatic translation. Moreover, in the presence of new words in the source sentence, the MT system either does not produce any translation for the new word, or directly copies it in the output. Due to the above two reasons, there will be missing alignments between the automatic translation and postedit, which ultimately results in incomplete paths from source to post-edit. But, the goal here is to accurately align the known words, as well as learning the alignments of the new words, which is not feasible by this approach. In order to improve the quality of the word alignments McCarley et al. (2011) proposed a trainable correction model which given a sentence pair and their corresponding automatically produced word alignment, it tries to fix the wrong alignment links. Similar to the hill-climbing approach used in IBM models 3-5 (Brown et al., 1993), this approach iteratively performs small modifications in each step, based on the changes of the previous step. However, the use of additional sources of knowledge, such as POS tags of the words and their neighbours, helps the system to take more accurate decisions. But, requiring manual word alignments for learning the alignment moves makes </context>
<context position="8872" citStr="McCarley et al., 2011" startWordPosition="1442" endWordPosition="1445"> quality word alignments, which is trained on a manually aligned training corpus. To reduce the search space of the word aligner, they propose to provide the system with a set of automatic word alignments and consider the union of these alignments as the possible search space. This transforms the word alignment process into 85 the alignment refinement task in which given a set 3.1 Evaluation Measures of automatic word alignments, the system tries to A word aligner is usually evaluated in terms of find the best word alignment points. Similar to Precision, Recall, and F-measure (or shortly F), (McCarley et al., 2011), this approach relies on the which are defined as follows (Fraser and Marcu, manually annotated training corpora which is not 2007): available for most of the language pairs. 3 Word Alignment Word alignment is the task of finding the correspondence among the words of a sentence pair (Figure 1). From a mathematical point of view, it is a relation among the words, because any word in a sentence can be mapped into zero, one or more words of the other, and vice-versa; in other words, any kind of link is allowed, namely one-toone, many-to-one, many-to-many, as well as leaving words unaligned. So c</context>
</contexts>
<marker>McCarley, Ittycheriah, Roukos, Xiang, Xu, 2011</marker>
<rawString>J. Scott McCarley, Abraham Ittycheriah, Salim Roukos, Bing Xiang, and Jian-ming Xu. 2011. A correction model for word alignments. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 889– 898, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association of Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="14342" citStr="Och and Ney, 2000" startWordPosition="2305" endWordPosition="2308"> Statistics of the three training corpora are reported in Table 1. En-It En-Fr En-Es Segments 940K 1.1M 713K Tokenssrc 19.8M 19.8M 19.8M Tokenstrg 20.3M 23.3M 20.4M Table 1: Statistics of the training corpora for English-Italian, English-French, and EnglishSpanish tasks. Three evaluation data sets are also available, which belong to the same domains of the corresponding training corpora. The English-Italian test set was built by two professional translators by correcting an automatically produced wordalignment. The English-French test set is the manually aligned parallel corpus introduced in (Och and Ney, 2000)3. The English-Spanish test set was provided by (Lambert et al., 2005)4. Statistics of the three test sets are reported in Table 2. To have a better understanding of the behavior of the word aligners on the unknown words, we created new test sets with an increasing ratio of the unknown words (oov-rate), for each task. Starting from each of the original test set, we replaced an increasing portion of randomly chosen words by strings which do not exist in the training corpus; the oov-noise artificially introduced ranges from 3www.cse.unt.edu/˜rada/wpt/data/ English-French.test.tar.gz 4www.computi</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association of Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="5541" citStr="Och and Ney, 2003" startWordPosition="892" endWordPosition="895">nhanced faster implementation of the best performing word aligner, to make it usable in the online scenario. In Section 5 we show experimental results of this module on three different languages. Finally, we draw some final comments in Section 6. 2 Related works Hardt et al. (2010) presented an incremental retraining method which simulates the procedure of learning from post-edited MT outputs (references), in a real time fashion. By dividing the learning task into word alignment and phrase extraction tasks, and replacing the standard wordalignment module, which is a variation of EM algorithm (Och and Ney, 2003), with a greedy search algorithm, they attempt to find a quick approximation of the word alignments of the newly translated sentence. They also use some heuristics to improve the obtained alignments, without supporting it with some proofs or even providing some experimental results. Furthermore, the running time of this approach is not discussed, and it is not clear how effective this approach is in online scenarios. Blain et al. (2012) have recently studied the problem of incremental learning from post-editing data, with minimum computational complexity and acceptable quality. They use the MT</context>
<context position="17477" citStr="Och and Ney, 2003" startWordPosition="2794" endWordPosition="2797">ew sentence pairs, the system produces bi-directional symmetrized alignment. fast-align is a recently developed unsupervised word aligner that uses a log-linear reparametrization of IBM model 2 for training the word alignment models (Dyer et al., 2013). We exploited the default configuration with 5 iterations for training. As the system is directional, we trained two systems (source-to-target and targetto-source). When applied to new sentence pairs, we first produced the two directional alignments, and then combined them into a symmetrized alignment by using the grow-diag-final-and heuristic (Och and Ney, 2003). mgiza++ (Gao and Vogel, 2008) and its ancestors, i.e. giza, and giza++, implement all the IBM models and HMM based alignment models. mgiza++ is a multithreaded version of giza++, which enables an efficient use of multi-core platforms. We trained the system using the following configuration for model iterations: 15h53343. mgiza++ also produces directional alignment; hence, we followed the same protocol to create a symmetrize alignment of sentence pairs as we did for fast-align. Differently from berkeley and fast-align, mgiza++ somehow adapts its models when applied to new sentence pairs. Acco</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F.J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Anna Widiger</author>
<author>Camelia Ignat</author>
<author>Tomaˇz Erjavec</author>
<author>Dan Tufis¸</author>
<author>D´aniel Varga</author>
</authors>
<title>The jrc-acquis: A multilingual aligned parallel corpus with 20+ languages. In</title>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>2142--2147</pages>
<location>Genoa, Italy.</location>
<marker>Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis¸, Varga, </marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaˇz Erjavec, Dan Tufis¸, and D´aniel Varga. The jrc-acquis: A multilingual aligned parallel corpus with 20+ languages. In In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC), pages 2142–2147, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadi Tomeh</author>
<author>Alexandre Allauzen</author>
<author>Guillaume Wisniewski</author>
<author>Franois Yvon</author>
</authors>
<title>Refining word alignment with discriminative training.</title>
<date>2010</date>
<booktitle>In Proceedings of the ninth Conference of the Association for Machine Translation in the America (AMTA).</booktitle>
<contexts>
<context position="8169" citStr="Tomeh et al. (2010)" startWordPosition="1328" endWordPosition="1331">ent, it tries to fix the wrong alignment links. Similar to the hill-climbing approach used in IBM models 3-5 (Brown et al., 1993), this approach iteratively performs small modifications in each step, based on the changes of the previous step. However, the use of additional sources of knowledge, such as POS tags of the words and their neighbours, helps the system to take more accurate decisions. But, requiring manual word alignments for learning the alignment moves makes this approach only applicable for a limited number of language pairs for which manual aligned gold references are available. Tomeh et al. (2010) introduced a supervised discriminative word alignment model for producing higher quality word alignments, which is trained on a manually aligned training corpus. To reduce the search space of the word aligner, they propose to provide the system with a set of automatic word alignments and consider the union of these alignments as the possible search space. This transforms the word alignment process into 85 the alignment refinement task in which given a set 3.1 Evaluation Measures of automatic word alignments, the system tries to A word aligner is usually evaluated in terms of find the best wor</context>
</contexts>
<marker>Tomeh, Allauzen, Wisniewski, Yvon, 2010</marker>
<rawString>Nadi Tomeh, Alexandre Allauzen, Guillaume Wisniewski, and Franois Yvon. 2010. Refining word alignment with discriminative training. In Proceedings of the ninth Conference of the Association for Machine Translation in the America (AMTA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="9576" citStr="Vogel et al., 1996" startWordPosition="1566" endWordPosition="1569">y annotated training corpora which is not 2007): available for most of the language pairs. 3 Word Alignment Word alignment is the task of finding the correspondence among the words of a sentence pair (Figure 1). From a mathematical point of view, it is a relation among the words, because any word in a sentence can be mapped into zero, one or more words of the other, and vice-versa; in other words, any kind of link is allowed, namely one-toone, many-to-one, many-to-many, as well as leaving words unaligned. So called IBM models 1-5 (Brown et al., 1993) as well as the HMM-based alignment models (Vogel et al., 1996), and their variations are extensively studied and widely used for this task. They are directional alignment models, because permit only many-to-one links; but often the alignments in the two opposite directions are combined in a so-called symmetrized alignment, which is obtained by intersection, union or other smart combination. Nowadays, word-aligners are mostly employed in an intermediate step of the training procedure of a SMT system; In this step, the training corpus is word aligned as a side effect of the estimation of the alignment models by means of the Expectation-Maximization algorit</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based word alignment in statistical translation. In Proceedings of COLING, pages 836–841, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuqi Zhang</author>
<author>Evgeny Matusov</author>
<author>Hermann Ney</author>
</authors>
<title>Are unaligned words important for machine translation?</title>
<date>2009</date>
<booktitle>In Conference of the European Association for Machine Translation,</booktitle>
<pages>226--233</pages>
<location>Barcelona,</location>
<contexts>
<context position="23461" citStr="Zhang et al., 2009" startWordPosition="3801" endWordPosition="3804">e aligned, but most of the unknown words will not. It is worth mentioning that aligning unknown words in this step depends on the quality of the employed word aligner. Once the alignments are computed and symmetrized (if required), phrase extraction procedure is applied to extract all valid phrase-pairs. Note that un-aligned words are included in the extracted phrase pairs, if their surrounding words are aligned. It has been shown that inclusion of un-aligned words in the phrase-pairs, generally, has negative effects on the translation quality and can produce errors in the translation output (Zhang et al., 2009). Nevertheless, the overlap among phrase-pairs, which contain un-aligned unknown words, can be considered as a valuable source of knowledge for inducing the correct alignment of these words. To get their alignments from the extracted phrase-pairs we follow an approach similar to (Espl´a-Gomis et al., 2012) in which the word alignment probabilities are determined by the alignment strength measure. Given the source and target segments (S = {s1,... , sl} and T = {t1, ... , sm}), and the set of extracted parallel phrase-pairs (Φ), the alignment strength Ai,j(S, T, Φ) of the si and tj can be calcul</context>
</contexts>
<marker>Zhang, Matusov, Ney, 2009</marker>
<rawString>Yuqi Zhang, Evgeny Matusov, and Hermann Ney. 2009. Are unaligned words important for machine translation? In Conference of the European Association for Machine Translation, pages 226–233, Barcelona, Spain.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>