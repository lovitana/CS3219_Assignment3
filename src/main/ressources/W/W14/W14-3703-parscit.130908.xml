<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001009">
<title confidence="0.978591">
Multi-document Summarization Using Bipartite Graphs
</title>
<author confidence="0.842421">
Daraksha Parveen and Michael Strube
</author>
<affiliation confidence="0.774012">
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.566871">
Schloss-Wolfsbrunnenweg 35
69118 Heidelberg, Germany
</address>
<email confidence="0.857493">
(daraksha.parveen|michael.strube)@h-its.org
</email>
<sectionHeader confidence="0.990252" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999837083333333">
In this paper, we introduce a novel graph
based technique for topic based multi-
document summarization. We transform
documents into a bipartite graph where
one set of nodes represents entities and the
other set of nodes represents sentences. To
obtain the summary we apply a ranking
technique to the bipartite graph which is
followed by an optimization step. We test
the performance of our method on several
DUC datasets and compare it to the state-
of-the-art.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999543416666666">
Topic-based multi-document summarization aims
to create a single summary from a set of given
documents while considering the topic of inter-
est. The input documents can be created by query-
ing an information retrieval or search engine for a
particular topic and retaining highly ranked docu-
ments, or by clustering documents of a large col-
lection and then using each cluster as a set of input
documents (Galanis et al., 2012). Here, each clus-
ter of the set of documents contains a representa-
tive topic.
A summary extracted from a set of input doc-
uments must be related to the topic of that set.
If textual units (or sentences) extracted from
different documents convey the same informa-
tion, then those units are called redundant. Ide-
ally, the multi-document summary should be non-
redundant. Hence each textual unit in a summary
should convey unique information. Still, all ex-
tracted textual units should be related to the topic.
They should also make up a coherent summary.
When building summaries from multiple docu-
ments belonging to different sets, a system should
attempt to optimize these three basic properties:
</bodyText>
<listItem confidence="0.916897625">
1. Relevance: A summary should contain only
those textual units which are relevant to the
topic and provide useful information.
2. Non-redundancy: A summary should not
contain the same information twice.
3. Readability: A summary should have good
readability (syntactically well formed, no
dangling pronouns, coherent,...).
</listItem>
<bodyText confidence="0.988463303030303">
Generally, multi-document summarization sys-
tems differ from each other on the basis of docu-
ment representation, sentence selection method or
on the requirements for the output summary. Pop-
ular methods for document representation include
graph-based representations (e.g. LexRank (Erkan
and Radev, 2004) and TextRank (Mihalcea and Ta-
rau, 2004)) and tf-idf vector-based representations
(Luhn, 1958; Nenkova and Vanderwende, 2005;
Goldstein et al., 2000). These document represen-
tations act as input for the next phase and provide
information about the importance of individual
sentences. Sentence selection is the crucial phase
of the summarizer where sentence redundancy
must be handled in an efficient way. A widely
used technique is the greedy approach introduced
by Carbonell and Goldstein (1998) and Goldstein
et al. (2000). They compute a relevance score for
all sentences with regard to the topic, start by ex-
tracting the most relevant sentence, and then itera-
tively extract further sentences which are relevant
to the topic and at the same time most dissimilar
to already extracted sentences. Later more fun-
damental optimization methods have been widely
used in multi-document summarization, e.g. Inte-
ger Linear Programming (ILP) (McDonald, 2007;
Gillick et al., 2009; Nishikawa et al., 2010; Gala-
nis et al., 2012). Unlike most other approaches
(Galanis et al., 2012) has also taken into account
the readability of the final summary.
In this work, we introduce an extractive
topic based multi-document summarization sys-
tem which represents documents graphically and
</bodyText>
<page confidence="0.973086">
15
</page>
<note confidence="0.4778025">
Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 15–24,
October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999638571428571">
optimizes the importance of sentences and non-
redundancy. The importance of sentences is ob-
tained by means of applying the Hubs and Author-
ities ranking algorithm (Kleinberg, 1999) on the
unweighted bipartite graph whereas redundancy in
the final summary is dealt with entities in a graph.
In Section 2 we introduce the state-of-the-art in
topic based multi-document summarizaton. Sec-
tion 3 provides a detailed description of our ap-
proach. Experiments are described in Section 4
where we also briefly describe the datasets used
and the results. Section 5 discusses the results of
our approach, and in Section 6 we finally give con-
clusions.
</bodyText>
<sectionHeader confidence="0.999593" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999822904761905">
A graph-based representation of documents for
summarization is adopted by various approaches.
For instance, TextRank by Mihalcea and Tarau
(2004) applies the PageRank algorithm (Brin and
Page, 1998) to extract important sentences for sin-
gle document summarization. This ranking algo-
rithm proclaims the importance of a sentence by
considering the global information which is com-
puted recursively from the entire graph. Later,
the graph is converted into a weighted graph in
which the weights are calculated by measuring the
similarity of sentences (Mihalcea, 2004). Simi-
larly, in the LexRank approach (Erkan and Radev,
2004), documents are represented as a similarity
graph in which the sentences are nodes and these
sentences are then ranked according to centrality
measures. The three centrality measures used are
degree, LexRank with threshold and continuous
LexRank. LexRank is a measure to calculate ranks
using the similarity graph of sentences. It is also
known as lexical PageRank. The summarization
approach developed by Gong and Liu (2001) is
also based on ranking sentences where important
sentences are selected using a relevance measure
and latent semantic analysis.
Later, for better performance, sentences are
classified according to their existence in their final
summary in binary format i.e. 1 (belongs to sum-
mary) and 0 (doesn’t belong to summary) (Shen et
al., 2007; Gong and Liu, 2001). Here, the sen-
tences are projected as feature vectors and con-
ditional random fields are used to classify them.
During document processing, most informative
sentences are selected by the summarizer (Shen
et al., 2007). Fattah and Ren (2009) also consid-
ers summarization as two class classification prob-
lem. They use a genetic algorithm and mathemati-
cal regression to select appropriate weights for the
features and used different classification technique
for e.g. feed forward neural network, probablistic
neural network and Gaussian mixture models.
In the summarization task, optimization of the
three properties discussed in Section 1, relevance,
non-redundancy and readability, is required. This
is a global inference problem, which can be solved
by two approaches. Firstly, relevance and redun-
dancy can be optimized simultaneously. For in-
stance, Goldstein et al. (2000) developed a met-
ric named MMR-MD (influenced by the Max-
imum Marginal Relevance (MMR) approach of
Carbonell and Goldstein (1998)) and applied it to
clusters of passages. Similarly, influenced by the
SumBasic system (Nenkova and Vanderwende,
2005), Yih et al. (2007) developed a system which
assigns a score to each term on the basis of po-
sition and frequency information and selects the
sentence having highest score. Other approaches
are based on an estimate of word importance (e.g.
Lin and Hovy (2000)) or the log likelihood ratio
test which identifies the importance of words using
a supervised model that considers a rich set of fea-
tures (Hong and Nenkova, 2014). Finally, Barzi-
lay and Elhadad (1999) extract sentences which
are strongly connected by lexical chains for sum-
marization. The second approach deals with rel-
evance and redundancy seperately. For instance,
McKeown et al. (1999) create clusters of similar
sentences and pick the representative one from ev-
ery cluster. The representative sentence of a clus-
ter of sentences takes care of the requirement to
extract relevant information whereas clustering re-
duces the redundancy.
McDonald (2007) proposes a new ILP opti-
mization method for extractive summarization. He
introduces an objective function which maximizes
the importance of sentences and minimizes the
similarity of sentences. ILP methods for optimiza-
tion have also been adopted by Berg-Kirkpatrick
et al. (2011),Woodsend and Lapata (2012) and
Galanis et al. (2012). Until now, Galanis et
al. (2012) have reported the highest scores for
multi-document summarization on DUC2005 and
DUC2007. However, their approach is not com-
pletely unsupervised.
</bodyText>
<page confidence="0.998414">
16
</page>
<sectionHeader confidence="0.996132" genericHeader="method">
3 Our method
</sectionHeader>
<bodyText confidence="0.999797857142857">
This section describes the technique, which we
adopted for summarization. We start by discussing
the graphical representation of the text followed
by a description how to quantify the importance
of sentences in the input texts. We then discuss
the ILP technique which optimizes the importance
of sentences and redundancy.
</bodyText>
<subsectionHeader confidence="0.999111">
3.1 Graphical representation of text
</subsectionHeader>
<bodyText confidence="0.999670055555556">
The graphical representation of a text makes it
more expressive than a traditional tf-idf depiction
for summarization. A graph can easily capture
the essence of the whole text without leading to
high computational complexity. Guinaudeau and
Strube (2013) introduced a bipartite graph repre-
sentation of text based on the entity grid (Barzilay
and Lapata, 2008) representation of text. The pro-
jection of this bipartite graph representation has
been used for calculating the local coherence of
a text (Guinaudeau and Strube, 2013). The basic
intuition to use a bipartite graph for summariza-
tion is that it contains entity transitions similar to
lexical chains (Barzilay and Elhadad, 1999). An
appropriate measure to determine the importance
of sentences by considering strong entity transi-
tions indicates the information central to a text bet-
ter than simply giving scores on the basis of most
frequent words. The unweighted bipartite graph
G = (V3l Vel L) contains two sets of nodes, V3
corresponding to the sentences from the input text
and Ve corresonding to the entities, and a set of
edges represented by L. Figure 1 shows a model
summary from the DUC 2006 data, which is trans-
formed into an entity grid in Figure 2 (Barzilay
and Lapata, 2008; Elsner and Charniak, 2011).
Here, cells are filled with the syntactic role a men-
tion of an entity occupies in a sentence. Subjects
are denoted by S, objects by O and all other roles
by X. If an entity is not mentioned in a sentence
then the corresponding cell contains “-”. In the
corresponding bipartite graph (Figure 3), edges are
created between a sentence and an entity only if
the entity is mentioned in a sentence (the cell in
entity grid is not “-”). Since this is a dyadic graph,
there are no edges between nodes of the same set.
</bodyText>
<subsectionHeader confidence="0.999896">
3.2 Ranking the importance of sentences
</subsectionHeader>
<bodyText confidence="0.999987933333333">
A graph based ranking algorithm is used to cal-
culate the importance of a sentence represented
as a node in the graph discussed above. In con-
trast to the local information specific to a ver-
tex, graphical ranking algorithms take (graph-)
global information to calculate the rank of a node.
The Hyperlink-Induced Topic Search algorithm
(HITS, also known as Hubs and Authorities) by
Kleinberg (1999) is used to rank sentences in our
method. This algorithm considers two types of
nodes, hence it is well suited to rank sentences in
our bipartite graph. Entities are considered as hub
nodes, and sentences are considered as authority
nodes. The importance of a sentence is calculated
in two steps:
</bodyText>
<listItem confidence="0.54610975">
• Hub update rule: Update each node’s hub
score to be equal to the sum of the author-
ity scores of each node that it points to. It can
be written as:
</listItem>
<equation confidence="0.91318">
Hub5core = A • Authority5core (1)
</equation>
<bodyText confidence="0.9749285">
Here, A is an adjacency matrix which represents
the connection between the nodes in a graph.
</bodyText>
<listItem confidence="0.9977288">
• Authority update rule: In this step, each au-
thority node is updated by equating them to
the sum of the hub scores of each node, which
is pointing to that authority node. It can be
written as:
</listItem>
<equation confidence="0.963995">
Authority5core = AT • Hub5core (2)
</equation>
<bodyText confidence="0.99952315">
Hence, the authority weight is high if it is
pointed at by a hub having high weights.
Given some intial ranks to all nodes in a graph,
the hub and authority update rules are applied un-
til convergence. After applying this algorithm, the
rank of every node is obtained. The rank is consid-
ered as importance of the node within the graph.
We normalize the ranks of sentences according to
sentence length to avoid assigning high ranks to
long sentences.
To incorporate important information from doc-
uments, ranks of entities are incremented by
Rank+tfdoe•idfdoe in every iteration, where tfdoe
shows the importance of an entity in a document
by calculating the frequency whereas idfdoe is an
inverse document frequency from the current clus-
ter. Rank + tfdoe • idfdoe is used in calculating the
AuthorityScore. Initially, the Rank can be any nu-
merical value but after every iteration of the HITS
algorithm it will be updated accordingly.
</bodyText>
<page confidence="0.994413">
17
</page>
<bodyText confidence="0.986383428571428">
S1 The treatment of osteoarthritis includes a number of non-steroidal anti-inflammatory drugs such as
aspirin, acetaminophen, and ibuprofen.
S2 These drugs, however, cause liver damage and gastrointestinal bleeding and contribute to thousands
of hospitalizations and deaths per year.
S3 New cox-2 inhibitor drugs are proven as effective against pain, with fewer gastrointestinal side
effects.
S4 The two together appeared to reduce knee pain after 8 weeks.
</bodyText>
<figureCaption confidence="0.9999">
Figure 1: Model summary from DUC 2006
</figureCaption>
<figure confidence="0.9787905625">
- - - - - - - -
S X O X X X X -
S
---
S
---
- -
- - - - - - -
- - - - - - - - - - -
- O O X X X - - - -
- X X - -
- O - S X
S1
S2
S3
S4
</figure>
<figureCaption confidence="0.9998915">
Figure 2: Entity grid of the model summary from Figure 1
Figure 3: Bipartite graph derived from the entity grid from Figure 2
</figureCaption>
<subsectionHeader confidence="0.998828">
3.3 Optimization algorithm
</subsectionHeader>
<bodyText confidence="0.999989842105263">
In topic-based multi-document summarization,
the final summary should be non-redundant. At
the same time it should contain the important in-
formation from the documents. To achieve these
two conditions, we employ integer linear program-
ming (ILP) to obtain an optimal solution. In ILP
we maximize an objective function. Our objective
function, given in Equation 3, has two parts: the
importance of a summary and the non-redundancy
of a summary. The values obtained after ranking
by the HITS algorithm are used as the importance
of sentences for ILP. Non-redundancy can not be
calculated for a single sentence. Instead, it has to
be evaluated with respect to other sentences. We
calculate non-redundancy by the number of un-
shared entities, i.e. entities which are not shared
by other sentences, after appending a sentence to
a summary. The least redundant sentence will in-
crease the number of entities in the final summary.
</bodyText>
<equation confidence="0.8938068">
Equation 3 is the objective function where m is
n
max(A1
i=1
(Rank(si) + topicsim(si))·xi
(3)
yj)
+A2
�m
j=1
</equation>
<page confidence="0.989575">
18
</page>
<table confidence="0.9963535">
Topic Documents per topic Human Summaries Word limit in final summary
DUC 2005 50 25-50 4-9 250
DUC 2006 50 25 4 250
DUC 2007 45 25 4 250
</table>
<tableCaption confidence="0.996878">
Table 1: Document Statistics
</tableCaption>
<bodyText confidence="0.999854307692308">
the number of entities in a document and n is the
number of sentences in a document. xi and yj are
binary variables for sentences and entities respec-
tively. A1 and A2 are tuning parameters. Rank(si)
is a rank of a sentence si obtained by applying the
HITS algorithm. Since, we work on topic-based
multi-document summarization, we include topic
information by calculating topicsim(si), which
captures the cosine similarity of a sentence si with
the corresponding topic. If the topic contains more
than one sentence then we take an average of co-
sine similarity with a sentence si. The constraints
on the variables are shown in Equations 4-6:
</bodyText>
<equation confidence="0.865782">
Xn Len(si) · xi G Len(summary) (4)
i=1
</equation>
<bodyText confidence="0.9783625">
Here, Len(si) and Len(summary) are the
number of words in a sentence si and in the fi-
nal summary, respectively. This constraint does
not allow the length of final summary to exceed its
maximum length. The maximum length varies de-
pending on the datasets discussed in Section 4.1.
</bodyText>
<equation confidence="0.978179">
X yj &gt; Entities(si),for i = 1,...,n (5)
jEEi
</equation>
<bodyText confidence="0.9998794">
In constraint 5, Ei is a set of entities present in
a sentence si. The number of entities present in a
sentence is represented as Entities(si). If a sen-
tence si is selected then the entities present in a
sentence are also selected(P yj = Entities(si)).
Whereas, if a sentence si is not selected then
some of its entities can also be selected because
they may appear in already selected sentences
(Entities(si) = 0, P yj &gt; 0). In both the
cases, constraint 5 is not violated.
</bodyText>
<equation confidence="0.936749333333333">
X
xi &gt; yj, forj = 1, ... , m (6)
iESj
</equation>
<bodyText confidence="0.999903875">
In constraint 6, Sj is a set of sentences contain-
ing entity yj. This constraint shows that, if an en-
tity yj is selected then at least one sentence is se-
lected which contains it (yj = 1, P xi &gt; 1). If
an entity yj is not selected, then it is possible that
none of the sentences which contain it may not be
selected (yj = 0, P xi = 0). Also, constraint 4
holds in either of the cases.
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999799333333333">
We perform experiments on various DUC datasets
to compare the results with state-of-the-art sys-
tems.
</bodyText>
<subsectionHeader confidence="0.875104">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999982434782609">
Datasets used for our experiments are DUC2005
(Dang, 2005), DUC2006 (Dang, 2006) and
DUC20071 . Each dataset contains group of re-
lated documents. Each group of documents con-
tains one related topic or a query consisting of a
few sentences. In DUC, the final summary should
respond to the corresponding topic. Also, the sum-
mary cannot exceed the maximum allowed length.
For instance, in DUC2005, 250 words are allowed
in the final summary. Every document cluster has
corresponding human summaries for evaluating
system summaries on the basis of ROUGE scores
(Lin, 2004). The sources of DUC datasets are Los
Angeles Times, Financial Times of London, As-
sociated Press, New York Times and Xinhua news
agency. We employ ROUGE SU4 and ROUGE 2
as evaluation metrics. ROUGE returns recall, pre-
cision and F-score of a system, but usually only re-
call is used in for evaluating automatic summariza-
tion systems, because the final summary does not
contain many words. Hence, if the recall is high
then the summarization system is working well.
Document statistics is provided in Table 1.
</bodyText>
<subsectionHeader confidence="0.97139">
4.2 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999967833333333">
We use raw documents from the various DUC
datasets as input for our system. We remove non-
alphabetical characters from the documents. Then
we obtain a clean sentence split by means of the
Stanford parser (Klein and Manning, 2003) so that
the sentences are compatible with the next steps.
</bodyText>
<footnote confidence="0.985085">
1http://www-nlpir.nist.gov/projects/
duc/index.html
</footnote>
<page confidence="0.996177">
19
</page>
<table confidence="0.710794">
ROUGE-2 ROUGE-SU4
A1 = 0.5 &amp; A2 = 0.5 0.07950 0.14060
A1 = 0.6 &amp; A2 = 0.4 0.07956 0.14071
A1 = 0.7 &amp; A2 = 0.3 0.07975 0.14105
A1 = 0.8 &amp; A2 = 0.2 0.07976 0.14106
A1 = 0.9 &amp; A2 = 0.1 0.07985 0.14107
</table>
<tableCaption confidence="0.993005">
Table 2: Results on different A’s on DUC 2005
</tableCaption>
<bodyText confidence="0.9999735">
We use the Brown coherence toolkit (Elsner and
Charniak, 2011) to convert the documents into the
entity grid representation from which the bipar-
tite graph is constructed (Guinaudeau and Strube,
2013). Entities in the graph correspond to head
nouns of noun phrase mentioned in the sentences.
The ranking algorithm from Section 3.2 is applied
to this graph and returns the importance score of
a sentence as required by the objective function
given in Equation 3. Next optimization using ILP
is performed as described in Section 3.3. We use
GUROBI Optimizer2for performing ILP. ILP re-
turns a binary value, i.e., if a sentence should be
included in the summary it returns 1, if not it re-
turns 0. We set A1 = 0.7 and A2 = 0.3 for
all datasets. We did not choose the optimal val-
ues, but rather opted for ones which favor impor-
tance over non-redundancy. We did not observe
significant differences between different A values
as long as A1 &gt; A2 (see Table 2). The sentences in
the output summary are ordered according to their
ranks. If the output summary contains pronouns,
we perform pronoun resolution in the source doc-
uments using the coreference resolution system by
Martschat (2013). If pronoun and antecedent oc-
cur in the same sentence, we leave the pronoun.
If the antecedent occurs in an earlier sentence, we
replace the pronoun in the summary by the first
element of the coreference chain the pronoun be-
longs to. Except for setting A1 and A2 on DUC
2005, our approach is unsupervised, as there is no
traning data required. The recall (ROUGE) scores
on different datasets are shown in Table 3.
Table 3 shows that our system would have per-
formed very well in the DUC 2005 and DUC 2006
competitions with ranks in the top 3 and well in
the DUC 2007 competition. Since the compe-
titions date a while back, we compare in addi-
tion to the current state-of-art in multi-document
summarization. To our knowledge Galanis et al.
</bodyText>
<footnote confidence="0.9848965">
2Gurobi Optimization, Inc., http://www.gurobi.
com
</footnote>
<table confidence="0.9919915">
Dataset ROUGE-2 ROUGE-SU4
DUC 2005 (32) 0.07975 (1) 0.14105
DUC 2006 (35) 0.08969 0.15070
DUC 2007 (32) 0.10928 (6) 0.16735 (5)
</table>
<tableCaption confidence="0.99774">
Table 3: System performance (and rank) on the
</tableCaption>
<bodyText confidence="0.993102033333333">
DUC 2005, 2006 and 2007 (main) data. The num-
ber in parenthesis after the DUC year indicates the
number of competing systems.
(2012) report the best results on DUC 2005 data.
While their ROUGE-2 score is slightly better than
ours, we outperform them in terms of ROUGE-
SU4 (0.14105 vs. 0.13640), where, to our knowl-
edge, our results are the highest reported so far.
However, their results on DUC 2007 (ROUGE-2
0.12517 and ROUGE-SU4 0.17603) are still quite
a bit better than our results. On the DUC 2006
data we outperform the HIERSUM system by
Haghighi and Vanderwende (2009) on ROUGE-
2 (0.08969 vs. 0.086) as well as on ROUGE-
SU4 (0.15070 vs. 0.143). On the DUC 2007
data, our results are worse than theirs on ROUGE-
2 (0.10928 vs. 0.118) and on par on ROUGE-
SU4 (0.16735 vs. 0.167). The system which won
the DUC 2007 task, PYTHY by Toutanova et al.
(2007), performs similar to HIERSUM and hence
slightly better than our system on these data. The
recent work by Suzuki and Fukumoto (2014) eval-
uates also on DUC 2007 but reports only ROUGE-
1 scores. We obtain a ROUGE-1 score of 0.448 on
DUC 2007 which is better than Suzuki and Fuku-
moto (2014) (0.438) as well as PYTHY (0.426).
The best ROUGE-1 score reported to date has
been reported by Celikyilmaz and Hakkani-T¨ur
(2010) with 0.456. The difference between this
score and our score of 0.448 is rather small.
</bodyText>
<sectionHeader confidence="0.998122" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999885166666667">
Several approaches have been proposed for topic
based multi-document summarization on the DUC
datasets we use for our experiments. The best re-
sults to date have been obtained by supervised and
semi-supervised systems. The results of our sys-
tem are mostly on par with these systems though
our system is unsupervised (as mentioned in Sec-
tion 4 the values for A1 and A2 in the objective
function (Equation 3) were not tuned for optimal
ROUGE scores but rather set for favoring impor-
tance over non-redundancy).
We compared our results with various state-of-
</bodyText>
<page confidence="0.905715">
20
</page>
<figure confidence="0.793116333333333">
51 What is being learned from the study of deep water, seabeds, and deep water life?
52 What equipment and techniques are used?
53 What are plans for future related activity?
</figure>
<figureCaption confidence="0.991228">
Figure 4: Topic containing interrogative words from DUC 2007
</figureCaption>
<figure confidence="0.778683">
51 I’ve started to use irrigation hoses called “leaky pipe”.
52 Soil’s usually best to water the target area a few days before I plan to dig.
53 If I don’t place element in the root zone, element can’t be added later when the plants are growing.
54 The new composts were much lighter and more suitable for container plants in garden centres and
through these were rapidly introduced to gardeners.
</figure>
<figureCaption confidence="0.997879">
Figure 5: Sentences containing dangling first person pronoun from DUC 2005
</figureCaption>
<bodyText confidence="0.999988782608696">
the-art systems, and our system is giving compet-
itive results in both ROUGE-2 and ROUGE-SU4
scores. However, the ROUGE-2 score of Galanis
et al. (2012) on DUC 2005 is slightly better than
our score. This might be because they use bigram
information for redundancy reduction. However,
they need training data for sentence importance.
Hence their system has to be classified as super-
vised while ours is unsupervised.
We have also calculated the ROUGE-1 score
on DUC 2007 and compared it with state-of-
the-art approaches. HybHsum (Celikyilmaz and
Hakkani-T¨ur, 2010) has obtained the top ROUGE-
1 score on DUC 2007 with 0.456. However,
HybHsum is a semi-supervised approach which
requires a labeled training data. The difference
between our ROUGE-1 score of 0.448 and HybH-
sum ROUGE-1 score on DUC2007 is not signif-
icant (to be fair, achieving significant improve-
ments in ROUGE scores on DUC data is very dif-
ficult). In contrast to HybHsum, our approach is
unsupervised.
Our method computes importance on the basis
of a bipartite graph. We believe that our bipartite
graph captures more information than the general
graphs used in earlier graph-based approaches to
automatic summarization. Entity transition infor-
mation present in the bipartite graph of a docu-
ment, helps us in finding the salient sentences. Our
approach works well if the graph is not sparse.
We observed a couple of problems in the out-
put of our system which we plan to address in
future work. If topics contain interrogative pro-
nouns as shown in Figure 4 the mapping between
topic and sentences from the documents does not
work well. We need to resolve which entities the
interrogative pronouns refer to. Another problem
occurs, because the coreference resolution system
employed does not resolve first person pronouns.
Hence, we end up with summaries containing dan-
gling first person pronouns as shown in Figure 5.
However, our system appears to work reasonably
well in other cases where the summaries are co-
herent and readable and also have a high ROUGE
score as shown in the summary from DUC 2007
data in Figure 6.
</bodyText>
<sectionHeader confidence="0.99647" genericHeader="method">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999913888888889">
In this paper, we have presented an unsuper-
vised graph based approach for topic based multi-
document summarization. Our graph based ap-
proach provides state-of-the-art results on various
datasets taken from DUC competitions. The graph
based representation of a document makes com-
putation very efficient and less complex. In future
work, we incorporate the syntactic roles of enti-
ties, to provide more information in the method.
</bodyText>
<sectionHeader confidence="0.989766" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.973666">
This work has been funded by Klaus Tschira
Foundation, Heidelberg, Germany. The first au-
thor has been supported by a Heidelberg Institute
for Theoretical Studies Ph.D. scholarship.
</bodyText>
<page confidence="0.997969">
21
</page>
<bodyText confidence="0.9996775">
The European Parliament, angered by Turkey ’s human rights record, voted Thursday to freeze hundreds
of millions of US dollars in aid to Turkey for setting up a customs union with the EU. Since then , the
EU has been trying to patch up the relationship , with several leaders of member countries insisting
that Turkey ’s place is in the union. The special aid is part of the agreement between the European
Union EU and Turkey on the establishment of a customs union between the two sides. “ The European
Union, without renouncing its principles , ” will have to decide in December to allow Turkey to become
a formal candidate for EU membership. ANKARA , February 27 Xinhua Turkey today welcomed the
European Union ’s attitude toward its dispute with Greece and urged the EU to release financial assistance
immediately despite Greek efforts to block it. After the decision in December to exclude Turkey from
the first wave of enlargement talks , Turkey put its relations with the 15 member union on hold. During
Solana stay here, Turkish leaders reiterated their position to link the expansion of the NATO with Turkey
’s entry into the European Union. The European Union , European Union Ankara wants to join , is
pressing Turkey to find a peaceful solution to the war. The statement added that Greece , despite its
attempts , was unable to get the support of the other 14 European Union members in getting a statement
that would express solidarity with Greece and condemn Turkey. Both the European Union and the United
States criticized Turkey for jailing Birdal.
</bodyText>
<figureCaption confidence="0.977811">
Figure 6: Output summary from DUC 2007
</figureCaption>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99878">
This work has been funded by Klaus Tschira
Foundation, Heidelberg, Germany. The first au-
thor has been supported by a Heidelberg Institute
for Theoretical Studies Ph.D. scholarship.
</bodyText>
<sectionHeader confidence="0.997782" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997338672131147">
Regina Barzilay and Michael Elhadad. 1999. Us-
ing lexical chains for text summarization. In Inder-
jeet Mani and Mark T. Maybury, editors, Advances
in Automatic Text Summarization, pages 111–121.
Cambridge, Mass.: MIT Press.
Regina Barzilay and Mirella Lapata. 2008. Modeling
local coherence: An entity-based approach. Compu-
tational Linguistics, 34(1):1–34.
Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.
2011. Jointly learning to extract and compress. In
Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics, Portland,
Oreg., 19–24 June 2011, pages 481–490.
Sergey Brin and Lawrence Page. 1998. The
anatomy of a large-scale hypertextual web search
engine. Computer Networks and ISDN Systems,
30(1–7):107–117.
Jaime G. Carbonell and Jade Goldstein. 1998. The use
of MMR, diversity-based reranking for reordering
documents and producing summaries. In Proceed-
ings of the 21st Annual International ACM-SIGIR
Conference on Research and Development in Infor-
mation Retrieval, Melbourne, Australia, 24–28 Au-
gust 1998, pages 335–336.
Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2010. A hy-
brid hierarchical model for multi-document summa-
rization. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguis-
tics, Uppsala, Sweden, 11–16 July 2010, pages 815–
824.
Hoa Trang Dang. 2005. Overview of DUC 2005. In
Proceedings of the 2005 Document Understanding
Conference held at the Human Language Technol-
ogy Conference and Conference on Empirical Meth-
ods in Natural Language Processing, Vancouver,
B.C., Canada, 9–10 October 2005.
Hoa Trang Dang. 2006. Overview of DUC 2006. In
Proceedings of the 2006 Document Understanding
Conference held at the Human Language Technol-
ogy Conference of the North American Chapter of
the Association for Computational Linguistics, New
York, N.Y., 8–9 June 2006.
Micha Elsner and Eugene Charniak. 2011. Extending
the entity grid with entity-specific features. In Pro-
ceedings of the ACL 2011 Conference Short Papers,
Portland, Oreg., 19–24 June 2011, pages 125–129.
G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank:
Graph-based lexical centrality as salience in text
summarization. Journal of Artificial Intelligence
Research, 22:457–479.
Mohamed Abdel Fattah and Fuji Ren. 2009. GA,
MR, FFNN, PNN and GMM based models for au-
tomatic text summarization. Computer Speech and
Language, 23(1):126–144.
Dimitrios Galanis, Gerasimos Lampouras, and Ion An-
droutsopoulos. 2012. Extractive multi-document
summarization with integer linear programming and
support vector regression. In Proceedings of the
24th International Conference on Computational
Linguistics, Mumbai, India, 8–15 December 2012,
pages 911–926.
</reference>
<page confidence="0.9951">
22
</page>
<note confidence="0.536779333333333">
Daniel Gillick, Korbinian Riedhammer, Benoit Favre,
and Dilek Hakkani-T¨ur. 2009. A global optimiza-
tion framework for meeting summarization. In Pro-
ceedings of the 2009 IEEE International Conference
on Acoustics, Speech, and Signal Processing, Taipei,
Taiwan, 19–24 June 2009, pages 4769–4772.
</note>
<reference confidence="0.999675523809524">
Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and
Mark Kantrowitz. 2000. Multi-document sum-
marization by sentence extraction. In Proceedings
of the Workshop on Automatic Summarization at
ANLP/NAACL 2000, Seattle, Wash., 30 April 2000,
pages 40–48.
Yihong Gong and Xin Liu. 2001. Generic text summa-
rization using relevance measure and latent semantic
analysis. In Proceedings of the 24th Annual Inter-
national ACM SIGIR Conference on Research and
Development in Information Retrieval New Orleans,
Louis., 9–12 September 2001, pages 19–25.
Camille Guinaudeau and Michael Strube. 2013.
Graph-based local coherence modeling. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics, Sofia, Bulgaria, 4–9
August 2013, pages 93–103.
Aria Haghighi and Lucy Vanderwende. 2009. Explor-
ing content models for multi-document summariza-
tion. In Proceedings of Human Language Technolo-
gies 2009: The Conference of the North American
Chapter of the Association for Computational Lin-
guistics, Boulder, Col., 31 May – 5 June 2009, pages
362–370.
Kai Hong and Ani Nenkova. 2014. Improving
the estimation of word importance for news multi-
document summarization. In Proceedings of the
14th Conference of the European Chapter of the
Association for Computational Linguistics, Gothen-
burg, Sweden, 26–30 April 2014, pages 712–721.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting of the Association for Com-
putational Linguistics, Sapporo, Japan, 7–12 July
2003, pages 423–430.
Jon M. Kleinberg. 1999. Authoritative sources in
a hyperlinked environment. Journal of the ACM,
46(5):604–632.
Chin-Yew Lin and Eduard Hovy. 2000. The auto-
mated acquisition of topic signatures for automatic
summarization. In Proceedings of the 18th Inter-
national Conference on Computational Linguistics,
Saarbr¨ucken, Germany, 31 July – 4 August 2000,
pages 495–501.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Proceedings of
the Text Summarization Branches Out Workshop at
ACL ’04, Barcelona, Spain, 25–26 July 2004, pages
74–81.
H.P. Luhn. 1958. The automatic creation of literature
abstracts. IBM Journal of Research and Develop-
ment, 2:159–165.
Sebastian Martschat. 2013. Multigraph clustering for
unsupervised coreference resolution. In Proceed-
ings of the Student Research Workshop at the 51st
Annual Meeting of the Association for Computa-
tional Linguistics, Sofia, Bulgaria, 5–7 August 2013,
pages 81–88.
Ryan McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Pro-
ceedings of the European Conference on Informa-
tion Retrieval, Rome, Italy, 2-5 April 2007.
Kathleen R. McKeown, Judith L. Klavans, Vassileios
Hatzivassiloglou, Regina Barzilay, and Eleazar Es-
kin. 1999. Towards multidocument summarization
by reformulation: Progress and prospects. In Pro-
ceedings of the 16th National Conference on Arti-
ficial Intelligence, Orlando, Flo., 18–22 July 1999,
pages 453–460.
Rada Mihalcea and Paul Tarau. 2004. TextRank:
Bringing order into texts. In Proceedings of the
2004 Conference on Empirical Methods in Natural
Language Processing, Barcelona, Spain, 25–26 July
2004, pages 404–411.
Rada Mihalcea. 2004. Graph-based ranking algo-
rithms for sentence extraction, applied to text sum-
marization. In Companion Volume to the Proceed-
ings of the 42nd Annual Meeting of the Association
for Computational Linguistics, Barcelona, Spain,
21–26 July 2004, pages 170–173.
Ani Nenkova and Lucy Vanderwende. 2005. The im-
pact of frequency on summarization. Technical Re-
port MSR-TR-2005-101, Microsoft Research.
Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Mat-
suo, and Genichiro Kikui. 2010. Opinion summa-
rization with integer linear programming formula-
tion for sentence extraction and ordering. In Pro-
ceedings of the 23rd International Conference on
Computational Linguistics, Beijing, China, 23–27
August 2010, pages 910–918.
Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, and
Zheng Chen. 2007. Document summarization us-
ing conditional random fields. In Proceedings of
the 20th International Joint Conference on Artificial
Intelligence, Hyderabad, India, 6–12 January 2007,
pages 2862–2867.
Yoshimi Suzuki and Fumiyo Fukumoto. 2014. De-
tection of topic and its extrinsic evaluation through
multi-document summarization. In Proceedings of
the ACL 2014 Conference Short Papers, Baltimore,
Md., 22–27 June 2014, pages 241–246.
Kristina Toutanova, Chris Brockett, Michael Gamon,
Jagadeesh Jagarlamudi, Hisami Suzuki, and Lucy
Vanderwende. 2007. The PYTHY summariza-
tion system: Microsoft Research at DUC 2007.
</reference>
<page confidence="0.970477">
23
</page>
<reference confidence="0.997192882352941">
In Proceedings of the 2007 Document Understand-
ing Conference held at the Human Language Tech-
nology Conference of the North American Chapter
of the Association for Computational Linguistics,
Rochester, N.Y., 26–27 April 2007.
Kristian Woodsend and Mirella Lapata. 2012. Mul-
tiple aspect summarization using integer linear pro-
gramming. In Proceedings of the 2012 Conference
on Empirical Methods in Natural Language Pro-
cessing and Natural Language Learning, Jeju Is-
land, Korea, 12–14 July 2012, pages 233–242.
Wen-tau Yih, Joshua Goodman, Lucy Vanderwende,
and Hisami Suzuki. 2007. Multi-document summa-
rization by maximizing informative content-words.
In Proceedings of the 20th International Joint Con-
ference on Artificial Intelligence, Hyderabad, India,
6–12 January 2007, pages 1776–1782.
</reference>
<page confidence="0.999163">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.161636">
<title confidence="0.99991">Multi-document Summarization Using Bipartite Graphs</title>
<author confidence="0.451959">Parveen</author>
<affiliation confidence="0.439523">Heidelberg Institute for Theoretical Studies Schloss-Wolfsbrunnenweg</affiliation>
<address confidence="0.992076">69118 Heidelberg,</address>
<email confidence="0.998925">(daraksha.parveen|michael.strube)@h-its.org</email>
<abstract confidence="0.970387461538461">In this paper, we introduce a novel graph based technique for topic based multidocument summarization. We transform documents into a bipartite graph where one set of nodes represents entities and the other set of nodes represents sentences. To obtain the summary we apply a ranking technique to the bipartite graph which is followed by an optimization step. We test the performance of our method on several DUC datasets and compare it to the stateof-the-art.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1999</date>
<booktitle>In Inderjeet Mani and</booktitle>
<pages>111--121</pages>
<editor>Mark T. Maybury, editors,</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="7557" citStr="Barzilay and Elhadad (1999)" startWordPosition="1157" endWordPosition="1161">e (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentence</context>
<context position="9581" citStr="Barzilay and Elhadad, 1999" startWordPosition="1465" endWordPosition="1468">ssive than a traditional tf-idf depiction for summarization. A graph can easily capture the essence of the whole text without leading to high computational complexity. Guinaudeau and Strube (2013) introduced a bipartite graph representation of text based on the entity grid (Barzilay and Lapata, 2008) representation of text. The projection of this bipartite graph representation has been used for calculating the local coherence of a text (Guinaudeau and Strube, 2013). The basic intuition to use a bipartite graph for summarization is that it contains entity transitions similar to lexical chains (Barzilay and Elhadad, 1999). An appropriate measure to determine the importance of sentences by considering strong entity transitions indicates the information central to a text better than simply giving scores on the basis of most frequent words. The unweighted bipartite graph G = (V3l Vel L) contains two sets of nodes, V3 corresponding to the sentences from the input text and Ve corresonding to the entities, and a set of edges represented by L. Figure 1 shows a model summary from the DUC 2006 data, which is transformed into an entity grid in Figure 2 (Barzilay and Lapata, 2008; Elsner and Charniak, 2011). Here, cells </context>
</contexts>
<marker>Barzilay, Elhadad, 1999</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1999. Using lexical chains for text summarization. In Inderjeet Mani and Mark T. Maybury, editors, Advances in Automatic Text Summarization, pages 111–121. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="9255" citStr="Barzilay and Lapata, 2008" startWordPosition="1414" endWordPosition="1417">sing the graphical representation of the text followed by a description how to quantify the importance of sentences in the input texts. We then discuss the ILP technique which optimizes the importance of sentences and redundancy. 3.1 Graphical representation of text The graphical representation of a text makes it more expressive than a traditional tf-idf depiction for summarization. A graph can easily capture the essence of the whole text without leading to high computational complexity. Guinaudeau and Strube (2013) introduced a bipartite graph representation of text based on the entity grid (Barzilay and Lapata, 2008) representation of text. The projection of this bipartite graph representation has been used for calculating the local coherence of a text (Guinaudeau and Strube, 2013). The basic intuition to use a bipartite graph for summarization is that it contains entity transitions similar to lexical chains (Barzilay and Elhadad, 1999). An appropriate measure to determine the importance of sentences by considering strong entity transitions indicates the information central to a text better than simply giving scores on the basis of most frequent words. The unweighted bipartite graph G = (V3l Vel L) contai</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Gillick</author>
<author>Dan Klein</author>
</authors>
<title>Jointly learning to extract and compress.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>481--490</pages>
<location>Portland, Oreg.,</location>
<contexts>
<context position="8287" citStr="Berg-Kirkpatrick et al. (2011)" startWordPosition="1267" endWordPosition="1270">oach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentences and minimizes the similarity of sentences. ILP methods for optimization have also been adopted by Berg-Kirkpatrick et al. (2011),Woodsend and Lapata (2012) and Galanis et al. (2012). Until now, Galanis et al. (2012) have reported the highest scores for multi-document summarization on DUC2005 and DUC2007. However, their approach is not completely unsupervised. 16 3 Our method This section describes the technique, which we adopted for summarization. We start by discussing the graphical representation of the text followed by a description how to quantify the importance of sentences in the input texts. We then discuss the ILP technique which optimizes the importance of sentences and redundancy. 3.1 Graphical representation</context>
</contexts>
<marker>Berg-Kirkpatrick, Gillick, Klein, 2011</marker>
<rawString>Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein. 2011. Jointly learning to extract and compress. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, Portland, Oreg., 19–24 June 2011, pages 481–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual web search engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>30--1</pages>
<contexts>
<context position="4773" citStr="Brin and Page, 1998" startWordPosition="724" endWordPosition="727"> in the final summary is dealt with entities in a graph. In Section 2 we introduce the state-of-the-art in topic based multi-document summarizaton. Section 3 provides a detailed description of our approach. Experiments are described in Section 4 where we also briefly describe the datasets used and the results. Section 5 discusses the results of our approach, and in Section 6 we finally give conclusions. 2 Related work A graph-based representation of documents for summarization is adopted by various approaches. For instance, TextRank by Mihalcea and Tarau (2004) applies the PageRank algorithm (Brin and Page, 1998) to extract important sentences for single document summarization. This ranking algorithm proclaims the importance of a sentence by considering the global information which is computed recursively from the entire graph. Later, the graph is converted into a weighted graph in which the weights are calculated by measuring the similarity of sentences (Mihalcea, 2004). Similarly, in the LexRank approach (Erkan and Radev, 2004), documents are represented as a similarity graph in which the sentences are nodes and these sentences are then ranked according to centrality measures. The three centrality m</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 30(1–7):107–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>335--336</pages>
<location>Melbourne, Australia, 24–28</location>
<contexts>
<context position="2954" citStr="Carbonell and Goldstein (1998)" startWordPosition="444" endWordPosition="447"> output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the topic and at the same time most dissimilar to already extracted sentences. Later more fundamental optimization methods have been widely used in multi-document summarization, e.g. Integer Linear Programming (ILP) (McDonald, 2007; Gillick et al., 2009; Nishikawa et al., 2010; Galanis et al., 2012). Unlike most other approaches (Galanis et al., 2012) has also taken into acco</context>
<context position="6980" citStr="Carbonell and Goldstein (1998)" startWordPosition="1062" endWordPosition="1065">ect appropriate weights for the features and used different classification technique for e.g. feed forward neural network, probablistic neural network and Gaussian mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences whic</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime G. Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, Melbourne, Australia, 24–28 August 1998, pages 335–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>A hybrid hierarchical model for multi-document summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>815--824</pages>
<location>Uppsala,</location>
<marker>Celikyilmaz, Hakkani-T¨ur, 2010</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2010. A hybrid hierarchical model for multi-document summarization. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, 11–16 July 2010, pages 815– 824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of DUC</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 Document Understanding Conference held at the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Vancouver, B.C.,</location>
<contexts>
<context position="16920" citStr="Dang, 2005" startWordPosition="2787" endWordPosition="2788">ed. X xi &gt; yj, forj = 1, ... , m (6) iESj In constraint 6, Sj is a set of sentences containing entity yj. This constraint shows that, if an entity yj is selected then at least one sentence is selected which contains it (yj = 1, P xi &gt; 1). If an entity yj is not selected, then it is possible that none of the sentences which contain it may not be selected (yj = 0, P xi = 0). Also, constraint 4 holds in either of the cases. 4 Experiments We perform experiments on various DUC datasets to compare the results with state-of-the-art systems. 4.1 Datasets Datasets used for our experiments are DUC2005 (Dang, 2005), DUC2006 (Dang, 2006) and DUC20071 . Each dataset contains group of related documents. Each group of documents contains one related topic or a query consisting of a few sentences. In DUC, the final summary should respond to the corresponding topic. Also, the summary cannot exceed the maximum allowed length. For instance, in DUC2005, 250 words are allowed in the final summary. Every document cluster has corresponding human summaries for evaluating system summaries on the basis of ROUGE scores (Lin, 2004). The sources of DUC datasets are Los Angeles Times, Financial Times of London, Associated </context>
</contexts>
<marker>Dang, 2005</marker>
<rawString>Hoa Trang Dang. 2005. Overview of DUC 2005. In Proceedings of the 2005 Document Understanding Conference held at the Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Vancouver, B.C., Canada, 9–10 October 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of DUC</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>New York, N.Y., 8–9</location>
<contexts>
<context position="16942" citStr="Dang, 2006" startWordPosition="2790" endWordPosition="2791">1, ... , m (6) iESj In constraint 6, Sj is a set of sentences containing entity yj. This constraint shows that, if an entity yj is selected then at least one sentence is selected which contains it (yj = 1, P xi &gt; 1). If an entity yj is not selected, then it is possible that none of the sentences which contain it may not be selected (yj = 0, P xi = 0). Also, constraint 4 holds in either of the cases. 4 Experiments We perform experiments on various DUC datasets to compare the results with state-of-the-art systems. 4.1 Datasets Datasets used for our experiments are DUC2005 (Dang, 2005), DUC2006 (Dang, 2006) and DUC20071 . Each dataset contains group of related documents. Each group of documents contains one related topic or a query consisting of a few sentences. In DUC, the final summary should respond to the corresponding topic. Also, the summary cannot exceed the maximum allowed length. For instance, in DUC2005, 250 words are allowed in the final summary. Every document cluster has corresponding human summaries for evaluating system summaries on the basis of ROUGE scores (Lin, 2004). The sources of DUC datasets are Los Angeles Times, Financial Times of London, Associated Press, New York Times </context>
</contexts>
<marker>Dang, 2006</marker>
<rawString>Hoa Trang Dang. 2006. Overview of DUC 2006. In Proceedings of the 2006 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, New York, N.Y., 8–9 June 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Eugene Charniak</author>
</authors>
<title>Extending the entity grid with entity-specific features.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL 2011 Conference Short Papers,</booktitle>
<pages>125--129</pages>
<location>Portland, Oreg.,</location>
<contexts>
<context position="10167" citStr="Elsner and Charniak, 2011" startWordPosition="1567" endWordPosition="1570">ical chains (Barzilay and Elhadad, 1999). An appropriate measure to determine the importance of sentences by considering strong entity transitions indicates the information central to a text better than simply giving scores on the basis of most frequent words. The unweighted bipartite graph G = (V3l Vel L) contains two sets of nodes, V3 corresponding to the sentences from the input text and Ve corresonding to the entities, and a set of edges represented by L. Figure 1 shows a model summary from the DUC 2006 data, which is transformed into an entity grid in Figure 2 (Barzilay and Lapata, 2008; Elsner and Charniak, 2011). Here, cells are filled with the syntactic role a mention of an entity occupies in a sentence. Subjects are denoted by S, objects by O and all other roles by X. If an entity is not mentioned in a sentence then the corresponding cell contains “-”. In the corresponding bipartite graph (Figure 3), edges are created between a sentence and an entity only if the entity is mentioned in a sentence (the cell in entity grid is not “-”). Since this is a dyadic graph, there are no edges between nodes of the same set. 3.2 Ranking the importance of sentences A graph based ranking algorithm is used to calcu</context>
<context position="18607" citStr="Elsner and Charniak, 2011" startWordPosition="3075" endWordPosition="3078">rom the various DUC datasets as input for our system. We remove nonalphabetical characters from the documents. Then we obtain a clean sentence split by means of the Stanford parser (Klein and Manning, 2003) so that the sentences are compatible with the next steps. 1http://www-nlpir.nist.gov/projects/ duc/index.html 19 ROUGE-2 ROUGE-SU4 A1 = 0.5 &amp; A2 = 0.5 0.07950 0.14060 A1 = 0.6 &amp; A2 = 0.4 0.07956 0.14071 A1 = 0.7 &amp; A2 = 0.3 0.07975 0.14105 A1 = 0.8 &amp; A2 = 0.2 0.07976 0.14106 A1 = 0.9 &amp; A2 = 0.1 0.07985 0.14107 Table 2: Results on different A’s on DUC 2005 We use the Brown coherence toolkit (Elsner and Charniak, 2011) to convert the documents into the entity grid representation from which the bipartite graph is constructed (Guinaudeau and Strube, 2013). Entities in the graph correspond to head nouns of noun phrase mentioned in the sentences. The ranking algorithm from Section 3.2 is applied to this graph and returns the importance score of a sentence as required by the objective function given in Equation 3. Next optimization using ILP is performed as described in Section 3.3. We use GUROBI Optimizer2for performing ILP. ILP returns a binary value, i.e., if a sentence should be included in the summary it re</context>
</contexts>
<marker>Elsner, Charniak, 2011</marker>
<rawString>Micha Elsner and Eugene Charniak. 2011. Extending the entity grid with entity-specific features. In Proceedings of the ACL 2011 Conference Short Papers, Portland, Oreg., 19–24 June 2011, pages 125–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>22--457</pages>
<contexts>
<context position="2458" citStr="Erkan and Radev, 2004" startWordPosition="370" endWordPosition="373">elevance: A summary should contain only those textual units which are relevant to the topic and provide useful information. 2. Non-redundancy: A summary should not contain the same information twice. 3. Readability: A summary should have good readability (syntactically well formed, no dangling pronouns, coherent,...). Generally, multi-document summarization systems differ from each other on the basis of document representation, sentence selection method or on the requirements for the output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic,</context>
<context position="5198" citStr="Erkan and Radev, 2004" startWordPosition="790" endWordPosition="793"> graph-based representation of documents for summarization is adopted by various approaches. For instance, TextRank by Mihalcea and Tarau (2004) applies the PageRank algorithm (Brin and Page, 1998) to extract important sentences for single document summarization. This ranking algorithm proclaims the importance of a sentence by considering the global information which is computed recursively from the entire graph. Later, the graph is converted into a weighted graph in which the weights are calculated by measuring the similarity of sentences (Mihalcea, 2004). Similarly, in the LexRank approach (Erkan and Radev, 2004), documents are represented as a similarity graph in which the sentences are nodes and these sentences are then ranked according to centrality measures. The three centrality measures used are degree, LexRank with threshold and continuous LexRank. LexRank is a measure to calculate ranks using the similarity graph of sentences. It is also known as lexical PageRank. The summarization approach developed by Gong and Liu (2001) is also based on ranking sentences where important sentences are selected using a relevance measure and latent semantic analysis. Later, for better performance, sentences are</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research, 22:457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Abdel Fattah</author>
<author>Fuji Ren</author>
</authors>
<title>PNN and GMM based models for automatic text summarization.</title>
<date>2009</date>
<journal>Computer Speech and Language,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="6220" citStr="Fattah and Ren (2009)" startWordPosition="950" endWordPosition="953">d by Gong and Liu (2001) is also based on ranking sentences where important sentences are selected using a relevance measure and latent semantic analysis. Later, for better performance, sentences are classified according to their existence in their final summary in binary format i.e. 1 (belongs to summary) and 0 (doesn’t belong to summary) (Shen et al., 2007; Gong and Liu, 2001). Here, the sentences are projected as feature vectors and conditional random fields are used to classify them. During document processing, most informative sentences are selected by the summarizer (Shen et al., 2007). Fattah and Ren (2009) also considers summarization as two class classification problem. They use a genetic algorithm and mathematical regression to select appropriate weights for the features and used different classification technique for e.g. feed forward neural network, probablistic neural network and Gaussian mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For </context>
</contexts>
<marker>Fattah, Ren, 2009</marker>
<rawString>Mohamed Abdel Fattah and Fuji Ren. 2009. GA, MR, FFNN, PNN and GMM based models for automatic text summarization. Computer Speech and Language, 23(1):126–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitrios Galanis</author>
<author>Gerasimos Lampouras</author>
<author>Ion Androutsopoulos</author>
</authors>
<title>Extractive multi-document summarization with integer linear programming and support vector regression.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics,</booktitle>
<pages>911--926</pages>
<location>Mumbai,</location>
<contexts>
<context position="1141" citStr="Galanis et al., 2012" startWordPosition="168" endWordPosition="171">anking technique to the bipartite graph which is followed by an optimization step. We test the performance of our method on several DUC datasets and compare it to the stateof-the-art. 1 Introduction Topic-based multi-document summarization aims to create a single summary from a set of given documents while considering the topic of interest. The input documents can be created by querying an information retrieval or search engine for a particular topic and retaining highly ranked documents, or by clustering documents of a large collection and then using each cluster as a set of input documents (Galanis et al., 2012). Here, each cluster of the set of documents contains a representative topic. A summary extracted from a set of input documents must be related to the topic of that set. If textual units (or sentences) extracted from different documents convey the same information, then those units are called redundant. Ideally, the multi-document summary should be nonredundant. Hence each textual unit in a summary should convey unique information. Still, all extracted textual units should be related to the topic. They should also make up a coherent summary. When building summaries from multiple documents belo</context>
<context position="3476" citStr="Galanis et al., 2012" startWordPosition="527" endWordPosition="531">nt way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the topic and at the same time most dissimilar to already extracted sentences. Later more fundamental optimization methods have been widely used in multi-document summarization, e.g. Integer Linear Programming (ILP) (McDonald, 2007; Gillick et al., 2009; Nishikawa et al., 2010; Galanis et al., 2012). Unlike most other approaches (Galanis et al., 2012) has also taken into account the readability of the final summary. In this work, we introduce an extractive topic based multi-document summarization system which represents documents graphically and 15 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 15–24, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics optimizes the importance of sentences and nonredundancy. The importance of sentences is obtained by means of applying the Hubs and Authorities ranking alg</context>
<context position="8340" citStr="Galanis et al. (2012)" startWordPosition="1275" endWordPosition="1278">nce, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentences and minimizes the similarity of sentences. ILP methods for optimization have also been adopted by Berg-Kirkpatrick et al. (2011),Woodsend and Lapata (2012) and Galanis et al. (2012). Until now, Galanis et al. (2012) have reported the highest scores for multi-document summarization on DUC2005 and DUC2007. However, their approach is not completely unsupervised. 16 3 Our method This section describes the technique, which we adopted for summarization. We start by discussing the graphical representation of the text followed by a description how to quantify the importance of sentences in the input texts. We then discuss the ILP technique which optimizes the importance of sentences and redundancy. 3.1 Graphical representation of text The graphical representation of a text makes</context>
<context position="23468" citStr="Galanis et al. (2012)" startWordPosition="3919" endWordPosition="3922"> I’ve started to use irrigation hoses called “leaky pipe”. 52 Soil’s usually best to water the target area a few days before I plan to dig. 53 If I don’t place element in the root zone, element can’t be added later when the plants are growing. 54 The new composts were much lighter and more suitable for container plants in garden centres and through these were rapidly introduced to gardeners. Figure 5: Sentences containing dangling first person pronoun from DUC 2005 the-art systems, and our system is giving competitive results in both ROUGE-2 and ROUGE-SU4 scores. However, the ROUGE-2 score of Galanis et al. (2012) on DUC 2005 is slightly better than our score. This might be because they use bigram information for redundancy reduction. However, they need training data for sentence importance. Hence their system has to be classified as supervised while ours is unsupervised. We have also calculated the ROUGE-1 score on DUC 2007 and compared it with state-ofthe-art approaches. HybHsum (Celikyilmaz and Hakkani-T¨ur, 2010) has obtained the top ROUGE1 score on DUC 2007 with 0.456. However, HybHsum is a semi-supervised approach which requires a labeled training data. The difference between our ROUGE-1 score of</context>
</contexts>
<marker>Galanis, Lampouras, Androutsopoulos, 2012</marker>
<rawString>Dimitrios Galanis, Gerasimos Lampouras, and Ion Androutsopoulos. 2012. Extractive multi-document summarization with integer linear programming and support vector regression. In Proceedings of the 24th International Conference on Computational Linguistics, Mumbai, India, 8–15 December 2012, pages 911–926.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jade Goldstein</author>
<author>Vibhu Mittal</author>
<author>Jaime Carbonell</author>
<author>Mark Kantrowitz</author>
</authors>
<title>Multi-document summarization by sentence extraction.</title>
<date>2000</date>
<booktitle>In Proceedings of the Workshop on Automatic Summarization at ANLP/NAACL 2000,</booktitle>
<pages>40--48</pages>
<location>Seattle, Wash.,</location>
<contexts>
<context position="2607" citStr="Goldstein et al., 2000" startWordPosition="391" endWordPosition="394">mary should not contain the same information twice. 3. Readability: A summary should have good readability (syntactically well formed, no dangling pronouns, coherent,...). Generally, multi-document summarization systems differ from each other on the basis of document representation, sentence selection method or on the requirements for the output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the topic and at the same time </context>
<context position="6853" citStr="Goldstein et al. (2000)" startWordPosition="1042" endWordPosition="1045">iders summarization as two class classification problem. They use a genetic algorithm and mathematical regression to select appropriate weights for the features and used different classification technique for e.g. feed forward neural network, probablistic neural network and Gaussian mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised mo</context>
</contexts>
<marker>Goldstein, Mittal, Carbonell, Kantrowitz, 2000</marker>
<rawString>Jade Goldstein, Vibhu Mittal, Jaime Carbonell, and Mark Kantrowitz. 2000. Multi-document summarization by sentence extraction. In Proceedings of the Workshop on Automatic Summarization at ANLP/NAACL 2000, Seattle, Wash., 30 April 2000, pages 40–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yihong Gong</author>
<author>Xin Liu</author>
</authors>
<title>Generic text summarization using relevance measure and latent semantic analysis.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</booktitle>
<pages>pages</pages>
<location>New Orleans, Louis., 9–12</location>
<contexts>
<context position="5623" citStr="Gong and Liu (2001)" startWordPosition="855" endWordPosition="858">graph is converted into a weighted graph in which the weights are calculated by measuring the similarity of sentences (Mihalcea, 2004). Similarly, in the LexRank approach (Erkan and Radev, 2004), documents are represented as a similarity graph in which the sentences are nodes and these sentences are then ranked according to centrality measures. The three centrality measures used are degree, LexRank with threshold and continuous LexRank. LexRank is a measure to calculate ranks using the similarity graph of sentences. It is also known as lexical PageRank. The summarization approach developed by Gong and Liu (2001) is also based on ranking sentences where important sentences are selected using a relevance measure and latent semantic analysis. Later, for better performance, sentences are classified according to their existence in their final summary in binary format i.e. 1 (belongs to summary) and 0 (doesn’t belong to summary) (Shen et al., 2007; Gong and Liu, 2001). Here, the sentences are projected as feature vectors and conditional random fields are used to classify them. During document processing, most informative sentences are selected by the summarizer (Shen et al., 2007). Fattah and Ren (2009) al</context>
</contexts>
<marker>Gong, Liu, 2001</marker>
<rawString>Yihong Gong and Xin Liu. 2001. Generic text summarization using relevance measure and latent semantic analysis. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval New Orleans, Louis., 9–12 September 2001, pages 19–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Camille Guinaudeau</author>
<author>Michael Strube</author>
</authors>
<title>Graph-based local coherence modeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>93--103</pages>
<location>Sofia, Bulgaria, 4–9</location>
<contexts>
<context position="9150" citStr="Guinaudeau and Strube (2013)" startWordPosition="1397" endWordPosition="1400">6 3 Our method This section describes the technique, which we adopted for summarization. We start by discussing the graphical representation of the text followed by a description how to quantify the importance of sentences in the input texts. We then discuss the ILP technique which optimizes the importance of sentences and redundancy. 3.1 Graphical representation of text The graphical representation of a text makes it more expressive than a traditional tf-idf depiction for summarization. A graph can easily capture the essence of the whole text without leading to high computational complexity. Guinaudeau and Strube (2013) introduced a bipartite graph representation of text based on the entity grid (Barzilay and Lapata, 2008) representation of text. The projection of this bipartite graph representation has been used for calculating the local coherence of a text (Guinaudeau and Strube, 2013). The basic intuition to use a bipartite graph for summarization is that it contains entity transitions similar to lexical chains (Barzilay and Elhadad, 1999). An appropriate measure to determine the importance of sentences by considering strong entity transitions indicates the information central to a text better than simply</context>
<context position="18744" citStr="Guinaudeau and Strube, 2013" startWordPosition="3096" endWordPosition="3099">entence split by means of the Stanford parser (Klein and Manning, 2003) so that the sentences are compatible with the next steps. 1http://www-nlpir.nist.gov/projects/ duc/index.html 19 ROUGE-2 ROUGE-SU4 A1 = 0.5 &amp; A2 = 0.5 0.07950 0.14060 A1 = 0.6 &amp; A2 = 0.4 0.07956 0.14071 A1 = 0.7 &amp; A2 = 0.3 0.07975 0.14105 A1 = 0.8 &amp; A2 = 0.2 0.07976 0.14106 A1 = 0.9 &amp; A2 = 0.1 0.07985 0.14107 Table 2: Results on different A’s on DUC 2005 We use the Brown coherence toolkit (Elsner and Charniak, 2011) to convert the documents into the entity grid representation from which the bipartite graph is constructed (Guinaudeau and Strube, 2013). Entities in the graph correspond to head nouns of noun phrase mentioned in the sentences. The ranking algorithm from Section 3.2 is applied to this graph and returns the importance score of a sentence as required by the objective function given in Equation 3. Next optimization using ILP is performed as described in Section 3.3. We use GUROBI Optimizer2for performing ILP. ILP returns a binary value, i.e., if a sentence should be included in the summary it returns 1, if not it returns 0. We set A1 = 0.7 and A2 = 0.3 for all datasets. We did not choose the optimal values, but rather opted for o</context>
</contexts>
<marker>Guinaudeau, Strube, 2013</marker>
<rawString>Camille Guinaudeau and Michael Strube. 2013. Graph-based local coherence modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, 4–9 August 2013, pages 93–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Exploring content models for multi-document summarization.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5</booktitle>
<pages>362--370</pages>
<contexts>
<context position="21260" citStr="Haghighi and Vanderwende (2009)" startWordPosition="3533" endWordPosition="3536">0.16735 (5) Table 3: System performance (and rank) on the DUC 2005, 2006 and 2007 (main) data. The number in parenthesis after the DUC year indicates the number of competing systems. (2012) report the best results on DUC 2005 data. While their ROUGE-2 score is slightly better than ours, we outperform them in terms of ROUGESU4 (0.14105 vs. 0.13640), where, to our knowledge, our results are the highest reported so far. However, their results on DUC 2007 (ROUGE-2 0.12517 and ROUGE-SU4 0.17603) are still quite a bit better than our results. On the DUC 2006 data we outperform the HIERSUM system by Haghighi and Vanderwende (2009) on ROUGE2 (0.08969 vs. 0.086) as well as on ROUGESU4 (0.15070 vs. 0.143). On the DUC 2007 data, our results are worse than theirs on ROUGE2 (0.10928 vs. 0.118) and on par on ROUGESU4 (0.16735 vs. 0.167). The system which won the DUC 2007 task, PYTHY by Toutanova et al. (2007), performs similar to HIERSUM and hence slightly better than our system on these data. The recent work by Suzuki and Fukumoto (2014) evaluates also on DUC 2007 but reports only ROUGE1 scores. We obtain a ROUGE-1 score of 0.448 on DUC 2007 which is better than Suzuki and Fukumoto (2014) (0.438) as well as PYTHY (0.426). Th</context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Aria Haghighi and Lucy Vanderwende. 2009. Exploring content models for multi-document summarization. In Proceedings of Human Language Technologies 2009: The Conference of the North American Chapter of the Association for Computational Linguistics, Boulder, Col., 31 May – 5 June 2009, pages 362–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Hong</author>
<author>Ani Nenkova</author>
</authors>
<title>Improving the estimation of word importance for news multidocument summarization.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>712--721</pages>
<location>Gothenburg,</location>
<contexts>
<context position="7519" citStr="Hong and Nenkova, 2014" startWordPosition="1152" endWordPosition="1155">d by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function whic</context>
</contexts>
<marker>Hong, Nenkova, 2014</marker>
<rawString>Kai Hong and Ani Nenkova. 2014. Improving the estimation of word importance for news multidocument summarization. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, Gothenburg, Sweden, 26–30 April 2014, pages 712–721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<location>Sapporo,</location>
<contexts>
<context position="18187" citStr="Klein and Manning, 2003" startWordPosition="2996" endWordPosition="2999">y. We employ ROUGE SU4 and ROUGE 2 as evaluation metrics. ROUGE returns recall, precision and F-score of a system, but usually only recall is used in for evaluating automatic summarization systems, because the final summary does not contain many words. Hence, if the recall is high then the summarization system is working well. Document statistics is provided in Table 1. 4.2 Experimental setup We use raw documents from the various DUC datasets as input for our system. We remove nonalphabetical characters from the documents. Then we obtain a clean sentence split by means of the Stanford parser (Klein and Manning, 2003) so that the sentences are compatible with the next steps. 1http://www-nlpir.nist.gov/projects/ duc/index.html 19 ROUGE-2 ROUGE-SU4 A1 = 0.5 &amp; A2 = 0.5 0.07950 0.14060 A1 = 0.6 &amp; A2 = 0.4 0.07956 0.14071 A1 = 0.7 &amp; A2 = 0.3 0.07975 0.14105 A1 = 0.8 &amp; A2 = 0.2 0.07976 0.14106 A1 = 0.9 &amp; A2 = 0.1 0.07985 0.14107 Table 2: Results on different A’s on DUC 2005 We use the Brown coherence toolkit (Elsner and Charniak, 2011) to convert the documents into the entity grid representation from which the bipartite graph is constructed (Guinaudeau and Strube, 2013). Entities in the graph correspond to head </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan, 7–12 July 2003, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="4100" citStr="Kleinberg, 1999" startWordPosition="620" endWordPosition="621"> most other approaches (Galanis et al., 2012) has also taken into account the readability of the final summary. In this work, we introduce an extractive topic based multi-document summarization system which represents documents graphically and 15 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 15–24, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics optimizes the importance of sentences and nonredundancy. The importance of sentences is obtained by means of applying the Hubs and Authorities ranking algorithm (Kleinberg, 1999) on the unweighted bipartite graph whereas redundancy in the final summary is dealt with entities in a graph. In Section 2 we introduce the state-of-the-art in topic based multi-document summarizaton. Section 3 provides a detailed description of our approach. Experiments are described in Section 4 where we also briefly describe the datasets used and the results. Section 5 discusses the results of our approach, and in Section 6 we finally give conclusions. 2 Related work A graph-based representation of documents for summarization is adopted by various approaches. For instance, TextRank by Mihal</context>
<context position="11114" citStr="Kleinberg (1999)" startWordPosition="1736" endWordPosition="1737">ce and an entity only if the entity is mentioned in a sentence (the cell in entity grid is not “-”). Since this is a dyadic graph, there are no edges between nodes of the same set. 3.2 Ranking the importance of sentences A graph based ranking algorithm is used to calculate the importance of a sentence represented as a node in the graph discussed above. In contrast to the local information specific to a vertex, graphical ranking algorithms take (graph-) global information to calculate the rank of a node. The Hyperlink-Induced Topic Search algorithm (HITS, also known as Hubs and Authorities) by Kleinberg (1999) is used to rank sentences in our method. This algorithm considers two types of nodes, hence it is well suited to rank sentences in our bipartite graph. Entities are considered as hub nodes, and sentences are considered as authority nodes. The importance of a sentence is calculated in two steps: • Hub update rule: Update each node’s hub score to be equal to the sum of the authority scores of each node that it points to. It can be written as: Hub5core = A • Authority5core (1) Here, A is an adjacency matrix which represents the connection between the nodes in a graph. • Authority update rule: In</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>The automated acquisition of topic signatures for automatic summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany, 31 July – 4</booktitle>
<pages>495--501</pages>
<contexts>
<context position="7356" citStr="Lin and Hovy (2000)" startWordPosition="1124" endWordPosition="1127">approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information where</context>
</contexts>
<marker>Lin, Hovy, 2000</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2000. The automated acquisition of topic signatures for automatic summarization. In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany, 31 July – 4 August 2000, pages 495–501.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Proceedings of the Text Summarization Branches Out Workshop at ACL ’04,</booktitle>
<pages>74--81</pages>
<location>Barcelona,</location>
<contexts>
<context position="17429" citStr="Lin, 2004" startWordPosition="2870" endWordPosition="2871">ith state-of-the-art systems. 4.1 Datasets Datasets used for our experiments are DUC2005 (Dang, 2005), DUC2006 (Dang, 2006) and DUC20071 . Each dataset contains group of related documents. Each group of documents contains one related topic or a query consisting of a few sentences. In DUC, the final summary should respond to the corresponding topic. Also, the summary cannot exceed the maximum allowed length. For instance, in DUC2005, 250 words are allowed in the final summary. Every document cluster has corresponding human summaries for evaluating system summaries on the basis of ROUGE scores (Lin, 2004). The sources of DUC datasets are Los Angeles Times, Financial Times of London, Associated Press, New York Times and Xinhua news agency. We employ ROUGE SU4 and ROUGE 2 as evaluation metrics. ROUGE returns recall, precision and F-score of a system, but usually only recall is used in for evaluating automatic summarization systems, because the final summary does not contain many words. Hence, if the recall is high then the summarization system is working well. Document statistics is provided in Table 1. 4.2 Experimental setup We use raw documents from the various DUC datasets as input for our sy</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Proceedings of the Text Summarization Branches Out Workshop at ACL ’04, Barcelona, Spain, 25–26 July 2004, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Luhn</author>
</authors>
<title>The automatic creation of literature abstracts.</title>
<date>1958</date>
<journal>IBM Journal of Research and Development,</journal>
<pages>2--159</pages>
<contexts>
<context position="2551" citStr="Luhn, 1958" startWordPosition="385" endWordPosition="386">seful information. 2. Non-redundancy: A summary should not contain the same information twice. 3. Readability: A summary should have good readability (syntactically well formed, no dangling pronouns, coherent,...). Generally, multi-document summarization systems differ from each other on the basis of document representation, sentence selection method or on the requirements for the output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentenc</context>
</contexts>
<marker>Luhn, 1958</marker>
<rawString>H.P. Luhn. 1958. The automatic creation of literature abstracts. IBM Journal of Research and Development, 2:159–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Martschat</author>
</authors>
<title>Multigraph clustering for unsupervised coreference resolution.</title>
<date>2013</date>
<booktitle>In Proceedings of the Student Research Workshop at the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>81--88</pages>
<location>Sofia, Bulgaria, 5–7</location>
<contexts>
<context position="19724" citStr="Martschat (2013)" startWordPosition="3269" endWordPosition="3270">orming ILP. ILP returns a binary value, i.e., if a sentence should be included in the summary it returns 1, if not it returns 0. We set A1 = 0.7 and A2 = 0.3 for all datasets. We did not choose the optimal values, but rather opted for ones which favor importance over non-redundancy. We did not observe significant differences between different A values as long as A1 &gt; A2 (see Table 2). The sentences in the output summary are ordered according to their ranks. If the output summary contains pronouns, we perform pronoun resolution in the source documents using the coreference resolution system by Martschat (2013). If pronoun and antecedent occur in the same sentence, we leave the pronoun. If the antecedent occurs in an earlier sentence, we replace the pronoun in the summary by the first element of the coreference chain the pronoun belongs to. Except for setting A1 and A2 on DUC 2005, our approach is unsupervised, as there is no traning data required. The recall (ROUGE) scores on different datasets are shown in Table 3. Table 3 shows that our system would have performed very well in the DUC 2005 and DUC 2006 competitions with ranks in the top 3 and well in the DUC 2007 competition. Since the competitio</context>
</contexts>
<marker>Martschat, 2013</marker>
<rawString>Sebastian Martschat. 2013. Multigraph clustering for unsupervised coreference resolution. In Proceedings of the Student Research Workshop at the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, 5–7 August 2013, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>A study of global inference algorithms in multi-document summarization.</title>
<date>2007</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval,</booktitle>
<location>Rome,</location>
<contexts>
<context position="3407" citStr="McDonald, 2007" startWordPosition="517" endWordPosition="518">arizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the topic and at the same time most dissimilar to already extracted sentences. Later more fundamental optimization methods have been widely used in multi-document summarization, e.g. Integer Linear Programming (ILP) (McDonald, 2007; Gillick et al., 2009; Nishikawa et al., 2010; Galanis et al., 2012). Unlike most other approaches (Galanis et al., 2012) has also taken into account the readability of the final summary. In this work, we introduce an extractive topic based multi-document summarization system which represents documents graphically and 15 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 15–24, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics optimizes the importance of sentences and nonredundancy. The importance of sentences </context>
<context position="8009" citStr="McDonald (2007)" startWordPosition="1228" endWordPosition="1229">ch identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentences and minimizes the similarity of sentences. ILP methods for optimization have also been adopted by Berg-Kirkpatrick et al. (2011),Woodsend and Lapata (2012) and Galanis et al. (2012). Until now, Galanis et al. (2012) have reported the highest scores for multi-document summarization on DUC2005 and DUC2007. However, their approach is not completely unsupervised. 16 3 Our method This section describes the technique, which we adopted for summarization</context>
</contexts>
<marker>McDonald, 2007</marker>
<rawString>Ryan McDonald. 2007. A study of global inference algorithms in multi-document summarization. In Proceedings of the European Conference on Information Retrieval, Rome, Italy, 2-5 April 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
<author>Judith L Klavans</author>
<author>Vassileios Hatzivassiloglou</author>
<author>Regina Barzilay</author>
<author>Eleazar Eskin</author>
</authors>
<title>Towards multidocument summarization by reformulation: Progress and prospects.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th National Conference on Artificial Intelligence,</booktitle>
<pages>453--460</pages>
<location>Orlando, Flo.,</location>
<contexts>
<context position="7745" citStr="McKeown et al. (1999)" startWordPosition="1186" endWordPosition="1189">ped a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentences and minimizes the similarity of sentences. ILP methods for optimization have also been adopted by Berg-Kirkpatrick et al. (2011),Woodsend and Lapata (2012) and Galanis et al. (2012). Unt</context>
</contexts>
<marker>McKeown, Klavans, Hatzivassiloglou, Barzilay, Eskin, 1999</marker>
<rawString>Kathleen R. McKeown, Judith L. Klavans, Vassileios Hatzivassiloglou, Regina Barzilay, and Eleazar Eskin. 1999. Towards multidocument summarization by reformulation: Progress and prospects. In Proceedings of the 16th National Conference on Artificial Intelligence, Orlando, Flo., 18–22 July 1999, pages 453–460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>404--411</pages>
<location>Barcelona,</location>
<contexts>
<context position="2498" citStr="Mihalcea and Tarau, 2004" startWordPosition="376" endWordPosition="380">ly those textual units which are relevant to the topic and provide useful information. 2. Non-redundancy: A summary should not contain the same information twice. 3. Readability: A summary should have good readability (syntactically well formed, no dangling pronouns, coherent,...). Generally, multi-document summarization systems differ from each other on the basis of document representation, sentence selection method or on the requirements for the output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant s</context>
<context position="4720" citStr="Mihalcea and Tarau (2004)" startWordPosition="716" endWordPosition="719">1999) on the unweighted bipartite graph whereas redundancy in the final summary is dealt with entities in a graph. In Section 2 we introduce the state-of-the-art in topic based multi-document summarizaton. Section 3 provides a detailed description of our approach. Experiments are described in Section 4 where we also briefly describe the datasets used and the results. Section 5 discusses the results of our approach, and in Section 6 we finally give conclusions. 2 Related work A graph-based representation of documents for summarization is adopted by various approaches. For instance, TextRank by Mihalcea and Tarau (2004) applies the PageRank algorithm (Brin and Page, 1998) to extract important sentences for single document summarization. This ranking algorithm proclaims the importance of a sentence by considering the global information which is computed recursively from the entire graph. Later, the graph is converted into a weighted graph in which the weights are calculated by measuring the similarity of sentences (Mihalcea, 2004). Similarly, in the LexRank approach (Erkan and Radev, 2004), documents are represented as a similarity graph in which the sentences are nodes and these sentences are then ranked acc</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing order into texts. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain, 25–26 July 2004, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
</authors>
<title>Graph-based ranking algorithms for sentence extraction, applied to text summarization.</title>
<date>2004</date>
<booktitle>In Companion Volume to the Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>170--173</pages>
<location>Barcelona,</location>
<contexts>
<context position="5138" citStr="Mihalcea, 2004" startWordPosition="782" endWordPosition="783">ction 6 we finally give conclusions. 2 Related work A graph-based representation of documents for summarization is adopted by various approaches. For instance, TextRank by Mihalcea and Tarau (2004) applies the PageRank algorithm (Brin and Page, 1998) to extract important sentences for single document summarization. This ranking algorithm proclaims the importance of a sentence by considering the global information which is computed recursively from the entire graph. Later, the graph is converted into a weighted graph in which the weights are calculated by measuring the similarity of sentences (Mihalcea, 2004). Similarly, in the LexRank approach (Erkan and Radev, 2004), documents are represented as a similarity graph in which the sentences are nodes and these sentences are then ranked according to centrality measures. The three centrality measures used are degree, LexRank with threshold and continuous LexRank. LexRank is a measure to calculate ranks using the similarity graph of sentences. It is also known as lexical PageRank. The summarization approach developed by Gong and Liu (2001) is also based on ranking sentences where important sentences are selected using a relevance measure and latent sem</context>
</contexts>
<marker>Mihalcea, 2004</marker>
<rawString>Rada Mihalcea. 2004. Graph-based ranking algorithms for sentence extraction, applied to text summarization. In Companion Volume to the Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, Barcelona, Spain, 21–26 July 2004, pages 170–173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
<author>Lucy Vanderwende</author>
</authors>
<title>The impact of frequency on summarization.</title>
<date>2005</date>
<tech>Technical Report MSR-TR-2005-101, Microsoft Research.</tech>
<contexts>
<context position="2582" citStr="Nenkova and Vanderwende, 2005" startWordPosition="387" endWordPosition="390">ation. 2. Non-redundancy: A summary should not contain the same information twice. 3. Readability: A summary should have good readability (syntactically well formed, no dangling pronouns, coherent,...). Generally, multi-document summarization systems differ from each other on the basis of document representation, sentence selection method or on the requirements for the output summary. Popular methods for document representation include graph-based representations (e.g. LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004)) and tf-idf vector-based representations (Luhn, 1958; Nenkova and Vanderwende, 2005; Goldstein et al., 2000). These document representations act as input for the next phase and provide information about the importance of individual sentences. Sentence selection is the crucial phase of the summarizer where sentence redundancy must be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the to</context>
<context position="7098" citStr="Nenkova and Vanderwende, 2005" startWordPosition="1079" endWordPosition="1082">ork, probablistic neural network and Gaussian mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy </context>
</contexts>
<marker>Nenkova, Vanderwende, 2005</marker>
<rawString>Ani Nenkova and Lucy Vanderwende. 2005. The impact of frequency on summarization. Technical Report MSR-TR-2005-101, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi Nishikawa</author>
<author>Takaaki Hasegawa</author>
<author>Yoshihiro Matsuo</author>
<author>Genichiro Kikui</author>
</authors>
<title>Opinion summarization with integer linear programming formulation for sentence extraction and ordering.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>910--918</pages>
<location>Beijing, China, 23–27</location>
<contexts>
<context position="3453" citStr="Nishikawa et al., 2010" startWordPosition="523" endWordPosition="526">be handled in an efficient way. A widely used technique is the greedy approach introduced by Carbonell and Goldstein (1998) and Goldstein et al. (2000). They compute a relevance score for all sentences with regard to the topic, start by extracting the most relevant sentence, and then iteratively extract further sentences which are relevant to the topic and at the same time most dissimilar to already extracted sentences. Later more fundamental optimization methods have been widely used in multi-document summarization, e.g. Integer Linear Programming (ILP) (McDonald, 2007; Gillick et al., 2009; Nishikawa et al., 2010; Galanis et al., 2012). Unlike most other approaches (Galanis et al., 2012) has also taken into account the readability of the final summary. In this work, we introduce an extractive topic based multi-document summarization system which represents documents graphically and 15 Proceedings of TextGraphs-9: the workshop on Graph-based Methods for Natural Language Processing, pages 15–24, October 29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics optimizes the importance of sentences and nonredundancy. The importance of sentences is obtained by means of applying the Hubs and </context>
</contexts>
<marker>Nishikawa, Hasegawa, Matsuo, Kikui, 2010</marker>
<rawString>Hitoshi Nishikawa, Takaaki Hasegawa, Yoshihiro Matsuo, and Genichiro Kikui. 2010. Opinion summarization with integer linear programming formulation for sentence extraction and ordering. In Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, 23–27 August 2010, pages 910–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dou Shen</author>
<author>Jian-Tao Sun</author>
<author>Hua Li</author>
<author>Qiang Yang</author>
<author>Zheng Chen</author>
</authors>
<title>Document summarization using conditional random fields.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2862--2867</pages>
<location>Hyderabad, India, 6–12</location>
<contexts>
<context position="5959" citStr="Shen et al., 2007" startWordPosition="908" endWordPosition="911">easures. The three centrality measures used are degree, LexRank with threshold and continuous LexRank. LexRank is a measure to calculate ranks using the similarity graph of sentences. It is also known as lexical PageRank. The summarization approach developed by Gong and Liu (2001) is also based on ranking sentences where important sentences are selected using a relevance measure and latent semantic analysis. Later, for better performance, sentences are classified according to their existence in their final summary in binary format i.e. 1 (belongs to summary) and 0 (doesn’t belong to summary) (Shen et al., 2007; Gong and Liu, 2001). Here, the sentences are projected as feature vectors and conditional random fields are used to classify them. During document processing, most informative sentences are selected by the summarizer (Shen et al., 2007). Fattah and Ren (2009) also considers summarization as two class classification problem. They use a genetic algorithm and mathematical regression to select appropriate weights for the features and used different classification technique for e.g. feed forward neural network, probablistic neural network and Gaussian mixture models. In the summarization task, op</context>
</contexts>
<marker>Shen, Sun, Li, Yang, Chen, 2007</marker>
<rawString>Dou Shen, Jian-Tao Sun, Hua Li, Qiang Yang, and Zheng Chen. 2007. Document summarization using conditional random fields. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, 6–12 January 2007, pages 2862–2867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimi Suzuki</author>
<author>Fumiyo Fukumoto</author>
</authors>
<title>Detection of topic and its extrinsic evaluation through multi-document summarization.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACL 2014 Conference Short Papers,</booktitle>
<pages>241--246</pages>
<location>Baltimore, Md.,</location>
<contexts>
<context position="21669" citStr="Suzuki and Fukumoto (2014)" startWordPosition="3610" endWordPosition="3613">o far. However, their results on DUC 2007 (ROUGE-2 0.12517 and ROUGE-SU4 0.17603) are still quite a bit better than our results. On the DUC 2006 data we outperform the HIERSUM system by Haghighi and Vanderwende (2009) on ROUGE2 (0.08969 vs. 0.086) as well as on ROUGESU4 (0.15070 vs. 0.143). On the DUC 2007 data, our results are worse than theirs on ROUGE2 (0.10928 vs. 0.118) and on par on ROUGESU4 (0.16735 vs. 0.167). The system which won the DUC 2007 task, PYTHY by Toutanova et al. (2007), performs similar to HIERSUM and hence slightly better than our system on these data. The recent work by Suzuki and Fukumoto (2014) evaluates also on DUC 2007 but reports only ROUGE1 scores. We obtain a ROUGE-1 score of 0.448 on DUC 2007 which is better than Suzuki and Fukumoto (2014) (0.438) as well as PYTHY (0.426). The best ROUGE-1 score reported to date has been reported by Celikyilmaz and Hakkani-T¨ur (2010) with 0.456. The difference between this score and our score of 0.448 is rather small. 5 Discussion Several approaches have been proposed for topic based multi-document summarization on the DUC datasets we use for our experiments. The best results to date have been obtained by supervised and semi-supervised system</context>
</contexts>
<marker>Suzuki, Fukumoto, 2014</marker>
<rawString>Yoshimi Suzuki and Fumiyo Fukumoto. 2014. Detection of topic and its extrinsic evaluation through multi-document summarization. In Proceedings of the ACL 2014 Conference Short Papers, Baltimore, Md., 22–27 June 2014, pages 241–246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Chris Brockett</author>
<author>Michael Gamon</author>
<author>Jagadeesh Jagarlamudi</author>
<author>Hisami Suzuki</author>
<author>Lucy Vanderwende</author>
</authors>
<title>The PYTHY summarization system: Microsoft Research at DUC</title>
<date>2007</date>
<contexts>
<context position="21537" citStr="Toutanova et al. (2007)" startWordPosition="3588" endWordPosition="3591">s, we outperform them in terms of ROUGESU4 (0.14105 vs. 0.13640), where, to our knowledge, our results are the highest reported so far. However, their results on DUC 2007 (ROUGE-2 0.12517 and ROUGE-SU4 0.17603) are still quite a bit better than our results. On the DUC 2006 data we outperform the HIERSUM system by Haghighi and Vanderwende (2009) on ROUGE2 (0.08969 vs. 0.086) as well as on ROUGESU4 (0.15070 vs. 0.143). On the DUC 2007 data, our results are worse than theirs on ROUGE2 (0.10928 vs. 0.118) and on par on ROUGESU4 (0.16735 vs. 0.167). The system which won the DUC 2007 task, PYTHY by Toutanova et al. (2007), performs similar to HIERSUM and hence slightly better than our system on these data. The recent work by Suzuki and Fukumoto (2014) evaluates also on DUC 2007 but reports only ROUGE1 scores. We obtain a ROUGE-1 score of 0.448 on DUC 2007 which is better than Suzuki and Fukumoto (2014) (0.438) as well as PYTHY (0.426). The best ROUGE-1 score reported to date has been reported by Celikyilmaz and Hakkani-T¨ur (2010) with 0.456. The difference between this score and our score of 0.448 is rather small. 5 Discussion Several approaches have been proposed for topic based multi-document summarization </context>
</contexts>
<marker>Toutanova, Brockett, Gamon, Jagarlamudi, Suzuki, Vanderwende, 2007</marker>
<rawString>Kristina Toutanova, Chris Brockett, Michael Gamon, Jagadeesh Jagarlamudi, Hisami Suzuki, and Lucy Vanderwende. 2007. The PYTHY summarization system: Microsoft Research at DUC 2007.</rawString>
</citation>
<citation valid="true">
<date>2007</date>
<booktitle>In Proceedings of the 2007 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Rochester, N.Y.,</location>
<contexts>
<context position="7117" citStr="(2007)" startWordPosition="1086" endWordPosition="1086">an mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For ins</context>
<context position="21537" citStr="(2007)" startWordPosition="3591" endWordPosition="3591">them in terms of ROUGESU4 (0.14105 vs. 0.13640), where, to our knowledge, our results are the highest reported so far. However, their results on DUC 2007 (ROUGE-2 0.12517 and ROUGE-SU4 0.17603) are still quite a bit better than our results. On the DUC 2006 data we outperform the HIERSUM system by Haghighi and Vanderwende (2009) on ROUGE2 (0.08969 vs. 0.086) as well as on ROUGESU4 (0.15070 vs. 0.143). On the DUC 2007 data, our results are worse than theirs on ROUGE2 (0.10928 vs. 0.118) and on par on ROUGESU4 (0.16735 vs. 0.167). The system which won the DUC 2007 task, PYTHY by Toutanova et al. (2007), performs similar to HIERSUM and hence slightly better than our system on these data. The recent work by Suzuki and Fukumoto (2014) evaluates also on DUC 2007 but reports only ROUGE1 scores. We obtain a ROUGE-1 score of 0.448 on DUC 2007 which is better than Suzuki and Fukumoto (2014) (0.438) as well as PYTHY (0.426). The best ROUGE-1 score reported to date has been reported by Celikyilmaz and Hakkani-T¨ur (2010) with 0.456. The difference between this score and our score of 0.448 is rather small. 5 Discussion Several approaches have been proposed for topic based multi-document summarization </context>
</contexts>
<marker>2007</marker>
<rawString>In Proceedings of the 2007 Document Understanding Conference held at the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, Rochester, N.Y., 26–27 April 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristian Woodsend</author>
<author>Mirella Lapata</author>
</authors>
<title>Multiple aspect summarization using integer linear programming.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning,</booktitle>
<pages>233--242</pages>
<location>Jeju Island,</location>
<contexts>
<context position="8314" citStr="Woodsend and Lapata (2012)" startWordPosition="1270" endWordPosition="1273">edundancy seperately. For instance, McKeown et al. (1999) create clusters of similar sentences and pick the representative one from every cluster. The representative sentence of a cluster of sentences takes care of the requirement to extract relevant information whereas clustering reduces the redundancy. McDonald (2007) proposes a new ILP optimization method for extractive summarization. He introduces an objective function which maximizes the importance of sentences and minimizes the similarity of sentences. ILP methods for optimization have also been adopted by Berg-Kirkpatrick et al. (2011),Woodsend and Lapata (2012) and Galanis et al. (2012). Until now, Galanis et al. (2012) have reported the highest scores for multi-document summarization on DUC2005 and DUC2007. However, their approach is not completely unsupervised. 16 3 Our method This section describes the technique, which we adopted for summarization. We start by discussing the graphical representation of the text followed by a description how to quantify the importance of sentences in the input texts. We then discuss the ILP technique which optimizes the importance of sentences and redundancy. 3.1 Graphical representation of text The graphical repr</context>
</contexts>
<marker>Woodsend, Lapata, 2012</marker>
<rawString>Kristian Woodsend and Mirella Lapata. 2012. Multiple aspect summarization using integer linear programming. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning, Jeju Island, Korea, 12–14 July 2012, pages 233–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-tau Yih</author>
<author>Joshua Goodman</author>
<author>Lucy Vanderwende</author>
<author>Hisami Suzuki</author>
</authors>
<title>Multi-document summarization by maximizing informative content-words.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1776--1782</pages>
<location>Hyderabad, India, 6–12</location>
<contexts>
<context position="7117" citStr="Yih et al. (2007)" startWordPosition="1083" endWordPosition="1086"> and Gaussian mixture models. In the summarization task, optimization of the three properties discussed in Section 1, relevance, non-redundancy and readability, is required. This is a global inference problem, which can be solved by two approaches. Firstly, relevance and redundancy can be optimized simultaneously. For instance, Goldstein et al. (2000) developed a metric named MMR-MD (influenced by the Maximum Marginal Relevance (MMR) approach of Carbonell and Goldstein (1998)) and applied it to clusters of passages. Similarly, influenced by the SumBasic system (Nenkova and Vanderwende, 2005), Yih et al. (2007) developed a system which assigns a score to each term on the basis of position and frequency information and selects the sentence having highest score. Other approaches are based on an estimate of word importance (e.g. Lin and Hovy (2000)) or the log likelihood ratio test which identifies the importance of words using a supervised model that considers a rich set of features (Hong and Nenkova, 2014). Finally, Barzilay and Elhadad (1999) extract sentences which are strongly connected by lexical chains for summarization. The second approach deals with relevance and redundancy seperately. For ins</context>
</contexts>
<marker>Yih, Goodman, Vanderwende, Suzuki, 2007</marker>
<rawString>Wen-tau Yih, Joshua Goodman, Lucy Vanderwende, and Hisami Suzuki. 2007. Multi-document summarization by maximizing informative content-words. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, Hyderabad, India, 6–12 January 2007, pages 1776–1782.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>