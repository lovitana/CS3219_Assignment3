<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.986788">
Types and Records for Predication
</title>
<author confidence="0.994446">
Aarne Ranta
</author>
<affiliation confidence="0.999202">
Department of Computer Science and Engineering, University of Gothenburg
</affiliation>
<email confidence="0.978167">
aarne@chalmers.se
</email>
<sectionHeader confidence="0.993422" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999986894736842">
This paper studies the use of records
and dependent types in GF (Grammatical
Framework) to build a grammar for pred-
ication with an unlimited number of sub-
categories, also covering extraction and
coordination. The grammar is imple-
mented for Chinese, English, Finnish, and
Swedish, sharing the maximum of code
to identify similarities and differences be-
tween the languages. Equipped with a
probabilistic model and a large lexicon,
the grammar has also been tested in wide-
coverage machine translation. The first
evaluations show improvements in parsing
speed, coverage, and robustness in com-
parison to earlier GF grammars. The study
confirms that dependent types, records,
and functors are useful in both engineer-
ing and theoretical perspectives.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999910172413793">
Predication is the basic level of syntax. In logic, it
means building atomic formulas by predicates. In
linguistics, it means building sentences by verbs.
Categorial grammars (Bar-Hillel, 1953; Lambek,
1958) adapt logical predication to natural lan-
guage. Thus for instance transitive verbs are cat-
egorized as (n\s/n), which is the logical type
n → n → s with the information that one argument
comes before the verb and the other one after. But
most approaches to syntax and semantics, includ-
ing (Montague, 1974), introduce predicate cate-
gories as primitives rather than as function types.
Thus transitive verbs are a category of its own, re-
lated to logic via a semantic rule. This gives more
expressive power, as it permits predicates with dif-
ferent syntactic properties and variable word order
(e.g. inversion in questions). A drawback is that
a grammar may need a large number of categories
and rules. In GPSG (Gazdar et al., 1985), and later
in HPSG (Pollard and Sag, 1994), this is solved
by introducing a feature called subcat for verbs.
Verbs taking different arguments differ in the sub-
cat feature but share otherwise the characteristic of
being verbs.
In this paper, we will study the syntax and se-
mantics of predication in GF, Grammatical Frame-
work (Ranta, 2011). We will generalize both over
subcategories (as in GPSG and HPSG), and over
languages (as customary in GF). We use depen-
dent types to control the application of verbs to
legitimate arguments, and records to control the
placement of arguments in sentences. The record
structure is inspired by the topological model of
syntax in (Diderichsen, 1962).
The approach is designed to apply to all lan-
guages in the GF Resource Grammar Library
(RGL, (Ranta, 2009)), factoring out their typolog-
ical differences in a modular way. We have tested
the grammar with four languages from three fam-
ilies: Chinese, English, Finnish, and Swedish. As
the implementation reuses old RGL code for all
parts but predication, it can be ported to new lan-
guages with just a few pages of new GF code. We
have also tested it in wide coverage tasks, with a
probabilistic tree model and a lexicon of 60,000
lemmas.
We will start with an introduction to the abstrac-
tion mechanisms of GF and conclude with a sum-
mary of some recent research. Section 2 places
GF on the map of grammar formalisms. Section 3
works out an example showing how abstract syn-
tax can be shared between languages. Section 4
shows how parts of concrete syntax can be shared
as well. Section 5 gives the full picture of predi-
cation with dependent types and records, also ad-
dressing extraction, coordination, and semantics.
Section 6 gives preliminary evaluation. Section 7
concludes.
</bodyText>
<page confidence="0.822062">
1
</page>
<note confidence="0.808704666666667">
Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 1–9,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
2 GF: an executive summary
</note>
<bodyText confidence="0.999238920634921">
GF belongs to a subfamily of categorial grammars
inspired by (Curry, 1961). These grammars make
a distinction between tectogrammar, which spec-
ifies the syntactic structures (tree-like representa-
tions), and phenogrammar, which relates these
structures to linear representations, such as se-
quences of characters, words, or phonemes. Other
formalisms in this family include ACG (de Groote,
2001) and Lambda grammars (Muskens, 2001).
GF inherits its name from LF, Logical Frame-
works, which are type theories used for defin-
ing logics (Harper et al., 1993). GF builds on
the LF called ALF, Another Logical Framework
(Magnusson, 1994), which implements Martin-
L¨of’s higher-level type theory (first introduced
in the preface of (Martin-L¨of, 1984); see Chap-
ter 8 of (Ranta, 1994) for more details). Before
GF was introduced as an independent formalism
in 1998, GF-like applications were built as plug-
ins to ALF (Ranta, 1997). The idea was that the
LF defines the tectogrammar, and the plug-in de-
fines the phenogrammar. The intended application
was natural language interfaces to formal proof
systems, in the style of (Coscoy et al., 1995).
GF was born via two additions to the natural
language interface idea. The first one was multi-
linguality: one and the same tectogrammar can
be given multiple phenogrammars. The second
addition was parsing: the phenogrammar, which
was initially just linearization (generating strings
from type theoretical formulas), was reversed to
rules that parse natural language into type theory.
The result was a method for translation, which
combines parsing the source language with lin-
earization into the target language. This idea was
indeed suggested in (Curry, 1961), and applied
before GF in the Rosetta project (Landsbergen,
1982), which used Montague’s analysis trees as
tectogrammar.
GF can be seen as a formalization and gener-
alization of Montague grammar. Formalization,
because it introduces a formal notation for the
linearization rules that in Montague’s work were
expressed informally. Generalization, because of
multilinguality and also because the type system
for analysis trees has dependent types.
Following the terminology of programming lan-
guage theory, the tectogrammar is in GF called
the abstract syntax whereas the phenogrammar is
called the concrete syntax. As in compilers and
logical frameworks, the abstract syntax encodes
the structure relevant for semantics, whereas the
concrete syntax defines “syntactic sugar”.
The resulting system turned out to be equiv-
alent to parallel multiple context-free gram-
mars (Seki et al., 1991) and therefore parsable
in polynomial time (Ljungl¨of, 2004). Compre-
hensive grammars have been written for 29 lan-
guages, and later work has optimized GF pars-
ing and also added probabilistic disambiguation
and robustness, resulting in state-of-the-art perfor-
mance in wide-coverage deep parsing (Angelov,
2011; Angelov and Ljungl¨of, 2014).
</bodyText>
<sectionHeader confidence="0.9878565" genericHeader="method">
3 Example: subject-verb-object
sentences
</sectionHeader>
<bodyText confidence="0.975097">
Let us start with an important special case of predi-
cation: the subject-verb-object structure. The sim-
plest possible rule is
</bodyText>
<listItem confidence="0.367061916666667">
fun PredTV : NP -&gt; TV -&gt; NP -&gt; S
that is, a function that takes a subject NP, a tran-
sitive verb TV, and an object NP, and returns a
sentence S. This function builds abstract syntax
trees. Concrete syntax defines linearization rules,
which convert trees into strings. The above rule
can give rise to different word orders, such as SVO
(as in English), SOV (as in Hindi), and VSO (as in
Arabic):
lin PredTV s v o=s++v++o
lin PredTV svo=s++o++v
lin PredTV s v o=v++s++o
</listItem>
<bodyText confidence="0.999222142857143">
where ++ means concatenation.
The above rule builds a sentence in one step.
A more flexible approach is to do it in two steps:
complementation, forming a VP (verb phrase)
from the verb and the object, and predication
proper that provides the subject. The abstract syn-
tax is
</bodyText>
<listItem confidence="0.533888">
fun Compl : TV -&gt; NP -&gt; VP
fun Pred : NP -&gt; VP -&gt; S
</listItem>
<bodyText confidence="0.868247">
These functions are easy to linearize for the SVO
and SOV orders:
</bodyText>
<equation confidence="0.263178">
lin Compl v o = v ++ o -- SVO
lin Compl v o = o ++ v -- SOV
lin Pred s vp = s ++ vp -- both
</equation>
<bodyText confidence="0.999683714285714">
where -- marks a comment. However, the VSO
order cannot be obtained in this way, because the
two parts of the VP are separated by the subject.
The solution is to generalize linearization from
strings to records. Complementation can then re-
turn a record that has the verb and the object as
separate fields. Then we can also generate VSO:
</bodyText>
<page confidence="0.979272">
2
</page>
<bodyText confidence="0.855018894736842">
lin Compl v o = {verb = v ; obj = o}
lin Pred s vp = vp.verb ++ s ++ vp.obj
The dot (.) means projection, picking the value
of a field in a record.
Records enable the abstract syntax to abstract
away not only from word order, but also from
whether a language uses discontinuous con-
stituents. VP in VSO languages is one example.
Once we enable discontinuous constituents, they
turn out useful almost everywhere, as they enable
us to delay the decision about linear order. It can
then be varied even inside a single language, if it
depends on syntactic context (as e.g. in German;
cf. (M¨uller, 2004) for a survey).
The next thing to abstract away from is inflec-
tion and agreement. Given the lexicon
fun We, She : NP
fun Love : TV
we can build the abstract syntax tree
</bodyText>
<subsectionHeader confidence="0.478241">
Pred We (Compl Love She)
</subsectionHeader>
<bodyText confidence="0.991431">
to represent we love her. If we swap the subject
and the object, we get
</bodyText>
<subsectionHeader confidence="0.880495">
Pred She (Compl Love We)
</subsectionHeader>
<bodyText confidence="0.9999">
for she loves us. Now, these two sentences are
built from the same abstract syntax objects, but
no single word is shared between them! This is
because the noun phrases inflect for case and the
verb agrees to the subject.
In contrast to English, Chinese just reorders the
words:
women ai ta - “we love her”
ta ai women - “she loves us”
Thus the above rules for SVO languages work as
they are for Chinese. But in English, we must in-
clude case and agreement as features in the con-
crete syntax. Thus the linearization of an NP is
a record that includes a table producing the case
forms, and agreement as an inherent feature:
</bodyText>
<equation confidence="0.982238428571429">
lin She = {
s = table {
Nom =&gt; &amp;quot;she&amp;quot; ;
Acc =&gt; &amp;quot;her&amp;quot;
} ;
a={n=Sg ; p = P3} ;
}
</equation>
<bodyText confidence="0.9999615">
The agreement feature (field a) is itself a record,
with a number and a gender. In other languages,
case and agreement can of course have different
sets of values.
Verbs likewise include tables that inflect them
for different agreement features:
</bodyText>
<equation confidence="0.957860454545455">
lin Love = {
s = table {
{n = Sg ; p = P3} =&gt; &amp;quot;loves&amp;quot; ;
_ =&gt; &amp;quot;love&amp;quot;
}
}
We can now define English linearization:
lin Compl v o =
{s = table {a =&gt; v.s ! a ++ o.s ! Acc}}
lin Pred s vp =
{s = s.s ! Nom ++ vp.s ! np.a}
</equation>
<bodyText confidence="0.999941125">
using the same type of records for VP as for TV,
and a one-string record for S. The Compl rule
passes the agreement feature to the verb of the VP,
and selects the Acc form of the object (with ! de-
noting selection from a table). The Pred rule se-
lects the Nom form of the subject, and attaches to
this the VP form selected for np.a, i.e. the agree-
ment feature of the subject.
</bodyText>
<sectionHeader confidence="0.990149" genericHeader="method">
4 Generalized concrete syntax
</sectionHeader>
<bodyText confidence="0.999366923076923">
To see the full power of GF, we now take a look
at its type and module system. Figure 1 shows a
complete set of grammar modules implementing
transitive verb predication for Finnish and Chinese
with a maximum of shared code.
The first module in Figure 1 is the abstract syn-
tax Pred, where the fun rules are preceded by
a set of cat rules defining the categories of the
grammar, i.e. the basic types. Pred defines five
categories: S, Cl, NP, VP, and TV. S is the top-
level category of sentences, whereas Cl (clause) is
the intermediate category of predications, which
can be used as sentences in many ways—here, as
declaratives and as questions.
The concrete syntax has corresponding lincat
rules, which equip each category with a lineariza-
tion type, i.e. the type of the values returned
when linearizing trees of that category. The mod-
ule PredFunctor in Figure 1 contains four such
rules. In lincat NP, the type Case =&gt; Str is
the type of tables that produce a string as a func-
tion of a case, and Agr is the type of agreement
features.
When a GF grammar is compiled, each lin rule
is type checked with respect to the lincats of the
categories involved, to guarantee that, for every
</bodyText>
<equation confidence="0.409183666666667">
fun f : C1 —* ··· —* Cn —* C
we have
lin f : C*1 —* ··· —* C*n —* C*
</equation>
<page confidence="0.830157">
3
</page>
<figure confidence="0.99753971875">
abstract Pred = {
cat S ; Cl ; NP ; VP ; TV ;
fun Compl : TV -&gt; NP -&gt; VP ; fun Pred : TV -&gt; NP -&gt; Cl ;
fun Decl : Cl -&gt; S ; fun Quest : Cl -&gt; S ;
}
incomplete concrete PredFunctor of Pred = open PredInterface in {
lincat S = {s : Str} ; lincat Cl = {subj,verb,obj : Str} ;
lincat NP = {s : Case =&gt; Str ; a : Agr} ;
lincat VP = {verb : Agr =&gt; Str ; obj : Str} ; lincat TV = {s : Agr =&gt; Str} ;
lin Compl tv np = {verb = tv.s ; obj = np.s ! objCase} ;
lin Pred np vp = {subj = np.s !subjCase ; verb = vp.verb ! np.a ; obj = vp.obj} ;
lin Decl cl = {s = decl cl.subj cl.verb cl.obj} ;
lin Quest cl = {s = quest cl.subj cl.verb cl.obj} ;
}
interface PredInterface = {
oper Case, Agr : PType ;
oper subjCase, objCase : Case ;
oper decl, quest : Str -&gt; Str -&gt; Str -&gt; Str ;
}
instance PredInstanceFin of PredInterface = { concrete PredFin of Pred =
oper Case = -- Nom  |Acc  |... ; PredFunctor with
oper Agr = {n : Number ; p : Person} ; (PredInterface =
oper subjCase = Nom ; objCase = Acc ; PredInstanceFin) ;
oper decl s v o = s ++ v ++ o ;
oper quest s v o = v ++ &amp;quot;&amp;+ ko&amp;quot; ++ s ++ o ;
}
instance PredInstanceChi of PredInterface = { concrete PredChi of Pred =
oper Case, Agr = {} ; PredFunctor with
oper subjCase, objCase = &lt;&gt; ; (PredInterface =
oper decl s v o = s ++ v ++ o ; PredInstanceChi) ;
oper quest s v o = s ++ v ++ o ++ &amp;quot;ma&amp;quot; ;
}
</figure>
<figureCaption confidence="0.999989">
Figure 1: Functorized grammar for transitive verb predication.
</figureCaption>
<bodyText confidence="0.999868833333333">
where A∗ is the linearization type of A. Thus lin-
earization is a homomorphism. It is actually
an instance of denotational semantics, where the
lincats are the domains of possible denota-
tions.
Much of the strength of GF comes from us-
ing different linearization types for different lan-
guages. Thus English needs case and agreement,
Finnish needs many more cases (in the full gram-
mar), Chinese needs mostly only strings, and so
on. However, it is both useful and illuminating to
unify the types. The way to do this is by the use
of functors, also known as a parametrized mod-
ules.
PredFunctor in Figure 1 is an example; func-
tors are marked with the keyword incomplete. A
functor depends on an interface, which declares
a set of parameters (PredInterface in Figure
1). A concrete module is produced by giving
an instance to the interface (PredInstanceFin
and PredInstanceChi).
The rules in PredFunctor in Figure 1 are de-
signed to work for both languages, by varying the
definitions of the constants in PredInterface.
And more languages can be added to use it. Con-
sider for example the definition of NP. The expe-
rience from the RGL shows that, if a language
has case and agreement, its NPs inflect for case
and have inherent agreement. The limiting case
of Chinese can be treated by using the unit type
({} i.e. the record type with no fields) for both
features. This would not be so elegant for Chinese
alone, but makes sense in the code sharing context.
Discontinuity now appears as another useful
generalization. With the lincat definition in
PredFunctor, we can share the Compl rule in all
of the languages discussed so far. In clauses (Cl),
we continue on similar lines: we keep the subject,
the verb, and the object on separate fields. Notice
that verb in Cl is a plain string, since the value of
Agr gets fixed when the subject is added.
The final sentence word order is created as the
last step, when converting Cl into S. As Cl is dis-
continuous, it can be linearized in different orders.
In Figure 1, this is used in Finnish for generat-
ing the SVO order in declaratives and VSO on
questions (with an intervening question particle ko
glued to the verb). It also supports the other word
</bodyText>
<page confidence="0.987463">
4
</page>
<bodyText confidence="0.998320173913044">
orders of Finnish (Karttunen and Kay, 1985).
By using an abstract syntax in combination with
unordered records, parameters, and functors for
the concrete syntax, we follow a kind of a “prin-
ciples and parameters” approach to language vari-
ation (Chomsky, 1981). The actual parameter set
for the whole RGL is of course larger than the one
shown here.
Mathematically, it is possible to treat all differ-
ences in concrete syntax by parameters, simply by
declaring a new parameter for every lincat and
lin rule! But this is both vacuous as a theory and
an unnecessary detour in practice. It is more il-
luminating to keep the functor simple and the set
of parameters small. If the functor does not work
for a new language, it usually makes more sense to
override it than to grow the parameter list, and GF
provides a mechanism for this. Opposite to “prin-
ciples and parameters”, this is “a model in which
language-particular rules take over the work of pa-
rameter settings” (Newmeyer, 2004). A combina-
tion of the two models enables language compari-
son by measuring the amount of overrides.
</bodyText>
<sectionHeader confidence="0.944784" genericHeader="method">
5 The full predication system
</sectionHeader>
<bodyText confidence="0.990656">
So far we have only dealt with one kind of verbs,
TV. But we need more: intransitive, ditransitive,
sentence-complement, etc. The general verb cate-
gory is a dependent type, which varies over argu-
ment type lists:
cat V (x : Args)
The list x : Args corresponds to the subcat fea-
ture in GPSG and HPSG. Verb phrases and clauses
have the same dependencies. Syntactically, a
phrase depending on x : Args has “holes” for
every argument in the list x. Semantically, it is a
function over the denotations of its arguments (see
Section 5.3 below).
</bodyText>
<subsectionHeader confidence="0.994273">
5.1 The code
</subsectionHeader>
<bodyText confidence="0.999472333333333">
Figure 2 shows the essentials of the resulting
grammar, and we will now explain this code. The
full code is available at the GF web site.
</bodyText>
<listItem confidence="0.403991">
1. Argument lists and dependent categories.
</listItem>
<bodyText confidence="0.999786464285714">
The argument of a verb can be an adjectival phrase
(AP, become old), a clause (Cl, say that we go), a
common noun (CN, become a president), a noun
phrase (NP, love her), a question (QCl, wonder
who goes), or a verb phrase (VP, want to go). The
definition allows an arbitrary list of arguments.
For example, NP+QCl is used in verbs such as ask
(someone whether something).
What about PP (prepositional phrase) comple-
ments? The best approach in a multilingual set-
ting is to treat them as NP complements with des-
ignated cases. Thus in Figure 2.5, the lineariza-
tion type of VP has fields of type complCase.
This covers cases and prepositions, often in com-
bination. For instance, the German verb lieben
(“love”) takes a plain accusative argument, fol-
gen (“love”) a plain dative, and warten (“wait”)
the preposition auf with the accusative. From the
abstract syntax point of view, all of them are NP-
complement verbs. Cases and prepositions, and
thereby transitivity, are defined in concrete syntax.
The category Cl, clause, is the discontinuous
structure of sentences before word order is deter-
mined. Its instance Cl (c np O) corresponds to
the slash categories S/NP and S/PP in GPSG.
Similarly, VP (c np O) corresponds to VP/NP
and VP/PP, Adv (c np O) to Adv/NP (preposi-
tions), and so on.
</bodyText>
<listItem confidence="0.979807555555556">
2. Initial formation of verb phases. A VP is
formed from a V by fixing its tense and polarity.
In the resulting VP, the verb depends only on the
agreement features of the expected subject. The
complement case comes from the verb’s lexical
entry, but the other fields—such as the objects—
are left empty. This makes the VP usable in both
complementation and slash operations (where the
subject is added before some complement).
</listItem>
<bodyText confidence="0.923382333333334">
VPs can also be formed from adverbials, ad-
jectival phrases, and common nouns, by adding a
copula. Thus was in results from applying UseAdv
to the preposition (i.e. Adv/NP) in, and expands to
a VP with ComplNP (was in France) and to a slash
clause with PredVP (she was in).
</bodyText>
<listItem confidence="0.790406">
3. Complementation, VP slash formation, re-
</listItem>
<bodyText confidence="0.779825375">
flexivization. The Compl functions in Figure 2.3
provide each verb phrase with its “first” comple-
ment. The Slash functions provide the “last”
complement, leaving a “gap” in the middle. For
instance, SlashCl provides the slash clause used
in the question whom did you tell that we sleep.
The Refl rules fill argument places with reflexive
pronouns.
</bodyText>
<listItem confidence="0.9760698">
4. NP-VP predication, slash termination, and
adverbial modification. PredVP is the basic NP-
VP predication rule. With x = c np O, it be-
comes the rule that combines NP with VP/NP to
form S/NP. SlashTerm is the GPSG “slash termi-
</listItem>
<page confidence="0.879577">
5
</page>
<figure confidence="0.634055851851852">
1. Argument lists and some dependent categories
cat Arg ; Args -- arguments and argument lists
fun ap, cl, cn, np, qcl, vp : Arg -- AP, Cl, CN, NP, QCl, VP argument
fun O : Args -- no arguments
fun c : Arg -&gt; Args -&gt; Args -- one more argument
cat V (x : Args) -- verb in the lexicon
cat VP (x : Args) -- verb phrase
cat Cl (x : Args) -- clause
cat AP (x : Args) -- adjectival phrase
cat CN (x : Args) -- common noun phrase
cat Adv (x : Args) -- adverbial phrase
2. Initial formation of verb phases
fun UseV : (x : Args) -&gt; Temp -&gt; Pol -&gt; V x -&gt; VP x -- loved (X)
fun UseAP : (x : Args) -&gt; Temp -&gt; Pol -&gt; AP x -&gt; VP x -- was married to (X)
fun UseCN : (x : Args) -&gt; Temp -&gt; Pol -&gt; CN x -&gt; VP x -- was a son of (X)
fun UseAdv : (x : Args) -&gt; Temp -&gt; Pol -&gt; Adv x -&gt; VP x -- was in (X)
3. Complementation, VP slash formation, reflexivization
fun ComplNP : (x : Args) -&gt; VP (c np x) -&gt; NP -&gt; VP x -- love her
fun ComplCl : (x : Args) -&gt; VP (c cl x) -&gt; Cl x -&gt; VP x -- say that we go
fun SlashNP : (x : Args) -&gt; VP (c np (c np x)) -&gt; NP -&gt; VP (c np x) -- show (X) to him
fun SlashCl : (x : Args) -&gt; VP (c np (c cl x)) -&gt; Cl x -&gt; VP (c np x) -- tell (X) that..
fun ReflVP : (x : Args) -&gt; VP (c np x) -&gt; VP x -- love herself
fun ReflVP2 : (x : Args) -&gt; VP (c np (c np x)) -&gt; VP (c np x) -- show (X) to herself
4. NP-VP predication, slash termination, and adverbial modification
fun PredVP : (x : Args) -&gt; NP -&gt; VP x -&gt; Cl x -- she loves (X)
fun SlashTerm : (x : Args) -&gt; Cl (c np x) -&gt; NP -&gt; Cl x -- she loves + X
5. The functorial linearization type of VP
</figure>
<equation confidence="0.970516533333333">
lincat VP = {
verb : Agr =&gt; Str * Str * Str ; -- finite: would,have,gone
inf : VVType =&gt; Str ; -- infinitive: (not) (to) go
imp : ImpType =&gt; Str ; -- imperative: go
c1 : ComplCase ; -- case of first complement
c2 : ComplCase ; -- case of second complement
vvtype : VVType ; -- type of VP complement
adj : Agr =&gt; Str ; -- adjective complement
obj1 : Agr =&gt; Str ; -- first complement
obj2 : Agr =&gt; Str ; -- second complement
objagr : {a : Agr ; objCtr : Bool} ; -- agreement used in object control
adv1 : Str ; -- pre-verb adverb
adv2 : Str ; -- post-verb adverb
ext : Str ; -- extraposed element e.g. that-clause
}
</equation>
<table confidence="0.536342888888889">
6. Some functorial linearization rules
lin ComplNP x vp np = vp ** {obj1 = \\a =&gt; appComplCase vp.c1 np}
lin ComplCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}
lin SlashNP2 x vp np = vp ** {obj2 = \\a =&gt; appComplCase vp.c2 np}
lin SlashCl x vp cl = vp ** {ext = that_Compl ++ declSubordCl cl}
7. Some interface parameters
oper Agr, ComplCase : PType -- agreement, complement case
oper appComplCase : ComplCase -&gt; NP -&gt; Str -- apply complement case to NP
oper declSubordCl : Cl -&gt; Str -- subordinate question word order
</table>
<figureCaption confidence="0.962597">
Figure 2: Dependent types, records, and parameters for predication.
</figureCaption>
<page confidence="0.99678">
6
</page>
<bodyText confidence="0.782725375">
nation” rule.
5. The functorial linearization type of VP.
This record type contains the string-valued fields
that can appear in different orders, as well as the
inherent features that are needed when comple-
ments are added. The corresponding record for Cl
has similar fields with constant strings, plus a sub-
ject field.
</bodyText>
<listItem confidence="0.99522625">
6. Some functorial linearization rules. The
verb-phrase expanding rules typically work with
record updates, where the old VP is left un-
changed except for a few fields that get new val-
ues. GF uses the symbol ** for record updates.
Notice that ComplCl and SlashCl have exactly
the same linearization rules; the difference comes
from the argument list x in the abstract syntax.
7. Some interface parameters. The code
in Figure 2.5 and 2.6 is shared by different lan-
guages, but it depends on an interface that declares
parameters, some of which are shown here.
</listItem>
<subsectionHeader confidence="0.999437">
5.2 More constructions
</subsectionHeader>
<bodyText confidence="0.999917931034483">
Extraction. The formation of questions and rel-
atives is straighforward. Sentential (yes/no) ques-
tions, formed by QuestCl in Figure 3.1, don’t in
many languages need any changes in the clause,
but just a different ordering in final linearization.
Wh questions typically put one interrogative (IP)
in the focus, which may be in the beginning of the
sentence even though the corresponding argument
place in declaratives is later. The focus field in
QCl is used for this purpose. It carries a Boolean
feature saying whether the field is occupied. If its
value is True, the next IP is put into the “normal”
argument place, as in who loves whom.
Coordination. The VP conjunction rules in
Figure 3.2 take care of both intransitive VPs (she
walks and runs) and of verb phrases with argu-
ments (she loves and hates us). Similarly, Cl con-
juction covers both complete sentences and slash
clauses (she loves and we hate him). Some VP
coordination instances may be ungrammatical, in
particular with inverted word orders. Thus she is
tired and wants to sleep works as a declarative,
but the question is not so good: ?is she tired and
wants to sleep. Preventing this would need a much
more complex rules. Since the goal of our gram-
mar is not to define grammaticality (as in formal
language theory), but to analyse and translate ex-
isting texts, we opted for a simple system in this
case (but did not need to do so elsewhere).
</bodyText>
<subsectionHeader confidence="0.997688">
5.3 Semantics
</subsectionHeader>
<bodyText confidence="0.995317166666667">
The abstract syntax has straightforward denota-
tional semantics: each type in the Args list of a
category adds an argument to the type of denota-
tions. For instance, the basic VP denotation type is
Ent -&gt; Prop, and the type for an arbitrary sub-
category of VP x is
</bodyText>
<equation confidence="0.951815">
(x : Args) -&gt; Den x (Ent -&gt; Prop)
</equation>
<bodyText confidence="0.558223">
where Den is a type family defined recursively
over Args,
</bodyText>
<equation confidence="0.990594">
Den : Args -&gt; Type -&gt; Type
Den O t = t
Den (c np xs) t = Ent -&gt; Den xs t
Den (c cl xs) t = Prop -&gt; Den xs t
</equation>
<bodyText confidence="0.99887525">
and so on for all values of Arg. The second ar-
gument t varies over the basic denotation types of
VP, AP, Adv, and CN.
Montague-style semantics is readily available
for all rules operating on these categories. As a
logical framework, GF has the expressive power
needed for defining semantics (Ranta, 2004). The
types can moreover be extended to express selec-
tional restrictions, where verb arguments are re-
stricted to domains of individuals. Here is a type
system that adds a domain argument to NP and
VP:
</bodyText>
<equation confidence="0.655260333333333">
cat NP (d : Dom)
cat VP (d : Dom)(x : Args)
fun PredVP : (d : Dom) -&gt; (x : Args)
</equation>
<bodyText confidence="0.890649333333333">
-&gt;NPd-&gt;VPdx-&gt;Clx
The predication rule checks that the NP and the
VP have the same domain.
</bodyText>
<sectionHeader confidence="0.997005" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.9999037">
Coverage. The dependent type system for verbs,
verb phrases, and clauses is a generalization of
the old Resource Grammar Library (Ranta, 2009),
which has a set of hard-wired verb subcategories
and a handful of slash categories. While it cov-
ers “all usual cases”, many logically possible ones
are missing. Some such cases even appear in the
Penn treebank (Marcus et al., 1993), requiring ex-
tra rules in the GF interpretation of the treebank
(Angelov, 2011). An example is a function of type
</bodyText>
<equation confidence="0.932237">
V (c np (c vp O)) -&gt;
VPC (c np O) -&gt; VP (c np O)
</equation>
<bodyText confidence="0.999564">
which is used 12 times, for example in This is de-
signed to get the wagons in a circle and defend
the smoking franchise. It has been easy to write
conversion rules showing that the old coverage is
preserved. But it remains future work to see what
new cases are covered by the increased generality.
</bodyText>
<page confidence="0.996122">
7
</page>
<figure confidence="0.860034875">
1. Extraction.
cat QCl (x : Args) -- question clause
cat IP -- interrogative phrase
-- does she love him
-- who loves him
-- whom does she love
lincat QCl = Cl ** {focus : {s : Str ; isOcc : Bool}} -- focal IP, whether occupied
2. Coordination.
cat VPC (x : Args) -- VP conjunction
cat ClC (x : Args) -- Clause conjunction
fun StartVPC : (x : Args) -&gt; Conj -&gt; VP x -&gt; VP x -&gt; VPC x -- love or hate
fun ContVPC : (x : Args) -&gt; VP x -&gt; VPC x -&gt; VPC x -- admire, love or hate
fun UseVPC : (x : Args) -&gt; VPC x -&gt; VP x -- [use VPC as VP]
fun StartClC : (x : Args) -&gt; Conj -&gt; Cl x -&gt; Cl x -&gt; ClC x -- he sells and I buy
fun ContClC : (x : Args) -&gt; Cl x -&gt; ClC x -&gt; ClC x -- you steal, he sells and I buy
fun UseClC : (x : Args) -&gt; ClC x -&gt; Cl x -- [use ClC as Cl]
</figure>
<figureCaption confidence="0.993857">
Figure 3: Extraction and coordination.
</figureCaption>
<table confidence="0.486666333333333">
fun QuestCl : (x : Args) -&gt; Cl x -&gt; QCl x
fun QuestVP : (x : Args) -&gt; IP -&gt; VP x -&gt; QCl x
fun QuestSlash : (x : Args) -&gt; IP -&gt; QCl (c np x) -&gt; QCl x
</table>
<bodyText confidence="0.994919829787234">
Multilinguality. How universal are the con-
crete syntax functor and interface? In the stan-
dard RGL, functorization has only been attempted
for families of closely related languages, with Ro-
mance languages sharing 75% of syntax code and
Scandinavian languages 85% (Ranta, 2009). The
new predication grammar shares code across all
languages. The figure to compare is the percent-
age of shared code (abstract syntax + functor + in-
terface) of the total code written for a particular
language (shared + language-specific). This per-
centage is 70 for Chinese, 64 for English, 61 for
Finnish, and 76 for Swedish, when calculated as
lines of code. The total amount of shared code is
760 lines. One example of overrides is negation
and questions in English, which are complicated
by the need of auxiliaries for some verbs (go) but
not for others (be). This explains why Swedish
shares more of the common code than English.
Performance. Dependent types are not inte-
grated in current GF parsers, but checked by post-
processing. This implies a loss of speed, be-
cause many trees are constructed just to be thrown
away. But when we specialized dependent types
and rules to nondependent instances needed by the
lexicon (using them as metarules in the sense of
GPSG), parsing became several times faster than
with the old grammar. An analysis remains to do,
but one hypothesis is that the speed-up is due to
fixing tense and polarity earlier than in the old
RGL: when starting to build VPs, as opposed to
when using clauses in full sentences. Dependent
types made it easy to test this refactoring, since
they reduced the number of rules that had to be
written.
Robustness. Robustness in GF parsing is
achieved by introducing metavariables (“ques-
tion marks”) when tree nodes cannot be con-
structed by the grammar (Angelov, 2011). The
subtrees under a metavariable node are linearized
separately, just like a sequence of chunks. In
translation, this leads to decrease in quality, be-
cause dependencies between chunks are not de-
tected. The early application of tense and polarity
is an improvement, as it makes verb chunks con-
tain information that was previously detected only
if the parser managed to build a whole sentence.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.997819352941176">
We have shown a GF grammar for predication al-
lowing an unlimited variation of argument lists: an
abstract syntax with a concise definition using de-
pendent types, a concrete syntax using a functor
and records, and a straightforward denotational se-
mantics. The grammar has been tested with four
languages and shown promising results in speed
and robustness, also in large-scale processing. A
more general conclusion is that dependent types,
records, and functors are powerful tools both for
computational grammar engineering and for the
theoretical study of languages.
Acknowledgements. I am grateful to Krasimir
Angelov and Robin Cooper for comments, and
to Swedish Research Council for support under
grant nr. 2012-5746 (Reliable Multilingual Dig-
ital Communication).
</bodyText>
<page confidence="0.989917">
8
</page>
<bodyText confidence="0.9964134">
L. Magnusson. 1994. The Implementation of ALF - a
Proof Editor based on Martin-L¨of’s Monomorphic
Type Theory with Explicit Substitution. Ph.D. thesis,
Department of Computing Science, Chalmers Uni-
versity of Technology and University of G¨oteborg.
</bodyText>
<sectionHeader confidence="0.934788" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997786741935484">
K. Angelov and P. Ljungl¨of. 2014. Fast statistical pars-
ing with parallel multiple context-free grammars. In
Proceedings of EACL-2014, Gothenburg.
K. Angelov. 2011. The Mechanics of the Grammatical
Framework. Ph.D. thesis, Chalmers University of
Technology.
Y. Bar-Hillel. 1953. A quasi-arithmetical notation for
syntactic description. Language, 29:27–58.
N. Chomsky. 1981. Lectures on Government and
Binding. Mouton de Gruyter.
Y. Coscoy, G. Kahn, and L. Thery. 1995. Extract-
ing text from proofs. In M. Dezani-Ciancaglini and
G. Plotkin, editors, Proc. Second Int. Conf. on Typed
Lambda Calculi and Applications, volume 902 of
LNCS, pages 109–123.
H. B. Curry. 1961. Some logical aspects of grammat-
ical structure. In Roman Jakobson, editor, Structure
of Language and its Mathematical Aspects: Pro-
ceedings of the Twelfth Symposium in Applied Math-
ematics, pages 56–68. American Mathematical So-
ciety.
Ph. de Groote. 2001. Towards Abstract Categorial
Grammars. In Association for Computational Lin-
guistics, 39th Annual Meeting and 10th Conference
of the European Chapter, Toulouse, France, pages
148–155.
P. Diderichsen. 1962. Elementcer dansk grammatik.
Gyldendal, København.
G. Gazdar, E. Klein, G. Pullum, and I. Sag. 1985. Gen-
eralized Phrase Structure Grammar. Basil Black-
well, Oxford.
R. Harper, F. Honsell, and G. Plotkin. 1993. A Frame-
work for Defining Logics. JACM, 40(1):143–184.
L. Karttunen and M. Kay. 1985. Parsing in a free
word order language. In D. Dowty, L. Karttunen,
and A. Zwicky, editors, Natural Language Pars-
ing, Psychological, Computational, and Theoretical
Perspectives, pages 279–306. Cambridge University
Press.
J. Lambek. 1958. The mathematics of sentence struc-
ture. American Mathematical Monthly, 65:154–170.
J. Landsbergen. 1982. Machine translation based
on logically isomorphic Montague grammars. In
COLING-1982.
P. Ljungl¨of. 2004. The Expressivity and Com-
plexity of Grammatical Framework. Ph.D.
thesis, Dept. of Computing Science, Chalmers
University of Technology and Gothenburg Uni-
versity. http://www.cs.chalmers.se/~peb/
pubs/p04-PhD-thesis.pdf.
M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a Large Annotated Corpus of En-
glish: The Penn Treebank. Computational Linguis-
tics, 19(2):313–330.
P. Martin-L¨of. 1984. Intuitionistic Type Theory. Bib-
liopolis, Napoli.
R. Montague. 1974. Formal Philosophy. Yale Univer-
sity Press, New Haven. Collected papers edited by
Richmond Thomason.
S. M¨uller. 2004. Continuous or Discontinuous Con-
stituents? A Comparison between Syntactic Analy-
ses for Constituent Order and Their Processing Sys-
tems. Research on Language and Computation,
2(2):209–257.
R. Muskens. 2001. Lambda Grammars and the
Syntax-Semantics Interface. In R. van Rooy and
M. Stokhof, editors, Proceedings of the Thirteenth
Amsterdam Colloquium, pages 150–155, Amster-
dam. http://let.uvt.nl/general/people/
rmuskens/pubs/amscoll.pdf.
F. J. Newmeyer. 2004. Against a parameter-setting
approach to language variation. Linguistic Variation
Yearbook, 4:181–234.
C. Pollard and I. Sag. 1994. Head-Driven Phrase
Structure Grammar. University of Chicago Press.
A. Ranta. 1994. Type Theoretical Grammar. Oxford
University Press.
A. Ranta. 1997. Structures grammaticales dans le
franc¸ais math´ematique. Math´ematiques, informa-
tique et Sciences Humaines, 138/139:5–56/5–36.
A. Ranta. 2004. Computational Semantics in Type
Theory. Mathematics and Social Sciences, 165:31–
57.
A. Ranta. 2009. The GF Resource Grammar
Library. Linguistics in Language Technology,
2. http://elanguage.net/journals/index.
php/lilt/article/viewFile/214/158.
A. Ranta. 2011. Grammatical Framework: Program-
ming with Multilingual Grammars. CSLI Publica-
tions, Stanford.
H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
On multiple context-free grammars. Theoretical
Computer Science, 88:191–229.
</reference>
<page confidence="0.997114">
9
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.762199">
<title confidence="0.999905">Types and Records for Predication</title>
<author confidence="0.995561">Aarne Ranta</author>
<affiliation confidence="0.99691">Department of Computer Science and Engineering, University of</affiliation>
<email confidence="0.797347">aarne@chalmers.se</email>
<abstract confidence="0.99801545">This paper studies the use of records and dependent types in GF (Grammatical Framework) to build a grammar for predication with an unlimited number of subcategories, also covering extraction and coordination. The grammar is implemented for Chinese, English, Finnish, and Swedish, sharing the maximum of code to identify similarities and differences between the languages. Equipped with a probabilistic model and a large lexicon, the grammar has also been tested in widecoverage machine translation. The first evaluations show improvements in parsing speed, coverage, and robustness in comparison to earlier GF grammars. The study confirms that dependent types, records, and functors are useful in both engineering and theoretical perspectives.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Angelov</author>
<author>P Ljungl¨of</author>
</authors>
<title>Fast statistical parsing with parallel multiple context-free grammars.</title>
<date>2014</date>
<booktitle>In Proceedings of EACL-2014, Gothenburg.</booktitle>
<marker>Angelov, Ljungl¨of, 2014</marker>
<rawString>K. Angelov and P. Ljungl¨of. 2014. Fast statistical parsing with parallel multiple context-free grammars. In Proceedings of EACL-2014, Gothenburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Angelov</author>
</authors>
<title>The Mechanics of the Grammatical Framework.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Chalmers University of Technology.</institution>
<contexts>
<context position="6700" citStr="Angelov, 2011" startWordPosition="1052" endWordPosition="1053">ar is called the concrete syntax. As in compilers and logical frameworks, the abstract syntax encodes the structure relevant for semantics, whereas the concrete syntax defines “syntactic sugar”. The resulting system turned out to be equivalent to parallel multiple context-free grammars (Seki et al., 1991) and therefore parsable in polynomial time (Ljungl¨of, 2004). Comprehensive grammars have been written for 29 languages, and later work has optimized GF parsing and also added probabilistic disambiguation and robustness, resulting in state-of-the-art performance in wide-coverage deep parsing (Angelov, 2011; Angelov and Ljungl¨of, 2014). 3 Example: subject-verb-object sentences Let us start with an important special case of predication: the subject-verb-object structure. The simplest possible rule is fun PredTV : NP -&gt; TV -&gt; NP -&gt; S that is, a function that takes a subject NP, a transitive verb TV, and an object NP, and returns a sentence S. This function builds abstract syntax trees. Concrete syntax defines linearization rules, which convert trees into strings. The above rule can give rise to different word orders, such as SVO (as in English), SOV (as in Hindi), and VSO (as in Arabic): lin Pred</context>
<context position="26614" citStr="Angelov, 2011" startWordPosition="4873" endWordPosition="4874">d : Dom)(x : Args) fun PredVP : (d : Dom) -&gt; (x : Args) -&gt;NPd-&gt;VPdx-&gt;Clx The predication rule checks that the NP and the VP have the same domain. 6 Evaluation Coverage. The dependent type system for verbs, verb phrases, and clauses is a generalization of the old Resource Grammar Library (Ranta, 2009), which has a set of hard-wired verb subcategories and a handful of slash categories. While it covers “all usual cases”, many logically possible ones are missing. Some such cases even appear in the Penn treebank (Marcus et al., 1993), requiring extra rules in the GF interpretation of the treebank (Angelov, 2011). An example is a function of type V (c np (c vp O)) -&gt; VPC (c np O) -&gt; VP (c np O) which is used 12 times, for example in This is designed to get the wagons in a circle and defend the smoking franchise. It has been easy to write conversion rules showing that the old coverage is preserved. But it remains future work to see what new cases are covered by the increased generality. 7 1. Extraction. cat QCl (x : Args) -- question clause cat IP -- interrogative phrase -- does she love him -- who loves him -- whom does she love lincat QCl = Cl ** {focus : {s : Str ; isOcc : Bool}} -- focal IP, whethe</context>
<context position="29749" citStr="Angelov, 2011" startWordPosition="5490" endWordPosition="5491">lexicon (using them as metarules in the sense of GPSG), parsing became several times faster than with the old grammar. An analysis remains to do, but one hypothesis is that the speed-up is due to fixing tense and polarity earlier than in the old RGL: when starting to build VPs, as opposed to when using clauses in full sentences. Dependent types made it easy to test this refactoring, since they reduced the number of rules that had to be written. Robustness. Robustness in GF parsing is achieved by introducing metavariables (“question marks”) when tree nodes cannot be constructed by the grammar (Angelov, 2011). The subtrees under a metavariable node are linearized separately, just like a sequence of chunks. In translation, this leads to decrease in quality, because dependencies between chunks are not detected. The early application of tense and polarity is an improvement, as it makes verb chunks contain information that was previously detected only if the parser managed to build a whole sentence. 7 Conclusion We have shown a GF grammar for predication allowing an unlimited variation of argument lists: an abstract syntax with a concise definition using dependent types, a concrete syntax using a func</context>
</contexts>
<marker>Angelov, 2011</marker>
<rawString>K. Angelov. 2011. The Mechanics of the Grammatical Framework. Ph.D. thesis, Chalmers University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
</authors>
<title>A quasi-arithmetical notation for syntactic description.</title>
<date>1953</date>
<journal>Language,</journal>
<pages>29--27</pages>
<contexts>
<context position="1097" citStr="Bar-Hillel, 1953" startWordPosition="160" endWordPosition="161">d differences between the languages. Equipped with a probabilistic model and a large lexicon, the grammar has also been tested in widecoverage machine translation. The first evaluations show improvements in parsing speed, coverage, and robustness in comparison to earlier GF grammars. The study confirms that dependent types, records, and functors are useful in both engineering and theoretical perspectives. 1 Introduction Predication is the basic level of syntax. In logic, it means building atomic formulas by predicates. In linguistics, it means building sentences by verbs. Categorial grammars (Bar-Hillel, 1953; Lambek, 1958) adapt logical predication to natural language. Thus for instance transitive verbs are categorized as (n\s/n), which is the logical type n → n → s with the information that one argument comes before the verb and the other one after. But most approaches to syntax and semantics, including (Montague, 1974), introduce predicate categories as primitives rather than as function types. Thus transitive verbs are a category of its own, related to logic via a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word ord</context>
</contexts>
<marker>Bar-Hillel, 1953</marker>
<rawString>Y. Bar-Hillel. 1953. A quasi-arithmetical notation for syntactic description. Language, 29:27–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<date>1981</date>
<booktitle>Lectures on Government and Binding. Mouton de Gruyter.</booktitle>
<contexts>
<context position="15737" citStr="Chomsky, 1981" startWordPosition="2819" endWordPosition="2820">ded. The final sentence word order is created as the last step, when converting Cl into S. As Cl is discontinuous, it can be linearized in different orders. In Figure 1, this is used in Finnish for generating the SVO order in declaratives and VSO on questions (with an intervening question particle ko glued to the verb). It also supports the other word 4 orders of Finnish (Karttunen and Kay, 1985). By using an abstract syntax in combination with unordered records, parameters, and functors for the concrete syntax, we follow a kind of a “principles and parameters” approach to language variation (Chomsky, 1981). The actual parameter set for the whole RGL is of course larger than the one shown here. Mathematically, it is possible to treat all differences in concrete syntax by parameters, simply by declaring a new parameter for every lincat and lin rule! But this is both vacuous as a theory and an unnecessary detour in practice. It is more illuminating to keep the functor simple and the set of parameters small. If the functor does not work for a new language, it usually makes more sense to override it than to grow the parameter list, and GF provides a mechanism for this. Opposite to “principles and pa</context>
</contexts>
<marker>Chomsky, 1981</marker>
<rawString>N. Chomsky. 1981. Lectures on Government and Binding. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Coscoy</author>
<author>G Kahn</author>
<author>L Thery</author>
</authors>
<title>Extracting text from proofs.</title>
<date>1995</date>
<booktitle>Proc. Second Int. Conf. on Typed Lambda Calculi and Applications,</booktitle>
<volume>902</volume>
<pages>109--123</pages>
<editor>In M. Dezani-Ciancaglini and G. Plotkin, editors,</editor>
<contexts>
<context position="4947" citStr="Coscoy et al., 1995" startWordPosition="791" endWordPosition="794">or defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level type theory (first introduced in the preface of (Martin-L¨of, 1984); see Chapter 8 of (Ranta, 1994) for more details). Before GF was introduced as an independent formalism in 1998, GF-like applications were built as plugins to ALF (Ranta, 1997). The idea was that the LF defines the tectogrammar, and the plug-in defines the phenogrammar. The intended application was natural language interfaces to formal proof systems, in the style of (Coscoy et al., 1995). GF was born via two additions to the natural language interface idea. The first one was multilinguality: one and the same tectogrammar can be given multiple phenogrammars. The second addition was parsing: the phenogrammar, which was initially just linearization (generating strings from type theoretical formulas), was reversed to rules that parse natural language into type theory. The result was a method for translation, which combines parsing the source language with linearization into the target language. This idea was indeed suggested in (Curry, 1961), and applied before GF in the Rosetta </context>
</contexts>
<marker>Coscoy, Kahn, Thery, 1995</marker>
<rawString>Y. Coscoy, G. Kahn, and L. Thery. 1995. Extracting text from proofs. In M. Dezani-Ciancaglini and G. Plotkin, editors, Proc. Second Int. Conf. on Typed Lambda Calculi and Applications, volume 902 of LNCS, pages 109–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H B Curry</author>
</authors>
<title>Some logical aspects of grammatical structure.</title>
<date>1961</date>
<booktitle>Structure of Language and its Mathematical Aspects: Proceedings of the Twelfth Symposium in Applied Mathematics,</booktitle>
<pages>56--68</pages>
<editor>In Roman Jakobson, editor,</editor>
<publisher>American Mathematical Society.</publisher>
<contexts>
<context position="3891" citStr="Curry, 1961" startWordPosition="629" endWordPosition="630"> abstract syntax can be shared between languages. Section 4 shows how parts of concrete syntax can be shared as well. Section 5 gives the full picture of predication with dependent types and records, also addressing extraction, coordination, and semantics. Section 6 gives preliminary evaluation. Section 7 concludes. 1 Proceedings of the EACL 2014 Workshop on Type Theory and Natural Language Semantics (TTNLS), pages 1–9, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 GF: an executive summary GF belongs to a subfamily of categorial grammars inspired by (Curry, 1961). These grammars make a distinction between tectogrammar, which specifies the syntactic structures (tree-like representations), and phenogrammar, which relates these structures to linear representations, such as sequences of characters, words, or phonemes. Other formalisms in this family include ACG (de Groote, 2001) and Lambda grammars (Muskens, 2001). GF inherits its name from LF, Logical Frameworks, which are type theories used for defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level ty</context>
<context position="5508" citStr="Curry, 1961" startWordPosition="878" endWordPosition="879">roof systems, in the style of (Coscoy et al., 1995). GF was born via two additions to the natural language interface idea. The first one was multilinguality: one and the same tectogrammar can be given multiple phenogrammars. The second addition was parsing: the phenogrammar, which was initially just linearization (generating strings from type theoretical formulas), was reversed to rules that parse natural language into type theory. The result was a method for translation, which combines parsing the source language with linearization into the target language. This idea was indeed suggested in (Curry, 1961), and applied before GF in the Rosetta project (Landsbergen, 1982), which used Montague’s analysis trees as tectogrammar. GF can be seen as a formalization and generalization of Montague grammar. Formalization, because it introduces a formal notation for the linearization rules that in Montague’s work were expressed informally. Generalization, because of multilinguality and also because the type system for analysis trees has dependent types. Following the terminology of programming language theory, the tectogrammar is in GF called the abstract syntax whereas the phenogrammar is called the conc</context>
</contexts>
<marker>Curry, 1961</marker>
<rawString>H. B. Curry. 1961. Some logical aspects of grammatical structure. In Roman Jakobson, editor, Structure of Language and its Mathematical Aspects: Proceedings of the Twelfth Symposium in Applied Mathematics, pages 56–68. American Mathematical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>de Groote</author>
</authors>
<title>Towards Abstract Categorial Grammars.</title>
<date>2001</date>
<booktitle>In Association for Computational Linguistics, 39th Annual Meeting and 10th Conference of the European Chapter,</booktitle>
<pages>148--155</pages>
<location>Toulouse, France,</location>
<marker>de Groote, 2001</marker>
<rawString>Ph. de Groote. 2001. Towards Abstract Categorial Grammars. In Association for Computational Linguistics, 39th Annual Meeting and 10th Conference of the European Chapter, Toulouse, France, pages 148–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Diderichsen</author>
</authors>
<title>Elementcer dansk grammatik.</title>
<date>1962</date>
<location>Gyldendal, København.</location>
<contexts>
<context position="2523" citStr="Diderichsen, 1962" startWordPosition="399" endWordPosition="400">oducing a feature called subcat for verbs. Verbs taking different arguments differ in the subcat feature but share otherwise the characteristic of being verbs. In this paper, we will study the syntax and semantics of predication in GF, Grammatical Framework (Ranta, 2011). We will generalize both over subcategories (as in GPSG and HPSG), and over languages (as customary in GF). We use dependent types to control the application of verbs to legitimate arguments, and records to control the placement of arguments in sentences. The record structure is inspired by the topological model of syntax in (Diderichsen, 1962). The approach is designed to apply to all languages in the GF Resource Grammar Library (RGL, (Ranta, 2009)), factoring out their typological differences in a modular way. We have tested the grammar with four languages from three families: Chinese, English, Finnish, and Swedish. As the implementation reuses old RGL code for all parts but predication, it can be ported to new languages with just a few pages of new GF code. We have also tested it in wide coverage tasks, with a probabilistic tree model and a lexicon of 60,000 lemmas. We will start with an introduction to the abstraction mechanisms</context>
</contexts>
<marker>Diderichsen, 1962</marker>
<rawString>P. Diderichsen. 1962. Elementcer dansk grammatik. Gyldendal, København.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G Pullum</author>
<author>I Sag</author>
</authors>
<title>Generalized Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Basil Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="1838" citStr="Gazdar et al., 1985" startWordPosition="284" endWordPosition="287">/n), which is the logical type n → n → s with the information that one argument comes before the verb and the other one after. But most approaches to syntax and semantics, including (Montague, 1974), introduce predicate categories as primitives rather than as function types. Thus transitive verbs are a category of its own, related to logic via a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word order (e.g. inversion in questions). A drawback is that a grammar may need a large number of categories and rules. In GPSG (Gazdar et al., 1985), and later in HPSG (Pollard and Sag, 1994), this is solved by introducing a feature called subcat for verbs. Verbs taking different arguments differ in the subcat feature but share otherwise the characteristic of being verbs. In this paper, we will study the syntax and semantics of predication in GF, Grammatical Framework (Ranta, 2011). We will generalize both over subcategories (as in GPSG and HPSG), and over languages (as customary in GF). We use dependent types to control the application of verbs to legitimate arguments, and records to control the placement of arguments in sentences. The r</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>G. Gazdar, E. Klein, G. Pullum, and I. Sag. 1985. Generalized Phrase Structure Grammar. Basil Blackwell, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Harper</author>
<author>F Honsell</author>
<author>G Plotkin</author>
</authors>
<title>A Framework for Defining Logics.</title>
<date>1993</date>
<journal>JACM,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="4367" citStr="Harper et al., 1993" startWordPosition="698" endWordPosition="701"> Association for Computational Linguistics 2 GF: an executive summary GF belongs to a subfamily of categorial grammars inspired by (Curry, 1961). These grammars make a distinction between tectogrammar, which specifies the syntactic structures (tree-like representations), and phenogrammar, which relates these structures to linear representations, such as sequences of characters, words, or phonemes. Other formalisms in this family include ACG (de Groote, 2001) and Lambda grammars (Muskens, 2001). GF inherits its name from LF, Logical Frameworks, which are type theories used for defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level type theory (first introduced in the preface of (Martin-L¨of, 1984); see Chapter 8 of (Ranta, 1994) for more details). Before GF was introduced as an independent formalism in 1998, GF-like applications were built as plugins to ALF (Ranta, 1997). The idea was that the LF defines the tectogrammar, and the plug-in defines the phenogrammar. The intended application was natural language interfaces to formal proof systems, in the style of (Coscoy et al., 1995). GF was born via tw</context>
</contexts>
<marker>Harper, Honsell, Plotkin, 1993</marker>
<rawString>R. Harper, F. Honsell, and G. Plotkin. 1993. A Framework for Defining Logics. JACM, 40(1):143–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Karttunen</author>
<author>M Kay</author>
</authors>
<title>Parsing in a free word order language. In</title>
<date>1985</date>
<booktitle>Natural Language Parsing, Psychological, Computational, and Theoretical Perspectives,</booktitle>
<pages>279--306</pages>
<editor>D. Dowty, L. Karttunen, and A. Zwicky, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="15522" citStr="Karttunen and Kay, 1985" startWordPosition="2783" endWordPosition="2786">ussed so far. In clauses (Cl), we continue on similar lines: we keep the subject, the verb, and the object on separate fields. Notice that verb in Cl is a plain string, since the value of Agr gets fixed when the subject is added. The final sentence word order is created as the last step, when converting Cl into S. As Cl is discontinuous, it can be linearized in different orders. In Figure 1, this is used in Finnish for generating the SVO order in declaratives and VSO on questions (with an intervening question particle ko glued to the verb). It also supports the other word 4 orders of Finnish (Karttunen and Kay, 1985). By using an abstract syntax in combination with unordered records, parameters, and functors for the concrete syntax, we follow a kind of a “principles and parameters” approach to language variation (Chomsky, 1981). The actual parameter set for the whole RGL is of course larger than the one shown here. Mathematically, it is possible to treat all differences in concrete syntax by parameters, simply by declaring a new parameter for every lincat and lin rule! But this is both vacuous as a theory and an unnecessary detour in practice. It is more illuminating to keep the functor simple and the set</context>
</contexts>
<marker>Karttunen, Kay, 1985</marker>
<rawString>L. Karttunen and M. Kay. 1985. Parsing in a free word order language. In D. Dowty, L. Karttunen, and A. Zwicky, editors, Natural Language Parsing, Psychological, Computational, and Theoretical Perspectives, pages 279–306. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>The mathematics of sentence structure.</title>
<date>1958</date>
<pages>65--154</pages>
<publisher>American Mathematical Monthly,</publisher>
<contexts>
<context position="1112" citStr="Lambek, 1958" startWordPosition="162" endWordPosition="163">een the languages. Equipped with a probabilistic model and a large lexicon, the grammar has also been tested in widecoverage machine translation. The first evaluations show improvements in parsing speed, coverage, and robustness in comparison to earlier GF grammars. The study confirms that dependent types, records, and functors are useful in both engineering and theoretical perspectives. 1 Introduction Predication is the basic level of syntax. In logic, it means building atomic formulas by predicates. In linguistics, it means building sentences by verbs. Categorial grammars (Bar-Hillel, 1953; Lambek, 1958) adapt logical predication to natural language. Thus for instance transitive verbs are categorized as (n\s/n), which is the logical type n → n → s with the information that one argument comes before the verb and the other one after. But most approaches to syntax and semantics, including (Montague, 1974), introduce predicate categories as primitives rather than as function types. Thus transitive verbs are a category of its own, related to logic via a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word order (e.g. invers</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>J. Lambek. 1958. The mathematics of sentence structure. American Mathematical Monthly, 65:154–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Landsbergen</author>
</authors>
<title>Machine translation based on logically isomorphic Montague grammars.</title>
<date>1982</date>
<booktitle>In COLING-1982.</booktitle>
<contexts>
<context position="5574" citStr="Landsbergen, 1982" startWordPosition="888" endWordPosition="889">born via two additions to the natural language interface idea. The first one was multilinguality: one and the same tectogrammar can be given multiple phenogrammars. The second addition was parsing: the phenogrammar, which was initially just linearization (generating strings from type theoretical formulas), was reversed to rules that parse natural language into type theory. The result was a method for translation, which combines parsing the source language with linearization into the target language. This idea was indeed suggested in (Curry, 1961), and applied before GF in the Rosetta project (Landsbergen, 1982), which used Montague’s analysis trees as tectogrammar. GF can be seen as a formalization and generalization of Montague grammar. Formalization, because it introduces a formal notation for the linearization rules that in Montague’s work were expressed informally. Generalization, because of multilinguality and also because the type system for analysis trees has dependent types. Following the terminology of programming language theory, the tectogrammar is in GF called the abstract syntax whereas the phenogrammar is called the concrete syntax. As in compilers and logical frameworks, the abstract </context>
</contexts>
<marker>Landsbergen, 1982</marker>
<rawString>J. Landsbergen. 1982. Machine translation based on logically isomorphic Montague grammars. In COLING-1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ljungl¨of</author>
</authors>
<title>The Expressivity and Complexity of Grammatical Framework.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Dept. of Computing Science, Chalmers University of Technology and Gothenburg University.</institution>
<note>http://www.cs.chalmers.se/~peb/ pubs/p04-PhD-thesis.pdf.</note>
<marker>Ljungl¨of, 2004</marker>
<rawString>P. Ljungl¨of. 2004. The Expressivity and Complexity of Grammatical Framework. Ph.D. thesis, Dept. of Computing Science, Chalmers University of Technology and Gothenburg University. http://www.cs.chalmers.se/~peb/ pubs/p04-PhD-thesis.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="26534" citStr="Marcus et al., 1993" startWordPosition="4858" endWordPosition="4861">e is a type system that adds a domain argument to NP and VP: cat NP (d : Dom) cat VP (d : Dom)(x : Args) fun PredVP : (d : Dom) -&gt; (x : Args) -&gt;NPd-&gt;VPdx-&gt;Clx The predication rule checks that the NP and the VP have the same domain. 6 Evaluation Coverage. The dependent type system for verbs, verb phrases, and clauses is a generalization of the old Resource Grammar Library (Ranta, 2009), which has a set of hard-wired verb subcategories and a handful of slash categories. While it covers “all usual cases”, many logically possible ones are missing. Some such cases even appear in the Penn treebank (Marcus et al., 1993), requiring extra rules in the GF interpretation of the treebank (Angelov, 2011). An example is a function of type V (c np (c vp O)) -&gt; VPC (c np O) -&gt; VP (c np O) which is used 12 times, for example in This is designed to get the wagons in a circle and defend the smoking franchise. It has been easy to write conversion rules showing that the old coverage is preserved. But it remains future work to see what new cases are covered by the increased generality. 7 1. Extraction. cat QCl (x : Args) -- question clause cat IP -- interrogative phrase -- does she love him -- who loves him -- whom does sh</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Martin-L¨of</author>
</authors>
<title>Intuitionistic Type Theory. Bibliopolis,</title>
<date>1984</date>
<location>Napoli.</location>
<marker>Martin-L¨of, 1984</marker>
<rawString>P. Martin-L¨of. 1984. Intuitionistic Type Theory. Bibliopolis, Napoli.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>Formal Philosophy.</title>
<date>1974</date>
<publisher>Yale University Press,</publisher>
<location>New</location>
<contexts>
<context position="1416" citStr="Montague, 1974" startWordPosition="215" endWordPosition="216">ypes, records, and functors are useful in both engineering and theoretical perspectives. 1 Introduction Predication is the basic level of syntax. In logic, it means building atomic formulas by predicates. In linguistics, it means building sentences by verbs. Categorial grammars (Bar-Hillel, 1953; Lambek, 1958) adapt logical predication to natural language. Thus for instance transitive verbs are categorized as (n\s/n), which is the logical type n → n → s with the information that one argument comes before the verb and the other one after. But most approaches to syntax and semantics, including (Montague, 1974), introduce predicate categories as primitives rather than as function types. Thus transitive verbs are a category of its own, related to logic via a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word order (e.g. inversion in questions). A drawback is that a grammar may need a large number of categories and rules. In GPSG (Gazdar et al., 1985), and later in HPSG (Pollard and Sag, 1994), this is solved by introducing a feature called subcat for verbs. Verbs taking different arguments differ in the subcat feature but sh</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>R. Montague. 1974. Formal Philosophy. Yale University Press, New Haven. Collected papers edited by Richmond Thomason.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M¨uller</author>
</authors>
<title>Continuous or Discontinuous Constituents? A Comparison between Syntactic Analyses for Constituent Order and Their Processing Systems.</title>
<date>2004</date>
<journal>Research on Language and Computation,</journal>
<volume>2</volume>
<issue>2</issue>
<marker>M¨uller, 2004</marker>
<rawString>S. M¨uller. 2004. Continuous or Discontinuous Constituents? A Comparison between Syntactic Analyses for Constituent Order and Their Processing Systems. Research on Language and Computation, 2(2):209–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Muskens</author>
</authors>
<title>Lambda Grammars and the Syntax-Semantics Interface. In</title>
<date>2001</date>
<booktitle>Proceedings of the Thirteenth Amsterdam Colloquium,</booktitle>
<pages>150--155</pages>
<editor>R. van Rooy and M. Stokhof, editors,</editor>
<location>Amsterdam.</location>
<note>http://let.uvt.nl/general/people/ rmuskens/pubs/amscoll.pdf.</note>
<contexts>
<context position="4245" citStr="Muskens, 2001" startWordPosition="678" endWordPosition="679">kshop on Type Theory and Natural Language Semantics (TTNLS), pages 1–9, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 GF: an executive summary GF belongs to a subfamily of categorial grammars inspired by (Curry, 1961). These grammars make a distinction between tectogrammar, which specifies the syntactic structures (tree-like representations), and phenogrammar, which relates these structures to linear representations, such as sequences of characters, words, or phonemes. Other formalisms in this family include ACG (de Groote, 2001) and Lambda grammars (Muskens, 2001). GF inherits its name from LF, Logical Frameworks, which are type theories used for defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level type theory (first introduced in the preface of (Martin-L¨of, 1984); see Chapter 8 of (Ranta, 1994) for more details). Before GF was introduced as an independent formalism in 1998, GF-like applications were built as plugins to ALF (Ranta, 1997). The idea was that the LF defines the tectogrammar, and the plug-in defines the phenogrammar. The intended appl</context>
</contexts>
<marker>Muskens, 2001</marker>
<rawString>R. Muskens. 2001. Lambda Grammars and the Syntax-Semantics Interface. In R. van Rooy and M. Stokhof, editors, Proceedings of the Thirteenth Amsterdam Colloquium, pages 150–155, Amsterdam. http://let.uvt.nl/general/people/ rmuskens/pubs/amscoll.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Newmeyer</author>
</authors>
<title>Against a parameter-setting approach to language variation. Linguistic Variation Yearbook,</title>
<date>2004</date>
<pages>4--181</pages>
<contexts>
<context position="16458" citStr="Newmeyer, 2004" startWordPosition="2947" endWordPosition="2948">it is possible to treat all differences in concrete syntax by parameters, simply by declaring a new parameter for every lincat and lin rule! But this is both vacuous as a theory and an unnecessary detour in practice. It is more illuminating to keep the functor simple and the set of parameters small. If the functor does not work for a new language, it usually makes more sense to override it than to grow the parameter list, and GF provides a mechanism for this. Opposite to “principles and parameters”, this is “a model in which language-particular rules take over the work of parameter settings” (Newmeyer, 2004). A combination of the two models enables language comparison by measuring the amount of overrides. 5 The full predication system So far we have only dealt with one kind of verbs, TV. But we need more: intransitive, ditransitive, sentence-complement, etc. The general verb category is a dependent type, which varies over argument type lists: cat V (x : Args) The list x : Args corresponds to the subcat feature in GPSG and HPSG. Verb phrases and clauses have the same dependencies. Syntactically, a phrase depending on x : Args has “holes” for every argument in the list x. Semantically, it is a func</context>
</contexts>
<marker>Newmeyer, 2004</marker>
<rawString>F. J. Newmeyer. 2004. Against a parameter-setting approach to language variation. Linguistic Variation Yearbook, 4:181–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1881" citStr="Pollard and Sag, 1994" startWordPosition="292" endWordPosition="295">with the information that one argument comes before the verb and the other one after. But most approaches to syntax and semantics, including (Montague, 1974), introduce predicate categories as primitives rather than as function types. Thus transitive verbs are a category of its own, related to logic via a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word order (e.g. inversion in questions). A drawback is that a grammar may need a large number of categories and rules. In GPSG (Gazdar et al., 1985), and later in HPSG (Pollard and Sag, 1994), this is solved by introducing a feature called subcat for verbs. Verbs taking different arguments differ in the subcat feature but share otherwise the characteristic of being verbs. In this paper, we will study the syntax and semantics of predication in GF, Grammatical Framework (Ranta, 2011). We will generalize both over subcategories (as in GPSG and HPSG), and over languages (as customary in GF). We use dependent types to control the application of verbs to legitimate arguments, and records to control the placement of arguments in sentences. The record structure is inspired by the topologi</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. Sag. 1994. Head-Driven Phrase Structure Grammar. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<title>Type Theoretical Grammar.</title>
<date>1994</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="4588" citStr="Ranta, 1994" startWordPosition="734" endWordPosition="735">ic structures (tree-like representations), and phenogrammar, which relates these structures to linear representations, such as sequences of characters, words, or phonemes. Other formalisms in this family include ACG (de Groote, 2001) and Lambda grammars (Muskens, 2001). GF inherits its name from LF, Logical Frameworks, which are type theories used for defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level type theory (first introduced in the preface of (Martin-L¨of, 1984); see Chapter 8 of (Ranta, 1994) for more details). Before GF was introduced as an independent formalism in 1998, GF-like applications were built as plugins to ALF (Ranta, 1997). The idea was that the LF defines the tectogrammar, and the plug-in defines the phenogrammar. The intended application was natural language interfaces to formal proof systems, in the style of (Coscoy et al., 1995). GF was born via two additions to the natural language interface idea. The first one was multilinguality: one and the same tectogrammar can be given multiple phenogrammars. The second addition was parsing: the phenogrammar, which was initia</context>
</contexts>
<marker>Ranta, 1994</marker>
<rawString>A. Ranta. 1994. Type Theoretical Grammar. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<title>Structures grammaticales dans le franc¸ais math´ematique.</title>
<date>1997</date>
<booktitle>Math´ematiques, informatique et Sciences Humaines,</booktitle>
<pages>138--139</pages>
<contexts>
<context position="4733" citStr="Ranta, 1997" startWordPosition="758" endWordPosition="759">cters, words, or phonemes. Other formalisms in this family include ACG (de Groote, 2001) and Lambda grammars (Muskens, 2001). GF inherits its name from LF, Logical Frameworks, which are type theories used for defining logics (Harper et al., 1993). GF builds on the LF called ALF, Another Logical Framework (Magnusson, 1994), which implements MartinL¨of’s higher-level type theory (first introduced in the preface of (Martin-L¨of, 1984); see Chapter 8 of (Ranta, 1994) for more details). Before GF was introduced as an independent formalism in 1998, GF-like applications were built as plugins to ALF (Ranta, 1997). The idea was that the LF defines the tectogrammar, and the plug-in defines the phenogrammar. The intended application was natural language interfaces to formal proof systems, in the style of (Coscoy et al., 1995). GF was born via two additions to the natural language interface idea. The first one was multilinguality: one and the same tectogrammar can be given multiple phenogrammars. The second addition was parsing: the phenogrammar, which was initially just linearization (generating strings from type theoretical formulas), was reversed to rules that parse natural language into type theory. T</context>
</contexts>
<marker>Ranta, 1997</marker>
<rawString>A. Ranta. 1997. Structures grammaticales dans le franc¸ais math´ematique. Math´ematiques, informatique et Sciences Humaines, 138/139:5–56/5–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<date>2004</date>
<booktitle>Computational Semantics in Type Theory. Mathematics and Social Sciences,</booktitle>
<pages>165--31</pages>
<contexts>
<context position="25774" citStr="Ranta, 2004" startWordPosition="4724" endWordPosition="4725">instance, the basic VP denotation type is Ent -&gt; Prop, and the type for an arbitrary subcategory of VP x is (x : Args) -&gt; Den x (Ent -&gt; Prop) where Den is a type family defined recursively over Args, Den : Args -&gt; Type -&gt; Type Den O t = t Den (c np xs) t = Ent -&gt; Den xs t Den (c cl xs) t = Prop -&gt; Den xs t and so on for all values of Arg. The second argument t varies over the basic denotation types of VP, AP, Adv, and CN. Montague-style semantics is readily available for all rules operating on these categories. As a logical framework, GF has the expressive power needed for defining semantics (Ranta, 2004). The types can moreover be extended to express selectional restrictions, where verb arguments are restricted to domains of individuals. Here is a type system that adds a domain argument to NP and VP: cat NP (d : Dom) cat VP (d : Dom)(x : Args) fun PredVP : (d : Dom) -&gt; (x : Args) -&gt;NPd-&gt;VPdx-&gt;Clx The predication rule checks that the NP and the VP have the same domain. 6 Evaluation Coverage. The dependent type system for verbs, verb phrases, and clauses is a generalization of the old Resource Grammar Library (Ranta, 2009), which has a set of hard-wired verb subcategories and a handful of slash</context>
</contexts>
<marker>Ranta, 2004</marker>
<rawString>A. Ranta. 2004. Computational Semantics in Type Theory. Mathematics and Social Sciences, 165:31– 57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<date>2009</date>
<booktitle>The GF Resource Grammar Library. Linguistics in Language Technology,</booktitle>
<volume>2</volume>
<pages>214--158</pages>
<contexts>
<context position="2630" citStr="Ranta, 2009" startWordPosition="418" endWordPosition="419">e otherwise the characteristic of being verbs. In this paper, we will study the syntax and semantics of predication in GF, Grammatical Framework (Ranta, 2011). We will generalize both over subcategories (as in GPSG and HPSG), and over languages (as customary in GF). We use dependent types to control the application of verbs to legitimate arguments, and records to control the placement of arguments in sentences. The record structure is inspired by the topological model of syntax in (Diderichsen, 1962). The approach is designed to apply to all languages in the GF Resource Grammar Library (RGL, (Ranta, 2009)), factoring out their typological differences in a modular way. We have tested the grammar with four languages from three families: Chinese, English, Finnish, and Swedish. As the implementation reuses old RGL code for all parts but predication, it can be ported to new languages with just a few pages of new GF code. We have also tested it in wide coverage tasks, with a probabilistic tree model and a lexicon of 60,000 lemmas. We will start with an introduction to the abstraction mechanisms of GF and conclude with a summary of some recent research. Section 2 places GF on the map of grammar forma</context>
<context position="26301" citStr="Ranta, 2009" startWordPosition="4820" endWordPosition="4821">al framework, GF has the expressive power needed for defining semantics (Ranta, 2004). The types can moreover be extended to express selectional restrictions, where verb arguments are restricted to domains of individuals. Here is a type system that adds a domain argument to NP and VP: cat NP (d : Dom) cat VP (d : Dom)(x : Args) fun PredVP : (d : Dom) -&gt; (x : Args) -&gt;NPd-&gt;VPdx-&gt;Clx The predication rule checks that the NP and the VP have the same domain. 6 Evaluation Coverage. The dependent type system for verbs, verb phrases, and clauses is a generalization of the old Resource Grammar Library (Ranta, 2009), which has a set of hard-wired verb subcategories and a handful of slash categories. While it covers “all usual cases”, many logically possible ones are missing. Some such cases even appear in the Penn treebank (Marcus et al., 1993), requiring extra rules in the GF interpretation of the treebank (Angelov, 2011). An example is a function of type V (c np (c vp O)) -&gt; VPC (c np O) -&gt; VP (c np O) which is used 12 times, for example in This is designed to get the wagons in a circle and defend the smoking franchise. It has been easy to write conversion rules showing that the old coverage is preserv</context>
<context position="28218" citStr="Ranta, 2009" startWordPosition="5228" endWordPosition="5229"> buy fun ContClC : (x : Args) -&gt; Cl x -&gt; ClC x -&gt; ClC x -- you steal, he sells and I buy fun UseClC : (x : Args) -&gt; ClC x -&gt; Cl x -- [use ClC as Cl] Figure 3: Extraction and coordination. fun QuestCl : (x : Args) -&gt; Cl x -&gt; QCl x fun QuestVP : (x : Args) -&gt; IP -&gt; VP x -&gt; QCl x fun QuestSlash : (x : Args) -&gt; IP -&gt; QCl (c np x) -&gt; QCl x Multilinguality. How universal are the concrete syntax functor and interface? In the standard RGL, functorization has only been attempted for families of closely related languages, with Romance languages sharing 75% of syntax code and Scandinavian languages 85% (Ranta, 2009). The new predication grammar shares code across all languages. The figure to compare is the percentage of shared code (abstract syntax + functor + interface) of the total code written for a particular language (shared + language-specific). This percentage is 70 for Chinese, 64 for English, 61 for Finnish, and 76 for Swedish, when calculated as lines of code. The total amount of shared code is 760 lines. One example of overrides is negation and questions in English, which are complicated by the need of auxiliaries for some verbs (go) but not for others (be). This explains why Swedish shares mo</context>
</contexts>
<marker>Ranta, 2009</marker>
<rawString>A. Ranta. 2009. The GF Resource Grammar Library. Linguistics in Language Technology, 2. http://elanguage.net/journals/index. php/lilt/article/viewFile/214/158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<title>Grammatical Framework: Programming with Multilingual Grammars.</title>
<date>2011</date>
<publisher>CSLI Publications, Stanford.</publisher>
<contexts>
<context position="2176" citStr="Ranta, 2011" startWordPosition="343" endWordPosition="344">a semantic rule. This gives more expressive power, as it permits predicates with different syntactic properties and variable word order (e.g. inversion in questions). A drawback is that a grammar may need a large number of categories and rules. In GPSG (Gazdar et al., 1985), and later in HPSG (Pollard and Sag, 1994), this is solved by introducing a feature called subcat for verbs. Verbs taking different arguments differ in the subcat feature but share otherwise the characteristic of being verbs. In this paper, we will study the syntax and semantics of predication in GF, Grammatical Framework (Ranta, 2011). We will generalize both over subcategories (as in GPSG and HPSG), and over languages (as customary in GF). We use dependent types to control the application of verbs to legitimate arguments, and records to control the placement of arguments in sentences. The record structure is inspired by the topological model of syntax in (Diderichsen, 1962). The approach is designed to apply to all languages in the GF Resource Grammar Library (RGL, (Ranta, 2009)), factoring out their typological differences in a modular way. We have tested the grammar with four languages from three families: Chinese, Engl</context>
</contexts>
<marker>Ranta, 2011</marker>
<rawString>A. Ranta. 2011. Grammatical Framework: Programming with Multilingual Grammars. CSLI Publications, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Seki</author>
<author>T Matsumura</author>
<author>M Fujii</author>
<author>T Kasami</author>
</authors>
<title>On multiple context-free grammars.</title>
<date>1991</date>
<journal>Theoretical Computer Science,</journal>
<pages>88--191</pages>
<contexts>
<context position="6393" citStr="Seki et al., 1991" startWordPosition="1006" endWordPosition="1009">ation rules that in Montague’s work were expressed informally. Generalization, because of multilinguality and also because the type system for analysis trees has dependent types. Following the terminology of programming language theory, the tectogrammar is in GF called the abstract syntax whereas the phenogrammar is called the concrete syntax. As in compilers and logical frameworks, the abstract syntax encodes the structure relevant for semantics, whereas the concrete syntax defines “syntactic sugar”. The resulting system turned out to be equivalent to parallel multiple context-free grammars (Seki et al., 1991) and therefore parsable in polynomial time (Ljungl¨of, 2004). Comprehensive grammars have been written for 29 languages, and later work has optimized GF parsing and also added probabilistic disambiguation and robustness, resulting in state-of-the-art performance in wide-coverage deep parsing (Angelov, 2011; Angelov and Ljungl¨of, 2014). 3 Example: subject-verb-object sentences Let us start with an important special case of predication: the subject-verb-object structure. The simplest possible rule is fun PredTV : NP -&gt; TV -&gt; NP -&gt; S that is, a function that takes a subject NP, a transitive verb</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991. On multiple context-free grammars. Theoretical Computer Science, 88:191–229.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>