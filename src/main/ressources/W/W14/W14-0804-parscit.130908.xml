<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001352">
<title confidence="0.982934">
The Relevance of Collocations for Parsing
</title>
<author confidence="0.995713">
Eric Wehrli
</author>
<affiliation confidence="0.984352">
LATL-CUI
University of Geneva
</affiliation>
<email confidence="0.993014">
Eric.Wehrli@unige.ch
</email>
<sectionHeader confidence="0.993715" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992460705882353">
Although multiword expressions
(MWEs) have received an increasing
amount of attention in the NLP com-
munity over the last two decades, few
papers have been dedicated to the spe-
cific problem of the interaction between
MWEs and parsing. In this paper, we will
discuss how the collocation identification
task has been integrated in our rule-
based parser and show how collocation
knowledge has a positive impact on the
parsing process. A manual evaluation
has been conducted over a corpus of
4000 sentences, comparing outputs of
the parser used with and without the
collocation component. Results of the
evaluation clearly support our claim.
</bodyText>
<sectionHeader confidence="0.99912" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999929366666667">
Collocations and more generally multiword ex-
pressions (MWEs) have received a large and in-
creasing amount of attention in the NLP com-
munity over the last two decades, as attested
by the number of workshops, special interest
groups, and –of course– publications. The im-
portance of this phenomenon is now clearly rec-
ognized within the NLP community.
It is fair to say that collocation extraction has
been the main focus of attention, and a great
deal of research has been devoted to developing
techniques for collocation extraction from cor-
pora (Church &amp; Hanks, 1990; Smadja, 1993;
Evert, 2004; Seretan &amp; Wehrli, 2009, among
many others). Much less attention has been paid
to the interaction between collocations and the
parsing process1. In this paper, we will argue (i)
that collocation detection should be considered
as a component of the parsing process, and (ii)
that contrary to a common view, collocations
(and more generally MWEs) do not constitute
a problem or a hurdle for NLP (cf. Green et al.,
2011; Sag et al., 2002), but rather have a posi-
tive impact on parsing results.
Section 2 shows how collocation identifica-
tion has been integrated into the parsing pro-
cess. An evaluation which compares the re-
sults of the parse of a corpus with and without
the collocation identification component will be
discussed in section 3.
</bodyText>
<sectionHeader confidence="0.95183" genericHeader="method">
2 Parsing collocations
</sectionHeader>
<bodyText confidence="0.959929909090909">
That syntactic information is useful – indeed
necessary – for a proper identification of collo-
cations is widely acknowledged by now. More
controversial, however, is the dual point, that is
1Preprocessing, that is, the detection of MWEs during
tokenisation (ie. before parsing) is used in several sys-
tems – for instance, ParGram (Butt et al., 1999), or more
recently, Talismane (Urieli, 2013). However, this tech-
nique can only be successfully applied to MWEs whose
components are adjacent (or near-adjacent), leaving aside
most of the cases that will be discussed below.
</bodyText>
<page confidence="0.954297">
26
</page>
<note confidence="0.438519">
Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 26–32,
Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.987552561643836">
that collocation identification is useful for pars-
ing.
Several researchers (cf. Seretan et al., 2009;
Seretan, 2011, and references given there) have
convincingly argued that collocation identifica-
tion crucially depends on precise and detailed
syntactic information. One main argument sup-
porting that view is the fact that in some col-
locations, the two constituents can be far away
from each other, or in reverse order, depend-
ing on grammatical processes such as extraposi-
tion, relativization, passive, etc. Based on such
considerations, we developed a collocation ex-
traction system based on our Fips multilingual
rule-based parser(cf. Wehrli, 2007; Wehrli et
al., 2010). Although quite satisfactory in terms
of extraction precision, we noticed some short-
comings in terms of recall, due to the fact that
the parser would not always return the most ap-
propriate structure. A closer examination of
some of the cases where the parser failed to
return the structure containing a collocation –
and therefore failed to identify it – showed that
heuristics had (wrongly) favoured an alternative
structure. Had the parser known that there was
a collocation, the correct structure could have
received a higher score.
These observations led us to revise our po-
sition and consider that parsing and the identi-
fication of collocations are in fact interrelated
tasks. Not only does collocation identifica-
tion rely on syntactic dependencies, and thus on
parsed data, but the parser can fruitfully use col-
locational knowledge to favour some analyses
over competing ones. A new version of the Fips
parser has since been developed, in which col-
locations are identified as soon as the relevant
structure is computed, that is as soon as the sec-
ond term of the collocation is attached to the
structure.
The collocation identification process is trig-
gered by the (left or right) attachment of a
lexical element marked [+partOfCollocation]2.
Governing nodes are iteratively considered,
halting at the first node of major category (noun,
verb, adjective, adverb). If that second node
is itself marked [+partOfCollocation], then we
check whether the two terms correspond to a
known collocation.
Consider first some simple cases, as illus-
trated in (1).
(1)a. He had no loose change.
b. Paul took up a new challenge.
The collocation loose change in sentence (1a)
is identified when the adjective loose is (left-)
attached to the noun change. Both elements are
lexically marked [+partOfCollocation], the pro-
cedure looked up the collocation database for
a [ NP [ AP loose ] change ] collocation. In
the second example (1b), the procedure is trig-
gered by the attachment of the noun challenge
to the determiner phrase (DP) a, which is al-
ready attached as direct object subconstituent
of the verb took (up). As pointed out above,
the procedure checks the governing nodes un-
til finding a node of major category – in this
case the verb. Both the verb and the noun are
marked [+partOfCollocation], so that the pro-
cedure looks up the database for a collocation
of type verb-direct object.
Let us now turn to somewhat more complex
cases, such as the ones illustrated (2):
(2)a. Which record did Paul break?
</bodyText>
<listItem confidence="0.9158846">
b. The record Paul has just broken was very
old.
c. This record seems difficult to break.
d. This record, Paul will break at the next
Olympic Games.
</listItem>
<footnote confidence="0.763820666666667">
2The collocation identification process only concerns
lexicalized collocations, that is collocations that we have
entered into the parser’s lexical database.
</footnote>
<page confidence="0.988372">
27
</page>
<listItem confidence="0.823621333333333">
e. Which record did Paul consider difficult to
break?
f. The record will be broken.
g. The record is likely to be broken.
h. Ce d´efi, Jean le consid`ere comme difficile
a` relever.
</listItem>
<bodyText confidence="0.990131176470589">
”This challenge, Jean considers [it] as dif-
ficult to take up”
Sentence (2a) is a wh-interrogative clause,
in which the direct object constituent occurs
at the beginning of the sentence. Assuming
a generative grammar analysis, we consider
that such preposed constituents are connected
to so-called canonical positions. In this case,
the fronted element being a direct object, the
canonical position is the typical direct object
position in an English declarative sentence, that
is a postverbal DP position immediately dom-
inated by the VP node. The parser establishes
such a link and returns the structure below,
where [ DP e]i stands for the empty category
(the ”trace”) of the preposed constituent which
record.
</bodyText>
<listItem confidence="0.9930885">
(3) [CP [ DP which record]i ] did [TP [DP Paul
] break [ DP e]i ]
</listItem>
<bodyText confidence="0.9884055">
In such cases, the collocation identification
process is triggered by the insertion of the
empty constituent in the direct object position
of the verb. Since the empty constituent is con-
nected to the preposed constituent, such exam-
ples can be easily treated as a minor variant of
case (1b).
All so-called wh-constructions3 are treated in
a similar fashion, that is relative clause (2b) and
topicalization (2c). Sentence (2d) concerns the
tough-movement construction, that is construc-
tions involving adjectives such as tough, easy,
</bodyText>
<footnote confidence="0.6261665">
3See Chomsky (1977) for a general analysis of wh-
constructions.
</footnote>
<bodyText confidence="0.999840571428572">
difficult, etc. governing an infinitival clause. In
such constructions, the matrix subject is con-
strued as the direct object of the infinitival verb.
In dealing with such structures, the parser will
hypothesize an abstract wh-operator in the spec-
ifier position of the infinitival clause, which
is linked to the matrix subject. Like all wh-
constituents, the abstract operator will itself be
connected to an empty constituent later on in the
analysis, giving rise to a chain connecting the
subject of the main clause and the direct object
position of the infinitival clause. The structure
as computed by the parser is given in (4), with
the chain marked by the index i.
</bodyText>
<listItem confidence="0.878398">
(4) [TP [ DP this record]i seems [AP difficult
</listItem>
<bodyText confidence="0.940732583333333">
[CP [ DP e]i [TP to [VP break [ DP e]i ] ] ]
] ]
Finally, examples (2f,g) concern the passive
construction, in which we assume that the direct
object is promoted to the subject position. In
the tradition of generative grammar, we could
say that the ”surface” subject is interpreted as
the ”deep” direct object of the verb. Given such
an analysis of passive, the parser will connect
the subject constituent of a passive verb with an
empty constituent in direct object position, as
illustrated in (5).
</bodyText>
<listItem confidence="0.9580545">
(5) [TP [DP the record]i will [VP be [VP broken
[ DP e]i ] ] ]
</listItem>
<bodyText confidence="0.999612285714286">
The detection of a verb-object collocation in
a passive sentence is thus triggered by the inser-
tion of the empty constituent in direct object po-
sition. The collocation identification procedure
checks whether the antecedent of the (empty)
direct object and the verb constitute a (verb-
object) collocation.
</bodyText>
<subsectionHeader confidence="0.967662">
2.1 Why collocations help
</subsectionHeader>
<bodyText confidence="0.999947">
The parser can benefit from collocation knowl-
edge in two ways. The improvement comes ei-
ther from a better choice of lexical element (in
</bodyText>
<page confidence="0.993054">
28
</page>
<bodyText confidence="0.974010019607843">
case of ambiguous words), or from a more fe-
licitous phrase attachment. Both cases are illus-
trated below, by means of examples taken from
our evaluation corpus. Consider first colloca-
tions of the noun-noun type containing syntac-
tically ambiguous words (in the sense that they
can be assigned more than one lexical category)
as in (6):
(6)a. balancing act
eating habits
nursing care
living standards
working conditions
b. austerity measures
opinion polls
tax cuts
protest marches
As illustrated by Chomsky’s famous example
Flying planes can be dangerous, -ing forms of
English transitive verbs are quite systematically
ambiguous, between a verbal reading (gerund)
and an adjectival reading (participle use). The
examples given in (6a) are all cases of colloca-
tions involving a present participle modifying a
noun. All those examples were wrongly inter-
preted as gerunds by the parser running without
the collocation identification procedure. The
noun-noun collocations in (6b) all have a noun
head which is ambiguous between a nominal
and a verbal reading. Such examples were
also wrongly interpreted with the verbal read-
ing when parsed without the identification pro-
cedure.
The second way in which collocational
knowledge can help the parser has to do with
structural ambiguities. This concerns particu-
larly collocations which include a prepositional
phrase, such as the noun-preposition-noun col-
locations, as in (7):
(7) bone of contention
state of emergency
struggle for life
flag of convenience
The attachment of prepositional phrases is
known to be a very difficult task for parsers (cf.
Church &amp; Patil, 1982). So, knowing that a par-
ticular prepositional phrase is part of a colloca-
tion (and giving priority to such analyses con-
taining collocations over other possible analy-
ses) is an effective way to solve many cases of
PP attachments.
</bodyText>
<sectionHeader confidence="0.998721" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.952603">
To evaluate the effect of collocational knowl-
edge on parsing, we compared the results pro-
duced by the parser with and without the col-
location identification procedure. The corpus
used for this evaluation consists of 56 arti-
cles taken from the magazine The Economist,
corresponding to almost 4000 sentences. We
first compared the number of complete analy-
ses achieved by both runs, with the results in
Figure 14:
</bodyText>
<figure confidence="0.4478075">
with collocations without collocations
70.3% 69.2%
</figure>
<figureCaption confidence="0.999875">
Figure 1: Percentage of complete analyses
</figureCaption>
<bodyText confidence="0.999932272727273">
Although the number of complete parses
(sentences for which the parser can assign a
complete structure) varies very slightly (a little
more than a percent point better for the version
with collocation identification, at 70.3%), the
content of the analyses may differ in significant
ways, as the next evaluation will show.
A manual evaluation of the results was con-
ducted over the corpus, using a specific user in-
terface. To simplify the evaluation, we selected
the POS-tagging mode of the parser, and further
</bodyText>
<footnote confidence="0.964774">
4By complete analysis, we mean a single constituent
covering the whole sentence. When the Fips parser fails
to achieve a complete analysis, it returns a sequence of
chunks (usually 2 or 3) covering the whole sentence.
</footnote>
<page confidence="0.99764">
29
</page>
<figure confidence="0.6588465">
diff. diff N vs V with coll. without coll.
416 148 116 32
</figure>
<figureCaption confidence="0.997476">
Figure 3: Differences with and without collocation
</figureCaption>
<bodyText confidence="0.998220882352941">
restricted the output to the triple (word, pos-tag,
position)5. For the POS tagset, we opted for the
universal tagset (cf. Petrov et al., 2012). Both
output files could then easily be manually com-
pared using a specific user interface as illus-
trated in figure 2 below, where differences are
displayed in red.
Notice that in order to facilitate the manual
evaluation, we only took into account differ-
ences involving the NOUN and VERB tags. In
the screenshot the two result files are displayed,
on the left the results obtained by the parser
with (W) the collocation identification compo-
nent, on the right the results obtained with the
parser without (WO) the collocation identifica-
tion component. For each file, one line contains
the input lexical item (simple word or com-
pound), its tag, and its position with respect to
the beginning of file (article). Differences (re-
stricted here to NOUN vs VERB tags) between
the two files are indicated in red. For each dif-
ference, the user selects the best choice, using
the Better left or Better right button or the
Skip button if the difference is irrelevant (or if
neither tag is correct). After each choice, the
next difference is immediately displayed.
The results are given in figure 3. Column 1
gives the total number of differences, column
2 the number of differences for the NOUN vs
VERB tags, columns 3 and 4 show how many
times the result (NOUN / VERB) is better with
the collocation component (column 3) or with-
out it (column 4).
This manual evaluation clearly shows that
</bodyText>
<footnote confidence="0.9520295">
5Using Fips in POS-tagging mode only means that the
output will restricted to word and POS-tags. The analysis
itself is identical whether we use Fips in parsing mode or
in Pos-tagging mode.
</footnote>
<bodyText confidence="0.999900347826087">
the quality of the parses improves significantly
when the parser ”knows” about collocations,
that is when collocation detection takes place
during the parse. The comparison of the results
obtained with and without collocation knowl-
edge shows a total 416 differences of POS-tags,
of which 148 concern the difference between
Noun vs Verb tags. In 116 cases (nearly 80%)
the choice was better when the parser had collo-
cational knowledge, while in 32 cases (approx.
21%) the choice was better without the colloca-
tional knowledge.
The fact that in a little over 20% of the cases
the parser makes a better choice without col-
locational knowledge may seem a bit odd or
counter-intuitive. Going through several such
cases revealed that in all of them, the parser
could not achieve a full parse and returned a se-
quence of chunks. It turns out that in its current
state, the Fips parser does not use collocational
knowledge to rank chunks. Nor can it iden-
tify collocations that spread over two chunks.
Clearly something to be updated.
</bodyText>
<sectionHeader confidence="0.960986" genericHeader="method">
4 Concluding remarks and future
work
</sectionHeader>
<bodyText confidence="0.999891875">
In this paper, we have argued that collocation
identification and parsing should be viewed as
interrelated tasks. One the one hand, colloca-
tion identification relies on precise and detailed
syntactic information, while on the other hand
the parser can fruitfully use collocation knowl-
edge in order to rank competing analyses and,
more interestingly, to disambiguate some other-
wise difficult cases.
This preliminary study focused primarily on
the NOUN vs VERB ambiguity, an ambiguity
which is very common in English and which
may have a devastating effect when the wrong
reading is chosen. For instance, in a translation
task, such mistakes are very likely to lead to in-
comprehensible results.
</bodyText>
<page confidence="0.995697">
30
</page>
<figureCaption confidence="0.984291">
Figure 2: Manual evaluation user interface
</figureCaption>
<page confidence="0.999473">
31
</page>
<bodyText confidence="0.9999274">
In future work, we intend (i) to perform a
evaluation over a much larger corpus, (ii) to take
into account all types of collocations, and (iii) to
consider other languages, such as French, Ger-
man or Italian.
</bodyText>
<sectionHeader confidence="0.999728" genericHeader="references">
5 References
</sectionHeader>
<reference confidence="0.999554733333333">
Butt, M., T.H. King, M.-E. Ni˜no &amp; F. Segond,
1999. A Grammar Writer’s Cookbook,
Stanford, CSLI Publications.
Church, K. &amp; P. Hanks, 1990. “Word as-
sociation norms, mutual information, and
lexicography”, Computational Linguistics
16(1), 22-29.
Church, K. &amp; R. Patil, 1982. “Coping with Syn-
tactic Ambiguity or How to Put the Block
in the Box on the Table”, American Journal
of Computational Linguistics, vol. 8, num-
ber 3-4, 139-150.
Chomsky, N. 1977. “On Wh-Movement”,
in Peter Culicover, Thomas Wasow, and
Adrian Akmajian, eds., Formal Syntax,
New York: Academic Press, 71-132.
Evert, S., 2004. The Statistics of Word
Cooccurrences: Word Pairs and Colloca-
tions, PhD dissertation, IMS, University of
Stuttgart.
Green S., M.-C. de Marneffe, J. Bauer &amp;
Ch.D. Manning, 2011. ”Multiword Ex-
pression Identification with Tree Substitu-
tion Grammars: A Parsing tour de force
with French”, Proceedings of the 2011
Conference on Empirical Methods in Nat-
ural Language Processing, 725-735.
Petrov, S., D. Das &amp; R. McDonald, 2012.
“A Universal Part-of-Speech Tagset”, Pro-
ceedings of LREC-2011.
Sag, I., T. Baldwin, F. Bond, A. Copestake &amp;
D. Flickinger (2002), ”Multiword Expres-
sions: A Pain in the Neck for NLP”, Pro-
ceedings of Cicling 2002, Springer-Verlag.
Seretan, V., 2011. Syntax-Based Collocation
Extraction, Springer Verlag.
Seretan, V. &amp; E. Wehrli, 2009. “Multilin-
gual Collocation Extraction with a Syntac-
tic Parser”, Language Resources and Eval-
uation 43:1, 71-85.
Smadja, F., 1993. “Retrieving collocations from
text: Xtract”, Computational Linguistics
19(1), 143-177.
Urieli, A., 2013. Robust French Syntax
Analysis: reconciling statistical meth-
ods and linguistic knowledge in the Tal-
ismane toolkit, PhD dissertation, Uni-
versity of Toulouse. [http://redac.univ-
tlse2.fr/applications/talismane/biblio/
URIELI-thesis-2013.pdf]
Wehrli, E., 2007. “Fips, a deep linguistic multi-
lingual parser” in Proceedings of the ACL
2007 Workshop on Deep Linguistic Pro-
cessing, Prague, Czech Republic, 120-127.
Wehrli, E., V. Seretan &amp; L. Nerima, 2010. “Sen-
tence Analysis and Collocation Identifi-
cation” in Proceedings of the Workshop
on Multiword Expressions: from The-
ory to Applications (MWE 2010), Beijing,
China, 27-35.
</reference>
<page confidence="0.999294">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.530256">
<title confidence="0.999992">The Relevance of Collocations for Parsing</title>
<author confidence="0.993395">Eric</author>
<affiliation confidence="0.998656">University of</affiliation>
<email confidence="0.541991">Eric.Wehrli@unige.ch</email>
<abstract confidence="0.999156277777778">Although multiword expressions (MWEs) have received an increasing amount of attention in the NLP community over the last two decades, few papers have been dedicated to the specific problem of the interaction between MWEs and parsing. In this paper, we will discuss how the collocation identification task has been integrated in our rulebased parser and show how collocation knowledge has a positive impact on the parsing process. A manual evaluation has been conducted over a corpus of 4000 sentences, comparing outputs of the parser used with and without the collocation component. Results of the evaluation clearly support our claim.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Butt</author>
<author>T H King</author>
<author>M-E Ni˜no</author>
<author>F Segond</author>
</authors>
<title>A Grammar Writer’s Cookbook,</title>
<date>1999</date>
<publisher>Publications.</publisher>
<location>Stanford, CSLI</location>
<marker>Butt, King, Ni˜no, Segond, 1999</marker>
<rawString>Butt, M., T.H. King, M.-E. Ni˜no &amp; F. Segond, 1999. A Grammar Writer’s Cookbook, Stanford, CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography”,</title>
<date>1990</date>
<journal>Computational Linguistics</journal>
<volume>16</volume>
<issue>1</issue>
<pages>22--29</pages>
<contexts>
<context position="1328" citStr="Church &amp; Hanks, 1990" startWordPosition="208" endWordPosition="211">the evaluation clearly support our claim. 1 Introduction Collocations and more generally multiword expressions (MWEs) have received a large and increasing amount of attention in the NLP community over the last two decades, as attested by the number of workshops, special interest groups, and –of course– publications. The importance of this phenomenon is now clearly recognized within the NLP community. It is fair to say that collocation extraction has been the main focus of attention, and a great deal of research has been devoted to developing techniques for collocation extraction from corpora (Church &amp; Hanks, 1990; Smadja, 1993; Evert, 2004; Seretan &amp; Wehrli, 2009, among many others). Much less attention has been paid to the interaction between collocations and the parsing process1. In this paper, we will argue (i) that collocation detection should be considered as a component of the parsing process, and (ii) that contrary to a common view, collocations (and more generally MWEs) do not constitute a problem or a hurdle for NLP (cf. Green et al., 2011; Sag et al., 2002), but rather have a positive impact on parsing results. Section 2 shows how collocation identification has been integrated into the parsi</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, K. &amp; P. Hanks, 1990. “Word association norms, mutual information, and lexicography”, Computational Linguistics 16(1), 22-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>R Patil</author>
</authors>
<title>Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table”,</title>
<date>1982</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>8</volume>
<pages>3--4</pages>
<contexts>
<context position="11252" citStr="Church &amp; Patil, 1982" startWordPosition="1824" endWordPosition="1827">head which is ambiguous between a nominal and a verbal reading. Such examples were also wrongly interpreted with the verbal reading when parsed without the identification procedure. The second way in which collocational knowledge can help the parser has to do with structural ambiguities. This concerns particularly collocations which include a prepositional phrase, such as the noun-preposition-noun collocations, as in (7): (7) bone of contention state of emergency struggle for life flag of convenience The attachment of prepositional phrases is known to be a very difficult task for parsers (cf. Church &amp; Patil, 1982). So, knowing that a particular prepositional phrase is part of a collocation (and giving priority to such analyses containing collocations over other possible analyses) is an effective way to solve many cases of PP attachments. 3 Evaluation To evaluate the effect of collocational knowledge on parsing, we compared the results produced by the parser with and without the collocation identification procedure. The corpus used for this evaluation consists of 56 articles taken from the magazine The Economist, corresponding to almost 4000 sentences. We first compared the number of complete analyses a</context>
</contexts>
<marker>Church, Patil, 1982</marker>
<rawString>Church, K. &amp; R. Patil, 1982. “Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table”, American Journal of Computational Linguistics, vol. 8, number 3-4, 139-150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chomsky</author>
</authors>
<title>On Wh-Movement”,</title>
<date>1977</date>
<pages>71--132</pages>
<editor>in Peter Culicover, Thomas Wasow, and Adrian Akmajian, eds., Formal Syntax,</editor>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="7851" citStr="Chomsky (1977)" startWordPosition="1267" endWordPosition="1268">) [CP [ DP which record]i ] did [TP [DP Paul ] break [ DP e]i ] In such cases, the collocation identification process is triggered by the insertion of the empty constituent in the direct object position of the verb. Since the empty constituent is connected to the preposed constituent, such examples can be easily treated as a minor variant of case (1b). All so-called wh-constructions3 are treated in a similar fashion, that is relative clause (2b) and topicalization (2c). Sentence (2d) concerns the tough-movement construction, that is constructions involving adjectives such as tough, easy, 3See Chomsky (1977) for a general analysis of whconstructions. difficult, etc. governing an infinitival clause. In such constructions, the matrix subject is construed as the direct object of the infinitival verb. In dealing with such structures, the parser will hypothesize an abstract wh-operator in the specifier position of the infinitival clause, which is linked to the matrix subject. Like all whconstituents, the abstract operator will itself be connected to an empty constituent later on in the analysis, giving rise to a chain connecting the subject of the main clause and the direct object position of the infi</context>
</contexts>
<marker>Chomsky, 1977</marker>
<rawString>Chomsky, N. 1977. “On Wh-Movement”, in Peter Culicover, Thomas Wasow, and Adrian Akmajian, eds., Formal Syntax, New York: Academic Press, 71-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations,</title>
<date>2004</date>
<institution>University of Stuttgart.</institution>
<note>PhD dissertation, IMS,</note>
<contexts>
<context position="1355" citStr="Evert, 2004" startWordPosition="214" endWordPosition="215">laim. 1 Introduction Collocations and more generally multiword expressions (MWEs) have received a large and increasing amount of attention in the NLP community over the last two decades, as attested by the number of workshops, special interest groups, and –of course– publications. The importance of this phenomenon is now clearly recognized within the NLP community. It is fair to say that collocation extraction has been the main focus of attention, and a great deal of research has been devoted to developing techniques for collocation extraction from corpora (Church &amp; Hanks, 1990; Smadja, 1993; Evert, 2004; Seretan &amp; Wehrli, 2009, among many others). Much less attention has been paid to the interaction between collocations and the parsing process1. In this paper, we will argue (i) that collocation detection should be considered as a component of the parsing process, and (ii) that contrary to a common view, collocations (and more generally MWEs) do not constitute a problem or a hurdle for NLP (cf. Green et al., 2011; Sag et al., 2002), but rather have a positive impact on parsing results. Section 2 shows how collocation identification has been integrated into the parsing process. An evaluation w</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Evert, S., 2004. The Statistics of Word Cooccurrences: Word Pairs and Collocations, PhD dissertation, IMS, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Green</author>
<author>M-C de Marneffe</author>
<author>J Bauer</author>
<author>Ch D Manning</author>
</authors>
<title>Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French”,</title>
<date>2011</date>
<booktitle>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>725--735</pages>
<marker>Green, de Marneffe, Bauer, Manning, 2011</marker>
<rawString>Green S., M.-C. de Marneffe, J. Bauer &amp; Ch.D. Manning, 2011. ”Multiword Expression Identification with Tree Substitution Grammars: A Parsing tour de force with French”, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, 725-735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A Universal Part-of-Speech Tagset”,</title>
<date>2012</date>
<booktitle>Proceedings of LREC-2011.</booktitle>
<contexts>
<context position="12980" citStr="Petrov et al., 2012" startWordPosition="2109" endWordPosition="2112">onducted over the corpus, using a specific user interface. To simplify the evaluation, we selected the POS-tagging mode of the parser, and further 4By complete analysis, we mean a single constituent covering the whole sentence. When the Fips parser fails to achieve a complete analysis, it returns a sequence of chunks (usually 2 or 3) covering the whole sentence. 29 diff. diff N vs V with coll. without coll. 416 148 116 32 Figure 3: Differences with and without collocation restricted the output to the triple (word, pos-tag, position)5. For the POS tagset, we opted for the universal tagset (cf. Petrov et al., 2012). Both output files could then easily be manually compared using a specific user interface as illustrated in figure 2 below, where differences are displayed in red. Notice that in order to facilitate the manual evaluation, we only took into account differences involving the NOUN and VERB tags. In the screenshot the two result files are displayed, on the left the results obtained by the parser with (W) the collocation identification component, on the right the results obtained with the parser without (WO) the collocation identification component. For each file, one line contains the input lexic</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Petrov, S., D. Das &amp; R. McDonald, 2012. “A Universal Part-of-Speech Tagset”, Proceedings of LREC-2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword Expressions: A Pain in the Neck for NLP”,</title>
<date>2002</date>
<booktitle>Proceedings of Cicling</booktitle>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="1791" citStr="Sag et al., 2002" startWordPosition="286" endWordPosition="289">n focus of attention, and a great deal of research has been devoted to developing techniques for collocation extraction from corpora (Church &amp; Hanks, 1990; Smadja, 1993; Evert, 2004; Seretan &amp; Wehrli, 2009, among many others). Much less attention has been paid to the interaction between collocations and the parsing process1. In this paper, we will argue (i) that collocation detection should be considered as a component of the parsing process, and (ii) that contrary to a common view, collocations (and more generally MWEs) do not constitute a problem or a hurdle for NLP (cf. Green et al., 2011; Sag et al., 2002), but rather have a positive impact on parsing results. Section 2 shows how collocation identification has been integrated into the parsing process. An evaluation which compares the results of the parse of a corpus with and without the collocation identification component will be discussed in section 3. 2 Parsing collocations That syntactic information is useful – indeed necessary – for a proper identification of collocations is widely acknowledged by now. More controversial, however, is the dual point, that is 1Preprocessing, that is, the detection of MWEs during tokenisation (ie. before pars</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, I., T. Baldwin, F. Bond, A. Copestake &amp; D. Flickinger (2002), ”Multiword Expressions: A Pain in the Neck for NLP”, Proceedings of Cicling 2002, Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Seretan</author>
</authors>
<title>Syntax-Based Collocation Extraction,</title>
<date>2011</date>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="2977" citStr="Seretan, 2011" startWordPosition="472" endWordPosition="473">kenisation (ie. before parsing) is used in several systems – for instance, ParGram (Butt et al., 1999), or more recently, Talismane (Urieli, 2013). However, this technique can only be successfully applied to MWEs whose components are adjacent (or near-adjacent), leaving aside most of the cases that will be discussed below. 26 Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 26–32, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics that collocation identification is useful for parsing. Several researchers (cf. Seretan et al., 2009; Seretan, 2011, and references given there) have convincingly argued that collocation identification crucially depends on precise and detailed syntactic information. One main argument supporting that view is the fact that in some collocations, the two constituents can be far away from each other, or in reverse order, depending on grammatical processes such as extraposition, relativization, passive, etc. Based on such considerations, we developed a collocation extraction system based on our Fips multilingual rule-based parser(cf. Wehrli, 2007; Wehrli et al., 2010). Although quite satisfactory in terms of ext</context>
</contexts>
<marker>Seretan, 2011</marker>
<rawString>Seretan, V., 2011. Syntax-Based Collocation Extraction, Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Seretan</author>
<author>E Wehrli</author>
</authors>
<title>Multilingual Collocation Extraction with a Syntactic Parser”,</title>
<date>2009</date>
<journal>Language Resources and Evaluation</journal>
<volume>43</volume>
<pages>71--85</pages>
<contexts>
<context position="1379" citStr="Seretan &amp; Wehrli, 2009" startWordPosition="216" endWordPosition="219">duction Collocations and more generally multiword expressions (MWEs) have received a large and increasing amount of attention in the NLP community over the last two decades, as attested by the number of workshops, special interest groups, and –of course– publications. The importance of this phenomenon is now clearly recognized within the NLP community. It is fair to say that collocation extraction has been the main focus of attention, and a great deal of research has been devoted to developing techniques for collocation extraction from corpora (Church &amp; Hanks, 1990; Smadja, 1993; Evert, 2004; Seretan &amp; Wehrli, 2009, among many others). Much less attention has been paid to the interaction between collocations and the parsing process1. In this paper, we will argue (i) that collocation detection should be considered as a component of the parsing process, and (ii) that contrary to a common view, collocations (and more generally MWEs) do not constitute a problem or a hurdle for NLP (cf. Green et al., 2011; Sag et al., 2002), but rather have a positive impact on parsing results. Section 2 shows how collocation identification has been integrated into the parsing process. An evaluation which compares the result</context>
</contexts>
<marker>Seretan, Wehrli, 2009</marker>
<rawString>Seretan, V. &amp; E. Wehrli, 2009. “Multilingual Collocation Extraction with a Syntactic Parser”, Language Resources and Evaluation 43:1, 71-85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations from text: Xtract”,</title>
<date>1993</date>
<journal>Computational Linguistics</journal>
<volume>19</volume>
<issue>1</issue>
<pages>143--177</pages>
<contexts>
<context position="1342" citStr="Smadja, 1993" startWordPosition="212" endWordPosition="213"> support our claim. 1 Introduction Collocations and more generally multiword expressions (MWEs) have received a large and increasing amount of attention in the NLP community over the last two decades, as attested by the number of workshops, special interest groups, and –of course– publications. The importance of this phenomenon is now clearly recognized within the NLP community. It is fair to say that collocation extraction has been the main focus of attention, and a great deal of research has been devoted to developing techniques for collocation extraction from corpora (Church &amp; Hanks, 1990; Smadja, 1993; Evert, 2004; Seretan &amp; Wehrli, 2009, among many others). Much less attention has been paid to the interaction between collocations and the parsing process1. In this paper, we will argue (i) that collocation detection should be considered as a component of the parsing process, and (ii) that contrary to a common view, collocations (and more generally MWEs) do not constitute a problem or a hurdle for NLP (cf. Green et al., 2011; Sag et al., 2002), but rather have a positive impact on parsing results. Section 2 shows how collocation identification has been integrated into the parsing process. An</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, F., 1993. “Retrieving collocations from text: Xtract”, Computational Linguistics 19(1), 143-177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Urieli</author>
</authors>
<title>Robust French Syntax Analysis: reconciling statistical methods and linguistic knowledge in the Talismane toolkit,</title>
<date>2013</date>
<institution>University of Toulouse.</institution>
<note>PhD dissertation,</note>
<contexts>
<context position="2510" citStr="Urieli, 2013" startWordPosition="404" endWordPosition="405"> been integrated into the parsing process. An evaluation which compares the results of the parse of a corpus with and without the collocation identification component will be discussed in section 3. 2 Parsing collocations That syntactic information is useful – indeed necessary – for a proper identification of collocations is widely acknowledged by now. More controversial, however, is the dual point, that is 1Preprocessing, that is, the detection of MWEs during tokenisation (ie. before parsing) is used in several systems – for instance, ParGram (Butt et al., 1999), or more recently, Talismane (Urieli, 2013). However, this technique can only be successfully applied to MWEs whose components are adjacent (or near-adjacent), leaving aside most of the cases that will be discussed below. 26 Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 26–32, Gothenburg, Sweden, 26-27 April 2014. c�2014 Association for Computational Linguistics that collocation identification is useful for parsing. Several researchers (cf. Seretan et al., 2009; Seretan, 2011, and references given there) have convincingly argued that collocation identification crucially depends on precise and detailed synt</context>
</contexts>
<marker>Urieli, 2013</marker>
<rawString>Urieli, A., 2013. Robust French Syntax Analysis: reconciling statistical methods and linguistic knowledge in the Talismane toolkit, PhD dissertation, University of Toulouse. [http://redac.univtlse2.fr/applications/talismane/biblio/ URIELI-thesis-2013.pdf]</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Wehrli</author>
</authors>
<title>Fips, a deep linguistic multilingual parser”</title>
<date>2007</date>
<booktitle>in Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing,</booktitle>
<pages>120--127</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="3510" citStr="Wehrli, 2007" startWordPosition="552" endWordPosition="553">seful for parsing. Several researchers (cf. Seretan et al., 2009; Seretan, 2011, and references given there) have convincingly argued that collocation identification crucially depends on precise and detailed syntactic information. One main argument supporting that view is the fact that in some collocations, the two constituents can be far away from each other, or in reverse order, depending on grammatical processes such as extraposition, relativization, passive, etc. Based on such considerations, we developed a collocation extraction system based on our Fips multilingual rule-based parser(cf. Wehrli, 2007; Wehrli et al., 2010). Although quite satisfactory in terms of extraction precision, we noticed some shortcomings in terms of recall, due to the fact that the parser would not always return the most appropriate structure. A closer examination of some of the cases where the parser failed to return the structure containing a collocation – and therefore failed to identify it – showed that heuristics had (wrongly) favoured an alternative structure. Had the parser known that there was a collocation, the correct structure could have received a higher score. These observations led us to revise our p</context>
</contexts>
<marker>Wehrli, 2007</marker>
<rawString>Wehrli, E., 2007. “Fips, a deep linguistic multilingual parser” in Proceedings of the ACL 2007 Workshop on Deep Linguistic Processing, Prague, Czech Republic, 120-127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Wehrli</author>
<author>V Seretan</author>
<author>L Nerima</author>
</authors>
<title>Sentence Analysis and Collocation Identification”</title>
<date>2010</date>
<booktitle>in Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010),</booktitle>
<pages>27--35</pages>
<location>Beijing, China,</location>
<contexts>
<context position="3532" citStr="Wehrli et al., 2010" startWordPosition="554" endWordPosition="557">ing. Several researchers (cf. Seretan et al., 2009; Seretan, 2011, and references given there) have convincingly argued that collocation identification crucially depends on precise and detailed syntactic information. One main argument supporting that view is the fact that in some collocations, the two constituents can be far away from each other, or in reverse order, depending on grammatical processes such as extraposition, relativization, passive, etc. Based on such considerations, we developed a collocation extraction system based on our Fips multilingual rule-based parser(cf. Wehrli, 2007; Wehrli et al., 2010). Although quite satisfactory in terms of extraction precision, we noticed some shortcomings in terms of recall, due to the fact that the parser would not always return the most appropriate structure. A closer examination of some of the cases where the parser failed to return the structure containing a collocation – and therefore failed to identify it – showed that heuristics had (wrongly) favoured an alternative structure. Had the parser known that there was a collocation, the correct structure could have received a higher score. These observations led us to revise our position and consider t</context>
</contexts>
<marker>Wehrli, Seretan, Nerima, 2010</marker>
<rawString>Wehrli, E., V. Seretan &amp; L. Nerima, 2010. “Sentence Analysis and Collocation Identification” in Proceedings of the Workshop on Multiword Expressions: from Theory to Applications (MWE 2010), Beijing, China, 27-35.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>