<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.034357">
<title confidence="0.7758715">
An explicit statistical model of learning lexical segmentation using
multiple cues
</title>
<author confidence="0.691947">
C¸ a˘grı C¸ ¨oltekin
</author>
<affiliation confidence="0.92105">
University of Groningen
</affiliation>
<email confidence="0.968528">
c.coltekin@rug.nl
</email>
<sectionHeader confidence="0.997072" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999965705882353">
This paper presents an unsupervised and
incremental model of learning segmenta-
tion that combines multiple cues whose
use by children and adults were attested by
experimental studies. The cues we exploit
in this study are predictability statistics,
phonotactics, lexical stress and partial lex-
ical information. The performance of the
model presented in this paper is competi-
tive with the state-of-the-art segmentation
models in the literature, while following
the child language acquisition more faith-
fully. Besides the performance improve-
ments over the similar models in the liter-
ature, the cues are combined in an explicit
manner, allowing easier interpretation of
what the model learns.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999784">
Segmenting the continuous speech stream into lex-
ical units is one of the challenges we face while lis-
tening to other speakers. For competent language
users, probably the biggest aid in identifying the
word boundaries is the knowledge of the words.
Not surprisingly, the models of adult word recog-
nition depend heavily on a lexicon (see Dahan and
Magnuson, 2006, for a recent review). The same
can be observed in speech and language technol-
ogy where all automatic speech recognition sys-
tems make use of a comprehensive lexicon.
Even with a comprehensive lexicon and an
error-free representation of the acoustic input, the
problem is not trivial, since the input is often com-
patible with multiple segmentations spanning the
complete utterance. The problem, however, is
even more difficult for a learner who starts with
no lexicon. Fortunately, the lexicon is not the
only aid for segmentation. Experimental research
within last two decades has revealed an array of
cues that are used by adults and children for lexi-
cal segmentation. These cues include, but are not
</bodyText>
<author confidence="0.832858">
John Nerbonne
</author>
<affiliation confidence="0.928914">
University of Groningen
</affiliation>
<email confidence="0.848008">
j.nerbonne@rug.nl
</email>
<bodyText confidence="0.998662642857143">
limited to, lexical stress (Cutler and Butterfield,
1992; Jusczyk, Houston, et al., 1999), phonotac-
tics (Jusczyk, Cutler, et al., 1993), predictability
statistics (Saffran et al., 1996), allophonic differ-
ences (Jusczyk, Hohne, et al., 1999), coarticula-
tion (E. K. Johnson and Jusczyk, 2001), and vowel
harmony (Suomi et al., 1997). The relative utility
or dominance of these cues is a matter of current
debate. However, it seems uncontroversial that
none of these cues solves the segmentation prob-
lem alone and, when available, they are used in
conjunction.
Along with experimental research on segmen-
tation, a large number of computational models
have been proposed in the literature. The early
studies typically made use of connectionist mod-
els (e.g., Elman, 1990; Christiansen et al., 1998).
Of these studies, Christiansen et al. (1998) is par-
ticularly interesting for the present study since it
incorporates most of the cues used in this study.
Using a simple recurrent network (SRN, Elman,
1990), Christiansen et al. (1998) demonstrated the
usefulness of lexical stress, predictability statistics
(included implicitly in any SRN model), and utter-
ance boundaries, and showed that combining the
cues improves the performance. The connection-
ist models have been instrumental in investigating
a large number of cognitive phenomena. However,
they have also been subject to the criticism that
what a connectionist model learns is rather dif-
ficult to interpret. Furthermore, the performance
achieved using connectionist models is far lower
than that is expected from humans.
Models that use explicit representations in com-
bination with statistical procedures (e.g., Brent
and Cartwright, 1996; Brent, 1999; Venkatara-
man, 2001; Goldwater et al., 2009; M. Johnson
and Goldwater, 2009) avoid both problems: these
models perform better, and it is easier to reason
about what they learn. Although these models
were also instrumental in our understanding of the
problem, they lack at least two aspects of con-
</bodyText>
<page confidence="0.992297">
19
</page>
<note confidence="0.9699105">
Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28,
Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99993428125">
nectionist models that fit human processing better.
First, even though we know that human segmen-
tation is incremental and predictive, most of these
models process their input either in a batch fash-
ion, or they require the complete utterance to be
presented before attempting to segment the input.
Second, it is generally difficult to incorporate ar-
bitrary cues into most of these models.
Models that use explicit representations with
incremental models exist (e.g., Monaghan and
Christiansen, 2010; Lignos, 2011), but are rather
rare. Furthermore, the investigation of cues and
cue combination in segmentation is also relatively
scarce within the recent studies (exceptions in-
clude the investigation of various suprevised mod-
els by Jarosz and J. A. Johnson, 2013).
The present paper introduces a strictly incre-
mental, unsupervised method for learning seg-
mentation where the learning method and internal
representations are explicitly defined. Crucially,
we use a set of cues demonstrated to be used by
humans in solving the segmentation problem. The
simulations results that we present are based on
the same child-directed speech input used by many
other studies in the literature.
The rest of this article is organized as follows:
in the next section, we present a method for com-
bining cues. Section 3 describes the cues used in
this study. The simulations are described and re-
sults are presented in Section 4. A general discus-
sion of the modeling framework and the simula-
tion results are given in Section 5.
</bodyText>
<sectionHeader confidence="0.945276" genericHeader="method">
2 A cue combination method
</sectionHeader>
<bodyText confidence="0.999844">
We know that there is no single cue that always
gives the correct answer in the lexical segmenta-
tion task. We also know that humans combine
multiple cues when available. In this section we
define a method to segment a given utterance using
multiple boundary indicators, or cues, and learn
to segment better by estimating usefulness of each
indicator. In essence, each indicator makes a de-
cision on each potential boundary location. The
method combines these indicators’ decisions to ar-
rive at a hopefully more accurate decision. In ma-
chine learning terms, we formulate a number of
binary classifiers, and aim to get a better classi-
fier using a combination of them. This problems
is a relatively well-studied subject in the machine
learning literature (e.g., Bishop, 2006, chapter 14).
Here a simple and well-known method, major-
ity voting, will be used for combining multiple
boundary indicators.
Majority voting is a common (and arguably ef-
fective) method in everyday social and political
life. As a result, it has been well studied, and
known to work well especially if each voter’s de-
cision is better than random on average, and votes
are cast independently. In practice, even though
the votes are almost never independent, majority
voting is still an effective way of combining mul-
tiple classifiers (see Narasimhamurthy, 2005, for a
discussion of the effectiveness of the method).
The majority voting combines each vote
equally. Even though this may be a virtue in the
social and political context, it is a shortcoming for
a computational procedure that incorporates infor-
mation from multiple sources with varying useful-
ness. We will use a simple augmentation of ma-
jority voting to model, weighted majority voting
(Littlestone and Warmuth, 1994), that weighs the
utility of the information provided by each source.
In weighted majority voting, the voters that
make fewer errors get higher weights. In an un-
supervised setting as ours, we do not know for
certain when a voter makes an mistake. Instead,
we take a voter’s decision to be correct if it agrees
with the majority. Initially we set all the weights
to 1, trusting all the voters equally. We adopt an
incremental version of the algorithm, where we
keep the count of ‘errors’ made by each voter i,
ei, which is incremented every time the voter dis-
agrees with the majority. After every boundary de-
cision, first, the error counts are updated for each
voter. Then, the weight, wi, of each voter is up-
dated using,
</bodyText>
<equation confidence="0.993464">
(0.5 − ei �
wi ← 2 N
</equation>
<bodyText confidence="0.999925625">
where N is the number of boundary decisions
made so far, including the current one.
This update rule sets the weight of a voter that
is half the time wrong (a voter that votes at ran-
dom) to zero, eliminating the incompetent voters.
If the votes of a voter are in accordance with the
weighted majority decision almost all the time, the
weight stays close to one.
</bodyText>
<sectionHeader confidence="0.99061" genericHeader="method">
3 Cues and boundary indicators
</sectionHeader>
<bodyText confidence="0.9999295">
The combination method above allows us to com-
bine an arbitrary number of boundary indicators.
In our setting, each psychologically motivated cue
is represented by multiple boundary indicators that
</bodyText>
<page confidence="0.990112">
20
</page>
<bodyText confidence="0.9999096">
differ based on the source of information used and
the way this information is turned into a quantita-
tive measure. This section introduces all of these
cues, and the boundary indicators that stem from
quantification of these cues in different ways.
</bodyText>
<subsectionHeader confidence="0.999863">
3.1 Predictability statistics
</subsectionHeader>
<bodyText confidence="0.99977592">
At least as early as Harris (1955), it was known
that a simple property of natural language utter-
ances can aid identifying the lexical units that
form an utterance: predictability within the units
is high, predictability between the units is low.
However, until the influential study by Saffran,
Aslin, and Newport (1996), the idea was not in-
vestigated in developmental psycholinguistics as a
possible source of information that children may
use for segmentation. After Saffran et al. (1996)
showed that 8-month-old infants make use of pre-
dictability statistics to extract word-like units from
an artificial language stream, a large number of
studies confirmed that predictability based strate-
gies are used by adults and children for learning
different aspects of language (e.g., Thiessen and
Saffran, 2003; Newport and Aslin, 2004; Graf
Estes et al., 2007; Thompson and Newport, 2007;
Perruchet and Desaulty, 2008).
To use in our cue combination system, we need
to quantify the notion of predictability. In this
study, we use two information theoretic measures
of predictability (or surprise), to define a set of
boundary indicators. The first one, pointwise mu-
tual information (MI) is defined as
</bodyText>
<equation confidence="0.995282">
P(l, r)
MI(l, r) = log2
P(l)P(r)
</equation>
<bodyText confidence="0.99997975">
where l and r are strings of phonemes to the left
and right of the possible boundary location. We
define our second measure, boundary entropy (H)
of a potential boundary after string l as
</bodyText>
<equation confidence="0.974787">
H(l) = − � P(r|l)log2 (P (r|l))
r∈A
</equation>
<bodyText confidence="0.9998918">
where the sum ranges over all phonemes in the al-
phabet, A.1
The use of both the MI and the H is moti-
vated by the finding that combination multiple pre-
dictability measures result in better segmentation
</bodyText>
<footnote confidence="0.9127875">
1The input to children is better represented by ‘segments’
or ‘phones’. However, since the data used in our simulations
does not contain any phonetic variation, in this paper, we use
the term phoneme when referring to the basic input unit.
</footnote>
<bodyText confidence="0.999859470588235">
(see C¸ ¨oltekin, 2011, p.101, for an analysis). Fur-
thermore, for asymmetric measures, like entropy,
H(l) is clearly not the same as H(r). Motivated by
the finding that children use ‘reverse predictabil-
ity’ (Pelucchi et al., 2009), we also incorporate a
reverse entropy measure in the present study.
In most studies in the literature, the context l
and r are single basic units (phonemes in our case).
The different phoneme context sizes may capture
regularities that exist because of different linguis-
tic units. The relation between the phoneme con-
text size and the linguistic units, of course, is not
clear-cut. However, for example, we expect con-
text size of one to capture the regularities between
the phonemes, while context size of two or three
to capture regularities between larger units, such
as syllables.
The above parameters result in an array of in-
dicators. However, none of the indicators we use
have a natural threshold to decide whether a given
position is a boundary or not. To get a boundary
decision out of a single measure (MI or H), we
adopt a method similar to a commonly used unsu-
pervised method that decides for a boundary at the
‘peaks’ of unpredictability. A particular shortcom-
ing of this strategy, however, is that it can never
find both boundaries of a single-phoneme word,
as there cannot be two peaks one after another. To
remedy this, the partial-peak strategy we employ
here makes use of two sets of boundary indicators
for each potential boundary: one posits a bound-
ary after an increase in H (or a decrease in MI)
and the other posits a boundary before a decrease
in H.
</bodyText>
<subsectionHeader confidence="0.999912">
3.2 Utterance boundaries
</subsectionHeader>
<bodyText confidence="0.999894727272727">
An attractive aspect of the predictability-based
segmentation is that it does not require any lexical
knowledge in advance—unlike other cues noted in
Section 1. However, certain aspects of phonotac-
tics, such as the regularities found at the beginning
and end of words, can be induced from the bound-
aries already marked in the input without the need
for a lexicon. As a result, clearly marked lexical
unit boundaries may serve as another source of in-
formation that can bootstrap the acquisition of lex-
ical units.2
</bodyText>
<footnote confidence="0.6817452">
2There are a number of acoustic cues (e.g., pauses) that
are highly correlated with lexical unit boundaries. However,
we do not make use of them in this study since they are con-
sidered to be unreliable, and they are not marked in the cor-
pora at hand.
</footnote>
<page confidence="0.997836">
21
</page>
<bodyText confidence="0.999952105263158">
All models of segmentation in the literature
use utterance boundaries implicitly by assuming
that the words cannot straddle utterance bound-
aries. The explicit use of utterance boundaries
to discover regularities about words is common
in connectionist models (e.g., Aslin et al., 1996;
Christiansen et al., 1998; Stoianov and Nerbonne,
2000). Similar use of utterance boundaries in non-
connectionist models is rather rare. Three excep-
tions to this are the models described by Brent
(1996), Fleck (2008) and Monaghan and Chris-
tiansen (2010). The method described in this sec-
tion is similar to Fleck’s method, where the model
estimates the probability of observing a boundary
given its left and right context, P(b|l, r), where b
represents boundary, and as before, l and r rep-
resent left and right contexts, respectively. If this
probability is greater than 0.5, the model inserts
a boundary. Using utterance boundaries and the
pauses, Fleck (2008) presents a batch algorithm
with a few ad hoc corrections that estimates the
probabilities P(b), P(l|b), P(r|b), P(l), P(r), and
uses Bayesian inversion to estimate P(b|l, r).
In this work, instead of P(b|l, r), we estimate
probabilities of utterance beginnings, P(ub|r),
and probabilities of utterance ends, P(ub|l),
where ub stands for utterance boundary. These
probabilities can directly be estimated from the
utterance edges in the input corpus, and can be
used as cues for discovering non-initial or non-
final boundaries. Similar to the predictability, us-
ing different length l and r we obtain a set of indi-
cators for P(ub|r) and P(ub|l).
Unlike P(b|l, r), for P(ub|r) and P(ub|l) we
do not have a straightforward threshold to make
a boundary decision. Instead, we appeal to the
familiar solution, and use ‘partial peaks’ in these
values as boundary indications.
</bodyText>
<subsectionHeader confidence="0.999835">
3.3 Lexical stress
</subsectionHeader>
<bodyText confidence="0.999908731707317">
Lexical stress is one of the cues for segmentation
that is well supported by psycholinguistic research
(e.g., Cutler and Butterfield, 1992; Jusczyk, Hous-
ton, et al., 1999; Jusczyk, 1999). Lexical stress
is used in many languages for marking the promi-
nent syllable in a word. For languages that exhibit
lexical stress, the prominent syllable will typically
be in a particular position in the word, allowing
discovery of the boundaries based on the position
of stressed syllable.
Despite the prominence of stress as a cue for
segmentation, there are relatively few computa-
tional studies that investigate use of stress. Chris-
tiansen et al. (1998) incorporates stress as a cue
in their connectionist cue combination system.
Swingley (2005) provides a careful analysis of
stress patterns of the bisyllabic words found by
a discovery procedure on mutual information and
frequency. Gambell and Yang (2006) present sur-
prisingly good segmentation results with a rule-
based learner whose main source of information
is lexical stress. One of the major problems with
the these studies, which has also been carried over
to the present study, is the lack of corpora with re-
alistic stress assignment (see Section 4.1).
Our stress-based strategy is similar to the strat-
egy used for learning phonotactics described in
Section 3.2. Instead of collecting statistics about
phoneme n-grams, we collect statistics over stress
assignments on phoneme n-grams. However, the
probabilities are estimated over already known
lexical units. Given stress patterns l and r, we es-
timate P(b|l) from endings of the known lexical
units, and P(b|r) from the beginnings of the lexi-
cal units. Again we use these quantities as indica-
tors for variable length l and r. Using the partial-
peak boundary decision strategy in combination
with the weighted majority voting algorithm, as
before, we define a set of boundary indicators and
operationalize lexical stress as another cue for seg-
mentation.
</bodyText>
<subsectionHeader confidence="0.948785">
3.4 Lexicon
</subsectionHeader>
<bodyText confidence="0.99999052631579">
For adults, a comprehensive lexicon is probably
the most useful cue for segmentation. We do
not expect infants to have a lexicon at the begin-
ning. However, as they build their lexicon, or
‘proto-lexicon’, they may put it in use for discov-
ering novel lexical units. This is the main strat-
egy behind the majority of state-of-the-art compu-
tational models of segmentation (e.g., Brent, 1999;
Venkataraman, 2001; Goldwater et al., 2009). The
models that guess boundaries rarely build and use
an explicit lexicon (exceptions include Monaghan
and Christiansen, 2010).
In this study we also experiment with an (admit-
tedly naive) set of lexical cues to word boundaries.
The idea is to indicate a boundary when there are
word-like strings on both sides of the boundary
candidate. In our usual majority voting frame-
work, these form two additional sets of boundary
indicators. First, given a possible boundary loca-
</bodyText>
<page confidence="0.98272">
22
</page>
<bodyText confidence="0.999954904761905">
tion, we simply count the frequencies of already
known words beginning or ending at the position
in question. The second indicator is based on
the number of times the phoneme sequences sur-
rounding the boundary found at the beginnings or
ends of the previously discovered words. The sec-
ond indicator is essentially the same as the phono-
tactics component discussed in Section 3.2, ex-
cept that it is calculated using already known word
types instead of utterance boundaries.
Similar to the other asymmetric indicators dis-
cussed previously, we have two flavors for each in-
dicator. One indicating the existence of words to
the right of the boundary candidate (words begin-
ning at the boundary), and the other indicating the
existence of words the left of the boundary can-
didate (word ending at the boundary). As with the
other cues, these result in a set of indicators whose
primary source of information is the potential lexi-
cal units in the learner’s incomplete and noisy lex-
icon.
</bodyText>
<sectionHeader confidence="0.999703" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.9597">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.99999205">
We use a child-directed speech corpus from the
CHILDES database (MacWhinney and Snow,
1985). It was collected by Bernstein Ratner (1987)
and the original orthographic transcription of the
corpus was converted to a phonemic transcription
by Brent and Cartwright (1996). The same corpus
has been used by many recent studies. Following
the convention in the literature the corpus will be
called the BR corpus.
For the results reported for segmentation strate-
gies that make use of lexical stress, the BR corpus
was marked for lexical stress semi-automatically
following the procedure described by Christiansen
et al. (1998) for annotating the Korman corpus
(Korman, 1984). The stress assignment is done
according to stress patterns in the MRC psycholin-
guistic database. All single-syllable words are
coded as having primary stress, and the words that
were not found or did not have stress assignment
in the MRC database were annotated manually.
</bodyText>
<subsectionHeader confidence="0.968181">
4.2 Evaluation metrics
</subsectionHeader>
<bodyText confidence="0.999970545454545">
Two quantitative measures, precision (P), recall
(R) and their harmonic mean F1-score (F-score, or
F, for short), have become the standard evaluation
measures for computational simulations. Follow-
ing recent studies in the literature we present pre-
cision recall and F-scores for boundaries (BP, BR,
BF), word tokens (WP, WR, WF) and word types
or lexicon (LP, LR, LF). Besides precision and
recall, we also present two error measures, over-
segmentation (Eo) and undersegmentation (Eu) er-
rors, defined as Eo = FP/(FP + TN) and Eu =
FN/(FN +TP), where TP, FP, TN and FN are true
positives, false positives, true negatives, and false
negatives respectively.
In plain words, Eo is the number of the false
boundaries inserted by the model divided by the
total number of word internal positions in the
corpus. Similarly, Eu is the ratio of boundaries
missed to the total number of boundaries. Al-
though these error measures are related to preci-
sion and recall, they provide different, and some-
times better, insights into the model’s behavior.
</bodyText>
<subsectionHeader confidence="0.996203">
4.3 Reference models
</subsectionHeader>
<bodyText confidence="0.999979615384615">
In this paper, we compare the results obtained by
the cue combination model with two baselines.
The first baseline is a random model (RM) that
assigns boundaries with the probability of bound-
aries in the input corpus. The RM is more in-
formed than a completely random classifier, but it
has been customary (since Brent and Cartwright,
1996) in segmentation literature to set the bar a
little bit higher. The second reference model is a
lexicon-building model similar to many state-of-
the-art models. The model described here, which
we call LM, assigns probabilities to possible seg-
mentations as described in Equations 1 and 2.
</bodyText>
<equation confidence="0.989891666666667">
P(wi) (1)
P(w) = (1 − α) f(w) if w is known (2)
iαHIL&apos;=1 P(ai) if w is unknown
</equation>
<bodyText confidence="0.99977925">
where s is a sequence of phonemes (e.g., an ut-
terance or a corpus), wi is the ith word in the se-
quence, ai is the ith sound in the word, f(w) is the
relative frequency of the word w, m is the number
of known words, and 0 &lt; α &lt; 1 is the only pa-
rameter of the model. In all experiments reported
in this paper, we will fix α at 0.5.
For the incremental model defined here, a word
is ‘known’, if it was used in a previous segmenta-
tion. The model accepts whole utterances as single
words if the utterance does not contain any known
words.
</bodyText>
<equation confidence="0.977635">
n
r1
P(s) =
</equation>
<page confidence="0.996572">
23
</page>
<table confidence="0.999715125">
model boundary word lexicon
P R F P R F P R F
Brent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4
Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7
Goldwater et al. (2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1
Blanchard et al. (2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3
RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5
LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3
</table>
<tableCaption confidence="0.723501">
Table 1: Performance scores of the reference mod-
els LM and RM in comparison with some of the
earlier scores reported in the literature. If there
</tableCaption>
<bodyText confidence="0.982055">
were multiple models reported in a study, the re-
sult with the highest lexicon F-score is presented.
All scores are obtained on the BR corpus.
Table 1 compares the performances of some re-
cent models in the literature using the BR corpus
with the two reference models. The LM performs
similar to the state-of-the-art models presented in
this table. Hence, to aid comparison of the mod-
els proposed in this study with the others in the
literature, we will (re)report the result of the two
baseline models in the rest of this paper. Note
that the scores presented in Table 1 can be mis-
leading since the batch models have an advantage
due to the way scores are calculated. The scores
of the batch models are calculated at the end of
training, while scores of the incremental models
include initial (presumably bad) choices made be-
fore enough exposure to the input. For example,
the LM achieves boundary, word and lexicon F-
scores of 89%, 81% and 74% respectively, towards
the end of the BR corpus. These scores are higher
than all of the scores presented in Table 1 (see Ta-
ble 4 for details the way these scores are calcu-
lated).
</bodyText>
<subsectionHeader confidence="0.989985">
4.4 Experiments and results
</subsectionHeader>
<bodyText confidence="0.99997640625">
This section reports results of a set of simulations
using the modeling framework described so far.
All experiments are run on the BR corpus. For
all the results reported below, each cue is repre-
sented by a set indicators as described in Section 3,
multiple indicators for each phoneme n-gram of
length one and three are used for left (1) and right
(T) contexts, for all measures that are calculated
over phoneme n-grams surrounding the potential
boundary. The use of lexical information and lex-
ical stress as standalone strategies are similar to
the ‘lexicon-building’ strategy. The learner inserts
complete utterances to the lexicon when the strat-
egy cannot segment the utterance. As the learner
starts to learn (from the edges of the sequences in
the lexicon) what the edges of words look like, it
uses this information to segment later utterances
in the input.3
We first report the performance results of indi-
vidual cues, namely, predictability (P), utterance
boundaries (U), lexical information (W) and lexi-
cal stress (S) in Table 2.
Using the predictability cue alone leads to a
segmentation performance lower than but close to
the state-of-the-art reference model LM. Although
these results are not directly comparable to the
earlier studies in the literature, the performance
scores presented in Table 2 are the best scores pre-
sented to date for models using the predictability
cue alone. Graphs presented by Brent (1999) in-
dicates about 50%–60% WP and WR and 20%–
30% LP for his baseline model utilizing mutual
information on the BR corpus. Cohen et al. (2007)
report 76% BP, and 75% BR on George Orwell’s
1984. Christiansen et al. (1998) report 37% WP
and 40% WR with an SRN using phonotactics and
utterance boundary cues on another child-directed
speech corpus (Korman, 1984).
The model that learns from the utterance bound-
aries seems to perform the best. The results are
comparable, and in some cases better than the LM.
Furthermore, the overall scores are also higher
than the scores reported by Fleck (2008), where
the boundary, word and lexical F-scores were
82.9%, 70.7% and 36.6%, respectively.
Although it is somewhat behind both pre-
dictability and utterance boundary cues, the lexical
information alone certainly performs better than
random. The lower performance of this model in
comparison to ‘U’ suggests that, at least in this set-
ting, phonotactics learned from word tokens found
at the utterance edges leads to a better perfor-
mance compared to the phonotactics learned from
the word types in the learner’s lexicon.
The experiment that takes only the stress cue
into account yields the worst overall results. It
seems, when the cue indicates a boundary, it is
extremely precise. However, it is also very con-
servative. This seems to be due to the fact that
the model learns to segment at weak–strong tran-
sitions, which is expected to be precise. However,
since majority of the stress transitions are strong–
strong, this covers rather a small portion of the
boundaries.
</bodyText>
<footnote confidence="0.996067">
3The source code of the application and the data used in
this study can be found at https://bitbucket.org/
coltekin/seg/.
</footnote>
<page confidence="0.996587">
24
</page>
<table confidence="0.99960375">
model boundary word lexicon error
P R F P R F P R F Eo Eu
P 69.6 92.5 79.5 56.9 70.2 62.9 36.7 49.8 42.3 15.3 7.5
U 82.9 84.8 83.8 70.5 71.7 71.1 33.8 66.9 44.9 6.6 15.2
W 77.5 71.3 74.3 60.6 57.2 58.9 18.3 47.7 26.4 7.8 28.7
S 78.2 8.2 14.8 26.5 9.7 14.2 8.2 38.7 13.5 0.9 92.8
RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 27.1 73.0
LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 5.9 17.3
</table>
<tableCaption confidence="0.9979854">
Table 2: Results of simulations using individual
cues: predictability (P), utterance boundaries (U),
lexicon (W) and lexical stress (S). The rows la-
beled LM and RM are scores of reference models
repeated for ease of comparison.
</tableCaption>
<table confidence="0.999809428571429">
boundary word lexicon error
model P R F P R F P R F Eo Eu
PU 82.6 90.7 86.5 72.4 77.4 74.8 42.8 65.3 51.7 7.2 9.3
PUW 83.7 91.2 87.3 74.1 78.8 76.4 43.9 67.7 53.3 6.7 8.8
PUWS 92.8 75.7 83.4 78.3 68.1 72.9 26.8 62.7 37.5 2.2 24.3
RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 27.1 73.0
LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 5.9 17.3
</table>
<tableCaption confidence="0.998909">
Table 3: Results of combination of strategies
</tableCaption>
<bodyText confidence="0.994754833333334">
based on four cues: starting with predictability
and utterance boundaries (PU), addition of lexi-
con (PUW) and lexical stress (PUWS). The rows
labeled LM and RM are scores of reference mod-
els repeated for ease of comparison.
Table 3 presents combination of predictability
and utterance boundaries, followed by lexical in-
formation and stress. Here all indicators are com-
bined in a flat, non-hierarchical manner. The com-
bination of predictability and utterance bound-
aries results in higher F-scores, and it results in
more balanced under- and over-segmentation er-
rors. The addition of the lexical information pro-
vide a small but consistent improvement. How-
ever, adding stress information seems to have an
adverse effect. Despite the increased boundary
and word precision, all other performance scores
go down substantially when we add the stress cue.
The scores in Table 3 are obtained over the com-
plete corpus. As noted in Section 4.3, these scores
do not reflect the ‘learned’ state of the models.
Furthermore, we are interested in the progress of a
learner as more input is provided. To demonstrate
both, Eo and Eu for all combined models are plot-
ted in Figure 1 for each 500 utterances.
An interesting observation that can be made
in these graphs is that the models without the
stress cue make fewer undersegmentation errors,
with the cost of slightly higher oversegmentation.
However, the strategy that combines all cues keeps
</bodyText>
<table confidence="0.9981348">
model boundary word lexicon error
P R F P R F P R F Eo Eu
PU 85.6 96.7 90.8 78.7 86.0 82.2 71.8 75.9 73.8 6.6 3.3
PUW 83.3 97.2 89.7 75.6 84.5 79.8 69.8 75.5 72.5 7.9 2.8
PUWS 92.5 89.3 90.9 84.2 82.2 83.2 70.9 77.6 74.1 2.9 10.7
</table>
<tableCaption confidence="0.969091">
Table 4: The same results presented in Table 3, but
</tableCaption>
<bodyText confidence="0.987866291666667">
measured for the last 290-utterances (last block in
an incremental experiment with 500-utterance in-
crements).
oversegmentation errors low throughout the learn-
ing process, and towards the end, it makes fewer
undersegmentation errors as well. This suggests
that the model combining all cues, including the
stress, may be doing better as it collects more
evidence. To demonstrate this further, Table 4
presents the same results presented in Table 3, cal-
culated on the last block of an experiment where
performance scores were calculated after every
500 input utterances. Besides demonstrating the
increase in performance scores when calculated at
later stages of learning, the differences between
tables 3 and 4 show clearly that despite the fact
that it has a detrimental affect when scores are cal-
culated over the complete corpus, the stress cue
has a positive effect at the end of the learning pro-
cess. This suggests that the combined model using
stress cue learns slower and makes more mistakes
at the beginning. However as evidence accumu-
lates, it starts to be useful, and increases the over-
all performance of the combined model.
</bodyText>
<sectionHeader confidence="0.995794" genericHeader="conclusions">
5 General discussion
</sectionHeader>
<bodyText confidence="0.999938105263158">
This paper introduced an unsupervised and in-
cremental model of segmentation that focuses on
combining multiple cues relevant to child lan-
guage acquisition as attested by earlier studies in
psycholinguistics. Unsupervised and incremen-
tal models of segmentation that combine multiple
cues are not new. There have been many models
sharing these properties to some extent. In partic-
ular, the model presented in this paper has many
similarities with an earlier connectionist model
of segmentation presented by Christiansen et al.
(1998). However, unlike connectionist models, the
model presented here uses accessible explicit rep-
resentations, and an concrete learning procedure.
Most recent models with explicit representa-
tions and statistical learning procedures tend to be
models that process their input in ‘batch’. These
models typically perform better when measured at
the overall best performance level, and the insights
</bodyText>
<page confidence="0.99056">
25
</page>
<figure confidence="0.999154588235294">
(a) Oversegmentation errors
1 2 3 4 5 6 7 8 9 10
1000 uttrances
(b) Undersegmentation errors
1 2 3 4 5 6 7 8 9 10
1000 uttrances
Error rate
0.0 0.2 0.4 0.6 0.8
PU
PUW
PUWS
LM
0.0 0.2 0.4 0.6 0.8
PU
PUW
PUWS
LM
</figure>
<figureCaption confidence="0.999997">
Figure 1: Progression of (a) over- and (b) under-segmentation errors of the combined strategies.
</figureCaption>
<bodyText confidence="0.999989108108108">
we get from these models are undeniably useful.
However, these models typically provide explana-
tions at Marr’s (1982) computational level. The
modeling practice we follow is similar to these
models in many ways, and can provide explana-
tions for the same type of questions. However,
it may also provide explanations at lower levels
(e.g., Marr’s algorithmic level). This is not to
claim that children learn exactly the way the model
learns. However, the type of models presented in
this paper follow human behavior more faithfully,
and, at least in principle, more detailed predictions
can be tested on these models. Naturally, rele-
vance of the findings for human cognition will be
increased as we constrain our models further in ac-
cordance with what we know about the cognitive
processes.
The first contribution of this study is the de-
scription of a modeling framework that follows
what we know about human segmentation process
with high fidelity while keeping the benefits of a
model with explicit representations and statistical
learning methods.
Besides the performance scores that are com-
petitive with the state-of-the-art models in the lit-
erature, the simulations also provide some insights
regarding the cues commonly studied in the psy-
cholinguistics literature. Some of the findings con-
firm the previous results. Indeed, it seems that
combining multiple cues help. However, the prop-
erties of the modeling framework presented in this
paper allows us to make some other interesting ob-
servations, for example, the effect of stress cue
presented in Section 4.4.
When we look at the overall effect of the stress
cue throughout the complete simulations, it seems
stress degrades the performance. However, if we
take a look at the models’ performances at the end
of the learning, we see that effect of the stress cue
is actually positive. In other words, once ‘boot-
strapped’ by the other cues, stress becomes a use-
ful cue. Furthermore, the way the stress cue is use-
ful for the model is also in line with the findings in
the literature where stress is commonly found to
be a dominant cue (Jusczyk, Cutler, et al., 1993;
Thiessen and Saffran, 2003). Given the findings
here that stress is rather a precise cue (despite its
low recall), it is understandable why it dominates
the boundary decisions when available.
The segmentation model presented in this pa-
per demonstrates a way to achieve good segmenta-
tion performance using more cognitively relevant
and transparent strategies. It is also instrumental
at investigating some of the interesting issues re-
garding cue combination in segmentation, and it is
a first step towards models that are more faithful
to the human segmentation process. Among other
things, we consider two important improvements
to the model described here for future work. First,
although the combination method used (weighted
majority voting) has been successful, other meth-
ods such as Bayesian cue combination used for
modeling other cognitive processes may be a bet-
ter approach for segmentation as well. The sec-
ond improvement we plan is regarding the input.
Even though we used a standard corpus as used
by many other studies in the literature, it is ide-
alized (e.g., contains no phonetic variation), and
poor (e.g., lacking some cues that are available to
children) at the same time. Hence, as well as bet-
ter input representations, using input with varia-
tion and noise, and the use of different languages
are steps we would like to take in future studies
towards a better modeling of segmentation.
</bodyText>
<page confidence="0.99417">
26
</page>
<sectionHeader confidence="0.996256" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999943963235295">
Richard N. Aslin, Julide Z. Woodward, Nicholas P. LaMen-
dola, and Thomas G. Bever (1996). “Models of Word Seg-
mentation in Fluent Maternal Speech to Infants”. In: Sig-
nal to Syntax: Bootstrapping From Speech to Grammar in
Early Acquisition. Ed. by James L. Morgan and Katherine
Demuth. Lawrence Erlbaum Associates. Chap. 8, pp. 117–
134.
Nan Bernstein Ratner (1987). “The phonology of parent-
child speech”. In: Children’s language. Ed. by K. Nel-
son and A. van Kleeck. Vol. 6. Hillsdale, NJ: Erlbaum,
pp. 159–174.
Christopher M. Bishop (2006). Pattern Recognition and Ma-
chine Learning. Springer.
Daniel Blanchard, Jeffrey Heinz, and Roberta Golinkoff
(2010). “Modeling the contribution of phonotactic cues to
the problem of word segmentation”. In: Journal of Child
Language 37.Special Issue 03, pp. 487–511.
Michael R. Brent (1996). “Advances in the computational
study of language acquisition”. In: Cognition 61 (1-2),
pp. 1–38.
Michael R. Brent (1999). “An Efficient, Probabilistically
Sound Algorithm for Segmentation and Word Discovery”.
In: Machine Learning 34.1-3, pp. 71–105.
Michael R. Brent and Timothy A. Cartwright (1996). “Distri-
butional regularity and phonotactic constraints are useful
for segmentation”. In: Cognition 61 (1-2), pp. 93–125.
Morten H. Christiansen, Joseph Allen, and Mark S. Seiden-
berg (1998). “Learning to Segment Speech Using Multiple
Cues: A Connectionist Model”. In: Language and Cogni-
tive Processes 13.2, pp. 221–268.
Paul Cohen, Niall Adams, and Brent Heeringa (2007). “Vot-
ing experts: An unsupervised algorithm for segmenting se-
quences”. In: Intelligent Data Analysis 11.6, pp. 607–625.
C¸a˘grı C¸ ¨oltekin (2011). “Catching Words in a Stream of
Speech: Computational simulations of segmenting tran-
scribed child-directed speech”. PhD thesis. University of
Groningen.
Anne Cutler and Sally Butterfield (1992). “Rhythmic cues to
speech segmentation: Evidence from juncture mispercep-
tion”. In: Journal of Memory and Language 31.2, pp. 218–
236.
Delphine Dahan and James S. Magnuson (2006). “Spoken
Word Recognition”. In: Handbook of Psycholinguistics.
2nd. Elsevier. Chap. 8, pp. 249–283.
Jeffrey L. Elman (1990). “Finding Structure in Time”. In:
Cognitive Science 14, pp. 179–211.
Margaret M. Fleck (2008). “Lexicalized phonotactic word
segmentation”. In: Proceedings of the Annual Meeting of
the Association of Computational Linguistics (ACL-08),
pp. 130–138.
Timothy Gambell and Charles Yang (2006). Word segmenta-
tion: Quick but not dirty. Unpublished manuscript.
Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson
(2009). “A Bayesian framework for word segmentation:
Exploring the effects of context”. In: Cognition 112 (1),
pp. 21–54.
Katharine Graf Estes, Julia L. Evans, Martha W. Alibali, and
Jenny R. Saffran (2007). “Can Infants Map Meaning to
Newly Segmented Words? Statistical Segmentation and
Word Learning”. In: Psychological Science 18.3, pp. 254–
260.
Zellig S. Harris (1955). “From Phoneme to Morpheme”. In:
Language 31.2, pp. 190–222.
Gaja Jarosz and J. Alex Johnson (2013). “The Richness of
Distributional Cues to Word Boundaries in Speech to
Young Children”. In: Language Learning and Develop-
ment 9.2, pp. 175–210.
Elizabeth K. Johnson and Peter W. Jusczyk (2001). “Word
Segmentation by 8-Month-Olds: When Speech Cues
Count More Than Statistics”. In: Journal of Memory and
Language 44.4, pp. 548–567.
Mark Johnson and Sharon Goldwater (2009). “Improving
nonparameteric Bayesian inference: experiments on unsu-
pervised word segmentation with adaptor grammars”. In:
Proceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chapter of the
Association for Computational Linguistics, pp. 317–325.
Peter W. Jusczyk (1999). “How infants begin to extract
words from speech”. In: Trends in Cognitive Sciences 3.9,
pp. 323–328.
Peter W. Jusczyk, Anne Cutler, and Nancy J. Redanz (1993).
“Infants’ preference for the predominant stress patterns of
English words”. In: Child Development 64.3, pp. 675–
687.
Peter W. Jusczyk, Elizabeth A. Hohne, and Angela Bauman
(1999). “Infants’ sensitivity to allophonic cues for word
segmentation”. In: Perception and Psychophysics 61.8,
pp. 1465–1476.
Peter W. Jusczyk, Derek M. Houston, and Mary New-
some (1999). “The Beginnings of Word Segmentation in
English-Learning Infants”. In: Cognitive Psychology 39,
pp. 159–207.
Myron Korman (1984). “Adaptive aspects of maternal vocal-
izations in differing contexts at ten weeks”. In: First Lan-
guage 5, pp. 44–45.
Constantine Lignos (2011). “Modeling infant word segmen-
tation”. In: Proceedings of the Fifteenth Conference on
Computational Natural Language Learning, pp. 29–38.
Nick Littlestone and Manfred K. Warmuth (1994). “The
Weighted Majority Algorithm”. In: Information and Com-
putation 108.2, pp. 212–261.
Brian MacWhinney and Catherine Snow (1985). “The child
language data exchange system”. In: Journal of Child Lan-
guage 12.2, pp. 271–269.
David Marr (1982). Vision: A Computational Investigation
into the Human Representation and Processing of Visual
Information. New York: Freeman.
Padraic Monaghan and Morten H. Christiansen (2010).
“Words in puddles of sound: modelling psycholinguistic
effects in speech segmentation”. In: Journal of Child Lan-
guage 37.Special Issue 03, pp. 545–564.
Anand Narasimhamurthy (2005). “Theoretical Bounds of
Majority Voting Performance for a Binary Classification
Problem”. In: IEEE Trans. Pattern Anal. Mach. Intell. 27
(12), pp. 1988–1995.
Elissa L. Newport and Richard N. Aslin (2004). “Learning
at a distance: I. Statistical learning of non-adjacent depen-
dencies”. In: Cognitive Psychology 48.2, pp. 127–162.
Bruna Pelucchi, Jessica F. Hay, and Jenny R. Saffran (2009).
“Learning in reverse: Eight-month-old infants track back-
ward transitional probabilities”. In: Cognition 113.2,
pp. 244–247.
Pierre Perruchet and St´ephane Desaulty (2008). “A role
for backward transitional probabilities in word segmenta-
tion?” In: Memory and Cognition 36.7, pp. 1299–1305.
Jenny R. Saffran, Richard N. Aslin, and Elissa L. Newport
(1996). “Statistical learning by 8-month old infants”. In:
Science 274.5294, pp. 1926–1928.
Ivelin Stoianov and John Nerbonne (2000). “Exploring
Phonotactics with Simple Recurrent Networks”. In: Pro-
ceedings of Computational Linguistics in the Netherlands
1999. Ed. by Frank van Eynde, Ineke Schuurman, and
Ness Schelkens, pp. 51–67.
Kari Suomi, James M. McQueen, and Anne Cutler (1997).
“Vowel Harmony and Speech Segmentation in Finnish”.
In: Journal of Memory and Language 36.3, pp. 422–444.
</reference>
<page confidence="0.965607">
27
</page>
<reference confidence="0.998632642857143">
Daniel Swingley (2005). “Statistical clustering and the con-
tents of the infant vocabulary”. In: Cognitive Psychology
50.1, pp. 86–132.
Erik D. Thiessen and Jenny R. Saffran (2003). “When Cues
Collide: Use of Stress and Statistical Cues to Word Bound-
aries by 7- to 9-Month-Old Infants,” in: Developmental
Psychology 39.4, pp. 706–716.
Susan P. Thompson and Elissa L. Newport (2007). “Statisti-
cal Learning of Syntax: The Role of Transitional Probabil-
ity”. In: Language Learning and Development 3.1, pp. 1–
42.
Anand Venkataraman (2001). “A Statistical Model for Word
Discovery in Transcribed Speech”. In: Computational Lin-
guistics 27.3, pp. 351–372.
</reference>
<page confidence="0.999071">
28
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.738882">
<title confidence="0.878708">An explicit statistical model of learning lexical segmentation multiple cues</title>
<author confidence="0.763572">a˘grı ¨oltekin</author>
<affiliation confidence="0.97438">University of Groningen</affiliation>
<email confidence="0.982265">c.coltekin@rug.nl</email>
<abstract confidence="0.999881833333333">This paper presents an unsupervised and incremental model of learning segmentation that combines multiple cues whose use by children and adults were attested by experimental studies. The cues we exploit this study are stress partial lex- The performance of the model presented in this paper is competitive with the state-of-the-art segmentation models in the literature, while following the child language acquisition more faithfully. Besides the performance improvements over the similar models in the literature, the cues are combined in an explicit manner, allowing easier interpretation of what the model learns.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richard N Aslin</author>
<author>Julide Z Woodward</author>
<author>Nicholas P LaMendola</author>
<author>Thomas G Bever</author>
</authors>
<title>Models of Word Segmentation in Fluent Maternal Speech to Infants”. In: Signal to Syntax: Bootstrapping From Speech to Grammar in Early Acquisition.</title>
<date>1996</date>
<journal>Ed. by</journal>
<volume>8</volume>
<pages>117--134</pages>
<contexts>
<context position="13653" citStr="Aslin et al., 1996" startWordPosition="2217" endWordPosition="2220">ther source of information that can bootstrap the acquisition of lexical units.2 2There are a number of acoustic cues (e.g., pauses) that are highly correlated with lexical unit boundaries. However, we do not make use of them in this study since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boun</context>
</contexts>
<marker>Aslin, Woodward, LaMendola, Bever, 1996</marker>
<rawString>Richard N. Aslin, Julide Z. Woodward, Nicholas P. LaMendola, and Thomas G. Bever (1996). “Models of Word Segmentation in Fluent Maternal Speech to Infants”. In: Signal to Syntax: Bootstrapping From Speech to Grammar in Early Acquisition. Ed. by James L. Morgan and Katherine Demuth. Lawrence Erlbaum Associates. Chap. 8, pp. 117– 134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nan Bernstein Ratner</author>
</authors>
<title>The phonology of parentchild speech”. In: Children’s</title>
<date>1987</date>
<volume>6</volume>
<pages>159--174</pages>
<publisher>Erlbaum,</publisher>
<location>Hillsdale, NJ:</location>
<contexts>
<context position="19206" citStr="Ratner (1987)" startWordPosition="3117" endWordPosition="3118">d previously, we have two flavors for each indicator. One indicating the existence of words to the right of the boundary candidate (words beginning at the boundary), and the other indicating the existence of words the left of the boundary candidate (word ending at the boundary). As with the other cues, these result in a set of indicators whose primary source of information is the potential lexical units in the learner’s incomplete and noisy lexicon. 4 Experiments 4.1 Data We use a child-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). It was collected by Bernstein Ratner (1987) and the original orthographic transcription of the corpus was converted to a phonemic transcription by Brent and Cartwright (1996). The same corpus has been used by many recent studies. Following the convention in the literature the corpus will be called the BR corpus. For the results reported for segmentation strategies that make use of lexical stress, the BR corpus was marked for lexical stress semi-automatically following the procedure described by Christiansen et al. (1998) for annotating the Korman corpus (Korman, 1984). The stress assignment is done according to stress patterns in the M</context>
</contexts>
<marker>Ratner, 1987</marker>
<rawString>Nan Bernstein Ratner (1987). “The phonology of parentchild speech”. In: Children’s language. Ed. by K. Nelson and A. van Kleeck. Vol. 6. Hillsdale, NJ: Erlbaum, pp. 159–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<date>2006</date>
<booktitle>Pattern Recognition and Machine Learning.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="6485" citStr="Bishop, 2006" startWordPosition="1011" endWordPosition="1012"> available. In this section we define a method to segment a given utterance using multiple boundary indicators, or cues, and learn to segment better by estimating usefulness of each indicator. In essence, each indicator makes a decision on each potential boundary location. The method combines these indicators’ decisions to arrive at a hopefully more accurate decision. In machine learning terms, we formulate a number of binary classifiers, and aim to get a better classifier using a combination of them. This problems is a relatively well-studied subject in the machine learning literature (e.g., Bishop, 2006, chapter 14). Here a simple and well-known method, majority voting, will be used for combining multiple boundary indicators. Majority voting is a common (and arguably effective) method in everyday social and political life. As a result, it has been well studied, and known to work well especially if each voter’s decision is better than random on average, and votes are cast independently. In practice, even though the votes are almost never independent, majority voting is still an effective way of combining multiple classifiers (see Narasimhamurthy, 2005, for a discussion of the effectiveness of</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Christopher M. Bishop (2006). Pattern Recognition and Machine Learning. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Blanchard</author>
<author>Jeffrey Heinz</author>
<author>Roberta Golinkoff</author>
</authors>
<title>Modeling the contribution of phonotactic cues to the problem of word segmentation”.</title>
<date>2010</date>
<journal>In: Journal of Child Language 37.Special Issue</journal>
<volume>03</volume>
<pages>487--511</pages>
<contexts>
<context position="22603" citStr="Blanchard et al. (2010)" startWordPosition="3707" endWordPosition="3710"> the number of known words, and 0 &lt; α &lt; 1 is the only parameter of the model. In all experiments reported in this paper, we will fix α at 0.5. For the incremental model defined here, a word is ‘known’, if it was used in a previous segmentation. The model accepts whole utterances as single words if the utterance does not contain any known words. n r1 P(s) = 23 model boundary word lexicon P R F P R F P R F Brent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4 Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7 Goldwater et al. (2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1 Blanchard et al. (2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3 RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 Table 1: Performance scores of the reference models LM and RM in comparison with some of the earlier scores reported in the literature. If there were multiple models reported in a study, the result with the highest lexicon F-score is presented. All scores are obtained on the BR corpus. Table 1 compares the performances of some recent models in the literature using the BR corpus with the two reference models. The LM performs similar to the state-of-the-art</context>
</contexts>
<marker>Blanchard, Heinz, Golinkoff, 2010</marker>
<rawString>Daniel Blanchard, Jeffrey Heinz, and Roberta Golinkoff (2010). “Modeling the contribution of phonotactic cues to the problem of word segmentation”. In: Journal of Child Language 37.Special Issue 03, pp. 487–511.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>Advances in the computational study of language acquisition”.</title>
<date>1996</date>
<journal>In: Cognition</journal>
<volume>61</volume>
<pages>1--2</pages>
<contexts>
<context position="13856" citStr="Brent (1996)" startWordPosition="2251" endWordPosition="2252">make use of them in this study since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boundary. Using utterance boundaries and the pauses, Fleck (2008) presents a batch algorithm with a few ad hoc corrections that estimates the probabilities P(b), P(l|b), P(r|b), P(l), P(r), and uses Bayesian</context>
</contexts>
<marker>Brent, 1996</marker>
<rawString>Michael R. Brent (1996). “Advances in the computational study of language acquisition”. In: Cognition 61 (1-2), pp. 1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
</authors>
<title>An Efficient, Probabilistically Sound Algorithm for Segmentation and Word Discovery”. In:</title>
<date>1999</date>
<booktitle>Machine Learning 34.1-3,</booktitle>
<pages>71--105</pages>
<contexts>
<context position="3680" citStr="Brent, 1999" startWordPosition="560" endWordPosition="561">tatistics (included implicitly in any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that what a connectionist model learns is rather difficult to interpret. Furthermore, the performance achieved using connectionist models is far lower than that is expected from humans. Models that use explicit representations in combination with statistical procedures (e.g., Brent and Cartwright, 1996; Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; M. Johnson and Goldwater, 2009) avoid both problems: these models perform better, and it is easier to reason about what they learn. Although these models were also instrumental in our understanding of the problem, they lack at least two aspects of con19 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation</context>
<context position="17551" citStr="Brent, 1999" startWordPosition="2844" endWordPosition="2845">tialpeak boundary decision strategy in combination with the weighted majority voting algorithm, as before, we define a set of boundary indicators and operationalize lexical stress as another cue for segmentation. 3.4 Lexicon For adults, a comprehensive lexicon is probably the most useful cue for segmentation. We do not expect infants to have a lexicon at the beginning. However, as they build their lexicon, or ‘proto-lexicon’, they may put it in use for discovering novel lexical units. This is the main strategy behind the majority of state-of-the-art computational models of segmentation (e.g., Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009). The models that guess boundaries rarely build and use an explicit lexicon (exceptions include Monaghan and Christiansen, 2010). In this study we also experiment with an (admittedly naive) set of lexical cues to word boundaries. The idea is to indicate a boundary when there are word-like strings on both sides of the boundary candidate. In our usual majority voting framework, these form two additional sets of boundary indicators. First, given a possible boundary loca22 tion, we simply count the frequencies of already known words beginning or ending </context>
<context position="22400" citStr="Brent (1999)" startWordPosition="3672" endWordPosition="3673">nown where s is a sequence of phonemes (e.g., an utterance or a corpus), wi is the ith word in the sequence, ai is the ith sound in the word, f(w) is the relative frequency of the word w, m is the number of known words, and 0 &lt; α &lt; 1 is the only parameter of the model. In all experiments reported in this paper, we will fix α at 0.5. For the incremental model defined here, a word is ‘known’, if it was used in a previous segmentation. The model accepts whole utterances as single words if the utterance does not contain any known words. n r1 P(s) = 23 model boundary word lexicon P R F P R F P R F Brent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4 Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7 Goldwater et al. (2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1 Blanchard et al. (2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3 RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 Table 1: Performance scores of the reference models LM and RM in comparison with some of the earlier scores reported in the literature. If there were multiple models reported in a study, the result with the highest lexicon F-score is presented. All scores </context>
<context position="25468" citStr="Brent (1999)" startWordPosition="4201" endWordPosition="4202">ation to segment later utterances in the input.3 We first report the performance results of individual cues, namely, predictability (P), utterance boundaries (U), lexical information (W) and lexical stress (S) in Table 2. Using the predictability cue alone leads to a segmentation performance lower than but close to the state-of-the-art reference model LM. Although these results are not directly comparable to the earlier studies in the literature, the performance scores presented in Table 2 are the best scores presented to date for models using the predictability cue alone. Graphs presented by Brent (1999) indicates about 50%–60% WP and WR and 20%– 30% LP for his baseline model utilizing mutual information on the BR corpus. Cohen et al. (2007) report 76% BP, and 75% BR on George Orwell’s 1984. Christiansen et al. (1998) report 37% WP and 40% WR with an SRN using phonotactics and utterance boundary cues on another child-directed speech corpus (Korman, 1984). The model that learns from the utterance boundaries seems to perform the best. The results are comparable, and in some cases better than the LM. Furthermore, the overall scores are also higher than the scores reported by Fleck (2008), where </context>
</contexts>
<marker>Brent, 1999</marker>
<rawString>Michael R. Brent (1999). “An Efficient, Probabilistically Sound Algorithm for Segmentation and Word Discovery”. In: Machine Learning 34.1-3, pp. 71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael R Brent</author>
<author>Timothy A Cartwright</author>
</authors>
<title>Distributional regularity and phonotactic constraints are useful for segmentation”.</title>
<date>1996</date>
<journal>In: Cognition</journal>
<volume>61</volume>
<pages>1--2</pages>
<contexts>
<context position="3667" citStr="Brent and Cartwright, 1996" startWordPosition="556" endWordPosition="559">cal stress, predictability statistics (included implicitly in any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that what a connectionist model learns is rather difficult to interpret. Furthermore, the performance achieved using connectionist models is far lower than that is expected from humans. Models that use explicit representations in combination with statistical procedures (e.g., Brent and Cartwright, 1996; Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; M. Johnson and Goldwater, 2009) avoid both problems: these models perform better, and it is easier to reason about what they learn. Although these models were also instrumental in our understanding of the problem, they lack at least two aspects of con19 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human</context>
<context position="19337" citStr="Brent and Cartwright (1996)" startWordPosition="3134" endWordPosition="3137">ary candidate (words beginning at the boundary), and the other indicating the existence of words the left of the boundary candidate (word ending at the boundary). As with the other cues, these result in a set of indicators whose primary source of information is the potential lexical units in the learner’s incomplete and noisy lexicon. 4 Experiments 4.1 Data We use a child-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). It was collected by Bernstein Ratner (1987) and the original orthographic transcription of the corpus was converted to a phonemic transcription by Brent and Cartwright (1996). The same corpus has been used by many recent studies. Following the convention in the literature the corpus will be called the BR corpus. For the results reported for segmentation strategies that make use of lexical stress, the BR corpus was marked for lexical stress semi-automatically following the procedure described by Christiansen et al. (1998) for annotating the Korman corpus (Korman, 1984). The stress assignment is done according to stress patterns in the MRC psycholinguistic database. All single-syllable words are coded as having primary stress, and the words that were not found or di</context>
<context position="21428" citStr="Brent and Cartwright, 1996" startWordPosition="3475" endWordPosition="3478"> internal positions in the corpus. Similarly, Eu is the ratio of boundaries missed to the total number of boundaries. Although these error measures are related to precision and recall, they provide different, and sometimes better, insights into the model’s behavior. 4.3 Reference models In this paper, we compare the results obtained by the cue combination model with two baselines. The first baseline is a random model (RM) that assigns boundaries with the probability of boundaries in the input corpus. The RM is more informed than a completely random classifier, but it has been customary (since Brent and Cartwright, 1996) in segmentation literature to set the bar a little bit higher. The second reference model is a lexicon-building model similar to many state-ofthe-art models. The model described here, which we call LM, assigns probabilities to possible segmentations as described in Equations 1 and 2. P(wi) (1) P(w) = (1 − α) f(w) if w is known (2) iαHIL&apos;=1 P(ai) if w is unknown where s is a sequence of phonemes (e.g., an utterance or a corpus), wi is the ith word in the sequence, ai is the ith sound in the word, f(w) is the relative frequency of the word w, m is the number of known words, and 0 &lt; α &lt; 1 is the</context>
</contexts>
<marker>Brent, Cartwright, 1996</marker>
<rawString>Michael R. Brent and Timothy A. Cartwright (1996). “Distributional regularity and phonotactic constraints are useful for segmentation”. In: Cognition 61 (1-2), pp. 93–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morten H Christiansen</author>
<author>Joseph Allen</author>
<author>Mark S Seidenberg</author>
</authors>
<title>Learning to Segment Speech Using Multiple Cues: A Connectionist Model”. In:</title>
<date>1998</date>
<booktitle>Language and Cognitive Processes 13.2,</booktitle>
<pages>221--268</pages>
<contexts>
<context position="2770" citStr="Christiansen et al., 1998" startWordPosition="423" endWordPosition="426">ffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been proposed in the literature. The early studies typically made use of connectionist models (e.g., Elman, 1990; Christiansen et al., 1998). Of these studies, Christiansen et al. (1998) is particularly interesting for the present study since it incorporates most of the cues used in this study. Using a simple recurrent network (SRN, Elman, 1990), Christiansen et al. (1998) demonstrated the usefulness of lexical stress, predictability statistics (included implicitly in any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that w</context>
<context position="13680" citStr="Christiansen et al., 1998" startWordPosition="2221" endWordPosition="2224">mation that can bootstrap the acquisition of lexical units.2 2There are a number of acoustic cues (e.g., pauses) that are highly correlated with lexical unit boundaries. However, we do not make use of them in this study since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boundary. Using utterance bound</context>
<context position="15843" citStr="Christiansen et al. (1998)" startWordPosition="2567" endWordPosition="2571"> one of the cues for segmentation that is well supported by psycholinguistic research (e.g., Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999; Jusczyk, 1999). Lexical stress is used in many languages for marking the prominent syllable in a word. For languages that exhibit lexical stress, the prominent syllable will typically be in a particular position in the word, allowing discovery of the boundaries based on the position of stressed syllable. Despite the prominence of stress as a cue for segmentation, there are relatively few computational studies that investigate use of stress. Christiansen et al. (1998) incorporates stress as a cue in their connectionist cue combination system. Swingley (2005) provides a careful analysis of stress patterns of the bisyllabic words found by a discovery procedure on mutual information and frequency. Gambell and Yang (2006) present surprisingly good segmentation results with a rulebased learner whose main source of information is lexical stress. One of the major problems with the these studies, which has also been carried over to the present study, is the lack of corpora with realistic stress assignment (see Section 4.1). Our stress-based strategy is similar to </context>
<context position="19689" citStr="Christiansen et al. (1998)" startWordPosition="3190" endWordPosition="3193">1 Data We use a child-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). It was collected by Bernstein Ratner (1987) and the original orthographic transcription of the corpus was converted to a phonemic transcription by Brent and Cartwright (1996). The same corpus has been used by many recent studies. Following the convention in the literature the corpus will be called the BR corpus. For the results reported for segmentation strategies that make use of lexical stress, the BR corpus was marked for lexical stress semi-automatically following the procedure described by Christiansen et al. (1998) for annotating the Korman corpus (Korman, 1984). The stress assignment is done according to stress patterns in the MRC psycholinguistic database. All single-syllable words are coded as having primary stress, and the words that were not found or did not have stress assignment in the MRC database were annotated manually. 4.2 Evaluation metrics Two quantitative measures, precision (P), recall (R) and their harmonic mean F1-score (F-score, or F, for short), have become the standard evaluation measures for computational simulations. Following recent studies in the literature we present precision r</context>
<context position="25686" citStr="Christiansen et al. (1998)" startWordPosition="4239" endWordPosition="4242">s (S) in Table 2. Using the predictability cue alone leads to a segmentation performance lower than but close to the state-of-the-art reference model LM. Although these results are not directly comparable to the earlier studies in the literature, the performance scores presented in Table 2 are the best scores presented to date for models using the predictability cue alone. Graphs presented by Brent (1999) indicates about 50%–60% WP and WR and 20%– 30% LP for his baseline model utilizing mutual information on the BR corpus. Cohen et al. (2007) report 76% BP, and 75% BR on George Orwell’s 1984. Christiansen et al. (1998) report 37% WP and 40% WR with an SRN using phonotactics and utterance boundary cues on another child-directed speech corpus (Korman, 1984). The model that learns from the utterance boundaries seems to perform the best. The results are comparable, and in some cases better than the LM. Furthermore, the overall scores are also higher than the scores reported by Fleck (2008), where the boundary, word and lexical F-scores were 82.9%, 70.7% and 36.6%, respectively. Although it is somewhat behind both predictability and utterance boundary cues, the lexical information alone certainly performs better</context>
<context position="31562" citStr="Christiansen et al. (1998)" startWordPosition="5245" endWordPosition="5248">o be useful, and increases the overall performance of the combined model. 5 General discussion This paper introduced an unsupervised and incremental model of segmentation that focuses on combining multiple cues relevant to child language acquisition as attested by earlier studies in psycholinguistics. Unsupervised and incremental models of segmentation that combine multiple cues are not new. There have been many models sharing these properties to some extent. In particular, the model presented in this paper has many similarities with an earlier connectionist model of segmentation presented by Christiansen et al. (1998). However, unlike connectionist models, the model presented here uses accessible explicit representations, and an concrete learning procedure. Most recent models with explicit representations and statistical learning procedures tend to be models that process their input in ‘batch’. These models typically perform better when measured at the overall best performance level, and the insights 25 (a) Oversegmentation errors 1 2 3 4 5 6 7 8 9 10 1000 uttrances (b) Undersegmentation errors 1 2 3 4 5 6 7 8 9 10 1000 uttrances Error rate 0.0 0.2 0.4 0.6 0.8 PU PUW PUWS LM 0.0 0.2 0.4 0.6 0.8 PU PUW PUWS</context>
</contexts>
<marker>Christiansen, Allen, Seidenberg, 1998</marker>
<rawString>Morten H. Christiansen, Joseph Allen, and Mark S. Seidenberg (1998). “Learning to Segment Speech Using Multiple Cues: A Connectionist Model”. In: Language and Cognitive Processes 13.2, pp. 221–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cohen</author>
<author>Niall Adams</author>
<author>Brent Heeringa</author>
</authors>
<title>Voting experts: An unsupervised algorithm for segmenting sequences”.</title>
<date>2007</date>
<journal>In: Intelligent Data Analysis</journal>
<volume>11</volume>
<pages>607--625</pages>
<contexts>
<context position="25608" citStr="Cohen et al. (2007)" startWordPosition="4225" endWordPosition="4228">P), utterance boundaries (U), lexical information (W) and lexical stress (S) in Table 2. Using the predictability cue alone leads to a segmentation performance lower than but close to the state-of-the-art reference model LM. Although these results are not directly comparable to the earlier studies in the literature, the performance scores presented in Table 2 are the best scores presented to date for models using the predictability cue alone. Graphs presented by Brent (1999) indicates about 50%–60% WP and WR and 20%– 30% LP for his baseline model utilizing mutual information on the BR corpus. Cohen et al. (2007) report 76% BP, and 75% BR on George Orwell’s 1984. Christiansen et al. (1998) report 37% WP and 40% WR with an SRN using phonotactics and utterance boundary cues on another child-directed speech corpus (Korman, 1984). The model that learns from the utterance boundaries seems to perform the best. The results are comparable, and in some cases better than the LM. Furthermore, the overall scores are also higher than the scores reported by Fleck (2008), where the boundary, word and lexical F-scores were 82.9%, 70.7% and 36.6%, respectively. Although it is somewhat behind both predictability and ut</context>
</contexts>
<marker>Cohen, Adams, Heeringa, 2007</marker>
<rawString>Paul Cohen, Niall Adams, and Brent Heeringa (2007). “Voting experts: An unsupervised algorithm for segmenting sequences”. In: Intelligent Data Analysis 11.6, pp. 607–625.</rawString>
</citation>
<citation valid="false">
<authors>
<author>C¸a˘grı C¸</author>
</authors>
<title>oltekin (2011). “Catching Words in a Stream of Speech: Computational simulations of segmenting transcribed child-directed speech”. PhD thesis.</title>
<institution>University of Groningen.</institution>
<marker>C¸, </marker>
<rawString>C¸a˘grı C¸ ¨oltekin (2011). “Catching Words in a Stream of Speech: Computational simulations of segmenting transcribed child-directed speech”. PhD thesis. University of Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Cutler</author>
<author>Sally Butterfield</author>
</authors>
<title>Rhythmic cues to speech segmentation: Evidence from juncture misperception”.</title>
<date>1992</date>
<journal>In: Journal of Memory and Language</journal>
<volume>31</volume>
<pages>218--236</pages>
<contexts>
<context position="2034" citStr="Cutler and Butterfield, 1992" startWordPosition="309" endWordPosition="312">nsive lexicon and an error-free representation of the acoustic input, the problem is not trivial, since the input is often compatible with multiple segmentations spanning the complete utterance. The problem, however, is even more difficult for a learner who starts with no lexicon. Fortunately, the lexicon is not the only aid for segmentation. Experimental research within last two decades has revealed an array of cues that are used by adults and children for lexical segmentation. These cues include, but are not John Nerbonne University of Groningen j.nerbonne@rug.nl limited to, lexical stress (Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999), phonotactics (Jusczyk, Cutler, et al., 1993), predictability statistics (Saffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been</context>
<context position="15338" citStr="Cutler and Butterfield, 1992" startWordPosition="2486" endWordPosition="2489">timated from the utterance edges in the input corpus, and can be used as cues for discovering non-initial or nonfinal boundaries. Similar to the predictability, using different length l and r we obtain a set of indicators for P(ub|r) and P(ub|l). Unlike P(b|l, r), for P(ub|r) and P(ub|l) we do not have a straightforward threshold to make a boundary decision. Instead, we appeal to the familiar solution, and use ‘partial peaks’ in these values as boundary indications. 3.3 Lexical stress Lexical stress is one of the cues for segmentation that is well supported by psycholinguistic research (e.g., Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999; Jusczyk, 1999). Lexical stress is used in many languages for marking the prominent syllable in a word. For languages that exhibit lexical stress, the prominent syllable will typically be in a particular position in the word, allowing discovery of the boundaries based on the position of stressed syllable. Despite the prominence of stress as a cue for segmentation, there are relatively few computational studies that investigate use of stress. Christiansen et al. (1998) incorporates stress as a cue in their connectionist cue combination system. Swingley (2005) pr</context>
</contexts>
<marker>Cutler, Butterfield, 1992</marker>
<rawString>Anne Cutler and Sally Butterfield (1992). “Rhythmic cues to speech segmentation: Evidence from juncture misperception”. In: Journal of Memory and Language 31.2, pp. 218– 236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delphine Dahan</author>
<author>James S Magnuson</author>
</authors>
<title>Spoken Word Recognition”. In:</title>
<date>2006</date>
<booktitle>Handbook of Psycholinguistics. 2nd. Elsevier. Chap.</booktitle>
<volume>8</volume>
<pages>249--283</pages>
<contexts>
<context position="1219" citStr="Dahan and Magnuson, 2006" startWordPosition="181" endWordPosition="184">e, while following the child language acquisition more faithfully. Besides the performance improvements over the similar models in the literature, the cues are combined in an explicit manner, allowing easier interpretation of what the model learns. 1 Introduction Segmenting the continuous speech stream into lexical units is one of the challenges we face while listening to other speakers. For competent language users, probably the biggest aid in identifying the word boundaries is the knowledge of the words. Not surprisingly, the models of adult word recognition depend heavily on a lexicon (see Dahan and Magnuson, 2006, for a recent review). The same can be observed in speech and language technology where all automatic speech recognition systems make use of a comprehensive lexicon. Even with a comprehensive lexicon and an error-free representation of the acoustic input, the problem is not trivial, since the input is often compatible with multiple segmentations spanning the complete utterance. The problem, however, is even more difficult for a learner who starts with no lexicon. Fortunately, the lexicon is not the only aid for segmentation. Experimental research within last two decades has revealed an array </context>
</contexts>
<marker>Dahan, Magnuson, 2006</marker>
<rawString>Delphine Dahan and James S. Magnuson (2006). “Spoken Word Recognition”. In: Handbook of Psycholinguistics. 2nd. Elsevier. Chap. 8, pp. 249–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey L Elman</author>
</authors>
<title>Finding Structure in Time”.</title>
<date>1990</date>
<journal>In: Cognitive Science</journal>
<volume>14</volume>
<pages>179--211</pages>
<contexts>
<context position="2742" citStr="Elman, 1990" startWordPosition="421" endWordPosition="422">tatistics (Saffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been proposed in the literature. The early studies typically made use of connectionist models (e.g., Elman, 1990; Christiansen et al., 1998). Of these studies, Christiansen et al. (1998) is particularly interesting for the present study since it incorporates most of the cues used in this study. Using a simple recurrent network (SRN, Elman, 1990), Christiansen et al. (1998) demonstrated the usefulness of lexical stress, predictability statistics (included implicitly in any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been sub</context>
</contexts>
<marker>Elman, 1990</marker>
<rawString>Jeffrey L. Elman (1990). “Finding Structure in Time”. In: Cognitive Science 14, pp. 179–211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margaret M Fleck</author>
</authors>
<title>Lexicalized phonotactic word segmentation”. In:</title>
<date>2008</date>
<booktitle>Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL-08),</booktitle>
<pages>130--138</pages>
<contexts>
<context position="13870" citStr="Fleck (2008)" startWordPosition="2253" endWordPosition="2254">em in this study since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boundary. Using utterance boundaries and the pauses, Fleck (2008) presents a batch algorithm with a few ad hoc corrections that estimates the probabilities P(b), P(l|b), P(r|b), P(l), P(r), and uses Bayesian inversion to </context>
<context position="26060" citStr="Fleck (2008)" startWordPosition="4303" endWordPosition="4304">nted by Brent (1999) indicates about 50%–60% WP and WR and 20%– 30% LP for his baseline model utilizing mutual information on the BR corpus. Cohen et al. (2007) report 76% BP, and 75% BR on George Orwell’s 1984. Christiansen et al. (1998) report 37% WP and 40% WR with an SRN using phonotactics and utterance boundary cues on another child-directed speech corpus (Korman, 1984). The model that learns from the utterance boundaries seems to perform the best. The results are comparable, and in some cases better than the LM. Furthermore, the overall scores are also higher than the scores reported by Fleck (2008), where the boundary, word and lexical F-scores were 82.9%, 70.7% and 36.6%, respectively. Although it is somewhat behind both predictability and utterance boundary cues, the lexical information alone certainly performs better than random. The lower performance of this model in comparison to ‘U’ suggests that, at least in this setting, phonotactics learned from word tokens found at the utterance edges leads to a better performance compared to the phonotactics learned from the word types in the learner’s lexicon. The experiment that takes only the stress cue into account yields the worst overal</context>
</contexts>
<marker>Fleck, 2008</marker>
<rawString>Margaret M. Fleck (2008). “Lexicalized phonotactic word segmentation”. In: Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL-08), pp. 130–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Gambell</author>
<author>Charles Yang</author>
</authors>
<title>Word segmentation: Quick but not dirty.</title>
<date>2006</date>
<note>Unpublished manuscript.</note>
<contexts>
<context position="16098" citStr="Gambell and Yang (2006)" startWordPosition="2606" endWordPosition="2609">For languages that exhibit lexical stress, the prominent syllable will typically be in a particular position in the word, allowing discovery of the boundaries based on the position of stressed syllable. Despite the prominence of stress as a cue for segmentation, there are relatively few computational studies that investigate use of stress. Christiansen et al. (1998) incorporates stress as a cue in their connectionist cue combination system. Swingley (2005) provides a careful analysis of stress patterns of the bisyllabic words found by a discovery procedure on mutual information and frequency. Gambell and Yang (2006) present surprisingly good segmentation results with a rulebased learner whose main source of information is lexical stress. One of the major problems with the these studies, which has also been carried over to the present study, is the lack of corpora with realistic stress assignment (see Section 4.1). Our stress-based strategy is similar to the strategy used for learning phonotactics described in Section 3.2. Instead of collecting statistics about phoneme n-grams, we collect statistics over stress assignments on phoneme n-grams. However, the probabilities are estimated over already known lex</context>
</contexts>
<marker>Gambell, Yang, 2006</marker>
<rawString>Timothy Gambell and Charles Yang (2006). Word segmentation: Quick but not dirty. Unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Thomas L Griffiths</author>
<author>Mark Johnson</author>
</authors>
<title>A Bayesian framework for word segmentation: Exploring the effects of context”. In:</title>
<date>2009</date>
<journal>Cognition</journal>
<volume>112</volume>
<issue>1</issue>
<pages>21--54</pages>
<contexts>
<context position="3724" citStr="Goldwater et al., 2009" startWordPosition="565" endWordPosition="568"> any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that what a connectionist model learns is rather difficult to interpret. Furthermore, the performance achieved using connectionist models is far lower than that is expected from humans. Models that use explicit representations in combination with statistical procedures (e.g., Brent and Cartwright, 1996; Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; M. Johnson and Goldwater, 2009) avoid both problems: these models perform better, and it is easier to reason about what they learn. Although these models were also instrumental in our understanding of the problem, they lack at least two aspects of con19 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation is incremental and predictive, most of thes</context>
<context position="17596" citStr="Goldwater et al., 2009" startWordPosition="2848" endWordPosition="2851">gy in combination with the weighted majority voting algorithm, as before, we define a set of boundary indicators and operationalize lexical stress as another cue for segmentation. 3.4 Lexicon For adults, a comprehensive lexicon is probably the most useful cue for segmentation. We do not expect infants to have a lexicon at the beginning. However, as they build their lexicon, or ‘proto-lexicon’, they may put it in use for discovering novel lexical units. This is the main strategy behind the majority of state-of-the-art computational models of segmentation (e.g., Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009). The models that guess boundaries rarely build and use an explicit lexicon (exceptions include Monaghan and Christiansen, 2010). In this study we also experiment with an (admittedly naive) set of lexical cues to word boundaries. The idea is to indicate a boundary when there are word-like strings on both sides of the boundary candidate. In our usual majority voting framework, these form two additional sets of boundary indicators. First, given a possible boundary loca22 tion, we simply count the frequencies of already known words beginning or ending at the position in question. The second indic</context>
<context position="22534" citStr="Goldwater et al. (2009)" startWordPosition="3694" endWordPosition="3697">sound in the word, f(w) is the relative frequency of the word w, m is the number of known words, and 0 &lt; α &lt; 1 is the only parameter of the model. In all experiments reported in this paper, we will fix α at 0.5. For the incremental model defined here, a word is ‘known’, if it was used in a previous segmentation. The model accepts whole utterances as single words if the utterance does not contain any known words. n r1 P(s) = 23 model boundary word lexicon P R F P R F P R F Brent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4 Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7 Goldwater et al. (2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1 Blanchard et al. (2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3 RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 Table 1: Performance scores of the reference models LM and RM in comparison with some of the earlier scores reported in the literature. If there were multiple models reported in a study, the result with the highest lexicon F-score is presented. All scores are obtained on the BR corpus. Table 1 compares the performances of some recent models in the literature using the BR corpus with the </context>
</contexts>
<marker>Goldwater, Griffiths, Johnson, 2009</marker>
<rawString>Sharon Goldwater, Thomas L. Griffiths, and Mark Johnson (2009). “A Bayesian framework for word segmentation: Exploring the effects of context”. In: Cognition 112 (1), pp. 21–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharine Graf Estes</author>
<author>Julia L Evans</author>
<author>Martha W Alibali</author>
<author>Jenny R Saffran</author>
</authors>
<title>Can Infants Map Meaning to Newly Segmented Words? Statistical Segmentation and Word Learning”. In:</title>
<date>2007</date>
<journal>Psychological Science</journal>
<volume>18</volume>
<pages>254--260</pages>
<contexts>
<context position="9933" citStr="Estes et al., 2007" startWordPosition="1583" endWordPosition="1586"> is low. However, until the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surprise), to define a set of boundary indicators. The first one, pointwise mutual information (MI) is defined as P(l, r) MI(l, r) = log2 P(l)P(r) where l and r are strings of phonemes to the left and right of the possible boundary location. We define our second measure, boundary entropy (H) of a potential boundary after string l as H(l) = − � P(r|l)log2 (P (r|l)) r∈A w</context>
</contexts>
<marker>Estes, Evans, Alibali, Saffran, 2007</marker>
<rawString>Katharine Graf Estes, Julia L. Evans, Martha W. Alibali, and Jenny R. Saffran (2007). “Can Infants Map Meaning to Newly Segmented Words? Statistical Segmentation and Word Learning”. In: Psychological Science 18.3, pp. 254– 260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig S Harris</author>
</authors>
<title>From Phoneme to Morpheme”.</title>
<date>1955</date>
<journal>In: Language</journal>
<volume>31</volume>
<pages>190--222</pages>
<contexts>
<context position="9111" citStr="Harris (1955)" startWordPosition="1458" endWordPosition="1459">ajority decision almost all the time, the weight stays close to one. 3 Cues and boundary indicators The combination method above allows us to combine an arbitrary number of boundary indicators. In our setting, each psychologically motivated cue is represented by multiple boundary indicators that 20 differ based on the source of information used and the way this information is turned into a quantitative measure. This section introduces all of these cues, and the boundary indicators that stem from quantification of these cues in different ways. 3.1 Predictability statistics At least as early as Harris (1955), it was known that a simple property of natural language utterances can aid identifying the lexical units that form an utterance: predictability within the units is high, predictability between the units is low. However, until the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large n</context>
</contexts>
<marker>Harris, 1955</marker>
<rawString>Zellig S. Harris (1955). “From Phoneme to Morpheme”. In: Language 31.2, pp. 190–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gaja Jarosz</author>
<author>J Alex Johnson</author>
</authors>
<title>The Richness of Distributional Cues to Word Boundaries in Speech to Young Children”. In:</title>
<date>2013</date>
<booktitle>Language Learning and Development 9.2,</booktitle>
<pages>175--210</pages>
<marker>Jarosz, Johnson, 2013</marker>
<rawString>Gaja Jarosz and J. Alex Johnson (2013). “The Richness of Distributional Cues to Word Boundaries in Speech to Young Children”. In: Language Learning and Development 9.2, pp. 175–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elizabeth K Johnson</author>
<author>Peter W Jusczyk</author>
</authors>
<title>Word Segmentation by 8-Month-Olds: When Speech Cues Count More Than Statistics”. In:</title>
<date>2001</date>
<journal>Journal of Memory and Language</journal>
<volume>44</volume>
<pages>548--567</pages>
<contexts>
<context position="2268" citStr="Johnson and Jusczyk, 2001" startWordPosition="343" endWordPosition="346">ult for a learner who starts with no lexicon. Fortunately, the lexicon is not the only aid for segmentation. Experimental research within last two decades has revealed an array of cues that are used by adults and children for lexical segmentation. These cues include, but are not John Nerbonne University of Groningen j.nerbonne@rug.nl limited to, lexical stress (Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999), phonotactics (Jusczyk, Cutler, et al., 1993), predictability statistics (Saffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been proposed in the literature. The early studies typically made use of connectionist models (e.g., Elman, 1990; Christiansen et al., 1998). Of these studies, Christiansen et al. (1998) is particularly interesting for the present study s</context>
</contexts>
<marker>Johnson, Jusczyk, 2001</marker>
<rawString>Elizabeth K. Johnson and Peter W. Jusczyk (2001). “Word Segmentation by 8-Month-Olds: When Speech Cues Count More Than Statistics”. In: Journal of Memory and Language 44.4, pp. 548–567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Sharon Goldwater</author>
</authors>
<title>Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars”. In:</title>
<date>2009</date>
<booktitle>Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>317--325</pages>
<contexts>
<context position="3757" citStr="Johnson and Goldwater, 2009" startWordPosition="570" endWordPosition="573">nce boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that what a connectionist model learns is rather difficult to interpret. Furthermore, the performance achieved using connectionist models is far lower than that is expected from humans. Models that use explicit representations in combination with statistical procedures (e.g., Brent and Cartwright, 1996; Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; M. Johnson and Goldwater, 2009) avoid both problems: these models perform better, and it is easier to reason about what they learn. Although these models were also instrumental in our understanding of the problem, they lack at least two aspects of con19 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation is incremental and predictive, most of these models process their input eith</context>
</contexts>
<marker>Johnson, Goldwater, 2009</marker>
<rawString>Mark Johnson and Sharon Goldwater (2009). “Improving nonparameteric Bayesian inference: experiments on unsupervised word segmentation with adaptor grammars”. In: Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 317–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
</authors>
<title>How infants begin to extract words from speech”. In:</title>
<date>1999</date>
<booktitle>Trends in Cognitive Sciences 3.9,</booktitle>
<pages>323--328</pages>
<contexts>
<context position="15386" citStr="Jusczyk, 1999" startWordPosition="2496" endWordPosition="2497">be used as cues for discovering non-initial or nonfinal boundaries. Similar to the predictability, using different length l and r we obtain a set of indicators for P(ub|r) and P(ub|l). Unlike P(b|l, r), for P(ub|r) and P(ub|l) we do not have a straightforward threshold to make a boundary decision. Instead, we appeal to the familiar solution, and use ‘partial peaks’ in these values as boundary indications. 3.3 Lexical stress Lexical stress is one of the cues for segmentation that is well supported by psycholinguistic research (e.g., Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999; Jusczyk, 1999). Lexical stress is used in many languages for marking the prominent syllable in a word. For languages that exhibit lexical stress, the prominent syllable will typically be in a particular position in the word, allowing discovery of the boundaries based on the position of stressed syllable. Despite the prominence of stress as a cue for segmentation, there are relatively few computational studies that investigate use of stress. Christiansen et al. (1998) incorporates stress as a cue in their connectionist cue combination system. Swingley (2005) provides a careful analysis of stress patterns of </context>
</contexts>
<marker>Jusczyk, 1999</marker>
<rawString>Peter W. Jusczyk (1999). “How infants begin to extract words from speech”. In: Trends in Cognitive Sciences 3.9, pp. 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>Anne Cutler</author>
<author>Nancy J Redanz</author>
</authors>
<title>Infants’ preference for the predominant stress patterns of English words”.</title>
<date>1993</date>
<journal>In: Child Development</journal>
<volume>64</volume>
<pages>675--687</pages>
<marker>Jusczyk, Cutler, Redanz, 1993</marker>
<rawString>Peter W. Jusczyk, Anne Cutler, and Nancy J. Redanz (1993). “Infants’ preference for the predominant stress patterns of English words”. In: Child Development 64.3, pp. 675– 687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>Elizabeth A Hohne</author>
<author>Angela Bauman</author>
</authors>
<title>Infants’ sensitivity to allophonic cues for word segmentation”. In: Perception and Psychophysics 61.8,</title>
<date>1999</date>
<pages>1465--1476</pages>
<marker>Jusczyk, Hohne, Bauman, 1999</marker>
<rawString>Peter W. Jusczyk, Elizabeth A. Hohne, and Angela Bauman (1999). “Infants’ sensitivity to allophonic cues for word segmentation”. In: Perception and Psychophysics 61.8, pp. 1465–1476.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Jusczyk</author>
<author>Derek M Houston</author>
<author>Mary Newsome</author>
</authors>
<date>1999</date>
<booktitle>The Beginnings of Word Segmentation in English-Learning Infants”. In: Cognitive Psychology 39,</booktitle>
<pages>159--207</pages>
<marker>Jusczyk, Houston, Newsome, 1999</marker>
<rawString>Peter W. Jusczyk, Derek M. Houston, and Mary Newsome (1999). “The Beginnings of Word Segmentation in English-Learning Infants”. In: Cognitive Psychology 39, pp. 159–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myron Korman</author>
</authors>
<title>Adaptive aspects of maternal vocalizations in differing contexts at ten weeks”.</title>
<date>1984</date>
<journal>In: First Language</journal>
<volume>5</volume>
<pages>44--45</pages>
<contexts>
<context position="19737" citStr="Korman, 1984" startWordPosition="3199" endWordPosition="3200"> database (MacWhinney and Snow, 1985). It was collected by Bernstein Ratner (1987) and the original orthographic transcription of the corpus was converted to a phonemic transcription by Brent and Cartwright (1996). The same corpus has been used by many recent studies. Following the convention in the literature the corpus will be called the BR corpus. For the results reported for segmentation strategies that make use of lexical stress, the BR corpus was marked for lexical stress semi-automatically following the procedure described by Christiansen et al. (1998) for annotating the Korman corpus (Korman, 1984). The stress assignment is done according to stress patterns in the MRC psycholinguistic database. All single-syllable words are coded as having primary stress, and the words that were not found or did not have stress assignment in the MRC database were annotated manually. 4.2 Evaluation metrics Two quantitative measures, precision (P), recall (R) and their harmonic mean F1-score (F-score, or F, for short), have become the standard evaluation measures for computational simulations. Following recent studies in the literature we present precision recall and F-scores for boundaries (BP, BR, BF), </context>
<context position="25825" citStr="Korman, 1984" startWordPosition="4263" endWordPosition="4264">. Although these results are not directly comparable to the earlier studies in the literature, the performance scores presented in Table 2 are the best scores presented to date for models using the predictability cue alone. Graphs presented by Brent (1999) indicates about 50%–60% WP and WR and 20%– 30% LP for his baseline model utilizing mutual information on the BR corpus. Cohen et al. (2007) report 76% BP, and 75% BR on George Orwell’s 1984. Christiansen et al. (1998) report 37% WP and 40% WR with an SRN using phonotactics and utterance boundary cues on another child-directed speech corpus (Korman, 1984). The model that learns from the utterance boundaries seems to perform the best. The results are comparable, and in some cases better than the LM. Furthermore, the overall scores are also higher than the scores reported by Fleck (2008), where the boundary, word and lexical F-scores were 82.9%, 70.7% and 36.6%, respectively. Although it is somewhat behind both predictability and utterance boundary cues, the lexical information alone certainly performs better than random. The lower performance of this model in comparison to ‘U’ suggests that, at least in this setting, phonotactics learned from w</context>
</contexts>
<marker>Korman, 1984</marker>
<rawString>Myron Korman (1984). “Adaptive aspects of maternal vocalizations in differing contexts at ten weeks”. In: First Language 5, pp. 44–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Constantine Lignos</author>
</authors>
<title>Modeling infant word segmentation”. In:</title>
<date>2011</date>
<booktitle>Proceedings of the Fifteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>29--38</pages>
<contexts>
<context position="4690" citStr="Lignos, 2011" startWordPosition="716" endWordPosition="717">14, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation is incremental and predictive, most of these models process their input either in a batch fashion, or they require the complete utterance to be presented before attempting to segment the input. Second, it is generally difficult to incorporate arbitrary cues into most of these models. Models that use explicit representations with incremental models exist (e.g., Monaghan and Christiansen, 2010; Lignos, 2011), but are rather rare. Furthermore, the investigation of cues and cue combination in segmentation is also relatively scarce within the recent studies (exceptions include the investigation of various suprevised models by Jarosz and J. A. Johnson, 2013). The present paper introduces a strictly incremental, unsupervised method for learning segmentation where the learning method and internal representations are explicitly defined. Crucially, we use a set of cues demonstrated to be used by humans in solving the segmentation problem. The simulations results that we present are based on the same chil</context>
</contexts>
<marker>Lignos, 2011</marker>
<rawString>Constantine Lignos (2011). “Modeling infant word segmentation”. In: Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pp. 29–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Littlestone</author>
<author>Manfred K Warmuth</author>
</authors>
<title>The Weighted Majority Algorithm”. In:</title>
<date>1994</date>
<journal>Information and Computation</journal>
<volume>108</volume>
<pages>212--261</pages>
<contexts>
<context position="7463" citStr="Littlestone and Warmuth, 1994" startWordPosition="1166" endWordPosition="1169">average, and votes are cast independently. In practice, even though the votes are almost never independent, majority voting is still an effective way of combining multiple classifiers (see Narasimhamurthy, 2005, for a discussion of the effectiveness of the method). The majority voting combines each vote equally. Even though this may be a virtue in the social and political context, it is a shortcoming for a computational procedure that incorporates information from multiple sources with varying usefulness. We will use a simple augmentation of majority voting to model, weighted majority voting (Littlestone and Warmuth, 1994), that weighs the utility of the information provided by each source. In weighted majority voting, the voters that make fewer errors get higher weights. In an unsupervised setting as ours, we do not know for certain when a voter makes an mistake. Instead, we take a voter’s decision to be correct if it agrees with the majority. Initially we set all the weights to 1, trusting all the voters equally. We adopt an incremental version of the algorithm, where we keep the count of ‘errors’ made by each voter i, ei, which is incremented every time the voter disagrees with the majority. After every boun</context>
</contexts>
<marker>Littlestone, Warmuth, 1994</marker>
<rawString>Nick Littlestone and Manfred K. Warmuth (1994). “The Weighted Majority Algorithm”. In: Information and Computation 108.2, pp. 212–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian MacWhinney</author>
<author>Catherine Snow</author>
</authors>
<title>The child language data exchange system”.</title>
<date>1985</date>
<journal>In: Journal of Child Language</journal>
<volume>12</volume>
<pages>271--269</pages>
<contexts>
<context position="19161" citStr="MacWhinney and Snow, 1985" startWordPosition="3108" endWordPosition="3111">aries. Similar to the other asymmetric indicators discussed previously, we have two flavors for each indicator. One indicating the existence of words to the right of the boundary candidate (words beginning at the boundary), and the other indicating the existence of words the left of the boundary candidate (word ending at the boundary). As with the other cues, these result in a set of indicators whose primary source of information is the potential lexical units in the learner’s incomplete and noisy lexicon. 4 Experiments 4.1 Data We use a child-directed speech corpus from the CHILDES database (MacWhinney and Snow, 1985). It was collected by Bernstein Ratner (1987) and the original orthographic transcription of the corpus was converted to a phonemic transcription by Brent and Cartwright (1996). The same corpus has been used by many recent studies. Following the convention in the literature the corpus will be called the BR corpus. For the results reported for segmentation strategies that make use of lexical stress, the BR corpus was marked for lexical stress semi-automatically following the procedure described by Christiansen et al. (1998) for annotating the Korman corpus (Korman, 1984). The stress assignment </context>
</contexts>
<marker>MacWhinney, Snow, 1985</marker>
<rawString>Brian MacWhinney and Catherine Snow (1985). “The child language data exchange system”. In: Journal of Child Language 12.2, pp. 271–269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Marr</author>
</authors>
<title>Vision: A Computational Investigation into the Human Representation and Processing of Visual Information.</title>
<date>1982</date>
<publisher>Freeman.</publisher>
<location>New York:</location>
<marker>Marr, 1982</marker>
<rawString>David Marr (1982). Vision: A Computational Investigation into the Human Representation and Processing of Visual Information. New York: Freeman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Padraic Monaghan</author>
<author>Morten H Christiansen</author>
</authors>
<title>Words in puddles of sound: modelling psycholinguistic effects in speech segmentation”.</title>
<date>2010</date>
<journal>In: Journal of Child Language 37.Special Issue</journal>
<volume>03</volume>
<pages>545--564</pages>
<contexts>
<context position="4675" citStr="Monaghan and Christiansen, 2010" startWordPosition="712" endWordPosition="715">uage Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation is incremental and predictive, most of these models process their input either in a batch fashion, or they require the complete utterance to be presented before attempting to segment the input. Second, it is generally difficult to incorporate arbitrary cues into most of these models. Models that use explicit representations with incremental models exist (e.g., Monaghan and Christiansen, 2010; Lignos, 2011), but are rather rare. Furthermore, the investigation of cues and cue combination in segmentation is also relatively scarce within the recent studies (exceptions include the investigation of various suprevised models by Jarosz and J. A. Johnson, 2013). The present paper introduces a strictly incremental, unsupervised method for learning segmentation where the learning method and internal representations are explicitly defined. Crucially, we use a set of cues demonstrated to be used by humans in solving the segmentation problem. The simulations results that we present are based o</context>
<context position="13907" citStr="Monaghan and Christiansen (2010)" startWordPosition="2256" endWordPosition="2260">since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boundary. Using utterance boundaries and the pauses, Fleck (2008) presents a batch algorithm with a few ad hoc corrections that estimates the probabilities P(b), P(l|b), P(r|b), P(l), P(r), and uses Bayesian inversion to estimate P(b|l, r). In this work, ins</context>
<context position="17724" citStr="Monaghan and Christiansen, 2010" startWordPosition="2866" endWordPosition="2869">erationalize lexical stress as another cue for segmentation. 3.4 Lexicon For adults, a comprehensive lexicon is probably the most useful cue for segmentation. We do not expect infants to have a lexicon at the beginning. However, as they build their lexicon, or ‘proto-lexicon’, they may put it in use for discovering novel lexical units. This is the main strategy behind the majority of state-of-the-art computational models of segmentation (e.g., Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009). The models that guess boundaries rarely build and use an explicit lexicon (exceptions include Monaghan and Christiansen, 2010). In this study we also experiment with an (admittedly naive) set of lexical cues to word boundaries. The idea is to indicate a boundary when there are word-like strings on both sides of the boundary candidate. In our usual majority voting framework, these form two additional sets of boundary indicators. First, given a possible boundary loca22 tion, we simply count the frequencies of already known words beginning or ending at the position in question. The second indicator is based on the number of times the phoneme sequences surrounding the boundary found at the beginnings or ends of the previ</context>
</contexts>
<marker>Monaghan, Christiansen, 2010</marker>
<rawString>Padraic Monaghan and Morten H. Christiansen (2010). “Words in puddles of sound: modelling psycholinguistic effects in speech segmentation”. In: Journal of Child Language 37.Special Issue 03, pp. 545–564.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anand Narasimhamurthy</author>
</authors>
<title>Theoretical Bounds of Majority Voting Performance for a Binary Classification Problem”. In:</title>
<date>2005</date>
<journal>IEEE Trans. Pattern Anal. Mach. Intell.</journal>
<volume>27</volume>
<issue>12</issue>
<pages>1988--1995</pages>
<contexts>
<context position="7043" citStr="Narasimhamurthy, 2005" startWordPosition="1101" endWordPosition="1102"> subject in the machine learning literature (e.g., Bishop, 2006, chapter 14). Here a simple and well-known method, majority voting, will be used for combining multiple boundary indicators. Majority voting is a common (and arguably effective) method in everyday social and political life. As a result, it has been well studied, and known to work well especially if each voter’s decision is better than random on average, and votes are cast independently. In practice, even though the votes are almost never independent, majority voting is still an effective way of combining multiple classifiers (see Narasimhamurthy, 2005, for a discussion of the effectiveness of the method). The majority voting combines each vote equally. Even though this may be a virtue in the social and political context, it is a shortcoming for a computational procedure that incorporates information from multiple sources with varying usefulness. We will use a simple augmentation of majority voting to model, weighted majority voting (Littlestone and Warmuth, 1994), that weighs the utility of the information provided by each source. In weighted majority voting, the voters that make fewer errors get higher weights. In an unsupervised setting </context>
</contexts>
<marker>Narasimhamurthy, 2005</marker>
<rawString>Anand Narasimhamurthy (2005). “Theoretical Bounds of Majority Voting Performance for a Binary Classification Problem”. In: IEEE Trans. Pattern Anal. Mach. Intell. 27 (12), pp. 1988–1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elissa L Newport</author>
<author>Richard N Aslin</author>
</authors>
<title>Learning at a distance: I. Statistical learning of non-adjacent dependencies”.</title>
<date>2004</date>
<journal>In: Cognitive Psychology</journal>
<volume>48</volume>
<pages>127--162</pages>
<contexts>
<context position="9908" citStr="Newport and Aslin, 2004" startWordPosition="1578" endWordPosition="1581">edictability between the units is low. However, until the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surprise), to define a set of boundary indicators. The first one, pointwise mutual information (MI) is defined as P(l, r) MI(l, r) = log2 P(l)P(r) where l and r are strings of phonemes to the left and right of the possible boundary location. We define our second measure, boundary entropy (H) of a potential boundary after string l as H(l) = − � P</context>
</contexts>
<marker>Newport, Aslin, 2004</marker>
<rawString>Elissa L. Newport and Richard N. Aslin (2004). “Learning at a distance: I. Statistical learning of non-adjacent dependencies”. In: Cognitive Psychology 48.2, pp. 127–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruna Pelucchi</author>
<author>Jessica F Hay</author>
<author>Jenny R Saffran</author>
</authors>
<title>Learning in reverse: Eight-month-old infants track backward transitional probabilities”. In: Cognition 113.2,</title>
<date>2009</date>
<pages>244--247</pages>
<contexts>
<context position="11203" citStr="Pelucchi et al., 2009" startWordPosition="1800" endWordPosition="1803">habet, A.1 The use of both the MI and the H is motivated by the finding that combination multiple predictability measures result in better segmentation 1The input to children is better represented by ‘segments’ or ‘phones’. However, since the data used in our simulations does not contain any phonetic variation, in this paper, we use the term phoneme when referring to the basic input unit. (see C¸ ¨oltekin, 2011, p.101, for an analysis). Furthermore, for asymmetric measures, like entropy, H(l) is clearly not the same as H(r). Motivated by the finding that children use ‘reverse predictability’ (Pelucchi et al., 2009), we also incorporate a reverse entropy measure in the present study. In most studies in the literature, the context l and r are single basic units (phonemes in our case). The different phoneme context sizes may capture regularities that exist because of different linguistic units. The relation between the phoneme context size and the linguistic units, of course, is not clear-cut. However, for example, we expect context size of one to capture the regularities between the phonemes, while context size of two or three to capture regularities between larger units, such as syllables. The above para</context>
</contexts>
<marker>Pelucchi, Hay, Saffran, 2009</marker>
<rawString>Bruna Pelucchi, Jessica F. Hay, and Jenny R. Saffran (2009). “Learning in reverse: Eight-month-old infants track backward transitional probabilities”. In: Cognition 113.2, pp. 244–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Perruchet</author>
<author>St´ephane Desaulty</author>
</authors>
<title>A role for backward transitional probabilities in word segmentation?” In:</title>
<date>2008</date>
<booktitle>Memory and Cognition 36.7,</booktitle>
<pages>1299--1305</pages>
<contexts>
<context position="9992" citStr="Perruchet and Desaulty, 2008" startWordPosition="1591" endWordPosition="1594"> Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surprise), to define a set of boundary indicators. The first one, pointwise mutual information (MI) is defined as P(l, r) MI(l, r) = log2 P(l)P(r) where l and r are strings of phonemes to the left and right of the possible boundary location. We define our second measure, boundary entropy (H) of a potential boundary after string l as H(l) = − � P(r|l)log2 (P (r|l)) r∈A where the sum ranges over all phonemes in the alphabet, A.1 </context>
</contexts>
<marker>Perruchet, Desaulty, 2008</marker>
<rawString>Pierre Perruchet and St´ephane Desaulty (2008). “A role for backward transitional probabilities in word segmentation?” In: Memory and Cognition 36.7, pp. 1299–1305.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Saffran</author>
<author>Richard N Aslin</author>
<author>Elissa L Newport</author>
</authors>
<title>Statistical learning by 8-month old infants”.</title>
<date>1996</date>
<journal>In: Science</journal>
<volume>274</volume>
<pages>1926--1928</pages>
<contexts>
<context position="2163" citStr="Saffran et al., 1996" startWordPosition="327" endWordPosition="330">th multiple segmentations spanning the complete utterance. The problem, however, is even more difficult for a learner who starts with no lexicon. Fortunately, the lexicon is not the only aid for segmentation. Experimental research within last two decades has revealed an array of cues that are used by adults and children for lexical segmentation. These cues include, but are not John Nerbonne University of Groningen j.nerbonne@rug.nl limited to, lexical stress (Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999), phonotactics (Jusczyk, Cutler, et al., 1993), predictability statistics (Saffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been proposed in the literature. The early studies typically made use of connectionist models (e.g., Elman, 1990; Christiansen et al.</context>
<context position="9568" citStr="Saffran et al. (1996)" startWordPosition="1527" endWordPosition="1530">se cues, and the boundary indicators that stem from quantification of these cues in different ways. 3.1 Predictability statistics At least as early as Harris (1955), it was known that a simple property of natural language utterances can aid identifying the lexical units that form an utterance: predictability within the units is high, predictability between the units is low. However, until the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surpris</context>
</contexts>
<marker>Saffran, Aslin, Newport, 1996</marker>
<rawString>Jenny R. Saffran, Richard N. Aslin, and Elissa L. Newport (1996). “Statistical learning by 8-month old infants”. In: Science 274.5294, pp. 1926–1928.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivelin Stoianov</author>
<author>John Nerbonne</author>
</authors>
<title>Exploring Phonotactics with Simple Recurrent Networks”. In:</title>
<date>2000</date>
<booktitle>Proceedings of Computational Linguistics in the Netherlands 1999. Ed. by Frank van Eynde, Ineke Schuurman, and Ness Schelkens,</booktitle>
<pages>51--67</pages>
<contexts>
<context position="13710" citStr="Stoianov and Nerbonne, 2000" startWordPosition="2225" endWordPosition="2228">he acquisition of lexical units.2 2There are a number of acoustic cues (e.g., pauses) that are highly correlated with lexical unit boundaries. However, we do not make use of them in this study since they are considered to be unreliable, and they are not marked in the corpora at hand. 21 All models of segmentation in the literature use utterance boundaries implicitly by assuming that the words cannot straddle utterance boundaries. The explicit use of utterance boundaries to discover regularities about words is common in connectionist models (e.g., Aslin et al., 1996; Christiansen et al., 1998; Stoianov and Nerbonne, 2000). Similar use of utterance boundaries in nonconnectionist models is rather rare. Three exceptions to this are the models described by Brent (1996), Fleck (2008) and Monaghan and Christiansen (2010). The method described in this section is similar to Fleck’s method, where the model estimates the probability of observing a boundary given its left and right context, P(b|l, r), where b represents boundary, and as before, l and r represent left and right contexts, respectively. If this probability is greater than 0.5, the model inserts a boundary. Using utterance boundaries and the pauses, Fleck (2</context>
</contexts>
<marker>Stoianov, Nerbonne, 2000</marker>
<rawString>Ivelin Stoianov and John Nerbonne (2000). “Exploring Phonotactics with Simple Recurrent Networks”. In: Proceedings of Computational Linguistics in the Netherlands 1999. Ed. by Frank van Eynde, Ineke Schuurman, and Ness Schelkens, pp. 51–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kari Suomi</author>
<author>James M McQueen</author>
<author>Anne Cutler</author>
</authors>
<title>Vowel Harmony and Speech Segmentation in Finnish”. In:</title>
<date>1997</date>
<journal>Journal of Memory and Language</journal>
<volume>36</volume>
<pages>422--444</pages>
<contexts>
<context position="2308" citStr="Suomi et al., 1997" startWordPosition="350" endWordPosition="353">ortunately, the lexicon is not the only aid for segmentation. Experimental research within last two decades has revealed an array of cues that are used by adults and children for lexical segmentation. These cues include, but are not John Nerbonne University of Groningen j.nerbonne@rug.nl limited to, lexical stress (Cutler and Butterfield, 1992; Jusczyk, Houston, et al., 1999), phonotactics (Jusczyk, Cutler, et al., 1993), predictability statistics (Saffran et al., 1996), allophonic differences (Jusczyk, Hohne, et al., 1999), coarticulation (E. K. Johnson and Jusczyk, 2001), and vowel harmony (Suomi et al., 1997). The relative utility or dominance of these cues is a matter of current debate. However, it seems uncontroversial that none of these cues solves the segmentation problem alone and, when available, they are used in conjunction. Along with experimental research on segmentation, a large number of computational models have been proposed in the literature. The early studies typically made use of connectionist models (e.g., Elman, 1990; Christiansen et al., 1998). Of these studies, Christiansen et al. (1998) is particularly interesting for the present study since it incorporates most of the cues us</context>
</contexts>
<marker>Suomi, McQueen, Cutler, 1997</marker>
<rawString>Kari Suomi, James M. McQueen, and Anne Cutler (1997). “Vowel Harmony and Speech Segmentation in Finnish”. In: Journal of Memory and Language 36.3, pp. 422–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Swingley</author>
</authors>
<title>Statistical clustering and the contents of the infant vocabulary”.</title>
<date>2005</date>
<journal>In: Cognitive Psychology</journal>
<volume>50</volume>
<pages>86--132</pages>
<contexts>
<context position="15935" citStr="Swingley (2005)" startWordPosition="2583" endWordPosition="2584"> Butterfield, 1992; Jusczyk, Houston, et al., 1999; Jusczyk, 1999). Lexical stress is used in many languages for marking the prominent syllable in a word. For languages that exhibit lexical stress, the prominent syllable will typically be in a particular position in the word, allowing discovery of the boundaries based on the position of stressed syllable. Despite the prominence of stress as a cue for segmentation, there are relatively few computational studies that investigate use of stress. Christiansen et al. (1998) incorporates stress as a cue in their connectionist cue combination system. Swingley (2005) provides a careful analysis of stress patterns of the bisyllabic words found by a discovery procedure on mutual information and frequency. Gambell and Yang (2006) present surprisingly good segmentation results with a rulebased learner whose main source of information is lexical stress. One of the major problems with the these studies, which has also been carried over to the present study, is the lack of corpora with realistic stress assignment (see Section 4.1). Our stress-based strategy is similar to the strategy used for learning phonotactics described in Section 3.2. Instead of collecting </context>
</contexts>
<marker>Swingley, 2005</marker>
<rawString>Daniel Swingley (2005). “Statistical clustering and the contents of the infant vocabulary”. In: Cognitive Psychology 50.1, pp. 86–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik D Thiessen</author>
<author>Jenny R Saffran</author>
</authors>
<title>When Cues Collide: Use of Stress and Statistical Cues to Word Boundaries by 7- to 9-Month-Old Infants,” in:</title>
<date>2003</date>
<booktitle>Developmental Psychology 39.4,</booktitle>
<pages>706--716</pages>
<contexts>
<context position="9883" citStr="Thiessen and Saffran, 2003" startWordPosition="1574" endWordPosition="1577">within the units is high, predictability between the units is low. However, until the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surprise), to define a set of boundary indicators. The first one, pointwise mutual information (MI) is defined as P(l, r) MI(l, r) = log2 P(l)P(r) where l and r are strings of phonemes to the left and right of the possible boundary location. We define our second measure, boundary entropy (H) of a potential boundary after</context>
<context position="34409" citStr="Thiessen and Saffran, 2003" startWordPosition="5719" endWordPosition="5722">ffect of stress cue presented in Section 4.4. When we look at the overall effect of the stress cue throughout the complete simulations, it seems stress degrades the performance. However, if we take a look at the models’ performances at the end of the learning, we see that effect of the stress cue is actually positive. In other words, once ‘bootstrapped’ by the other cues, stress becomes a useful cue. Furthermore, the way the stress cue is useful for the model is also in line with the findings in the literature where stress is commonly found to be a dominant cue (Jusczyk, Cutler, et al., 1993; Thiessen and Saffran, 2003). Given the findings here that stress is rather a precise cue (despite its low recall), it is understandable why it dominates the boundary decisions when available. The segmentation model presented in this paper demonstrates a way to achieve good segmentation performance using more cognitively relevant and transparent strategies. It is also instrumental at investigating some of the interesting issues regarding cue combination in segmentation, and it is a first step towards models that are more faithful to the human segmentation process. Among other things, we consider two important improvement</context>
</contexts>
<marker>Thiessen, Saffran, 2003</marker>
<rawString>Erik D. Thiessen and Jenny R. Saffran (2003). “When Cues Collide: Use of Stress and Statistical Cues to Word Boundaries by 7- to 9-Month-Old Infants,” in: Developmental Psychology 39.4, pp. 706–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan P Thompson</author>
<author>Elissa L Newport</author>
</authors>
<title>Statistical Learning of Syntax: The Role of Transitional Probability”. In:</title>
<date>2007</date>
<booktitle>Language Learning and Development 3.1,</booktitle>
<pages>1--42</pages>
<contexts>
<context position="9961" citStr="Thompson and Newport, 2007" startWordPosition="1587" endWordPosition="1590">til the influential study by Saffran, Aslin, and Newport (1996), the idea was not investigated in developmental psycholinguistics as a possible source of information that children may use for segmentation. After Saffran et al. (1996) showed that 8-month-old infants make use of predictability statistics to extract word-like units from an artificial language stream, a large number of studies confirmed that predictability based strategies are used by adults and children for learning different aspects of language (e.g., Thiessen and Saffran, 2003; Newport and Aslin, 2004; Graf Estes et al., 2007; Thompson and Newport, 2007; Perruchet and Desaulty, 2008). To use in our cue combination system, we need to quantify the notion of predictability. In this study, we use two information theoretic measures of predictability (or surprise), to define a set of boundary indicators. The first one, pointwise mutual information (MI) is defined as P(l, r) MI(l, r) = log2 P(l)P(r) where l and r are strings of phonemes to the left and right of the possible boundary location. We define our second measure, boundary entropy (H) of a potential boundary after string l as H(l) = − � P(r|l)log2 (P (r|l)) r∈A where the sum ranges over all</context>
</contexts>
<marker>Thompson, Newport, 2007</marker>
<rawString>Susan P. Thompson and Elissa L. Newport (2007). “Statistical Learning of Syntax: The Role of Transitional Probability”. In: Language Learning and Development 3.1, pp. 1– 42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anand Venkataraman</author>
</authors>
<title>A Statistical Model for Word Discovery in Transcribed Speech”. In:</title>
<date>2001</date>
<booktitle>Computational Linguistics 27.3,</booktitle>
<pages>351--372</pages>
<contexts>
<context position="3700" citStr="Venkataraman, 2001" startWordPosition="562" endWordPosition="564">cluded implicitly in any SRN model), and utterance boundaries, and showed that combining the cues improves the performance. The connectionist models have been instrumental in investigating a large number of cognitive phenomena. However, they have also been subject to the criticism that what a connectionist model learns is rather difficult to interpret. Furthermore, the performance achieved using connectionist models is far lower than that is expected from humans. Models that use explicit representations in combination with statistical procedures (e.g., Brent and Cartwright, 1996; Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009; M. Johnson and Goldwater, 2009) avoid both problems: these models perform better, and it is easier to reason about what they learn. Although these models were also instrumental in our understanding of the problem, they lack at least two aspects of con19 Proc. of 5th Workshop on Cognitive Aspects of Computational Language Learning (CogACLL) @ EACL 2014, pages 19–28, Gothenburg, Sweden, April 26 2014. c�2014 Association for Computational Linguistics nectionist models that fit human processing better. First, even though we know that human segmentation is incremental and </context>
<context position="17571" citStr="Venkataraman, 2001" startWordPosition="2846" endWordPosition="2847">dary decision strategy in combination with the weighted majority voting algorithm, as before, we define a set of boundary indicators and operationalize lexical stress as another cue for segmentation. 3.4 Lexicon For adults, a comprehensive lexicon is probably the most useful cue for segmentation. We do not expect infants to have a lexicon at the beginning. However, as they build their lexicon, or ‘proto-lexicon’, they may put it in use for discovering novel lexical units. This is the main strategy behind the majority of state-of-the-art computational models of segmentation (e.g., Brent, 1999; Venkataraman, 2001; Goldwater et al., 2009). The models that guess boundaries rarely build and use an explicit lexicon (exceptions include Monaghan and Christiansen, 2010). In this study we also experiment with an (admittedly naive) set of lexical cues to word boundaries. The idea is to indicate a boundary when there are word-like strings on both sides of the boundary candidate. In our usual majority voting framework, these form two additional sets of boundary indicators. First, given a possible boundary loca22 tion, we simply count the frequencies of already known words beginning or ending at the position in q</context>
<context position="22465" citStr="Venkataraman (2001)" startWordPosition="3683" endWordPosition="3684"> or a corpus), wi is the ith word in the sequence, ai is the ith sound in the word, f(w) is the relative frequency of the word w, m is the number of known words, and 0 &lt; α &lt; 1 is the only parameter of the model. In all experiments reported in this paper, we will fix α at 0.5. For the incremental model defined here, a word is ‘known’, if it was used in a previous segmentation. The model accepts whole utterances as single words if the utterance does not contain any known words. n r1 P(s) = 23 model boundary word lexicon P R F P R F P R F Brent (1999) 80.3 84.3 82.3 67.0 69.4 68.2 53.6 51.3 52.4 Venkataraman (2001) 81.7 82.5 82.1 68.1 68.6 68.3 54.5 57.0 55.7 Goldwater et al. (2009) 90.3 80.8 85.2 75.2 69.6 72.3 63.5 55.2 59.1 Blanchard et al. (2010) 81.4 82.5 81.9 65.8 66.4 66.1 57.2 55.4 56.3 RM 27.4 27.0 27.2 12.6 12.5 12.5 6.0 43.6 10.5 LM 84.1 82.7 83.4 72.0 71.2 71.6 50.6 61.0 55.3 Table 1: Performance scores of the reference models LM and RM in comparison with some of the earlier scores reported in the literature. If there were multiple models reported in a study, the result with the highest lexicon F-score is presented. All scores are obtained on the BR corpus. Table 1 compares the performances </context>
</contexts>
<marker>Venkataraman, 2001</marker>
<rawString>Anand Venkataraman (2001). “A Statistical Model for Word Discovery in Transcribed Speech”. In: Computational Linguistics 27.3, pp. 351–372.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>