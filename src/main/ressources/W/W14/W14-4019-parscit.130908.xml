<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.964942">
How Synchronous are Adjuncts in Translation Data?
</title>
<author confidence="0.935119">
Sophie Arnoult Khalil Sima’an
</author>
<affiliation confidence="0.9295315">
ILLC ILLC
University of Amsterdam University of Amsterdam
</affiliation>
<email confidence="0.991375">
s.i.arnoult@uva.nl k.simaan@uva.nl
</email>
<sectionHeader confidence="0.993676" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999920214285714">
The argument-adjunct distinction is cen-
tral to most syntactic and semantic the-
ories. As optional elements that refine
(the meaning of) a phrase, adjuncts are
important for recursive, compositional ac-
counts of syntax, semantics and transla-
tion. In formal accounts of machine trans-
lation, adjuncts are often treated as modi-
fiers applying synchronously in source and
target derivations. But how well can the
assumption of synchronous adjunction ex-
plain translation equivalence in actual par-
allel data? In this paper we present the
first empirical study of translation equiva-
lence of adjuncts on a variety of French-
English parallel corpora, while varying
word alignments so we can gauge the ef-
fect of errors in them. We show that for
proper measurement of the types of trans-
lation equivalence of adjuncts, we must
work with non-contiguous, many-to-many
relations, thereby amending the traditional
Direct Correspondence Assumption. Our
empirical results show that 70% of manu-
ally identified adjuncts have adjunct trans-
lation equivalents in training data, against
roughly 50% for automatically identified
adjuncts.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999857843137255">
Most syntactic and semantic theories agree on the
argument-adjunct distinction, although they vary
on the specifics of this distinction. Common to
these theories is that adjunction is a central de-
vice for language recursion, as adjunction modi-
fies initial but complete sentences by adding op-
tional phrases; adjunction also contributes to se-
mantic compositionality, albeit in various ways,
as syntactic adjuncts may take different seman-
tic roles. Shieber and Schabes (1990) transfer the
role of adjuncts from monolingual syntax (Joshi
et al., 1975) to the realm of translation equiva-
lence using a Synchronous Tree Adjoining Gram-
mars (STAG), and propose to view adjunction as
a synchronous operation for recursive, composi-
tional translation. STAG therefore relies substan-
tially on what Hwa (2002) calls the Direct Corre-
spondence Assumption, the notion that semantic
or syntactic relations correspond across a bitext.
We know from various works–notably by Hwa et
al. (2002) for dependency relations, Arnoult and
Sima’an (2012) for adjuncts, and Pad´o and Lap-
ata (2009) and Wu and Fung (2009) for semantic
roles–that the Direct Correspondence Assumption
does not always hold.
A question that has not received much atten-
tion is the degree to which the assumption of
synchronous adjunction is supported in human
translation data. This is crucial for the succes-
ful application of linguistically-motivated STAG,
but attempts at answering this question empirically
are hampered by a variety of difficulties. Lin-
guistic structures may diverge between languages
(Dorr, 1994), translations may be more or less lit-
eral, and annotation resources may be inaccurate,
when they are available at all. Besides, automatic
word alignments are known to be noisy and man-
ual alignments are rather scarse. The work of
Arnoult and Sima’an (2012) reports lower and up-
per bounds of one-to-one adjunct correspondence,
using rather limited resources to identify French
adjuncts making their results not directly applica-
ble for measuring the stability of the synchronous
adjunction assumption.
In this paper we aim at redefining the transla-
tion equivalence of adjuncts in ways that allow us
to report far more accurate bounds on their cross-
linguistic correspondence. In particular, we are in-
terested in measuring adjunct correspondence ro-
bustly, in training data.
Consider for example the sentence pair of Fig-
</bodyText>
<page confidence="0.968783">
157
</page>
<note confidence="0.7827585">
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 157–165,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.998912153846154">
ure 1. Most adjuncts in each sentence translate
as adjuncts in the other sentence, but one of these
translation equivalences appears to be many-to-
many, because of parsing mismatches across the
bitext; both parses and adjunct labellers on both
sides of the bitext must be on par for adjunct trans-
lation equivalences to be established. Besides, one
generally establishes translation equivalence using
word alignments, which may be noisy. Another
factor is that of the degree of translation equiva-
lence in the data in general; while parallel bitexts
express the same meaning, meaning may diverge
locally.
</bodyText>
<figure confidence="0.550823888888889">
I think that the time Ae1 Ae6 has been Ae7 long
taken Ae2 , for example, too
in handling Ae3 applications Ae4
routine for changes of facilities Ae5
along a pipeline
je crois qu’il a pris Af1 de temps Af2
trop
a` ´etudier des demandes Af3 de changements d’installations Af4 , Af5
courantes le long d’un pipe-line par exemple
</figure>
<figureCaption confidence="0.999982">
Figure 1: Example sentence pair
</figureCaption>
<bodyText confidence="0.999973971428572">
This paper contributes the first study to mea-
sure the degree of adjunction synchronicity: we
derive many-to-many pairings between adjuncts
across a bitext, thus supporting a generic view
of translation equivalence, where meaning can
be expressed by distinct entities and redistributed
freely in translation; practically, this also allows
us to capture equivalence in spite of mismatched
parses. We abstract away from word alignments
to a certain degree, as we directly pair adjuncts
across a bitext, but we still use word alignments–
namely the overlap of adjunct projections with tar-
get adjuncts–to decide on these pairings. We fur-
ther distinguish between adjunct pairings that are
bijective through the word alignment, and other
pairings, where the translation equivalence does
not exactly agree with the word alignment; we
qualify these pairings as weakly equivalent.
Under this new view of adjunct translation
equivalence, we perform measures in French-
English data. We show that adjunction is pre-
served in 40% to 50% of the cases with automati-
cally labelled adjuncts, with differences between
data sets, word aligners and sentence length;
about 25% more adjuncts form weakly translation-
equivalent pairings. With gold adjunct annota-
tions, the proportion of translation-equivalent ad-
juncts increases to 70%.
These results show that adjunct labelling accu-
racy on both sides of the data is crucial for adjunct
alignment, while suggesting that applications that
exploit adjunction can gain from decreasing their
dependence on word alignments and idealized ex-
perimental conditions , and identifying favorable
contexts for adjunct preservation.
</bodyText>
<sectionHeader confidence="0.686585" genericHeader="method">
2 Alignment-based role pairing
</sectionHeader>
<bodyText confidence="0.9999225">
How can one find translation-equivalent adjuncts
using word alignments, without being too con-
strained by the latter? Obviously, adjunct pairs
that are consistent with the word alignments are
translation equivalent, but we also want to be able
to identify translation-equivalent adjuncts that are
not exactly aligned to each other, and also to ac-
cept many-to-many pairings; not only to get lin-
guistically justified discontinuous pairs, as with
the French double negation particle, but also for
robustness with regard to dissimilar attachments
in the French and English parses.
</bodyText>
<subsectionHeader confidence="0.919916">
2.1 Translation equivalence under the
alignment-consistency constraint
</subsectionHeader>
<bodyText confidence="0.999442583333333">
Consider for instance Figure 2, which represents
a word alignment for part of the sentence pair of
Figure 1. We would like to match f2 to ¯e2 and ¯e6,
f3 to ¯e3, f4 to ¯e5, and f5 to ¯e6. If one only pairs
adjuncts that are consistent with the word align-
ment, one obtains only half of these adjunct pairs:
( f3, ¯e3) and ( f4, ¯e5); one cannot pair up f5 and
¯e6 because the latter is also aligned outside of the
former; and one can also not find the equivalence
between f2 on one hand and ¯e2 and ¯e6 on the other
hand if one assumes one-to-one correspondence
between adjuncts.
</bodyText>
<subsectionHeader confidence="0.8397985">
2.2 Translation equivalence through
projection
</subsectionHeader>
<bodyText confidence="0.999771">
We align adjuncts across the bitext by projecting
them through the word alignment and finding, for
each adjunct, the shortest adjunct or sequence of
adjuncts that overlaps the most with that adjunct’s
</bodyText>
<page confidence="0.986381">
158
</page>
<figure confidence="0.783716875">
in for
handling example
routine ,
applications
for
changes
of
facilities
along
a
pipeline
,
¯e2 ¯e3 ¯e4 ¯e5
f3
f4
f5
</figure>
<figureCaption confidence="0.999245">
Figure 2: Example with word alignment
</figureCaption>
<bodyText confidence="0.9993345">
projection. To prevent source adjuncts from be-
ing aligned to the first target adjunct that sub-
sumes their projection, we also enforce that only
non-overlapping source adjuncts may be aligned
to a same target sequence, as explained in sec-
tion 2.2.1.
This procedure results in a many-to-many align-
ment between adjuncts on either side. We distin-
guish several types of adjunct pairings through this
alignment, which we interpret as divergent, equiv-
alent or weakly equivalent, as described in sec-
tion 2.2.2.
We perform this alignment in both source-target
and target-source directions to measure the pro-
portion of source, respectively target, adjuncts that
fall in each category.
</bodyText>
<subsectionHeader confidence="0.946564">
2.2.1 Adjunct pairing procedure
</subsectionHeader>
<bodyText confidence="0.979852707317073">
We define the projection of an adjunct σ as the
unique tuple of maximal, non-overlapping phrases
φn1 that are aligned to σ through the word align-
ment. Each phrase φi in this tuple is understood
as being extended with possible surrounding un-
aligned positions–phrases are primarily identified
by the aligned positions they cover. And each φi
is maximal as any larger phrase distinct from φi
would also include (aligned) positions not aligned
to σ. Let I(φi) be the set of aligned positions
in each φi, and I(φn1) the set of aligned positions
covered by φn1.
We align σ to the non-overlapping sequence
of target adjuncts τm1 that has the smallest set of
aligned positions while having the largest over-
lap with φn1; the overlap of a projection and a tar-
get sequence is the intersection of their respective
sets of aligned positions. For instance in Figure 2,
the projection of ¯f4 is maximally covered by ¯e2,
¯e4, and ¯e5; we align the latter to ¯f4 as it covers
the least aligned positions. In practice, we search
through the tree of target adjuncts for adjuncts that
overlap with φn1, and for each such adjunct τ we
compare its overlap with φn1 to that of the sequence
of its children γk1 to determine which (of τ or γk 1 )
should be part of the final target sequence.
We perform a similar selection on overlapping
source adjuncts that point to the same target se-
quence. For each source adjunct σ, we determine
if its target sequence τm1 is also aligned to adjuncts
dominated by σ, in which case we compare the
overlap of σ’s projection with τn1 to that of its chil-
dren in the source adjunct tree to determine which
should be aligned to τm1 . For instance in Figure 2,
¯e4 is aligned to ¯f2 (when projecting from English
to French), but so is ¯e2; as ¯e2’s projection overlaps
more with f2, we discard the alignment between
¯e4 and
f2.
The final alignments for our example are repre-
sented in Table 1.
</bodyText>
<tableCaption confidence="0.597396">
Table 1: Adjunct pairings for the alignment of
</tableCaption>
<figureCaption confidence="0.804499">
Figure 2
</figureCaption>
<table confidence="0.5845372">
f → e e → f
f2 ¯e2, ¯e6 ¯e2 f2
f3 ¯e3 ¯e3 f3
f5 ¯e6 ¯e5 f4
¯e6 f2
</table>
<subsectionHeader confidence="0.947843">
2.2.2 Types of adjunct pairings
</subsectionHeader>
<bodyText confidence="0.999976111111111">
We distinguish three main classes of adjunct
translation equivalence: divergent, equivalent and
weakly equivalent. We further subdivide each
class into two types, as shown in Table 2. Ad-
junct pairings fall into one of these types depend-
ing on their configuration (unaligned, one-to-one
or many-to-many) and their agreement with the
word alignments. Equivalent types notably differ
from weakly equivalent ones by being bijectively
</bodyText>
<figure confidence="0.6395992">
¯e6
a`
´etudier
de
les
demandes
courantes
de
changements
de
installations
le
long
de
un
pipe
-
line
,
par
exemple
f2
159
aligned; With the notations of section 2.2.1, two
adjunct sequences σn1 and τm1 with respective pro-
jections φn�
1 and ψm, 1are translation equivalent iff
I(φn�
1 ) = I(τm1 ) and I(ψm�
1 ) = I(σn 1 ).
</figure>
<tableCaption confidence="0.4370268">
Table 2: Adjunct pairing types
divergent
null empty projection
div no aligned target adjuncts
weakly equivalent
we-nm many-to-many non-bijective
we-11 one-to-one non-bijective
equivalent
eq-nm many-to-many bijective
eq-11 one-to-one bijective
</tableCaption>
<bodyText confidence="0.999853333333334">
In Table 1, ¯e4’s translation is divergent as it is
not aligned to any adjunct; f5 and ¯e6 are weakly
equivalent as the projection of f5 does not cover
all the aligned positions of ¯e6. The pairing from f2
to ¯e2, ¯e6 is many-to-many equivalent, and so are
the pairings from ¯e2 and ¯e6 to f2; the remaining
pairings are one-to-one equivalent.
As Table 3 shows, the divergent types null and
div regroup untranslated adjuncts (Example 1)
and divergent adjuncts: Examples (2) and (3) show
cases of conflational divergence (Dorr, 1994), that
appear in different types because of the underly-
ing word alignments; in Example (4), the prepo-
sitional phrase with this task has been wrongly
labelled as an adjunct, leading to a falsely diver-
gent pairing. The weakly-equivalent types we-nm
and we-11 regroup both divergent and equiva-
lent pairings: the adjuncts of Examples (5) and (8)
are aligned by our method to adjuncts that are not
their translation equivalent, the adjunct in Exam-
ple (6) cannot be aligned to its equivalent because
of a parsing error, and the equivalences in Exam-
ples (7) and (9) cannot be identified because of a
word-alignment error. Finally, we show a number
of equivalent pairings (eq-nm and eq-11): in
Example (10), an attachment error in the French
parse induces a many-to-one equivalence where
there should be two one-to-one equivalences; Ex-
amples (11) to (13) show a number of true many-
to-many equivalences, while Examples (14) and
(15) show that adjuncts may be equivalent across a
bitext while belonging to a different syntactic cate-
gory and modifying a different type of phrase (15).
</bodyText>
<sectionHeader confidence="0.987465" genericHeader="method">
3 Adjunct identification
</sectionHeader>
<bodyText confidence="0.99996325">
We identify adjuncts in dependency trees obtained
by conversion from phrase-structure trees: we map
modifier labels to adjuncts, except when the de-
pendent is a closed-class word. For English, we
use the Berkeley parser and convert its output with
the pennconverter (Johansson and Nugues, 2007;
Surdeanu et al., 2008); for French, we use the
Berkeley parser and the functional role labeller of
Candito et al. (2010). The pennconverter with de-
fault options and the French converter make sim-
ilar structural choices concerning the representa-
tion of coordination and the choice of heads.
</bodyText>
<subsectionHeader confidence="0.995296">
3.1 English adjuncts
</subsectionHeader>
<bodyText confidence="0.999973384615385">
We first identify closed-class words by their POS
tag: CC, DT, EX, IN, POS, PRP, PRP$, RP, SYM,
TO, WDT, WP, WP$, WRB. Punctuation marks,
identified by the P dependency relation, and name
dependencies, identified by NAME, POSTHON, or
TITLE, are also treated as closed-class words.
Adjuncts are identified by the dependency rela-
tion: ADV, APPO, NMOD (except determiners, pos-
sessives and ‘of’ complements), PRN, AMOD (ex-
cept when the head is labeled with ADV) and PMOD
left of its head. Cardinals, identified by the CD
POS tag, and remaining dependents are classified
as arguments.
</bodyText>
<subsectionHeader confidence="0.999445">
3.2 French adjuncts
</subsectionHeader>
<bodyText confidence="0.999892125">
Closed-class words are identified by the (coarse)
POS tags: C, D, CL, P, PONCT, P+D, PRO. Aux-
iliary verbs, identified by the dependency relations
aux tps and aux pass, are also included.
Adjuncts are identified by the dependency re-
lations mod rel and mod (except if the depen-
dent’s head is a cardinal number, identified by the
s=card label).
</bodyText>
<subsectionHeader confidence="0.989835">
3.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.9997125">
We evaluate adjunct identification accuracy using
a set of 100 English and French sentences, drawn
randomly from the Europarl corpus. A single an-
notator marked adjuncts in both sets, identifying
slightly more than 500 adjuncts in both sets. We
find F scores of 71.3 and 72.2 for English and
French respectively, as summarized in Table 4. We
find that about a quarter of errors are related to
parse attachment, yielding scores of 77.7 and 78.6
if one corrects them.
</bodyText>
<page confidence="0.999068">
160
</page>
<tableCaption confidence="0.999078">
Table 3: Examples of adjunct pairing types
</tableCaption>
<bodyText confidence="0.704438">
null
</bodyText>
<listItem confidence="0.9864998">
(1) it is indeed a great honour vous me faites un grand honneur
(2) the polling booths les isoloirs
div
(3) the voting stations les isoloirs
(4) to be entrusted with this task en me confiant cette tˆache
we-nm
(5) reforms to the Canadian military r´eformes des forces [arm´ees] [canadiennes]
(6) an even greater country un pays [encore] [plus] magnifique
(7) in safe communities [en s´ecurit´e] [dans nos communaut´es]
we-11
(8) across the land de tout le pays
(9) strong opinions des opinions bien arrˆet´ees
eq-nm
(10) a proud moment for Canada un moment heureux pour le Canada
(11) we have used the wrong process nous ne suivons pas le bon processus
(12) our common space and our common means un espace et des moyens communs
(13) the [personal] [protected] files les dossiers confidentiels et prot´eg´es
eq-11
(14) the names just announced les noms que je viens de mentionner
(15) one in three Canadian jobs au Canada, un emploi sur trois
</listItem>
<tableCaption confidence="0.995662">
Table 4: Adjunct identification F scores
</tableCaption>
<table confidence="0.74867">
prec. recall F
En auto. 66.2 77.2 71.3
corr. 72.3 84.0 77.7
Fr auto. 68.1 76.7 72.2
corr. 74.7 83.0 78.6
</table>
<sectionHeader confidence="0.999332" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.994428">
4.1 Experimental set-up
</subsectionHeader>
<bodyText confidence="0.999848285714286">
We measure adjunct translation equivalence in
four data sets: the manually-aligned Canadian
Hansards corpus (Och and Ney, 2003), contain-
ing 447 sentence pairs, the house and senate train-
ing data of the Canadian Hansards (1.13M sen-
tence pairs), the French-English Europarl training
set (1.97M sentence pairs) and the Moses news-
commentaries corpus (156k sentence pairs). Be-
sides, we randomly selected 100 sentence pairs
from the Europarl set to measure adjunct identi-
fication accuracy as reported in section 3 and ad-
junct correspondence with gold adjunct annota-
tions.
All four corpora except the manual Hansards
are preprocessed to keep sentences with up to
80 words, and all four data sets are used jointly
to train unsupervised alignments, both with the
Berkeley aligner (Liang et al., 2006) and GIZA++
(Brown et al., 1993; Och and Ney, 2003) through
mgiza (Gao and Vogel, 2008), using 5 iterations of
Model 1 and 5 iterations of HMM for the Berkeley
aligner, and 5 iterations of Model 1 and HMM and
3 iterations of Model 3 and Model 4 for GIZA++.
The GIZA++ alignments are symmetrized using
the grow-diag-final heuristics. Besides, the man-
ual Hansards corpus is aligned with Sure Only
(SO) and Sure and Possible (SP) manual align-
ments.
</bodyText>
<subsectionHeader confidence="0.9780575">
4.2 Measurements with gold adjunct
annotations
</subsectionHeader>
<bodyText confidence="0.9999355">
We compared adjunct translation equivalence of
automatically identified adjuncts and gold anno-
tations using 100 manually annotated sentence
pairs from the Europarl corpus; adjuncts were
aligned automatically, using the Berkeley word
alignments. We also measured adjunct equiv-
alence using automatic adjunct annotations cor-
rected for parse attachment errors, as introduced
</bodyText>
<page confidence="0.996585">
161
</page>
<bodyText confidence="0.9998448">
in section 3.3. Table 5 reports harmonic mean fig-
ures (mh) for each adjunct projection type. For
information, we also report their decomposition in
the case of gold annotations, showing some depen-
dence on the projection direction.
</bodyText>
<tableCaption confidence="0.9993025">
Table 5: Translation equivalence of auto-
matic, rebracketed and gold adjuncts
</tableCaption>
<table confidence="0.961083125">
auto. corr. ef gold mh
mh mh fe
null 7.6 7.7 8.1 7.3 7.7
div 22.3 22.5 14.7 12.0 13.2
we-nm 10.8 9.6 2.7 4.6 3.4
we-11 12.5 10.8 7.4 8.5 7.9
eq-nm 3.5 2.2 2.5 3.3 2.9
eq-11 41.8 45.8 64.5 64.3 64.4
</table>
<bodyText confidence="0.999337916666667">
About two thirds of manually identified ad-
juncts form equivalent pairs, representing a gain
of 20 points with regard to automatically identi-
fied adjuncts. This is accompanied by a halving of
divergent pairings and of weakly equivalent ones.
Further, we find that about half of the remaining
weak equivalences can be interpreted as transla-
tion equivalent (to compare to an estimated third
for automatically identified adjuncts), allowing us
to estimate to 70% the degree of translation equiv-
alence given Berkeley word alignments in the Eu-
roparl corpus.
</bodyText>
<subsectionHeader confidence="0.9939495">
4.3 Measurements with manual and
automatic alignments
</subsectionHeader>
<bodyText confidence="0.9996505">
We aligned adjuncts in the manual Hansards cor-
pus using all four word alignments. Table 6
presents the mean proportions for each category
of adjunct projection.
</bodyText>
<tableCaption confidence="0.696404">
Table 6: Translation-equivalence of adjuncts
in the manual Hansards
</tableCaption>
<table confidence="0.998667857142857">
SO SP bky giza
null 32.1 2.8 8.7 3.3
div 19.7 29.3 27.1 30.3
we-nm 3.4 14.6 8.5 11.4
we-11 5.7 13.8 13.5 15.3
eq-nm 4.1 7.3 4.1 4.2
eq-11 33.7 31.8 37.6 35.3
</table>
<bodyText confidence="0.984768888888889">
Comparing the mean proportions per type be-
tween the four alignments, we see that a third of
adjuncts on either side are not aligned at all with
the sure-only manual alignments. In the example
of Figure 2 for instance, these alignments do not
link ¯f3 to ¯e3. On the other hand, the sure and
possible manual alignments lead to many diver-
gent or weakly equivalent pairings, a result of their
dense phrasal alignments. In comparison, the au-
tomatic alignments connect more words than the
sure-only alignments, leading to a mixed result for
the adjunct pairings: one gains more translation-
equivalent, but also more divergent and weakly
equivalent pairs. In this, the Berkeley aligner ap-
pears less noisy than GIZA++, as it captures more
translation equivalent pairs and less weakly equiv-
alent ones. This is confirmed in the other data sets
too, as Table 7 shows.
</bodyText>
<tableCaption confidence="0.9956135">
Table 7: Mean proportions of adjunct-pairing
types in automatically aligned data
</tableCaption>
<table confidence="0.999402">
hans-hst europarl news
bky giza bky giza bky giza
null 7.5 2.7 6.3 2.3 8.3 3.3
div 28.1 30.8 21.8 24.2 21.0 23.9
we-nm 10.4 12.2 11.0 12.7 10.6 12.6
we-11 13.4 15.5 12.4 14.6 11.7 14.2
eq-nm 3.2 4.0 3.2 4.0 3.1 3.8
eq-11 37.1 34.6 45.0 42.0 44.9 41.8
</table>
<bodyText confidence="0.999817538461538">
Comparing figures between the different data
sets, we see that the Europarl and the News
data have more translation-equivalent and less di-
vergent adjuncts than the Hansards training data
(hans-hst). Taking the harmonic mean for both
equivalent types (eq-nm and eq-11), we find
that 48.2% of adjuncts have an adjunct translation
equivalent in the Europarl data (with the Berke-
ley aligner) and 48.0% in the News corpus, against
40.3% the Hansards training set and 41.6% in the
manual Hansards set. This suggests that transla-
tions in the Hansards data are less literal than in
the Europarl or the News corpus.
</bodyText>
<subsectionHeader confidence="0.999903">
4.4 Effect of sentence length
</subsectionHeader>
<bodyText confidence="0.9999432">
We explore the relation between sentence length
and translation equivalence by performing mea-
surements in bucketed data. We bucket the data
using the length of the English sentences. Mea-
surements are reported in Table 8 for the Hansards
</bodyText>
<page confidence="0.998014">
162
</page>
<tableCaption confidence="0.8295065">
Table 8: Adjunct translation equivalence with the Berkeley aligner in bucketed
data
</tableCaption>
<table confidence="0.999676">
hans-man 1-15 hansard-hst 51-80 1-15 europarl 51-80
1-15 16-30 16-30 31-50 16-30 31-50
null 9.3 8.5 6.5 7.6 7.8 8.0 6.4 6.0 6.2 6.6
div 28.1 25.9 39.5 25.3 23.5 22.6 25.3 22.2 21.2 20.6
we-nm 6.1 9.4 5.3 10.1 13.6 16.7 5.0 9.3 12.5 14.9
we-11 11.8 14.1 12.2 13.4 14.2 14.8 10.0 11.7 13.0 13.9
eq-nm 3.1 4.5 2.8 3.4 3.3 3.1 3.4 3.3 3.1 2.9
eq-11 40.6 36.3 32.5 39.6 37.3 34.4 49.1 47.1 43.7 40.7
</table>
<bodyText confidence="0.9991">
and the Europarl sets (the News set yields similar
results to the Europarl data).
All data sets show a dramatic increase of the
proportion of adjuncts involved in many-to-many,
and to a lesser extent one-to-one weakly equiva-
lent translations. This increase is accompanied by
a decrease of all other adjunct-pairing types (un-
aligned adjuncts excepted), and is likely to result
from increased word-alignment and parsing errors
with sentence length.
A rather surprising result is the high proportion
of divergent adjunct translations in the shorter sen-
tences of the Hansards training set; we find the
same phenomenon with the GIZA++ alignment.
We attribute this effect to the Hansards set having
less literal translations than the other sets. That
we see this effect mostly in shorter sentences may
result from translation mismatches being mostly
local. As sentence length increases however, word
and adjunct alignment errors are also likely to link
more unrelated adjuncts, resulting in a drop of di-
vergent adjuncts.
</bodyText>
<subsectionHeader confidence="0.9997">
4.5 Simplifying alignments
</subsectionHeader>
<bodyText confidence="0.99431425">
We perform a simple experiment to test the effect
of word-alignment simplification of adjunct trans-
lation equivalence. For this we remove alignment
links between function words (as defined in sec-
tion 3) on both sides of the data, and we realign
adjuncts using these simplified alignments. Ta-
ble 9 shows that this simplification (column ‘-fw’)
slightly decreases the proportion of weakly equiv-
alent pairings with regard to the standard align-
ment (‘std’), mostly to the benefit of translation-
equivalent pairings. This suggests that further
gains may be obtained with better alignments.
</bodyText>
<tableCaption confidence="0.973781333333333">
Table 9: Effect of alignment simplification
on adjunct translation equivalence in the Eu-
roparl data
</tableCaption>
<table confidence="0.999105375">
bky giza
std -fw std -fw
null 6.3 7.5 2.3 3.1
div 21.8 21.5 24.2 24.0
we-nm 11.0 9.1 12.7 10.8
we-11 12.4 10.0 14.6 13.2
eq-nm 3.2 4.0 4.0 4.8
eq-11 45.0 47.5 42.0 43.7
</table>
<sectionHeader confidence="0.9997" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.999960105263158">
While adjunction is a formal operation that may be
applied to non-linguistic adjuncts in STAG, De-
Neefe and Knight (2009) restrict it to syntactic
adjuncts in a Synchronous Tree Insertion Gram-
mar. They identify complements using (Collins,
2003)’s rules, and regard all other non-head con-
stituents as adjuncts. Their model is able to gen-
eralize to unseen adjunction patterns, and to beat a
string-to-tree baseline in an Arabic-English trans-
lation task.
Arnoult and Sima’an (2012) exploit adjunct op-
tionality to generate new training data for a phrase-
based model, by removing phrase pairs with an
English adjunct from the training data. They iden-
tify adjuncts using syntactic heuristics in phrase-
structure parses. They found that few of the gener-
ated phrase pairs were actually used at decoding,
leading to marginal improvement over the base-
line in a French-English task. They also report
</bodyText>
<page confidence="0.996837">
163
</page>
<bodyText confidence="0.999945208333333">
figures of role preservation for different categories
of adjuncts, with lower bounds between 29% and
65% and upper bounds between 61% and 78%, in
automatically aligned Europarl data. The upper
bounds are limited by discontinuous adjunct pro-
jections, while the estimation of lower bounds is
limited by the lack of adjunct-identification means
for French.
There has been a growing body of work on ex-
ploiting semantic annotations for SMT. In many
cases, predicate-argument structures are used to
provide source-side contextual information for
lexical selection and/or reordering (Xiong et al.,
2012; Li et al., 2013), without requiring cross-
linguistic correspondence. When correspondence
between semantic roles is required, predicates are
commonly aligned first. For instance, Lo et al.
(2012) use a maximum-weighted bipartite match-
ing algorithm to align predicates with a lexical-
similarity measure to evaluate semantic-role corre-
spondence. Pad´o and Lapata (2009) use the same
algorithm with a similarity measure based on con-
stituent overlap to project semantic roles from En-
glish to German.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999731129032258">
In this paper we presented the first study of trans-
lation equivalence of adjuncts on a variety of
French-English parallel corpora and word align-
ments. We use a method based on overlap to de-
rive many-to-many adjunct pairings, that are inter-
pretable in terms of translation equivalence.
We found through measurements in French-
English data sets that 40% to 50% of adjuncts–
depending on the data–are bijectively aligned
across a bitext, whereas about 25% more adjuncts
align to adjuncts, albeit not bijectively. We esti-
mate that a third of these weakly equivalent links
represent true, adjunct translation equivalences.
With manually identified adjuncts, we found
that about 70% have adjunct translation-
equivalents in automatically aligned data.
These are fairly low results if one considers that
French and English are relatively close syntacti-
cally. So while they show that adjunct labelling
accuracy on both sides of the data is crucial for
adjunct alignment, and that applications that
exploit adjunction can gain from decreasing their
dependence on word alignments and idealized
experimental conditions, they call for better
understanding of the factors behind translation
divergence.
In fact, as a remaining quarter of adjuncts have
divergent translations, it would be interesting to
determine, for instance, the degree to which diver-
gence is caused by lexical conflation, or reflects
non-literal translations.
</bodyText>
<sectionHeader confidence="0.996557" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999809166666667">
We thank the anonymous reviewers for their perti-
nent comments. This research is part of the project
“Statistical Translation of Novel Constructions”,
which is supported by NWO VC EW grant from
the Netherlands Organisation for Scientific Re-
search (NWO).
</bodyText>
<sectionHeader confidence="0.99943" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999671552631579">
Sophie Arnoult and Khalil Sima’an. 2012. Adjunct
Alignment in Translation Data with an Applica-
tion to Phrase-Based Statistical Machine Transla-
tion. In Proceedings of the 16th Annual Conference
of the European Association for Machine Transla-
tion, pages 287–294.
Peter F. Brown, Stephen A. Della Pietra, Vincent J.
Della Pietra, and Robert L. Mercer. 1993. The
Mathematics of Statistical Machine Translation: Pa-
rameter Estimation. Computational Linguistics,
19(2):263–311.
M.-H. Candito, B. Crabb´e, and P. Denis. 2010. Statisti-
cal French dependency parsing: treebank conversion
and first results. In Proceedings of The seventh in-
ternational conference on Language Resources and
Evaluation (LREC).
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Lin-
guistics, 29(4):589–637.
Steve DeNeefe and Kevin Knight. 2009. Synchronous
Tree Adjoining Machine Translation. In Proceed-
ings of the 2009 Conference on Empirical Methods
in Natural Language Processing, pages 727–736.
Bonnie J. Dorr. 1994. Machine Translation Diver-
gences: A Formal Description and Proposed Solu-
tion. Computational Linguistics, 20(4):597–633.
Qin Gao and Stephan Vogel. 2008. Parallel Implemen-
tations of Word Alignment Tool. In Software En-
gineering, Testing, and Quality Assurance for Natu-
ral Language Processing, pages 49–57, Columbus,
Ohio, June. Association for Computational Linguis-
tics.
Rebecca Hwa, Philip Resnik, Amy Weinberg, and
Okan Kolak. 2002. Evaluating Translational Cor-
respondence Using Annotation Projection. In Pro-
ceedings of the 40th Annual Meeting on Association
for Computational Linguistics, ACL ’02, pages 392–
399.
</reference>
<page confidence="0.984999">
164
</page>
<reference confidence="0.99985666">
Richard Johansson and Pierre Nugues. 2007. Ex-
tended Constituent-to-dependency Conversion for
English. In Proceedings of NODALIDA 2007, pages
105–112, Tartu, Estonia, May 25-26.
Aravind K. Joshi, Leon S. Levy, and Masako Taka-
hashi. 1975. Tree adjunct grammars. Journal of
Computer and System Sciences, 10(1):136–163.
Junhui Li, Philip Resnik, and Hal Daum´e III. 2013.
Modeling Syntactic and Semantic Structures in Hi-
erarchical Phrase-based Translation. In Proceed-
ings of the 2013 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
540–549, Atlanta, Georgia.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by Agreement. In Proceedings of the Main
Conference on Human Language Technology Con-
ference of the North American Chapter of the Asso-
ciation of Computational Linguistics, HLT-NAACL
’06, pages 104–111.
Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu.
2012. Fully Automatic Semantic MT Evaluation. In
Proceedings of the Seventh Workshop on Statistical
Machine Translation, WMT ’12, pages 243–252.
Franz Josef Och and Hermann Ney. 2003. A System-
atic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29:19–51.
Sebastian Pad´o and Mirella Lapata. 2009. Cross-
lingual Annotation Projection for Semantic Roles.
Journal of Artificial Intelligence Research, 36:307–
340.
Stuart Shieber and Yves Schabes. 1990. Synchronous
tree-adjoining grammars. In Handbook of Formal
Languages, pages 69–123. Springer.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The
CoNLL-2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In CoNLL 2008:
Proceedings of the Twelfth Conference on Natural
Language Learning, pages 159–177, Manchester,
United Kingdom.
Dekai Wu and Pascale Fung. 2009. Can Semantic Role
Labeling Improve SMT? In Proceedings of the 13th
Annual Conference of the European Association for
Machine Translation, pages 218–225.
Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Mod-
eling the Translation of Predicate-Argument Struc-
ture for SMT. In Proceedings of the 50th Annual
Meeting of the Association for Computational Lin-
guistics, pages 902–911.
</reference>
<page confidence="0.998742">
165
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.888474">
<title confidence="0.999636">How Synchronous are Adjuncts in Translation Data?</title>
<author confidence="0.995265">Sophie Arnoult Khalil Sima’an</author>
<affiliation confidence="0.9988235">ILLC ILLC University of Amsterdam University of Amsterdam</affiliation>
<email confidence="0.966349">s.i.arnoult@uva.nlk.simaan@uva.nl</email>
<abstract confidence="0.997388206896552">The argument-adjunct distinction is central to most syntactic and semantic theories. As optional elements that refine (the meaning of) a phrase, adjuncts are important for recursive, compositional accounts of syntax, semantics and translation. In formal accounts of machine translation, adjuncts are often treated as modiapplying source and target derivations. But how well can the of adjunction explain translation equivalence in actual parallel data? In this paper we present the first empirical study of translation equivalence of adjuncts on a variety of French- English parallel corpora, while varying word alignments so we can gauge the effect of errors in them. We show that for proper measurement of the types of translation equivalence of adjuncts, we must work with non-contiguous, many-to-many relations, thereby amending the traditional Direct Correspondence Assumption. Our empirical results show that 70% of manually identified adjuncts have adjunct translation equivalents in training data, against roughly 50% for automatically identified adjuncts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sophie Arnoult</author>
<author>Khalil Sima’an</author>
</authors>
<title>Adjunct Alignment in Translation Data with an Application to Phrase-Based Statistical Machine Translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 16th Annual Conference of the European Association for Machine Translation,</booktitle>
<pages>287--294</pages>
<marker>Arnoult, Sima’an, 2012</marker>
<rawString>Sophie Arnoult and Khalil Sima’an. 2012. Adjunct Alignment in Translation Data with an Application to Phrase-Based Statistical Machine Translation. In Proceedings of the 16th Annual Conference of the European Association for Machine Translation, pages 287–294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="17561" citStr="Brown et al., 1993" startWordPosition="2843" endWordPosition="2846">nadian Hansards (1.13M sentence pairs), the French-English Europarl training set (1.97M sentence pairs) and the Moses newscommentaries corpus (156k sentence pairs). Besides, we randomly selected 100 sentence pairs from the Europarl set to measure adjunct identification accuracy as reported in section 3 and adjunct correspondence with gold adjunct annotations. All four corpora except the manual Hansards are preprocessed to keep sentences with up to 80 words, and all four data sets are used jointly to train unsupervised alignments, both with the Berkeley aligner (Liang et al., 2006) and GIZA++ (Brown et al., 1993; Och and Ney, 2003) through mgiza (Gao and Vogel, 2008), using 5 iterations of Model 1 and 5 iterations of HMM for the Berkeley aligner, and 5 iterations of Model 1 and HMM and 3 iterations of Model 3 and Model 4 for GIZA++. The GIZA++ alignments are symmetrized using the grow-diag-final heuristics. Besides, the manual Hansards corpus is aligned with Sure Only (SO) and Sure and Possible (SP) manual alignments. 4.2 Measurements with gold adjunct annotations We compared adjunct translation equivalence of automatically identified adjuncts and gold annotations using 100 manually annotated sentenc</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-H Candito</author>
<author>B Crabb´e</author>
<author>P Denis</author>
</authors>
<title>Statistical French dependency parsing: treebank conversion and first results.</title>
<date>2010</date>
<booktitle>In Proceedings of The seventh international conference on Language Resources and Evaluation (LREC).</booktitle>
<marker>Candito, Crabb´e, Denis, 2010</marker>
<rawString>M.-H. Candito, B. Crabb´e, and P. Denis. 2010. Statistical French dependency parsing: treebank conversion and first results. In Proceedings of The seventh international conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="24596" citStr="Collins, 2003" startWordPosition="4017" endWordPosition="4018">ent pairings. This suggests that further gains may be obtained with better alignments. Table 9: Effect of alignment simplification on adjunct translation equivalence in the Europarl data bky giza std -fw std -fw null 6.3 7.5 2.3 3.1 div 21.8 21.5 24.2 24.0 we-nm 11.0 9.1 12.7 10.8 we-11 12.4 10.0 14.6 13.2 eq-nm 3.2 4.0 4.0 4.8 eq-11 45.0 47.5 42.0 43.7 5 Related work While adjunction is a formal operation that may be applied to non-linguistic adjuncts in STAG, DeNeefe and Knight (2009) restrict it to syntactic adjuncts in a Synchronous Tree Insertion Grammar. They identify complements using (Collins, 2003)’s rules, and regard all other non-head constituents as adjuncts. Their model is able to generalize to unseen adjunction patterns, and to beat a string-to-tree baseline in an Arabic-English translation task. Arnoult and Sima’an (2012) exploit adjunct optionality to generate new training data for a phrasebased model, by removing phrase pairs with an English adjunct from the training data. They identify adjuncts using syntactic heuristics in phrasestructure parses. They found that few of the generated phrase pairs were actually used at decoding, leading to marginal improvement over the baseline </context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve DeNeefe</author>
<author>Kevin Knight</author>
</authors>
<title>Synchronous Tree Adjoining Machine Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>727--736</pages>
<contexts>
<context position="24473" citStr="DeNeefe and Knight (2009)" startWordPosition="3996" endWordPosition="4000">he proportion of weakly equivalent pairings with regard to the standard alignment (‘std’), mostly to the benefit of translationequivalent pairings. This suggests that further gains may be obtained with better alignments. Table 9: Effect of alignment simplification on adjunct translation equivalence in the Europarl data bky giza std -fw std -fw null 6.3 7.5 2.3 3.1 div 21.8 21.5 24.2 24.0 we-nm 11.0 9.1 12.7 10.8 we-11 12.4 10.0 14.6 13.2 eq-nm 3.2 4.0 4.0 4.8 eq-11 45.0 47.5 42.0 43.7 5 Related work While adjunction is a formal operation that may be applied to non-linguistic adjuncts in STAG, DeNeefe and Knight (2009) restrict it to syntactic adjuncts in a Synchronous Tree Insertion Grammar. They identify complements using (Collins, 2003)’s rules, and regard all other non-head constituents as adjuncts. Their model is able to generalize to unseen adjunction patterns, and to beat a string-to-tree baseline in an Arabic-English translation task. Arnoult and Sima’an (2012) exploit adjunct optionality to generate new training data for a phrasebased model, by removing phrase pairs with an English adjunct from the training data. They identify adjuncts using syntactic heuristics in phrasestructure parses. They foun</context>
</contexts>
<marker>DeNeefe, Knight, 2009</marker>
<rawString>Steve DeNeefe and Kevin Knight. 2009. Synchronous Tree Adjoining Machine Translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 727–736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>Machine Translation Divergences: A Formal Description and Proposed Solution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2869" citStr="Dorr, 1994" startWordPosition="429" endWordPosition="430"> Hwa et al. (2002) for dependency relations, Arnoult and Sima’an (2012) for adjuncts, and Pad´o and Lapata (2009) and Wu and Fung (2009) for semantic roles–that the Direct Correspondence Assumption does not always hold. A question that has not received much attention is the degree to which the assumption of synchronous adjunction is supported in human translation data. This is crucial for the succesful application of linguistically-motivated STAG, but attempts at answering this question empirically are hampered by a variety of difficulties. Linguistic structures may diverge between languages (Dorr, 1994), translations may be more or less literal, and annotation resources may be inaccurate, when they are available at all. Besides, automatic word alignments are known to be noisy and manual alignments are rather scarse. The work of Arnoult and Sima’an (2012) reports lower and upper bounds of one-to-one adjunct correspondence, using rather limited resources to identify French adjuncts making their results not directly applicable for measuring the stability of the synchronous adjunction assumption. In this paper we aim at redefining the translation equivalence of adjuncts in ways that allow us to </context>
<context position="12436" citStr="Dorr, 1994" startWordPosition="1998" endWordPosition="1999">n-bijective equivalent eq-nm many-to-many bijective eq-11 one-to-one bijective In Table 1, ¯e4’s translation is divergent as it is not aligned to any adjunct; f5 and ¯e6 are weakly equivalent as the projection of f5 does not cover all the aligned positions of ¯e6. The pairing from f2 to ¯e2, ¯e6 is many-to-many equivalent, and so are the pairings from ¯e2 and ¯e6 to f2; the remaining pairings are one-to-one equivalent. As Table 3 shows, the divergent types null and div regroup untranslated adjuncts (Example 1) and divergent adjuncts: Examples (2) and (3) show cases of conflational divergence (Dorr, 1994), that appear in different types because of the underlying word alignments; in Example (4), the prepositional phrase with this task has been wrongly labelled as an adjunct, leading to a falsely divergent pairing. The weakly-equivalent types we-nm and we-11 regroup both divergent and equivalent pairings: the adjuncts of Examples (5) and (8) are aligned by our method to adjuncts that are not their translation equivalent, the adjunct in Example (6) cannot be aligned to its equivalent because of a parsing error, and the equivalences in Examples (7) and (9) cannot be identified because of a word-al</context>
</contexts>
<marker>Dorr, 1994</marker>
<rawString>Bonnie J. Dorr. 1994. Machine Translation Divergences: A Formal Description and Proposed Solution. Computational Linguistics, 20(4):597–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel Implementations of Word Alignment Tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="17617" citStr="Gao and Vogel, 2008" startWordPosition="2853" endWordPosition="2856">lish Europarl training set (1.97M sentence pairs) and the Moses newscommentaries corpus (156k sentence pairs). Besides, we randomly selected 100 sentence pairs from the Europarl set to measure adjunct identification accuracy as reported in section 3 and adjunct correspondence with gold adjunct annotations. All four corpora except the manual Hansards are preprocessed to keep sentences with up to 80 words, and all four data sets are used jointly to train unsupervised alignments, both with the Berkeley aligner (Liang et al., 2006) and GIZA++ (Brown et al., 1993; Och and Ney, 2003) through mgiza (Gao and Vogel, 2008), using 5 iterations of Model 1 and 5 iterations of HMM for the Berkeley aligner, and 5 iterations of Model 1 and HMM and 3 iterations of Model 3 and Model 4 for GIZA++. The GIZA++ alignments are symmetrized using the grow-diag-final heuristics. Besides, the manual Hansards corpus is aligned with Sure Only (SO) and Sure and Possible (SP) manual alignments. 4.2 Measurements with gold adjunct annotations We compared adjunct translation equivalence of automatically identified adjuncts and gold annotations using 100 manually annotated sentence pairs from the Europarl corpus; adjuncts were aligned </context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel Implementations of Word Alignment Tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Okan Kolak</author>
</authors>
<title>Evaluating Translational Correspondence Using Annotation Projection.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>392--399</pages>
<contexts>
<context position="2276" citStr="Hwa et al. (2002)" startWordPosition="337" endWordPosition="340">itionality, albeit in various ways, as syntactic adjuncts may take different semantic roles. Shieber and Schabes (1990) transfer the role of adjuncts from monolingual syntax (Joshi et al., 1975) to the realm of translation equivalence using a Synchronous Tree Adjoining Grammars (STAG), and propose to view adjunction as a synchronous operation for recursive, compositional translation. STAG therefore relies substantially on what Hwa (2002) calls the Direct Correspondence Assumption, the notion that semantic or syntactic relations correspond across a bitext. We know from various works–notably by Hwa et al. (2002) for dependency relations, Arnoult and Sima’an (2012) for adjuncts, and Pad´o and Lapata (2009) and Wu and Fung (2009) for semantic roles–that the Direct Correspondence Assumption does not always hold. A question that has not received much attention is the degree to which the assumption of synchronous adjunction is supported in human translation data. This is crucial for the succesful application of linguistically-motivated STAG, but attempts at answering this question empirically are hampered by a variety of difficulties. Linguistic structures may diverge between languages (Dorr, 1994), trans</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Kolak, 2002</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, and Okan Kolak. 2002. Evaluating Translational Correspondence Using Annotation Projection. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 392– 399.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Extended Constituent-to-dependency Conversion for English.</title>
<date>2007</date>
<booktitle>In Proceedings of NODALIDA</booktitle>
<pages>105--112</pages>
<location>Tartu, Estonia,</location>
<contexts>
<context position="13827" citStr="Johansson and Nugues, 2007" startWordPosition="2222" endWordPosition="2225">ivalence where there should be two one-to-one equivalences; Examples (11) to (13) show a number of true manyto-many equivalences, while Examples (14) and (15) show that adjuncts may be equivalent across a bitext while belonging to a different syntactic category and modifying a different type of phrase (15). 3 Adjunct identification We identify adjuncts in dependency trees obtained by conversion from phrase-structure trees: we map modifier labels to adjuncts, except when the dependent is a closed-class word. For English, we use the Berkeley parser and convert its output with the pennconverter (Johansson and Nugues, 2007; Surdeanu et al., 2008); for French, we use the Berkeley parser and the functional role labeller of Candito et al. (2010). The pennconverter with default options and the French converter make similar structural choices concerning the representation of coordination and the choice of heads. 3.1 English adjuncts We first identify closed-class words by their POS tag: CC, DT, EX, IN, POS, PRP, PRP$, RP, SYM, TO, WDT, WP, WP$, WRB. Punctuation marks, identified by the P dependency relation, and name dependencies, identified by NAME, POSTHON, or TITLE, are also treated as closed-class words. Adjunct</context>
</contexts>
<marker>Johansson, Nugues, 2007</marker>
<rawString>Richard Johansson and Pierre Nugues. 2007. Extended Constituent-to-dependency Conversion for English. In Proceedings of NODALIDA 2007, pages 105–112, Tartu, Estonia, May 25-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Leon S Levy</author>
<author>Masako Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="1853" citStr="Joshi et al., 1975" startWordPosition="272" endWordPosition="275">ainst roughly 50% for automatically identified adjuncts. 1 Introduction Most syntactic and semantic theories agree on the argument-adjunct distinction, although they vary on the specifics of this distinction. Common to these theories is that adjunction is a central device for language recursion, as adjunction modifies initial but complete sentences by adding optional phrases; adjunction also contributes to semantic compositionality, albeit in various ways, as syntactic adjuncts may take different semantic roles. Shieber and Schabes (1990) transfer the role of adjuncts from monolingual syntax (Joshi et al., 1975) to the realm of translation equivalence using a Synchronous Tree Adjoining Grammars (STAG), and propose to view adjunction as a synchronous operation for recursive, compositional translation. STAG therefore relies substantially on what Hwa (2002) calls the Direct Correspondence Assumption, the notion that semantic or syntactic relations correspond across a bitext. We know from various works–notably by Hwa et al. (2002) for dependency relations, Arnoult and Sima’an (2012) for adjuncts, and Pad´o and Lapata (2009) and Wu and Fung (2009) for semantic roles–that the Direct Correspondence Assumpti</context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Aravind K. Joshi, Leon S. Levy, and Masako Takahashi. 1975. Tree adjunct grammars. Journal of Computer and System Sciences, 10(1):136–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Philip Resnik</author>
<author>Hal Daum´e</author>
</authors>
<title>Modeling Syntactic and Semantic Structures in Hierarchical Phrase-based Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>540--549</pages>
<location>Atlanta,</location>
<marker>Li, Resnik, Daum´e, 2013</marker>
<rawString>Junhui Li, Philip Resnik, and Hal Daum´e III. 2013. Modeling Syntactic and Semantic Structures in Hierarchical Phrase-based Translation. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 540–549, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by Agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL ’06,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="17530" citStr="Liang et al., 2006" startWordPosition="2837" endWordPosition="2840">d senate training data of the Canadian Hansards (1.13M sentence pairs), the French-English Europarl training set (1.97M sentence pairs) and the Moses newscommentaries corpus (156k sentence pairs). Besides, we randomly selected 100 sentence pairs from the Europarl set to measure adjunct identification accuracy as reported in section 3 and adjunct correspondence with gold adjunct annotations. All four corpora except the manual Hansards are preprocessed to keep sentences with up to 80 words, and all four data sets are used jointly to train unsupervised alignments, both with the Berkeley aligner (Liang et al., 2006) and GIZA++ (Brown et al., 1993; Och and Ney, 2003) through mgiza (Gao and Vogel, 2008), using 5 iterations of Model 1 and 5 iterations of HMM for the Berkeley aligner, and 5 iterations of Model 1 and HMM and 3 iterations of Model 3 and Model 4 for GIZA++. The GIZA++ alignments are symmetrized using the grow-diag-final heuristics. Besides, the manual Hansards corpus is aligned with Sure Only (SO) and Sure and Possible (SP) manual alignments. 4.2 Measurements with gold adjunct annotations We compared adjunct translation equivalence of automatically identified adjuncts and gold annotations using</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by Agreement. In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, HLT-NAACL ’06, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi-kiu Lo</author>
<author>Anand Karthik Tumuluru</author>
<author>Dekai Wu</author>
</authors>
<title>Fully Automatic Semantic MT Evaluation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT ’12,</booktitle>
<pages>243--252</pages>
<contexts>
<context position="26033" citStr="Lo et al. (2012)" startWordPosition="4237" endWordPosition="4240">rl data. The upper bounds are limited by discontinuous adjunct projections, while the estimation of lower bounds is limited by the lack of adjunct-identification means for French. There has been a growing body of work on exploiting semantic annotations for SMT. In many cases, predicate-argument structures are used to provide source-side contextual information for lexical selection and/or reordering (Xiong et al., 2012; Li et al., 2013), without requiring crosslinguistic correspondence. When correspondence between semantic roles is required, predicates are commonly aligned first. For instance, Lo et al. (2012) use a maximum-weighted bipartite matching algorithm to align predicates with a lexicalsimilarity measure to evaluate semantic-role correspondence. Pad´o and Lapata (2009) use the same algorithm with a similarity measure based on constituent overlap to project semantic roles from English to German. 6 Conclusion In this paper we presented the first study of translation equivalence of adjuncts on a variety of French-English parallel corpora and word alignments. We use a method based on overlap to derive many-to-many adjunct pairings, that are interpretable in terms of translation equivalence. We</context>
</contexts>
<marker>Lo, Tumuluru, Wu, 2012</marker>
<rawString>Chi-kiu Lo, Anand Karthik Tumuluru, and Dekai Wu. 2012. Fully Automatic Semantic MT Evaluation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT ’12, pages 243–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics,</title>
<date>2003</date>
<pages>29--19</pages>
<contexts>
<context position="16866" citStr="Och and Ney, 2003" startWordPosition="2730" endWordPosition="2733"> le bon processus (12) our common space and our common means un espace et des moyens communs (13) the [personal] [protected] files les dossiers confidentiels et prot´eg´es eq-11 (14) the names just announced les noms que je viens de mentionner (15) one in three Canadian jobs au Canada, un emploi sur trois Table 4: Adjunct identification F scores prec. recall F En auto. 66.2 77.2 71.3 corr. 72.3 84.0 77.7 Fr auto. 68.1 76.7 72.2 corr. 74.7 83.0 78.6 4 Experiments 4.1 Experimental set-up We measure adjunct translation equivalence in four data sets: the manually-aligned Canadian Hansards corpus (Och and Ney, 2003), containing 447 sentence pairs, the house and senate training data of the Canadian Hansards (1.13M sentence pairs), the French-English Europarl training set (1.97M sentence pairs) and the Moses newscommentaries corpus (156k sentence pairs). Besides, we randomly selected 100 sentence pairs from the Europarl set to measure adjunct identification accuracy as reported in section 3 and adjunct correspondence with gold adjunct annotations. All four corpora except the manual Hansards are preprocessed to keep sentences with up to 80 words, and all four data sets are used jointly to train unsupervised</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29:19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Crosslingual Annotation Projection for Semantic Roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>36</volume>
<pages>340</pages>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Crosslingual Annotation Projection for Semantic Roles. Journal of Artificial Intelligence Research, 36:307– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Shieber</author>
<author>Yves Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In Handbook of Formal Languages,</booktitle>
<pages>69--123</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1778" citStr="Shieber and Schabes (1990)" startWordPosition="260" endWordPosition="263">ally identified adjuncts have adjunct translation equivalents in training data, against roughly 50% for automatically identified adjuncts. 1 Introduction Most syntactic and semantic theories agree on the argument-adjunct distinction, although they vary on the specifics of this distinction. Common to these theories is that adjunction is a central device for language recursion, as adjunction modifies initial but complete sentences by adding optional phrases; adjunction also contributes to semantic compositionality, albeit in various ways, as syntactic adjuncts may take different semantic roles. Shieber and Schabes (1990) transfer the role of adjuncts from monolingual syntax (Joshi et al., 1975) to the realm of translation equivalence using a Synchronous Tree Adjoining Grammars (STAG), and propose to view adjunction as a synchronous operation for recursive, compositional translation. STAG therefore relies substantially on what Hwa (2002) calls the Direct Correspondence Assumption, the notion that semantic or syntactic relations correspond across a bitext. We know from various works–notably by Hwa et al. (2002) for dependency relations, Arnoult and Sima’an (2012) for adjuncts, and Pad´o and Lapata (2009) and Wu</context>
</contexts>
<marker>Shieber, Schabes, 1990</marker>
<rawString>Stuart Shieber and Yves Schabes. 1990. Synchronous tree-adjoining grammars. In Handbook of Formal Languages, pages 69–123. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<booktitle>The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning,</booktitle>
<pages>159--177</pages>
<location>Manchester, United Kingdom.</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Natural Language Learning, pages 159–177, Manchester, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Can Semantic Role Labeling Improve SMT?</title>
<date>2009</date>
<booktitle>In Proceedings of the 13th Annual Conference of the European Association for Machine Translation,</booktitle>
<pages>218--225</pages>
<contexts>
<context position="2394" citStr="Wu and Fung (2009)" startWordPosition="357" endWordPosition="360">0) transfer the role of adjuncts from monolingual syntax (Joshi et al., 1975) to the realm of translation equivalence using a Synchronous Tree Adjoining Grammars (STAG), and propose to view adjunction as a synchronous operation for recursive, compositional translation. STAG therefore relies substantially on what Hwa (2002) calls the Direct Correspondence Assumption, the notion that semantic or syntactic relations correspond across a bitext. We know from various works–notably by Hwa et al. (2002) for dependency relations, Arnoult and Sima’an (2012) for adjuncts, and Pad´o and Lapata (2009) and Wu and Fung (2009) for semantic roles–that the Direct Correspondence Assumption does not always hold. A question that has not received much attention is the degree to which the assumption of synchronous adjunction is supported in human translation data. This is crucial for the succesful application of linguistically-motivated STAG, but attempts at answering this question empirically are hampered by a variety of difficulties. Linguistic structures may diverge between languages (Dorr, 1994), translations may be more or less literal, and annotation resources may be inaccurate, when they are available at all. Besid</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009. Can Semantic Role Labeling Improve SMT? In Proceedings of the 13th Annual Conference of the European Association for Machine Translation, pages 218–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Modeling the Translation of Predicate-Argument Structure for SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>902--911</pages>
<contexts>
<context position="25838" citStr="Xiong et al., 2012" startWordPosition="4210" endWordPosition="4213">. They also report 163 figures of role preservation for different categories of adjuncts, with lower bounds between 29% and 65% and upper bounds between 61% and 78%, in automatically aligned Europarl data. The upper bounds are limited by discontinuous adjunct projections, while the estimation of lower bounds is limited by the lack of adjunct-identification means for French. There has been a growing body of work on exploiting semantic annotations for SMT. In many cases, predicate-argument structures are used to provide source-side contextual information for lexical selection and/or reordering (Xiong et al., 2012; Li et al., 2013), without requiring crosslinguistic correspondence. When correspondence between semantic roles is required, predicates are commonly aligned first. For instance, Lo et al. (2012) use a maximum-weighted bipartite matching algorithm to align predicates with a lexicalsimilarity measure to evaluate semantic-role correspondence. Pad´o and Lapata (2009) use the same algorithm with a similarity measure based on constituent overlap to project semantic roles from English to German. 6 Conclusion In this paper we presented the first study of translation equivalence of adjuncts on a varie</context>
</contexts>
<marker>Xiong, Zhang, Li, 2012</marker>
<rawString>Deyi Xiong, Min Zhang, and Haizhou Li. 2012. Modeling the Translation of Predicate-Argument Structure for SMT. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 902–911.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>