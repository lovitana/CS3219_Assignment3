<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000199">
<title confidence="0.984801">
Evaluation Report of the fourth Chinese Parsing Evaluation: CIPS-
SIGHAN-ParsEval-2014
</title>
<author confidence="0.997598">
Qiang Zhou
</author>
<affiliation confidence="0.947846">
Center for Speech and Language Technology
Research Institute of Information Technology
Tsinghua National Laboratory for Information Science
and Technology
Tsinghua University, Beijing 100084, China.
</affiliation>
<email confidence="0.933176">
zq-lxd@mail.tsinghua.edu.cn
</email>
<sectionHeader confidence="0.977788" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997789857142857">
This paper gives the overview of the fourth
Chinese parsing evaluation: CIPS-SIGHAN-
ParsEval-2014, including its parsing, evalua-
tion metrics, training and test data. The de-
tailed evaluation results and simple discus-
sions will be given to show the difficulties in
Chinese syntactic parsing.
</bodyText>
<sectionHeader confidence="0.995137" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999928140625">
For Chinese parsing evaluations, we have suc-
cessfully held three times in 2009, 2010 and
2012. They are the CIPS-ParsEval-2009 (Zhou
and Li, 2009), CIPS-SIGHAN-ParsEval-2010
(Zhou and Zhu, 2010) and CIPS-SIGHan-
ParsEval-2012 (Zhou, 2012) respectively. Each
evaluation has its different theme and goal.
The first ParsEval-2009 focused on Chinese
chunk parsing. Three kinds of chunking tasks
were designed for the Chinese chunks with dif-
ferent descriptive complexities. The evaluation
results showed that as the increasing of the word
number and descriptive complexity of the chunks
from base chunks (BC) to functional chunks (FC)
and event descriptive chunks (EDC), the final
F1-value will also decrease about 6 points from
92% to 86% and 80%.
The second ParsEval-2010 and third ParsEval-
2012 focused on Chinese syntactic parsing. They
had different points of emphasis for parse tree
evaluation.
In ParsEval-2010, we compared the parsing
performance differences in two kinds of Chinese
sentences. One is the EDC clauses with about 10
words averagely. The other is the complete sen-
tences with about 23 words averagely. Evalua-
tion results showed that there were about 8%
drops for the complete sentence in the labelled
F1-score measure.
In ParsEval-2012, we compared the parsing
performance differences in two kinds of syntactic
constituent in Chinese complete sentences. One
is the syntactic constituents with complex inter-
nal compound relationships, including event
combination and concept composition relations.
The other is the syntactic constituents with ordi-
nary internal relations, such as subject-predicate,
predicate-object, modifier-head, etc. Evaluation
results showed that there were 20% drops for the
syntactic constituents with complex internal rela-
tions in the labelled F1-score measure.
The above evaluation results in the Chinese
clause and sentence levels show that the complex
sentence parsing is still a big challenge for the
Chinese language.
This time we will focus on the deeper parsing
evaluation in the Predicate-Argument Structure
(PAS) level to test whether the parser can deal
with different syntactic alternatives with same
event contents. We will introduce a new lexicon-
based Combinatory Categorical Grammar (CCG)
(Steedman 1996, 2000) annotation scheme in the
evaluation, and propose a new implicit predicate
argument (IPA) relation annotation method to
build a large scale CCG bank with detailed PAS
annotations. The special lexical dependency pairs
automatically extracted from the CCG bank will
be used as the final gold-standard data for evalu-
ating parsers’ IPA recognition capacity.
Same with previous ParsEval-2010 and Par-
sEval-2014, we also set two tracks in the ParsE-
val-2014. One is the Close track in which model
parameter estimation is conducted solely on the
train data. The other is the Open track in which
</bodyText>
<page confidence="0.69052">
146
</page>
<note confidence="0.9088945">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 146–152,
Wuhan, China, 20-21 October 2014
</note>
<bodyText confidence="0.948889">
any datasets other than the given training data
can be used to estimate model parameters. We
will set separated evaluation ranks for these two
tracks.
In addition, we will evaluate following two
kinds of methods separately in each track.
</bodyText>
<listItem confidence="0.993279">
1) Single system: parsers that use a single
parsing model to finish the parsing task.
2) System combination: participants are al-
lowed to combine multiple models to improve
the performance. Collaborative decoding meth-
ods will be regarded as a combination method.
</listItem>
<sectionHeader confidence="0.481486" genericHeader="introduction">
2 Evaluation Task and Metrics
</sectionHeader>
<subsectionHeader confidence="0.98062">
2.1 Parsing Evaluation Task
</subsectionHeader>
<bodyText confidence="0.991421">
Input: A Chinese sentence with correct word
segmentations. The following is an example:
</bodyText>
<equation confidence="0.978952">
小型(small) 木材(wood) 加工场(factory) 在
(is) 忙(busy) 着(-modality) 制作(build) 各
(several) 种(-classifier) 木制品(woodwork) 。
(period) (A small wood factory is busy to build
several woodworks.)
</equation>
<bodyText confidence="0.938003">
Parsing goal: Assign appropriate CCG category
tags to the words in the sentence and generate
CCG derivation tree for the sentence.
Output: The CCG derivation tree with CCG cat-
egory tags and feature annotations.
</bodyText>
<listItem confidence="0.905883571428571">
• (S{decl} (S (NP (NP/NP 小型) (NP (NP/NP
木材) (NP 加工场) ) ) (S\NP ([S\NP]/[S\NP]
在 ) (S{Cmb=LW}\NP (S\NP (S\NP 忙 )
([S\NP]\[S\NP] 着) ) (S\NP ([S\NP]/NP 制
作) (NP (NP/NP ([NP/NP]/M 各) (M 种) )
(NP 木制品) ) ) ) ) ) (wE 。) )
(1)
</listItem>
<subsectionHeader confidence="0.99939">
2.2 Parsing Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999468875">
There are two parsing stages for the CCG
parsers. One is the syntactic category (CCG cat-
egory) assignment stage. The other is the parse
tree (CCG derivation tree) generation stage. So
we design two different sets of metrics for them.
For the syntactic category (SC) parsing stage,
basic metrics are SC tagging precision (SC_P),
recall (SC_R) and F1-score(SC_F1).
</bodyText>
<listItem confidence="0.9994544">
• SC_P= (# of correctly tagged words) / (#
of automatically tagged words) * 100%
• SC_R= (# of correctly tagged words) / (#
of gold-standard words) * 100%
• SC_F1= 2*SC_P*SC_R / (SC_P + SC_R)
</listItem>
<bodyText confidence="0.998875666666667">
The correctly tagged words must have the
same syntactic categories with the gold-standard
ones.
To obtain detailed evaluation results for dif-
ferent syntactic categories, we will classify all
tagged words into different sets and compute
different SC_P, SC_R and SC_F1 for them. The
classification condition is as follows.
If (SC_Token_Ratio &gt;=10%), then the syntac-
tic tag will be one class with its SC tag, other-
wise all other low-frequency SC-tagged words
will be classified with a special class with
Oth_SC tag. Where, SC_Token_Ratio= (word
token # of one special SC in the test set) / (word
token # in the test set) * 100%.
For the CCG derivation tree generation stage,
the lexical dependency pairs (LDPs) automatical-
ly extracted from the CCG derivation trees will
be used as the basic evaluation units. Basic met-
rics for them are LDP precision (LDP_P), recall
(LDP_R) and F1-score (LDP_F1).
</bodyText>
<listItem confidence="0.9993226">
• LDP_P = (# of correctly labeled LDPs) /
(# of automatically parsed LDPs) * 100%
• LDP_R= (# of correctly labeled LDPs) /
(# of gold-standard LDPs) * 100%
• LDP F1= 2*LDP P*LDP R /
</listItem>
<equation confidence="0.7554765">
_ _ _
(LDP_P+LDP_R)
</equation>
<bodyText confidence="0.999897857142857">
The correctly labeled LDPs must have the
same annotation information with the gold-
standard ones.
To obtain detailed evaluation results for dif-
ferent LDPs, we can classify them into 5 sets and
compute different LDP_P, LDP_R and LDP_F1
for them respectively.
</bodyText>
<listItem confidence="0.907421615384615">
(1) LDPs with complex event relations in the
sentence levels;
(2) LDPs with concept compound relations in
the chunk levels;
(3) LDPs with predicate-argument relations
in the clause levels, including head-
complement and adjunct-head relations.
(4) LDPs with other non-PA relations in the
chunk and clause levels, including modi-
fier-head and operator-complement rela-
tions.
147
(5) All other LDPs.
</listItem>
<bodyText confidence="0.999460538461539">
We compute the weighted average of the F1-
scores of the first four sets (Tot4_F1) to obtain
the final ranked scores for different proposed
parser systems. The computation formula is as
follows: Tot5_F1=∑LDP_F1i * LDP_Ratioi,i
∈[1,4].
LDP_Ratioi is the distributional ratio for the ith
LDP set in the test set. It computation formula is:
LDP_Ratioi= (# of LDPs in ith set) / (# of all
LDPs) * 100%
For comparison analysis, we also compute the
weighted average of F1-scores of all five sets for
ranking reference.
</bodyText>
<sectionHeader confidence="0.96831" genericHeader="method">
3 Evaluation data
</sectionHeader>
<bodyText confidence="0.998838351351351">
We used the annotated sentences in the TCT ver-
sion 1.0 (Zhou, 2004) as the basic resources and
designed the following transformation and anno-
tation procedures to obtain the final training and
test data for the parsing evaluation task.
Firstly, we automatically transformed all the
TCT parse trees into CCG derivation trees by
using the TCT2CCG tool (Zhou, 2011), and built
a CCG bank version 1.0 for the TCT data. In the
bank, most of clauses can be obtained correct
CCG derivation trees due to the direct applica-
tion of the syntax-semantics linking (SSL) prin-
ciples among the basic syntactic constructions in
Chinese sentences. The above CCG derivation
tree (1) in section 2.1 is a good example. But
there are still many syntactic constructions con-
sist of implicit predicate-argument (IPA) rela-
tions, such as the topicalization and relative
clause constructions. They can’t be automatically
transformed into correct CCG derivation trees
through the explicit SSL mapping rules. To deal
with the problem, we proposed to manually an-
notate the IPA relations in these special construc-
tions and restructure the corresponding CCG der-
ivation sub-trees according to these annotated PA
tags.
The key for IPA annotation is to find the suit-
able construction examples that carry the IPA
relations in Chinese sentences. So we classify all
the event constructions (ECs) in the Chinese sen-
tences into the following three sets:
1) Basic event constructions (BEC)
They are the typical subject-predicate-object
constructions in Chinese clause level. The direct
SSL can be found in the constructions. So the
current TCT2CCG tool is OK for them. A sim-
ple example is as follows:
</bodyText>
<listItem confidence="0.898193">
• 我(I) 读过(have read) 这本书(the book).
(I have read the book.)
2) Derived event constructions (DEC)
</listItem>
<bodyText confidence="0.9999494">
They are the derived constructions in Chinese
clause level due to some special pragmatics pur-
poses or contexts. Most of them are the topicali-
zation or argument-ellipsis constructions. The
following is a topicalization example:
</bodyText>
<listItem confidence="0.993726">
• 这本书(the book) 我(I) 读过(have read).
(The book, I have read.)
</listItem>
<bodyText confidence="0.991583">
The topicalized deep object “ 这 本 书 (the
book)” should be given special IPA tags to show
the detailed SSL relations.
3) Transformed event constructions (TEC)
Most of them are the relative sub-clauses to
describe the special event backgrounds for an
ongoing main event predicate. The structural par-
ticle 的(de) is used as the relative marker for
them. The following is a relative sub-clause ex-
ample (underlined) in a complete clause:
</bodyText>
<listItem confidence="0.903766666666667">
• 我(I) 读过(have read) 的(de) 这本书(the
book) 很 有 趣 (very interesting). (The
book that I have read is very interesting.)
It is a big challenge to identify whether the
relative noun phrases are the real extracted ar-
guments in TECs or not.
</listItem>
<bodyText confidence="0.997532916666667">
Based on the above event construction classi-
fication, we proposed an EC-based IPA annota-
tion scheme. For each DEC or TEC example ex-
tracted from Chinese real sentences, two or three
independent annotators were asked to select the
suitable corresponding BEC menu for them on
an IPA annotation platform. Some detailed in-
formation about the IPA annotation procedure
can be found in (Qiu, 2014).
After manual IPA annotation, we can obtain
the following ECs with IPA tags for the above
two DEC and TEC examples:
</bodyText>
<listItem confidence="0.990420166666667">
• [T-np-Arg2 这 本 书(the book) ] [S-np-
Arg1 我 (I) ] [P-vp-Pred 读 过 (have
read) ]1
• [S-np-Arg1 我(I) ] [P-vp-Pred 读过(have
read) ] 的(de) [H-np-Arg2 这本书(the
book) ]
</listItem>
<bodyText confidence="0.992595">
So, they show the same event contents with
the following corresponding BEC annotation:
</bodyText>
<table confidence="0.714684666666667">
1 Each event chunk will be given the following tag combi-
nations: &lt;Functional tag&gt;-&lt;Constituent tag&gt;-&lt;PA tag&gt;.
Some tags used in these examples are listed as follows: T-
topic, S-subject, P-predicate, O-object, H-head; np-noun
phrase, vp-verb phrase; ArgX-different argument position,
Pred-predicate position
</table>
<page confidence="0.588089">
148
</page>
<listItem confidence="0.952546166666667">
• [S-np-Arg1 R(I) ] [P-vp-Pred tgx1(have
read) ] [O-np-Arg2 i*(the book) ]
These detailed IPA tags provided us with
enough indicators for further CCG derivation
tree rebuilding. Some main CCG rebuilding
principles are as follows:
1) The same CCG tags should be assigned to
the event target predicates (ETP) in the
corresponding BEC, DEC and TEC exam-
ples. So in the above three ECs, the ETP
“�(read)” should be assigned the same
CCG tag: (S\NP)/NP.
</listItem>
<bodyText confidence="0.960066666666667">
2) The deep arguments with same IPA tags
should be linked to the same argument po-
sitions in the corresponding ETP’s CCG
tags. For example, the argument chunk
with IPA tag “Arg1” should be linked to
the first NP argument position in the cor-
responding ETP-ig�(read): (S\NP1)/NP2.
Based on the above principles, we proposed a
CCG derivation tree rebuilding algorithm. Please
refer (Qiu, 2014) for more details about the algo-
rithm. Here, we will give some figures to show
the key idea of rebuilding procedure for the DEC
and TEC examples.
(2)
Figure (2) shows the rebuilt CCG derivation
tree for a topicalized DEC. Two CCG type rais-
ing (TR) rules are used for locating two deep
arguments:
</bodyText>
<listItem confidence="0.9995835">
• For deep subject: NP 4 S/(S\NP)
• For deep object: NP 4 S/(S/NP)
</listItem>
<bodyText confidence="0.9998306">
The CCG forward composition rule: S/(S\NP)
(S\NP)/NP 4B S/NP, is used for the SSL of the
deep subject. The special CCG forward applica-
tion rule: S/(S\NP) S\NP 4 S, is used for the
SSL of the topicalized deep object.
Figure (3) shows the rebuilt CCG derivation
tree for a relative sub-clause TEC. The SSL of
the deep subject is same with the above figure
(2). The CCG co-indexing (CI) scheme is used
for the SSL of the extracted deep object. It is as-
signed as a special feature in the CCG tag of the
structure particle M, (de): (NP1/NP2)\(S/NP3)
[CI:2=3], which means that the modified head
(NP2) of the relative clause is co-index with re-
duced deep object (NP3) in the relative clause.
</bodyText>
<equation confidence="0.553837">
(3)
</equation>
<bodyText confidence="0.999242">
The rebuilt CCG derivation trees can provide
consistent representations for different shallow
syntactic alternatives with the same deep PA re-
lations. Therefore, the same lexical dependency
pairs for describing the PA relations in the above
three different BEC, DEC and TEC examples
can be automatically extracted (Hockenmaier et
al., 2007) from the corresponding rebuilt CCG
derivation trees:
</bodyText>
<listItem confidence="0.9994275">
• ig�(read), (S\NP)/NP, 1, R(I)
• &apos;(read), (S\NP)/NP, 2, 书(book)
</listItem>
<bodyText confidence="0.99991725">
They describe the same event contents consist
in the above three EC examples. So we used
these LDPs as the benchmark data for CCG parse
tree evaluation.
</bodyText>
<sectionHeader confidence="0.995699" genericHeader="evaluation">
4 Evaluation Results
</sectionHeader>
<subsectionHeader confidence="0.999185">
4.1 Training and Test data
</subsectionHeader>
<bodyText confidence="0.9997616">
All the news and academic articles annotated in
the TCT version 1.0 (Zhou, 2004) are selected as
the basic training data for the evaluation. It con-
sists of about 480,000 Chinese words. 1000 sen-
tences extracted from the TCT-2010 version are
used as the basic test data. After the TCT2CCG
transformation, EC-based IPA annotation and
CCG derivation tree rebuilding, all the training
and test data have been annotated with suitable
CCG format tags and derivation trees.
</bodyText>
<tableCaption confidence="0.993911">
Table 1 Basic statistics of the training and test data:
</tableCaption>
<table confidence="0.993308166666667">
Average Sentence Length (ASL)= Word Sum/ Sent. Sum
Sent. Word Char. ASL
Sum Sum Sum
Training 17558 473587 762866 26.97
Set
Test Set 1000 24108 34079 24.11
</table>
<page confidence="0.778217">
149
</page>
<bodyText confidence="0.983794090909091">
Table 1 shows the basic statistics of the train-
ing and test set. Figure 1 and Figure 2 list the
distribution curve of the annotated sentences
with different lengths (word sums) in the training
and test set. They show very similar statistical
characteristics. Their peaks are located in the
region of 14 to 23. More than 75% annotated
sentences have 15 or more Chinese words. The
average sentence length is about 25. All these
data show the complexity of the syntactic parsing
task in the Chinese real world texts.
</bodyText>
<figureCaption confidence="0.805849">
Figure 1 Sentence Length Distribution of the
Training Set
Figure 2 Sentence Length Distribution of the Test
</figureCaption>
<subsectionHeader confidence="0.848999">
Set
</subsectionHeader>
<bodyText confidence="0.999808">
final evaluation result. Table 2 lists the basic in-
formation of these participants.
i!c�f o shows the ranked re-
sults of the proposed systems in the only Open
track. Due to the difficulty of Chinese CCG pars-
ing, the proposed system didn’t show good pars-
ing performance: SC_F1=71.81%,
Tot5_LDP_F1=41.95%. Compared with the
state-of-the-art English CCG parsers (Clark et al.,
2004), the syntactic category tagging (supertag-
ging) performance has about 20% drops in the
Chinese CCG parser. It may indicate that the un-
known word supertagging may be a big chal-
lenge for the Chinese language.
Table 4 lists the parsing performances of the
LDPs with different internal dependency rela-
tions. As we have expected, the parsing perfor-
mances of the LDPs with other non-PA relations
(class 4) are the highest ones among them. The
LDP-F1 score of them is about 5% better than
the overall Tot4-LDP-F1 score. The second ones
are the LDPs with PA relations. They show
about 6% drops compared with the LDP with
non-PA relations. It indicates that some outside
lexical semantic resources may need for efficient
PAS analysis. The parsing performances of the
LDPs with complex event relations (class 1) and
concept compound relations (class 2) are much
lower than the overall LDP-F1 score with about
10-30% drops. Between them, the F1 score of the
LDPs in class 1 is about 19% lower than that of
class 2. A possible reason is that they may need
more long-distance dependency features that are
very difficult to be extracted through current sta-
tistical parsing model. These performance chang-
ing trends are very similar with that were found
in ParsEval-2012.
</bodyText>
<figure confidence="0.999658777777778">
Sentence Number 600
500
400
300
200
100
0
0 100 200 300
Sentence Length
0 50 100 150
Sentence Length
Sentence Number
40
50
30
20
10
0
</figure>
<subsectionHeader confidence="0.893104">
4.2 General results
</subsectionHeader>
<bodyText confidence="0.9283325">
9 participants proposed the registration forms.
Among them, only 1 participant proposed the
</bodyText>
<tableCaption confidence="0.974975">
Table 2 Participant information for ParsEval-2014
</tableCaption>
<table confidence="0.933368636363636">
ID Participants Systems (Open/Close)
1 NLP Labortory, Zhengzhou University /
2 Brandeis University, USA /
3 Beijing University of Posts and Telecommunications /
4 Institute of Automation, CAS 1/0
5 Harbin Institute of Technology /
6 Singapore Univ. of Technology and Design /
7 Institut national des langues et civilisation Orientales(INALCO) /
8 Zhejian Institute of Marine /
9 Yahoo Corp. /
150
</table>
<tableCaption confidence="0.92146">
Table 3 Ranked results in the Open Track of the CCG parsing task
</tableCaption>
<table confidence="0.998743">
ID Models SC_F1 LDP_P LDP_R LDP_F1 Tot4_LDP_P Tot4_LDP_R Tot4_LDP_F1 Rank
4 Single 71.81% 42.32% 42.27% 42.29% 41.83% 42.07% 41.95% 1
</table>
<tableCaption confidence="0.992901">
Table 4 Evaluation results of the different classes of LDPs in the Open Track
</tableCaption>
<table confidence="0.9979168">
Class 1 Class 2 Class 3 Class 4 Class 5
I P R F1 P R F1 P R F1 P R F1 P R F1
D
4 12.9 11.9 12.4 26.8 36.8 31.0 40.6 40.4 40.5 47.6 46.7 47.1 45.8 43.6 44.6
9% 2% 3% 0% 7% 4% 9% 7% 8% 0% 1% 5% 1% 2% 9%
</table>
<sectionHeader confidence="0.99757" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.99991">
Combinatory categorical grammar can provide
strong platform for describing the deep PAS of
different shallow syntactic alternatives with same
event contents. So we introduced CCG into the
4th Chinese parsing evaluation (ParsEval-2014)
and proposed an EC-based IPA annotation meth-
od to build a new CCG-based evaluation bench-
mark data. Although the number of the proposed
systems was not enough to show the real applica-
tion potential of CCG parsing for the Chinese
language, we still think CCG parsing is a good
direction need to be explored in the future.
</bodyText>
<sectionHeader confidence="0.996558" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9994995">
The research was supported by National Basic
Research Program of China (Grant No.:
2013CB329304) and National Science Founda-
tion of China (Grant No.: 61373075). Thanks Mr.
Zhou Xiaocong to develop the LDP evaluation
tools for the evaluation task.
</bodyText>
<sectionHeader confidence="0.996408" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999645976744186">
Clark, S., Copestake, A., Curran, J.R., Zhang, Y.,
Herbelot, A., Haggerty, J., Ahn, B.G., Wyk, C.V.,
Roesner, J., Kummerfeld, J., Dawborn, T.: 2009
Large-scale syntactic processing: Parsing the web.
Final Report of the 2009 JHU CLSP Workshop
Clark, Stephen and James R. Curran. Parsing the WSJ using
CCG and log-linear models. 2004. In Proceedings of the
42nd Annual Meeting of the Association for Computa-
tional Linguistics, pages 103–110, Barcelona, Spain.
Hockenmaier, J., Steedman, M.: 2007. CCGbank: A Corpus
of CCG Derivations and Dependency Structures Extract-
ed from the Penn Treebank. Computational Linguistics
33(3), 355--396
Han Qiu. 2014. Research on Chinese Predicate-
Argument Structure Analysis and Annotation. Mas-
ter thesis. Dept. of computer science and technolo-
gy, Tsinghua University.
Mark Steedman. 1996. Surface Structure and Inter-
pretation. MIT Press, Cambridge, MA.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA.
Qiang Zhou. 2004. Chinese Treebank Annotation
Scheme. Journal of Chinese Information, 18(4), p1-
8.
Qiang Zhou, Yuemei Li. 2009. Evaluation report of
CIPS-ParsEval-2009. In Proc. of First Workshop
on Chinese Syntactic Parsing Evaluation, Beijing
China, Nov. 2009. pIII—XIII.
Qiang Zhou, Jingbo Zhu. 2010. Chinese Syntactic
Parsing Evaluation. Proc. of CIPS-SIGHAN Joint
Conference on Chinese Language Processing
(CLP-2010), Beijing, August 2010, pp 286-295.
Qiang Zhou. 2011. Automatically transform the TCT
data into a CCG bank: designation specification
Ver 3.0. Technical Report CSLT-20110512, Center
for speech and language technology, Research In-
stitute of Information Technology, Tsinghua Uni-
versity.
Qiang Zhou. 2012. Evaluation Report of the third
Chinese Parsing Evaluation: CIPS-SIGHAN-
ParsEval-2012. Proc. of CIPS-SIGHAN Joint Con-
ference on Chinese Language Processing (CLP-
2012), Tianjin.
</reference>
<page confidence="0.6656065">
151
152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.071680">
<pubnum confidence="0.6000305">Report of the fourth Chinese Parsing Evaluation: SIGHAN-ParsEval-2014</pubnum>
<email confidence="0.576635">Qiang</email>
<affiliation confidence="0.8251548">Center for Speech and Language Research Institute of Information Tsinghua National Laboratory for Information and Tsinghua University, Beijing 100084, China.</affiliation>
<email confidence="0.922736">zq-lxd@mail.tsinghua.edu.cn</email>
<abstract confidence="0.989840875">This paper gives the overview of the fourth Chinese parsing evaluation: CIPS-SIGHAN- ParsEval-2014, including its parsing, evaluation metrics, training and test data. The detailed evaluation results and simple discussions will be given to show the difficulties in Chinese syntactic parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>A Copestake</author>
<author>J R Curran</author>
<author>Y Zhang</author>
<author>A Herbelot</author>
<author>J Haggerty</author>
<author>B G Ahn</author>
<author>C V Wyk</author>
<author>J Roesner</author>
<author>J Kummerfeld</author>
<author>T Dawborn</author>
</authors>
<title>Large-scale syntactic processing: Parsing the web. Final Report of the</title>
<date>2009</date>
<journal>JHU CLSP Workshop</journal>
<marker>Clark, Copestake, Curran, Zhang, Herbelot, Haggerty, Ahn, Wyk, Roesner, Kummerfeld, Dawborn, 2009</marker>
<rawString>Clark, S., Copestake, A., Curran, J.R., Zhang, Y., Herbelot, A., Haggerty, J., Ahn, B.G., Wyk, C.V., Roesner, J., Kummerfeld, J., Dawborn, T.: 2009 Large-scale syntactic processing: Parsing the web. Final Report of the 2009 JHU CLSP Workshop</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>103--110</pages>
<location>Barcelona,</location>
<marker>Clark, Curran, 2004</marker>
<rawString>Clark, Stephen and James R. Curran. Parsing the WSJ using CCG and log-linear models. 2004. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 103–110, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hockenmaier</author>
<author>M Steedman</author>
</authors>
<title>CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>33</volume>
<issue>3</issue>
<pages>355--396</pages>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Hockenmaier, J., Steedman, M.: 2007. CCGbank: A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank. Computational Linguistics 33(3), 355--396</rawString>
</citation>
<citation valid="true">
<authors>
<author>Han Qiu</author>
</authors>
<title>Research on Chinese PredicateArgument Structure Analysis and Annotation. Master thesis. Dept. of computer science and technology,</title>
<date>2014</date>
<institution>Tsinghua University.</institution>
<contexts>
<context position="10838" citStr="Qiu, 2014" startWordPosition="1719" endWordPosition="1720">ve read) 的(de) 这本书(the book) 很 有 趣 (very interesting). (The book that I have read is very interesting.) It is a big challenge to identify whether the relative noun phrases are the real extracted arguments in TECs or not. Based on the above event construction classification, we proposed an EC-based IPA annotation scheme. For each DEC or TEC example extracted from Chinese real sentences, two or three independent annotators were asked to select the suitable corresponding BEC menu for them on an IPA annotation platform. Some detailed information about the IPA annotation procedure can be found in (Qiu, 2014). After manual IPA annotation, we can obtain the following ECs with IPA tags for the above two DEC and TEC examples: • [T-np-Arg2 这 本 书(the book) ] [S-npArg1 我 (I) ] [P-vp-Pred 读 过 (have read) ]1 • [S-np-Arg1 我(I) ] [P-vp-Pred 读过(have read) ] 的(de) [H-np-Arg2 这本书(the book) ] So, they show the same event contents with the following corresponding BEC annotation: 1 Each event chunk will be given the following tag combinations: &lt;Functional tag&gt;-&lt;Constituent tag&gt;-&lt;PA tag&gt;. Some tags used in these examples are listed as follows: Ttopic, S-subject, P-predicate, O-object, H-head; np-noun phrase, vp-ve</context>
<context position="12348" citStr="Qiu, 2014" startWordPosition="1965" endWordPosition="1966">s: 1) The same CCG tags should be assigned to the event target predicates (ETP) in the corresponding BEC, DEC and TEC examples. So in the above three ECs, the ETP “�(read)” should be assigned the same CCG tag: (S\NP)/NP. 2) The deep arguments with same IPA tags should be linked to the same argument positions in the corresponding ETP’s CCG tags. For example, the argument chunk with IPA tag “Arg1” should be linked to the first NP argument position in the corresponding ETP-ig�(read): (S\NP1)/NP2. Based on the above principles, we proposed a CCG derivation tree rebuilding algorithm. Please refer (Qiu, 2014) for more details about the algorithm. Here, we will give some figures to show the key idea of rebuilding procedure for the DEC and TEC examples. (2) Figure (2) shows the rebuilt CCG derivation tree for a topicalized DEC. Two CCG type raising (TR) rules are used for locating two deep arguments: • For deep subject: NP 4 S/(S\NP) • For deep object: NP 4 S/(S/NP) The CCG forward composition rule: S/(S\NP) (S\NP)/NP 4B S/NP, is used for the SSL of the deep subject. The special CCG forward application rule: S/(S\NP) S\NP 4 S, is used for the SSL of the topicalized deep object. Figure (3) shows the </context>
</contexts>
<marker>Qiu, 2014</marker>
<rawString>Han Qiu. 2014. Research on Chinese PredicateArgument Structure Analysis and Annotation. Master thesis. Dept. of computer science and technology, Tsinghua University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2889" citStr="Steedman 1996" startWordPosition="416" endWordPosition="417">ad, etc. Evaluation results showed that there were 20% drops for the syntactic constituents with complex internal relations in the labelled F1-score measure. The above evaluation results in the Chinese clause and sentence levels show that the complex sentence parsing is still a big challenge for the Chinese language. This time we will focus on the deeper parsing evaluation in the Predicate-Argument Structure (PAS) level to test whether the parser can deal with different syntactic alternatives with same event contents. We will introduce a new lexiconbased Combinatory Categorical Grammar (CCG) (Steedman 1996, 2000) annotation scheme in the evaluation, and propose a new implicit predicate argument (IPA) relation annotation method to build a large scale CCG bank with detailed PAS annotations. The special lexical dependency pairs automatically extracted from the CCG bank will be used as the final gold-standard data for evaluating parsers’ IPA recognition capacity. Same with previous ParsEval-2010 and ParsEval-2014, we also set two tracks in the ParsEval-2014. One is the Close track in which model parameter estimation is conducted solely on the train data. The other is the Open track in which 146 Pro</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Mark Steedman. 1996. Surface Structure and Interpretation. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
</authors>
<title>Chinese Treebank Annotation Scheme.</title>
<date>2004</date>
<journal>Journal of Chinese Information,</journal>
<volume>18</volume>
<issue>4</issue>
<pages>1--8</pages>
<contexts>
<context position="7808" citStr="Zhou, 2004" startWordPosition="1224" endWordPosition="1225"> other LDPs. We compute the weighted average of the F1- scores of the first four sets (Tot4_F1) to obtain the final ranked scores for different proposed parser systems. The computation formula is as follows: Tot5_F1=∑LDP_F1i * LDP_Ratioi,i ∈[1,4]. LDP_Ratioi is the distributional ratio for the ith LDP set in the test set. It computation formula is: LDP_Ratioi= (# of LDPs in ith set) / (# of all LDPs) * 100% For comparison analysis, we also compute the weighted average of F1-scores of all five sets for ranking reference. 3 Evaluation data We used the annotated sentences in the TCT version 1.0 (Zhou, 2004) as the basic resources and designed the following transformation and annotation procedures to obtain the final training and test data for the parsing evaluation task. Firstly, we automatically transformed all the TCT parse trees into CCG derivation trees by using the TCT2CCG tool (Zhou, 2011), and built a CCG bank version 1.0 for the TCT data. In the bank, most of clauses can be obtained correct CCG derivation trees due to the direct application of the syntax-semantics linking (SSL) principles among the basic syntactic constructions in Chinese sentences. The above CCG derivation tree (1) in s</context>
<context position="14140" citStr="Zhou, 2004" startWordPosition="2273" endWordPosition="2274">me deep PA relations. Therefore, the same lexical dependency pairs for describing the PA relations in the above three different BEC, DEC and TEC examples can be automatically extracted (Hockenmaier et al., 2007) from the corresponding rebuilt CCG derivation trees: • ig�(read), (S\NP)/NP, 1, R(I) • &apos;(read), (S\NP)/NP, 2, 书(book) They describe the same event contents consist in the above three EC examples. So we used these LDPs as the benchmark data for CCG parse tree evaluation. 4 Evaluation Results 4.1 Training and Test data All the news and academic articles annotated in the TCT version 1.0 (Zhou, 2004) are selected as the basic training data for the evaluation. It consists of about 480,000 Chinese words. 1000 sentences extracted from the TCT-2010 version are used as the basic test data. After the TCT2CCG transformation, EC-based IPA annotation and CCG derivation tree rebuilding, all the training and test data have been annotated with suitable CCG format tags and derivation trees. Table 1 Basic statistics of the training and test data: Average Sentence Length (ASL)= Word Sum/ Sent. Sum Sent. Word Char. ASL Sum Sum Sum Training 17558 473587 762866 26.97 Set Test Set 1000 24108 34079 24.11 149</context>
</contexts>
<marker>Zhou, 2004</marker>
<rawString>Qiang Zhou. 2004. Chinese Treebank Annotation Scheme. Journal of Chinese Information, 18(4), p1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
<author>Yuemei Li</author>
</authors>
<title>Evaluation report of CIPS-ParsEval-2009.</title>
<date>2009</date>
<booktitle>In Proc. of First Workshop on Chinese Syntactic Parsing Evaluation,</booktitle>
<pages>pIII—XIII.</pages>
<location>Beijing China,</location>
<contexts>
<context position="782" citStr="Zhou and Li, 2009" startWordPosition="103" endWordPosition="106">rmation Technology Tsinghua National Laboratory for Information Science and Technology Tsinghua University, Beijing 100084, China. zq-lxd@mail.tsinghua.edu.cn Abstract This paper gives the overview of the fourth Chinese parsing evaluation: CIPS-SIGHANParsEval-2014, including its parsing, evaluation metrics, training and test data. The detailed evaluation results and simple discussions will be given to show the difficulties in Chinese syntactic parsing. 1 Introduction For Chinese parsing evaluations, we have successfully held three times in 2009, 2010 and 2012. They are the CIPS-ParsEval-2009 (Zhou and Li, 2009), CIPS-SIGHAN-ParsEval-2010 (Zhou and Zhu, 2010) and CIPS-SIGHanParsEval-2012 (Zhou, 2012) respectively. Each evaluation has its different theme and goal. The first ParsEval-2009 focused on Chinese chunk parsing. Three kinds of chunking tasks were designed for the Chinese chunks with different descriptive complexities. The evaluation results showed that as the increasing of the word number and descriptive complexity of the chunks from base chunks (BC) to functional chunks (FC) and event descriptive chunks (EDC), the final F1-value will also decrease about 6 points from 92% to 86% and 80%. The </context>
</contexts>
<marker>Zhou, Li, 2009</marker>
<rawString>Qiang Zhou, Yuemei Li. 2009. Evaluation report of CIPS-ParsEval-2009. In Proc. of First Workshop on Chinese Syntactic Parsing Evaluation, Beijing China, Nov. 2009. pIII—XIII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
<author>Jingbo Zhu</author>
</authors>
<title>Chinese Syntactic Parsing Evaluation.</title>
<date>2010</date>
<booktitle>Proc. of CIPS-SIGHAN Joint Conference on Chinese Language Processing (CLP-2010),</booktitle>
<pages>286--295</pages>
<location>Beijing,</location>
<contexts>
<context position="830" citStr="Zhou and Zhu, 2010" startWordPosition="108" endWordPosition="111"> for Information Science and Technology Tsinghua University, Beijing 100084, China. zq-lxd@mail.tsinghua.edu.cn Abstract This paper gives the overview of the fourth Chinese parsing evaluation: CIPS-SIGHANParsEval-2014, including its parsing, evaluation metrics, training and test data. The detailed evaluation results and simple discussions will be given to show the difficulties in Chinese syntactic parsing. 1 Introduction For Chinese parsing evaluations, we have successfully held three times in 2009, 2010 and 2012. They are the CIPS-ParsEval-2009 (Zhou and Li, 2009), CIPS-SIGHAN-ParsEval-2010 (Zhou and Zhu, 2010) and CIPS-SIGHanParsEval-2012 (Zhou, 2012) respectively. Each evaluation has its different theme and goal. The first ParsEval-2009 focused on Chinese chunk parsing. Three kinds of chunking tasks were designed for the Chinese chunks with different descriptive complexities. The evaluation results showed that as the increasing of the word number and descriptive complexity of the chunks from base chunks (BC) to functional chunks (FC) and event descriptive chunks (EDC), the final F1-value will also decrease about 6 points from 92% to 86% and 80%. The second ParsEval-2010 and third ParsEval2012 focu</context>
</contexts>
<marker>Zhou, Zhu, 2010</marker>
<rawString>Qiang Zhou, Jingbo Zhu. 2010. Chinese Syntactic Parsing Evaluation. Proc. of CIPS-SIGHAN Joint Conference on Chinese Language Processing (CLP-2010), Beijing, August 2010, pp 286-295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
</authors>
<title>Automatically transform the TCT data into a CCG bank: designation specification Ver 3.0.</title>
<date>2011</date>
<tech>Technical Report CSLT-20110512,</tech>
<institution>Center</institution>
<contexts>
<context position="8102" citStr="Zhou, 2011" startWordPosition="1270" endWordPosition="1271"> ith LDP set in the test set. It computation formula is: LDP_Ratioi= (# of LDPs in ith set) / (# of all LDPs) * 100% For comparison analysis, we also compute the weighted average of F1-scores of all five sets for ranking reference. 3 Evaluation data We used the annotated sentences in the TCT version 1.0 (Zhou, 2004) as the basic resources and designed the following transformation and annotation procedures to obtain the final training and test data for the parsing evaluation task. Firstly, we automatically transformed all the TCT parse trees into CCG derivation trees by using the TCT2CCG tool (Zhou, 2011), and built a CCG bank version 1.0 for the TCT data. In the bank, most of clauses can be obtained correct CCG derivation trees due to the direct application of the syntax-semantics linking (SSL) principles among the basic syntactic constructions in Chinese sentences. The above CCG derivation tree (1) in section 2.1 is a good example. But there are still many syntactic constructions consist of implicit predicate-argument (IPA) relations, such as the topicalization and relative clause constructions. They can’t be automatically transformed into correct CCG derivation trees through the explicit SS</context>
</contexts>
<marker>Zhou, 2011</marker>
<rawString>Qiang Zhou. 2011. Automatically transform the TCT data into a CCG bank: designation specification Ver 3.0. Technical Report CSLT-20110512, Center for speech and language technology, Research Institute of Information Technology, Tsinghua University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiang Zhou</author>
</authors>
<title>Evaluation Report of the third Chinese Parsing Evaluation:</title>
<date>2012</date>
<booktitle>CIPS-SIGHANParsEval-2012. Proc. of CIPS-SIGHAN Joint Conference on Chinese Language Processing (CLP2012),</booktitle>
<location>Tianjin.</location>
<contexts>
<context position="872" citStr="Zhou, 2012" startWordPosition="115" endWordPosition="116">niversity, Beijing 100084, China. zq-lxd@mail.tsinghua.edu.cn Abstract This paper gives the overview of the fourth Chinese parsing evaluation: CIPS-SIGHANParsEval-2014, including its parsing, evaluation metrics, training and test data. The detailed evaluation results and simple discussions will be given to show the difficulties in Chinese syntactic parsing. 1 Introduction For Chinese parsing evaluations, we have successfully held three times in 2009, 2010 and 2012. They are the CIPS-ParsEval-2009 (Zhou and Li, 2009), CIPS-SIGHAN-ParsEval-2010 (Zhou and Zhu, 2010) and CIPS-SIGHanParsEval-2012 (Zhou, 2012) respectively. Each evaluation has its different theme and goal. The first ParsEval-2009 focused on Chinese chunk parsing. Three kinds of chunking tasks were designed for the Chinese chunks with different descriptive complexities. The evaluation results showed that as the increasing of the word number and descriptive complexity of the chunks from base chunks (BC) to functional chunks (FC) and event descriptive chunks (EDC), the final F1-value will also decrease about 6 points from 92% to 86% and 80%. The second ParsEval-2010 and third ParsEval2012 focused on Chinese syntactic parsing. They had</context>
</contexts>
<marker>Zhou, 2012</marker>
<rawString>Qiang Zhou. 2012. Evaluation Report of the third Chinese Parsing Evaluation: CIPS-SIGHANParsEval-2012. Proc. of CIPS-SIGHAN Joint Conference on Chinese Language Processing (CLP2012), Tianjin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>