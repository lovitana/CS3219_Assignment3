<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.044651">
<title confidence="0.929973">
Fast and Robust Arabic Error Correction System
</title>
<author confidence="0.877104">
Michael N. Nawar
</author>
<affiliation confidence="0.927368">
Computer Engineering Department
Cairo University
</affiliation>
<address confidence="0.842269">
Giza, Egypt
</address>
<email confidence="0.998799">
michael.nawar@eng.cu.edu.eg
</email>
<author confidence="0.935483">
Moheb M. Ragheb
</author>
<affiliation confidence="0.955522">
Computer Engineering Department
Cairo University
</affiliation>
<address confidence="0.843584">
Giza, Egypt
</address>
<email confidence="0.998825">
moheb.ragheb@eng.cu.edu.eg
</email>
<sectionHeader confidence="0.995849" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993906">
In this paper we describe the implementation
of an Arabic error correction system devel-
oped for the EMNLP2014 shared task on au-
tomatic error correction for Arabic text. We
proposed a novel algorithm, where we find
some correction rules and calculate their
probability based on the training data, they
we rank the correction rules, then we apply
them on the text to maximize the overall F-
score for the provided data. The system
achieves and F-score of 0.6573 on the test da-
ta.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998006">
Traditional techniques in text correction is the
generation of a large set of candidates for an in-
correct word using different approaches like
enumerating all possible candidates in edit dis-
tance of one. Then, all the candidates are ranked
such that the best candidates are ranked on the
top of the list. Finally, the best candidate is cho-
sen to replace incorrect word.
The traditional techniques are slow, since the
generation of a large set of candidates is time
consuming task. Also, it doesn’t take into con-
sideration the overall score of the system. While,
in this paper we apply a novel technique in au-
tomatic error correction, where we take into con-
sideration the correction rules, not the variants.
In the propose technique, we order corrections to
be applied on text to maximize the F-score.
This shared task was on automatic Arabic text
correction. For this task, the Qatar Arabic Lan-
guage Bank (QALB) corpus (Mohit et. al, 2014)
was provided. The QALB corpus contains a pre-
processed input text with some features extracted
and the corrected output. The main issue in the
shared task, that the tools used for the extraction
of the provided features wasn’t provided. So, we
had a choice, to create an algorithm that can deal
with missing features, or to generate our own set
of features. Finally, we have chosen to generate
our own set of features.
The proposed framework could be described
as a probabilistic rule-based framework. During
the training of this framework, we extracted
some rules and assign a probability to each rule
as shown later in section 3. The extracted rules
are then sorted based on their probabilities. And
during the test, we apply the rules from the high-
est probability to the lowest probability one by
one, on the entire test data till a stopping criteria
is satisfied. During the algorithm we have some
kind of heuristic to estimate the F-score after
each rule is apply. The stopping criteria for the
algorithm is that the estimated F-score start to
decrease.
This paper is organized as follow, in section 2,
an overview of the related work in the field of
error correction is discussed. In section 3, the
proposed system and its main components are
explained. The evaluation process is presented in
section 4. Finally, concluding remarks and future
work are presented in section 5.
</bodyText>
<sectionHeader confidence="0.999766" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999824769230769">
Most of the work done in the field automatic er-
ror correction for text, is made for English lan-
guage (Kukich, 1992; Golding and Roth, 1999;
Carlson and Fette, 2007; Banko and Brill, 2001).
Arabic spelling correction has also received con-
siderable interest, Ben Othmane Zribi and Ben
Ahmed, (2003) have proposed a new aiming to
reduce the number of proposals given by auto-
matic Arabic spelling correction tools, which
have reduced the proposals by about 75%. Had-
dad and Yaseen (2007) took into consideration
the complex nature of the Arabic language and
the effect of the root-pattern relationship to lo-
</bodyText>
<page confidence="0.983394">
143
</page>
<bodyText confidence="0.933636875">
Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
cate, reduce and rank the most probable correc-
tion candidates in Arabic derivative words to
improve the process of error detection and cor-
rection. Hassan et al. (2008) used a finite state
automata to propose candidates corrections, then
assign a score to each candidate and choose the
best correction in the context. Shaalan et al.
(2010) developed an error correction system to
Arabic learners. Alkanhal et al. (2012) have de-
veloped an error correction system and they em-
phasized on space insertion and deletion. Zag-
houani et al. (2014) provided a large scale da-
taset for the task of automatic error correction for
Arabic text.
</bodyText>
<sectionHeader confidence="0.98585" genericHeader="method">
3 The Proposed System
</sectionHeader>
<bodyText confidence="0.999921222222222">
The main system idea is explained by the al-
gorithm, in figure 1. The algorithm has two in-
puts: the set of sentences that need to be modi-
fied T[1..n], and the set of correction rules
C[1..m] that could be applied to text. The algo-
rithm has one single output: the set of modified
sentences T’[1..n]. The algorithm could be divid-
ed into two main component: the initialization
and the main loop.
</bodyText>
<equation confidence="0.878344666666667">
Input: T[1..n], C[1..m]
Output: T’[1..n]
1: T’ = T
</equation>
<listItem confidence="0.98896752">
2: Gold Edits = #Words in Test * # Gold Edits in
Train / # Words in Train
3: Correct Edits = 0
4: Performed Edits = 0
5: Precision = 0
6: Recall = 0
7: Old F-score = 0
8: F-score = 0
9: Do
10: T’ = T
11: Old F-score = F-score
12: Get next correction “c” with the highest
probability “p” from C
13: Apply the correction “c” on T
14: N = number of changes between T and
T’
15: Performed Edits = Performed Edits + N
16: Correct Edits = Correct Edits + p * N
17: Precision = Correct Edits / Performed
Edits
18: Recall = Correct Edits / Gold Edits
19: F-score = 2*Precision*Recall / (Preci-
sion+Recall)
20: while F-score &gt; Old F-score do
21: return T’
</listItem>
<figureCaption confidence="0.999833">
Figure 1: Proposed Algorithm
</figureCaption>
<bodyText confidence="0.999962658536586">
First, the initialization part of the algorithm
starts from line 1 to line 8. In the first line, the
sentences are copied from T[1..n] to T’[1..n]. In
line number 2, the number of errors in the test set
T[1..n] is expected using the rate of errors in the
train set (#error / #words). In lines 3 to 8, the
variables used in the algorithm are initialized to
zero.
The main loop of the algorithm starts from
line 9 to line 20. In line 9, the loop begins, and
the sentences are copied from T[1..n] to T’[1..n]
and the F-score is copied to old F-score, in lina-
rae 10 and 11. Then the first not applied correc-
tion with the highest probability to be correct is
correct is chosen in line 12. In line 13, the cor-
rection is applied on the text T[1..n]. Then we
calculate the number of changes between T[1..n]
and T’[1..n], in line 14. And based on the ex-
pected number of changes, we update the ex-
pected number of performed edits in line 14. Al-
so, we update the expected number of the correct
edits based on the number of change and the
probability of a change to be correct in line 15.
In lines 17 to 19, we calculate the expected pre-
cision, recall and F-score based on the expected
gold edits, performed edits, and correct edits cal-
culated at lines 2, 14, and 15. If the F-score is
higher than the old F-score, which means that
applying the correction c on the text T[1..n] will
increase the expected F-score, then go to line 9
and start a new iteration in the loop. And if the F-
score is lower than the old F-score, which means
that applying the correction c on the text T[1..n]
will decrease the expected F-score, then exit the
loop and return the modified text T’[1..n].
After we have discussed the main idea of algo-
rithm, in the following subsections we will dis-
cuss some of the extracted corrections rules and
the calculation of the probability of each rule.
These rules and their probabilities are compiled
by analyzing the training data.
</bodyText>
<subsectionHeader confidence="0.996484">
3.1 Morphological Analyzer Corrections
Rules
</subsectionHeader>
<bodyText confidence="0.895402636363636">
We used a morphological analyzer, BAMA-
v2.0 (Buckwalter Arabic morphological analyzer
version 2.0) (Buckwalter, 2010), in the extraction
of a correction rule. This rule will be used to
solve the errors caused by the exchange between
some characters like: (“I”, “A”), (“i”, “&gt;”), (“1”,
“&lt;”) and (“-”, “h”), (“;”, “p”) and (“4”, “y”),
(“LS”, “Y”).
RULE: We analyze a word with the morpho-
logical analyzer, if all the solutions of the word
have the same form that is different from the
</bodyText>
<page confidence="0.995088">
144
</page>
<bodyText confidence="0.999926954545455">
word, then change the word by the solutions
form.
For example, the word (“دمحا”, “AHmd”),
when the word is analyzed by the morphological
analyzer, there are 02 different solutions, 14 are
proper noun (“دمحأ”, “&gt;Hmd”, “Ahmed”) and the
remaining 6 of them are verb (“ دمحأ”, “&gt;Hmd”, “I
praise”). Since all the solution of the word
(“دمحا”, “AHmd”) have the form (“دمحأ”,
“&gt;Hmd”), then we will change (“دمحا”, “AHmd”)
to (“دمحأ”, “&gt;Hmd”). Another example, the word
(“ماما”, “AmAm”), when the word is analyzed by
the morphological analyzer, there are 04 differ-
ent solutions, 12 of them have the form (“مامأ”,
“&gt;mAm”), and the other 12 have the form (“مامإ”,
“&lt;mAm”), so we leave it unchanged.
To calculate the correctness probability of the
rule, we apply the following rule to all the train-
ing set, then we calculate the number of correct
edits, and the number of performed edits, finally
we calculate the probability as the ratio between
the correct and the performed edits.
</bodyText>
<subsectionHeader confidence="0.999179">
3.2 Colloquial to Arabic Corrections Rules
</subsectionHeader>
<bodyText confidence="0.999502210526316">
To convert the colloquial Arabic words to Ar-
abic words, we have compiled some rules as
shown below:
RULE: Replace a word or a phrase by a spe-
cific word or phrase from a list extracted from
the training set provided in Qalb shared task
(Mohit et. al, 2014).
From example replace the word (“انحا”, “AH-
nA”, “we”) by the word (“نحن”, “nHn”, “we”).
RULE: Replace a word or phrase with a spe-
cific word or phrase based on its context.
RULE: Replace a word or phrase with a spe-
cific pattern to another word or phrase.
From example replace the word (“بعليب”,
“bylEb”, “is playing”) by the word (“بعلي”,
“ylEb”, “is playing”).
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data.
</bodyText>
<subsectionHeader confidence="0.9392605">
3.3 The Single Character Spelling Errors
Correction
</subsectionHeader>
<bodyText confidence="0.997408535714286">
The single character spelling errors are divid-
ed into four main subcategories: replace charac-
ter by another character, insert character, delete
character, and transpose two adjacent characters.
For these four errors, we have conducted four
types of rules.
RULE 1: We analyze a word with the mor-
phological analyzer, if it is outside the corpus,
and it not defined in the correct words in qalb
corpus (the words that don’t change) try to
change one character by a specific character, if
the new word is recognized by the morphological
analyzer or it is inside the corpus, then change
the word and keep the new solution.
For example, if we have a word (“ظعب”,
“bEZ”) and a rule that change the character (‘ظ’,
‘Z’) to (‘ض’, ‘D’). And the word (“ضعب”,
“bED”) is recognized by the morphological ana-
lyzer, then we change the word (“ظعب”, “bEZ”) to
(“ضعب”, “bED”). Another example, if we have
the word (“ظعب”, “bEZ”) and a rule that change
the character (‘ع’, ‘E’) to (‘غ’, ‘g’). And the
word (“ظغب”, “bgZ”) is not recognized by the
morphological analyzer and it is outside the Qalb
corpus, then we don’t change the word.
RULE 2: We analyze a word with the mor-
phological analyzer, if it is outside the corpus,
and it not defined in the correct words in qalb
corpus (the words that don’t change) try to insert
one specific character between a pair of specific
characters, if the new word is recognized by the
morphological analyzer or it is inside the corpus,
then change the word and keep the new solution.
RULE 3: We analyze a word with the mor-
phological analyzer, if it is outside the corpus,
and it not defined in the correct words in qalb
corpus (the words that don’t change) try to delete
one specific character from a triplet of specific
characters, if the new word is recognized by the
morphological analyzer or it is inside the corpus,
then change the word and keep the new solution.
RULE 4: We analyze a word with the mor-
phological analyzer, if it is outside the corpus,
and it not defined in the correct words in Qalb
corpus (the words that don’t change) try to re-
place a pair of characters to the transpose of the
pair of characters, if the new word is recognized
by the morphological analyzer or it is inside the
corpus, then change the word and keep the new
solution.
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data, and it
differs from one character to another (i.e. the two
examples in rule 1, will have different correct-
ness probabilities based on the training data).
</bodyText>
<subsectionHeader confidence="0.993662">
3.4 The Space Insertion Errors Correction
</subsectionHeader>
<bodyText confidence="0.999387">
The space insertion error correction is the pro-
cess of splitting an incorrect word to multiple
correct word.
RULE: If there is a character concatenated af-
ter taa marbouta (‘ة’, ‘p’), insert a space between
them.
</bodyText>
<page confidence="0.997688">
145
</page>
<bodyText confidence="0.9998969375">
RULE: If the word starts with negation parti-
cle, split negation particle from it.
RULE: If the word starts with vocative parti-
cle, split vocative particle from it.
RULE: If the word starts with vocative parti-
cle, split vocative particle from it.
RULE: We analyze a word with the morpho-
logical analyzer, if it is outside the corpus, and it
not defined in the correct words in Qalb corpus
(the words that don’t change) try to find the long
substring from the word, that keep another sub-
string, where both of them are recognized by the
morphological analyzer.
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data.
</bodyText>
<subsectionHeader confidence="0.985745">
3.5 The Space Deletion Errors Correction
</subsectionHeader>
<bodyText confidence="0.999888181818182">
The space deletion errors correction is the pro-
cess of merging multiple tokens into one correct
word.
RULE: Merge conjunction particles, with
their succeeding token.
RULE: If two out of corpus tokens could be
merged to an inside the corpus word, then merge
them.
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data.
</bodyText>
<subsectionHeader confidence="0.996925">
3.6 Punctuation Errors Corrections
</subsectionHeader>
<bodyText confidence="0.9998484">
The punctuation errors are hard to correct be-
cause they depends on the meaning of the sen-
tence, and require almost full understanding of
the sentence. However, we have conducted some
rules for the punctuation, for example:
RULE: If the sentence doesn’t end with a
punctuation point from (“.”, “!”, “؟”), then add a
point at the end of the sentence.
RULE: Insert a punctuation mark before a
certain word.
For example, insert a semicolon before the
word (“هJلأ”, “l&gt;nH”, “because he”).
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data.
</bodyText>
<subsectionHeader confidence="0.994552">
3.7 Syntactic Errors Corrections
</subsectionHeader>
<bodyText confidence="0.99891625">
The syntactic errors is one of the most difficult
error to correct. For this task we apply a simple
kind of a grammatical analyzer to assign simple
grammatical tag to some words. One simple
grammatical system, is the one to determine gen-
itive noun. Nouns are genitive mainly if they oc-
cur after a preposition, or if they are possessives
(definite noun after indefinite noun) or if they are
adjectives of genitive nouns, or if they are con-
junction with genitive noun.
RULE: Plural and Dual genitive nouns that
end with (“W”, “wn”) or (“J”, “An”) should end
with (“��”, “yn”).
The correctness probability of each rule is the
ratio between the correct and the performed edits
when this rule is applied on the train data.
</bodyText>
<subsectionHeader confidence="0.985225">
3.8 Additional Corrections Rules
</subsectionHeader>
<bodyText confidence="0.997143833333333">
Finally, we generated some rules that present
the data on a correct format as the training data
and we will assign their correctness probability
manually to be equal to 1.
RULE: Remove kashida (tatweel) from text.
RULE: Replace “*” if between parenthesis by
the Arabic character (‘ذ’, ‘*’).
RULE: If a character is repeated consecutive-
ly more than twice inside a word, remove the
extra characters except if the word consists of
only one char like (“ههههه”, “hhhhh”).
RULE: Write a comma between two numbers.
</bodyText>
<sectionHeader confidence="0.951099" genericHeader="evaluation">
4 Evaluation of the System
</sectionHeader>
<bodyText confidence="0.999955363636364">
For the evaluation of the system, we used the
M2 scorer by Dahlmeier and Ng (2012). When
we evaluated the system with the development
dataset, we have reached an F-score of 0.6817;
and when the system is evaluated the test dataset,
we have reached and F-score of 0.6573.
The proposed algorithm is very fast compared
to traditional error correction algorithm. In tradi-
tional error correction algorithm, you generate all
possible variants of an incorrect word, then you
rank the solutions and choose the best solution.
But, in the proposed algorithm, you rank the
rules during the training time, and you apply one
rule at the time until you find an appropriate so-
lution of an incorrect word.
For example, let’s consider single character
replace spelling error, if the incorrect word
length is five characters, so you need to make
((28-1)*5) iterations to generate all possible vari-
ants of a word, while in the proposed algorithm
you generate one variant at the time, and you
might stop after that.
</bodyText>
<sectionHeader confidence="0.999265" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9979064">
In this paper we have presented a novel and
fast algorithm for the automatic text correction
for Arabic. The proposed algorithm has a good
F-score, and the system has the potential to be
further improved. As a future work, the punctua-
</bodyText>
<page confidence="0.996477">
146
</page>
<bodyText confidence="0.999922666666667">
tion error correction might need to be further im-
proved. And the expected number of gold edits,
could be improved or calculated on the sentence
level. And finally, the rules used in the frame-
work could be extended by further analysis of the
training data.
</bodyText>
<sectionHeader confidence="0.989928" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996164">
Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny,
Mansour M. Alghamdi, and Abdulaziz O. AlQab-
bany. 2012. Automatic Stochastic Arabic Spelling
Correction with Emphasis on Space Insertions and
Deletions. IEEE Transactions on Audio, Speech
&amp; Language Processing, 20:2111–2122.
Michele Banko and Eric Brill, 2001. Scaling to very
very large corpora for natural language disambigu-
ation. In Proceedings of 39th Annual Meeting
of the Association for Computational Linguis-
tics. Toulouse, France.
Chiraz Ben Othmane Zribi and Mohammed Ben Ah-
med. 2003. Efficient Automatic Correction of Mis-
spelled Arabic Words Based on Contextual Infor-
mation. In Proceedings of the Knowledge-
Based Intelligent Information and Engineering
Systems Conference, Oxford, UK.
Tim Buckwalter. 2010. Buckwalter Arabic Morpho-
logical Analyzer Version 2.0. Linguistic Data Con-
sortium, University of Pennsylvania, 2002. LDC
Catalog No.: LDC2004L02. ISBN 1-58563-324-0.
Andrew Carlson and Ian Fette. 2007. Memory-based
context-sensitive spelling correction at web scale.
In Proceedings of the IEEE International Con-
ference on Machine Learning and Applica-
tions (ICMLA).
Daniel Dahlmeier and Hwee Tou Ng. 2012. Better
evaluation for grammatical error correction. In
Proceeding of the 2012 Conference of the
North American Chapter of the Association
for Computational Linguistics: Human Lan-
guage Technologies.
Andrew R. Golding and Dan Roth. 1999. A Winnow
based approach to context-sensitive spelling cor-
rection. Machine Learning, 34(1-3):107–130.
Bassam Haddad and Mustafa Yaseen. 2007. Detection
and Correction of Non-Words in Arabic: A Hybrid
Approach. International Journal of Computer
Processing Of Languages (IJCPOL).
Ahmed Hassan, Sara Noeman, and Hany Hassan.
2008. Language Independent Text Correction using
Finite State Automata. In Proceedings of the In-
ternational Joint Conference on Natural Lan-
guage Processing (IJCNLP 2008).
Karen Kukich. 1992. Techniques for Automatically
Correcting Words in Text. ACM Computing Sur-
veys, 24(4).
Behrang Mohit, Alla Rozovskaya, Nizar Habash,
Wajdi Zaghouani, and Ossama Obeid, 2014. The
First shared Task on Automatic Text Correction for
Arabic. In Proceedings of EMNLP workshop
on Arabic Natural Language Processing. Do-
ha, Qatar.
Khaled Shaalan, Rana Aref, and Aly Fahmy. 2010.
An approach for analyzing and correcting spelling
errors for non-native Arabic learners. In Proceed-
ings of Informatics and Systems (INFOS).
Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Os-
sama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura
Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014.
Large Scale Arabic Error Annotation: Guidelines
and Framework. In Proceedings of the Ninth In-
ternational Conference on Language Re-
sources and Evaluation (LREC’14), Reykjavik,
Iceland.
</reference>
<page confidence="0.998005">
147
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.400839">
<title confidence="0.999991">Fast and Robust Arabic Error Correction System</title>
<author confidence="0.999425">N Michael</author>
<affiliation confidence="0.995791">Computer Engineering</affiliation>
<address confidence="0.855207">Cairo Giza, Egypt</address>
<email confidence="0.980246">michael.nawar@eng.cu.edu.eg</email>
<author confidence="0.901849">M Moheb</author>
<affiliation confidence="0.992751">Computer Engineering</affiliation>
<address confidence="0.8541565">Cairo Giza, Egypt</address>
<email confidence="0.990673">moheb.ragheb@eng.cu.edu.eg</email>
<abstract confidence="0.992211">In this paper we describe the implementation of an Arabic error correction system developed for the EMNLP2014 shared task on automatic error correction for Arabic text. We proposed a novel algorithm, where we find some correction rules and calculate their probability based on the training data, they we rank the correction rules, then we apply them on the text to maximize the overall Fscore for the provided data. The system achieves and F-score of 0.6573 on the test data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohamed I Alkanhal</author>
<author>Mohammed A Al-Badrashiny</author>
<author>Mansour M Alghamdi</author>
<author>Abdulaziz O AlQabbany</author>
</authors>
<title>Automatic Stochastic Arabic Spelling Correction with Emphasis on Space Insertions and Deletions.</title>
<date>2012</date>
<journal>IEEE Transactions on Audio, Speech &amp; Language Processing,</journal>
<pages>20--2111</pages>
<contexts>
<context position="4297" citStr="Alkanhal et al. (2012)" startWordPosition="702" endWordPosition="705">n relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics cate, reduce and rank the most probable correction candidates in Arabic derivative words to improve the process of error detection and correction. Hassan et al. (2008) used a finite state automata to propose candidates corrections, then assign a score to each candidate and choose the best correction in the context. Shaalan et al. (2010) developed an error correction system to Arabic learners. Alkanhal et al. (2012) have developed an error correction system and they emphasized on space insertion and deletion. Zaghouani et al. (2014) provided a large scale dataset for the task of automatic error correction for Arabic text. 3 The Proposed System The main system idea is explained by the algorithm, in figure 1. The algorithm has two inputs: the set of sentences that need to be modified T[1..n], and the set of correction rules C[1..m] that could be applied to text. The algorithm has one single output: the set of modified sentences T’[1..n]. The algorithm could be divided into two main component: the initializ</context>
</contexts>
<marker>Alkanhal, Al-Badrashiny, Alghamdi, AlQabbany, 2012</marker>
<rawString>Mohamed I. Alkanhal, Mohammed A. Al-Badrashiny, Mansour M. Alghamdi, and Abdulaziz O. AlQabbany. 2012. Automatic Stochastic Arabic Spelling Correction with Emphasis on Space Insertions and Deletions. IEEE Transactions on Audio, Speech &amp; Language Processing, 20:2111–2122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Eric Brill</author>
</authors>
<title>Scaling to very very large corpora for natural language disambiguation.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3280" citStr="Banko and Brill, 2001" startWordPosition="542" endWordPosition="545"> apply. The stopping criteria for the algorithm is that the estimated F-score start to decrease. This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed. In section 3, the proposed system and its main components are explained. The evaluation process is presented in section 4. Finally, concluding remarks and future work are presented in section 5. 2 Related Work Most of the work done in the field automatic error correction for text, is made for English language (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest, Ben Othmane Zribi and Ben Ahmed, (2003) have proposed a new aiming to reduce the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics c</context>
</contexts>
<marker>Banko, Brill, 2001</marker>
<rawString>Michele Banko and Eric Brill, 2001. Scaling to very very large corpora for natural language disambiguation. In Proceedings of 39th Annual Meeting of the Association for Computational Linguistics. Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chiraz Ben Othmane Zribi</author>
<author>Mohammed Ben Ahmed</author>
</authors>
<title>Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information.</title>
<date>2003</date>
<booktitle>In Proceedings of the KnowledgeBased Intelligent Information and Engineering Systems Conference,</booktitle>
<location>Oxford, UK.</location>
<marker>Zribi, Ahmed, 2003</marker>
<rawString>Chiraz Ben Othmane Zribi and Mohammed Ben Ahmed. 2003. Efficient Automatic Correction of Misspelled Arabic Words Based on Contextual Information. In Proceedings of the KnowledgeBased Intelligent Information and Engineering Systems Conference, Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium,</title>
<date>2010</date>
<booktitle>LDC Catalog No.: LDC2004L02. ISBN</booktitle>
<pages>1--58563</pages>
<institution>University of Pennsylvania,</institution>
<contexts>
<context position="7744" citStr="Buckwalter, 2010" startWordPosition="1346" endWordPosition="1347">lower than the old F-score, which means that applying the correction c on the text T[1..n] will decrease the expected F-score, then exit the loop and return the modified text T’[1..n]. After we have discussed the main idea of algorithm, in the following subsections we will discuss some of the extracted corrections rules and the calculation of the probability of each rule. These rules and their probabilities are compiled by analyzing the training data. 3.1 Morphological Analyzer Corrections Rules We used a morphological analyzer, BAMAv2.0 (Buckwalter Arabic morphological analyzer version 2.0) (Buckwalter, 2010), in the extraction of a correction rule. This rule will be used to solve the errors caused by the exchange between some characters like: (“I”, “A”), (“i”, “&gt;”), (“1”, “&lt;”) and (“-”, “h”), (“;”, “p”) and (“4”, “y”), (“LS”, “Y”). RULE: We analyze a word with the morphological analyzer, if all the solutions of the word have the same form that is different from the 144 word, then change the word by the solutions form. For example, the word (“دمحا”, “AHmd”), when the word is analyzed by the morphological analyzer, there are 02 different solutions, 14 are proper noun (“دمحأ”, “&gt;Hmd”, “Ahmed”) and t</context>
</contexts>
<marker>Buckwalter, 2010</marker>
<rawString>Tim Buckwalter. 2010. Buckwalter Arabic Morphological Analyzer Version 2.0. Linguistic Data Consortium, University of Pennsylvania, 2002. LDC Catalog No.: LDC2004L02. ISBN 1-58563-324-0.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Ian Fette</author>
</authors>
<title>Memory-based context-sensitive spelling correction at web scale.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference on Machine Learning and Applications (ICMLA).</booktitle>
<contexts>
<context position="3256" citStr="Carlson and Fette, 2007" startWordPosition="538" endWordPosition="541">-score after each rule is apply. The stopping criteria for the algorithm is that the estimated F-score start to decrease. This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed. In section 3, the proposed system and its main components are explained. The evaluation process is presented in section 4. Finally, concluding remarks and future work are presented in section 5. 2 Related Work Most of the work done in the field automatic error correction for text, is made for English language (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest, Ben Othmane Zribi and Ben Ahmed, (2003) have proposed a new aiming to reduce the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Com</context>
</contexts>
<marker>Carlson, Fette, 2007</marker>
<rawString>Andrew Carlson and Ian Fette. 2007. Memory-based context-sensitive spelling correction at web scale. In Proceedings of the IEEE International Conference on Machine Learning and Applications (ICMLA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Better evaluation for grammatical error correction.</title>
<date>2012</date>
<booktitle>In Proceeding of the 2012 Conference of the North American Chapter of the Association</booktitle>
<contexts>
<context position="15980" citStr="Dahlmeier and Ng (2012)" startWordPosition="2776" endWordPosition="2779">Rules Finally, we generated some rules that present the data on a correct format as the training data and we will assign their correctness probability manually to be equal to 1. RULE: Remove kashida (tatweel) from text. RULE: Replace “*” if between parenthesis by the Arabic character (‘ذ’, ‘*’). RULE: If a character is repeated consecutively more than twice inside a word, remove the extra characters except if the word consists of only one char like (“ههههه”, “hhhhh”). RULE: Write a comma between two numbers. 4 Evaluation of the System For the evaluation of the system, we used the M2 scorer by Dahlmeier and Ng (2012). When we evaluated the system with the development dataset, we have reached an F-score of 0.6817; and when the system is evaluated the test dataset, we have reached and F-score of 0.6573. The proposed algorithm is very fast compared to traditional error correction algorithm. In traditional error correction algorithm, you generate all possible variants of an incorrect word, then you rank the solutions and choose the best solution. But, in the proposed algorithm, you rank the rules during the training time, and you apply one rule at the time until you find an appropriate solution of an incorrec</context>
</contexts>
<marker>Dahlmeier, Ng, 2012</marker>
<rawString>Daniel Dahlmeier and Hwee Tou Ng. 2012. Better evaluation for grammatical error correction. In Proceeding of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew R Golding</author>
<author>Dan Roth</author>
</authors>
<title>A Winnow based approach to context-sensitive spelling correction.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<pages>34--1</pages>
<contexts>
<context position="3231" citStr="Golding and Roth, 1999" startWordPosition="534" endWordPosition="537">ristic to estimate the F-score after each rule is apply. The stopping criteria for the algorithm is that the estimated F-score start to decrease. This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed. In section 3, the proposed system and its main components are explained. The evaluation process is presented in section 4. Finally, concluding remarks and future work are presented in section 5. 2 Related Work Most of the work done in the field automatic error correction for text, is made for English language (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest, Ben Othmane Zribi and Ben Ahmed, (2003) have proposed a new aiming to reduce the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c</context>
</contexts>
<marker>Golding, Roth, 1999</marker>
<rawString>Andrew R. Golding and Dan Roth. 1999. A Winnow based approach to context-sensitive spelling correction. Machine Learning, 34(1-3):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bassam Haddad</author>
<author>Mustafa Yaseen</author>
</authors>
<title>Detection and Correction of Non-Words in Arabic: A Hybrid Approach.</title>
<date>2007</date>
<journal>International Journal of Computer Processing Of Languages (IJCPOL).</journal>
<contexts>
<context position="3575" citStr="Haddad and Yaseen (2007)" startWordPosition="589" endWordPosition="593">ned. The evaluation process is presented in section 4. Finally, concluding remarks and future work are presented in section 5. 2 Related Work Most of the work done in the field automatic error correction for text, is made for English language (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest, Ben Othmane Zribi and Ben Ahmed, (2003) have proposed a new aiming to reduce the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics cate, reduce and rank the most probable correction candidates in Arabic derivative words to improve the process of error detection and correction. Hassan et al. (2008) used a finite state automata to propose candidates corrections, then assign a score to each candidate and choose the best correc</context>
</contexts>
<marker>Haddad, Yaseen, 2007</marker>
<rawString>Bassam Haddad and Mustafa Yaseen. 2007. Detection and Correction of Non-Words in Arabic: A Hybrid Approach. International Journal of Computer Processing Of Languages (IJCPOL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmed Hassan</author>
<author>Sara Noeman</author>
<author>Hany Hassan</author>
</authors>
<title>Language Independent Text Correction using Finite State Automata.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<contexts>
<context position="4046" citStr="Hassan et al. (2008)" startWordPosition="662" endWordPosition="665"> the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics cate, reduce and rank the most probable correction candidates in Arabic derivative words to improve the process of error detection and correction. Hassan et al. (2008) used a finite state automata to propose candidates corrections, then assign a score to each candidate and choose the best correction in the context. Shaalan et al. (2010) developed an error correction system to Arabic learners. Alkanhal et al. (2012) have developed an error correction system and they emphasized on space insertion and deletion. Zaghouani et al. (2014) provided a large scale dataset for the task of automatic error correction for Arabic text. 3 The Proposed System The main system idea is explained by the algorithm, in figure 1. The algorithm has two inputs: the set of sentences </context>
</contexts>
<marker>Hassan, Noeman, Hassan, 2008</marker>
<rawString>Ahmed Hassan, Sara Noeman, and Hany Hassan. 2008. Language Independent Text Correction using Finite State Automata. In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karen Kukich</author>
</authors>
<title>Techniques for Automatically Correcting Words in Text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<issue>4</issue>
<contexts>
<context position="3207" citStr="Kukich, 1992" startWordPosition="532" endWordPosition="533">me kind of heuristic to estimate the F-score after each rule is apply. The stopping criteria for the algorithm is that the estimated F-score start to decrease. This paper is organized as follow, in section 2, an overview of the related work in the field of error correction is discussed. In section 3, the proposed system and its main components are explained. The evaluation process is presented in section 4. Finally, concluding remarks and future work are presented in section 5. 2 Related Work Most of the work done in the field automatic error correction for text, is made for English language (Kukich, 1992; Golding and Roth, 1999; Carlson and Fette, 2007; Banko and Brill, 2001). Arabic spelling correction has also received considerable interest, Ben Othmane Zribi and Ben Ahmed, (2003) have proposed a new aiming to reduce the number of proposals given by automatic Arabic spelling correction tools, which have reduced the proposals by about 75%. Haddad and Yaseen (2007) took into consideration the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October </context>
</contexts>
<marker>Kukich, 1992</marker>
<rawString>Karen Kukich. 1992. Techniques for Automatically Correcting Words in Text. ACM Computing Surveys, 24(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Mohit</author>
<author>Alla Rozovskaya</author>
<author>Nizar Habash</author>
<author>Wajdi Zaghouani</author>
<author>Ossama Obeid</author>
</authors>
<title>The First shared Task on Automatic Text Correction for Arabic.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP workshop on Arabic Natural Language Processing.</booktitle>
<location>Doha, Qatar.</location>
<marker>Mohit, Rozovskaya, Habash, Zaghouani, Obeid, 2014</marker>
<rawString>Behrang Mohit, Alla Rozovskaya, Nizar Habash, Wajdi Zaghouani, and Ossama Obeid, 2014. The First shared Task on Automatic Text Correction for Arabic. In Proceedings of EMNLP workshop on Arabic Natural Language Processing. Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khaled Shaalan</author>
<author>Rana Aref</author>
<author>Aly Fahmy</author>
</authors>
<title>An approach for analyzing and correcting spelling errors for non-native Arabic learners.</title>
<date>2010</date>
<booktitle>In Proceedings of Informatics and Systems (INFOS).</booktitle>
<contexts>
<context position="4217" citStr="Shaalan et al. (2010)" startWordPosition="690" endWordPosition="693">ion the complex nature of the Arabic language and the effect of the root-pattern relationship to lo143 Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 143–147, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics cate, reduce and rank the most probable correction candidates in Arabic derivative words to improve the process of error detection and correction. Hassan et al. (2008) used a finite state automata to propose candidates corrections, then assign a score to each candidate and choose the best correction in the context. Shaalan et al. (2010) developed an error correction system to Arabic learners. Alkanhal et al. (2012) have developed an error correction system and they emphasized on space insertion and deletion. Zaghouani et al. (2014) provided a large scale dataset for the task of automatic error correction for Arabic text. 3 The Proposed System The main system idea is explained by the algorithm, in figure 1. The algorithm has two inputs: the set of sentences that need to be modified T[1..n], and the set of correction rules C[1..m] that could be applied to text. The algorithm has one single output: the set of modified sentences</context>
</contexts>
<marker>Shaalan, Aref, Fahmy, 2010</marker>
<rawString>Khaled Shaalan, Rana Aref, and Aly Fahmy. 2010. An approach for analyzing and correcting spelling errors for non-native Arabic learners. In Proceedings of Informatics and Systems (INFOS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wajdi Zaghouani</author>
</authors>
<title>Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14),</booktitle>
<location>Reykjavik, Iceland.</location>
<marker>Zaghouani, 2014</marker>
<rawString>Wajdi Zaghouani, Behrang Mohit, Nizar Habash, Ossama Obeid, Nadi Tomeh, Alla Rozovskaya, Noura Farra, Sarah Alkuhlani, and Kemal Oflazer. 2014. Large Scale Arabic Error Annotation: Guidelines and Framework. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>