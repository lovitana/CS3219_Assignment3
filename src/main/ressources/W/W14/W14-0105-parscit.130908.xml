<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000271">
<title confidence="0.960156">
WoNeF, an improved, expanded and evaluated
automatic French translation of WordNet
</title>
<author confidence="0.549738">
Quentin Pradet, Gaël de Chalendar and Jeanne Baguenier Desormeaux
</author>
<note confidence="0.834486">
CEA, LIST, Laboratoire Vision et Ingénierie des Contenus
Gif-sur-Yvette, F-91191, France
</note>
<email confidence="0.996923">
quentin.pradet|gael.de-chalendar@cea.fr
</email>
<sectionHeader confidence="0.993869" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995845833333334">
Automatic translations of WordNet have
been tried to many different target lan-
guages. JAWS is such a translation for
French nouns using bilingual dictionaries
and a syntactic language model. We im-
prove its precision and coverage, complete
it with translations of other parts of speech
and enhance its evaluation method. The
result is named WoNeF. We produce three
final translations balanced between pre-
cision (up to 93%) and coverage (up to
109 447 (literal, synset) pairs).
</bodyText>
<sectionHeader confidence="0.998705" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982186440678">
Reproducing the lexicographic work of WordNet
(Fellbaum, 1998) for other languages is costly and
difficult to maintain. Even with some theoretical
problems, (Fellbaum and Vossen, 2007; de Melo
and Weikum, 2008) show that translating Prince-
ton WordNet literals while keeping its structure
and its synsets leads to useful linguistic resources.
WordNet automatic translations use the expand
approach: its structure is preserved and only lit-
erals are translated. Three main techniques rep-
resent this approach in the literature. The sim-
plest one seeds WordNet using bilingual dictionar-
ies (Rigau and Agirre, 1995), which can be filtered
manually by lexicographers (Vossen, 1998; Tufi¸s
et al., 2004). A second translation method uses
parallel corpora, which avoids the use of dictionar-
ies that may cause lexical bias. Back-translations
between Norwegian and English were first ex-
plored (Dyvik, 2002), while (Sagot and Fišer,
2008) combine a multilingual lexicon and the dif-
ferent BalkaNet wordnets to help disambiguation.
Finally, the bilingual dictionaries extracted from
the Wiktionary and the Wikipedia interlanguage
links allow to create new wordnets (de Melo and
Weikum, 2009; Navigli and Ponzetto, 2010) or im-
prove existing ones (Hanoka and Sagot, 2012).
Three French WordNets exist. The French Eu-
roWordNet (Vossen, 1998) has a limited coverage
and requires significant improvements to be used
(Jacquin et al., 2007). It is also neither free nor
freely accessible, which prevented the community
from using and improving it. WOLF is a second
French translation originally built using parallel
corpora (Sagot and Fišer, 2008) and since then ex-
panded using various techniques (Apidianaki and
Sagot, 2012). WOLF is distributed under a free
LGPL-compatible license. Finally, JAWS (Mou-
ton and de Chalendar, 2010) is a translation of
WordNet nouns developed using bilingual dictio-
naries and a syntactic language model.
Our work expands and improves the techniques
used in JAWS and evaluates it based on the adjudi-
cation of two annotators work. The result is called
WoNeF1 and is distributed under the LGPL-LR li-
cence. To our knowledge, all current WordNet ma-
chine translations only exist in one version where
the authors decide what metric to optimize. We
provide such a version, but add two resources that
can serve different needs and have been obtained
using different means. The main WoNeF has an F-
score of 70.9%. Another version has a precision of
93.3%, and the last one contains 109 447 (literal,
synset) pairs. The main contributions of this pa-
per are the improvement and completion of JAWS
with all parts of speech (section 3) and its eval-
uation (sections 4 and 5). The evaluation is done
through an adjudication itself validated by measur-
ing the inter-annotator agreement, which validates
the expand approach to translate WordNet.
</bodyText>
<sectionHeader confidence="0.999707" genericHeader="introduction">
2 JAWS
</sectionHeader>
<subsectionHeader confidence="0.982278">
2.1 Translation process
</subsectionHeader>
<bodyText confidence="0.9948995">
JAWS was built with a weakly supervised algo-
rithm that does not require any manually anno-
</bodyText>
<footnote confidence="0.992334">
1This work was partially funded by the ANR ASFALDA
ANR-12-CORD-0023 project.
</footnote>
<bodyText confidence="0.999595108695652">
tated data, only the links between the French and
English Wiktionaries and a target syntactic lan-
guage model. The language model was trained
on a large corpus extracted from the Web (Grefen-
stette, 2007). The corpus was analyzed by LIMA
(Besançon et al., 2010), a rule-based parser pro-
ducing fine-grained syntactic dependencies. For
a given relation r and a word x, the language
model indicates what are the first 100 words co-
occurring most frequently with x through the re-
lation r. Thanks to the dictionary, JAWS does not
need to select each synset literals from the entire
vocabulary but only among a small number of can-
didates (9 on average). The translation process
is done in three steps. First, an empty wordnet
is created, preserving WordNet structure, but with
no literal associated to synsets. Then, the easiest
translations among dictionaries candidates are se-
lected to start filling JAWS. Finally, JAWS is ex-
tended incrementally using the language model,
relations between synsets and the existing JAWS.
Initial selectors Four algorithms called initial
selectors choose correct translations among those
proposed by the dictionary. First, words appear-
ing in only one synset are not ambiguous: all their
translations are added to the French wordnet. This
is the monosemy selector. For example, all trans-
lations of grumpy are selected in the only synset
where it appears. Second, the uniqueness selector
identifies words with only one translation and se-
lects this translation in all synsets where the words
appear. The five synsets containing pill in English
are thus completed with pilule. These two first
selectors were previously used in (Atserias et al.,
1997) and (Benítez et al., 1998). A third selector
translates words that are not in the dictionary us-
ing the English word itself: the direct translation
selector. A fourth selector uses the Levenshtein
edit distance: despite some false friends, if the dis-
tance between an English word and its translation
is short, it can be considered that they have the
same sense. Two examples are portion and uni-
versity).
JAWS expansion JAWS being partially filled, a
new expansion phase leverages the relationships
between WordNet synsets to propose new transla-
tions. For example, if a synset S1 is a meronym
of a synset S2 in WordNet and there is a context
where a selected literal in S1 is a meronym of a
candidate literal C in S2, then the literal C is con-
sidered correct. The translation task is thus re-
duced to the task of comparing on the one hand the
lexical relations between WordNet synsets and on
the other hand the lexical relations between French
lexemes.
Let’s take as an example the literal quill which
can be translated to piquant or plume (Figure 1).
In WordNet, quill is a meronym of porcupine
which has already been translated by porcupine
by an initial selector. In the language model, pi-
quant is a noun modifier of porcupine but this is
not the case of plume. Here, the noun-complement
relation implies meronymy. It is thus piquant that
must be chosen as the correct translation of quill.
The language model allowed to choose between
the two possible translations.
A potential problem with this approach could be
that the noun modifier relationship is not limited to
meronymy. For example, mémoire in the language
model comes from a book entitled Mémoires d’un
porc-épic (“Memoirs of a porcupine”). Fortu-
nately, mémoire is not in the quill translation can-
didates and thus cannot be chosen. Paradoxically,
the language model cannot choose between two
very different words, but is able to choose the cor-
rect translation of a polysemous word. While auto-
matically translating WordNet only with a dictio-
nary or a syntactic language model is impossible,
combining the two resources can solve the prob-
lem.
Each such syntactic selector follows the same
principle as the meronymy selector and translates
new synsets by identifying relationships between
lexemes through the syntactic language model.
The match between the noun modifier relation and
the meronymy relation is direct, but this is not the
case for all relations: there is for example no syn-
tactic relationship that directly expresses the syn-
onymy between two literals. For these relations,
JAWS uses second order syntactic relations (Lenci
and Benotto, 2012). See (Mouton and de Chalen-
dar, 2010) for more details and other selectors.
</bodyText>
<subsectionHeader confidence="0.983383">
2.2 JAWS limits
</subsectionHeader>
<bodyText confidence="0.9785945">
JAWS suffers from two main limitations. Above
all, it only contains nouns, which prevents its use
in many applications. Also, its evaluation proce-
dure makes it difficult to judge its quality. Indeed,
JAWS was evaluated by comparing it to the French
EuroWordNet and WOLF 0.1.4 (released in 2008).
These two French wordnets are not gold standards:
Synset S1
</bodyText>
<listItem confidence="0.659438">
- English : quill
- French : piquant? plume?
</listItem>
<bodyText confidence="0.926948">
(a stiff hollow protective spine)
</bodyText>
<equation confidence="0.809062333333333">
mémoire, piquant, poil,
épine, yéti, ragoût, grotte, ...
Synset S2
</equation>
<listItem confidence="0.70249175">
- English : porcupine, hedgehog
- French : porc-épic
(relatively large rodents with
sharp erectile bristles)
</listItem>
<figure confidence="0.9412784">
porc-épic
meronym of
(WordNet relation)
noun modifier of
(language model)
</figure>
<figureCaption confidence="0.999986">
Figure 1: Translation through the part-of meronym relation.
</figureCaption>
<bodyText confidence="0.95948585">
they suffer from either limited coverage or limited
accuracy. The authors decided to supplement this
limited evaluation by a manual evaluation of lit-
erals that do not exist in WOLF, but it has been
done on 120 (literal, synset) pairs only by a single
annotator. The accuracy of JAWS is evaluated to
67.1%, which is lower than WOLF 0.1.4 and sig-
nificantly lower than the accuracy of WOLF 1.0b.
Furthermore this score should be taken with cau-
tion because of the size of the test sample: the con-
fidence interval is approximately 25%.
3 WoNeF: JAWS improved and extended
to other parts of speech
This section presents three key enhancements that
have been made to JAWS and its extension to
cover verbs, adjectives and adverbs. A change that
is not detailed here is the one that led to a dramat-
ically higher execution speed: JAWS built in sev-
eral hours versus less than a minute for WoNeF,
which helped to run many more experiments.
</bodyText>
<subsectionHeader confidence="0.998488">
3.1 Initial selectors
</subsectionHeader>
<bodyText confidence="0.9999764">
JAWS initial selectors are not optimal. While we
keep the monosemy and uniqueness selectors, we
changed the other ones. The direct translation se-
lector is deleted as its precision was very low, even
for nouns. A new selector considers candidate
translations coming from several different English
words in a given synset: the multiple sources se-
lector, a variant the variant criterion of (Atserias et
al., 1997). For example, in the synset line, railway
line, rail line, the French literals ligne de chemin
de fer and voie are translations of both line and
railway line and are therefore chosen as transla-
tions.
Finally, the Levenshtein distance selector has
been improved. 28% of English vocabulary is
of French origin (Finkenstaedt and Wolff, 1973)
and anglicization produced predictable changes.
It is possible to apply the same changes to the
French candidate literal before computing the Lev-
enshtein distance, bringing related words closer.
We remove diacritics before applying several op-
erations to word tails (Table 1). For example, re-
versing the &amp;quot;r&amp;quot; and &amp;quot;e&amp;quot; letter takes into account
(ordre/order) and (tigre/tiger). 2 As before, false
friends are not taken into account.
</bodyText>
<subsectionHeader confidence="0.99993">
3.2 Learning thresholds
</subsectionHeader>
<bodyText confidence="0.940577375">
In JAWS, each English literal can only correspond
to the highest scoring French translation, regard-
less of the scores of lower-rated translations. This
rejects valid candidates and accepts wrong ones.
For example, JAWS does not include particulier
in the human being synset because personne is al-
ready included with a higher score.
In WoNeF, we learned a threshold for each part
of speech and selector. We first generated scores
for all (literal, synset) candidate pairs, then sorted
these pairs by score. The 12 399 pairs present in
the WOLF 1.0b manual evaluation (our training
set) were considered to be correct, while the pairs
2The Damerau-Levenshtein distance which takes into ac-
count transpositions anywhere in a word (Damerau, 1964) led
to poorer results.
-que -k banque bank
-aire -ary tertiaire tertiary
eur er chercheur researcher
ie y cajolerie cajolery
-té -ty extremité extremity
-re -er tigre tiger
ais ese libanais lebanese
-ant -ing changeant changing
</bodyText>
<tableCaption confidence="0.9134955">
Table 1: Changes to French word tails before
applying the Levenshtein distance.
</tableCaption>
<bodyText confidence="0.9948311">
outside this set were not. We then calculated the
thresholds maximizing precision and F-score.
Once these thresholds are defined, the selec-
tors choose all candidates above the new thresh-
old. This has two positive effects: valid candidates
are not rejected when only the best candidate is
already selected (improving both recall and cov-
erage) and invalid candidates which were previ-
ously accepted are now rejected thanks to a stricter
threshold (increasing precision).
</bodyText>
<subsectionHeader confidence="0.997434">
3.3 Vote
</subsectionHeader>
<bodyText confidence="0.981275852459016">
After applying all selectors, our WordNet is large
but contains some noisy synsets. In WoNeF, noise
comes from several factors: selectors try to in-
fer semantic information from a syntactic analy-
sis without taking into account the full complex-
ity of the syntax-semantics interface; the parser
itself produces some noisy results; the syntactic
language model is generated from a noisy corpus
extracted from the Web (poorly written text, non-
text content, non French sentences); and selected
translations in one step are considered valid in the
following steps while this is not always the case.
For the high-precision resource, we only keep
literals for which the selectors were more confi-
dent. Since multiple selectors can now choose a
given translation (section 3.2), our solution is sim-
ple and effective: translations proposed by multi-
ple selectors are kept while the others are deleted.
This voting principle is inspired from ensemble
learning in machine learning. It is also similar to
the combination method used in (Atserias et al.,
1997) but we can avoid their manual inspection of
samples of each method thanks to the development
of our gold standard.
This cleaning operation retains only 18% of
translations (from 87 757 (literal, synset) pairs to
15 625) but the accuracy increases from 68.4% to
93.3%. This high precision resource can be used
as training data for other French WordNets. A
typical voting methods problem is to choose only
easier and poorly interesting examples, but the
resource obtained here is well balanced between
synsets containing only monosemic words and
other synsets containing polysemous and more
difficult to disambiguate words (section 5.2).
3.4 Extension to verbs, adjectives and
adverbs
The work on JAWS began with nouns because they
represent 70% of the synsets in WordNet. We
continued this work on all other parts of speech:
verbs, adjectives and adverbs. Here, generic selec-
tors have been modified, but in the future, we will
develop selectors taking into account the different
parts of speech characteristics in WordNet.
Verbs Selectors chosen for verbs are the unique-
ness and monosemy selectors. Indeed, the Leven-
shtein distance gave poor results for verbs: only
25% of the verbs chosen by this selector were cor-
rect translations. For syntactic selectors, only the
selector by synonymy gave good results, while the
selector by hyponymy had the performance of a
random classifier.
Adjectives For adjectives, all initial selectors
are chosen, and the selected syntactic selector is
the selector by synonymy.
Adverbs The configuration is the same than for
adjectives. We have no gold standard for adverbs,
which explains why they are not included in our
evaluation. However, comparison with WOLF
(section 5.4) shows that adverbs are better than
other parts of speech.
</bodyText>
<sectionHeader confidence="0.970134" genericHeader="method">
4 WoNeF: an evaluated JAWS
</sectionHeader>
<subsectionHeader confidence="0.919502">
4.1 Gold standard development
</subsectionHeader>
<bodyText confidence="0.999901281690141">
Evaluation of JAWS suffers from a number of lim-
itations (section 2.2). We produced a gold stan-
dard for rigorous evaluation to evaluate WoNeF.
For nouns, verbs and adjectives, 300 synsets have
been annotated by two authors of this paper, both
computational linguists, both native French speak-
ers and respectively with a background in com-
puter science and linguistics. For each candi-
date provided by our translation dictionaries, they
had to decide whether or not it belonged to the
synset. They used WordNet synsets to examine
their neighbors, the Merriam-Webster dictionary,
the French electronic dictionary TLFi and search
engines to demonstrate the use of different senses
of the words in question. Because dictionaries do
not provide candidates for all synsets and some
synsets have no suitable candidate, the actual num-
ber of non-empty synsets is less than 300 (section
4.2).
During manual annotation, we encountered dif-
ficulties arising from the attempt to translate the
Princeton WordNet to French. Most problems
come from verbs and adjectives appearing in a col-
location. In WordNet, they can be grouped in a
way that makes sense in English, but that is not
reflected directly in another language. For exam-
ple, the adjective pointed is the only element of
a synset defined as Direct and obvious in mean-
ing or reference; often unpleasant, “a pointed cri-
tique”, “a pointed allusion to what was going
on”, “another pointed look in their direction”.
These three examples would result in three differ-
ent translations in French: une critique dure, une
allusion claire and un regard appuyé. There is no
satisfactory solution in translating such a synset:
the resulting synset contains either too many or too
few translations. We view this issue as a mainly
linguistic one in the way WordNet has grouped
those three usages of pointed. We marked the con-
cerned synsets and will handle them in a future
work, either manually or with other approaches.
These granularity problems concern 3% of nomi-
nal synsets, 8% of verbal synsets and 6% of adjec-
tival synsets.
The other main difficulty stems from transla-
tions in our bilingual dictionaries. Rare meanings
of a word are sometimes missing. For example,
there is a WordNet synset containing the egg verb
for its coat with beaten egg sense. Our dictionar-
ies only consider egg as a noun: neither our gold
standard nor JAWS can translate this synset. This
case appeared rarely in practice, and none of these
senses are in the most polysemous synsets (BCS
synsets as defined in section 5.2), confirming that
it doesn’t affect the quality of our gold standard for
the most important synsets. Yet WoNeF could be
improved by using specific dictionaries for species
(as in (Sagot and Fišer, 2008) with WikiSpecies),
medical terms, etc. Unwanted translations are an-
other issue. Our dictionaries translate unkindly to
sans aménité (without amenity) which is a com-
positional phrase. While such a translation is ex-
pected in a bilingual dictionary, it should not be
integrated in a lexical resource. The last diffi-
culty lied in judgment adjectives: for example,
there is no good translation of weird in French.
Although most dictionaries provide bizarre as a
translation, this one does not provide the stupid
aspect of weird. There is no translation that would
fit in all contexts: the synset meaning is not fully
preserved after translation.
</bodyText>
<subsectionHeader confidence="0.808889">
4.2 Inter-annotators agreement
</subsectionHeader>
<bodyText confidence="0.920225">
Table 2 shows the inter-annotator agreement mea-
sured through Fleiss kappa for the three annotated
</bodyText>
<table confidence="0.9993925">
Nouns Verbs Adj.
Fleiss Kappa 0.715 0.711 0.663
Synsets 270 222 267
Candidates 6.22 14.50 7.27
</table>
<tableCaption confidence="0.999462">
Table 2: Gold standard inter-annotator agreement
</tableCaption>
<bodyText confidence="0.999305333333333">
parts of speech. Even if it is a discussed met-
ric (Powers, 2012), all existing evaluation tables
consider these scores as high enough to describe
the inter-annotator agreement as &amp;quot;good&amp;quot; (Gwet,
2001), which allows us to say that our gold stan-
dard is good. The expand approach for the transla-
tion of WordNets is also validated: it is possible to
produce useful resource in spite of the difficulties
mentioned in section 4.1.
</bodyText>
<sectionHeader confidence="0.999949" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999918230769231">
We present in this section the results of WoNeF.
We first describe the initial selectors and proceed
with the full resource. Our gold standard is di-
vided into two parts: 10% of the literals form the
validation set used to choose the selectors that ap-
ply to different versions of WoNeF, while the re-
maining 90% form the evaluation set. No train-
ing was performed on our gold standard. Precision
and recall are based on the intersection of synsets
present in WoNeF and our gold standard. Preci-
sion is the fraction of correct (literal, synset) pairs
in the intersection while recall is the fraction of
correctly retrieved pairs.
</bodyText>
<subsectionHeader confidence="0.983534">
5.1 Initial selectors
</subsectionHeader>
<bodyText confidence="0.999994307692308">
For nouns, verbs and adjectives, we calculated the
efficiency of each initial selector on our develop-
ment set, and used this data to determine which
ones should be included in the high precision ver-
sion, the high F-score version and the large cover-
age one. Scores are reported on the test set.
Table 3 shows the results of this operation. Cov-
erage gives an idea of the size of the resource. De-
pending on the objectives of each resource, the se-
lected initial selectors are different. Since differ-
ent selectors can choose the same translation, the
sum of coverages is greater than the coverage of
the high coverage resource.
</bodyText>
<subsectionHeader confidence="0.996695">
5.2 Global results
</subsectionHeader>
<bodyText confidence="0.999372333333333">
We now focus on the overall results which include
the application of initial selectors and syntactic se-
lectors (Table 4). The high-precision method also
</bodyText>
<table confidence="0.9990235">
P R F1 C
monosemy 71.5 76.6 74.0 54 499
unicity 91.7 63.0 75.3 9 533
mult. sources 64.5 45.0 53.0 27 316
Levenshtein 61.9 29.0 39.3 20 034
high precision 93.8 50.1 65.3 13 867
high F-score 71.1 72.7 71.9 82 730
high coverage 69.0 69.8 69.4 90 248
</table>
<tableCaption confidence="0.999102">
Table 3: Top part: Precision, Recall and
</tableCaption>
<bodyText confidence="0.93295525">
F1-measure of initial selectors on all translations
(nouns, verbs and adjectives). Bottom part: scores
for various combinations of them. Coverage C is
the total number of pairs (literal, synset).
applies a vote (section 3.3). As in the previous
table, the coverage C is the number of (literal,
synset) pairs. Without using structure-based nor
conceptual distance-based selectors as in (Farreres
et al., 2010), we obtain a coverage at 93% preci-
sion for our French wordnet (15 625) equal to their
Spanish one (11 770) and larger than their Thai
one (2 013).
</bodyText>
<table confidence="0.999451625">
P R F1 C
93.3 51.5 66.4 15 625
68.9 73.0 70.9 88 736
60.5 74.3 66.7 109 447
P R F1 C
90.4 36.5 52.0 1 877
56.5 62.8 59.1 14 405
44.5 66.9 53.5 23 166
</table>
<tableCaption confidence="0.976243">
Table 4: Global results for all synsets and BCS
synsets only.
</tableCaption>
<bodyText confidence="0.999779133333333">
In WordNet, most words are monosemous, but a
small minority of polysemous words are the most
represented in texts. It is precisely on this minority
that we wish to create a quality resource. To evalu-
ate this, we use the list of BCS (Basic Concept Set)
synsets provided by the BalkaNet project (Tufi¸s et
al., 2004). This list contains 8 516 synsets lex-
icalized in six different translations of WordNet.
They should represent the most frequent synsets
and those with the most polysemous words. While
the high F-score and the high coverage resources
lose precision for BCS synsets, this is not the case
for the high precision resource. In fact, the vot-
ing mechanism makes the high-precision resource
very robust, even for the BCS synsets.
</bodyText>
<subsectionHeader confidence="0.990151">
5.3 Results by part of speech
</subsectionHeader>
<bodyText confidence="0.999616272727273">
Table 5 shows the detailed results for each part
of speech. Concerning nouns, the high precision
mode uses two selectors, both based on the noun
modifier syntactic relation: the meronymy selector
described in section 2.1 and the hyponymy selec-
tor. The high precision resource for nouns is our
best resource. The high F-score version has an F-
score of 72.4%, which ensures that present (literal,
synset) pairs have good quality and that it does not
miss too many translations. The nominal version
is better than JAWS by 2.8% points of F-score.
</bodyText>
<table confidence="0.999392181818182">
P R F1 C
nouns 96.8 56.6 71.4 11 294
PR verbs 68.4 41.9 52.0 1 110
adj. 90.0 36.7 52.2 3 221
nouns 71.7 73.2 72.4 59 213
F1R JAWS 70.7 68.5 69.6 55 416
verbs 48.9 76.6 59.6 9 138
adj. 69.8 71.0 70.4 20 385
nouns 61.8 78.4 69.1 70 218
CR verbs 45.4 61.5 52.2 18 844
adj. 69.8 71.9 70.8 20 385
</table>
<tableCaption confidence="0.985358">
Table 5: Results by part of speech. Horizontal
</tableCaption>
<bodyText confidence="0.904859697674419">
parts give scores for the high-precision resource
(PR), the high-F1-measure one (F1R) and the
high coverage one (CR). JAWS containing only
nouns, it is compared with the high F-score
nominal WoNeF resource.
Results for verbs are lower. The main reason
is that verbs are on average more polysemous in
WordNet and our dictionaries than other parts of
speech: verbal synsets have twice as many can-
didates as nouns and adjectives synsets (Table 2).
This shows the importance of the dictionary to
limit the number of literals from which algorithms
must choose. The synonymy selector is the only
syntactic selector applied to verbs: it uses second-
order syntactic relations for three types of ver-
bal syntactic dependencies: if two verbs share the
same objects, they are likely to be synonyms or
near-synonyms. This is the case for dévorer and
manger which both accept the object pain. Other
syntactic selectors have not been used for verbs
because of their poor results. Indeed, while the
detection of hyponymy using only the inclusion of
contexts was effective on the nouns, it has the per-
formance of a random classifier for verbs. This
All synsets
high precision
high F-score
high coverage
BCS synsets
high precision
high F-score
high coverage
highlights the complexity of verbal polysemy.
For adjectives and verbs, only the synonymy
selector was applied. For high F-score and high
coverage resources, the same selectors (initial and
syntactic) are applied, which is why the results
are the same. While the inter-annotator agreement
was lower on adjectives than on verbs, results are
much better for adjectives. This is mainly due to
the number of candidates from which to select:
there are twice as less candidates for adjectives.
This highlights the importance of dictionaries.
</bodyText>
<subsectionHeader confidence="0.978391">
5.4 Evaluation against WOLF
</subsectionHeader>
<bodyText confidence="0.999971066666667">
Using our gold standard to compare WOLF and
WoNeF would unfairly penalize WOLF for all cor-
rect words not present in our dictionaries. Con-
versely, we cannot consider WOLF as a direct
reference as WOLF itself is not fully validated.
The last publication giving overall WOLF figures
(Sagot and Fišer, 2012) indicates a number of pairs
around 77 000 with 86% precision3. We thus com-
pare the intersections between the high-precision
WoNeF (93.3% precision) and WOLF 0.1.4 and
1.0b (Table 6). It shows that although WoNeF is
still smaller than WOLF, it is a complementary
resource. The comparison of the differences be-
tween WOLF 0.1.4 and WOLF 1.0b is instructive
as it highlights WOLF improvements.
</bodyText>
<table confidence="0.9997826">
WOLF 0.1.4 C D ®
Nouns 18.7 3.0 10 526
Verbs 6.5 0.8 1 743
Adjectives 26.9 5.8 3 710
Adverbs 23.8 5.6 757
WOLF 1.0b C D ®
Nouns 49.7 8.6 6 503
Verbs 26.5 2.6 1 338
Adjectives 36.4 13.3 2 530
Adverbs 41.2 12.6 543
</table>
<tableCaption confidence="0.983519">
Table 6: Intersections between the high precision
</tableCaption>
<bodyText confidence="0.957573428571428">
WoNeF and WOLF 0.1.4 and 1.0b. C is the
percentage of WoNeF pairs included in WOLF
and D is the percentage of WOLF pairs included
in WoNeF. ® is the number of new elements
contributed by WoNeF.
The ® column gives the number of transla-
tions that are present in WoNeF but not in WOLF.
</bodyText>
<footnote confidence="0.9099125">
3The detailed results for WOLF 1.0b are not currently
available.
</footnote>
<bodyText confidence="0.999910666666667">
For nouns, verbs and adjectives, it means that
we contribute 10 914 new high precision (literal,
synset) pairs by merging WoNeF and WOLF 1.0,
in other words 94% of the high precision WoNeF
pairs which shows how much the two approaches
are complementary: different literals are selected.
This produces a French wordnet 10% larger than
WOLF with an improved accuracy. A merging
with the high F-score resource would be slightly
less precise, but it would provide 81 052 new (lit-
eral, synset) pairs comparing to WOLF 1.0b, re-
sulting in a merge containing 73 712 non-empty
synsets and 188,657 (literal, synset) pairs, increas-
ing WOLF coverage by 75% and the WoNeF one
by 63%.
</bodyText>
<sectionHeader confidence="0.941398" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999965652173913">
In this work, we have shown that the use of a syn-
tactic language model to identify lexical relations
between lexemes is possible in a constrained en-
vironment and leads to results with a state of the
art precision for the task of translating WordNet.
We offer three different resources, each with a dif-
ferent purpose. Finally, we provide a validated
high quality gold standard that has enabled us to
demonstrate both the validity of the approach of
translating WordNet by extension and the validity
of our specific approach. This gold standard can
also be used to evaluate and develop other French
WordNet translations. WoNeF is freely avail-
able on http://wonef.fr/ under the LGPL-
LR licence. A web interface based on sloWTool
(Fi[Pleaseinsertintopreamble]er and Novak, 2011)
(initially developed for sloWNet, the Slovenian
WordNet) allows to browse the resulting Word-
Net online. The current distribution formats are
the DEBVisDic XML and WordNet-LMF formats.
This allows to integrate WoNeF into the Global
WordNet Grid and facilitates access and conver-
sions into any lexical resource format.
Future work on WoNeF will focus on verbs, ad-
jectives and adverbs, for which dedicated new se-
lectors may be considered to improve coverage.
For example, the synonymy selector can be ex-
tended to the WordNet adjectival quasi-synonymy
relationship because distributional semantic tech-
niques tend to identify quasi-synonyms rather than
synonyms.
Another important source of improvement will
be to enrich our syntactic language model by tak-
ing into account reflexive verbs and multi-word
expressions. We would also like to move towards a
continuous language model (Le et al., 2012). This
will be coupled with the collection of a more re-
cent and larger Web corpus analyzed with a recent
version of our linguistic analyzer. This will allow
us to measure the impact of the language model
quality on the WordNet translation.
The WOLF French wordnet was built using sev-
eral techniques. Merging WoNeF and WOLF will
soon improve again the status of the French trans-
lation of WordNet: we are working with WOLF
authors to merge WOLF and WoNeF.
</bodyText>
<sectionHeader confidence="0.999421" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999567772727273">
Marianna Apidianaki and Benoît Sagot. 2012. Apply-
ing cross-lingual WSD to wordnet development. In
LREC’12, May.
Jordi Atserias, Salvador Climent, Xavier Farreres, Ger-
man Rigau, and Horacio Rodr Guez. 1997. Com-
bining Multiple Methods for the Automatic Con-
struction of Multilingual WordNets. In RANLP’97,
September.
Laura Benítez, Sergi Cervell, Gerard Escudero, Mònica
López, German Rigau, and Mariona Taulé. 1998.
Methods and Tools for Building the Catalan Word-
Net. In ELRA Workshop on Language Resources for
European Minority Languages, May.
Romaric Besançon, Gaël de Chalendar, Olivier Ferret,
Faiza Gara, and Nasredine Semmar. 2010. LIMA:
A Multilingual Framework for Linguistic Analysis
and Linguistic Resources Development and Evalua-
tion. In LREC 2010, May.
Fred J. Damerau. 1964. A technique for computer de-
tection and correction of spelling errors. Communi-
cations of the ACM, 7(3):171–176, March.
Gerard de Melo and Gerhard Weikum. 2008. On the
Utility of Automatically Generated Wordnets. In
GWC 2008, January.
Gerard de Melo and Gerhard Weikum. 2009. Towards
a universal wordnet by learning from combined evi-
dence. In CIKM 2009, November.
Helge Dyvik. 2002. Translations as Semantic Mirrors:
From Parallel Corpus to WordNet. In ICAME 23,
May.
Javier Farreres, Karina Gibert, Horacio Rodríguez, and
Charnyote Pluempitiwiriyawej. 2010. Inference of
lexical ontologies. The LeOnI methodology. Artifi-
cial Intelligence, 174(1):1–19, January.
Christiane Fellbaum and Piek Vossen. 2007. Connect-
ing the Universal to the Specific: Towards the Global
Grid. In IWIC 2007, January.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA, May.
Thomas Finkenstaedt and Dieter Wolff. 1973. Or-
dered profusion: Studies in dictionaries and the En-
glish lexicon, volume 13 of Annales Universitatis
Saraviensis. C. Winter.
Darja Fi&amp;quot;ser and Jernej Novak. 2011. Visualizing
slownet. In eLex 2011, November.
Gregory Grefenstette. 2007. Conquering language:
Using NLP on a massive scale to build high dimen-
sional language models from the web. In CICLing
2007, February.
Kilem L. Gwet. 2001. Handbook of inter-rater relia-
bility. Advanced Analytics, LLC, September.
Valérie Hanoka and Benoît Sagot. 2012. Wordnet ex-
tension made simple: A multilingual lexicon-based
approach using wiki resources. In LREC’12, may.
Christine Jacquin, Emmanuel Desmontils, and Laura
Monceaux. 2007. French eurowordnet lexical
database improvements. In CICLing 2007, Febru-
ary.
Hai-Son Le, Alexandre Allauzen, and François Yvon.
2012. Continuous Space Translation Models with
Neural Networks. In NAACL-HLT 2012, June.
Alessandro Lenci and Giulia Benotto. 2012. Identify-
ing hypernyms in distributional semantic spaces. In
*SEM 2012, June.
Claire Mouton and Gaël de Chalendar. 2010. JAWS:
Just Another WordNet Subset. In TALN 2010, June.
Roberto Navigli and Simone Paolo Ponzetto. 2010.
BabelNet: Building a very large multilingual seman-
tic network. In ACL 2010, July.
David M W Powers. 2012. The Problem with Kappa.
In EACL 2012, April.
German Rigau and Eneko Agirre. 1995. Disam-
biguating bilingual nominal entries against Word-
Net. In Workshop &amp;quot;The Computational Lexicon&amp;quot;.
ESSLLI’95, August.
Benoît Sagot and Darja Fi&amp;quot;ser. 2008. Building a free
French wordnet from multilingual resources. In On-
tolex 2008 Workshop, May.
Benoît Sagot and Darja Fi&amp;quot;ser. 2012. Automatic Exten-
sion of WOLF. In GWC 2012, January.
Dan Tufi¸s, Dan Cristea, and Sofia Stamou. 2004.
BalkaNet: Aims, methods, results and perspectives.
a general overview. Romanian Journal of Informa-
tion Science and Technology, 7(1-2):9–43.
Piek Vossen. 1998. EuroWordNet: a multilingual
database with lexical semantic networks. Kluwer
Academic, October.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.146683">
<title confidence="0.932434">WoNeF, an improved, expanded and automatic French translation of WordNet</title>
<author confidence="0.343951">Gaël de_Chalendar Baguenier Pradet</author>
<affiliation confidence="0.234015">CEA, LIST, Laboratoire Vision et Ingénierie des</affiliation>
<address confidence="0.606887">Gif-sur-Yvette, F-91191,</address>
<email confidence="0.988721">quentin.pradet|gael.de-chalendar@cea.fr</email>
<abstract confidence="0.979602923076923">Automatic translations of WordNet have been tried to many different target languages. JAWS is such a translation for French nouns using bilingual dictionaries and a syntactic language model. We improve its precision and coverage, complete it with translations of other parts of speech and enhance its evaluation method. The result is named WoNeF. We produce three final translations balanced between precision (up to 93%) and coverage (up to 109 447 (literal, synset) pairs).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
<author>Benoît Sagot</author>
</authors>
<title>Applying cross-lingual WSD to wordnet development.</title>
<date>2012</date>
<booktitle>In LREC’12,</booktitle>
<contexts>
<context position="2480" citStr="Apidianaki and Sagot, 2012" startWordPosition="364" endWordPosition="367">tionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French WordNets exist. The French EuroWordNet (Vossen, 1998) has a limited coverage and requires significant improvements to be used (Jacquin et al., 2007). It is also neither free nor freely accessible, which prevented the community from using and improving it. WOLF is a second French translation originally built using parallel corpora (Sagot and Fišer, 2008) and since then expanded using various techniques (Apidianaki and Sagot, 2012). WOLF is distributed under a free LGPL-compatible license. Finally, JAWS (Mouton and de Chalendar, 2010) is a translation of WordNet nouns developed using bilingual dictionaries and a syntactic language model. Our work expands and improves the techniques used in JAWS and evaluates it based on the adjudication of two annotators work. The result is called WoNeF1 and is distributed under the LGPL-LR licence. To our knowledge, all current WordNet machine translations only exist in one version where the authors decide what metric to optimize. We provide such a version, but add two resources that c</context>
</contexts>
<marker>Apidianaki, Sagot, 2012</marker>
<rawString>Marianna Apidianaki and Benoît Sagot. 2012. Applying cross-lingual WSD to wordnet development. In LREC’12, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordi Atserias</author>
<author>Salvador Climent</author>
<author>Xavier Farreres</author>
<author>German Rigau</author>
<author>Horacio Rodr Guez</author>
</authors>
<title>Combining Multiple Methods for the Automatic Construction of Multilingual WordNets.</title>
<date>1997</date>
<booktitle>In RANLP’97,</booktitle>
<contexts>
<context position="5481" citStr="Atserias et al., 1997" startWordPosition="853" endWordPosition="856">alled initial selectors choose correct translations among those proposed by the dictionary. First, words appearing in only one synset are not ambiguous: all their translations are added to the French wordnet. This is the monosemy selector. For example, all translations of grumpy are selected in the only synset where it appears. Second, the uniqueness selector identifies words with only one translation and selects this translation in all synsets where the words appear. The five synsets containing pill in English are thus completed with pilule. These two first selectors were previously used in (Atserias et al., 1997) and (Benítez et al., 1998). A third selector translates words that are not in the dictionary using the English word itself: the direct translation selector. A fourth selector uses the Levenshtein edit distance: despite some false friends, if the distance between an English word and its translation is short, it can be considered that they have the same sense. Two examples are portion and university). JAWS expansion JAWS being partially filled, a new expansion phase leverages the relationships between WordNet synsets to propose new translations. For example, if a synset S1 is a meronym of a syn</context>
<context position="10292" citStr="Atserias et al., 1997" startWordPosition="1653" endWordPosition="1656">s not detailed here is the one that led to a dramatically higher execution speed: JAWS built in several hours versus less than a minute for WoNeF, which helped to run many more experiments. 3.1 Initial selectors JAWS initial selectors are not optimal. While we keep the monosemy and uniqueness selectors, we changed the other ones. The direct translation selector is deleted as its precision was very low, even for nouns. A new selector considers candidate translations coming from several different English words in a given synset: the multiple sources selector, a variant the variant criterion of (Atserias et al., 1997). For example, in the synset line, railway line, rail line, the French literals ligne de chemin de fer and voie are translations of both line and railway line and are therefore chosen as translations. Finally, the Levenshtein distance selector has been improved. 28% of English vocabulary is of French origin (Finkenstaedt and Wolff, 1973) and anglicization produced predictable changes. It is possible to apply the same changes to the French candidate literal before computing the Levenshtein distance, bringing related words closer. We remove diacritics before applying several operations to word t</context>
<context position="13653" citStr="Atserias et al., 1997" startWordPosition="2183" endWordPosition="2186"> written text, nontext content, non French sentences); and selected translations in one step are considered valid in the following steps while this is not always the case. For the high-precision resource, we only keep literals for which the selectors were more confident. Since multiple selectors can now choose a given translation (section 3.2), our solution is simple and effective: translations proposed by multiple selectors are kept while the others are deleted. This voting principle is inspired from ensemble learning in machine learning. It is also similar to the combination method used in (Atserias et al., 1997) but we can avoid their manual inspection of samples of each method thanks to the development of our gold standard. This cleaning operation retains only 18% of translations (from 87 757 (literal, synset) pairs to 15 625) but the accuracy increases from 68.4% to 93.3%. This high precision resource can be used as training data for other French WordNets. A typical voting methods problem is to choose only easier and poorly interesting examples, but the resource obtained here is well balanced between synsets containing only monosemic words and other synsets containing polysemous and more difficult </context>
</contexts>
<marker>Atserias, Climent, Farreres, Rigau, Guez, 1997</marker>
<rawString>Jordi Atserias, Salvador Climent, Xavier Farreres, German Rigau, and Horacio Rodr Guez. 1997. Combining Multiple Methods for the Automatic Construction of Multilingual WordNets. In RANLP’97, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Benítez</author>
<author>Sergi Cervell</author>
<author>Gerard Escudero</author>
<author>Mònica López</author>
<author>German Rigau</author>
<author>Mariona Taulé</author>
</authors>
<title>Methods and Tools for Building the Catalan WordNet.</title>
<date>1998</date>
<booktitle>In ELRA Workshop on Language Resources for European Minority Languages,</booktitle>
<contexts>
<context position="5508" citStr="Benítez et al., 1998" startWordPosition="858" endWordPosition="861">se correct translations among those proposed by the dictionary. First, words appearing in only one synset are not ambiguous: all their translations are added to the French wordnet. This is the monosemy selector. For example, all translations of grumpy are selected in the only synset where it appears. Second, the uniqueness selector identifies words with only one translation and selects this translation in all synsets where the words appear. The five synsets containing pill in English are thus completed with pilule. These two first selectors were previously used in (Atserias et al., 1997) and (Benítez et al., 1998). A third selector translates words that are not in the dictionary using the English word itself: the direct translation selector. A fourth selector uses the Levenshtein edit distance: despite some false friends, if the distance between an English word and its translation is short, it can be considered that they have the same sense. Two examples are portion and university). JAWS expansion JAWS being partially filled, a new expansion phase leverages the relationships between WordNet synsets to propose new translations. For example, if a synset S1 is a meronym of a synset S2 in WordNet and there</context>
</contexts>
<marker>Benítez, Cervell, Escudero, López, Rigau, Taulé, 1998</marker>
<rawString>Laura Benítez, Sergi Cervell, Gerard Escudero, Mònica López, German Rigau, and Mariona Taulé. 1998. Methods and Tools for Building the Catalan WordNet. In ELRA Workshop on Language Resources for European Minority Languages, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Romaric Besançon</author>
<author>Gaël de Chalendar</author>
<author>Olivier Ferret</author>
<author>Faiza Gara</author>
<author>Nasredine Semmar</author>
</authors>
<title>LIMA: A Multilingual Framework for Linguistic Analysis and Linguistic Resources Development and Evaluation. In LREC</title>
<date>2010</date>
<marker>Besançon, de Chalendar, Ferret, Gara, Semmar, 2010</marker>
<rawString>Romaric Besançon, Gaël de Chalendar, Olivier Ferret, Faiza Gara, and Nasredine Semmar. 2010. LIMA: A Multilingual Framework for Linguistic Analysis and Linguistic Resources Development and Evaluation. In LREC 2010, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred J Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>Communications of the ACM,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="11825" citStr="Damerau, 1964" startWordPosition="1897" endWordPosition="1898">-rated translations. This rejects valid candidates and accepts wrong ones. For example, JAWS does not include particulier in the human being synset because personne is already included with a higher score. In WoNeF, we learned a threshold for each part of speech and selector. We first generated scores for all (literal, synset) candidate pairs, then sorted these pairs by score. The 12 399 pairs present in the WOLF 1.0b manual evaluation (our training set) were considered to be correct, while the pairs 2The Damerau-Levenshtein distance which takes into account transpositions anywhere in a word (Damerau, 1964) led to poorer results. -que -k banque bank -aire -ary tertiaire tertiary eur er chercheur researcher ie y cajolerie cajolery -té -ty extremité extremity -re -er tigre tiger ais ese libanais lebanese -ant -ing changeant changing Table 1: Changes to French word tails before applying the Levenshtein distance. outside this set were not. We then calculated the thresholds maximizing precision and F-score. Once these thresholds are defined, the selectors choose all candidates above the new threshold. This has two positive effects: valid candidates are not rejected when only the best candidate is alr</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>Fred J. Damerau. 1964. A technique for computer detection and correction of spelling errors. Communications of the ACM, 7(3):171–176, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>On the Utility of Automatically Generated Wordnets.</title>
<date>2008</date>
<booktitle>In GWC</booktitle>
<marker>de Melo, Weikum, 2008</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2008. On the Utility of Automatically Generated Wordnets. In GWC 2008, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard de Melo</author>
<author>Gerhard Weikum</author>
</authors>
<title>Towards a universal wordnet by learning from combined evidence.</title>
<date>2009</date>
<booktitle>In CIKM</booktitle>
<marker>de Melo, Weikum, 2009</marker>
<rawString>Gerard de Melo and Gerhard Weikum. 2009. Towards a universal wordnet by learning from combined evidence. In CIKM 2009, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helge Dyvik</author>
</authors>
<title>Translations as Semantic Mirrors: From Parallel Corpus to WordNet.</title>
<date>2002</date>
<booktitle>In ICAME 23,</booktitle>
<contexts>
<context position="1672" citStr="Dyvik, 2002" startWordPosition="243" endWordPosition="244">cture and its synsets leads to useful linguistic resources. WordNet automatic translations use the expand approach: its structure is preserved and only literals are translated. Three main techniques represent this approach in the literature. The simplest one seeds WordNet using bilingual dictionaries (Rigau and Agirre, 1995), which can be filtered manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French WordNets exist. The French EuroWordNet (Vossen, 1998) has a limited coverage and requires significant improvements to be used (Jacquin et al., 2007). It is also neither free nor freely accessible, which prevented the communit</context>
</contexts>
<marker>Dyvik, 2002</marker>
<rawString>Helge Dyvik. 2002. Translations as Semantic Mirrors: From Parallel Corpus to WordNet. In ICAME 23, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javier Farreres</author>
<author>Karina Gibert</author>
<author>Horacio Rodríguez</author>
<author>Charnyote Pluempitiwiriyawej</author>
</authors>
<title>Inference of lexical ontologies. The LeOnI methodology.</title>
<date>2010</date>
<journal>Artificial Intelligence,</journal>
<volume>174</volume>
<issue>1</issue>
<contexts>
<context position="21694" citStr="Farreres et al., 2010" startWordPosition="3507" endWordPosition="3510"> sources 64.5 45.0 53.0 27 316 Levenshtein 61.9 29.0 39.3 20 034 high precision 93.8 50.1 65.3 13 867 high F-score 71.1 72.7 71.9 82 730 high coverage 69.0 69.8 69.4 90 248 Table 3: Top part: Precision, Recall and F1-measure of initial selectors on all translations (nouns, verbs and adjectives). Bottom part: scores for various combinations of them. Coverage C is the total number of pairs (literal, synset). applies a vote (section 3.3). As in the previous table, the coverage C is the number of (literal, synset) pairs. Without using structure-based nor conceptual distance-based selectors as in (Farreres et al., 2010), we obtain a coverage at 93% precision for our French wordnet (15 625) equal to their Spanish one (11 770) and larger than their Thai one (2 013). P R F1 C 93.3 51.5 66.4 15 625 68.9 73.0 70.9 88 736 60.5 74.3 66.7 109 447 P R F1 C 90.4 36.5 52.0 1 877 56.5 62.8 59.1 14 405 44.5 66.9 53.5 23 166 Table 4: Global results for all synsets and BCS synsets only. In WordNet, most words are monosemous, but a small minority of polysemous words are the most represented in texts. It is precisely on this minority that we wish to create a quality resource. To evaluate this, we use the list of BCS (Basic C</context>
</contexts>
<marker>Farreres, Gibert, Rodríguez, Pluempitiwiriyawej, 2010</marker>
<rawString>Javier Farreres, Karina Gibert, Horacio Rodríguez, and Charnyote Pluempitiwiriyawej. 2010. Inference of lexical ontologies. The LeOnI methodology. Artificial Intelligence, 174(1):1–19, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
<author>Piek Vossen</author>
</authors>
<title>Connecting the Universal to the Specific: Towards the Global Grid. In IWIC</title>
<date>2007</date>
<contexts>
<context position="961" citStr="Fellbaum and Vossen, 2007" startWordPosition="133" endWordPosition="136"> to many different target languages. JAWS is such a translation for French nouns using bilingual dictionaries and a syntactic language model. We improve its precision and coverage, complete it with translations of other parts of speech and enhance its evaluation method. The result is named WoNeF. We produce three final translations balanced between precision (up to 93%) and coverage (up to 109 447 (literal, synset) pairs). 1 Introduction Reproducing the lexicographic work of WordNet (Fellbaum, 1998) for other languages is costly and difficult to maintain. Even with some theoretical problems, (Fellbaum and Vossen, 2007; de Melo and Weikum, 2008) show that translating Princeton WordNet literals while keeping its structure and its synsets leads to useful linguistic resources. WordNet automatic translations use the expand approach: its structure is preserved and only literals are translated. Three main techniques represent this approach in the literature. The simplest one seeds WordNet using bilingual dictionaries (Rigau and Agirre, 1995), which can be filtered manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries</context>
</contexts>
<marker>Fellbaum, Vossen, 2007</marker>
<rawString>Christiane Fellbaum and Piek Vossen. 2007. Connecting the Universal to the Specific: Towards the Global Grid. In IWIC 2007, January.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Finkenstaedt</author>
<author>Dieter Wolff</author>
</authors>
<title>Ordered profusion: Studies in dictionaries and the English lexicon, volume 13 of Annales Universitatis Saraviensis.</title>
<date>1973</date>
<journal>C. Winter.</journal>
<contexts>
<context position="10631" citStr="Finkenstaedt and Wolff, 1973" startWordPosition="1708" endWordPosition="1711">The direct translation selector is deleted as its precision was very low, even for nouns. A new selector considers candidate translations coming from several different English words in a given synset: the multiple sources selector, a variant the variant criterion of (Atserias et al., 1997). For example, in the synset line, railway line, rail line, the French literals ligne de chemin de fer and voie are translations of both line and railway line and are therefore chosen as translations. Finally, the Levenshtein distance selector has been improved. 28% of English vocabulary is of French origin (Finkenstaedt and Wolff, 1973) and anglicization produced predictable changes. It is possible to apply the same changes to the French candidate literal before computing the Levenshtein distance, bringing related words closer. We remove diacritics before applying several operations to word tails (Table 1). For example, reversing the &amp;quot;r&amp;quot; and &amp;quot;e&amp;quot; letter takes into account (ordre/order) and (tigre/tiger). 2 As before, false friends are not taken into account. 3.2 Learning thresholds In JAWS, each English literal can only correspond to the highest scoring French translation, regardless of the scores of lower-rated translations.</context>
</contexts>
<marker>Finkenstaedt, Wolff, 1973</marker>
<rawString>Thomas Finkenstaedt and Dieter Wolff. 1973. Ordered profusion: Studies in dictionaries and the English lexicon, volume 13 of Annales Universitatis Saraviensis. C. Winter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darja Fiser</author>
<author>Jernej Novak</author>
</authors>
<title>Visualizing slownet.</title>
<date>2011</date>
<booktitle>In eLex 2011,</booktitle>
<marker>Fiser, Novak, 2011</marker>
<rawString>Darja Fi&amp;quot;ser and Jernej Novak. 2011. Visualizing slownet. In eLex 2011, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Conquering language: Using NLP on a massive scale to build high dimensional language models from the web. In CICLing</title>
<date>2007</date>
<contexts>
<context position="4012" citStr="Grefenstette, 2007" startWordPosition="619" endWordPosition="621">ch (section 3) and its evaluation (sections 4 and 5). The evaluation is done through an adjudication itself validated by measuring the inter-annotator agreement, which validates the expand approach to translate WordNet. 2 JAWS 2.1 Translation process JAWS was built with a weakly supervised algorithm that does not require any manually anno1This work was partially funded by the ANR ASFALDA ANR-12-CORD-0023 project. tated data, only the links between the French and English Wiktionaries and a target syntactic language model. The language model was trained on a large corpus extracted from the Web (Grefenstette, 2007). The corpus was analyzed by LIMA (Besançon et al., 2010), a rule-based parser producing fine-grained syntactic dependencies. For a given relation r and a word x, the language model indicates what are the first 100 words cooccurring most frequently with x through the relation r. Thanks to the dictionary, JAWS does not need to select each synset literals from the entire vocabulary but only among a small number of candidates (9 on average). The translation process is done in three steps. First, an empty wordnet is created, preserving WordNet structure, but with no literal associated to synsets. </context>
</contexts>
<marker>Grefenstette, 2007</marker>
<rawString>Gregory Grefenstette. 2007. Conquering language: Using NLP on a massive scale to build high dimensional language models from the web. In CICLing 2007, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kilem L Gwet</author>
</authors>
<title>Handbook of inter-rater reliability. Advanced Analytics,</title>
<date>2001</date>
<location>LLC,</location>
<contexts>
<context position="19321" citStr="Gwet, 2001" startWordPosition="3101" endWordPosition="3102">tupid aspect of weird. There is no translation that would fit in all contexts: the synset meaning is not fully preserved after translation. 4.2 Inter-annotators agreement Table 2 shows the inter-annotator agreement measured through Fleiss kappa for the three annotated Nouns Verbs Adj. Fleiss Kappa 0.715 0.711 0.663 Synsets 270 222 267 Candidates 6.22 14.50 7.27 Table 2: Gold standard inter-annotator agreement parts of speech. Even if it is a discussed metric (Powers, 2012), all existing evaluation tables consider these scores as high enough to describe the inter-annotator agreement as &amp;quot;good&amp;quot; (Gwet, 2001), which allows us to say that our gold standard is good. The expand approach for the translation of WordNets is also validated: it is possible to produce useful resource in spite of the difficulties mentioned in section 4.1. 5 Results We present in this section the results of WoNeF. We first describe the initial selectors and proceed with the full resource. Our gold standard is divided into two parts: 10% of the literals form the validation set used to choose the selectors that apply to different versions of WoNeF, while the remaining 90% form the evaluation set. No training was performed on o</context>
</contexts>
<marker>Gwet, 2001</marker>
<rawString>Kilem L. Gwet. 2001. Handbook of inter-rater reliability. Advanced Analytics, LLC, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Valérie Hanoka</author>
<author>Benoît Sagot</author>
</authors>
<title>Wordnet extension made simple: A multilingual lexicon-based approach using wiki resources.</title>
<date>2012</date>
<booktitle>In LREC’12,</booktitle>
<contexts>
<context position="2032" citStr="Hanoka and Sagot, 2012" startWordPosition="295" endWordPosition="298"> manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French WordNets exist. The French EuroWordNet (Vossen, 1998) has a limited coverage and requires significant improvements to be used (Jacquin et al., 2007). It is also neither free nor freely accessible, which prevented the community from using and improving it. WOLF is a second French translation originally built using parallel corpora (Sagot and Fišer, 2008) and since then expanded using various techniques (Apidianaki and Sagot, 2012). WOLF is distributed under a free LGPL-compatible license. Finally, JAWS (Mouton and de Chalendar, 2010) is a translation of WordNet nouns developed us</context>
</contexts>
<marker>Hanoka, Sagot, 2012</marker>
<rawString>Valérie Hanoka and Benoît Sagot. 2012. Wordnet extension made simple: A multilingual lexicon-based approach using wiki resources. In LREC’12, may.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine Jacquin</author>
<author>Emmanuel Desmontils</author>
<author>Laura Monceaux</author>
</authors>
<title>French eurowordnet lexical database improvements. In CICLing</title>
<date>2007</date>
<contexts>
<context position="2195" citStr="Jacquin et al., 2007" startWordPosition="320" endWordPosition="323">se lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French WordNets exist. The French EuroWordNet (Vossen, 1998) has a limited coverage and requires significant improvements to be used (Jacquin et al., 2007). It is also neither free nor freely accessible, which prevented the community from using and improving it. WOLF is a second French translation originally built using parallel corpora (Sagot and Fišer, 2008) and since then expanded using various techniques (Apidianaki and Sagot, 2012). WOLF is distributed under a free LGPL-compatible license. Finally, JAWS (Mouton and de Chalendar, 2010) is a translation of WordNet nouns developed using bilingual dictionaries and a syntactic language model. Our work expands and improves the techniques used in JAWS and evaluates it based on the adjudication of </context>
</contexts>
<marker>Jacquin, Desmontils, Monceaux, 2007</marker>
<rawString>Christine Jacquin, Emmanuel Desmontils, and Laura Monceaux. 2007. French eurowordnet lexical database improvements. In CICLing 2007, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai-Son Le</author>
<author>Alexandre Allauzen</author>
<author>François Yvon</author>
</authors>
<title>Continuous Space Translation Models with Neural Networks.</title>
<date>2012</date>
<booktitle>In NAACL-HLT 2012,</booktitle>
<marker>Le, Allauzen, Yvon, 2012</marker>
<rawString>Hai-Son Le, Alexandre Allauzen, and François Yvon. 2012. Continuous Space Translation Models with Neural Networks. In NAACL-HLT 2012, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Lenci</author>
<author>Giulia Benotto</author>
</authors>
<title>Identifying hypernyms in distributional semantic spaces.</title>
<date>2012</date>
<booktitle>In *SEM 2012,</booktitle>
<contexts>
<context position="8095" citStr="Lenci and Benotto, 2012" startWordPosition="1288" endWordPosition="1291">th a dictionary or a syntactic language model is impossible, combining the two resources can solve the problem. Each such syntactic selector follows the same principle as the meronymy selector and translates new synsets by identifying relationships between lexemes through the syntactic language model. The match between the noun modifier relation and the meronymy relation is direct, but this is not the case for all relations: there is for example no syntactic relationship that directly expresses the synonymy between two literals. For these relations, JAWS uses second order syntactic relations (Lenci and Benotto, 2012). See (Mouton and de Chalendar, 2010) for more details and other selectors. 2.2 JAWS limits JAWS suffers from two main limitations. Above all, it only contains nouns, which prevents its use in many applications. Also, its evaluation procedure makes it difficult to judge its quality. Indeed, JAWS was evaluated by comparing it to the French EuroWordNet and WOLF 0.1.4 (released in 2008). These two French wordnets are not gold standards: Synset S1 - English : quill - French : piquant? plume? (a stiff hollow protective spine) mémoire, piquant, poil, épine, yéti, ragoût, grotte, ... Synset S2 - Engl</context>
</contexts>
<marker>Lenci, Benotto, 2012</marker>
<rawString>Alessandro Lenci and Giulia Benotto. 2012. Identifying hypernyms in distributional semantic spaces. In *SEM 2012, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Mouton</author>
<author>Gaël de Chalendar</author>
</authors>
<title>JAWS: Just Another WordNet Subset. In TALN</title>
<date>2010</date>
<marker>Mouton, de Chalendar, 2010</marker>
<rawString>Claire Mouton and Gaël de Chalendar. 2010. JAWS: Just Another WordNet Subset. In TALN 2010, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: Building a very large multilingual semantic network.</title>
<date>2010</date>
<booktitle>In ACL 2010,</booktitle>
<contexts>
<context position="1982" citStr="Navigli and Ponzetto, 2010" startWordPosition="286" endWordPosition="289">naries (Rigau and Agirre, 1995), which can be filtered manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French WordNets exist. The French EuroWordNet (Vossen, 1998) has a limited coverage and requires significant improvements to be used (Jacquin et al., 2007). It is also neither free nor freely accessible, which prevented the community from using and improving it. WOLF is a second French translation originally built using parallel corpora (Sagot and Fišer, 2008) and since then expanded using various techniques (Apidianaki and Sagot, 2012). WOLF is distributed under a free LGPL-compatible license. Finally, JAWS (Mouton and de Chalendar, 20</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2010. BabelNet: Building a very large multilingual semantic network. In ACL 2010, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M W Powers</author>
</authors>
<date>2012</date>
<booktitle>The Problem with Kappa. In EACL 2012,</booktitle>
<contexts>
<context position="19187" citStr="Powers, 2012" startWordPosition="3082" endWordPosition="3083"> is no good translation of weird in French. Although most dictionaries provide bizarre as a translation, this one does not provide the stupid aspect of weird. There is no translation that would fit in all contexts: the synset meaning is not fully preserved after translation. 4.2 Inter-annotators agreement Table 2 shows the inter-annotator agreement measured through Fleiss kappa for the three annotated Nouns Verbs Adj. Fleiss Kappa 0.715 0.711 0.663 Synsets 270 222 267 Candidates 6.22 14.50 7.27 Table 2: Gold standard inter-annotator agreement parts of speech. Even if it is a discussed metric (Powers, 2012), all existing evaluation tables consider these scores as high enough to describe the inter-annotator agreement as &amp;quot;good&amp;quot; (Gwet, 2001), which allows us to say that our gold standard is good. The expand approach for the translation of WordNets is also validated: it is possible to produce useful resource in spite of the difficulties mentioned in section 4.1. 5 Results We present in this section the results of WoNeF. We first describe the initial selectors and proceed with the full resource. Our gold standard is divided into two parts: 10% of the literals form the validation set used to choose th</context>
</contexts>
<marker>Powers, 2012</marker>
<rawString>David M W Powers. 2012. The Problem with Kappa. In EACL 2012, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>German Rigau</author>
<author>Eneko Agirre</author>
</authors>
<title>Disambiguating bilingual nominal entries against WordNet.</title>
<date>1995</date>
<booktitle>In Workshop &amp;quot;The Computational Lexicon&amp;quot;. ESSLLI’95,</booktitle>
<contexts>
<context position="1386" citStr="Rigau and Agirre, 1995" startWordPosition="198" endWordPosition="201">1 Introduction Reproducing the lexicographic work of WordNet (Fellbaum, 1998) for other languages is costly and difficult to maintain. Even with some theoretical problems, (Fellbaum and Vossen, 2007; de Melo and Weikum, 2008) show that translating Princeton WordNet literals while keeping its structure and its synsets leads to useful linguistic resources. WordNet automatic translations use the expand approach: its structure is preserved and only literals are translated. Three main techniques represent this approach in the literature. The simplest one seeds WordNet using bilingual dictionaries (Rigau and Agirre, 1995), which can be filtered manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or </context>
</contexts>
<marker>Rigau, Agirre, 1995</marker>
<rawString>German Rigau and Eneko Agirre. 1995. Disambiguating bilingual nominal entries against WordNet. In Workshop &amp;quot;The Computational Lexicon&amp;quot;. ESSLLI’95, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoît Sagot</author>
<author>Darja Fiser</author>
</authors>
<title>Building a free French wordnet from multilingual resources.</title>
<date>2008</date>
<booktitle>In Ontolex 2008 Workshop,</booktitle>
<marker>Sagot, Fiser, 2008</marker>
<rawString>Benoît Sagot and Darja Fi&amp;quot;ser. 2008. Building a free French wordnet from multilingual resources. In Ontolex 2008 Workshop, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoît Sagot</author>
<author>Darja Fiser</author>
</authors>
<title>Automatic Extension of WOLF.</title>
<date>2012</date>
<booktitle>In GWC 2012,</booktitle>
<marker>Sagot, Fiser, 2012</marker>
<rawString>Benoît Sagot and Darja Fi&amp;quot;ser. 2012. Automatic Extension of WOLF. In GWC 2012, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tufi¸s</author>
<author>Dan Cristea</author>
<author>Sofia Stamou</author>
</authors>
<title>BalkaNet: Aims, methods, results and perspectives. a general overview.</title>
<date>2004</date>
<journal>Romanian Journal of Information Science and Technology,</journal>
<pages>7--1</pages>
<marker>Tufi¸s, Cristea, Stamou, 2004</marker>
<rawString>Dan Tufi¸s, Dan Cristea, and Sofia Stamou. 2004. BalkaNet: Aims, methods, results and perspectives. a general overview. Romanian Journal of Information Science and Technology, 7(1-2):9–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piek Vossen</author>
</authors>
<title>EuroWordNet: a multilingual database with lexical semantic networks.</title>
<date>1998</date>
<publisher>Kluwer Academic,</publisher>
<contexts>
<context position="1450" citStr="Vossen, 1998" startWordPosition="209" endWordPosition="210">8) for other languages is costly and difficult to maintain. Even with some theoretical problems, (Fellbaum and Vossen, 2007; de Melo and Weikum, 2008) show that translating Princeton WordNet literals while keeping its structure and its synsets leads to useful linguistic resources. WordNet automatic translations use the expand approach: its structure is preserved and only literals are translated. Three main techniques represent this approach in the literature. The simplest one seeds WordNet using bilingual dictionaries (Rigau and Agirre, 1995), which can be filtered manually by lexicographers (Vossen, 1998; Tufi¸s et al., 2004). A second translation method uses parallel corpora, which avoids the use of dictionaries that may cause lexical bias. Back-translations between Norwegian and English were first explored (Dyvik, 2002), while (Sagot and Fišer, 2008) combine a multilingual lexicon and the different BalkaNet wordnets to help disambiguation. Finally, the bilingual dictionaries extracted from the Wiktionary and the Wikipedia interlanguage links allow to create new wordnets (de Melo and Weikum, 2009; Navigli and Ponzetto, 2010) or improve existing ones (Hanoka and Sagot, 2012). Three French Wor</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Piek Vossen. 1998. EuroWordNet: a multilingual database with lexical semantic networks. Kluwer Academic, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>