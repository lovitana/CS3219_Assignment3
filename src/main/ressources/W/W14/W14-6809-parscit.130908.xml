<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000765">
<title confidence="0.97908">
Segment-based Fine-grained Emotion Detection for Chinese Text
</title>
<author confidence="0.914032">
Odbal
</author>
<affiliation confidence="0.9837955">
Dept. Of Automation, University of
Science and Technology of China
Institute of Intelligent Machines,
Chinese Academy of Sciences
</affiliation>
<email confidence="0.995684">
wdbl@iim.ac.cn
</email>
<sectionHeader confidence="0.993848" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999768869565217">
Emotion detection has been extensively
studied in recent years. Current base-
line methods often use token-based fea-
tures which cannot properly capture more
complex linguistic phenomena and emo-
tional composition in fine grained emotion
detection. A novel supervised learning
approach―segment-based fine-grained e-
motion detection model for Chinese text
has been proposed in this paper. Differ-
ent from most existing methods, the pro-
posed model applies the hierarchical struc-
ture of sentence (e.g., dependency rela-
tionship) and exploits segment-based fea-
tures. Furthermore, the emotional compo-
sition in short text is addressed by using
the log linear model. We perform emotion
detection on our dataset: news contents,
fairly tales, and blog dataset, and compare
our proposed method to representative ex-
isting approaches. The experimental re-
sults demonstrate the effectiveness of the
proposed segment-based model.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998321714285714">
Emotion detection aims to identify fine-grained
emotion categories (e.g., happy, angry, disgust,
fear, sadness and surprise) of a given text, and it
is a challenging and difficult problem with appli-
cations throughout natural language processing.
Currently, the most widely used probability
models for emotion classification are supervised
based machine learning algorithms, such as Naive
Bayes (NB) and Support Vector Machine (SVM)
etc,. Researchers have trained the classifier de-
pends on corpus-based features, mainly unigrams,
combined with lexical features (Alm et al, 2005;
Aman and Szpakowicz, 2007; Katz, et al, 2007).
Nevertheless, these methods used in the emotion
</bodyText>
<author confidence="0.74473">
Zengfu Wang
</author>
<affiliation confidence="0.86186725">
Dept. Of Automation, University of
Science and Technology of China
Institute of Intelligent Machines,
Chinese Academy of Sciences
</affiliation>
<email confidence="0.979691">
zfwang@ustc.edu.cn
</email>
<bodyText confidence="0.999928682926829">
classification system concentrate on token based
features and do not include any linguistic or con-
textual information, which often yields poor per-
formance. Therefore, recent studies have investi-
gated the approach using contextual information
around emotional words to identify fine grained e-
motion classes. (Das and Bandyopadhyay, 2010)
observe that the emotion word, POS, intensifier
and direct dependency features play an importan-
t role in extracting emotional expressions as well
as tagging sentences with emotions and intensi-
ties. (Diman Ghazi et al., 2012) propose an ap-
proach which takes the contextual emotion of a
word and the syntactic structure of the sentence in-
to account to classify sentences by emotion class-
es. However, these works still use token-based
features, which cannot address the problem of the
emotional composition, especially those that are
the expression-level representations.
There has been previous work using composi-
tion rules and statistical methods to handle senti-
ment composition. (Moilanen and Pulman, 2007)
propose a theoretical composition model, and e-
valuate a lexical dependency parsing post-process
implementation, which treat both negation and
intensifier via three models: sentiment propaga-
tion, polarity conflict resolution and polarity re-
versal. (Choi and Cardie, 2008) incorporate struc-
tural inference motivated by compositional seman-
tics into the learning procedure for subsentential
sentiment analysis. (Socher et al., 2011, 2012)
present matrix-vector representations with a recur-
sive neural network. The model is built on a parse
tree where the nodes are associated to a vector.
The matrix captures how each constituent modi-
fies its neighbor. (Baptiste Chardon et al,. 2013)
propose a computational model that accounts for
the effects of negation and modality on opinion ex-
pressions. However, it is not as clear how to use a
compositional treatment to classify fine grained e-
motion classes. Sentiment composition combines
</bodyText>
<page confidence="0.984356">
52
</page>
<note confidence="0.9847855">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 52–60,
Wuhan, China, 20-21 October 2014
</note>
<bodyText confidence="0.971602214285714">
individual positive and negative words or phrases,
and the final polarity of a sentence is positive or
negative. Nevertheless, it is more challenging and
difficult to make categorization into distinct emo-
tion classes for the higher level of classification in
emotion recognition task. In order to facilitate our
discussion, consider the following examples:
1.不过在教堂里,站在讲台上的牧师却是大叫
大嚷,非常生气. (But inside the church the pas-
tor stood in the pulpit, and spoke very loudly and
angrily.)[anger]
2.迷 信 使 她 的 血 一 会 儿 变 冷,一 会 儿
热.(Superstition made her alternately shudder with
cold or burn with the heat of fever.)[fear]
</bodyText>
<equation confidence="0.975474285714286">
3.骑 在 桦 木 条 上 的 那 个 蜡 人 忽 然 变 得
高又大了.他像一阵旋风似地扑向纸花那儿
去,说:”居然把这样的怪想头灌进一个孩子的脑
子里去!全是些没有道理的幻想!”这蜡人跟那
位戴宽帽子的枢密顾问官一模一样,而且他的
那副面孔也是跟顾问官一样发黄和生气.可是
那些纸花在他的瘦腿上打了一下,于是他缩做
</equation>
<bodyText confidence="0.999002236111111">
一团,又变成了一个渺小的蜡人.(All at once the
wax doll which rode on the carnival rod seemed to
grow larger and taller, and it turned round and said
to the paper flowers, ”How can you put such things
in a child’s head? they are all foolish fancies;” and
then the doll was exactly like the lawyer with the
broad brimmed hat, and looked as yellow and as
cross as he did; but the paper dolls struck him on
his thin legs, and he shrunk up again and became
quite a little wax doll.)[anger]
In the first example, we can use the key word-
s ”大 叫”,”大 嚷”(spoke very loudly), and ”生
气”(anger), to easily identify the emotion class-
es of the sentence. However, in the second ex-
ample, we cannot use the words ”血”(blood), ”变
冷”(make cold), ”变热”(make burn) or the phrase
”血变冷” and ”血变热” to easily detect the final
emotion category of the sentence. ”血” and ”变
冷” carry ”fear” category, and the words ”血” and
”变热” can be classified as ”joy”, but the final e-
motion label of the sentence is ”fear”. In the last
example, there are four types of emotion classes
for sub-sentential segments, for example, ”蜡人变
得又高又大”( the wax doll seemed to grow larger
and taller)[joy], ”怪想头”(such things) [surprise],
”没有道理的幻想!”(foolish fancies)[anger], ”生
气”(anger) [anger], and ”一个渺小的蜡人”( a lit-
tle wax doll)[sad], but the overall emotion of the
short text is ”anger”.
These examples demonstrate that a sentence
or short text exists several expression-level emo-
tion labels, and the words or constituents inter-
act with each other to yield the overall emotion
label, which cannot be easily resolved by token-
based methods. To solve this problem, we present
segment-based supervised learning approach to in-
vestigate how to recognize the overall emotion tag
of a sentence or short text. Closer to our current
purposes is the work of (Nakagawa et al, 2010).
It employs a conditional random field (CRF) for
sentiment classification of Japanese and English
subjective sentences using dependency tree-based
method. In their method, the sentiment polarity of
each dependency subtree, which is not observable
in training data, is represented by a hidden vari-
able. The polarity of the whole sentence is calcu-
lated in consideration of interactions between the
hidden variables. However, this research doesn’t
work on the fine grained emotion recognition and
it is unable to deal with multiple consecutive to-
kens (e.g., a phrase).
In this paper, we employ semi-Markov con-
ditional random fields (semi-CRFs) for segment-
based emotion detection. Semi-CRFs (Sarawagi
and Cohen, 2004) are more powerful than CRFs
in that they can assign labels to segments instead
of tokens; hence, features can be defined at the
segment level. To our knowledge, segment-based
fine-grained emotion recognition for Chinese text
has not been attempted. Our learning framework
can be determined in a three-step process: (1) seg-
ment the input sentence or short text into some de-
pendency subtrees and then (2) employ the semi-
CRFs with various context informed features to
assess the emotion classes of the constituents of
the segment, and (3) exploit a composition learn-
ing model to combine the segment level emotion
labels. We evaluate the proposed model on our
construction dataset, which consists of news con-
tent, fairy tales and blog dataset, and the experi-
mental results show that segment-based learning
algorithm works well in our experimental data.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999900571428571">
Supervised learning method has been well studied
and used in fine-grained emotion detection with
promising results. (Alm et al., 2005) explores the
text-based emotion prediction problem empirical-
ly, using supervised machine learning. (Das and
Bandyopadhyay, 2010) deals with the extraction
of emotional expressions and tagging of English
</bodyText>
<page confidence="0.992596">
53
</page>
<bodyText confidence="0.999335351851852">
blog sentences with Ekman’s six basic emotion
tags and any of the three intensities: low, medi-
um and high. Baseline system is developed based
on WordNet Affect lists and dependency relation-
s. SVM based supervised framework is employed
by incorporating different word and context level
features. (Chaffar and Inkpen, 2011) adopts a su-
pervised machine learning approach to recognize
six basic emotions (anger, disgust, fear, happi-
ness, sadness and surprise) using a heterogeneous
emotion-annotated dataset which combines news
headlines, fairy tales and blogs. (Saif Mohammad,
2012) uses word-level affect lexicons to provide
significant improvements in sentence-level emo-
tion classification. (Purver and Battersby, 2012)
describe a set of experiments using automatical-
ly labeled data to train supervised classifiers for
multi-class emotion detection in Twitter messages
with no manual intervention. (Diman Ghazi et al.,
2012) present a method which enables us to take
the contextual emotion of a word and the syntactic
structure of the sentence into account to classify
sentences by emotion classes.
Other related studies on this task are emotion
resource construction. (Xu et al., 2010) adopts a
graph-based algorithm to build Chinese emotion
lexicons for public use. (Patra et al., 2013) us-
es the Potts model for constructing emotion lex-
icon annotated with Ekman’s six basic emotion
classes. There are also studies that analyzed the
deeper level information, such as color-concept-
emotion associations (Volkova et al., 2012); e-
motion causes detection (Chen et al., 2010); and
learning hashtags to improve emotion classifica-
tion performance (Qadir and Riloff, 2013). In sen-
timent composition, the presence of modalities is
generally used to combine the individual positive
and negative word (Moilanen and Pulman, 2007;
Choi and Cardie, 2008; Nakagawa, 2010; Socher
et al., 2011, 2012; Chardon et al,.2013). There is
a few works on the higher level of composition in
emotion recognition task.
Different from above approaches, we use a
segment-based method for the fine-grained emo-
tion detection. To use the strengths of segment-
based features, we propose to employ the semi-
Markov Conditional Random Field, which was
previously used in information extraction to tag
continuous segments of input sequences and out-
performed conventional CRFs in the task of named
entity recognition and opinion extraction (Sarawa-
gi and Cohen, 2004; Okanohara et al., 2006; An-
drew, 2006; Yang and Cardie, 2012). We describe
this model in the following section.
</bodyText>
<sectionHeader confidence="0.9270745" genericHeader="method">
3 Segment-based Emotion Detection
using semi-CRF
</sectionHeader>
<bodyText confidence="0.99947975">
In this section, we first introduce the semi-Markov
conditional random field and then elaborate the
proposed segment-based emotion detection mod-
el.
</bodyText>
<subsectionHeader confidence="0.999676">
3.1 Semi-CRF
</subsectionHeader>
<bodyText confidence="0.99920452173913">
In this subsection we briefly review the semi-
Markov conditional random field. We follow the
definitions in (Sarawagi and Cohen, 2004). Let
s = sm1 =&lt; s1, · · · , sm &gt; denote a segmenta-
tion of an observed sequence x. To represent al-
l the information associated with each segmenta-
tion, we define si as si =&lt; ti, ui, yi &gt;, which
consisting of three components: a start position
ti, an end position ui, and a label yi. We as-
sume that segments have a positive length bound-
ed above by the pre-defined upper bound L (1 &lt;
ui − ti + 1 &lt; |x|) and completely cover the
sequence x without overlapping, that is, s satis-
fies t1 = 1, um = |x|, and ti + 1 = ui + 1
for i = 1, ..., m-1. For emotion detection, a
valid segmentation of the sentence ” 善良的姑
娘细心地照顾这只弱小的猫” might be s =&lt;
(1, 3, happy), (4, 6, happy), (7, 11, sad) &gt;, cor-
responding to the label sequence y =&lt;
happy, happy, sad &gt;.
Then, Semi-CRF defines a conditional proba-
bility of a state sequence y given an observed se-
quence x by:
</bodyText>
<equation confidence="0.998603">
m |s|
p(y, s|x) = Z(x) exp( � λifi(x, s, y)) (1)
i t=1
</equation>
<bodyText confidence="0.99997">
where fi(x, s, y) = fi(yj_1, yj, x, sj) is a fea-
ture function and Z(x) is the normalization factor
as defined for CRF. The model parameters are a set
of real-valued weights λ = {λj}, each of which
represents the weight of a feature.
</bodyText>
<equation confidence="0.9990095">
Z(x) = � exp( m � |s |λifi(x, s′, y)) (2)
s′ i=1 t=1
</equation>
<bodyText confidence="0.93847075">
The inference problem for semi-CRF can be
solved by using a semi-Markov analog of the usu-
al Viterbi algorithm. An implementation of semi-
CRF is available at http://crf.sourceforge.net.
</bodyText>
<page confidence="0.803965">
=1
54
</page>
<subsectionHeader confidence="0.995903">
3.2 Segment-based Emotion Detection Model
</subsectionHeader>
<bodyText confidence="0.999977827586207">
In this subsection, we will describe our segment-
based emotion detection model (see Figure 1).
Assume that we are given a sequence of obser-
vations x = xJ1 =&lt; x1, · · · , xJ &gt; and we would
like to infer a corresponding label yt, where yt E y
is one of the Ekman’s six basic emotion type-
s such as happiness, sadness, fear, surprise, anger
and disgust. Every emotion class is regarded as
a possible emotion tag for the input sentence or
short text with a posterior probability p(y|x).
Our proposed segment-based approach can
be determined in a three-step process: at first, a
sentence or short text is divided into non-fixed
length segments. We construct segment units
from the dependency parse tree of each sentence,
and then build up possible segment candidates
based on those units. More specifically, the
dependency subtrees that contain the path from
the root node (e.g., core verb 照 顾(take care
of)) to leaf node are selected for the candidate
segmentation. For instance, let us consider the
subjective sentence ”善良 的 姑 娘 细心 地 照
这 只 弱 小 的 猫”(Good girl carefully take care
of the small cat). The dependency parse tree of
this sentence is illustrated in Figure 2. We can
select four dependency subtrees (善良的姑娘,照
顾) ( good girl, take care of), (细心地,照顾) (
carefully, take care of), (照 顾,这 只,猫) ( take
care of, the cat), and (照顾,弱小的猫) ( take care
of, the small cat) as the candidate segmentations.
The reason that the dependency representations
are chosen as the segment unit is, compared
with phrase-structure tree, it can describe more
complicated structure information of a sentence
(such as the long distance dependency relation).
Then, we use the segmentation strings as ob-
servations and supply various context-informed
features as inputs to the semi-CRF to assess the
emotion classes of the segment. That is, instead of
determining y directly from x, we introduce hid-
den variables z = (z1, · · · , zm) as intermediate
decision variables, where zi = (si, yi) and yi E {
happiness, sadness, fear, surprise, anger, disgust,
none }, so that yi represents whether si is a phrase
with happiness, sadness, fear, surprise, anger,
or disgust, or none of the above. In the above
example, we can obtain the emotion label of each
segment y =&lt; happy, happy, happy, sad &gt;. At
last, once we determine the intermediate decision
variables, we use a probabilistic model based
on log linear model to combine expression-level
emotion categories. For simplicity, we decompose
the probability by introducing two probability
distribution models: expression-level emotion
detection model and emotion tag distribution
model. Specifically, for the segment-based emo-
tion detection problem, the discriminate function
can be defined as follows:
</bodyText>
<equation confidence="0.89534125">
p(yt|x) = E p(sK1 |x) · p(yK1 |sK1 , x) · p(yt|yK1 , sK1 , x)
s,y
p(yK1 ,sK1 |x) · p(yt|yK1 )
(3)
</equation>
<bodyText confidence="0.998167588235294">
There are two probability distributions:
- Expression-level emotion detection model:
p(y, s|x). This model describes the distribution
of the sequence of segmentation si(1 : k) and its
corresponding emotion tag yi(1 : k). This distri-
bution can be calculated directly by the semi-CRF
model.
- Emotion tag distribution model: p(yt|yK1 ).
This model describes the probability distribution
of the emotion classes. Where yK 1 is expression-
level emotion tag and yt indicates the overall e-
motion tag. This distribution can be calculated by
similar n-gram model.
In this study, we use the maximum a posteriori
estimation with Gaussian priors for parameter es-
timation. The inference problem can be solved by
the Viterbi algorithm.
</bodyText>
<figureCaption confidence="0.9938715">
Figure 1: Graphical presentation for semi-CRF
segment based model
</figureCaption>
<subsectionHeader confidence="0.993411">
3.3 Feature Design
</subsectionHeader>
<bodyText confidence="0.8420536">
We reused features in the original token-based
model based on unigram, POS tags, emotion word
lists and context-informed dependency relations.
Bag-of-words: Surface forms of word unigram-
s and bigrams in the sentence are used as features.
</bodyText>
<equation confidence="0.674778">
K
H
k=1
=E
s,y
</equation>
<page confidence="0.950781">
55
</page>
<figureCaption confidence="0.967055">
Figure 2: A dependency parse tree example. There
are four segment units in the sentence
</figureCaption>
<bodyText confidence="0.991300975609756">
Part-of-speech: The part-of-speech (POS) of
the current word and the surrounding words are
used as a feature for emotion classification.
Content bag-of-words: N (noun), V (verb), JJ
(adjective) words by POS is used as features.
Emotion word lists: This set of features is
based on the emotion-word itself. The emotion
class of a word can be assigned as the word’s pri-
or emotion tag according to the Chinese emotion
lexicon, which is a translation and extension ver-
sion of WordNet-Affect lexicon and its construc-
tion details described as section 4.1.
Dependency relations: This set of features is
binary indicators of whether the leaf phrase in the
dependency parse tree belongs to one of the emo-
tion classes. The dependencies are all binary re-
lations: a grammatical relation holds between a
governor (head) and a dependent (modifier). De-
pendency arcs are stored as 3-tuples of the form
&lt; w1, r, w2 &gt;, denoting occurrences of words w1
and word w2 related by the syntactic dependency
r.
After parsing the sentence and getting the de-
pendencies, we count the following dependency-
tree boolean features for the emotional word, if
this sentence have the emotional words:
- Whether the word is in a ”neg” dependency
(negation modifier): true when there is a negation
word which modifies the emotional word.
- Whether the word is in an ”amod” dependency
(adjectival modifier): true if the emotional word
is (i) a noun modified by an adjective or (ii) an
adjective modifying a noun.
- Whether the word is in an ”advmod” depen-
dency (adverbial modifier): true if the emotion-
al word (i) is a non-clausal adverb or adverbial
phrase which serves to modify the meaning of a
word, or (ii) has been modified by an adverb.
If the sentence has not any emotional word, we
will consider the adjective words and its around
words.
</bodyText>
<sectionHeader confidence="0.986406" genericHeader="evaluation">
4 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.987761">
4.1 Data Construction
</subsectionHeader>
<bodyText confidence="0.998292428571429">
In this subsection, we explain the dataset and lex-
icon used in our experiments. Table 1 shows the
details of the construction dataset, and Figure 3
displays the distribution of the six emotion classes
(happy, fear, sad, surprised, angry, and disgust) in
the corpora. The various corpora and lexicon have
the following origins:
</bodyText>
<listItem confidence="0.8957435">
(1) Chinese emotion lexicon. Currently, there
is not any open and free existing Chinese emotion
</listItem>
<bodyText confidence="0.945280657142857">
lexicon with fine-grained emotion classes. There-
fore, the first resource we need to construct is an
emotional lexicon of Chinese with various emo-
tion categories. The English WordNet Affect lists
(Strapparava et al., 2004) based on Ekman’s six
basic emotion types have adequate number of e-
motion word entries. These English words lists
can be used to convert to Chinese words using En-
glish to Chinese bilingual dictionary or thesaurus.
Our final lexicon contains 1810 entries.
(2) News dataset. This news domain corpus is
created manually by two annotators. The annota-
tion process proceeds as follows: they have been
trained separately and work independently in or-
der to avoid any annotation bias and get a true
understanding of the task difficulty. Each anno-
tator marks the sentence level or short text with
one of six primary emotions (Ekman, 1992), and
then calculate the kappa value to assess such reli-
ability regarding emotion categories with a value
of 0.7 or above it indicating complete agreement.
Disagreements can be annotated by the third one,
then calculate the kappa value.
(3) Alm’s translation dataset. This data set is
based on Alm’s dataset (Alm et al., 2005), which
include annotated sentences from fairy tales, and
five emotion tags (happy, fearful, sad, surprised
and angry-disgusted) from the Ekman’s list of ba-
sic emotions were used for sentences or short tex-
t annotations. The construction process of this
dataset proceeds as follows: firstly, we collec-
t English-Chinese parallel corpora of fairy tales,
and split the text into individual sentences. Sec-
ondly, select Chinese sentences which correspond-
ing translation appeared in Alm’s Dataset accord-
</bodyText>
<page confidence="0.999205">
56
</page>
<tableCaption confidence="0.999605">
Table 1: The dataset entries used in our experiment
</tableCaption>
<figure confidence="0.902302">
Chinese emotion lexicon Alm’s translation dataset News dataset Blog dataset unlabeled corpora
1810 1223 1135 1000 115M
</figure>
<figureCaption confidence="0.994152">
Figure 3: The distribution of the six emotions (happy, fear, sad, surprised, angry, and disgust)in the
corpora
</figureCaption>
<bodyText confidence="0.9927365">
ing to sentence alignment strategy. Lastly, anno-
tate angry and disgusted sentences by manually.
Since Alm’s dataset doesn’t separate the angry and
disgusted categories.
</bodyText>
<listItem confidence="0.869632714285714">
(4) Blog dataset. This dataset consists of
emotion-rich sentences or short text collected
from blogs. These sentences or short text are la-
beled with six emotion tags by two annotators.
The annotation process is the same as that of news
dataset.
(5) Unlabeled corpora. We downloaded addi-
</listItem>
<bodyText confidence="0.917987125">
tional 15M Chinese version of children’s story
from Andersen’s and Green’s fairy tales and 100M
Chinese news dataset to use as the unlabeled set.
We haven’t select blog corpora, because it is noisy.
This allows us to check the performance of each
system on the same kinds of data, and the unla-
beled set and the test set are in the same domain
and have similar underlying feature distributions.
</bodyText>
<subsectionHeader confidence="0.997204">
4.2 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999840714285714">
Given a labeled or an unlabeled data, we first car-
ry out segmentation and part-of-speech (POS) tag-
ging on each sentence or short text using the Stan-
ford toolkit, and then apply a simple word filter
based on POS tags to select content words (noun-
s, verbs, and adjectives). In next step, we create
dependency parse tree produced by the Stanford
dependency parser, and construct dependency sub-
trees. As we all know, the performance of Chinese
dependency parser is not very satisfactory. Hence,
we modify several wrong results manually. We
just want to testify our idea of that the fragments
based on dependency grammar are better than to-
kens.
</bodyText>
<subsectionHeader confidence="0.999283">
4.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.995381083333334">
In this subsection, we report experimental results
on our dataset which contains news dataset, Alm’s
translation dataset and blogs dataset. The entries
of our dataset are short text or sentence. The news
dataset consists of 1135 entries and its average
length is 27.09. The Alm’s translation dataset con-
sist of 1223 entries and its average length 34.76.
The blog dataset contains 1000 entries and its av-
erage length is 30.73. The tasks on the Alm’s
translation dataset may be difficult because the
syntactic structures of the sentences are less re-
stricted and highly variable.
Table 2, Table 3 and Table 4 respectively
shows the accuracy result of our segment-based
method compared to two token-based approach
using SVM and MaxEnt, and a segment-based
method using CRF models (similar to the work
of (Nakagawa et al., 2010)), which employ five
kinds of feature sets (BOW, contentBOW, part-of-
speech, emotion words and dependency relation-
s) and their combination features, setting 10-fold
cross validation as a testing option.
As shown in Table 2-4, we can obtain below
conclusions:
</bodyText>
<listItem confidence="0.468642">
(1) We can see that our approach based on the
</listItem>
<page confidence="0.99913">
57
</page>
<tableCaption confidence="0.997215">
Table 2: Experimental results on news dataset %
</tableCaption>
<table confidence="0.976038857142857">
Feature
BOW
contentBOW
contentBOW+POS
contentBOW+Emotion
contentBOW+Emotion+POS
contentBOW+Emotion+POS+Dependency
SVM MaxEnt CRF Our approach
46.84 46.1 53.29 53.33
48.59 47.8 55 55.74
48.64 47.67 56.78 56.69
51.46 50.7 57.41 58.55
50.2 47.1 58.53 61.53
54.45 54.32 59.06 65.12
</table>
<tableCaption confidence="0.9928">
Table 3: Experimental results on Alm’s translation dataset %
</tableCaption>
<table confidence="0.922704857142857">
Feature
BOW
contentBOW
contentBOW+POS
contentBOW+Emotion
contentBOW+Emotion+POS
contentBOW+Emotion+POS+Dependency
SVM MaxEnt CRF Our approach
39.59 40.30 35.79 40.09
39.98 40.59 35.87 42.11
40.19 38.82 36.05 43.95
45.86 42.26 39.44 46.49
46.15 40.98 41.89 48.95
48.23 45.05 45.68 50.81
</table>
<tableCaption confidence="0.99259">
Table 4: Experimental results on blog dataset %
</tableCaption>
<table confidence="0.782013">
Feature
BOW
contentBOW
contentBOW+POS
contentBOW+Emotion
contentBOW+Emotion+POS
contentBOW+Emotion+POS+Dependency
SVM MaxEnt CRF Our approach
46.09 45.81 44.24 45.62
46.34 46.06 46.33 46.19
46.56 45.93 46.92 47.01
47.92 46.03 47.23 47.63
48.38 45.77 47.98 48.63
50.05 48.12 49.61 53.23
</table>
<bodyText confidence="0.99867405">
segment-based semi-CRF model has the highest
accuracy rate for each dataset using the combina-
tion features of contentBOW + Emotion + POS +
Dependency. Segment-based approach performed
better than token-based approach for the news
dataset, but without expected results for the Alm’s
translation and blogs dataset. This result, on the
one hand, demonstrates that Semi-CRF is more
powerful than CRF, and on the other hand, our e-
motion tag distribution model gives effective re-
sults. For token-based method, SVM gives a bet-
ter result than MaxEnt for all three of our Chinese
corpora.
(2) The accuracy rate of SVM has slightly less
than our model, but the results of MaxEnt and CR-
F is unbalanced. As we notice from table 2 to ta-
ble 4, CRF gives better results on the news dataset
than on the Alm’s translation dataset, but the re-
sults of MaxEnt on all dataset is worst. The rea-
sons for this result may be due to the bias problem
of MaxEnt.
(3) We can observe that using the combination
features of contentBOW + Emotion + POS + De-
pendency has the highest accuracy rate for each
dataset and each classifier. There are two types of
features achieve significantly improvements: emo-
tion words and the dependency relations, for ex-
ample, on news dataset, SVM with contentBOW
has the accuracy rate of 48.59% and adding e-
motion words has the accuracy rate of 51.46%,
showing the improvements of 2.87%. This is not
surprising result since emotion words has key in-
fluence to detection of the emotion category of a
sentence. However, the words or constituents in-
teract with each other to yield the overall emo-
tion label, there exists expression level emotion.
Dependency relationship features can solve this
problem and improve the performance of the sys-
tem,like in the example above,adding Dependen-
cy relationship features has the accuracy rate of
</bodyText>
<page confidence="0.993444">
58
</page>
<bodyText confidence="0.999517111111111">
54.45%, showing the improvements of 5.86%.
When the baseline system use the content-
BOW features, the POS, Emotion and Dependen-
cy representation improve the accuracy rates of the
SVM, CRF and our classifier for each dataset, but
the use of POS representation for the MaxEnt clas-
sifier decreased the accuracy rate compared to the
Emotion and Dependency representations. One
reason lead to this problem might be the quality
of the data we use in this experiment.
(4) Overall performances on the news dataset
are better than on the Alm’s translation dataset
and blogs dataset. The reason perhaps is that the
syntactic structures of the sentences from Alm’s
translation dataset are less restricted and highly
variable, and the sentences from blogs dataset are
noisy, and there exist some linguistic or spelling
error.
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999960095238095">
In this paper, we present a segment-based learning
approach for fine-grained emotion detection. In
this method, the emotion label of each dependen-
cy subtree of a subjective sentence or short text is
represented by a hidden variable. The values of the
hidden variables are calculated in consideration of
interactions between variables whose nodes have
head-modifier relation in the dependency tree. D-
iffer from the existing token-based approach, the
segment-based emotion detection model can si-
multaneously exploit both the linguistic structure
and the expression-level emotion relation embed-
ded in sentences or short text. Three different
dataset, which contains news content, fairly tales,
and blogs data, is constructed to test our proposed
model, and the experimental results show that our
approach performed the best on three emotion cor-
pora and make a statistically significant improve-
ment over other classification algorithms, reflect-
ing its potential usage in the emotion detection
task.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999345819672131">
P. Ekman. 1992. An argumentfor basic emotions Cog-
nition and Emotion, 6(3):169–200.
C. Alm, D. Roth, and R. Sproat. 2005. Emotions
from text: Machine learning for text-based emotion
prediction, In Proceedings of HLT–EMNLP, 579–
586.
Saima Aman and Stan Szpakowicz. 2007. Identifying
Expressions of Emotion in Text, TSD 2007, 196–
205.
Phil Katz, Matthew Singleton, Richard Wicentows-
ki. 2007. SWAT-MP: The SemEval-2007 System-
s for Task 5 and Task 14, Proceedings of the 4th
International Workshop on Semantic Evaluations
(SemEval-2007). Prague,308–313
Karo Moilanen and Stephen Pulman. 2007. Sentiment
Composition, In Proceedings of Recent Advances in
Natural Language Processing.
Yejin Choi and Claire Cardie. 2008. Learning
with Compositional Semantics as Structural Infer-
ence for Subsentential Sentiment Analysis, EMNLP
2008,793–801.
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, Christopher D. Manning. 2011.
Semi-Supervised Recursive Autoencoders for Pre-
dicting Sentiment Distributions, EMNLP 2011,151–
161.
Richard Socher, Brody Huval, Christopher D. Man-
ning, Andrew Y. Ng. 2012. Semantic Composi-
tionality through Recursive Matrix-Vector Spaces,
EMNLP-CoNLL 2012,1201–1211.
Baptiste Chardon, Farah Benamara, Yannick Math-
ieu,Vladimir Popescu, Nicholas Asher. 2013. Senti-
ment Composition Using a Parabolic Model, Pro-
ceedings of the 10th International Conference on
Computational Semantics (IWCS 2013) .
Tetsuji Nakagawa, Kentaro Inui, Sadao Kurohashi.
2010. Dependency Tree-based Sentiment Classifi-
cation using CRFs with Hidden Variables, HLT-
NAACL 2010,786–794.
S. Chaffar and D. Inkpen. 2011. Using a heteroge-
neous dataset for emotion analysis in text, In Cana-
dian Conference on AI,62–67.
S. M. Mohammad. 2012. Portable Features for
Classifying Emotional Text, 2012 Conference of
the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies,587–591.
Matthew Purver and Stuart Battersby. 2012. Experi-
menting with Distant Supervision for Emotion Clas-
sification, Proceedings of the 13th Conference of the
European Chapter of the Association for Computa-
tional Linguistics,482–491.
Ge Xu, Xinfan Meng, Houfeng Wang. 2010. Build
Chinese Emotion Lexicons Using A Graph-based Al-
gorithm and Multiple Resources, In Proceeding of
COLING-10,1209–1217.
Braja Gopal Patra, Hiroya Takamura, Dipankar
Das, Manabu Okumura and Sivaji Bandyopadhyay.
2013. Construction of Emotional Lexicon Using
Potts Model, International Joint Conference on Nat-
ural Language Processing,674–679.
</reference>
<page confidence="0.982873">
59
</page>
<reference confidence="0.999754365853659">
Svitlana Volkova, William B. Dolan, Theresa Wil-
son. 2012. CLex: A Lexicon for Exploring Col-
or, Concept and Emotion Associations in Language,
Proceedings of the 13th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics,306–314.
Ying Chen, Sophia Yat Mei Lee, Shoushan Li, Chu-
Ren Huang. 2010. Emotion Cause Detection
with Linguistic Constructions, Proceedings of the
23rd International Conference on Computational
Linguistics (Coling 2010),179–187.
Ashequl Qadir, Ellen Riloff. 2013. Bootstrapped
Learning of Emotion Hashtags hashtags4you, Pro-
ceedings of the 4th Workshop on Computational Ap-
proaches to Subjectivity, Sentiment and Social Me-
dia Analysis,2–11.
Dipankar Das and Sivaji Bandyopadhyay. 2010. Iden-
tifying Emotional Expressions, Intensities and Sen-
tence level Emotion Tags using a Supervised Frame-
work, PACLIC 2010,95–104.
Diman Ghazi, Diana Inkpen, Stan Szpakowicz. 2012.
Prior versus Contextual Emotion of a Word in a Sen-
tence, Proceedings of the 3rd Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis,70–78.
Sunita Sarawagi, William W. Cohen. 2004. Semi-
Markov Conditional Random Fields for Information
Extraction, NIPS 2004.
Daisuke Okanohara, Yusuke Miyao, Yoshimasa Tsu-
ruoka, Jun’ichi Tsujii. 2006. Improving the Scal-
ability of Semi-Markov Conditional Random Fields
for Named Entity Recognition, ACL 2006,465–472.
Galen Andrew. 2006. A Hybrid Markov/Semi-Markov
Conditional Random Field for Sequence Segmenta-
tion, EMNLP 2006,465–472.
Bishan Yang, Claire Cardie. 2012. Extracting Opinion
Expressions with semi-Markov Conditional Random
Fields, EMNLP-CoNLL 2012,1335–1345.
C Strapparava, A Valitutti. 2004. WordNet-Affect: an
Affective Extension of WordNet, LREC 2004,1083–
1086.
</reference>
<page confidence="0.998389">
60
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.558168">
<title confidence="0.919027">Segment-based Fine-grained Emotion Detection for Chinese Text</title>
<affiliation confidence="0.947856">Dept. Of Automation, University Science and Technology of Institute of Intelligent</affiliation>
<address confidence="0.72213">Chinese Academy of</address>
<email confidence="0.848815">wdbl@iim.ac.cn</email>
<abstract confidence="0.999076625">Emotion detection has been extensively studied in recent years. Current baseline methods often use token-based features which cannot properly capture more complex linguistic phenomena and emotional composition in fine grained emotion detection. A novel supervised learning fine-grained emotion detection model for Chinese text has been proposed in this paper. Different from most existing methods, the proposed model applies the hierarchical structure of sentence (e.g., dependency relationship) and exploits segment-based features. Furthermore, the emotional composition in short text is addressed by using the log linear model. We perform emotion detection on our dataset: news contents, fairly tales, and blog dataset, and compare our proposed method to representative existing approaches. The experimental results demonstrate the effectiveness of the proposed segment-based model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Ekman</author>
</authors>
<title>An argumentfor basic emotions Cognition and Emotion,</title>
<date>1992</date>
<pages>6--3</pages>
<contexts>
<context position="19963" citStr="Ekman, 1992" startWordPosition="3223" endWordPosition="3224">s six basic emotion types have adequate number of emotion word entries. These English words lists can be used to convert to Chinese words using English to Chinese bilingual dictionary or thesaurus. Our final lexicon contains 1810 entries. (2) News dataset. This news domain corpus is created manually by two annotators. The annotation process proceeds as follows: they have been trained separately and work independently in order to avoid any annotation bias and get a true understanding of the task difficulty. Each annotator marks the sentence level or short text with one of six primary emotions (Ekman, 1992), and then calculate the kappa value to assess such reliability regarding emotion categories with a value of 0.7 or above it indicating complete agreement. Disagreements can be annotated by the third one, then calculate the kappa value. (3) Alm’s translation dataset. This data set is based on Alm’s dataset (Alm et al., 2005), which include annotated sentences from fairy tales, and five emotion tags (happy, fearful, sad, surprised and angry-disgusted) from the Ekman’s list of basic emotions were used for sentences or short text annotations. The construction process of this dataset proceeds as f</context>
</contexts>
<marker>Ekman, 1992</marker>
<rawString>P. Ekman. 1992. An argumentfor basic emotions Cognition and Emotion, 6(3):169–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Alm</author>
<author>D Roth</author>
<author>R Sproat</author>
</authors>
<title>Emotions from text: Machine learning for text-based emotion prediction,</title>
<date>2005</date>
<booktitle>In Proceedings of HLT–EMNLP, 579–</booktitle>
<pages>586</pages>
<contexts>
<context position="1721" citStr="Alm et al, 2005" startWordPosition="240" endWordPosition="243">ed segment-based model. 1 Introduction Emotion detection aims to identify fine-grained emotion categories (e.g., happy, angry, disgust, fear, sadness and surprise) of a given text, and it is a challenging and difficult problem with applications throughout natural language processing. Currently, the most widely used probability models for emotion classification are supervised based machine learning algorithms, such as Naive Bayes (NB) and Support Vector Machine (SVM) etc,. Researchers have trained the classifier depends on corpus-based features, mainly unigrams, combined with lexical features (Alm et al, 2005; Aman and Szpakowicz, 2007; Katz, et al, 2007). Nevertheless, these methods used in the emotion Zengfu Wang Dept. Of Automation, University of Science and Technology of China Institute of Intelligent Machines, Chinese Academy of Sciences zfwang@ustc.edu.cn classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance. Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes. (Das and Bandyopadhyay, 2010) obser</context>
<context position="8366" citStr="Alm et al., 2005" startWordPosition="1287" endWordPosition="1290">subtrees and then (2) employ the semiCRFs with various context informed features to assess the emotion classes of the constituents of the segment, and (3) exploit a composition learning model to combine the segment level emotion labels. We evaluate the proposed model on our construction dataset, which consists of news content, fairy tales and blog dataset, and the experimental results show that segment-based learning algorithm works well in our experimental data. 2 Related Work Supervised learning method has been well studied and used in fine-grained emotion detection with promising results. (Alm et al., 2005) explores the text-based emotion prediction problem empirically, using supervised machine learning. (Das and Bandyopadhyay, 2010) deals with the extraction of emotional expressions and tagging of English 53 blog sentences with Ekman’s six basic emotion tags and any of the three intensities: low, medium and high. Baseline system is developed based on WordNet Affect lists and dependency relations. SVM based supervised framework is employed by incorporating different word and context level features. (Chaffar and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic em</context>
<context position="20289" citStr="Alm et al., 2005" startWordPosition="3275" endWordPosition="3278">he annotation process proceeds as follows: they have been trained separately and work independently in order to avoid any annotation bias and get a true understanding of the task difficulty. Each annotator marks the sentence level or short text with one of six primary emotions (Ekman, 1992), and then calculate the kappa value to assess such reliability regarding emotion categories with a value of 0.7 or above it indicating complete agreement. Disagreements can be annotated by the third one, then calculate the kappa value. (3) Alm’s translation dataset. This data set is based on Alm’s dataset (Alm et al., 2005), which include annotated sentences from fairy tales, and five emotion tags (happy, fearful, sad, surprised and angry-disgusted) from the Ekman’s list of basic emotions were used for sentences or short text annotations. The construction process of this dataset proceeds as follows: firstly, we collect English-Chinese parallel corpora of fairy tales, and split the text into individual sentences. Secondly, select Chinese sentences which corresponding translation appeared in Alm’s Dataset accord56 Table 1: The dataset entries used in our experiment Chinese emotion lexicon Alm’s translation dataset</context>
</contexts>
<marker>Alm, Roth, Sproat, 2005</marker>
<rawString>C. Alm, D. Roth, and R. Sproat. 2005. Emotions from text: Machine learning for text-based emotion prediction, In Proceedings of HLT–EMNLP, 579– 586.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saima Aman</author>
<author>Stan Szpakowicz</author>
</authors>
<date>2007</date>
<booktitle>Identifying Expressions of Emotion in Text, TSD</booktitle>
<pages>196--205</pages>
<contexts>
<context position="1748" citStr="Aman and Szpakowicz, 2007" startWordPosition="244" endWordPosition="247">model. 1 Introduction Emotion detection aims to identify fine-grained emotion categories (e.g., happy, angry, disgust, fear, sadness and surprise) of a given text, and it is a challenging and difficult problem with applications throughout natural language processing. Currently, the most widely used probability models for emotion classification are supervised based machine learning algorithms, such as Naive Bayes (NB) and Support Vector Machine (SVM) etc,. Researchers have trained the classifier depends on corpus-based features, mainly unigrams, combined with lexical features (Alm et al, 2005; Aman and Szpakowicz, 2007; Katz, et al, 2007). Nevertheless, these methods used in the emotion Zengfu Wang Dept. Of Automation, University of Science and Technology of China Institute of Intelligent Machines, Chinese Academy of Sciences zfwang@ustc.edu.cn classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance. Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes. (Das and Bandyopadhyay, 2010) observe that the emotion word, P</context>
</contexts>
<marker>Aman, Szpakowicz, 2007</marker>
<rawString>Saima Aman and Stan Szpakowicz. 2007. Identifying Expressions of Emotion in Text, TSD 2007, 196– 205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Katz</author>
<author>Matthew Singleton</author>
<author>Richard Wicentowski</author>
</authors>
<date>2007</date>
<booktitle>SWAT-MP: The SemEval-2007 Systems for Task 5 and Task 14, Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007). Prague,308–313</booktitle>
<contexts>
<context position="1768" citStr="Katz, et al, 2007" startWordPosition="248" endWordPosition="251">on detection aims to identify fine-grained emotion categories (e.g., happy, angry, disgust, fear, sadness and surprise) of a given text, and it is a challenging and difficult problem with applications throughout natural language processing. Currently, the most widely used probability models for emotion classification are supervised based machine learning algorithms, such as Naive Bayes (NB) and Support Vector Machine (SVM) etc,. Researchers have trained the classifier depends on corpus-based features, mainly unigrams, combined with lexical features (Alm et al, 2005; Aman and Szpakowicz, 2007; Katz, et al, 2007). Nevertheless, these methods used in the emotion Zengfu Wang Dept. Of Automation, University of Science and Technology of China Institute of Intelligent Machines, Chinese Academy of Sciences zfwang@ustc.edu.cn classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance. Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes. (Das and Bandyopadhyay, 2010) observe that the emotion word, POS, intensifier and </context>
</contexts>
<marker>Katz, Singleton, Wicentowski, 2007</marker>
<rawString>Phil Katz, Matthew Singleton, Richard Wicentowski. 2007. SWAT-MP: The SemEval-2007 Systems for Task 5 and Task 14, Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007). Prague,308–313</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment Composition,</title>
<date>2007</date>
<booktitle>In Proceedings of Recent Advances in Natural Language Processing.</booktitle>
<contexts>
<context position="3022" citStr="Moilanen and Pulman, 2007" startWordPosition="432" endWordPosition="435">lay an important role in extracting emotional expressions as well as tagging sentences with emotions and intensities. (Diman Ghazi et al., 2012) propose an approach which takes the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. However, these works still use token-based features, which cannot address the problem of the emotional composition, especially those that are the expression-level representations. There has been previous work using composition rules and statistical methods to handle sentiment composition. (Moilanen and Pulman, 2007) propose a theoretical composition model, and evaluate a lexical dependency parsing post-process implementation, which treat both negation and intensifier via three models: sentiment propagation, polarity conflict resolution and polarity reversal. (Choi and Cardie, 2008) incorporate structural inference motivated by compositional semantics into the learning procedure for subsentential sentiment analysis. (Socher et al., 2011, 2012) present matrix-vector representations with a recursive neural network. The model is built on a parse tree where the nodes are associated to a vector. The matrix cap</context>
<context position="10388" citStr="Moilanen and Pulman, 2007" startWordPosition="1587" endWordPosition="1590">ts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Coh</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. 2007. Sentiment Composition, In Proceedings of Recent Advances in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis,</title>
<date>2008</date>
<journal>EMNLP</journal>
<pages>2008--793</pages>
<contexts>
<context position="3293" citStr="Choi and Cardie, 2008" startWordPosition="469" endWordPosition="472">ify sentences by emotion classes. However, these works still use token-based features, which cannot address the problem of the emotional composition, especially those that are the expression-level representations. There has been previous work using composition rules and statistical methods to handle sentiment composition. (Moilanen and Pulman, 2007) propose a theoretical composition model, and evaluate a lexical dependency parsing post-process implementation, which treat both negation and intensifier via three models: sentiment propagation, polarity conflict resolution and polarity reversal. (Choi and Cardie, 2008) incorporate structural inference motivated by compositional semantics into the learning procedure for subsentential sentiment analysis. (Socher et al., 2011, 2012) present matrix-vector representations with a recursive neural network. The model is built on a parse tree where the nodes are associated to a vector. The matrix captures how each constituent modifies its neighbor. (Baptiste Chardon et al,. 2013) propose a computational model that accounts for the effects of negation and modality on opinion expressions. However, it is not as clear how to use a compositional treatment to classify fin</context>
<context position="10411" citStr="Choi and Cardie, 2008" startWordPosition="1591" endWordPosition="1594">to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et </context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with Compositional Semantics as Structural Inference for Subsentential Sentiment Analysis, EMNLP 2008,793–801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Jeffrey Pennington</author>
<author>Eric H Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions,</title>
<date>2011</date>
<journal>EMNLP</journal>
<volume>2011</volume>
<pages>161</pages>
<contexts>
<context position="3450" citStr="Socher et al., 2011" startWordPosition="490" endWordPosition="493"> those that are the expression-level representations. There has been previous work using composition rules and statistical methods to handle sentiment composition. (Moilanen and Pulman, 2007) propose a theoretical composition model, and evaluate a lexical dependency parsing post-process implementation, which treat both negation and intensifier via three models: sentiment propagation, polarity conflict resolution and polarity reversal. (Choi and Cardie, 2008) incorporate structural inference motivated by compositional semantics into the learning procedure for subsentential sentiment analysis. (Socher et al., 2011, 2012) present matrix-vector representations with a recursive neural network. The model is built on a parse tree where the nodes are associated to a vector. The matrix captures how each constituent modifies its neighbor. (Baptiste Chardon et al,. 2013) propose a computational model that accounts for the effects of negation and modality on opinion expressions. However, it is not as clear how to use a compositional treatment to classify fine grained emotion classes. Sentiment composition combines 52 Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 52–6</context>
<context position="10448" citStr="Socher et al., 2011" startWordPosition="1597" endWordPosition="1600">ublic use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et al., 2006; Andrew, 2006; Yang and Car</context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, Christopher D. Manning. 2011. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions, EMNLP 2011,151– 161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic Compositionality through Recursive Matrix-Vector Spaces,</title>
<date>2012</date>
<pages>2012--1201</pages>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, Andrew Y. Ng. 2012. Semantic Compositionality through Recursive Matrix-Vector Spaces, EMNLP-CoNLL 2012,1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baptiste Chardon</author>
<author>Farah Benamara</author>
<author>Yannick Mathieu</author>
<author>Vladimir Popescu</author>
<author>Nicholas Asher</author>
</authors>
<title>Sentiment Composition Using a Parabolic Model,</title>
<date>2013</date>
<booktitle>Proceedings of the 10th International Conference on Computational Semantics (IWCS</booktitle>
<pages>.</pages>
<marker>Chardon, Benamara, Mathieu, Popescu, Asher, 2013</marker>
<rawString>Baptiste Chardon, Farah Benamara, Yannick Mathieu,Vladimir Popescu, Nicholas Asher. 2013. Sentiment Composition Using a Parabolic Model, Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013) .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
</authors>
<title>Kentaro Inui, Sadao Kurohashi.</title>
<date>2010</date>
<journal>HLTNAACL</journal>
<pages>2010--786</pages>
<contexts>
<context position="10427" citStr="Nakagawa, 2010" startWordPosition="1595" endWordPosition="1596">n lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et al., 2006; Andre</context>
</contexts>
<marker>Nakagawa, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, Sadao Kurohashi. 2010. Dependency Tree-based Sentiment Classification using CRFs with Hidden Variables, HLTNAACL 2010,786–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chaffar</author>
<author>D Inkpen</author>
</authors>
<title>Using a heterogeneous dataset for emotion analysis in text,</title>
<date>2011</date>
<booktitle>In Canadian Conference on AI,62–67.</booktitle>
<contexts>
<context position="8894" citStr="Chaffar and Inkpen, 2011" startWordPosition="1365" endWordPosition="1368">ell studied and used in fine-grained emotion detection with promising results. (Alm et al., 2005) explores the text-based emotion prediction problem empirically, using supervised machine learning. (Das and Bandyopadhyay, 2010) deals with the extraction of emotional expressions and tagging of English 53 blog sentences with Ekman’s six basic emotion tags and any of the three intensities: low, medium and high. Baseline system is developed based on WordNet Affect lists and dependency relations. SVM based supervised framework is employed by incorporating different word and context level features. (Chaffar and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. (Saif Mohammad, 2012) uses word-level affect lexicons to provide significant improvements in sentence-level emotion classification. (Purver and Battersby, 2012) describe a set of experiments using automatically labeled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. (Diman Ghazi et al., 201</context>
</contexts>
<marker>Chaffar, Inkpen, 2011</marker>
<rawString>S. Chaffar and D. Inkpen. 2011. Using a heterogeneous dataset for emotion analysis in text, In Canadian Conference on AI,62–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Mohammad</author>
</authors>
<title>Portable Features for Classifying Emotional Text,</title>
<date>2012</date>
<booktitle>Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,587–591.</booktitle>
<contexts>
<context position="9152" citStr="Mohammad, 2012" startWordPosition="1403" endWordPosition="1404">pressions and tagging of English 53 blog sentences with Ekman’s six basic emotion tags and any of the three intensities: low, medium and high. Baseline system is developed based on WordNet Affect lists and dependency relations. SVM based supervised framework is employed by incorporating different word and context level features. (Chaffar and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. (Saif Mohammad, 2012) uses word-level affect lexicons to provide significant improvements in sentence-level emotion classification. (Purver and Battersby, 2012) describe a set of experiments using automatically labeled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. (Diman Ghazi et al., 2012) present a method which enables us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al.,</context>
</contexts>
<marker>Mohammad, 2012</marker>
<rawString>S. M. Mohammad. 2012. Portable Features for Classifying Emotional Text, 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,587–591.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>Stuart Battersby</author>
</authors>
<title>Experimenting with Distant Supervision for Emotion Classification,</title>
<date>2012</date>
<booktitle>Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,482–491.</booktitle>
<contexts>
<context position="9291" citStr="Purver and Battersby, 2012" startWordPosition="1418" endWordPosition="1421">edium and high. Baseline system is developed based on WordNet Affect lists and dependency relations. SVM based supervised framework is employed by incorporating different word and context level features. (Chaffar and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. (Saif Mohammad, 2012) uses word-level affect lexicons to provide significant improvements in sentence-level emotion classification. (Purver and Battersby, 2012) describe a set of experiments using automatically labeled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. (Diman Ghazi et al., 2012) present a method which enables us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al., 2010) adopts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for const</context>
</contexts>
<marker>Purver, Battersby, 2012</marker>
<rawString>Matthew Purver and Stuart Battersby. 2012. Experimenting with Distant Supervision for Emotion Classification, Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,482–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ge Xu</author>
</authors>
<title>Xinfan Meng, Houfeng Wang.</title>
<date>2010</date>
<booktitle>In Proceeding of COLING-10,1209–1217.</booktitle>
<marker>Xu, 2010</marker>
<rawString>Ge Xu, Xinfan Meng, Houfeng Wang. 2010. Build Chinese Emotion Lexicons Using A Graph-based Algorithm and Multiple Resources, In Proceeding of COLING-10,1209–1217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Braja Gopal Patra</author>
</authors>
<title>Hiroya Takamura, Dipankar Das, Manabu Okumura and Sivaji Bandyopadhyay.</title>
<date>2013</date>
<booktitle>Construction of Emotional Lexicon Using Potts Model, International Joint Conference on Natural Language Processing,674–679.</booktitle>
<marker>Patra, 2013</marker>
<rawString>Braja Gopal Patra, Hiroya Takamura, Dipankar Das, Manabu Okumura and Sivaji Bandyopadhyay. 2013. Construction of Emotional Lexicon Using Potts Model, International Joint Conference on Natural Language Processing,674–679.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svitlana Volkova</author>
<author>William B Dolan</author>
<author>Theresa Wilson</author>
</authors>
<title>CLex: A Lexicon for Exploring Color, Concept and Emotion Associations</title>
<date>2012</date>
<booktitle>in Language, Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,306–314.</booktitle>
<contexts>
<context position="10096" citStr="Volkova et al., 2012" startWordPosition="1543" endWordPosition="1546">n Ghazi et al., 2012) present a method which enables us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al., 2010) adopts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmen</context>
</contexts>
<marker>Volkova, Dolan, Wilson, 2012</marker>
<rawString>Svitlana Volkova, William B. Dolan, Theresa Wilson. 2012. CLex: A Lexicon for Exploring Color, Concept and Emotion Associations in Language, Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,306–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>Sophia Yat Mei Lee</author>
<author>Shoushan Li</author>
<author>ChuRen Huang</author>
</authors>
<title>Emotion Cause Detection with Linguistic Constructions,</title>
<date>2010</date>
<booktitle>Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>2010--179</pages>
<contexts>
<context position="10142" citStr="Chen et al., 2010" startWordPosition="1551" endWordPosition="1554">les us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al., 2010) adopts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semi</context>
</contexts>
<marker>Chen, Lee, Li, Huang, 2010</marker>
<rawString>Ying Chen, Sophia Yat Mei Lee, Shoushan Li, ChuRen Huang. 2010. Emotion Cause Detection with Linguistic Constructions, Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),179–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashequl Qadir</author>
<author>Ellen Riloff</author>
</authors>
<title>Bootstrapped Learning of Emotion Hashtags</title>
<date>2013</date>
<booktitle>hashtags4you, Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,2–11.</booktitle>
<contexts>
<context position="10236" citStr="Qadir and Riloff, 2013" startWordPosition="1564" endWordPosition="1567">ce into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al., 2010) adopts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012); emotion causes detection (Chen et al., 2010); and learning hashtags to improve emotion classification performance (Qadir and Riloff, 2013). In sentiment composition, the presence of modalities is generally used to combine the individual positive and negative word (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag co</context>
</contexts>
<marker>Qadir, Riloff, 2013</marker>
<rawString>Ashequl Qadir, Ellen Riloff. 2013. Bootstrapped Learning of Emotion Hashtags hashtags4you, Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis,2–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipankar Das</author>
<author>Sivaji Bandyopadhyay</author>
</authors>
<title>Identifying Emotional Expressions, Intensities and Sentence level Emotion Tags using a Supervised Framework,</title>
<date>2010</date>
<journal>PACLIC</journal>
<pages>2010--95</pages>
<contexts>
<context position="2315" citStr="Das and Bandyopadhyay, 2010" startWordPosition="324" endWordPosition="327"> lexical features (Alm et al, 2005; Aman and Szpakowicz, 2007; Katz, et al, 2007). Nevertheless, these methods used in the emotion Zengfu Wang Dept. Of Automation, University of Science and Technology of China Institute of Intelligent Machines, Chinese Academy of Sciences zfwang@ustc.edu.cn classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance. Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes. (Das and Bandyopadhyay, 2010) observe that the emotion word, POS, intensifier and direct dependency features play an important role in extracting emotional expressions as well as tagging sentences with emotions and intensities. (Diman Ghazi et al., 2012) propose an approach which takes the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. However, these works still use token-based features, which cannot address the problem of the emotional composition, especially those that are the expression-level representations. There has been previous work u</context>
<context position="8495" citStr="Das and Bandyopadhyay, 2010" startWordPosition="1303" endWordPosition="1306">constituents of the segment, and (3) exploit a composition learning model to combine the segment level emotion labels. We evaluate the proposed model on our construction dataset, which consists of news content, fairy tales and blog dataset, and the experimental results show that segment-based learning algorithm works well in our experimental data. 2 Related Work Supervised learning method has been well studied and used in fine-grained emotion detection with promising results. (Alm et al., 2005) explores the text-based emotion prediction problem empirically, using supervised machine learning. (Das and Bandyopadhyay, 2010) deals with the extraction of emotional expressions and tagging of English 53 blog sentences with Ekman’s six basic emotion tags and any of the three intensities: low, medium and high. Baseline system is developed based on WordNet Affect lists and dependency relations. SVM based supervised framework is employed by incorporating different word and context level features. (Chaffar and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines new</context>
</contexts>
<marker>Das, Bandyopadhyay, 2010</marker>
<rawString>Dipankar Das and Sivaji Bandyopadhyay. 2010. Identifying Emotional Expressions, Intensities and Sentence level Emotion Tags using a Supervised Framework, PACLIC 2010,95–104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diman Ghazi</author>
<author>Diana Inkpen</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Prior versus Contextual Emotion of a Word in a Sentence,</title>
<date>2012</date>
<booktitle>Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,70–78.</booktitle>
<contexts>
<context position="2540" citStr="Ghazi et al., 2012" startWordPosition="359" endWordPosition="362"> Machines, Chinese Academy of Sciences zfwang@ustc.edu.cn classification system concentrate on token based features and do not include any linguistic or contextual information, which often yields poor performance. Therefore, recent studies have investigated the approach using contextual information around emotional words to identify fine grained emotion classes. (Das and Bandyopadhyay, 2010) observe that the emotion word, POS, intensifier and direct dependency features play an important role in extracting emotional expressions as well as tagging sentences with emotions and intensities. (Diman Ghazi et al., 2012) propose an approach which takes the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. However, these works still use token-based features, which cannot address the problem of the emotional composition, especially those that are the expression-level representations. There has been previous work using composition rules and statistical methods to handle sentiment composition. (Moilanen and Pulman, 2007) propose a theoretical composition model, and evaluate a lexical dependency parsing post-process implementation, which</context>
<context position="9496" citStr="Ghazi et al., 2012" startWordPosition="1448" endWordPosition="1451">and Inkpen, 2011) adopts a supervised machine learning approach to recognize six basic emotions (anger, disgust, fear, happiness, sadness and surprise) using a heterogeneous emotion-annotated dataset which combines news headlines, fairy tales and blogs. (Saif Mohammad, 2012) uses word-level affect lexicons to provide significant improvements in sentence-level emotion classification. (Purver and Battersby, 2012) describe a set of experiments using automatically labeled data to train supervised classifiers for multi-class emotion detection in Twitter messages with no manual intervention. (Diman Ghazi et al., 2012) present a method which enables us to take the contextual emotion of a word and the syntactic structure of the sentence into account to classify sentences by emotion classes. Other related studies on this task are emotion resource construction. (Xu et al., 2010) adopts a graph-based algorithm to build Chinese emotion lexicons for public use. (Patra et al., 2013) uses the Potts model for constructing emotion lexicon annotated with Ekman’s six basic emotion classes. There are also studies that analyzed the deeper level information, such as color-conceptemotion associations (Volkova et al., 2012)</context>
</contexts>
<marker>Ghazi, Inkpen, Szpakowicz, 2012</marker>
<rawString>Diman Ghazi, Diana Inkpen, Stan Szpakowicz. 2012. Prior versus Contextual Emotion of a Word in a Sentence, Proceedings of the 3rd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,70–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>SemiMarkov Conditional Random Fields for Information Extraction,</title>
<date>2004</date>
<location>NIPS</location>
<contexts>
<context position="7367" citStr="Sarawagi and Cohen, 2004" startWordPosition="1127" endWordPosition="1130">d English subjective sentences using dependency tree-based method. In their method, the sentiment polarity of each dependency subtree, which is not observable in training data, is represented by a hidden variable. The polarity of the whole sentence is calculated in consideration of interactions between the hidden variables. However, this research doesn’t work on the fine grained emotion recognition and it is unable to deal with multiple consecutive tokens (e.g., a phrase). In this paper, we employ semi-Markov conditional random fields (semi-CRFs) for segmentbased emotion detection. Semi-CRFs (Sarawagi and Cohen, 2004) are more powerful than CRFs in that they can assign labels to segments instead of tokens; hence, features can be defined at the segment level. To our knowledge, segment-based fine-grained emotion recognition for Chinese text has not been attempted. Our learning framework can be determined in a three-step process: (1) segment the input sentence or short text into some dependency subtrees and then (2) employ the semiCRFs with various context informed features to assess the emotion classes of the constituents of the segment, and (3) exploit a composition learning model to combine the segment lev</context>
<context position="10996" citStr="Sarawagi and Cohen, 2004" startWordPosition="1682" endWordPosition="1686">and Pulman, 2007; Choi and Cardie, 2008; Nakagawa, 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et al., 2006; Andrew, 2006; Yang and Cardie, 2012). We describe this model in the following section. 3 Segment-based Emotion Detection using semi-CRF In this section, we first introduce the semi-Markov conditional random field and then elaborate the proposed segment-based emotion detection model. 3.1 Semi-CRF In this subsection we briefly review the semiMarkov conditional random field. We follow the definitions in (Sarawagi and Cohen, 2004). Let s = sm1 =&lt; s1, · · · , sm &gt; denote a segmentation of an observed sequence x. To represent all the information associated with each segment</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi, William W. Cohen. 2004. SemiMarkov Conditional Random Fields for Information Extraction, NIPS 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Okanohara</author>
</authors>
<title>Yusuke Miyao, Yoshimasa Tsuruoka, Jun’ichi Tsujii.</title>
<date>2006</date>
<journal>ACL</journal>
<pages>2006--465</pages>
<marker>Okanohara, 2006</marker>
<rawString>Daisuke Okanohara, Yusuke Miyao, Yoshimasa Tsuruoka, Jun’ichi Tsujii. 2006. Improving the Scalability of Semi-Markov Conditional Random Fields for Named Entity Recognition, ACL 2006,465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Galen Andrew</author>
</authors>
<title>A Hybrid Markov/Semi-Markov Conditional Random Field for Sequence Segmentation,</title>
<date>2006</date>
<journal>EMNLP</journal>
<pages>2006--465</pages>
<contexts>
<context position="11034" citStr="Andrew, 2006" startWordPosition="1691" endWordPosition="1693"> 2010; Socher et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et al., 2006; Andrew, 2006; Yang and Cardie, 2012). We describe this model in the following section. 3 Segment-based Emotion Detection using semi-CRF In this section, we first introduce the semi-Markov conditional random field and then elaborate the proposed segment-based emotion detection model. 3.1 Semi-CRF In this subsection we briefly review the semiMarkov conditional random field. We follow the definitions in (Sarawagi and Cohen, 2004). Let s = sm1 =&lt; s1, · · · , sm &gt; denote a segmentation of an observed sequence x. To represent all the information associated with each segmentation, we define si as si =&lt; ti, ui, y</context>
</contexts>
<marker>Andrew, 2006</marker>
<rawString>Galen Andrew. 2006. A Hybrid Markov/Semi-Markov Conditional Random Field for Sequence Segmentation, EMNLP 2006,465–472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Extracting Opinion Expressions with semi-Markov Conditional Random Fields,</title>
<date>2012</date>
<pages>2012--1335</pages>
<contexts>
<context position="11058" citStr="Yang and Cardie, 2012" startWordPosition="1694" endWordPosition="1697">et al., 2011, 2012; Chardon et al,.2013). There is a few works on the higher level of composition in emotion recognition task. Different from above approaches, we use a segment-based method for the fine-grained emotion detection. To use the strengths of segmentbased features, we propose to employ the semiMarkov Conditional Random Field, which was previously used in information extraction to tag continuous segments of input sequences and outperformed conventional CRFs in the task of named entity recognition and opinion extraction (Sarawagi and Cohen, 2004; Okanohara et al., 2006; Andrew, 2006; Yang and Cardie, 2012). We describe this model in the following section. 3 Segment-based Emotion Detection using semi-CRF In this section, we first introduce the semi-Markov conditional random field and then elaborate the proposed segment-based emotion detection model. 3.1 Semi-CRF In this subsection we briefly review the semiMarkov conditional random field. We follow the definitions in (Sarawagi and Cohen, 2004). Let s = sm1 =&lt; s1, · · · , sm &gt; denote a segmentation of an observed sequence x. To represent all the information associated with each segmentation, we define si as si =&lt; ti, ui, yi &gt;, which consisting of</context>
</contexts>
<marker>Yang, Cardie, 2012</marker>
<rawString>Bishan Yang, Claire Cardie. 2012. Extracting Opinion Expressions with semi-Markov Conditional Random Fields, EMNLP-CoNLL 2012,1335–1345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
</authors>
<title>A Valitutti.</title>
<date>2004</date>
<journal>LREC</journal>
<volume>2004</volume>
<pages>1086</pages>
<marker>Strapparava, 2004</marker>
<rawString>C Strapparava, A Valitutti. 2004. WordNet-Affect: an Affective Extension of WordNet, LREC 2004,1083– 1086.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>