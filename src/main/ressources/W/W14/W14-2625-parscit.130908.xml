<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.999087">
A Conceptual Framework for Inferring Implicatures
</title>
<author confidence="0.997268">
Janyce Wiebe Lingjia Deng
</author>
<affiliation confidence="0.999848">
Department of Computer Science Intelligent Systems Program
University of Pittsburgh University of Pittsburgh
</affiliation>
<email confidence="0.997958">
wiebe@cs.pitt.edu lid29@pitt.edu
</email>
<sectionHeader confidence="0.993866" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999702">
While previous sentiment analysis re-
search has concentrated on the interpreta-
tion of explicitly stated opinions and atti-
tudes, this work addresses a type of opin-
ion implicature (i.e., opinion-oriented de-
fault inference) in real-world text. This
work describes a rule-based conceptual
framework for representing and analyzing
opinion implicatures. In the course of un-
derstanding implicatures, the system rec-
ognizes implicit sentiments (and beliefs)
toward various events and entities in the
sentence, often of mixed polarities; thus,
it produces a richer interpretation than is
typical in opinion analysis.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999947815789474">
This paper is a brief introduction to a framework
we have developed for sentiment inference (Wiebe
and Deng, 2014). Overall, the goal of this work is
to make progress toward a deeper automatic inter-
pretation of opinionated language by developing
computational models for the representation and
interpretation of opinion implicature (i.e., opinion-
oriented default inference) in language. In this
paper, we feature a rule-based implementation of
a conceptual framework for opinion implicatures,
specifically implicatures that arise in the presence
of explicit sentiments, and events that positively or
negatively affect entities (goodFor/badFor events).
To eliminate interference introduced by the noisy
output of automatic NLP components, the sys-
tem takes as input manually annotated explicit-
sentiment and event information, and makes in-
ferences based on that input information. Thus,
the purpose of this work is to provide a conceptual
understanding of (a type of) opinion implicature,
to provide a blueprint for realizing fully automatic
systems in the future.
Below, we give terminology, overview the rule-
based system, and then present the rule schemas.
Finally, via discussion of an example from the
MPQA opinion-annotated corpus (Wiebe et al.,
2005)1, we illustrate the potential of the frame-
work for recognizing implicit sentiments and
writer-level sentiments that are not anchored on
clear sentiment words, and for capturing inter-
dependencies among explicit and implicit senti-
ments.
We have developed a graph-based computa-
tional model implementing some rules introduced
below (Deng and Wiebe, 2014). Moreover, in on-
going work, we have proposed an optimization
framework to jointly extract and resolve the input
ambiguities.
</bodyText>
<sectionHeader confidence="0.998444" genericHeader="introduction">
2 Terminology
</sectionHeader>
<bodyText confidence="0.99990719047619">
The building blocks of our opinion implicature
framework are subjectivity, inferred private states,
and benefactive/malefactive events and states.
Subjectivity. Following (Wiebe et al., 2005;
Wiebe, 1994), subjectivity is defined as the ex-
pression of private states in language, where pri-
vate states are mental and emotional states such as
speculations, sentiments, and beliefs (Quirk et al.,
1985). Subjective expressions (i.e., opinions) have
sources (or holders): the entity or entities whose
private states are being expressed. Again follow-
ing (Wiebe et al., 2005; Wiebe, 1994), a private
state is an attitude held by a source toward (op-
tionally) a target. Sentiment and belief are types
of attitudes. Subjectivity is the linguistic expres-
sion of private states. Subjectivity is a pragmatic
notion: as the sentence is interpreted in context,
a private state is attributed to a source in that con-
text (Banfield, 1982). By sentiment expression
or explicit sentiment, we mean a subjective ex-
pression where the attitude type of the expressed
</bodyText>
<footnote confidence="0.999507">
1Available at http://mpqa.cs.pitt.edu
</footnote>
<page confidence="0.997028">
154
</page>
<bodyText confidence="0.994280456521739">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
private state is sentiment.
There are many types of linguistic clues that
contribute to recognizing subjective expressions
(Wiebe, 1994). In the clearest case, some word
senses give rise to subjectivity whenever they are
used in discourse (Wiebe and Mihalcea, 2006).
Other clues are not as definitive. For example, re-
searchers in NLP have begun to develop lexicons
of connotations (Feng et al., 2011), i.e., words as-
sociated with polarities out of context (e.g., war
has negative connotation and sunshine has positive
connotation (Feng et al., 2013)). However, words
may be used in context with polarities opposite to
their connotations, as in Ghenghis Kan likes war.
Inferred Private States and Opinion Implica-
tures. We address private states inferred from
other private states, where the attitude type of both
is sentiment. Inference is initiated by explicit sen-
timent subjectivity. We borrow the term implica-
ture from linguistics, specifically generalized con-
versational implicature. Grice (1967; 1989) intro-
duced the notion to account for how more can be
pragmatically communicated than what is strictly
said - what is implicated vs. what is said (Doran
et al., 2012). Generalized conversational implica-
tures are cancellable, or defeasible.
Analogously, we can treat subjectivity as part
of what is said,2 and the private-state inferences
we address to be part of what is implicated.
Opinion implicatures are default inferences that
may not go through in context.
Benefactive/Malefactive Events and States.
This work addresses sentiments toward, in gen-
eral, states and events which positively or nega-
tively affect entities. Various lexical items and
semantic roles evoke such situations. We adopt
one clear case in this work (Deng et al., 2013):
(agent, event, object) triples, where event nega-
tively (badFor) or positively (goodFor) affects the
object. An event that is goodFor or badFor is a
gfbf event. Note that we have annotated a corpus
with gfbf information and the speaker’s sentiment
toward the agents and objects of gfbf events (Deng
et al., 2013).3
</bodyText>
<footnote confidence="0.984509222222222">
2While the focus in the literature on what is said is se-
mantics, Grice and people later working on the topic ac-
knowledge that what is said must include pragmatics such as
co-reference and indexical resolution (Doran et al., 2012),
and subjectivity arises from deixis (Bruder and Wiebe, 1995;
Stein and Wright, 1995). However, as long as what is said is
conceived of as only truth evaluable propositions, then it is
not exactly the notion for our setting.
3Available at http://mpqa.cs.pitt.edu
</footnote>
<sectionHeader confidence="0.989992" genericHeader="method">
3 Overview
</sectionHeader>
<bodyText confidence="0.999988166666667">
In this section, we give an overview of the rule-
based system to provide an intuitive big picture of
what it can infer, instead of elaborating specific
rules, which will be introduced in Section 4.
The system includes default inference rules
which apply if there is no evidence to the contrary.
It requires as input explicit sentiment and gfbf in-
formation (plus any evidence that is contrary to the
inferences). The data structure of the input and the
output are described in Section 3.1. The rules are
applied repeatedly until no new conclusions can be
drawn. If a rule matches a sentiment or event that
is the target of a private state, the nesting struc-
ture is preserved when generating the conclusions.
We say that inference is carried out in private state
spaces, introduced in Section 3.2. Finally in Sec-
tion 3.3, an example is provided to illustrate what
the system is able to infer.
</bodyText>
<subsectionHeader confidence="0.999678">
3.1 Data Structure
</subsectionHeader>
<bodyText confidence="0.998414666666667">
The system builds a graphical representation of
what it knows and infers about the meaning of
a sentence. A detailed knowledge representation
scheme is presented in (Wiebe and Deng, 2014).
Below is an example from the MPQA corpus.
Ex(1) [He] is therefore planning to trig-
ger [wars] here and there to revive [the
flagging arms industry].
There are two gfbf events in this sentence: (He,
trigger, wars) and (He, revive, arms industry). The
system builds these nodes as input (as printed by
the system):
</bodyText>
<listItem confidence="0.68398775">
8 writer positive believesTrue
4 He revive flagging arms industry
6 writer positive believesTrue
1 He trigger wars
</listItem>
<bodyText confidence="0.999856692307692">
The system’s printout does not show all the
structure of a node. Consider node 8. It has a
source edge to the node representing the writer,
and a target edge to node 4, which in turn has an
agent edge to the node representing He and a ob-
ject edge to the node representing flagging arms
industry. The nodes also have attributes which
record, e.g., what type of node it is (node 8 is a
privateState and node 4 is a gfbf), polarity (if rele-
vant), etc.
The graph is directed. For example, node 4 is
a child of 8. A specification for the input is that
each root node must be a sentiment or believesTrue
</bodyText>
<page confidence="0.99524">
155
</page>
<bodyText confidence="0.99996575">
node whose source is the writer. Inference pro-
ceeds by matching rules to the graph built so far
and, when a rule successfully fires, adding nodes
to the graph.
</bodyText>
<subsectionHeader confidence="0.999846">
3.2 Private State Spaces
</subsectionHeader>
<bodyText confidence="0.999990266666667">
The approach adopted here follows work on rea-
soning in belief spaces and belief ascription in nat-
ural language (Martins and Shapiro, 1983; Rapa-
port, 1986; Slator and Wilks, 1987). Other than
private states of the writer, all propositions and
events must be the target of some private state. In
the simplest case, the writer believes the proposi-
tion or event he/she describes in the document, so
the proposition or event is nested under a writer
positive believesTrue node.
We want to carry out inferences within private
state spaces so that, for example, from S positive
believesTrue P, &amp; P =⇒ Q, the system may in-
fer S positive believesTrue Q. However, we are
working with sentiment, not only belief as in ear-
lier work, and we want to allow, as appropriate,
these types of inferences: from S sentiment to-
ward P, &amp; P =⇒ Q, infer S sentiment toward Q.
For example, if I’m upset my computer is infected
with a virus, then I’m also upset with the conse-
quences (e.g., that my files may be corrupted).
A private state space is defined by a path where
the root is a believesTrue or sentiment node whose
source is the writer, and each node on the path is a
believesTrue or sentiment node. Two paths define
the same private state space if, at each correspond-
ing position, they have the same attitude type, po-
larity, and source. P is in a private state space if P
is the target of the rightmost node on a path defin-
ing that space.
</bodyText>
<subsectionHeader confidence="0.9996">
3.3 An Example
</subsectionHeader>
<bodyText confidence="0.949728454545455">
Now we have introduced the data structure and the
private state spaces, let’s see the potential conclu-
sions which the system can infer before we go into
the detailed rules in the next section.
Ex(2) However, it appears as if [the in-
ternational community (IC)] is tolerat-
ing [the Israeli] campaign of suppres-
sion against [the Palestinians].
The input nodes are the following.
writer negative sentiment
IC positive sentiment
</bodyText>
<subsubsectionHeader confidence="0.454202">
Israeli suppression Palestinians
</subsubsectionHeader>
<bodyText confidence="0.9980957">
The gfbf event (Israeli, suppression,
Palestinians) is a badFor event. According
to the writer, the IC is positive toward the event
in the sense that they tolerate (i.e., protect) it.
However and appears as if are clues that the
writer is negative toward IC’s positive sentiment.
Given these input annotations, the following are
the sentiments inferred by the system just toward
the entities in the sentence; note that many of the
sentiments are nested in private state spaces.
</bodyText>
<table confidence="0.988064894736842">
writer positive sentiment
Palestinians
writer negative sentiment
Israel
writer negative sentiment
IC
writer positive believesTrue
Israel negative sentiment
Palestinians
writer positive believesTrue
IC negative sentiment
Palestinians
writer positive believesTrue
IC positive sentiment
Israel
writer positive believesTrue
IC positive believesTrue
Israel negative sentiment
Palestinians
</table>
<bodyText confidence="0.9993855">
Note that for the sentiments between two enti-
ties other than the writer (e.g., Israel negative to-
ward Palestinians), they are nested under a writer
positive believesTrue node. This shows why we
need private state spaces. The writer expresses
his/her opinion that the sentiment from Israel to-
ward Palestinians is negative, which may not be
true outside the scope of this single document.
</bodyText>
<sectionHeader confidence="0.999105" genericHeader="method">
4 Rules
</sectionHeader>
<bodyText confidence="0.943428785714286">
Rules include preconditions and conclusions.
They may also include assumptions (Hobbs et al.,
1993). For example, suppose a rule would suc-
cessfully fire if an entity S believes P. If the entity
S is not the writer but we know that the writer be-
lieves P, and there is no evidence to the contrary
(i.e. there is no evidence showing that the entity
S doesn’t believe P), then we’ll assume that S be-
lieves it as well, if a rule “asks us to”.
Thus, our rules are conceptually of the form:
P1, ..., Pj : A1,.., Ak/Q1, ..., Qm
where the Ps are preconditions, the As are as-
sumptions, and the Qs are conclusions. For the Qs
to be concluded, the Ps must already hold; there
</bodyText>
<page confidence="0.994921">
156
</page>
<bodyText confidence="0.9968898">
must be a basis for assuming each A; and there
must be no evidence against any of the As or Qs.
Assumptions are indicated using the term “As-
sume”, as in rule 10, which infers sentiment from
connotation:
</bodyText>
<equation confidence="0.7090306">
rule10:
(Assume Writer positive ...
believesTrue) A gfbf T &amp;
T’s anchor is in connotation lexicon =⇒
Writer sentiment toward T
</equation>
<bodyText confidence="0.950389">
The first line contains an assumption, the sec-
ond line contains a precondition, and the third con-
tains a conclusion.
</bodyText>
<figure confidence="0.6134695">
rule8:
S positive believesTrue A gfbf T &amp;
S sentiment toward T =⇒
S sentiment toward A gfbf T
</figure>
<bodyText confidence="0.9983216">
For example, applying rule 8 to “The bill would
curb skyrocketing health care costs,” from the
writer’s (S’s) negative sentiment toward the costs
(T) expressed by skyrocketing, we can infer the
writer is positive toward the event (bill, curb,
costs) (A gfbf T) because it would decrease the
costs.
Note that, in rule 8, the inference is (senti-
ment toward object) =⇒ (sentiment toward event).
Rules 1 and 2 infer in the opposite direction.
</bodyText>
<figure confidence="0.9608275">
rule1:
S sentiment toward A gfbf T =⇒
S sentiment toward idea of A gfbf T
rule2:
S sentiment toward idea of A gfbf T =⇒
S sentiment toward T
</figure>
<bodyText confidence="0.9905323">
For rule 1, why “ideaOf A gfbf T”? Because the
purview of this work is making inferences about
attitudes, not about events themselves. Conceptu-
ally, ideaOf coerces an event into an idea, raising
it into the realm of private-state spaces. Reasoning
about the ideas of events avoids the classification
of whether the events are realis (i.e., whether they
did/will happen).
Rule 9 infers sentiment toward the agent in a
gfbf event.
</bodyText>
<figure confidence="0.926355166666667">
rule9:
S sentiment toward A gfbf T &amp;
A is a thing &amp;
(Assume S positive believesTrue ...
substantial) A gfbf T =⇒
S sentiment toward A
</figure>
<bodyText confidence="0.946546">
By default, the system infers the event is in-
tentional and that the agent is positive toward the
event; if there is evidence against either, the infer-
ence should be blocked.
</bodyText>
<figure confidence="0.967749793103448">
rule6:
A gfbf T, where A is animate =⇒
A intended A gfbf T
rule7:
S intended S gfbf T =⇒
S positive sentiment toward
ideaOf S gfbf T
So far, the preconditions have included only one
sentiment. Rule 3 applies when there are nested
sentiments, i.e., sentiments toward sentiments.
rule3.1:
S1 sentiment toward
S2 sentiment toward Z =⇒
S1 agrees/disagrees with S2 that
isGood/isBad Z &amp;
S1 sentiment toward Z
rule3.2:
S1 sentiment toward
S2 pos/neg believesTrue substantial Z
=⇒
S1 agrees/disagrees with S2 that
isTrue/isFalse Z &amp;
S1 pos/neg believesTrue substantial Z
rule3.3:
S1 sentiment toward
S2 pos/neg believesShould Z =⇒
S1 agrees/disagrees with S2 that
should/shouldNot Z &amp;
S1 pos/neg believesShould Z
</figure>
<bodyText confidence="0.998229444444445">
Among the subcases of rule 3, one shared con-
clusion is S1 agrees/disagrees with S2 *, which de-
pends on the sentiment from S1 toward S2. The
reason there are subcases is because the attitude
types of S2 are various, which determine the in-
ferred attitude type of S1.
By rule 3, given the sentiment between S1 and
S2, we can infer whether S1 and S2 agree. Simi-
larly, we can infer in the opposite direction, as rule
</bodyText>
<equation confidence="0.646392">
4 shows.
rule4:
S1 agrees/disagrees with S2 that * =⇒
S1 sentiment toward S2
</equation>
<bodyText confidence="0.9248545">
Two other rules are given in (Wiebe and Deng,
2014).
</bodyText>
<sectionHeader confidence="0.972474" genericHeader="method">
5 Inferences for An Example from
MPQA Corpus
</sectionHeader>
<bodyText confidence="0.97600725">
This section returns to the example from the
MPQA corpus in Section 3.1, illustrating some in-
teresting inference chains and conclusions.
Recall that the input for Ex(1) in Section 3.1 is:
</bodyText>
<footnote confidence="0.994784">
8 writer positive believesTrue
4 He revive flagging arms industry
6 writer positive believesTrue
1 He trigger wars
</footnote>
<page confidence="0.996158">
157
</page>
<bodyText confidence="0.996816">
The first inference is from connotation to sen-
timent since the word war is in the connotation
lexicon.
</bodyText>
<figure confidence="0.936379090909091">
rule10:
(Assume Writer positive ...
believesTrue) A gfbf T &amp;
T’s anchor is in connotation lexicon =⇒
Writer sentiment toward T
Assumptions:
6 writer positive believesTrue
1 He trigger wars
rule10 =⇒ Infer:
17 writer negative sentiment
2 wars
</figure>
<figureCaption confidence="0.61280175">
From the writer’s negative sentiment toward
wars, the system infers a negative sentiment to-
ward trigger wars, since triggering wars is good-
For them:
</figureCaption>
<figure confidence="0.9446785">
rule8:
S positive believesTrue A gfbf T &amp;
S sentiment toward T =⇒
S sentiment toward A gfbf T
Preconditions:
6 writer positive believesTrue
1 He trigger wars
17 writer negative sentiment
2 wars
rule8 =⇒ Infer:
28 writer negative sentiment
1 He trigger wars
</figure>
<bodyText confidence="0.998626">
On the other hand, since the agent, He, is ani-
mate and there is no evidence to the contrary, the
system infers that the triggering event is inten-
tional, and that He is positive toward the idea of
his performing the event:
</bodyText>
<table confidence="0.977142333333333">
rule6 =⇒ Infer:
38 writer negative sentiment
20 He positive intends
1 He trigger wars
rule7 =⇒ Infer:
41 writer negative sentiment
25 He positive sentiment
26 ideaOf
1 He trigger wars
</table>
<bodyText confidence="0.9907618">
Continuing with inference, since the writer has
a negative sentiment toward the agent’s positive
sentiment, the system infers that the writer dis-
agrees with him (rule 3) and thus that the writer
is negative toward him (rule 4):
</bodyText>
<table confidence="0.851611818181818">
rule3.1:
S1 sentiment toward
S2 sentiment toward Z =⇒
S1 agrees/disagrees with S2 that
isGood/isBad Z &amp;
S1 sentiment toward Z
Preconditions:
41 writer negative sentiment
25 He positive sentiment
26 ideaOf
1 He trigger wars
rule3.1 =⇒ Infer:
50 writer disagrees with He that
49 isGood
26 ideaOf
1 He trigger wars
30 writer negative sentiment
26 ideaOf
1 He trigger wars
Then rule 4 works on node 50 and infers:
rule4 =⇒ Infer:
55 writer negative sentiment
</table>
<sectionHeader confidence="0.652676" genericHeader="method">
3 He
</sectionHeader>
<bodyText confidence="0.99918925">
In addition to the sentiment related to the wars,
we have also drawn several conclusions of senti-
ment toward the arms industry. For example, one
of the output nodes related to the arms industry is:
</bodyText>
<sectionHeader confidence="0.291906666666667" genericHeader="method">
32 writer positive believesTrue
31 He positive sentiment
5 flagging arms industry
</sectionHeader>
<bodyText confidence="0.999934833333333">
The MPQA annotators marked the writer’s neg-
ative sentiment, choosing the long spans therefore
... industry and therefore planning ... here and
there as attitude and expressive subjective element
spans, respectively. They were not able to pinpoint
any clear sentiment phrases. A machine learning
system trained on such examples would have diffi-
culty recognizing the sentiments. The system, re-
lying on the negative connotation of war and the
gfbf information in the sentence, is ultimately able
to infer several sentiments, including the writer’s
negative sentiment toward the trigger event.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999959">
While previous sentiment analysis research has
concentrated on the interpretation of explicitly
stated opinions and attitudes, this work addresses
opinion implicature (i.e., opinion-oriented default
inference) in real-world text. This paper described
a rule-based framework for representing and
analyzing opinion implicatures which we hope
will contribute to deeper automatic interpretation
of subjective language. In the course of under-
standing implicatures, the system recognizes
implicit sentiments (and beliefs) toward various
events and entities in the sentence, often of mixed
polarities; thus, it produces a richer interpretation
than is typical in opinion analysis.
Acknowledgements. This work was supported
in part by DARPA-BAA-12-47 DEFT grant
#12475008 and National Science Foundation
grant #IIS-0916046. We would like to thank the
anonymous reviewers for their feedback.
</bodyText>
<page confidence="0.997594">
158
</page>
<sectionHeader confidence="0.990009" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999466407894737">
Ann Banfield. 1982. Unspeakable Sentences. Rout-
ledge and Kegan Paul, Boston.
G. Bruder and J. Wiebe. 1995. Recognizing subjec-
tivity and identifying subjective characters in third-
person fictional narrative. In Judy Duchan, Gail
Bruder, and Lynne Hewitt, editors, Deixis in Nar-
rative: A Cognitive Science Perspective. Lawrence
Erlbaum Associates.
Lingjia Deng and Janyce Wiebe. 2014. Sentiment
propagation via implicature constraints. In Meeting
of the European Chapter of the Association for Com-
putational Linguistics (EACL-2014).
Lingjia Deng, Yoonjung Choi, and Janyce Wiebe.
2013. Benefactive/malefactive event and writer at-
titude annotation. In Proceedings of the 51stAnnual
Meeting of the Association for Computational Lin-
guistics (Volume 2: Short Papers), pages 120–125,
Sofia, Bulgaria, August. Association for Computa-
tional Linguistics.
Ryan Doran, Gregory Ward, Meredith Larson, Yaron
McNabb, and Rachel E. Baker. 2012. A novel
experimental paradigm for distinguishing between
‘what is said’ and ‘what is implicated’. Language,
88(1):124–154.
Song Feng, Ritwik Bose, and Yejin Choi. 2011. Learn-
ing general connotation of words using graph-based
algorithms. In Proceedings of the 2011 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 1092–1103, Edinburgh, Scotland,
UK., July. Association for Computational Linguis-
tics.
Song Feng, Jun Seok Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash
of sentiment beneath the surface meaning. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics (Volume 1: Long
Papers), pages 1774–1784, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Herbert Paul Grice. 1967. Logic and conversation.
The William James lectures.
H Paul Grice. 1989. Studies in the Way of Words. Har-
vard University Press.
Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt,
and Paul Martin. 1993. Interpretation as abduction.
Artificial Intelligence, 63(1-2):69–142, October.
Jo˜ao Martins and Stuart C. Shapiro. 1983. Reasoning
in multiple belief spaces. In IJCAI.
Randolph Quirk, Sidney Greenbaum, Geoffry Leech,
and Jan Svartvik. 1985. A Comprehensive Gram-
mar of the English Language. Longman, New York.
William J. Rapaport. 1986. Logical foundations for
belief representation. Cognitive Science, 10(4):371–
422.
Brian M. Slator and Yorick Wilks. 1987. Towards se-
mantic structures from dictionary entries. Technical
Report MCCS-87-96, Computing Research Labora-
tory, NMSU.
Dieter Stein and Susan Wright, editors. 1995. Sub-
jectivity and Subjectivisation. Cambridge Univer-
sity Press, Cambridge.
Janyce Wiebe and Lingjia Deng. 2014. An account of
opinion implicatures. arXiv:1404.6491v1 [cs.CL].
Janyce Wiebe and Rada Mihalcea. 2006. Word sense
and subjectivity. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Com-
putational Linguistics, pages 1065–1072, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Eval-
uation (formerly Computers and the Humanities),
39(2/3):164–210.
Janyce Wiebe. 1994. Tracking point of view in narra-
tive. Computational Linguistics, 20(2):233–287.
</reference>
<page confidence="0.998844">
159
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985329">
<title confidence="0.999927">A Conceptual Framework for Inferring Implicatures</title>
<author confidence="0.99512">Janyce Wiebe Lingjia Deng</author>
<affiliation confidence="0.9998685">Department of Computer Science Intelligent Systems Program University of Pittsburgh University of Pittsburgh</affiliation>
<email confidence="0.998916">wiebe@cs.pitt.edulid29@pitt.edu</email>
<abstract confidence="0.99946775">While previous sentiment analysis research has concentrated on the interpretation of explicitly stated opinions and attitudes, this work addresses a type of opinion implicature (i.e., opinion-oriented default inference) in real-world text. This work describes a rule-based conceptual framework for representing and analyzing opinion implicatures. In the course of understanding implicatures, the system recognizes implicit sentiments (and beliefs) toward various events and entities in the sentence, often of mixed polarities; thus, it produces a richer interpretation than is typical in opinion analysis.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Banfield</author>
</authors>
<title>Unspeakable Sentences. Routledge and Kegan Paul,</title>
<date>1982</date>
<location>Boston.</location>
<contexts>
<context position="3512" citStr="Banfield, 1982" startWordPosition="513" endWordPosition="514">ental and emotional states such as speculations, sentiments, and beliefs (Quirk et al., 1985). Subjective expressions (i.e., opinions) have sources (or holders): the entity or entities whose private states are being expressed. Again following (Wiebe et al., 2005; Wiebe, 1994), a private state is an attitude held by a source toward (optionally) a target. Sentiment and belief are types of attitudes. Subjectivity is the linguistic expression of private states. Subjectivity is a pragmatic notion: as the sentence is interpreted in context, a private state is attributed to a source in that context (Banfield, 1982). By sentiment expression or explicit sentiment, we mean a subjective expression where the attitude type of the expressed 1Available at http://mpqa.cs.pitt.edu 154 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they </context>
</contexts>
<marker>Banfield, 1982</marker>
<rawString>Ann Banfield. 1982. Unspeakable Sentences. Routledge and Kegan Paul, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bruder</author>
<author>J Wiebe</author>
</authors>
<title>Recognizing subjectivity and identifying subjective characters in thirdperson fictional narrative.</title>
<date>1995</date>
<editor>In Judy Duchan, Gail Bruder, and Lynne Hewitt, editors,</editor>
<contexts>
<context position="6249" citStr="Bruder and Wiebe, 1995" startWordPosition="933" endWordPosition="936">ng et al., 2013): (agent, event, object) triples, where event negatively (badFor) or positively (goodFor) affects the object. An event that is goodFor or badFor is a gfbf event. Note that we have annotated a corpus with gfbf information and the speaker’s sentiment toward the agents and objects of gfbf events (Deng et al., 2013).3 2While the focus in the literature on what is said is semantics, Grice and people later working on the topic acknowledge that what is said must include pragmatics such as co-reference and indexical resolution (Doran et al., 2012), and subjectivity arises from deixis (Bruder and Wiebe, 1995; Stein and Wright, 1995). However, as long as what is said is conceived of as only truth evaluable propositions, then it is not exactly the notion for our setting. 3Available at http://mpqa.cs.pitt.edu 3 Overview In this section, we give an overview of the rulebased system to provide an intuitive big picture of what it can infer, instead of elaborating specific rules, which will be introduced in Section 4. The system includes default inference rules which apply if there is no evidence to the contrary. It requires as input explicit sentiment and gfbf information (plus any evidence that is cont</context>
</contexts>
<marker>Bruder, Wiebe, 1995</marker>
<rawString>G. Bruder and J. Wiebe. 1995. Recognizing subjectivity and identifying subjective characters in thirdperson fictional narrative. In Judy Duchan, Gail Bruder, and Lynne Hewitt, editors, Deixis in Narrative: A Cognitive Science Perspective. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lingjia Deng</author>
<author>Janyce Wiebe</author>
</authors>
<title>Sentiment propagation via implicature constraints.</title>
<date>2014</date>
<booktitle>In Meeting of the European Chapter of the Association for Computational Linguistics (EACL-2014).</booktitle>
<contexts>
<context position="2452" citStr="Deng and Wiebe, 2014" startWordPosition="349" endWordPosition="352">e, to provide a blueprint for realizing fully automatic systems in the future. Below, we give terminology, overview the rulebased system, and then present the rule schemas. Finally, via discussion of an example from the MPQA opinion-annotated corpus (Wiebe et al., 2005)1, we illustrate the potential of the framework for recognizing implicit sentiments and writer-level sentiments that are not anchored on clear sentiment words, and for capturing interdependencies among explicit and implicit sentiments. We have developed a graph-based computational model implementing some rules introduced below (Deng and Wiebe, 2014). Moreover, in ongoing work, we have proposed an optimization framework to jointly extract and resolve the input ambiguities. 2 Terminology The building blocks of our opinion implicature framework are subjectivity, inferred private states, and benefactive/malefactive events and states. Subjectivity. Following (Wiebe et al., 2005; Wiebe, 1994), subjectivity is defined as the expression of private states in language, where private states are mental and emotional states such as speculations, sentiments, and beliefs (Quirk et al., 1985). Subjective expressions (i.e., opinions) have sources (or hol</context>
</contexts>
<marker>Deng, Wiebe, 2014</marker>
<rawString>Lingjia Deng and Janyce Wiebe. 2014. Sentiment propagation via implicature constraints. In Meeting of the European Chapter of the Association for Computational Linguistics (EACL-2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lingjia Deng</author>
<author>Yoonjung Choi</author>
<author>Janyce Wiebe</author>
</authors>
<title>Benefactive/malefactive event and writer attitude annotation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51stAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>120--125</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="5643" citStr="Deng et al., 2013" startWordPosition="832" endWordPosition="835">ted vs. what is said (Doran et al., 2012). Generalized conversational implicatures are cancellable, or defeasible. Analogously, we can treat subjectivity as part of what is said,2 and the private-state inferences we address to be part of what is implicated. Opinion implicatures are default inferences that may not go through in context. Benefactive/Malefactive Events and States. This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Various lexical items and semantic roles evoke such situations. We adopt one clear case in this work (Deng et al., 2013): (agent, event, object) triples, where event negatively (badFor) or positively (goodFor) affects the object. An event that is goodFor or badFor is a gfbf event. Note that we have annotated a corpus with gfbf information and the speaker’s sentiment toward the agents and objects of gfbf events (Deng et al., 2013).3 2While the focus in the literature on what is said is semantics, Grice and people later working on the topic acknowledge that what is said must include pragmatics such as co-reference and indexical resolution (Doran et al., 2012), and subjectivity arises from deixis (Bruder and Wiebe</context>
</contexts>
<marker>Deng, Choi, Wiebe, 2013</marker>
<rawString>Lingjia Deng, Yoonjung Choi, and Janyce Wiebe. 2013. Benefactive/malefactive event and writer attitude annotation. In Proceedings of the 51stAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 120–125, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Doran</author>
<author>Gregory Ward</author>
<author>Meredith Larson</author>
<author>Yaron McNabb</author>
<author>Rachel E Baker</author>
</authors>
<title>A novel experimental paradigm for distinguishing between ‘what is said’ and ‘what is implicated’.</title>
<date>2012</date>
<journal>Language,</journal>
<volume>88</volume>
<issue>1</issue>
<contexts>
<context position="5066" citStr="Doran et al., 2012" startWordPosition="745" endWordPosition="748">However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967; 1989) introduced the notion to account for how more can be pragmatically communicated than what is strictly said - what is implicated vs. what is said (Doran et al., 2012). Generalized conversational implicatures are cancellable, or defeasible. Analogously, we can treat subjectivity as part of what is said,2 and the private-state inferences we address to be part of what is implicated. Opinion implicatures are default inferences that may not go through in context. Benefactive/Malefactive Events and States. This work addresses sentiments toward, in general, states and events which positively or negatively affect entities. Various lexical items and semantic roles evoke such situations. We adopt one clear case in this work (Deng et al., 2013): (agent, event, object</context>
</contexts>
<marker>Doran, Ward, Larson, McNabb, Baker, 2012</marker>
<rawString>Ryan Doran, Gregory Ward, Meredith Larson, Yaron McNabb, and Rachel E. Baker. 2012. A novel experimental paradigm for distinguishing between ‘what is said’ and ‘what is implicated’. Language, 88(1):124–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Ritwik Bose</author>
<author>Yejin Choi</author>
</authors>
<title>Learning general connotation of words using graph-based algorithms.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1092--1103</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="4295" citStr="Feng et al., 2011" startWordPosition="625" endWordPosition="628">roceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967; </context>
</contexts>
<marker>Feng, Bose, Choi, 2011</marker>
<rawString>Song Feng, Ritwik Bose, and Yejin Choi. 2011. Learning general connotation of words using graph-based algorithms. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1092–1103, Edinburgh, Scotland, UK., July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Seok Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1774--1784</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="4444" citStr="Feng et al., 2013" startWordPosition="648" endWordPosition="651">USA. June 27, 2014. c�2014 Association for Computational Linguistics private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967; 1989) introduced the notion to account for how more can be pragmatically communicated than what is strictly said - what is implicated vs. what is sai</context>
</contexts>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Seok Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1774–1784, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Paul Grice</author>
</authors>
<title>Logic and conversation. The William James lectures.</title>
<date>1967</date>
<contexts>
<context position="4893" citStr="Grice (1967" startWordPosition="716" endWordPosition="717">et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sentiment subjectivity. We borrow the term implicature from linguistics, specifically generalized conversational implicature. Grice (1967; 1989) introduced the notion to account for how more can be pragmatically communicated than what is strictly said - what is implicated vs. what is said (Doran et al., 2012). Generalized conversational implicatures are cancellable, or defeasible. Analogously, we can treat subjectivity as part of what is said,2 and the private-state inferences we address to be part of what is implicated. Opinion implicatures are default inferences that may not go through in context. Benefactive/Malefactive Events and States. This work addresses sentiments toward, in general, states and events which positively o</context>
</contexts>
<marker>Grice, 1967</marker>
<rawString>Herbert Paul Grice. 1967. Logic and conversation. The William James lectures.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Paul Grice</author>
</authors>
<title>Studies in the Way of Words.</title>
<date>1989</date>
<publisher>Harvard University Press.</publisher>
<marker>Grice, 1989</marker>
<rawString>H Paul Grice. 1989. Studies in the Way of Words. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Mark E Stickel</author>
<author>Douglas E Appelt</author>
<author>Paul Martin</author>
</authors>
<title>Interpretation as abduction.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="12024" citStr="Hobbs et al., 1993" startWordPosition="1912" endWordPosition="1915">ue IC positive sentiment Israel writer positive believesTrue IC positive believesTrue Israel negative sentiment Palestinians Note that for the sentiments between two entities other than the writer (e.g., Israel negative toward Palestinians), they are nested under a writer positive believesTrue node. This shows why we need private state spaces. The writer expresses his/her opinion that the sentiment from Israel toward Palestinians is negative, which may not be true outside the scope of this single document. 4 Rules Rules include preconditions and conclusions. They may also include assumptions (Hobbs et al., 1993). For example, suppose a rule would successfully fire if an entity S believes P. If the entity S is not the writer but we know that the writer believes P, and there is no evidence to the contrary (i.e. there is no evidence showing that the entity S doesn’t believe P), then we’ll assume that S believes it as well, if a rule “asks us to”. Thus, our rules are conceptually of the form: P1, ..., Pj : A1,.., Ak/Q1, ..., Qm where the Ps are preconditions, the As are assumptions, and the Qs are conclusions. For the Qs to be concluded, the Ps must already hold; there 156 must be a basis for assuming ea</context>
</contexts>
<marker>Hobbs, Stickel, Appelt, Martin, 1993</marker>
<rawString>Jerry R. Hobbs, Mark E. Stickel, Douglas E. Appelt, and Paul Martin. 1993. Interpretation as abduction. Artificial Intelligence, 63(1-2):69–142, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Martins</author>
<author>Stuart C Shapiro</author>
</authors>
<title>Reasoning in multiple belief spaces.</title>
<date>1983</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="8912" citStr="Martins and Shapiro, 1983" startWordPosition="1400" endWordPosition="1403"> nodes also have attributes which record, e.g., what type of node it is (node 8 is a privateState and node 4 is a gfbf), polarity (if relevant), etc. The graph is directed. For example, node 4 is a child of 8. A specification for the input is that each root node must be a sentiment or believesTrue 155 node whose source is the writer. Inference proceeds by matching rules to the graph built so far and, when a rule successfully fires, adding nodes to the graph. 3.2 Private State Spaces The approach adopted here follows work on reasoning in belief spaces and belief ascription in natural language (Martins and Shapiro, 1983; Rapaport, 1986; Slator and Wilks, 1987). Other than private states of the writer, all propositions and events must be the target of some private state. In the simplest case, the writer believes the proposition or event he/she describes in the document, so the proposition or event is nested under a writer positive believesTrue node. We want to carry out inferences within private state spaces so that, for example, from S positive believesTrue P, &amp; P =⇒ Q, the system may infer S positive believesTrue Q. However, we are working with sentiment, not only belief as in earlier work, and we want to a</context>
</contexts>
<marker>Martins, Shapiro, 1983</marker>
<rawString>Jo˜ao Martins and Stuart C. Shapiro. 1983. Reasoning in multiple belief spaces. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolph Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffry Leech</author>
<author>Jan Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<publisher>Longman,</publisher>
<location>New York.</location>
<contexts>
<context position="2990" citStr="Quirk et al., 1985" startWordPosition="427" endWordPosition="430">mputational model implementing some rules introduced below (Deng and Wiebe, 2014). Moreover, in ongoing work, we have proposed an optimization framework to jointly extract and resolve the input ambiguities. 2 Terminology The building blocks of our opinion implicature framework are subjectivity, inferred private states, and benefactive/malefactive events and states. Subjectivity. Following (Wiebe et al., 2005; Wiebe, 1994), subjectivity is defined as the expression of private states in language, where private states are mental and emotional states such as speculations, sentiments, and beliefs (Quirk et al., 1985). Subjective expressions (i.e., opinions) have sources (or holders): the entity or entities whose private states are being expressed. Again following (Wiebe et al., 2005; Wiebe, 1994), a private state is an attitude held by a source toward (optionally) a target. Sentiment and belief are types of attitudes. Subjectivity is the linguistic expression of private states. Subjectivity is a pragmatic notion: as the sentence is interpreted in context, a private state is attributed to a source in that context (Banfield, 1982). By sentiment expression or explicit sentiment, we mean a subjective expressi</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Randolph Quirk, Sidney Greenbaum, Geoffry Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William J Rapaport</author>
</authors>
<title>Logical foundations for belief representation.</title>
<date>1986</date>
<journal>Cognitive Science,</journal>
<volume>10</volume>
<issue>4</issue>
<pages>422</pages>
<contexts>
<context position="8928" citStr="Rapaport, 1986" startWordPosition="1404" endWordPosition="1406"> which record, e.g., what type of node it is (node 8 is a privateState and node 4 is a gfbf), polarity (if relevant), etc. The graph is directed. For example, node 4 is a child of 8. A specification for the input is that each root node must be a sentiment or believesTrue 155 node whose source is the writer. Inference proceeds by matching rules to the graph built so far and, when a rule successfully fires, adding nodes to the graph. 3.2 Private State Spaces The approach adopted here follows work on reasoning in belief spaces and belief ascription in natural language (Martins and Shapiro, 1983; Rapaport, 1986; Slator and Wilks, 1987). Other than private states of the writer, all propositions and events must be the target of some private state. In the simplest case, the writer believes the proposition or event he/she describes in the document, so the proposition or event is nested under a writer positive believesTrue node. We want to carry out inferences within private state spaces so that, for example, from S positive believesTrue P, &amp; P =⇒ Q, the system may infer S positive believesTrue Q. However, we are working with sentiment, not only belief as in earlier work, and we want to allow, as appropr</context>
</contexts>
<marker>Rapaport, 1986</marker>
<rawString>William J. Rapaport. 1986. Logical foundations for belief representation. Cognitive Science, 10(4):371– 422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian M Slator</author>
<author>Yorick Wilks</author>
</authors>
<title>Towards semantic structures from dictionary entries.</title>
<date>1987</date>
<tech>Technical Report MCCS-87-96,</tech>
<institution>Computing Research Laboratory, NMSU.</institution>
<contexts>
<context position="8953" citStr="Slator and Wilks, 1987" startWordPosition="1407" endWordPosition="1410">.g., what type of node it is (node 8 is a privateState and node 4 is a gfbf), polarity (if relevant), etc. The graph is directed. For example, node 4 is a child of 8. A specification for the input is that each root node must be a sentiment or believesTrue 155 node whose source is the writer. Inference proceeds by matching rules to the graph built so far and, when a rule successfully fires, adding nodes to the graph. 3.2 Private State Spaces The approach adopted here follows work on reasoning in belief spaces and belief ascription in natural language (Martins and Shapiro, 1983; Rapaport, 1986; Slator and Wilks, 1987). Other than private states of the writer, all propositions and events must be the target of some private state. In the simplest case, the writer believes the proposition or event he/she describes in the document, so the proposition or event is nested under a writer positive believesTrue node. We want to carry out inferences within private state spaces so that, for example, from S positive believesTrue P, &amp; P =⇒ Q, the system may infer S positive believesTrue Q. However, we are working with sentiment, not only belief as in earlier work, and we want to allow, as appropriate, these types of infe</context>
</contexts>
<marker>Slator, Wilks, 1987</marker>
<rawString>Brian M. Slator and Yorick Wilks. 1987. Towards semantic structures from dictionary entries. Technical Report MCCS-87-96, Computing Research Laboratory, NMSU.</rawString>
</citation>
<citation valid="true">
<title>Subjectivity and Subjectivisation.</title>
<date>1995</date>
<editor>Dieter Stein and Susan Wright, editors.</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<marker>1995</marker>
<rawString>Dieter Stein and Susan Wright, editors. 1995. Subjectivity and Subjectivisation. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Lingjia Deng</author>
</authors>
<title>An account of opinion implicatures.</title>
<date>2014</date>
<note>arXiv:1404.6491v1 [cs.CL].</note>
<contexts>
<context position="962" citStr="Wiebe and Deng, 2014" startWordPosition="131" endWordPosition="134">d attitudes, this work addresses a type of opinion implicature (i.e., opinion-oriented default inference) in real-world text. This work describes a rule-based conceptual framework for representing and analyzing opinion implicatures. In the course of understanding implicatures, the system recognizes implicit sentiments (and beliefs) toward various events and entities in the sentence, often of mixed polarities; thus, it produces a richer interpretation than is typical in opinion analysis. 1 Introduction This paper is a brief introduction to a framework we have developed for sentiment inference (Wiebe and Deng, 2014). Overall, the goal of this work is to make progress toward a deeper automatic interpretation of opinionated language by developing computational models for the representation and interpretation of opinion implicature (i.e., opinionoriented default inference) in language. In this paper, we feature a rule-based implementation of a conceptual framework for opinion implicatures, specifically implicatures that arise in the presence of explicit sentiments, and events that positively or negatively affect entities (goodFor/badFor events). To eliminate interference introduced by the noisy output of au</context>
<context position="7559" citStr="Wiebe and Deng, 2014" startWordPosition="1155" endWordPosition="1158">Section 3.1. The rules are applied repeatedly until no new conclusions can be drawn. If a rule matches a sentiment or event that is the target of a private state, the nesting structure is preserved when generating the conclusions. We say that inference is carried out in private state spaces, introduced in Section 3.2. Finally in Section 3.3, an example is provided to illustrate what the system is able to infer. 3.1 Data Structure The system builds a graphical representation of what it knows and infers about the meaning of a sentence. A detailed knowledge representation scheme is presented in (Wiebe and Deng, 2014). Below is an example from the MPQA corpus. Ex(1) [He] is therefore planning to trigger [wars] here and there to revive [the flagging arms industry]. There are two gfbf events in this sentence: (He, trigger, wars) and (He, revive, arms industry). The system builds these nodes as input (as printed by the system): 8 writer positive believesTrue 4 He revive flagging arms industry 6 writer positive believesTrue 1 He trigger wars The system’s printout does not show all the structure of a node. Consider node 8. It has a source edge to the node representing the writer, and a target edge to node 4, wh</context>
<context position="15697" citStr="Wiebe and Deng, 2014" startWordPosition="2573" endWordPosition="2576">1 agrees/disagrees with S2 that should/shouldNot Z &amp; S1 pos/neg believesShould Z Among the subcases of rule 3, one shared conclusion is S1 agrees/disagrees with S2 *, which depends on the sentiment from S1 toward S2. The reason there are subcases is because the attitude types of S2 are various, which determine the inferred attitude type of S1. By rule 3, given the sentiment between S1 and S2, we can infer whether S1 and S2 agree. Similarly, we can infer in the opposite direction, as rule 4 shows. rule4: S1 agrees/disagrees with S2 that * =⇒ S1 sentiment toward S2 Two other rules are given in (Wiebe and Deng, 2014). 5 Inferences for An Example from MPQA Corpus This section returns to the example from the MPQA corpus in Section 3.1, illustrating some interesting inference chains and conclusions. Recall that the input for Ex(1) in Section 3.1 is: 8 writer positive believesTrue 4 He revive flagging arms industry 6 writer positive believesTrue 1 He trigger wars 157 The first inference is from connotation to sentiment since the word war is in the connotation lexicon. rule10: (Assume Writer positive ... believesTrue) A gfbf T &amp; T’s anchor is in connotation lexicon =⇒ Writer sentiment toward T Assumptions: 6 w</context>
</contexts>
<marker>Wiebe, Deng, 2014</marker>
<rawString>Janyce Wiebe and Lingjia Deng. 2014. An account of opinion implicatures. arXiv:1404.6491v1 [cs.CL].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1065--1072</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="4160" citStr="Wiebe and Mihalcea, 2006" startWordPosition="602" endWordPosition="605">on or explicit sentiment, we mean a subjective expression where the attitude type of the expressed 1Available at http://mpqa.cs.pitt.edu 154 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private states inferred from other private states, where the attitude type of both is sentiment. Inference is initiated by explicit sent</context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 1065–1072, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language.</title>
<date>2005</date>
<booktitle>Language Resources and Evaluation (formerly Computers and the Humanities),</booktitle>
<pages>39--2</pages>
<contexts>
<context position="2101" citStr="Wiebe et al., 2005" startWordPosition="298" endWordPosition="301">r/badFor events). To eliminate interference introduced by the noisy output of automatic NLP components, the system takes as input manually annotated explicitsentiment and event information, and makes inferences based on that input information. Thus, the purpose of this work is to provide a conceptual understanding of (a type of) opinion implicature, to provide a blueprint for realizing fully automatic systems in the future. Below, we give terminology, overview the rulebased system, and then present the rule schemas. Finally, via discussion of an example from the MPQA opinion-annotated corpus (Wiebe et al., 2005)1, we illustrate the potential of the framework for recognizing implicit sentiments and writer-level sentiments that are not anchored on clear sentiment words, and for capturing interdependencies among explicit and implicit sentiments. We have developed a graph-based computational model implementing some rules introduced below (Deng and Wiebe, 2014). Moreover, in ongoing work, we have proposed an optimization framework to jointly extract and resolve the input ambiguities. 2 Terminology The building blocks of our opinion implicature framework are subjectivity, inferred private states, and benef</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation (formerly Computers and the Humanities), 39(2/3):164–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
</authors>
<title>Tracking point of view in narrative.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="2796" citStr="Wiebe, 1994" startWordPosition="398" endWordPosition="399"> and writer-level sentiments that are not anchored on clear sentiment words, and for capturing interdependencies among explicit and implicit sentiments. We have developed a graph-based computational model implementing some rules introduced below (Deng and Wiebe, 2014). Moreover, in ongoing work, we have proposed an optimization framework to jointly extract and resolve the input ambiguities. 2 Terminology The building blocks of our opinion implicature framework are subjectivity, inferred private states, and benefactive/malefactive events and states. Subjectivity. Following (Wiebe et al., 2005; Wiebe, 1994), subjectivity is defined as the expression of private states in language, where private states are mental and emotional states such as speculations, sentiments, and beliefs (Quirk et al., 1985). Subjective expressions (i.e., opinions) have sources (or holders): the entity or entities whose private states are being expressed. Again following (Wiebe et al., 2005; Wiebe, 1994), a private state is an attitude held by a source toward (optionally) a target. Sentiment and belief are types of attitudes. Subjectivity is the linguistic expression of private states. Subjectivity is a pragmatic notion: a</context>
<context position="4031" citStr="Wiebe, 1994" startWordPosition="583" endWordPosition="584">preted in context, a private state is attributed to a source in that context (Banfield, 1982). By sentiment expression or explicit sentiment, we mean a subjective expression where the attitude type of the expressed 1Available at http://mpqa.cs.pitt.edu 154 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 154–159, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics private state is sentiment. There are many types of linguistic clues that contribute to recognizing subjective expressions (Wiebe, 1994). In the clearest case, some word senses give rise to subjectivity whenever they are used in discourse (Wiebe and Mihalcea, 2006). Other clues are not as definitive. For example, researchers in NLP have begun to develop lexicons of connotations (Feng et al., 2011), i.e., words associated with polarities out of context (e.g., war has negative connotation and sunshine has positive connotation (Feng et al., 2013)). However, words may be used in context with polarities opposite to their connotations, as in Ghenghis Kan likes war. Inferred Private States and Opinion Implicatures. We address private</context>
</contexts>
<marker>Wiebe, 1994</marker>
<rawString>Janyce Wiebe. 1994. Tracking point of view in narrative. Computational Linguistics, 20(2):233–287.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>