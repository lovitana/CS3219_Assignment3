<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.997069">
Improving Chinese Sentence Polarity Classification
via Opinion Paraphrasing
</title>
<author confidence="0.976685">
Guohong Fu, Yu He, Jiaying Song, Chaoyue Wang
</author>
<affiliation confidence="0.942095">
Heilongjiang University, Harbin 150080, China
</affiliation>
<email confidence="0.907164">
ghfu@hlju.edu.cn, heyucs@yahoo.com, jy_song@outlook.com,
chaoyue.wang@yahoo.cn
</email>
<sectionHeader confidence="0.994166" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999458210526316">
While substantial studies have been achieved
on sentiment polarity classification to date,
lacking enough opinion-annotated corpora for
reliable training is still a challenge. In this
paper we propose to improve a supported
vector machines based polarity classifier by
enriching both training data and test data via
opinion paraphrasing. In particular, we first
extract an equivalent set of attribute-
evaluation pairs from the training data and
then exploit it to generate opinion para-
phrases in order to expand the training corpus
or enrich opinionated sentences for polarity
classification. We tested our system over two
sets of online product reviews in car and mo-
bilephone domains. The experimental results
show that using opinion paraphrases results
in significant performance improvement in
polarity classification.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959327868853">
With the explosive growth of the user-generated
opinionated texts on the web over the past years,
opinion mining has been attracting an ever-
increasing amount of attention from the natural
language processing community. As a key sub-
problem of opinion mining, sentiment polarity
classification aims to classify opinionated docu-
ments or sentences as expressing positive, nega-
tive or neutral opinions, and plays a critical role
in many opinion mining applications such as
opinion summarization and opinion question an-
swering. Since sentence is usually considered as
the smallest semantic unit for expressing the
complete opinion, the current study focused on
the sentence sentiment classification.
Although recent years have seen a great pro-
gress in sentiment classification, lacking large-
scale opinion-annotated corpora is still a funda-
mental issue. On the one hand, statistically-based
methods become the mainstream in sentiment
analysis. In general, a statistically-based polarity
classifier needs an annotated corpus for training.
So its performance heavily relies on the training
corpus used. On the other hand, to date there are
no any large-scale annotated corpora available
for achieving reliable training process. Further-
more, opinion mining is usually domain specific.
Obviously, it is time and cost consuming to
manually construct a large-scale opinion-
annotated corpus for each domain.
To address the above problems, in this paper
we propose to improve polarity classification by
enriching both training data and test data via par-
aphrasing. We have two motivations for this.
Firstly, paraphrasing has proven to be an effec-
tive tool for improve the coverage of systems and
has been successfully used in many applications
such as machine translation, information retrieval
and question answering (Bhagat and Hovy, 2013;
Heilman and Smith, 2010; Zhao et al., 2013;
Fader et al., 2013). However, to date, there has
been very limited study on sentiment or opinion
paraphrasing. Secondly, unlike opinion corpus
annotation, paraphrases are relatively more flexi-
ble to acquire using different resources like syn-
onym lexica, bilingual and parallel corpora, and
so forth. Therefore, we believe that paraphrasing
would be a feasible way to expand the training
corpus and at the same time, to alleviate the data
sparse problem in statistically-based systems. As
such, the purpose of this study is to ascertain the
effect of using opinion paraphrases in polarity
classification at sentence level. To approach this,
we first extract an equivalent set of attribute-
evaluation pairs from the training data and then
exploit it to generate opinion paraphrases in or-
der to expand the training corpus or enrich opin-
ionated sentences for polarity classification.
Based on the generated opinion paraphrases, we
also develop a polarity classification system for
Chinese under the framework of support vector
</bodyText>
<page confidence="0.581587">
35
</page>
<note confidence="0.996886">
Proceedings of the Third CIPS-SIGHAN Joint Conference on Chinese Language Processing, pages 35–42,
Wuhan, China, 20-21 October 2014
</note>
<bodyText confidence="0.9995466875">
machines (SVMs). Experimental results over two
sets of online reviews on car and mobilephone
products show that using the paraphrases gener-
ated by the proposed method can significantly
improve the performance of sentence polarity
classification.
The rests of the paper proceed as follows. Sec-
tion 2 provides a brief review of the literature on
sentiment classification and paraphrase genera-
tion. Section 3 describes in details the proposed
method to Chinese sentence polarity classifica-
tion via paraphrasing. Section 4 reports our ex-
perimental results on two sets of product reviews.
Finally, section 5 concludes our work and dis-
cusses some possible directions for future re-
search.
</bodyText>
<sectionHeader confidence="0.999784" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999941960784314">
Polarity classification is usually formulated as a
binary classification problem (Turney, 2002;
Pang and Lee, 2008). Most previous studies em-
ploy supervised machine learning methods, in-
cluding naïve Bayes model, support vector ma-
chines (SVMs), maximum entropy models
(MEMs), conditional random fields (CRFs),
fuzzy sets, and so forth (Pang et al., 2002; Pang
and Lee, 2008;Fu and Wang, 2010), to perform
polarity classification on different linguistic lev-
els such words, phrases, sentences and docu-
ments.
Lacking a large scale manually-annotated cor-
pus is one of the major bottlenecks that super-
vised machine learning methods faced. To break
this bottleneck, some recent studies exploit boot-
strapping or unsupervised techniques (Turney,
2002; Mihalcea et al., 2007; Wilson et al., 2009,
Speriosu et al. 2011, Mehrotra et al. 2012;
Volkova et al., 2013). Unfortunately, sentiment
classifiers based on unsupervised methods usual-
ly yield worse performance compared to the su-
pervised ones.
Different from most existing studies, in this
study we attempt to enhance Chinese sentence
polarity classifier by exploring opinion para-
phrasing. We believe that paraphrasing provides
us with an option to expand training corpora and
to enrich opinion sentences for polarity classifi-
cation, which would alleviate the problem of data
sparseness and lack of annotated corpora for
training. At this point, our current study is also
relevant to paraphrasing tasks, including para-
phrase recognition, paraphrase extraction and
paraphrase generation. Although a variety of
methods, from dictionary-based methods to data-
driven methods (Madnani and Dorr, 2010), have
been proposed for paraphrasing. Since in the pre-
sent study we aim to answer the question wheth-
er the use of paraphrasing can enhance polarity
classification performance, we do not want to
look insight into paraphrasing issues. Instead, we
just exploit some simple but efficient paraphras-
ing techniques to achieve opinion paraphrases for
expanding training data and enriching text data
for polarity classification, including opinion par-
aphrase extraction incorporating the Jaccard con-
efficient based literal similarity with the word
embedding based semantic similarity, and opin-
ion paraphrase generation with opinion element
substitution.
</bodyText>
<sectionHeader confidence="0.974205" genericHeader="method">
3 The Proposed Method
</sectionHeader>
<subsectionHeader confidence="0.8604">
3.1 Overview
</subsectionHeader>
<figure confidence="0.997873166666667">
Input: An
opinionated
sentence
Preprocessing
Paraphrase generation
Paraphrase extraction
Paraphrase Lib
Original train-
ing corpus
SVMs-based polarity classifier
SVM models
SVMs training
Polarity conflict resolution
Output:
Polarity
Expanded
training corpus
Paraphrase generation
</figure>
<figureCaption confidence="0.999915">
Figure 1. The overall framework of the proposed method to Chinese polarity classification.
</figureCaption>
<page confidence="0.71691">
36
</page>
<bodyText confidence="0.996423853658537">
Figure 1 presents the general framework for Chi-
nese polarity classification via opinion para-
phrasing, mainly including paraphrase extraction,
training corpus expansion via paraphrase genera-
tion and the SVMs-based polarity classifier with
paraphrasing.
Training corpus expansion. For each opin-
ionated sentence from the original corpus for
training, we first generate a set of suitable para-
phrases and thus expand the training corpus by
adding these generated paraphrases into it.
Paraphrase extraction. To achieve opinion
element substitution based paraphrasing, we need
to extract a set of equivalent attribute-evaluation
pairs from the training corpus. In the present
study, we incorporate literal similarity and word
embedding-based semantic similarity between
two coreferred product attributes with the polari-
ty of the paired evaluation expressions to per-
form attribute-evaluation clustering.
Paraphrase generation. With regard to the
focus of the current study, we generate sentential
paraphrases by simply substituting opinion ele-
ments such as product attributes and their evalua-
tions in the original sentence with their respec-
tive semantic equivalents.
SVMs-based polarity classifier. We perform
sentence polarity classification using supported
vector machines (SVMs) trained from the ex-
panded training data via opinion paraphrasing.
Polarity conflict resolution. To avoid data
sparseness, in the present study we perform par-
aphrasing on the input opinionated sentences in
test before polarity classification. As a conse-
quence, this may cause polarity conflicts be-
tween the original input sentences and their par-
aphrases after polarity classification. To address
this problem, we employ a rule-based voting
method.
In Sections 3.2 to 3.5, we provide the details
of our implementation.
</bodyText>
<subsectionHeader confidence="0.999425">
3.2 Paraphrases in Product Reviews
</subsectionHeader>
<bodyText confidence="0.999977971428571">
Before describing the techniques for paraphrase
extraction and generation, it is necessary to clari-
fy what a paraphrase is for product reviews. In
linguistics literature, paraphrases are most often
referred to as an approximate equivalence of
meaning across sentences or phrases (Bhagat and
Hovy, 2013). In the present study we character-
ize opinion paraphrases from the perspective of
opinion elements. In general, opinion infor-
mation consists of five main elements, namely
opinion source (viz. opinion holder), opinion
target, attribute, evaluation and polarity. Thus,
the opinion element perspective defines para-
phrases in terms of the kinds of opinion element
changes that can take place in an opinionated
sentence resulting in the generation of its para-
phrases. Considering the characteristics of prod-
uct reviews, here we focus on product attributes
and their relevant evaluations within opinionated
sentences in determining whether they are para-
phrasing each other. Thus, two opinion sentences
that contain the same or similar attribute-
evaluation pairs are termed as opinion para-
phrases.
With regard to semantic equivalence between
attributions and evaluations within opinion ex-
pressions, we can thus classify paraphrases in
product reviews into four main types, as shown
in Table 1. Based on this, given two different
opinionated sentences, if they involve identical
or coreferred attributions, and at the same time,
their corresponding evaluations are identical or
approximately equivalent with respect to senti-
ment polarity, then the two opinionated sentenc-
es are considered to be paraphrastic.
</bodyText>
<tableCaption confidence="0.998096">
Table 1. Categorization of opinion paraphrases in product reviews
</tableCaption>
<table confidence="0.829934">
Types Attributes Evaluations Examples
1 exactly exactly identical 操控性非常好(The controllability is very good.)
identical 该车的操控性非常好。(The controllability of this car is very good.)
2 exactly semantically 手感不错 (hand feeling is not bad)
identical equivalent 手感好 (hand feeling good)
3 coreferent exactly identical 性价比真高(The cost-performance ratio is really high)
性能价格比真高(The cost-performance ratio is really high)
4 coreferent semantically 质地真不错 (The texture is really good)
equivalent 材质挺好 (The material is very good)
</table>
<subsectionHeader confidence="0.998346">
3.3 Paraphrase Extraction
</subsectionHeader>
<bodyText confidence="0.9999615">
Since the definition of opinion paraphrase is
based on the equivalence of attributes and their
corresponding evaluations within opinionated
sentences, attribute-evaluation pairs are very im-
portant knowledge for substitution-based para-
phrase generation. To obtain such knowledge for
</bodyText>
<page confidence="0.816403">
37
</page>
<bodyText confidence="0.999983352941176">
opinion paraphrasing, we first extract all attrib-
ute-evaluation pairs from the training corpus and
further cluster them in terms of attribute corefer-
ence relation and the polarity. Given two differ-
ent attribute-evaluation pairs, if the attributes are
coreferred each other and at the same time, the
relevant polarity are identical, then the two at-
tribute-evaluation pairs are paraphrastic and can
be grouped to a cluster.
Due to the fact that polarity information has
been manually annotated in the training corpora,
attribute coreference resolution becomes the key
to attribution-evaluation grouping. To address
this problem, we combine two similarity
measures, namely the literal similarity based on
Jacard coefficient and the semantic similarity
based on word embeddings.
</bodyText>
<listItem confidence="0.870277333333333">
(1) Literal similarity. As shown in Equation
(1), Jaccard coefficient measures (denoted by J)
the literal similarity of two attribute expressions
A1 and A2 by counting the number of identical
characters contained in them.
(1)
</listItem>
<bodyText confidence="0.960821">
Where, set(A) denotes the set of characters
that form the attribute A.
It should be noted that unlike the classical edit
distance, Jaccard coefficient ignores the influ-
ence of character location in attributes. Consider-
ing two pairs of Chinese attributes (A*, ARI_)
_)
and (A, �A), their respective Jaccard coeffi-
cients are 0.33 and 1.
(2) Semantic similarity. Literal similarity
measures rely on literal matching and work for
product attributes with explicit literal connec-
tions. However, such information does not al-
ways exit in many co-referred feature expres-
sions like * (pixel) and 3 0)f* (resolution).
To address this problem, we introduce semantic
similarity based on word embeddings. Actually,
word embeddings map each word to an n-
dimensional dense vector of real numbers and
each dimension has certain latent semantic in-
formation (Mikolov, 2012; Mikolov et al., 2013).
Obviously, the data size has a strong relationship
with the expression of semantic. Thus, we can
obtain the similarity between two product attrib-
utes by calculating the cosine distance between
their relevant vectors, as shown in Equation (2).
n
</bodyText>
<equation confidence="0.998373875">
EEvi
i =1
n
vi
i =1
n
i=1vi(A1)X vi(A2) //2
(A1,A2 ) = l )
</equation>
<bodyText confidence="0.99333975">
Where, vi(A1) and vi(A2) (1in) denote the re-
spective word embeddings of product attributes
A1 and A2, and n denotes the number of dimen-
sions in word embedding representation of prod-
uct attributes.
Table 2 illustrates a sample of equivalent at-
tribute-evaluation pairs extracted from the train-
ing corpora.
</bodyText>
<table confidence="0.584346333333333">
SimS
(A1 ) 2 X (A2 ) 2
E
</table>
<tableCaption confidence="0.933433">
Table 2. A sample of equivalent attribute-evaluation pairs extracted from the training corpora
</tableCaption>
<bodyText confidence="0.264496">
Product attributes Positive evaluations Negative evaluations
</bodyText>
<equation confidence="0.784718388888889">
Price:价 |价 格 |价钱 |价位
|...
Acceleration: 加速|加速性
|加速能力|...
Low: 合适|适中|实惠|优惠|不高|公
道|比较便宜|有优势|值|...
Excellent: 有推背感|一点不软|很好|
很给力|令人满意|灵敏|很优秀|...
High: 高|太高|真高|偏高|有点高|贵|太贵|
偏贵|有点贵|不合理|有点无语|...
Weak: 差|偏弱|有延迟|很突然|比较没劲|
比较没力|...
Touch screen: 触摸屏 |触 Fast/Sensitive: 不错|好 |很 好|灵敏 |
屏|触控|触感|触控|... 灵活|快|给力|挺流畅|反应快|好用|
灵敏度高|...
Slow/Insensitive: 不太灵敏||不是很灵敏 |
比较慢|有点不灵活|反应太慢|不好用|迟
钝|过于灵敏|...
</equation>
<subsectionHeader confidence="0.982037">
3.4 Paraphrase Generation
</subsectionHeader>
<bodyText confidence="0.9990625">
Given an opinionated sentence S, we generate
paraphrases in two steps:
(1) Opinion element substitution. We first
construct a set of equivalent utterances for each
attribution or evaluation in S and store them with
word lattice. For convenience, here we refer this
word lattice as paraphrase word lattice.
The equivalent substitution of attributes or
evaluations is essential to opinion paraphrase
generation. In the present study, we perform this
task by substituting attributes and their evalua-
tions using the extracted attribute-evaluation
pairs shown in Table 2.
(2) n-best paraphrase decoding. Once the
paraphrase word lattice is constructed, our prob-
lem is now to score all potential paraphrases
within the lattice and select the most probable
paraphrases as the equivalent expansion of the
input sentence. For simplicity and efficiency of
implementation, in this paper we employ bigram
</bodyText>
<page confidence="0.77973">
38
</page>
<bodyText confidence="0.99534375">
language models to rank the paraphrase candi-
dates and thus decode n-best paths from the par-
aphrase word lattice. Each path forms a probable
paraphrase for the input sentence.
</bodyText>
<tableCaption confidence="0.856525333333333">
Table 3 shows some generated paraphrases
and their bigram scores.
Table 3. Examples of generated paraphrases.
</tableCaption>
<figure confidence="0.893131090909091">
Generated paraphrases scores
操控性非常好(The con- 1.12e-
trollability is very good) 34
操控性比较好(The con- 6.81e-
trollability is OK) 35
反应有点慢。(The
reaction is a bit
slow.) tardy.)
反应迟缓(The reaction is
1.29e-
11
</figure>
<bodyText confidence="0.999306333333333">
experiments over car and celphone product re-
views. This section reports our experimental re-
sults.
</bodyText>
<subsectionHeader confidence="0.979431">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.9998111">
The experimental data come from two domains
of online product reviews, namely car reviews
and mobilephone reviews. Both corpora are
manually annotated with multiple linguistic and
opinion information, such as word segmentation,
part-of-speech tags, opinion elements and polari-
ty classification, and are further divided into
training datasets and test datasets, respectively.
Table 4 presents the basic statistics of the exper-
imental data.
</bodyText>
<figure confidence="0.997793">
Dataset Car Mobilephone
Total Pos Neg Total Pos Neg
Original sentences
操控性特棒。(The
controllability is
excellent.)
反应比较慢(The reaction 5.55e-
is relatively slow) 05
3.70e-
05 Table 4. Basic statistics of the experimental data
8.40e- Training 1904 841 963 2042 1033 1009
12 Test 913 462 451 1021 516 505
价格合理!(Reasonable
价格最低! price!)
(Lowest price!) 价格优惠!(Favorable
price!)
</figure>
<subsectionHeader confidence="0.872547">
3.5 Polarity conflict resolution
</subsectionHeader>
<bodyText confidence="0.988244">
Polarity conflict will arise when an input opin-
ioned sentence and its paraphrases receive differ-
ent polarity types during polarity classification.
The reason may be due to inconsistent generation
of paraphrases between the training data and the
input opinionated sentences for polarity classifi-
cation.
In order to avoid polarity conflicts, we employ
a simple voting mechanism. Given an input opin-
ionated sentence and its k-best paraphrases gen-
erated by the systems, then we have k+1 opin-
ionated sentences for polarity classification. Let i
(0ik)be the number of sentences that are clas-
sified as positive by the system and j (0jk, and
i + j = k) be the number of sentences that are
negative during polarity classification. Thus, we
can take the following three rules to determine
the final polarity of the original sentence.
 Rule 1. if i &gt; j, then the final polarity is
positive.
 Rule 2. if i &lt; j, then the final polarity is
negative.
 Rule 3. if i = j, then the final polarity is the
same as that of the original polarity of the
input sentence during polarity classifica-
tion.
</bodyText>
<sectionHeader confidence="0.970631" genericHeader="method">
4 Experimental Results and Discussions
</sectionHeader>
<bodyText confidence="0.9992885">
To assess our approach, we developed a SVM-
based sentiment polarity classifier and conducted
</bodyText>
<tableCaption confidence="0.998246">
Table 5. The equivalent attribute-evaluation pairs.
</tableCaption>
<table confidence="0.9495918">
SimJ SimJ + SimS
Training data
A-P A-N A-P A-N
Car 137 177 109 161
Mobilephone 88 121 78 107
</table>
<bodyText confidence="0.998983">
As shown in Table 5, we have constructed two
knowledge bases, namely the equivalent pairs of
attributes and their related positive evaluations
(A-P pairs for short), and the equivalent pairs of
attributes and their related negative evaluations
(A-N pairs for short), for opinion paraphrase
generation from the two training corpora, respec-
tively. It should be noted that we consider two
strategies for attribute clustering during para-
phrase extraction, namely attribute clustering
with Jaccard coefficient (SimJ for short) and at-
tribute clustering incorporating Jaccard coeffi-
cient and the word embeddings based semantic
similarity with linear interpolation (SimJ+SimS
for short).
Furthermore, in this paper the performance of
polarity classification is reported in terms of ac-
curacy.
</bodyText>
<subsectionHeader confidence="0.995546">
4.2 Effects of different paraphrasing
</subsectionHeader>
<bodyText confidence="0.99995925">
Our first experiment intends to investigate the
effects of different paraphrasing strategies on
polarity classification, including different n-best
paraphrase generation and paraphrasing on dif-
ferent data. Note that in this experiment, we con-
sider five cases (viz. n = 1 to 5) during n-best
paraphrase generation, and compare the relevant
polarity classification results. Furthermore, to
</bodyText>
<page confidence="0.908774">
39
</page>
<bodyText confidence="0.9998491">
better understand the results for different n-best
paraphrase generation, we also conducted an in-
vestigation on the relationship between the num-
ber of generated paraphrases for different data
and the value of n in n-best paraphrases. It
should be noted that in this experiment para-
phrases are generated using equivalent attribute-
evaluation pairs extracted with SimJ and SimS,
as shown in Table 5. The results are summarized
in Tables 6-9.
</bodyText>
<tableCaption confidence="0.9797995">
Table 6. Number of generated paraphrases for the
training and test corpora in car domain
</tableCaption>
<table confidence="0.999948818181818">
n-best Dataset Total Pos Neg
1 Training 3460 1708 1637
Test 1702 805 792
2 Training 4914 2469 2296
Test 2394 1141 1123
3 Training 6361 3229 2949
Test 3083 1476 1452
4 Training 7796 3983 3596
Test 3768 1809 1779
5 Training 9224 4735 4238
Test 4450 2141 2104
</table>
<tableCaption confidence="0.9957885">
Table 7. Number of generated paraphrases for the
training and test corpora in mobilephone domain
</tableCaption>
<table confidence="0.999964818181818">
n-best Dataset Total Pos Neg
1 Training 3768 1966 1802
Test 1889 931 958
2 Training 5487 2897 2590
Test 2751 1342 1409
3 Training 7187 3825 3362
Test 3603 1749 1854
4 Training 8881 4751 4130
Test 4447 2152 2295
5 Training 10568 5676 4892
Test 5287 2555 2732
</table>
<tableCaption confidence="0.961675">
Table 8. Polarity classification over car reviews with
different paraphrasing strategies
</tableCaption>
<table confidence="0.981186625">
n- Para. on Para on test Para. on both
best training data data only training and
only test data
1 70.09 70.69 70.19
2 70.29 71.60 70.80
3 70.29 71.70 70.50
4 67.98 73.01 69.50
5 67.77 71.70 69.49
</table>
<bodyText confidence="0.991523642857143">
The results in Tables 7-8 reveal that the value
of n in n-best paraphrase generation appears to
be an important influence factor for polarity clas-
sification with paraphrases. As n increases, the
number of generated paraphrases is going up,
and at the same time, the polarity classification
accuracy is also rising for the case of performing
paraphrasing on the training corpora. But in case
of paraphrasing on the test data, the performance
in polarity classification does not always rise
with the number of generated paraphrases. The
reason might be due to the fact larger number of
generated paraphrases may introduce more polar-
ity conflicts during polarity classification.
</bodyText>
<tableCaption confidence="0.9905225">
Table 9. Polarity classification over mobilephone re-
views with different paraphrasing strategies
</tableCaption>
<table confidence="0.99854625">
n-best Para. on Para on Para. on both
training test data training and test
data only only data
1 83.45 83.74 83.45
2 84.62 84.62 87.86
3 85.41 85.31 87.76
4 86.19 86.10 89.81
5 85.21 85.50 89.81
</table>
<subsectionHeader confidence="0.9748645">
4.3 Comparison of polarity classification
with/without paraphrasing
</subsectionHeader>
<bodyText confidence="0.999697384615385">
As we have mentioned above, paraphrasing pro-
vides us with an option for avoiding the prob-
lems of data sparseness in open applications. So
our last experiment is designed to examine the
effectiveness of using paraphrasing in polarity
classification. The experiment is conducted by
comparing the results produced by the SVMs-
classifies with paraphrases to that of the systems
trained with the original corpora in Table 5 only
(viz. the baseline systems). Furthermore, we con-
sider two strategies, namely SimJ and
SimJ&amp;SimS, for paraphrase extraction in this
experiment. The results are presented in Table 10.
</bodyText>
<tableCaption confidence="0.999259">
Table 10. Comparison of polarity classification
</tableCaption>
<table confidence="0.9923651875">
with/without paraphrasing
Systems Car Mobilephone
Baseline 66.06 83.74
Para. on training data 69.99 86.39
based on SimJ
Para. on test 73.72 86.19
data based on SimJ
Para. both training and 70.90 89.62
test data based on SimJ
Para. on training data 70.29 89.19
based on SimJ&amp;SimS
Para. on test data based 73.01 86.10
on SimJ&amp;SimS
Para. on both training 70.80 89.81
and test data based on
SimJ&amp;SimS
</table>
<bodyText confidence="0.9800265">
As can be seen from Table 10, using para-
phrases can significantly improve polarity classi-
fication performance. Take the system with par-
aphrasing on the training data only via
</bodyText>
<page confidence="0.735821">
40
</page>
<bodyText confidence="0.99997895">
SimJ&amp;SimS, the accuracy can be improved by
more than 4 and 6 percents for car and mo-
bilephone reviews, respectively, compared to the
baseline without using any paraphrases, illustrat-
ing in as sense the effectiveness of the proposed
method. Furthermore, it can be observed from
Table 10 that the system yields better results for
mobilephone reviews than for cars. Moreover,
the results over mobilephone data shows the per-
formance in polarity classification can be en-
hanced by incorporating word embeddings based
semantic similarity with literal similarity for par-
aphrase extraction, while the experiments on car
reviews do not illustrate similar results. The rea-
son might be due to the fact that car products
have more attributes than mobilephone products,
which makes it more difficult to cluster product
attributes. In addition, more attributes may re-
sults in more paraphrases and thus produce more
polarity conflicts to polarity classification.
</bodyText>
<subsectionHeader confidence="0.997445">
4.4 Polarity conflicts between paraphrases
</subsectionHeader>
<bodyText confidence="0.999916461538461">
As we have mentioned above, larger number of
generated paraphrases may introduce more seri-
ous polarity conflicts to polarity classification.
Our third experiment is thus to investigate the
problem of polarity classification conflict be-
tween paraphrases. This experiment is conducted
by counting the number of polarity class con-
flicts between each sentence in the test data and
its paraphrases using different n-best paraphrase
generation. In addition, here the system for po-
larity classification is trained using the expanded
training data via 5-best paraphrase generation.
The results are summarized in Table 11.
</bodyText>
<tableCaption confidence="0.974592666666667">
Table 11. Number of polarity conflicts in the test da-
taset yielded by systems using training datasets
with/without paraphrasing
</tableCaption>
<table confidence="0.997910142857143">
n- Car Mobilephone
best SimJ SimJ&amp;SimS SimJ SimJ&amp;SimS
1 216 228 40 39
2 224 233 41 47
3 232 238 42 50
4 236 243 46 51
5 237 247 48 51
</table>
<bodyText confidence="0.947762352941177">
As can be seen from Table 11, the number of
conflicts is also increasing with the rise of gener-
ated paraphrases. Also, we can observe from Ta-
ble 11 that there are more polarity conflicts in the
car data than in the mobilephone data. This illus-
trates again that the larger number of product
attributes in car domain might be one potential
reason for its relative lower performance in po-
larity classification, in comparison to the mo-
bilephone domain.
Our in-depth analysis shows that there are
three main possible causes for polarity conflicts,
as shown in Table 12.
(1) Incorrect paraphrase generation. Wrongly-
generated paraphrases possibly lead to polarity
conflicts, as illustrated by the first example in
Table 12.
</bodyText>
<listItem confidence="0.741818333333333">
(2) Dynamic polarity. In cases of opinionated
and paraphrases with dynamic polar words, the
classifier does not always works and thus cannot
consistently yield correct polarity classes, as the
second example in Table 12 shows.
(3) Explanatory opinionated sentence. The
</listItem>
<bodyText confidence="0.770925375">
evaluation expressions in explanatory opinionat-
ed sentences usually have more complicated
structures and most often have no explicit polari-
ty words, as shown by the third example in Table
12. It is obviously very difficult for the system to
produce correct paraphrases or perform con-
sistent polarity classification for explanatory
opinionated sentences (Kim, et al., 2013).
</bodyText>
<tableCaption confidence="0.974832">
Table 12. Examples of generated paraphrases with
contradict polarity.
</tableCaption>
<figure confidence="0.989457933333333">
No. Paraphrases with polarity conflicts
1 (a) 价格浮动频繁(The price fluctuation is
frequent)
(b) 价格很不给力 (The price is ungelivable)
(c) 价格太高(The price is too high)
2 (a) 内置软件过多(There is too much built-in
software)
(b) 内置软件很多(There is very much built-in
software)
3 (a) 电池一般三天左右(The duration of the
battery is about three days)
(b) 电池玩一段时间会发烫(The battery will
be hot after a period of working)
(c) 电池 1880 毫安(The battery capacity is
1880 mAh)
</figure>
<sectionHeader confidence="0.962514" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999853333333333">
In this paper, we have exploited opinion para-
phrasing to enhance Chinese sentence polarity
classification. We have demonstrated that para-
phrasing on training corpora and test corpora can
result in a significant improvement of perfor-
mance in polarity classification.
The encouraging results of the present study
suggest several possibilities for future research.
With regard to the concentrate of our current
work, we have only employed very simple tech-
niques to perform paraphrase extraction and gen-
eration. To further enhance our system, in future
</bodyText>
<page confidence="0.879021">
41
</page>
<bodyText confidence="0.999976333333333">
work we intend to exploit a more tailored method
to achieve high-quality paraphrases for polarity
classification. The present study focuses on Chi-
nese polarity classification. In future, we also
plan to extend our current system and apply it to
other languages like English.
</bodyText>
<sectionHeader confidence="0.998708" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.944994">
This study was supported by National Natural
Science Foundation of China under Grant
No.61170148 and No.60973081, the Returned
Scholar Foundation of Heilongjiang Province,
and Harbin Innovative Foundation for Returnees
under Grant No.2009RFLXG007, respectively.
</bodyText>
<sectionHeader confidence="0.940908" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.99994930882353">
A. Fader, L. Zettlemoyer, and O. Etzioni. 2013. Para-
phrase-driven learning for open question answering.
In Proceedings of ACL’13, pages 1608-1618.
B. Pang, and L. Lee. 2008. Opinion mining and sen-
timent analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2): 1-135.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumps
up? Sentiment classification using machine learn-
ing techniques. In Proceedings of EMNLP-02, pag-
es 79-86.
C.-C. Chang, and C.-J. Lin. 2011. LIBSVM: A library
for support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2(27): 1-27.
G. Fu, and X. Wang. 2010. Chinese sentence-level
sentiment classification based on fuzzy sets. In
Proceedings of COLING’10, pages 312-319.
M. Heilman, N.A. Smith. 2010. Tree edit models for
recognizing textual entailments, paraphrases, and
answers to questions. In Proceedings of NAACL’10,
pages 1011-1019.
M. Speriosu, S. Upadhyay, N. Sudan, and J. Baldridge.
2011. Twitter polarity classification with label
propagation over lexical links and the follower
graph. In Proceedings of the First workshop on
Unsupervised Learning in NLP, pages 53-63.
N. Madnani, and B. J. Dorr. 2010. Generating phrasal
and sentential paraphrases: A survey of data-driven
methods. Computational Linguistics, 36(3): 342-
387.
P.D. Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of ACL’02,
pages 417-424.
R. Bhagat, and E. Hovy. 2013. What is a paraphrase?.
Computational Linguistics, 39(3): 463-472
R. Mehrotra, R. Agrawal, and S.A. Haider. 2012. Dic-
tionary based sparse representation for domain ad-
aptation. In Proceedings of CIKM’12, pages 2395-
2398.
R. Mihalcea, C. Banea, J. Wiebe. 2007. Learning mul-
tilingual subjective language via cross-lingual pro-
jections. In Proceedings of ACL’07, pages 976-983.
S. Volkova, T. Wilson, D. Yarowsky. 2013. Explor-
ing sentiment in social media: Bootstrapping sub-
jectivity clues from multilingual twitter streams. In
Proceedings of ACL’13, pages 505-510.
S. Zhao, X. Lan, T. Liu, et al. 2009. Application-
driven statistical paraphrase generation. In Pro-
ceedings of the ACL-IJCNL’09, pages 834-842.
T. Mikolov. 2012. Statistical language models based
on neural networks. Doctoral Thesis, Brno Univer-
sity of Technology.
T. Mikolov, W. Yih, and G. Zweig. 2013. Linguistic
regularities in continuous space word representa-
tions. In Proceedings of NAACL-HLT.’13, pages
746-751
T. Nakagawa, K. Inui, and S. Kurohashi. 2010. De-
pendency tree-based sentiment classification using
CRFs with hidden variables. In Proceedings of
HLT-NAACL’10, pages 786-794.
T. Wilson, J. Wiebe, and P. Hoffmann. 2009. Recog-
nizing contextual polarity: An exploration of fea-
tures for phrase-level sentiment analysis. Computa-
tional Linguistics, 35(3):99-433
H.D.Kim, M. Castellanos, M. Hsu, C.X. Zhai, U.
Dayal, and R. Ghosh. 2013. Ranking explanatory
sentences for opinion summarization. In Proceed-
ings of SIGIR’13, pages 1069-1072
</reference>
<page confidence="0.957403">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.344034">
<title confidence="0.9312275">Improving Chinese Sentence Polarity via Opinion Paraphrasing</title>
<author confidence="0.887011">Guohong Fu</author>
<author confidence="0.887011">Yu He</author>
<author confidence="0.887011">Jiaying Song</author>
<author confidence="0.887011">Chaoyue</author>
<affiliation confidence="0.903849">Heilongjiang University, Harbin 150080,</affiliation>
<email confidence="0.7016005">ghfu@hlju.edu.cn,heyucs@yahoo.com,chaoyue.wang@yahoo.cn</email>
<abstract confidence="0.9958432">While substantial studies have been achieved on sentiment polarity classification to date, lacking enough opinion-annotated corpora for reliable training is still a challenge. In this paper we propose to improve a supported vector machines based polarity classifier by enriching both training data and test data via opinion paraphrasing. In particular, we first extract an equivalent set of attributeevaluation pairs from the training data and then exploit it to generate opinion paraphrases in order to expand the training corpus or enrich opinionated sentences for polarity classification. We tested our system over two sets of online product reviews in car and mobilephone domains. The experimental results show that using opinion paraphrases results in significant performance improvement in polarity classification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Fader</author>
<author>L Zettlemoyer</author>
<author>O Etzioni</author>
</authors>
<title>Paraphrase-driven learning for open question answering.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL’13,</booktitle>
<pages>1608--1618</pages>
<contexts>
<context position="2980" citStr="Fader et al., 2013" startWordPosition="429" endWordPosition="432">ific. Obviously, it is time and cost consuming to manually construct a large-scale opinionannotated corpus for each domain. To address the above problems, in this paper we propose to improve polarity classification by enriching both training data and test data via paraphrasing. We have two motivations for this. Firstly, paraphrasing has proven to be an effective tool for improve the coverage of systems and has been successfully used in many applications such as machine translation, information retrieval and question answering (Bhagat and Hovy, 2013; Heilman and Smith, 2010; Zhao et al., 2013; Fader et al., 2013). However, to date, there has been very limited study on sentiment or opinion paraphrasing. Secondly, unlike opinion corpus annotation, paraphrases are relatively more flexible to acquire using different resources like synonym lexica, bilingual and parallel corpora, and so forth. Therefore, we believe that paraphrasing would be a feasible way to expand the training corpus and at the same time, to alleviate the data sparse problem in statistically-based systems. As such, the purpose of this study is to ascertain the effect of using opinion paraphrases in polarity classification at sentence leve</context>
</contexts>
<marker>Fader, Zettlemoyer, Etzioni, 2013</marker>
<rawString>A. Fader, L. Zettlemoyer, and O. Etzioni. 2013. Paraphrase-driven learning for open question answering. In Proceedings of ACL’13, pages 1608-1618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="4930" citStr="Pang and Lee, 2008" startWordPosition="726" endWordPosition="729">the performance of sentence polarity classification. The rests of the paper proceed as follows. Section 2 provides a brief review of the literature on sentiment classification and paraphrase generation. Section 3 describes in details the proposed method to Chinese sentence polarity classification via paraphrasing. Section 4 reports our experimental results on two sets of product reviews. Finally, section 5 concludes our work and discusses some possible directions for future research. 2 Related Work Polarity classification is usually formulated as a binary classification problem (Turney, 2002; Pang and Lee, 2008). Most previous studies employ supervised machine learning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervise</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang, and L. Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2): 1-135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumps up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP-02,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="5167" citStr="Pang et al., 2002" startWordPosition="762" endWordPosition="765">roposed method to Chinese sentence polarity classification via paraphrasing. Section 4 reports our experimental results on two sets of product reviews. Finally, section 5 concludes our work and discusses some possible directions for future research. 2 Related Work Polarity classification is usually formulated as a binary classification problem (Turney, 2002; Pang and Lee, 2008). Most previous studies employ supervised machine learning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumps up? Sentiment classification using machine learning techniques. In Proceedings of EMNLP-02, pages 79-86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-C Chang</author>
<author>C-J Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<issue>27</issue>
<pages>1--27</pages>
<marker>Chang, Lin, 2011</marker>
<rawString>C.-C. Chang, and C.-J. Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(27): 1-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fu</author>
<author>X Wang</author>
</authors>
<title>Chinese sentence-level sentiment classification based on fuzzy sets.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING’10,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="5206" citStr="Fu and Wang, 2010" startWordPosition="769" endWordPosition="772">arity classification via paraphrasing. Section 4 reports our experimental results on two sets of product reviews. Finally, section 5 concludes our work and discusses some possible directions for future research. 2 Related Work Polarity classification is usually formulated as a binary classification problem (Turney, 2002; Pang and Lee, 2008). Most previous studies employ supervised machine learning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Diffe</context>
</contexts>
<marker>Fu, Wang, 2010</marker>
<rawString>G. Fu, and X. Wang. 2010. Chinese sentence-level sentiment classification based on fuzzy sets. In Proceedings of COLING’10, pages 312-319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Heilman</author>
<author>N A Smith</author>
</authors>
<title>Tree edit models for recognizing textual entailments, paraphrases, and answers to questions.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL’10,</booktitle>
<pages>1011--1019</pages>
<contexts>
<context position="2940" citStr="Heilman and Smith, 2010" startWordPosition="421" endWordPosition="424">rmore, opinion mining is usually domain specific. Obviously, it is time and cost consuming to manually construct a large-scale opinionannotated corpus for each domain. To address the above problems, in this paper we propose to improve polarity classification by enriching both training data and test data via paraphrasing. We have two motivations for this. Firstly, paraphrasing has proven to be an effective tool for improve the coverage of systems and has been successfully used in many applications such as machine translation, information retrieval and question answering (Bhagat and Hovy, 2013; Heilman and Smith, 2010; Zhao et al., 2013; Fader et al., 2013). However, to date, there has been very limited study on sentiment or opinion paraphrasing. Secondly, unlike opinion corpus annotation, paraphrases are relatively more flexible to acquire using different resources like synonym lexica, bilingual and parallel corpora, and so forth. Therefore, we believe that paraphrasing would be a feasible way to expand the training corpus and at the same time, to alleviate the data sparse problem in statistically-based systems. As such, the purpose of this study is to ascertain the effect of using opinion paraphrases in </context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>M. Heilman, N.A. Smith. 2010. Tree edit models for recognizing textual entailments, paraphrases, and answers to questions. In Proceedings of NAACL’10, pages 1011-1019.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Speriosu</author>
<author>S Upadhyay</author>
<author>N Sudan</author>
<author>J Baldridge</author>
</authors>
<title>Twitter polarity classification with label propagation over lexical links and the follower graph.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>53--63</pages>
<contexts>
<context position="5622" citStr="Speriosu et al. 2011" startWordPosition="832" endWordPosition="835">uding naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Different from most existing studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for training. At this point, our current study i</context>
</contexts>
<marker>Speriosu, Upadhyay, Sudan, Baldridge, 2011</marker>
<rawString>M. Speriosu, S. Upadhyay, N. Sudan, and J. Baldridge. 2011. Twitter polarity classification with label propagation over lexical links and the follower graph. In Proceedings of the First workshop on Unsupervised Learning in NLP, pages 53-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Madnani</author>
<author>B J Dorr</author>
</authors>
<title>Generating phrasal and sentential paraphrases: A survey of data-driven methods.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<pages>342--387</pages>
<contexts>
<context position="6451" citStr="Madnani and Dorr, 2010" startWordPosition="953" endWordPosition="956">g studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for training. At this point, our current study is also relevant to paraphrasing tasks, including paraphrase recognition, paraphrase extraction and paraphrase generation. Although a variety of methods, from dictionary-based methods to datadriven methods (Madnani and Dorr, 2010), have been proposed for paraphrasing. Since in the present study we aim to answer the question whether the use of paraphrasing can enhance polarity classification performance, we do not want to look insight into paraphrasing issues. Instead, we just exploit some simple but efficient paraphrasing techniques to achieve opinion paraphrases for expanding training data and enriching text data for polarity classification, including opinion paraphrase extraction incorporating the Jaccard conefficient based literal similarity with the word embedding based semantic similarity, and opinion paraphrase g</context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>N. Madnani, and B. J. Dorr. 2010. Generating phrasal and sentential paraphrases: A survey of data-driven methods. Computational Linguistics, 36(3): 342-387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL’02,</booktitle>
<pages>417--424</pages>
<contexts>
<context position="4909" citStr="Turney, 2002" startWordPosition="724" endWordPosition="725">antly improve the performance of sentence polarity classification. The rests of the paper proceed as follows. Section 2 provides a brief review of the literature on sentiment classification and paraphrase generation. Section 3 describes in details the proposed method to Chinese sentence polarity classification via paraphrasing. Section 4 reports our experimental results on two sets of product reviews. Finally, section 5 concludes our work and discusses some possible directions for future research. 2 Related Work Polarity classification is usually formulated as a binary classification problem (Turney, 2002; Pang and Lee, 2008). Most previous studies employ supervised machine learning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstr</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P.D. Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proceedings of ACL’02, pages 417-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bhagat</author>
<author>E Hovy</author>
</authors>
<title>What is a paraphrase?.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<pages>463--472</pages>
<contexts>
<context position="2915" citStr="Bhagat and Hovy, 2013" startWordPosition="417" endWordPosition="420">raining process. Furthermore, opinion mining is usually domain specific. Obviously, it is time and cost consuming to manually construct a large-scale opinionannotated corpus for each domain. To address the above problems, in this paper we propose to improve polarity classification by enriching both training data and test data via paraphrasing. We have two motivations for this. Firstly, paraphrasing has proven to be an effective tool for improve the coverage of systems and has been successfully used in many applications such as machine translation, information retrieval and question answering (Bhagat and Hovy, 2013; Heilman and Smith, 2010; Zhao et al., 2013; Fader et al., 2013). However, to date, there has been very limited study on sentiment or opinion paraphrasing. Secondly, unlike opinion corpus annotation, paraphrases are relatively more flexible to acquire using different resources like synonym lexica, bilingual and parallel corpora, and so forth. Therefore, we believe that paraphrasing would be a feasible way to expand the training corpus and at the same time, to alleviate the data sparse problem in statistically-based systems. As such, the purpose of this study is to ascertain the effect of usin</context>
<context position="9631" citStr="Bhagat and Hovy, 2013" startWordPosition="1403" endWordPosition="1406">fication. As a consequence, this may cause polarity conflicts between the original input sentences and their paraphrases after polarity classification. To address this problem, we employ a rule-based voting method. In Sections 3.2 to 3.5, we provide the details of our implementation. 3.2 Paraphrases in Product Reviews Before describing the techniques for paraphrase extraction and generation, it is necessary to clarify what a paraphrase is for product reviews. In linguistics literature, paraphrases are most often referred to as an approximate equivalence of meaning across sentences or phrases (Bhagat and Hovy, 2013). In the present study we characterize opinion paraphrases from the perspective of opinion elements. In general, opinion information consists of five main elements, namely opinion source (viz. opinion holder), opinion target, attribute, evaluation and polarity. Thus, the opinion element perspective defines paraphrases in terms of the kinds of opinion element changes that can take place in an opinionated sentence resulting in the generation of its paraphrases. Considering the characteristics of product reviews, here we focus on product attributes and their relevant evaluations within opinionate</context>
</contexts>
<marker>Bhagat, Hovy, 2013</marker>
<rawString>R. Bhagat, and E. Hovy. 2013. What is a paraphrase?. Computational Linguistics, 39(3): 463-472</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mehrotra</author>
<author>R Agrawal</author>
<author>S A Haider</author>
</authors>
<title>Dictionary based sparse representation for domain adaptation.</title>
<date>2012</date>
<booktitle>In Proceedings of CIKM’12,</booktitle>
<pages>2395--2398</pages>
<contexts>
<context position="5644" citStr="Mehrotra et al. 2012" startWordPosition="836" endWordPosition="839">l, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Different from most existing studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for training. At this point, our current study is also relevant to par</context>
</contexts>
<marker>Mehrotra, Agrawal, Haider, 2012</marker>
<rawString>R. Mehrotra, R. Agrawal, and S.A. Haider. 2012. Dictionary based sparse representation for domain adaptation. In Proceedings of CIKM’12, pages 2395-2398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Banea</author>
<author>J Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL’07,</booktitle>
<pages>976--983</pages>
<contexts>
<context position="5579" citStr="Mihalcea et al., 2007" startWordPosition="824" endWordPosition="827">oy supervised machine learning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Different from most existing studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for t</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>R. Mihalcea, C. Banea, J. Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of ACL’07, pages 976-983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Volkova</author>
<author>T Wilson</author>
<author>D Yarowsky</author>
</authors>
<title>Exploring sentiment in social media: Bootstrapping subjectivity clues from multilingual twitter streams.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL’13,</booktitle>
<pages>505--510</pages>
<contexts>
<context position="5667" citStr="Volkova et al., 2013" startWordPosition="840" endWordPosition="843">ines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Different from most existing studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for training. At this point, our current study is also relevant to paraphrasing tasks, includ</context>
</contexts>
<marker>Volkova, Wilson, Yarowsky, 2013</marker>
<rawString>S. Volkova, T. Wilson, D. Yarowsky. 2013. Exploring sentiment in social media: Bootstrapping subjectivity clues from multilingual twitter streams. In Proceedings of ACL’13, pages 505-510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zhao</author>
<author>X Lan</author>
<author>T Liu</author>
</authors>
<title>Applicationdriven statistical paraphrase generation.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNL’09,</booktitle>
<pages>834--842</pages>
<marker>Zhao, Lan, Liu, 2009</marker>
<rawString>S. Zhao, X. Lan, T. Liu, et al. 2009. Applicationdriven statistical paraphrase generation. In Proceedings of the ACL-IJCNL’09, pages 834-842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
</authors>
<title>Statistical language models based on neural networks. Doctoral Thesis,</title>
<date>2012</date>
<institution>Brno University of Technology.</institution>
<contexts>
<context position="13673" citStr="Mikolov, 2012" startWordPosition="2000" endWordPosition="2001">ese attributes (A*, ARI_) _) and (A, �A), their respective Jaccard coefficients are 0.33 and 1. (2) Semantic similarity. Literal similarity measures rely on literal matching and work for product attributes with explicit literal connections. However, such information does not always exit in many co-referred feature expressions like * (pixel) and 3 0)f* (resolution). To address this problem, we introduce semantic similarity based on word embeddings. Actually, word embeddings map each word to an ndimensional dense vector of real numbers and each dimension has certain latent semantic information (Mikolov, 2012; Mikolov et al., 2013). Obviously, the data size has a strong relationship with the expression of semantic. Thus, we can obtain the similarity between two product attributes by calculating the cosine distance between their relevant vectors, as shown in Equation (2). n EEvi i =1 n vi i =1 n i=1vi(A1)X vi(A2) //2 (A1,A2 ) = l ) Where, vi(A1) and vi(A2) (1in) denote the respective word embeddings of product attributes A1 and A2, and n denotes the number of dimensions in word embedding representation of product attributes. Table 2 illustrates a sample of equivalent attribute-evaluation pairs ex</context>
</contexts>
<marker>Mikolov, 2012</marker>
<rawString>T. Mikolov. 2012. Statistical language models based on neural networks. Doctoral Thesis, Brno University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
<author>W Yih</author>
<author>G Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT.’13,</booktitle>
<pages>746--751</pages>
<contexts>
<context position="13696" citStr="Mikolov et al., 2013" startWordPosition="2002" endWordPosition="2005">(A*, ARI_) _) and (A, �A), their respective Jaccard coefficients are 0.33 and 1. (2) Semantic similarity. Literal similarity measures rely on literal matching and work for product attributes with explicit literal connections. However, such information does not always exit in many co-referred feature expressions like * (pixel) and 3 0)f* (resolution). To address this problem, we introduce semantic similarity based on word embeddings. Actually, word embeddings map each word to an ndimensional dense vector of real numbers and each dimension has certain latent semantic information (Mikolov, 2012; Mikolov et al., 2013). Obviously, the data size has a strong relationship with the expression of semantic. Thus, we can obtain the similarity between two product attributes by calculating the cosine distance between their relevant vectors, as shown in Equation (2). n EEvi i =1 n vi i =1 n i=1vi(A1)X vi(A2) //2 (A1,A2 ) = l ) Where, vi(A1) and vi(A2) (1in) denote the respective word embeddings of product attributes A1 and A2, and n denotes the number of dimensions in word embedding representation of product attributes. Table 2 illustrates a sample of equivalent attribute-evaluation pairs extracted from the traini</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>T. Mikolov, W. Yih, and G. Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of NAACL-HLT.’13, pages 746-751</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nakagawa</author>
<author>K Inui</author>
<author>S Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using CRFs with hidden variables.</title>
<date>2010</date>
<booktitle>In Proceedings of HLT-NAACL’10,</booktitle>
<pages>786--794</pages>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>T. Nakagawa, K. Inui, and S. Kurohashi. 2010. Dependency tree-based sentiment classification using CRFs with hidden variables. In Proceedings of HLT-NAACL’10, pages 786-794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
<author>J Wiebe</author>
<author>P Hoffmann</author>
</authors>
<title>Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<pages>35--3</pages>
<contexts>
<context position="5600" citStr="Wilson et al., 2009" startWordPosition="828" endWordPosition="831">earning methods, including naïve Bayes model, support vector machines (SVMs), maximum entropy models (MEMs), conditional random fields (CRFs), fuzzy sets, and so forth (Pang et al., 2002; Pang and Lee, 2008;Fu and Wang, 2010), to perform polarity classification on different linguistic levels such words, phrases, sentences and documents. Lacking a large scale manually-annotated corpus is one of the major bottlenecks that supervised machine learning methods faced. To break this bottleneck, some recent studies exploit bootstrapping or unsupervised techniques (Turney, 2002; Mihalcea et al., 2007; Wilson et al., 2009, Speriosu et al. 2011, Mehrotra et al. 2012; Volkova et al., 2013). Unfortunately, sentiment classifiers based on unsupervised methods usually yield worse performance compared to the supervised ones. Different from most existing studies, in this study we attempt to enhance Chinese sentence polarity classifier by exploring opinion paraphrasing. We believe that paraphrasing provides us with an option to expand training corpora and to enrich opinion sentences for polarity classification, which would alleviate the problem of data sparseness and lack of annotated corpora for training. At this poin</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>T. Wilson, J. Wiebe, and P. Hoffmann. 2009. Recognizing contextual polarity: An exploration of features for phrase-level sentiment analysis. Computational Linguistics, 35(3):99-433</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Castellanos H D Kim</author>
<author>M Hsu</author>
<author>C X Zhai</author>
<author>U Dayal</author>
<author>R Ghosh</author>
</authors>
<title>Ranking explanatory sentences for opinion summarization.</title>
<date>2013</date>
<booktitle>In Proceedings of SIGIR’13,</booktitle>
<pages>1069--1072</pages>
<contexts>
<context position="26722" citStr="Kim, et al., 2013" startWordPosition="4055" endWordPosition="4058">n cases of opinionated and paraphrases with dynamic polar words, the classifier does not always works and thus cannot consistently yield correct polarity classes, as the second example in Table 12 shows. (3) Explanatory opinionated sentence. The evaluation expressions in explanatory opinionated sentences usually have more complicated structures and most often have no explicit polarity words, as shown by the third example in Table 12. It is obviously very difficult for the system to produce correct paraphrases or perform consistent polarity classification for explanatory opinionated sentences (Kim, et al., 2013). Table 12. Examples of generated paraphrases with contradict polarity. No. Paraphrases with polarity conflicts 1 (a) 价格浮动频繁(The price fluctuation is frequent) (b) 价格很不给力 (The price is ungelivable) (c) 价格太高(The price is too high) 2 (a) 内置软件过多(There is too much built-in software) (b) 内置软件很多(There is very much built-in software) 3 (a) 电池一般三天左右(The duration of the battery is about three days) (b) 电池玩一段时间会发烫(The battery will be hot after a period of working) (c) 电池 1880 毫安(The battery capacity is 1880 mAh) 5 Conclusions and Future Work In this paper, we have exploited opinion paraphrasing to enhan</context>
</contexts>
<marker>Kim, Hsu, Zhai, Dayal, Ghosh, 2013</marker>
<rawString>H.D.Kim, M. Castellanos, M. Hsu, C.X. Zhai, U. Dayal, and R. Ghosh. 2013. Ranking explanatory sentences for opinion summarization. In Proceedings of SIGIR’13, pages 1069-1072</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>