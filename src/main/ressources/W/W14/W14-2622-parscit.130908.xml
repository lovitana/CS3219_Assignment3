<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.163673">
<title confidence="0.991979">
Effect of Using Regression on Class Confidence Scores in Sentiment
Analysis of Twitter Data
</title>
<author confidence="0.997705">
Itir Onal*, Ali Mert Ertugrul†, Ruken Cakici*
</author>
<affiliation confidence="0.998934">
*Department of Computer Engineering, Middle East Technical University, Ankara, Turkey
</affiliation>
<email confidence="0.946042">
itir,ruken@ceng.metu.edu.tr
</email>
<affiliation confidence="0.854615">
†Department of Information Systems, Middle East Technical University, Ankara, Turkey
</affiliation>
<email confidence="0.994949">
alimert@metu.edu.tr
</email>
<sectionHeader confidence="0.993794" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99986196">
In this study, we aim to test our hypothesis
that confidence scores of sentiment values
of tweets aid in classification of sentiment.
We used several feature sets consisting of
lexical features, emoticons, features based
on sentiment scores and combination of
lexical and sentiment features. Since our
dataset includes confidence scores of real
numbers in [0-1] range, we employ regres-
sion analysis on each class of sentiments.
We determine the class label of a tweet by
looking at the maximum of the confidence
scores assigned to it by these regressors.
We test the results against classification
results obtained by converting the confi-
dence scores into discrete labels. Thus,
the strength of sentiment is ignored. Our
expectation was that taking the strength
of sentiment into consideration would im-
prove the classification results. Contrary
to our expectations, our results indicate
that using classification on discrete class
labels and ignoring sentiment strength per-
form similar to using regression on contin-
uous confidence scores.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999992744186046">
In the past few years, there has been a growing
interest in using microblogging sites such as Twit-
ter. Generally, people tend to share their opinions,
ideas about entities, topics and issues via these
microblogs. Therefore, companies show interest
in these for the sentiment analysis to be used as
means of customer satisfaction evaluation about
their products.
Although some tweets express direct sentiment,
the polarity and intent of some tweets cannot be
understood even by humans because of lack of
context. Moreover, a tweet may be perceived as
positive or negative by some people whereas oth-
ers may think that the tweet is not polar. There-
fore, sometimes it is not easy to assign a senti-
ment class to a tweet. Instead of assigning a sin-
gle sentiment to a tweet, confidence scores reflect-
ing the likelihoods of sentiments of the tweet may
be provided. Our dataset consists of tweets and
their corresponding confidence scores of five sen-
timents namely positive, negative, neutral, irrel-
evant and unknown. An analysis on the dataset
reflects that, some tweets get similar confidence
scores for many classes. In other words, differ-
ent people assign different class labels to the same
tweet. On the other hand, confidence scores of
some tweets for a class are close to or equal to
1, meaning that the sentiment of the tweets are
clear. If we have discrete class labels for all tweets,
tweets assigned to classes with a low confidence
score will have equal effect as the ones whose con-
fidence scores are high during the training phase of
sentiment analysis.
In this study, we investigate whether the
strength of sentiment plays a role in classification
or not. We build regression models to estimate the
confidence scores of tweets for each class sepa-
rately. Then, we assign the sentiment, whose con-
fidence score is maximum among others to the
tweet. On the other hand, we also converted the
confidence scores to discrete class labels and per-
formed classification directly. The experiments
and results are explained in Section 5.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999664875">
Sentiment analysis on Twitter has some challenges
compared to the classical sentiment analysis meth-
ods on formal documents since the tweets may
have irregular structure, short length and non-
English words. Moreover, they may include el-
ements specific to microblogs such as hashtags,
emoticons, etc. Go et al. (2009) used emoti-
cons as features and Barbosa et al. (2010) used
</bodyText>
<page confidence="0.984509">
136
</page>
<bodyText confidence="0.994729324324324">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 136–141,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
retweets, hashtags, emoticons, links, etc. as fea-
tures to classify the sentiments as positive or neg-
ative. Furthermore, Kouloumpis et al. (2011)
showed that the features including presence of in-
tensifiers, positive/negative/neutral emoticons and
abbreviations are more successful than part-of-
speech tags for sentiment analysis on Twitter. Saif
et al. (2012) extracted sentiment topics from
tweets and then used them to augment the fea-
ture space. Agarwal et al. (2011) used tree kernel
to determine features and they used SVM, Naive
Bayes, Maximum entropy for classification. In our
experiments we used k-Nearest Neighbor (k-NN)
and SVM as classifiers.
Due to the rarity of class confidence scores of
datasets in the literature, a few studies employ re-
gression. Jain et al. (2012) use Support Vector Re-
gression (SVR) for sentiment analysis in movie re-
views but the labels they use are discrete. So, they
use SVR directly for classification purpose, not re-
gression. However, we employed SVR on con-
fidence scores with the aim of regression. More-
over, Lu et al. (2011) use SVR in multi-aspect sen-
timent analysis to detect the ratings of each aspect.
Since our approach does not include aspects, our
results are not comparable with that of (Lu et al.,
2011). The study of Liu (2012) consists of studies
employing regression in sentiment analysis. Yet,
in most of these studies the regressors are trained
using discrete rating scores between 1 and 5. Fur-
thermore, Pang et al. (2008) also mentions regres-
sion to classify sentiments using discrete rating
scores. Unlike these approaches, we employ re-
gression on real-valued confidence scores between
0 and 1.
</bodyText>
<sectionHeader confidence="0.905402" genericHeader="method">
3 Data Description and Pre-processing
</sectionHeader>
<bodyText confidence="0.999969805555556">
The data set we use (Kaggle, 2013) consists of
77946 tweets which are obtained with the aim of
sentiment classification. Each tweet is rated by
multiple raters and as a result, each tweet has con-
fidence scores of five classes namely positive, neg-
ative, neutral, irrelevant and unknown. Among
77946 tweets, only 800 of them has the maximum
confidence score of unknown class. Therefore, in
order to have a balanced dataset in our experi-
ments, we selected 800 tweets from each class. As
a result, the dataset used in our experiments is bal-
anced and includes a total of 4000 tweets.
The data set includes tweets both relevant and
irrelevant to weather. Tweets are expected to get
high confidence score of irrelevant class if the
tweet is not related to weather. Moreover, as their
name implies, positive and negative confidence
values represent the polarity level of each tweet
towards weather. If a tweet is not polar, it is ex-
pected to be given a high neutral confidence score.
Unknown class is expected to have a high score
when the tweet is related with weather, but the po-
larity of tweet cannot be decided.
The tweets in the data set are labeled by mul-
tiple raters. Then, the confidence scores for la-
bels are obtained by aggregating labels given to
tweets by raters and the individual reliability of
each rater. For a tweet, confidence scores of all
categories sum to 1 and confidence score values
are in range [0,1].
Before feature extraction, we pre-process the
data in a few steps. Firstly, we remove links and
mentions that are features specific to tweets. Then,
we remove emoticons from the text while record-
ing their number for each tweet in order to use
them later.
</bodyText>
<sectionHeader confidence="0.999322" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.9999775">
Our features can be divided into four main cate-
gories which are lexical features, emoticons, fea-
tures based on sentiment scores and a combination
of the lexical and sentiment features.
</bodyText>
<subsectionHeader confidence="0.998382">
4.1 Lexical Features
</subsectionHeader>
<bodyText confidence="0.999968181818182">
We extracted two different lexical features which
are word n-grams, part-of-speech (POS) n-grams.
Using all tweets in our training data, we ex-
tracted only unigrams of words to be used as base-
line. Moreover, after extracting POS tags of sen-
tences in each tweet using the POS tagger given in
(Toutanova et al., 2003), we computed unigrams
and bigrams of POS tags. We considered the pres-
ence of word unigrams, POS unigrams and bi-
grams. Therefore, those features can get binary
values.
</bodyText>
<subsectionHeader confidence="0.975776">
4.2 Emoticons
</subsectionHeader>
<bodyText confidence="0.999945375">
In the preprocessing step, we remove the emoti-
cons from the text. However, since emoti-
cons carry sentiment information, we also record
whether the tweet includes positive, negative or
neutral emoticons (see Table 1) during the re-
moval of emoticons. Therefore, we extract 3 bi-
nary features based on emoticon presence in the
tweet.
</bodyText>
<page confidence="0.998666">
137
</page>
<tableCaption confidence="0.999729">
Table 1: Emoticons and their sentiments
</tableCaption>
<table confidence="0.7930875">
Sentiment Emoticon
Positive :) , :-), =), =D, :D
Negative :( , :-(, =(, :/
Neutral :|
</table>
<subsectionHeader confidence="0.986027">
4.3 Features Based on Sentiment Scores
</subsectionHeader>
<bodyText confidence="0.999894789473684">
We extract features based on sentiment scores us-
ing two different approaches. In the first one, we
use SentiWordNet 3.0 (Baccianella et al., 2010) to
obtain the sentiment scores of each word. We used
the word and a tag representing the POS tag of the
word to output the sentiment score of the word.
Since the same word with different senses have
different scores, we obtained a single sentiment
score by computing the weighted average of Senti-
WordNet scores for each sense. Furthermore, POS
tagging is performed as explained in 4.1. How-
ever, since POS tags of Penn TreeBank and Senti-
WordNet are different, we convert one to other as
shown in Table 2. Therefore, the sentiment score
for a word is obtained after the Penn TreeBank
tags are converted to SentiWordNet tags. Using
all the words in a tweet and their corresponding
SentiWordNet scores, we compute the following
features:
</bodyText>
<listItem confidence="0.999436">
• # of words having positive sentiment
• # of words having negative sentiment
• total sentiment score
</listItem>
<bodyText confidence="0.9918076">
As a result, using SentiWordNet, we extract 3
more features. We observe that the acronym lol
representing laughing out loud is used extensively
in tweets. In order to keep its meaning, when a lol
is encountered, its sentiment score is assigned to 1.
Moreover, sentiment scores of words having other
POS tags than the ones in Table 2 are assigned
to 0. When not is encountered, we multiply the
sentiment score of its successor word by −1 and
convert the sentiment score of not to 0.
</bodyText>
<tableCaption confidence="0.8430625">
Table 2: Conversion of POS tags to SentiWordNet
tags
</tableCaption>
<table confidence="0.630248">
SentiWordNet Tag Penn TreeBank tag
a (adjective) JJ, JJR, JJS
n (noun) NN, NNS, NNP, NNPS
v (verb) VB,VBD, VBG, VBN, VBP, VPZ
r (adverb) RB, RBR, RBS
</table>
<bodyText confidence="0.99764975">
The second approach is using LabMT word list
(Dodds et al., 2011) which includes scores for sen-
timent analysis. It includes a list of words with
their happiness rank, happiness average and hap-
piness standard deviation. In our study, we com-
puted those values for all the words in a tweet and
extracted the 6 features namely the minima and the
maxima of happiness rank, happiness average and
happiness standard deviation.
Note that, if a word is not encountered in either
SentiWordNet or labMT dictionary, then the senti-
ment score of that word is assigned to 0.
</bodyText>
<subsectionHeader confidence="0.996861">
4.4 Combination of Lexical and Sentiment
Features
</subsectionHeader>
<bodyText confidence="0.999406222222222">
We extract features using POS tags and sentiment
scores. After the conversion of POS tags in Table
2, we have four main tags namely, a (adjective),
n (noun), v (verb), r (adverb). For each tweet we
compute the number of adjectives, nouns, verbs
and adverbs having positive, negative and neutral
sentiments. Therefore, we extract 12 features us-
ing combination of lexical and sentiment features.
Table 3 shows all the features used.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999956555555556">
In our experiments we extract the features using
training data set. Then, we formed training and
test feature matrices using these features. By using
these matrices, we both conduct classification and
regression.
We train separate regressors for each class using
the training feature matrix and confidence scores
of the corresponding class. We use Support Vector
Regression (SVR) library of (Chang et al., 2011)
in our computations. Recall that, the confidence
scores are between 0 and 1 and they carry informa-
tion about how likely it is that a tweet belongs to
a specified class. For instance it is very likely that
a positive with a 0.9 confidence score is actually a
positive, whereas a positive with a 0.2 confidence
score is much less likely to be positive. In order to
assign a sentiment label to a test tweet, we sepa-
rately test that tweet with the regressors trained for
each class. Then, each regressor assigns a score
between 0 and 1 to that test tweet. Finally, we as-
sign the class label with maximum score to the test
tweet.
During classification, we convert confidence
scores to discrete class labels by assigning them
the class which the majority of the raters agreed
upon. Using training feature matrix and their cor-
responding discrete labels, we train a Support Vec-
</bodyText>
<page confidence="0.999382">
138
</page>
<tableCaption confidence="0.997065">
Table 3: Features used in our experiments
</tableCaption>
<table confidence="0.99043075">
Lexical word unigram f1
POS unigram + bigram f2
Emoticons # of pos, neg, neu emoticons f3
Sentiment Scores SentiWordNet (# of pos, neg words, total sentiment score) f4
labMT ( min, max of happiness rank, avg and std) f5
Sentiment # of pos a, pos n, pos v, pos r f6
+ Lexical # of neg a, neg n, neg v, neg r
# of neu a, neu n, neu v, neu r
</table>
<bodyText confidence="0.984334">
tor Machine (SVM) using the method of (Chang et
al., 2011) and a k-Nearest Neighbor (k-NN) clas-
sifier. SVM and k-NN directly assigns class labels
to test tweets.
We employed classification and regression on
three types of data having classes:
</bodyText>
<listItem confidence="0.99988875">
• positive - negative - neutral - irrelevant - un-
known
• positive - negative - neutral
• positive - negative
</listItem>
<subsectionHeader confidence="0.985521">
5.1 Positive vs. Negative vs. Neutral vs.
Irrelevant vs. Unknown
</subsectionHeader>
<bodyText confidence="0.999986391304348">
In 5-class classification, our dataset consists of
4000 tweets (800 for each class). We used 3000 of
them as training data (600 for each class) and 1000
of them as test data (200 for each class). Since
our dataset is balanced, chance accuracy is 20% if
we assing all the tweets to one class. Using var-
ious features to train k-NN, SVM and SVR, we
obtained the results in Table 4.
Results in Table 4 show that, classification with
SVM performs the best when emoticon features
(f3) and SentiWordNet features (f4) are com-
bined with unigram baseline. Moreover, using
emoticon features (f3), and sentiment score fea-
tures (both SentiWordNet (f4) and labMT (f5))
together with the word unigram baseline perform
the best among others when SVR is used. No-
tice that using regression performs slightly worse
than using SVM for most of the feature combina-
tions. However, the p-value of SVM vs. SVR is
0.06, meaning that the performance improvement
of SVM is insignificant. On the other hand, using
SVR always performs much better than k-NN with
a p-value of 2 x 10−10.
</bodyText>
<subsectionHeader confidence="0.999645">
5.2 Positive vs. Negative vs. Neutral
</subsectionHeader>
<bodyText confidence="0.999750428571428">
In 3-class classification, our dataset consists of
2400 tweets (800 for each class). We use 1800 of
them as training data (600 for each class) and 600
of them as test data (200 for each class). Since our
dataset is balanced, chance accuracy is 33%. Us-
ing various features to train k-NN, SVM and SVR,
we obtain the results in Table 5.
</bodyText>
<tableCaption confidence="0.9897375">
Table 4: k-NN, SVM and SVR Performances for
5-class classification
</tableCaption>
<table confidence="0.999599230769231">
Features k-NN SVM SVR
Unigram (f1) 0,3140 0,4430 0,4290
+f2 0,3130 0,4330 0,4300
+f3 0,3350 0,4410 0,4350
+f5 0,3280 0,4460 0,4340
+f6 0,3490 0,4500 0,4260
+f3, f4 0,3450 0,4570 0,4370
+f3, f5 0,3300 0,4430 0,4340
+f4, f5 0,3550 0,4490 0,4350
+f4, f6 0,3490 0,4550 0,4260
+f3, f4, f5 0,3530 0,4490 0,4430
+f2, f3, f4, f5 0,3500 0,4350 0,4420
+f2, f3, f4, f5, f6 0,3430 0,4250 0,4350
</table>
<tableCaption confidence="0.9939585">
Table 5: k-NN, SVM and SVR Performances for
3-class classification
</tableCaption>
<table confidence="0.999114">
Features k-NN SVM SVR
Unigram (f1) 0,5183 0,6650 0,6467
+f2 0,5017 0,6267 0,6450
+f3 0,5333 0,6767 0,6567
+f5 0,5467 0,6617 0,6533
+f6 0,5450 0,6767 0,6700
+f3, f4 0,5550 0,6717 0,6583
+f3, f5 0,5517 0,6700 0,6667
+f4, f5 0,5533 0,6733 0,6567
+f4, f6 0,5233 0,6750 0,6700
+f3, f4, f5 0,5700 0,6700 0,6550
+f2, f3, f4, f5 0,5367 0,6583 0,6567
+f2, f3, f4, f5, f6 0,5450 0,6500 0,6550
</table>
<page confidence="0.998032">
139
</page>
<bodyText confidence="0.996129083333333">
Table 5 reflects that, using the combination of
sentiment and lexical features (f6) play an impor-
tant role in positive - negative - neutral classifica-
tion using SVR. On the other hand, using emoti-
con features (f3) with unigram baseline or labMT
features (f5) with unigram baseline performs the
best when SVM is used. It can be seen that SVM
performs slightly better than SVR most of the time
yet the performance improvemen is again insignif-
icant with a p-value of 0.58. Furthermore, they
always perform much better than k-NN with a p-
value of 2 × 10−8.
</bodyText>
<subsectionHeader confidence="0.997341">
5.3 Positive vs. Negative
</subsectionHeader>
<bodyText confidence="0.999677375">
In 2-class classification, since we have 800 posi-
tive and 800 negative tweets among 4000 tweets,
we used 1600 tweets. We used 1200 of them as
training data (600 for each class) and 400 of them
as test data (200 for each class). Since our dataset
is balanced, chance accuracy is 50%. Using the
same set of features to train k-NN, SVM and SVR,
we obtained the results in Table 6.
</bodyText>
<tableCaption confidence="0.9671715">
Table 6: k-NN, SVM and SVR Performances for
2-class classification
</tableCaption>
<table confidence="0.994804153846154">
Features k-NN SVM SVR
Unigram (f1) 0,6275 0,7700 0,7775
+f2 0,6575 0,7575 0,7375
+f3 0,7225 0,7850 0,7775
+f5 0,6900 0,7575 0,7700
+f6 0,6950 0,7975 0,7975
+f3, f4 0,6900 0,7825 0,7850
+f3, f5 0,7125 0,7800 0,7700
+f4, f5 0,6950 0,7800 0,7800
+f4, f6 0,6725 0,7950 0,7975
+f3, f4, f5 0,7000 0,7725 0,7800
+f2, f3, f4, f5 0,6675 0,7700 0,7800
+f2, f3, f4, f5, f6 0,6675 0,7825 0,7750
</table>
<bodyText confidence="0.9996634">
In positive - negative classification, using com-
bination of sentiment and lexical features (f6)
with unigram baseline results in the highest per-
formance among all when either SVM or SVR
is used. Similar to previous classification results,
performance improvement of using SVM on dis-
crete labels instead of using SVR is insignificant
with a p-value of 0.46 whereas SVR provides a
significant performance improvement over k-NN
with a p-value of 5 × 10−4.
</bodyText>
<sectionHeader confidence="0.998618" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99999355">
In this study we conducted sentiment analysis on
tweets about weather. We performed two types of
experiments, one using confidence scores directly
by regression and the other one by discreticis-
ing this information and using discrete classifiers.
We expected that employing regression on confi-
dence scores would better discriminate the senti-
ment classes of tweets than the classification on
discrete labels since they consider the sentiment
strength.
First, we extracted various types of features
including lexical features, emoticons, sentiment
scores and combination of lexical and sentiment
features. Then, we created the feature vectors
for these tweets. We trained a regressor for each
class separately using continuous valued confi-
dence scores. Then, a test tweet is assigned to
the label, whose estimated confidence score is the
highest among others. In our second experiment,
we assigned class labels having the maximum con-
fidence score to the tweets in the training set di-
rectly. Using the training data and discrete valued
class labels, we trained a classifier. Then, a test
tweet is assigned to a class label by the classifier.
Our results indicate that using classification on
discrete valued class labels performs slightly bet-
ter than using regression, which considers confi-
dence scores during training. However, the per-
formance improvement is shown to be insignifi-
cant. We would expect a significant performance
improvement using SVR compared to SVM as in
the case of k-NN vs. SVR. However, we explored
that the effect of strength of sentiment is insignifi-
cant.
As future work, we will employ our methods on
datasets including continuous scores rather than
discrete class labels such as movie reviews includ-
ing ratings. Moreover, we may enhance our ap-
proach on multi-aspect sentiment analysis prob-
lems where each aspect is given ratings.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998642428571428">
Alec Go, Richa Bhayani and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
Stanford Digital Library Technologies Project, NJ.
Luciano Barbosa and Junlan Feng 2010. Robust Sen-
timent Detection on Twitter from Biased and Noisy
Data. Proceedings of COLING, Beijing China, 36–
44.
</reference>
<page confidence="0.97216">
140
</page>
<reference confidence="0.999424716981132">
Efthymios Kouloumpis, Theresa Wilson and Johanna
Moore 2011. Twitter Sentiment Analysis: The
Good the Bad and the OMG! Proceedings of the
ICWSM, Barcelona, Spain.
Hassan Saif, Yulan He, and Harith Alani 2012. Alle-
viating data sparsity for twitter. 2nd Workshop on
Making Sense of Microposts, Lyon, France.
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-
bow and Rebecca Passonneau 2011. Sentiment
analysis of twitter data. Proceedings of the Work-
shop on Languages in Social Media, Portland, Ore-
gon, USA, 30–38
Siddharth Jain and Sushobhan Nayak 2012. Sentiment
Analysis of Movie Reviews: A Study of Features
and Classifiers. CS221 Course Project: Artificial
Intelligence, Stanford (Fall 2012) [Report].
Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou
2011. Multi-aspect sentiment analysis with topic
models. The ICDM2011 Workshop on Sentiment
Elicitation from Natural Text for Information Re-
trieval and Extraction, Vancouver, Canada.
Kristina Toutanova, Dan Klein, Christopher Manning,
and Yoram Singer. 2003. Feature-Rich Part-of-
Speech Tagging with a Cyclic Dependency Net-
work. Proceedings of HLT-NAACL 2003, Edmon-
ton, Canada, 252–259.
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani 2010. SentiWordNet 3.0: An Enhanced Lex-
ical Resource for Sentiment Analysis and Opinion
Mining Proceedings of the Seventh International
Conference on Language Resources and Evaluation
(LREC’10), Valletta, Malta
Peter S. Dodds, Kameron D.Harris, Isabel M.
Kloumann, Catherine A. Bliss and Christopher M.
Danforth 2011. Temporal Patterns of Happiness
and Information in a Global Social Network: He-
donometrics and Twitter PLoS ONE 6(12): e26752
Chih-Chung Chang and Chih-Jen Lin 2011. LIB-
SVM: A Library for Support Vector Machines ACM
Transactions on Intelligent Systems and Technology,
2:27:1–27:27
Kaggle ”Partly Sunny with a Chance of
Hashtags” competition dataset 2013
http://www.kaggle.com/c/crowdflower-weather-
twitter
Quinn McNemar 1947 Note on the sampling error
of the difference between correlated proportions or
percentages Psychometrika 12(2):153-157
Bo Pang and Lillian Lee 2008 Opinion mining and
sentiment analysis. Foundations and Trends in In-
formation Retrieval 2(1-2): p. 1–135.
Bing Liu 2012 Sentiment Analysis and Opinion Min-
ing Morgan &amp; Claypool Publishers
</reference>
<page confidence="0.998241">
141
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.749685">
<title confidence="0.990825">Effect of Using Regression on Class Confidence Scores in Analysis of Twitter Data</title>
<author confidence="0.999536">Ali Mert Ruken</author>
<affiliation confidence="0.89358">of Computer Engineering, Middle East Technical University, Ankara, of Information Systems, Middle East Technical University, Ankara,</affiliation>
<email confidence="0.989696">alimert@metu.edu.tr</email>
<abstract confidence="0.999070576923077">In this study, we aim to test our hypothesis that confidence scores of sentiment values of tweets aid in classification of sentiment. We used several feature sets consisting of lexical features, emoticons, features based on sentiment scores and combination of lexical and sentiment features. Since our dataset includes confidence scores of real numbers in [0-1] range, we employ regression analysis on each class of sentiments. We determine the class label of a tweet by looking at the maximum of the confidence scores assigned to it by these regressors. We test the results against classification results obtained by converting the confidence scores into discrete labels. Thus, the strength of sentiment is ignored. Our expectation was that taking the strength of sentiment into consideration would improve the classification results. Contrary to our expectations, our results indicate that using classification on discrete class labels and ignoring sentiment strength perform similar to using regression on continuous confidence scores.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>Stanford Digital Library Technologies Project, NJ.</booktitle>
<contexts>
<context position="3780" citStr="Go et al. (2009)" startWordPosition="593" endWordPosition="596">ass separately. Then, we assign the sentiment, whose confidence score is maximum among others to the tweet. On the other hand, we also converted the confidence scores to discrete class labels and performed classification directly. The experiments and results are explained in Section 5. 2 Related Work Sentiment analysis on Twitter has some challenges compared to the classical sentiment analysis methods on formal documents since the tweets may have irregular structure, short length and nonEnglish words. Moreover, they may include elements specific to microblogs such as hashtags, emoticons, etc. Go et al. (2009) used emoticons as features and Barbosa et al. (2010) used 136 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 136–141, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics retweets, hashtags, emoticons, links, etc. as features to classify the sentiments as positive or negative. Furthermore, Kouloumpis et al. (2011) showed that the features including presence of intensifiers, positive/negative/neutral emoticons and abbreviations are more successful than part-ofspeech tags for sentiment </context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani and Lei Huang. 2009. Twitter sentiment classification using distant supervision. Stanford Digital Library Technologies Project, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust Sentiment Detection on Twitter from Biased and Noisy Data.</title>
<date>2010</date>
<booktitle>Proceedings of COLING,</booktitle>
<volume>36</volume>
<pages>44</pages>
<location>Beijing</location>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng 2010. Robust Sentiment Detection on Twitter from Biased and Noisy Data. Proceedings of COLING, Beijing China, 36– 44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efthymios Kouloumpis</author>
<author>Theresa Wilson</author>
<author>Johanna Moore</author>
</authors>
<title>Twitter Sentiment Analysis: The Good the Bad and the OMG!</title>
<date>2011</date>
<booktitle>Proceedings of the ICWSM,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="4206" citStr="Kouloumpis et al. (2011)" startWordPosition="655" endWordPosition="658">uments since the tweets may have irregular structure, short length and nonEnglish words. Moreover, they may include elements specific to microblogs such as hashtags, emoticons, etc. Go et al. (2009) used emoticons as features and Barbosa et al. (2010) used 136 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 136–141, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics retweets, hashtags, emoticons, links, etc. as features to classify the sentiments as positive or negative. Furthermore, Kouloumpis et al. (2011) showed that the features including presence of intensifiers, positive/negative/neutral emoticons and abbreviations are more successful than part-ofspeech tags for sentiment analysis on Twitter. Saif et al. (2012) extracted sentiment topics from tweets and then used them to augment the feature space. Agarwal et al. (2011) used tree kernel to determine features and they used SVM, Naive Bayes, Maximum entropy for classification. In our experiments we used k-Nearest Neighbor (k-NN) and SVM as classifiers. Due to the rarity of class confidence scores of datasets in the literature, a few studies em</context>
</contexts>
<marker>Kouloumpis, Wilson, Moore, 2011</marker>
<rawString>Efthymios Kouloumpis, Theresa Wilson and Johanna Moore 2011. Twitter Sentiment Analysis: The Good the Bad and the OMG! Proceedings of the ICWSM, Barcelona, Spain.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hassan Saif</author>
</authors>
<title>Yulan He, and Harith Alani 2012. Alleviating data sparsity for twitter. 2nd Workshop on Making Sense of Microposts,</title>
<location>Lyon, France.</location>
<marker>Saif, </marker>
<rawString>Hassan Saif, Yulan He, and Harith Alani 2012. Alleviating data sparsity for twitter. 2nd Workshop on Making Sense of Microposts, Lyon, France.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Apoorv Agarwal</author>
</authors>
<title>Boyi Xie, Ilia Vovsha, Owen Rambow and Rebecca Passonneau 2011. Sentiment analysis of twitter data.</title>
<booktitle>Proceedings of the Workshop on Languages in Social Media,</booktitle>
<pages>30--38</pages>
<location>Portland, Oregon, USA,</location>
<marker>Agarwal, </marker>
<rawString>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow and Rebecca Passonneau 2011. Sentiment analysis of twitter data. Proceedings of the Workshop on Languages in Social Media, Portland, Oregon, USA, 30–38</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Jain</author>
<author>Sushobhan Nayak</author>
</authors>
<title>Sentiment Analysis of Movie Reviews: A Study of Features and Classifiers.</title>
<date>2012</date>
<booktitle>CS221 Course Project: Artificial Intelligence,</booktitle>
<location>Stanford (Fall</location>
<note>[Report].</note>
<marker>Jain, Nayak, 2012</marker>
<rawString>Siddharth Jain and Sushobhan Nayak 2012. Sentiment Analysis of Movie Reviews: A Study of Features and Classifiers. CS221 Course Project: Artificial Intelligence, Stanford (Fall 2012) [Report].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin Tsou</author>
</authors>
<title>Multi-aspect sentiment analysis with topic models.</title>
<date>2011</date>
<booktitle>The ICDM2011 Workshop on Sentiment Elicitation from Natural Text for Information Retrieval and Extraction,</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="5126" citStr="Lu et al. (2011)" startWordPosition="804" endWordPosition="807">arwal et al. (2011) used tree kernel to determine features and they used SVM, Naive Bayes, Maximum entropy for classification. In our experiments we used k-Nearest Neighbor (k-NN) and SVM as classifiers. Due to the rarity of class confidence scores of datasets in the literature, a few studies employ regression. Jain et al. (2012) use Support Vector Regression (SVR) for sentiment analysis in movie reviews but the labels they use are discrete. So, they use SVR directly for classification purpose, not regression. However, we employed SVR on confidence scores with the aim of regression. Moreover, Lu et al. (2011) use SVR in multi-aspect sentiment analysis to detect the ratings of each aspect. Since our approach does not include aspects, our results are not comparable with that of (Lu et al., 2011). The study of Liu (2012) consists of studies employing regression in sentiment analysis. Yet, in most of these studies the regressors are trained using discrete rating scores between 1 and 5. Furthermore, Pang et al. (2008) also mentions regression to classify sentiments using discrete rating scores. Unlike these approaches, we employ regression on real-valued confidence scores between 0 and 1. 3 Data Descri</context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou 2011. Multi-aspect sentiment analysis with topic models. The ICDM2011 Workshop on Sentiment Elicitation from Natural Text for Information Retrieval and Extraction, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-Rich Part-ofSpeech Tagging with a Cyclic Dependency Network.</title>
<date>2003</date>
<booktitle>Proceedings of HLT-NAACL 2003,</booktitle>
<pages>252--259</pages>
<location>Edmonton, Canada,</location>
<contexts>
<context position="7956" citStr="Toutanova et al., 2003" startWordPosition="1286" endWordPosition="1289">icons from the text while recording their number for each tweet in order to use them later. 4 Features Our features can be divided into four main categories which are lexical features, emoticons, features based on sentiment scores and a combination of the lexical and sentiment features. 4.1 Lexical Features We extracted two different lexical features which are word n-grams, part-of-speech (POS) n-grams. Using all tweets in our training data, we extracted only unigrams of words to be used as baseline. Moreover, after extracting POS tags of sentences in each tweet using the POS tagger given in (Toutanova et al., 2003), we computed unigrams and bigrams of POS tags. We considered the presence of word unigrams, POS unigrams and bigrams. Therefore, those features can get binary values. 4.2 Emoticons In the preprocessing step, we remove the emoticons from the text. However, since emoticons carry sentiment information, we also record whether the tweet includes positive, negative or neutral emoticons (see Table 1) during the removal of emoticons. Therefore, we extract 3 binary features based on emoticon presence in the tweet. 137 Table 1: Emoticons and their sentiments Sentiment Emoticon Positive :) , :-), =), =D</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher Manning, and Yoram Singer. 2003. Feature-Rich Part-ofSpeech Tagging with a Cyclic Dependency Network. Proceedings of HLT-NAACL 2003, Edmonton, Canada, 252–259.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stefano Baccianella</author>
</authors>
<title>Andrea Esuli, and Fabrizio Sebastiani 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining</title>
<booktitle>Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta, Malta</location>
<marker>Baccianella, </marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani 2010. SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter S Dodds</author>
<author>Kameron D Harris</author>
<author>Isabel M Kloumann</author>
<author>Catherine A Bliss</author>
<author>Christopher M Danforth</author>
</authors>
<date>2011</date>
<booktitle>Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter PLoS ONE</booktitle>
<volume>6</volume>
<issue>12</issue>
<pages>26752</pages>
<contexts>
<context position="10370" citStr="Dodds et al., 2011" startWordPosition="1703" endWordPosition="1706"> extensively in tweets. In order to keep its meaning, when a lol is encountered, its sentiment score is assigned to 1. Moreover, sentiment scores of words having other POS tags than the ones in Table 2 are assigned to 0. When not is encountered, we multiply the sentiment score of its successor word by −1 and convert the sentiment score of not to 0. Table 2: Conversion of POS tags to SentiWordNet tags SentiWordNet Tag Penn TreeBank tag a (adjective) JJ, JJR, JJS n (noun) NN, NNS, NNP, NNPS v (verb) VB,VBD, VBG, VBN, VBP, VPZ r (adverb) RB, RBR, RBS The second approach is using LabMT word list (Dodds et al., 2011) which includes scores for sentiment analysis. It includes a list of words with their happiness rank, happiness average and happiness standard deviation. In our study, we computed those values for all the words in a tweet and extracted the 6 features namely the minima and the maxima of happiness rank, happiness average and happiness standard deviation. Note that, if a word is not encountered in either SentiWordNet or labMT dictionary, then the sentiment score of that word is assigned to 0. 4.4 Combination of Lexical and Sentiment Features We extract features using POS tags and sentiment scores</context>
</contexts>
<marker>Dodds, Harris, Kloumann, Bliss, Danforth, 2011</marker>
<rawString>Peter S. Dodds, Kameron D.Harris, Isabel M. Kloumann, Catherine A. Bliss and Christopher M. Danforth 2011. Temporal Patterns of Happiness and Information in a Global Social Network: Hedonometrics and Twitter PLoS ONE 6(12): e26752</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<date>2011</date>
<booktitle>LIBSVM: A Library for Support Vector Machines ACM Transactions on Intelligent Systems and Technology,</booktitle>
<pages>2--27</pages>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin 2011. LIBSVM: A Library for Support Vector Machines ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaggle ”Partly</author>
</authors>
<title>Sunny with a Chance of Hashtags” competition dataset</title>
<date>2013</date>
<note>http://www.kaggle.com/c/crowdflower-weathertwitter</note>
<marker>”Partly, 2013</marker>
<rawString>Kaggle ”Partly Sunny with a Chance of Hashtags” competition dataset 2013 http://www.kaggle.com/c/crowdflower-weathertwitter</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quinn McNemar</author>
</authors>
<title>Note on the sampling error of the difference between correlated proportions or percentages Psychometrika</title>
<date>1947</date>
<pages>12--2</pages>
<marker>McNemar, 1947</marker>
<rawString>Quinn McNemar 1947 Note on the sampling error of the difference between correlated proportions or percentages Psychometrika 12(2):153-157</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval 2(1-2):</booktitle>
<pages>1--135</pages>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee 2008 Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval 2(1-2): p. 1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers</publisher>
<contexts>
<context position="5339" citStr="Liu (2012)" startWordPosition="844" endWordPosition="845">ty of class confidence scores of datasets in the literature, a few studies employ regression. Jain et al. (2012) use Support Vector Regression (SVR) for sentiment analysis in movie reviews but the labels they use are discrete. So, they use SVR directly for classification purpose, not regression. However, we employed SVR on confidence scores with the aim of regression. Moreover, Lu et al. (2011) use SVR in multi-aspect sentiment analysis to detect the ratings of each aspect. Since our approach does not include aspects, our results are not comparable with that of (Lu et al., 2011). The study of Liu (2012) consists of studies employing regression in sentiment analysis. Yet, in most of these studies the regressors are trained using discrete rating scores between 1 and 5. Furthermore, Pang et al. (2008) also mentions regression to classify sentiments using discrete rating scores. Unlike these approaches, we employ regression on real-valued confidence scores between 0 and 1. 3 Data Description and Pre-processing The data set we use (Kaggle, 2013) consists of 77946 tweets which are obtained with the aim of sentiment classification. Each tweet is rated by multiple raters and as a result, each tweet </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu 2012 Sentiment Analysis and Opinion Mining Morgan &amp; Claypool Publishers</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>