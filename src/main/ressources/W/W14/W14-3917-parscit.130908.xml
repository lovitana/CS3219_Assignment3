<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003563">
<title confidence="0.9985145">
The Tel Aviv University System
for the Code-Switching Workshop Shared Task
</title>
<author confidence="0.993811">
Kfir Bar
</author>
<affiliation confidence="0.820434333333333">
School of Computer Science
Tel Aviv University
Ramat Aviv, Israel
</affiliation>
<email confidence="0.995614">
kfirbar@post.tau.ac.i
</email>
<sectionHeader confidence="0.99382" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999987">
We describe our entry in the EMNLP 2014
code-switching shared task. Our system
is based on a sequential classifier, trained
on the shared training set using various
character- and word-level features, some
calculated using a large monolingual cor-
pora. We participated in the Twitter-genre
Spanish-English track, obtaining an accu-
racy of 0.868 when measured on the tweet
level and 0.858 on the word level.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99929304">
Code switching is the act of changing language
while speaking or writing, as often done by bilin-
guals (Winford, 2003). Identifying the transition
points is a necessary first step before applying
other linguistic algorithms, which usually target a
single language. A switching point may occur be-
tween sentences, phrases, words, or even between
certain morphological components. Code switch-
ing happens frequently in informal ways of com-
munication, such as verbal conversations, blogs
and microblogs; however, there are many exam-
ples in which languages are switched in formal
settings. For example, alternating between Collo-
quial Egyptian Arabic and Modern Standard Ara-
bic in modern Egyptian prose is prevalent (Rosen-
baum, 2000).
This shared task (Solorio et al., 2014),1 the first
of its kind, challenges participants with identify-
ing those switching points in blogs as well as in
microblog posts. Given posts with a mix of a
specific pair of languages, each participating sys-
tem is required to identify the language of ev-
ery word. Four language-pair tracks were offered
by the task organizers: Spanish-English, Nepali-
English, Modern Standard Arabic and Colloquial
</bodyText>
<footnote confidence="0.957885">
1http://emnlp2014.org/workshops/
CodeSwitch/call.html
</footnote>
<author confidence="0.652522">
Nachum Dershowitz
</author>
<affiliation confidence="0.633528333333333">
School of Computer Science
Tel Aviv University
Ramat Aviv, Israel
</affiliation>
<email confidence="0.939802">
nachumd@tau.ac.il
</email>
<bodyText confidence="0.999215842105263">
Arabic, and Mandarin-English. For each language
pair, a training set of Twitter2 statuses was pro-
vided, which was manually annotated with a label
for every word, indicating its language. In addi-
tion to the two language labels, a few additional
labels were used. Altogether there were six labels:
(1) lang1—the first language; (2) lang2—the sec-
ond language; (3) ne—named entity; (4) ambigu-
ous—for ambiguous words belonging to both lan-
guages; (5) mixed—for words composed of mor-
phemes in each language; and (6) other—for cases
where it is impossible to determine the language.
For most of the language pairs, the organizers sup-
plied three different evaluation sets. The first set
was composed of a set of unseen Twitter statuses,
provided with no manual annotation. The other
two sets contained data from a “surprise genre”,
mainly composed of blog posts.
We took part only in the Spanish-English track.
Both English and Spanish are written in Latin
script. The Spanish alphabet contains some addi-
tional letters, such as those indicating stress (vow-
els with acute accents: ´a, ´e, ´ı, ´o, ´u), a u adorned
with a diaeresis (¨u), the additional letter n˜ (e˜ne),
and inverted question and exclamation punctua-
tion marks ¿ and ¡ (used at the beginning of ques-
tions and exclamatory phrases, respectively). Al-
though social-media users are not generally con-
sistent in their use of accents, their appearance
in a word may disclose its language. By and
large, algorithms for code switching have used
the character-based k-mer feature, introduced by
(Cavnar and Trenkle, 1994).3
Our system is an implementation of a multi-
class classifier that works on the word level, con-
sidering features that we calculate using large
Spanish as well as English monolingual corpora.
Working with a sequential classifier, the predicted
</bodyText>
<footnote confidence="0.998774">
2http://www.twitter.com
3We propose the term “k-mer” for character k-grams, in
contradistinction to word n-grams.
</footnote>
<page confidence="0.963819">
139
</page>
<bodyText confidence="0.870047777777778">
Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 139–143,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
labels of the previous words are used as features in
predicting the current word.
In Section 2, we describe our system and the
features we use for classification. Section 3 con-
tains the evaluation results, as published by the or-
ganizers of this shared task. We conclude with a
brief discussion.
</bodyText>
<sectionHeader confidence="0.963284" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999979222222222">
We use a supervised framework to train a classifier
that predicts the label of every word in the order
written. The words were originally tokenized by
the organizers, preserving punctuation, emoticons,
user mentions (e.g., @emnlp2014), and hashtags
(e.g., #emnlp2014) as individual tokens. The in-
formal language, as used in social media, intro-
duces an additional challenge in predicting the lan-
guage of every word. Spelling mistakes as well
as grammatical errors are very common. Hence,
we believe that predicting the language of a given
word merely using dictionaries for the two lan-
guages is likely to be insufficient.
Our classifier is trained on a learning set, as pro-
vided by the organizers, enriched with some addi-
tional features. Every word in the order written is
treated as a single instance for the classifier, each
including features from a limited window of pre-
ceding and successive words, enriched with the
predicted label of some of the preceding words.
We ran a few experiments with different window
sizes, based on 10-fold cross validation, and found
that the best token-level accuracy is obtained us-
ing a window of size 2 for all features, that is, two
words before the focus word and two words after.
The features that we use may be grouped in
three main categories, as described next.
</bodyText>
<subsectionHeader confidence="0.870343">
2.1 Features
</subsectionHeader>
<bodyText confidence="0.999225909090909">
We use three main groups of features:
Word level: The specific word in focus, as well
as the two previous words and the two following
ones are considered as features. To reduce the
sparsity, we convert words into lowercase. In ad-
dition, we use a monolingual lexicon for English
words that are typically used in Twitter. For this
purpose, we employ a sample of the Twitter Gen-
eral English lexicon, released by Illocution, Inc.,4
containing the top 10K words and bigrams from
a relatively large corpus of public English tweets
</bodyText>
<footnote confidence="0.900992">
4http://www.illocutioninc.com
</footnote>
<bodyText confidence="0.999906333333334">
they collected over a period of time, along with
frequency information. We bin the frequency rates
into 5 integer values (with an additional value for
words that do not exist in the lexicon), which are
used as the feature value for every word in focus,
and for the other four words in its window. This
feature seems to be quite noisy, as some common
Spanish words appear in the lexicon (e.g., de, no,
a, me); on the other hand, it may capture typi-
cal English misspellings and acronyms (e.g., oomf,
noww, lmao). We could not find a similar resource
for Spanish, unfortunately.
To help identify named entities, we created a list
of English as well Spanish names of various en-
tity types (e.g., locations, family and given names)
and used it to generate an additional boolean fea-
ture, indicating whether the word in focus is an en-
tity name. The list was compiled out of all words
beginning with a capital letter in relatively large
monolingual corpora, one for English and another
for Spanish. To avoid words that were capitalized
because they occur at the beginning of a sentence,
regardless of whether they are proper names, we
first processed the text with a true-casing tool, pro-
vided as part of Moses (Koehn et al., 2007)—
the open source implementation for phrase-based
statistical machine translation. Our list contains
about 146K entries.
Intra-word level: Spanish, as opposed to En-
glish, is a morphologically rich language, demon-
strating a complicated suffix-based derivational
morphology. Therefore, in order to capture re-
peating suffixes and prefixes that may character-
ize the languages, we consider as features sub-
strings of 1–3 prefix and suffix characters of the
word in focus and the other four words in its win-
dow. Although it is presumed that capitalization
is not used consistently in social media, we con-
sider a boolean feature indicating whether the first
letter of each word in the window was capitalized
in the original text or not. At this level, we use
two additional features that capture the level of un-
certainty of seeing the sequence of characters that
form the specific word in each language. This is
done by employing a 3-mer character-based lan-
guage model, trained over a large corpus in each
language. Then, the two language models, one for
each language, are applied on the word in focus
to calculate two log-probability values. These are
binned into ten discrete values that are used as the
features’ values. We add a boolean feature, indi-
</bodyText>
<page confidence="0.985323">
140
</page>
<bodyText confidence="0.999787785714286">
cating which of the two models returned a lower
log probability.
Inter-word level: We capture the level of un-
certainty of seeing specific sequences of words in
each language. We used 3-gram word-level lan-
guage models, trained over large corpora in each
of the languages. We apply the models to the fo-
cus word, considering it to be the last in a sequence
of three words (with the two previous words) and
calculate log probabilities. Like before, we bin the
values into ten discrete values, which are then used
as the features’ values. An additional boolean fea-
ture is used, indicating which of the two models
returned a lower log probability.
</bodyText>
<subsectionHeader confidence="0.984749">
2.2 Supervised Framework
</subsectionHeader>
<bodyText confidence="0.999995928571429">
We designed a sequential classifier running on top
of the Weka platform (Frank et al., 2010) that is
capable of processing instances sequentially, sim-
ilar to YamCha (Kudo and Matsumoto, 2003).
We use LibSVM (Chang and Lin, 2011), an im-
plementation of Support Vector Machines (SVM)
(Cortes and Vapnik, 1995), as the underlying tech-
nology, with a degree 2 polynomial kernel. Since
we work on a multi-class classification problem,
we take the one-versus-one approach. As men-
tioned above, we use features from a window of
±2 words before and after the word of interest. In
addition, for every word, we consider as features
the predicted labels of the two prior words.
</bodyText>
<sectionHeader confidence="0.994355" genericHeader="evaluation">
3 Evaluation Results
</sectionHeader>
<bodyText confidence="0.996987235294118">
We report on the results obtained on the unseen
task evaluation sets, which were provided by the
workshop organizers.5 There are three evaluation
sets. The first is composed of a set of unseen Twit-
ter statuses and the other two contain data from a
“surprise genre”. The results are available online
at the time of writing only for the first and second
sets. The results of the third set will be published
during the upcoming workshop meeting.
The training set contains 11,400 statuses, com-
prising 140,706 words. Table 1 shows the distri-
bution of labels.
The first evaluation set contains 3,060 tweets.
However, we were asked to download the statuses
directly from Twitter, and some of the statuses
were missing. Therefore, we ended up with only
1,661 available statuses, corresponding to 17,723
</bodyText>
<footnote confidence="0.942603">
5http://emnlp2014.org/workshops/
CodeSwitch/results.php
</footnote>
<table confidence="0.991344857142857">
Label Number
lang1 77,101
lang2 33,099
ne 2,918
ambiguous 344
mixed 51
other 27,194
</table>
<tableCaption confidence="0.991819">
Table 1: Label distribution in the training set.
</tableCaption>
<table confidence="0.59049175">
Accuracy 0.868
Recall 0.720
Precision 0.803
F1-Score 0.759
</table>
<tableCaption confidence="0.979863">
Table 2: Results for the first evaluation set, mea-
sured on tweet level.
</tableCaption>
<bodyText confidence="0.999292304347826">
words. According to the organizers, the evaluation
was performed only on the 1,626 tweets that were
available for all the participating groups. Out of
the 1,626, there are 1,155 monolingual tweets and
471 code-switched tweets. Table 2 shows the eval-
uation results for the Tel Aviv University (TAU)
system on the first set, reported on the tweet level.
In addition, the organizers provide evaluation
results, calculated on the word level. Table 3
shows the label distribution among the words in
the first evaluation set, and Table 4 shows the ac-
tual results. The overall accuracy on the word level
is 0.858.
The second evaluation set contains 1,103 words
of a “surprise” (unseen) genre, mainly blog posts.
Out of the 49 posts, 27 are monolingual and 22 are
code-switched posts. Table 5 shows the results for
the surprise set, calculated on the post level.
As for the first set, Table 6 shows the distribu-
tion of the labels among the words in the surprise
set, and in Table 7 we present the results as mea-
sured on the word level. The overall accuracy on
the surprise set is 0.941.
</bodyText>
<sectionHeader confidence="0.999117" genericHeader="conclusions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.99989575">
We believe that we have demonstrated the po-
tential of using sequential classification for code-
switching, enriched with three types of features,
some calculated using large monolingual corpora.
Compared to the other participating systems as
published by the workshop organizers, our system
obtained encouraging results. In particular, we ob-
serve relatively good results in relating words to
</bodyText>
<page confidence="0.996162">
141
</page>
<table confidence="0.997586714285714">
Label Count
lang1 (English) 7,040
lang2 (Spanish) 5,549
ne 464
mixed 12
ambiguous 43
other 4,311
</table>
<tableCaption confidence="0.966071">
Table 3: Label distribution in the first evaluation
set.
</tableCaption>
<table confidence="0.999907571428571">
Label Recall Precision F1-Score
lang1 (English) 0.900 0.830 0.864
lang2 (Spanish) 0.869 0.914 0.891
ne 0.313 0.541 0.396
mixed 0.000 1.000 0.000
ambiguous 0.023 0.200 0.042
other 0.845 0.860 0.853
</table>
<tableCaption confidence="0.9562625">
Table 4: Results for the first evaluation set, mea-
sured on word level.
</tableCaption>
<bodyText confidence="0.999098888888889">
their language; however, identifying named enti-
ties did not work as well. We plan to further in-
vestigate this issue. The results on the surprise
genre are similar to that for the genre the system
was trained on. However, since the surprise set
is relatively small in size, we refrain from draw-
ing conclusions about this. Trying the same code-
switching techniques on other pairs of languages
is part of our planned future research.
</bodyText>
<sectionHeader confidence="0.997135" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.975063944444444">
William B. Cavnar and John M. Trenkle. 1994. N-
gram-based text categorization. In Proceedings of
the 3rd Annual Symposium on Document Analysis
and Information Retrieval (SDAIR-94), pages 161–
175.
Chih C. Chang and Chih J. Lin. 2011. LIBSVM:
A Library for Support Vector Machines. ACM
Transactions on Intelligent Systems and Technology,
2(27):1–27, May.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine Learning, 20:273–297.
Eibe Frank, Mark Hall, Geoffrey Holmes, Richard
Kirkby, Bernhard Pfahringer, Ian H. Witten, and Len
Trigg. 2010. Weka—A machine learning work-
bench for data mining. In Oded Maimon and Lior
Rokach, editors, Data Mining and Knowledge Dis-
covery Handbook, chapter 66, pages 1269–1277.
Springer US, Boston, MA.
</reference>
<table confidence="0.59895775">
Accuracy 0.864
Recall 0.708
Precision 0.803
F1-Score 0.753
</table>
<tableCaption confidence="0.7878095">
Table 5: Results for the second, “surprise” evalua-
tion set, measured on the post level.
</tableCaption>
<table confidence="0.964365857142857">
Label Count
lang1 (English) 636
lang2 (Spanish) 306
ne 38
mixed 1
ambiguous 1
other 120
</table>
<tableCaption confidence="0.9642195">
Table 6: Label distribution in the “surprise” eval-
uation set.
</tableCaption>
<table confidence="0.998288142857143">
Label Recall Precision F1-Score
lang1 (English) 0.883 0.824 0.853
lang2 (Spanish) 0.864 0.887 0.876
ne 0.293 0.537 0.379
mixed 0.000 1.000 0.000
ambiguous 0.022 0.200 0.039
other 0.824 0.843 0.833
</table>
<tableCaption confidence="0.956887">
Table 7: Results for the “surprise” evaluation set,
measured on the word level.
</tableCaption>
<reference confidence="0.999332958333333">
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the Interactive Poster and Demon-
stration Sessions of the 45th Annual Meeting of the
ACL (ACL ’07), pages 177–180, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Taku Kudo and Yuji Matsumoto. 2003. Fast methods
for kernel-based text analysis. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 24–31, Sapporo,
Japan.
Gabriel M. Rosenbaum. 2000. Fushammiyya: Alter-
nating style in Egyptian prose. Journal of Arabic
Linguistics (ZAL), 38:68–87.
Thamar Solorio, Elizabeth Blair, Suraj Maharjan, Steve
Bethard, Mona Diab, Mahmoud Gonheim, Abdelati
Hawwari, Fahad AlGhamdi, Julia Hirshberg, Alison
Chang, and Pascale Fung. 2014. Overview for the
first shared task on language identification in code-
switched data. In Proceedings of the First Workshop
</reference>
<page confidence="0.978314">
142
</page>
<reference confidence="0.993191166666667">
on Computational Approaches to Code-Switching.
EMNLP 2014, Conference on Empirical Methods in
Natural Language Processing, Doha, Qatar.
Donald Winford, 2003. Code Switching: Linguistic
Aspects, chapter 5, pages 126–167. Blackwell Pub-
lishing, Malden, MA.
</reference>
<page confidence="0.999133">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.323566">
<title confidence="0.982202">The Tel Aviv University for the Code-Switching Workshop Shared Task</title>
<author confidence="0.839539">Kfir</author>
<affiliation confidence="0.625760333333333">School of Computer Tel Aviv Ramat Aviv,</affiliation>
<email confidence="0.980838">kfirbar@post.tau.ac.i</email>
<abstract confidence="0.997994363636364">We describe our entry in the EMNLP 2014 code-switching shared task. Our system is based on a sequential classifier, trained on the shared training set using various characterand word-level features, some calculated using a large monolingual corpora. We participated in the Twitter-genre Spanish-English track, obtaining an accuracy of 0.868 when measured on the tweet level and 0.858 on the word level.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>William B Cavnar</author>
<author>John M Trenkle</author>
</authors>
<title>Ngram-based text categorization.</title>
<date>1994</date>
<booktitle>In Proceedings of the 3rd Annual Symposium on Document Analysis and Information Retrieval (SDAIR-94),</booktitle>
<pages>161--175</pages>
<contexts>
<context position="3485" citStr="Cavnar and Trenkle, 1994" startWordPosition="536" endWordPosition="539">n Latin script. The Spanish alphabet contains some additional letters, such as those indicating stress (vowels with acute accents: ´a, ´e, ´ı, ´o, ´u), a u adorned with a diaeresis (¨u), the additional letter n˜ (e˜ne), and inverted question and exclamation punctuation marks ¿ and ¡ (used at the beginning of questions and exclamatory phrases, respectively). Although social-media users are not generally consistent in their use of accents, their appearance in a word may disclose its language. By and large, algorithms for code switching have used the character-based k-mer feature, introduced by (Cavnar and Trenkle, 1994).3 Our system is an implementation of a multiclass classifier that works on the word level, considering features that we calculate using large Spanish as well as English monolingual corpora. Working with a sequential classifier, the predicted 2http://www.twitter.com 3We propose the term “k-mer” for character k-grams, in contradistinction to word n-grams. 139 Proceedings of The First Workshop on Computational Approaches to Code Switching, pages 139–143, October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics labels of the previous words are used as features in predicting</context>
</contexts>
<marker>Cavnar, Trenkle, 1994</marker>
<rawString>William B. Cavnar and John M. Trenkle. 1994. Ngram-based text categorization. In Proceedings of the 3rd Annual Symposium on Document Analysis and Information Retrieval (SDAIR-94), pages 161– 175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih C Chang</author>
<author>Chih J Lin</author>
</authors>
<title>LIBSVM: A Library for Support Vector Machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<issue>27</issue>
<contexts>
<context position="9578" citStr="Chang and Lin, 2011" startWordPosition="1548" endWordPosition="1551">pply the models to the focus word, considering it to be the last in a sequence of three words (with the two previous words) and calculate log probabilities. Like before, we bin the values into ten discrete values, which are then used as the features’ values. An additional boolean feature is used, indicating which of the two models returned a lower log probability. 2.2 Supervised Framework We designed a sequential classifier running on top of the Weka platform (Frank et al., 2010) that is capable of processing instances sequentially, similar to YamCha (Kudo and Matsumoto, 2003). We use LibSVM (Chang and Lin, 2011), an implementation of Support Vector Machines (SVM) (Cortes and Vapnik, 1995), as the underlying technology, with a degree 2 polynomial kernel. Since we work on a multi-class classification problem, we take the one-versus-one approach. As mentioned above, we use features from a window of ±2 words before and after the word of interest. In addition, for every word, we consider as features the predicted labels of the two prior words. 3 Evaluation Results We report on the results obtained on the unseen task evaluation sets, which were provided by the workshop organizers.5 There are three evaluati</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih C. Chang and Chih J. Lin. 2011. LIBSVM: A Library for Support Vector Machines. ACM Transactions on Intelligent Systems and Technology, 2(27):1–27, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<pages>20--273</pages>
<contexts>
<context position="9656" citStr="Cortes and Vapnik, 1995" startWordPosition="1560" endWordPosition="1563">ence of three words (with the two previous words) and calculate log probabilities. Like before, we bin the values into ten discrete values, which are then used as the features’ values. An additional boolean feature is used, indicating which of the two models returned a lower log probability. 2.2 Supervised Framework We designed a sequential classifier running on top of the Weka platform (Frank et al., 2010) that is capable of processing instances sequentially, similar to YamCha (Kudo and Matsumoto, 2003). We use LibSVM (Chang and Lin, 2011), an implementation of Support Vector Machines (SVM) (Cortes and Vapnik, 1995), as the underlying technology, with a degree 2 polynomial kernel. Since we work on a multi-class classification problem, we take the one-versus-one approach. As mentioned above, we use features from a window of ±2 words before and after the word of interest. In addition, for every word, we consider as features the predicted labels of the two prior words. 3 Evaluation Results We report on the results obtained on the unseen task evaluation sets, which were provided by the workshop organizers.5 There are three evaluation sets. The first is composed of a set of unseen Twitter statuses and the oth</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Machine Learning, 20:273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eibe Frank</author>
<author>Mark Hall</author>
<author>Geoffrey Holmes</author>
<author>Richard Kirkby</author>
<author>Bernhard Pfahringer</author>
<author>Ian H Witten</author>
<author>Len Trigg</author>
</authors>
<title>Weka—A machine learning workbench for data mining.</title>
<date>2010</date>
<booktitle>In Oded Maimon and Lior Rokach, editors, Data Mining and Knowledge Discovery Handbook, chapter 66,</booktitle>
<pages>1269--1277</pages>
<publisher>Springer US,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="9442" citStr="Frank et al., 2010" startWordPosition="1526" endWordPosition="1529">quences of words in each language. We used 3-gram word-level language models, trained over large corpora in each of the languages. We apply the models to the focus word, considering it to be the last in a sequence of three words (with the two previous words) and calculate log probabilities. Like before, we bin the values into ten discrete values, which are then used as the features’ values. An additional boolean feature is used, indicating which of the two models returned a lower log probability. 2.2 Supervised Framework We designed a sequential classifier running on top of the Weka platform (Frank et al., 2010) that is capable of processing instances sequentially, similar to YamCha (Kudo and Matsumoto, 2003). We use LibSVM (Chang and Lin, 2011), an implementation of Support Vector Machines (SVM) (Cortes and Vapnik, 1995), as the underlying technology, with a degree 2 polynomial kernel. Since we work on a multi-class classification problem, we take the one-versus-one approach. As mentioned above, we use features from a window of ±2 words before and after the word of interest. In addition, for every word, we consider as features the predicted labels of the two prior words. 3 Evaluation Results We repo</context>
</contexts>
<marker>Frank, Hall, Holmes, Kirkby, Pfahringer, Witten, Trigg, 2010</marker>
<rawString>Eibe Frank, Mark Hall, Geoffrey Holmes, Richard Kirkby, Bernhard Pfahringer, Ian H. Witten, and Len Trigg. 2010. Weka—A machine learning workbench for data mining. In Oded Maimon and Lior Rokach, editors, Data Mining and Knowledge Discovery Handbook, chapter 66, pages 1269–1277. Springer US, Boston, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Interactive Poster and Demonstration Sessions of the 45th Annual Meeting of the ACL (ACL ’07),</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7432" citStr="Koehn et al., 2007" startWordPosition="1191" endWordPosition="1194">ties, we created a list of English as well Spanish names of various entity types (e.g., locations, family and given names) and used it to generate an additional boolean feature, indicating whether the word in focus is an entity name. The list was compiled out of all words beginning with a capital letter in relatively large monolingual corpora, one for English and another for Spanish. To avoid words that were capitalized because they occur at the beginning of a sentence, regardless of whether they are proper names, we first processed the text with a true-casing tool, provided as part of Moses (Koehn et al., 2007)— the open source implementation for phrase-based statistical machine translation. Our list contains about 146K entries. Intra-word level: Spanish, as opposed to English, is a morphologically rich language, demonstrating a complicated suffix-based derivational morphology. Therefore, in order to capture repeating suffixes and prefixes that may characterize the languages, we consider as features substrings of 1–3 prefix and suffix characters of the word in focus and the other four words in its window. Although it is presumed that capitalization is not used consistently in social media, we consid</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Interactive Poster and Demonstration Sessions of the 45th Annual Meeting of the ACL (ACL ’07), pages 177–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>24--31</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="9541" citStr="Kudo and Matsumoto, 2003" startWordPosition="1541" endWordPosition="1544">rge corpora in each of the languages. We apply the models to the focus word, considering it to be the last in a sequence of three words (with the two previous words) and calculate log probabilities. Like before, we bin the values into ten discrete values, which are then used as the features’ values. An additional boolean feature is used, indicating which of the two models returned a lower log probability. 2.2 Supervised Framework We designed a sequential classifier running on top of the Weka platform (Frank et al., 2010) that is capable of processing instances sequentially, similar to YamCha (Kudo and Matsumoto, 2003). We use LibSVM (Chang and Lin, 2011), an implementation of Support Vector Machines (SVM) (Cortes and Vapnik, 1995), as the underlying technology, with a degree 2 polynomial kernel. Since we work on a multi-class classification problem, we take the one-versus-one approach. As mentioned above, we use features from a window of ±2 words before and after the word of interest. In addition, for every word, we consider as features the predicted labels of the two prior words. 3 Evaluation Results We report on the results obtained on the unseen task evaluation sets, which were provided by the workshop </context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2003. Fast methods for kernel-based text analysis. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 24–31, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel M Rosenbaum</author>
</authors>
<title>Fushammiyya: Alternating style in Egyptian prose.</title>
<date>2000</date>
<journal>Journal of Arabic Linguistics (ZAL),</journal>
<pages>38--68</pages>
<contexts>
<context position="1326" citStr="Rosenbaum, 2000" startWordPosition="198" endWordPosition="200">d, 2003). Identifying the transition points is a necessary first step before applying other linguistic algorithms, which usually target a single language. A switching point may occur between sentences, phrases, words, or even between certain morphological components. Code switching happens frequently in informal ways of communication, such as verbal conversations, blogs and microblogs; however, there are many examples in which languages are switched in formal settings. For example, alternating between Colloquial Egyptian Arabic and Modern Standard Arabic in modern Egyptian prose is prevalent (Rosenbaum, 2000). This shared task (Solorio et al., 2014),1 the first of its kind, challenges participants with identifying those switching points in blogs as well as in microblog posts. Given posts with a mix of a specific pair of languages, each participating system is required to identify the language of every word. Four language-pair tracks were offered by the task organizers: Spanish-English, NepaliEnglish, Modern Standard Arabic and Colloquial 1http://emnlp2014.org/workshops/ CodeSwitch/call.html Nachum Dershowitz School of Computer Science Tel Aviv University Ramat Aviv, Israel nachumd@tau.ac.il Arabic</context>
</contexts>
<marker>Rosenbaum, 2000</marker>
<rawString>Gabriel M. Rosenbaum. 2000. Fushammiyya: Alternating style in Egyptian prose. Journal of Arabic Linguistics (ZAL), 38:68–87.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Thamar Solorio</author>
<author>Elizabeth Blair</author>
<author>Suraj Maharjan</author>
<author>Steve Bethard</author>
<author>Mona Diab</author>
<author>Mahmoud Gonheim</author>
<author>Abdelati Hawwari</author>
<author>Fahad AlGhamdi</author>
<author>Julia Hirshberg</author>
<author>Alison Chang</author>
<author>Pascale Fung</author>
</authors>
<title>Overview for the first shared task on language identification in codeswitched data.</title>
<date>2014</date>
<booktitle>In Proceedings of the First Workshop on Computational Approaches to Code-Switching. EMNLP 2014, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Doha, Qatar.</location>
<contexts>
<context position="1367" citStr="Solorio et al., 2014" startWordPosition="204" endWordPosition="207"> points is a necessary first step before applying other linguistic algorithms, which usually target a single language. A switching point may occur between sentences, phrases, words, or even between certain morphological components. Code switching happens frequently in informal ways of communication, such as verbal conversations, blogs and microblogs; however, there are many examples in which languages are switched in formal settings. For example, alternating between Colloquial Egyptian Arabic and Modern Standard Arabic in modern Egyptian prose is prevalent (Rosenbaum, 2000). This shared task (Solorio et al., 2014),1 the first of its kind, challenges participants with identifying those switching points in blogs as well as in microblog posts. Given posts with a mix of a specific pair of languages, each participating system is required to identify the language of every word. Four language-pair tracks were offered by the task organizers: Spanish-English, NepaliEnglish, Modern Standard Arabic and Colloquial 1http://emnlp2014.org/workshops/ CodeSwitch/call.html Nachum Dershowitz School of Computer Science Tel Aviv University Ramat Aviv, Israel nachumd@tau.ac.il Arabic, and Mandarin-English. For each language</context>
</contexts>
<marker>Solorio, Blair, Maharjan, Bethard, Diab, Gonheim, Hawwari, AlGhamdi, Hirshberg, Chang, Fung, 2014</marker>
<rawString>Thamar Solorio, Elizabeth Blair, Suraj Maharjan, Steve Bethard, Mona Diab, Mahmoud Gonheim, Abdelati Hawwari, Fahad AlGhamdi, Julia Hirshberg, Alison Chang, and Pascale Fung. 2014. Overview for the first shared task on language identification in codeswitched data. In Proceedings of the First Workshop on Computational Approaches to Code-Switching. EMNLP 2014, Conference on Empirical Methods in Natural Language Processing, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Winford</author>
</authors>
<title>Code Switching: Linguistic Aspects, chapter 5,</title>
<date>2003</date>
<pages>126--167</pages>
<publisher>Blackwell Publishing,</publisher>
<location>Malden, MA.</location>
<contexts>
<context position="718" citStr="Winford, 2003" startWordPosition="109" endWordPosition="110">cience Tel Aviv University Ramat Aviv, Israel kfirbar@post.tau.ac.i Abstract We describe our entry in the EMNLP 2014 code-switching shared task. Our system is based on a sequential classifier, trained on the shared training set using various character- and word-level features, some calculated using a large monolingual corpora. We participated in the Twitter-genre Spanish-English track, obtaining an accuracy of 0.868 when measured on the tweet level and 0.858 on the word level. 1 Introduction Code switching is the act of changing language while speaking or writing, as often done by bilinguals (Winford, 2003). Identifying the transition points is a necessary first step before applying other linguistic algorithms, which usually target a single language. A switching point may occur between sentences, phrases, words, or even between certain morphological components. Code switching happens frequently in informal ways of communication, such as verbal conversations, blogs and microblogs; however, there are many examples in which languages are switched in formal settings. For example, alternating between Colloquial Egyptian Arabic and Modern Standard Arabic in modern Egyptian prose is prevalent (Rosenbau</context>
</contexts>
<marker>Winford, 2003</marker>
<rawString>Donald Winford, 2003. Code Switching: Linguistic Aspects, chapter 5, pages 126–167. Blackwell Publishing, Malden, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>