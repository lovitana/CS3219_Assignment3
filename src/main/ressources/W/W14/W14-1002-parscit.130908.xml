<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000683">
<title confidence="0.9968085">
Using Hypothesis Selection Based Features for Confusion Network MT
System Combination
</title>
<author confidence="0.876134">
Sahar Ghannay Lo¨ıc Barrault
</author>
<affiliation confidence="0.794702">
LIUM, University of Le Mans LIUM, University of Le Mans
</affiliation>
<address confidence="0.545375">
Le Mans, France Le Mans, France
</address>
<email confidence="0.981732">
Sahar.Gannay.Etu@univ-lemans.fr loic.barrault@lium.univ-lemans.fr
</email>
<sectionHeader confidence="0.993163" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999471875">
This paper describes the development op-
erated into MANY, an open source sys-
tem combination software based on con-
fusion networks developed at LIUM. The
hypotheses from Chinese-English MT sys-
tems were combined with a new version of
the software. MANY has been updated in
order to use word confidence score and to
boost n-grams occurring in input hypothe-
ses. In this paper we propose either to
use an adapted language model or adding
some additional features in the decoder to
boost certain n-grams probabilities. Ex-
perimental results show that the updates
yielded significant improvements in terms
of BLEU score.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999857333333333">
MANY (Barrault, 2010) is an open source system
combination software based on Confusion Net-
works (CN). The combination by confusion net-
works generates an exponential number of hy-
potheses. Most of these hypotheses contain n-
grams do not exist in input hypotheses. Some of
these new n-grams are ungrammatical, despite the
presence of a language model. These novel n-
grams are due to errors in hypothesis alignment
and the confusion network structure. In section
3 we present two methods used to boost n-grams
present in input hypotheses.
Currently, decisions taken by the decoder
mainly depend on the language model score,
which is deemed insufficient to precisely evaluate
the hypotheses. In consequence, it is interesting
to estimate a score for better judging their qual-
ity. The challenge of our work is to exploit certain
parameters defined by (Almut Siljaand and Vogel,
2008) to calculate word confidence score. These
features are detailed in section 4. The approach is
evaluated on the internal data of the BOLT project.
Some experiments have been performed on the
Chinese-English system combination task. The
experimental results are presented in section 5.
Before that, a quick description of MANY, includ-
ing recent developments can be found in section 2.
</bodyText>
<sectionHeader confidence="0.962185" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999798161290323">
MANY is a system combination software (Bar-
rault, 2010) based on the decoding of a lattice
made of several Confusion Networks (CN). This
is a widespread approach in MT system combina-
tion, see e.g. (Antti-Veikko I.Rosti and Schwartz,
2007; Damianos Karakos and Dreyer, 2008; Shen
et al., 2008; Antti-Veikko I. Rosti and Schw,
2009). MANY can be decomposed in two main
modules. The first one is the alignment module
which is a modified version of TERp (Matthew
G. Snover and Schwartz, 2009). Its role is to in-
crementally align the hypotheses against a back-
bone in order to create a confusion network. 1-best
hypotheses from all M systems are aligned in or-
der to build M confusion networks (one for each
system considered as backbone). These confusion
networks are then connected together to create a
lattice. This module uses different costs (which
corresponds to a match, an insertion, a deletion,
a substitution, a shift, a synonym and a stem)
to compute the best alignment and incrementally
build a confusion network. In the case of confu-
sion network, the match (substitution, synonym,
and stem) costs are considered when the word in
the hypothesis matches (is a substitution, a syn-
onym or a stem of) at least one word of the consid-
ered confusion sets in the CN. The second module
is the decoder. This decoder is based on the token
pass algorithm and it accepts as input the lattice
previously created. The probabilities computed in
the decoder can be expressed as follow:
</bodyText>
<page confidence="0.93469">
2
</page>
<note confidence="0.812373">
Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 2–6,
Gothenburg, Sweden, April 27, 2014. c�2014 Association for Computational Linguistics
</note>
<equation confidence="0.991241">
log(Pw) = αi log(hi(t)) (1)
i
</equation>
<bodyText confidence="0.98743175">
where t is the hypothesis, the αi are the weights of
the feature functions hi .
The following features are considered for de-
coding:
</bodyText>
<listItem confidence="0.94907694117647">
• The language model probability: the proba-
bility given by a 4-gram language model.
• The word penalty: penalty depending on the
size (in words) of the hypothesis.
• The null-arc penalty: penalty depending on
the number of null-arcs crossed in the lattice
to obtain the hypothesis.
• System weights: each system receives a
weight according to its importance. Each
word receives a weight corresponding to the
sum of the weights of all systems which pro-
posed it.
Our goal is to include the following ones:
• Word confidence score: each word is given a
score, which is the combination of the three
scores described in section 4 (equation 7).
• n-gram count: number of n-grams present in
</listItem>
<bodyText confidence="0.927552444444444">
input hypotheses for each combined hypoth-
esis.
In most cases, the new features have best
weights according to MERT (e.g. the best
decoding weights of these features by com-
bining two systems are: lm-weight: 0.049703,
word-penalty: 0.0605602, null-penalty: 0.319905,
weight-word-score: -0.378226, weight-ngram-
count: -0.11687, priors: 0.0141794#-0.0605561).
</bodyText>
<sectionHeader confidence="0.992376" genericHeader="method">
3 boost n-grams
</sectionHeader>
<bodyText confidence="0.999960125">
We defined two methods to boost n-grams present
in input hypotheses. The first one is adding the
count of bi or tri-grams like a new feature to the
decoder as mentioned in Section 2. The second
method is using an adapted language model (LM)
to decode the lattice, in order to modify n-grams
probabilities, that have been observed in input hy-
potheses.
</bodyText>
<subsectionHeader confidence="0.828018">
Language models
</subsectionHeader>
<bodyText confidence="0.999982909090909">
Three 4-gram language models named LM-Web,
LM-Tune and LM-Test, are used to interpolate the
adapted LM. They were trained respectively on the
English web Corpus and the system outputs : de-
velopment and test sets (except their references)
involved in system combination, using the SRILM
Toolkit (Stolcke, 2002). The resulting model from
the interpolation of LM-Tune and LM-Test is in-
terpolated linearly with the LM-Web to build the
adapted LM. These models are tuned to minimize
the perplexity on the tune reference.
</bodyText>
<sectionHeader confidence="0.950514" genericHeader="method">
4 Word confidence score
</sectionHeader>
<bodyText confidence="0.99924188">
The best hypothesis selection relies on several
features. In (Barrault, 2011) decisions taken by
the decoder depend mainly on a n-gram language
model, but it is sometimes insufficient to evaluate
correctly the quality of the hypotheses. In order
to improve these decisions, some additional infor-
mation should be used. Several researches pre-
sented some studies of confidence scores at word
and sentence level, such as (Almut Siljaand and
Vogel, 2008) and (Ueffing and Ney, 2007). A large
set of confidence scores were calculated over the
n-best list. (Almut Siljaand and Vogel, 2008) de-
fines several features extracted from n-best lists (at
the sentence level) to select the best hypothesis in
a combination approach via hypothesis selection.
The challenge of our work is to exploit these fea-
tures to estimate a confidence score at the word
level and injecting it into the confusion networks.
The following features are considered:
Word agreement score based on a window
of size t around position i
This score represents the relative frequency of hy-
potheses in the n-best lists containing the word e
in a window of size t around the position i. It is
computed as follows:
</bodyText>
<equation confidence="0.99918475">
WAk(ei,t) = Nk E
1 Nk
p=0 f(ep,i+t
p,i−t, e) (2)
</equation>
<bodyText confidence="0.998941571428571">
where NK is the number of hypotheses in the n-
best list for the corresponding source sentence k,
t={0, 1 or 2} and f(Sji , w) =1 if w appears in the
word sequence Sji .
When t equals 0, this means that i = t, then this
score only depends on words at the exact position
i. The agreement score is calculated accordingly:
</bodyText>
<page confidence="0.85453">
3
</page>
<equation confidence="0.982980333333333">
1 Nk
WAk (ei) = E
Nk
p=0
�
WAk(ei) +
NAk(ei)j + NPk(ei)j
f(ep,i, e) (3)
Sk(ei) =
(7)
1 + 2 ∗ |NG|
j∈NG
</equation>
<bodyText confidence="0.99973675">
The two equations described above, are handled
in our contribution, thus the final word agreement
score is the average between them if WAk(ei) =� 0
otherwise it is equal to WAk(ei,t) score.
</bodyText>
<subsectionHeader confidence="0.7495265">
Position independent n-best List n-gram
Agreement
</subsectionHeader>
<bodyText confidence="0.999714888888889">
This score represents the percentage of hypothe-
ses in the n-best lists that contain the n-gram
eii−(n−1), independently of its position in the sen-
tence, as shown in Equation 4. For each hypothe-
sis the n-gram is counted only once.
where NG is the set of n-gram order, experimen-
tally defined as NG={2-gram, 3-gram} and t = 2.
Each n-gram order in the set NG is considered as
a separate feature.
</bodyText>
<sectionHeader confidence="0.999529" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999753857142857">
During experiments, data from the BOLT project
on the Chinese to English translation task are used.
The outputs (200-best lists) of eight translation
systems were provided by the partners. The best
six systems were used for combination. Syscom-
tune is used as development set and Dev as internal
test, these corpora are described in Table 1:
</bodyText>
<equation confidence="0.9964806">
1 Nk
NAk(eii−(n−1)) = Nk E
i I
f (ei−(n−1), e1 ,p) (4)
p=0
</equation>
<bodyText confidence="0.902329">
where f(eii−(n−1), eI1,p) = 1 if the n-gram
</bodyText>
<table confidence="0.776726">
NAME #sent. #words.
Syscomtune 985 28671
Dev 1124 26350
</table>
<bodyText confidence="0.9545685">
eii−(n−1) exists in the pth hypothesis of the n-best
list. We use n-gram lengths of 2 and 3 as two sep-
arate features.
The position independent n-best list word agree-
ment is the average count of n-grams that contain
the word e. It is computed as:
</bodyText>
<equation confidence="0.861002333333333">
NAk(eii−(n−1)) (5)
Were Nng is the number of n-grams of hypothesis
k.
</equation>
<bodyText confidence="0.81303925">
N-best list n-gram probability
This score is a traditional n-gram language model
probability. The n-gram probability for a target
word ei given its history ei−1
</bodyText>
<equation confidence="0.909206857142857">
i−(n−1) is defined as:
C(ei i−(n−1))
NPk(ei|ei−1
i−(n−1)) = C(ei−1 (6)
i−(n−1))
Where C(eii−(n−1)) is the count of the n-gram
ei i−(n−1) in the n-best list for the hypothesis k.
</equation>
<bodyText confidence="0.9943792">
The n-best list word probability NPk(ei) is the av-
erage of the n-grams probabilities that contain the
word e.
The word confidence score is computed using
these three features as follows:
</bodyText>
<tableCaption confidence="0.9873635">
Table 1: BOLT corpora : number of sentences and words
calculated on the reference.
</tableCaption>
<bodyText confidence="0.999225653846154">
To explore the impact of each new feature on
the results, they are tested one by one (added one
by one in the decoder) then both, given that, the
oldest ones are used in all cases. These tests
are named respectively boost-ngram, CS-ngram and
Boost-ngram+CS-ngram later.
The language model is used to guide the decod-
ing in order to improve translation quality, there-
fore we evaluated the baseline combination system
and each test (described above) with two LMs named
LM-Web and LM-ad and compared their perfor-
mance in terms of BLEU. By comparing their per-
plexities, that are respectively 295.43 and 169.923,
we observe a relative reduction of about 42.5%,
that results in an improvement of BLEU score.
Figure 1 shows the results of combining the
best systems (up to 6) using these models, that
achieved respectively an improvement of 0.85 and
1.17 %BLEU point relatively to the best single
system. In the remaining experiments we assume
that MANY-LM-Web is the baseline.
Figure 2 shows interesting differences in how
approaches to boost n-gram estimates behave
when the number of input systems is varied. This
is due to the fact that results are conditioned by the
number and quality of n-grams added to the lattice
</bodyText>
<figure confidence="0.80570675">
1
NAk(ei) =
Nng
Nny
n=0
4
Bleu
16 LM Web LM-ad
15,75
15,5
15,25
15
14,75
14,5
2 3 4 5 6
Systems
</figure>
<figureCaption confidence="0.9946785">
Figure 1: Performance (%BLEU-cased) of MANY after
reassessment by LM-Web and LM-ad on the test set.
</figureCaption>
<bodyText confidence="0.9969338">
when the number of systems is varied, that pro-
vides varied outputs. In consequence, we observe
that using the adapted LM is better than n-gram
count feature to boost n-grams, indeed it guaran-
tees n-grams quality.
</bodyText>
<subsectionHeader confidence="0.70837">
Systems
</subsectionHeader>
<figureCaption confidence="0.999245">
Figure 2: Comparison of n-gram boost approaches.
</figureCaption>
<figure confidence="0.47149">
systems
</figure>
<figureCaption confidence="0.984725">
Figure 3: The impact of confidence score on the results
when using LM-Web and LM-ad for decoding.
</figureCaption>
<bodyText confidence="0.993706625">
The 200-best lists are operated to estimate the
word confidence score that contributes the most to
the improvement of results when several (up to 6)
systems are combined, as described in Figure 3,
whatever the language model used, compared to
the baseline. In addition, it seems that the confi-
dence score performs better with the adapted LM
than LM-Web.
</bodyText>
<table confidence="0.998857">
Systems BLEU
Best single 14.36
Sys2 14.21
Sys3 13.76
Sys4 13.52
Sys5 13.36
Sys6 12.99
MANY+LM-Web(baseline) 15.14
Boost-2gram+LM-Web 15.25
Boost-3gram+LM-Web 15.50
CS-2gram+LM-Web 15.32
CS-3gram+LM-Web 15.26
Boost-2gram+CS-2gram+LM-Web 15.39
Boost-3gram+CS-3gram+LM-Web 15.78
MANY+LM-ad 15.49
Boost-2gram+LM-ad 15.24
Boost-3gram+LM-ad 15.32
CS-2gram+LM-ad 15.72
CS-3gram+LM-ad 15.85
Boost-2gram+CS-2gram+LM-ad 15.61
Boost-3gram+CS-3gram+LM-ad 15.74
</table>
<tableCaption confidence="0.999193">
Table 2: Impact of new features and the adapted LM on the
combination result of six systems.
</tableCaption>
<bodyText confidence="0.9983223">
Table 2 summarizes the best experiments re-
sults by combining the best six systems on the test
set. We observe that new features yield signifi-
cant improvements in term of BLEU score what-
ever the language model used for decoding. But
it is clear that the adapted LM performs rela-
tively well in comparison with LM-Web, so the
best gains achieved over the best single system and
the baseline are respectively 1.49 and 0.71 for CS-
3-gram+LM-ad.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999645363636364">
Several technical improvements have been per-
formed into the MT system combination MANY,
that are evaluated with the BOLT project data.
An adapted LM and new features gave significant
gains. Previous experimental results show that
using the adapted LM in rescoring together with
word confidence score and the oldest features im-
proves results in term of BLEU score. This even
results in better translations than using a classi-
cal LM (LM-Web) trained on a monolingual training
corpus.
</bodyText>
<figure confidence="0.995550535714286">
16
15,75
15,5
Bleu
15,25
15
14,75
14,5
MANY-LM-ad Boost-2gram-LM-Web
Boost-3gram-LM-Web
2 3 4 5 6
2 3 4 5 6
Bleu
15,88
15,75
15,63
15,38
15,25
15,13
14,88
14,75
14,63
15,5
14,5
16
15
CM-2g-LM-Web CM-2g+LM-ad CM-3g-LM-Web
CM-3g+LM-ad Baseline
</figure>
<page confidence="0.925069">
5
</page>
<sectionHeader confidence="0.989042" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999719260869565">
Hildebrand Almut Siljaand and Stephan Vogel. 2008.
Combination of Machine Translation Systems via
Hypothesis Selection from Combined N-Best Lists.
Proceedings of the Eighth Conference of the Asso-
ciation for Machine Translation in the Americas,
pages 254–261.
Spyros Matsoukas Antti-Veikko I. Rosti, Bing Zhang
and Richard Schw. 2009. Incremental Hypothe-
sis Alignment with Flexible Matching for Building
Confusion Networks: BBN System Description for
WMT09 System Combination Task. StatMT ’09
Proceedings of the Fourth Workshop on Statistical
Machine Translation, pages 61–65.
Spyros Matsoukas Antti-Veikko I.Rosti and Richard
Schwartz. 2007. Improved Word-Level System
Combination for Machine Translation. Proceedings
of the 45th Annual Meeting of the Association of
Computational Linguistics, pages 312–319.
Loic Barrault. 2010. MANY Open Source Machine
Translation System Combination. The Prague Bul-
letin of Mathematical Linguistics, pages 147–155.
Loic Barrault. 2011. MANY improvements for
WMT’11. Proceedings of the Sixth Workshop on
Statistical Machine Translation, pages 135– 139.
Sanjeev Khudanpur Damianos Karakos, Jason Eisner
and Markus Dreyer. 2008. Machine Translation
System Combination using ITG-based Alignments.
In 46th Annual Meeting of the Association for Com-
putational Linguistics, pages 81–84.
Bonnie Dorr Matthew G. Snover, Nitin Madnani and
Richard Schwartz. 2009. TER-Plus: Paraphrase,
semantic, and alignment enhancements to transla-
tion edit rate. Machine Translation journal, pages
117–127.
Wade Shen, Brian Delaney, Tim Anderson, and Ray
Slyh. 2008. The MIT-LL/AFRL IWSLT-2008 MT
System. In Internationnal Workshop on Spoken
Language Translation, pages 69–76.
Andreas Stolcke. 2002. Srilm-an extensible lan-
guage modeling toolkit. In Proceedings Interna-
tional Conference for Spoken Language Processing,
Denver, Colorado.
Nicola Ueffing and Hermann Ney. 2007. Word-
Level Confidence Estimation for Machine Transla-
tion. Computational Linguistics journal, pages 9–
40.
</reference>
<page confidence="0.998765">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.449440">
<title confidence="0.9996435">Using Hypothesis Selection Based Features for Confusion Network System Combination</title>
<author confidence="0.806555">Sahar Ghannay Lo¨ıc Barrault</author>
<affiliation confidence="0.799534">LIUM, University of Le Mans LIUM, University of Le Mans</affiliation>
<address confidence="0.661722">Le Mans, France Le Mans, France</address>
<email confidence="0.609333">Sahar.Gannay.Etu@univ-lemans.frloic.barrault@lium.univ-lemans.fr</email>
<abstract confidence="0.997977352941176">This paper describes the development operated into MANY, an open source system combination software based on confusion networks developed at LIUM. The hypotheses from Chinese-English MT systems were combined with a new version of the software. MANY has been updated in order to use word confidence score and to occurring in input hypotheses. In this paper we propose either to use an adapted language model or adding some additional features in the decoder to certain probabilities. Experimental results show that the updates yielded significant improvements in terms of BLEU score.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hildebrand Almut Siljaand</author>
<author>Stephan Vogel</author>
</authors>
<title>Combination of Machine Translation Systems via Hypothesis Selection from Combined N-Best Lists.</title>
<date>2008</date>
<booktitle>Proceedings of the Eighth Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>254--261</pages>
<contexts>
<context position="1779" citStr="Siljaand and Vogel, 2008" startWordPosition="273" endWordPosition="276">ypotheses. Some of these new n-grams are ungrammatical, despite the presence of a language model. These novel ngrams are due to errors in hypothesis alignment and the confusion network structure. In section 3 we present two methods used to boost n-grams present in input hypotheses. Currently, decisions taken by the decoder mainly depend on the language model score, which is deemed insufficient to precisely evaluate the hypotheses. In consequence, it is interesting to estimate a score for better judging their quality. The challenge of our work is to exploit certain parameters defined by (Almut Siljaand and Vogel, 2008) to calculate word confidence score. These features are detailed in section 4. The approach is evaluated on the internal data of the BOLT project. Some experiments have been performed on the Chinese-English system combination task. The experimental results are presented in section 5. Before that, a quick description of MANY, including recent developments can be found in section 2. 2 System description MANY is a system combination software (Barrault, 2010) based on the decoding of a lattice made of several Confusion Networks (CN). This is a widespread approach in MT system combination, see e.g.</context>
<context position="6417" citStr="Siljaand and Vogel, 2008" startWordPosition="1031" endWordPosition="1034"> and LM-Test is interpolated linearly with the LM-Web to build the adapted LM. These models are tuned to minimize the perplexity on the tune reference. 4 Word confidence score The best hypothesis selection relies on several features. In (Barrault, 2011) decisions taken by the decoder depend mainly on a n-gram language model, but it is sometimes insufficient to evaluate correctly the quality of the hypotheses. In order to improve these decisions, some additional information should be used. Several researches presented some studies of confidence scores at word and sentence level, such as (Almut Siljaand and Vogel, 2008) and (Ueffing and Ney, 2007). A large set of confidence scores were calculated over the n-best list. (Almut Siljaand and Vogel, 2008) defines several features extracted from n-best lists (at the sentence level) to select the best hypothesis in a combination approach via hypothesis selection. The challenge of our work is to exploit these features to estimate a confidence score at the word level and injecting it into the confusion networks. The following features are considered: Word agreement score based on a window of size t around position i This score represents the relative frequency of hyp</context>
</contexts>
<marker>Siljaand, Vogel, 2008</marker>
<rawString>Hildebrand Almut Siljaand and Stephan Vogel. 2008. Combination of Machine Translation Systems via Hypothesis Selection from Combined N-Best Lists. Proceedings of the Eighth Conference of the Association for Machine Translation in the Americas, pages 254–261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
<author>Richard Schw</author>
</authors>
<title>Incremental Hypothesis Alignment with Flexible Matching for Building Confusion Networks:</title>
<date>2009</date>
<booktitle>BBN System Description for WMT09 System Combination Task. StatMT ’09 Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>61--65</pages>
<marker>Rosti, Zhang, Schw, 2009</marker>
<rawString>Spyros Matsoukas Antti-Veikko I. Rosti, Bing Zhang and Richard Schw. 2009. Incremental Hypothesis Alignment with Flexible Matching for Building Confusion Networks: BBN System Description for WMT09 System Combination Task. StatMT ’09 Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 61–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spyros Matsoukas Antti-Veikko I Rosti</author>
<author>Richard Schwartz</author>
</authors>
<title>Improved Word-Level System Combination for Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="2420" citStr="Rosti and Schwartz, 2007" startWordPosition="375" endWordPosition="378">d confidence score. These features are detailed in section 4. The approach is evaluated on the internal data of the BOLT project. Some experiments have been performed on the Chinese-English system combination task. The experimental results are presented in section 5. Before that, a quick description of MANY, including recent developments can be found in section 2. 2 System description MANY is a system combination software (Barrault, 2010) based on the decoding of a lattice made of several Confusion Networks (CN). This is a widespread approach in MT system combination, see e.g. (Antti-Veikko I.Rosti and Schwartz, 2007; Damianos Karakos and Dreyer, 2008; Shen et al., 2008; Antti-Veikko I. Rosti and Schw, 2009). MANY can be decomposed in two main modules. The first one is the alignment module which is a modified version of TERp (Matthew G. Snover and Schwartz, 2009). Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network. 1-best hypotheses from all M systems are aligned in order to build M confusion networks (one for each system considered as backbone). These confusion networks are then connected together to create a lattice. This module uses different cos</context>
</contexts>
<marker>Rosti, Schwartz, 2007</marker>
<rawString>Spyros Matsoukas Antti-Veikko I.Rosti and Richard Schwartz. 2007. Improved Word-Level System Combination for Machine Translation. Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Barrault</author>
</authors>
<title>MANY Open Source Machine Translation System Combination. The Prague Bulletin of Mathematical Linguistics,</title>
<date>2010</date>
<pages>147--155</pages>
<contexts>
<context position="925" citStr="Barrault, 2010" startWordPosition="137" endWordPosition="138">ment operated into MANY, an open source system combination software based on confusion networks developed at LIUM. The hypotheses from Chinese-English MT systems were combined with a new version of the software. MANY has been updated in order to use word confidence score and to boost n-grams occurring in input hypotheses. In this paper we propose either to use an adapted language model or adding some additional features in the decoder to boost certain n-grams probabilities. Experimental results show that the updates yielded significant improvements in terms of BLEU score. 1 Introduction MANY (Barrault, 2010) is an open source system combination software based on Confusion Networks (CN). The combination by confusion networks generates an exponential number of hypotheses. Most of these hypotheses contain ngrams do not exist in input hypotheses. Some of these new n-grams are ungrammatical, despite the presence of a language model. These novel ngrams are due to errors in hypothesis alignment and the confusion network structure. In section 3 we present two methods used to boost n-grams present in input hypotheses. Currently, decisions taken by the decoder mainly depend on the language model score, whi</context>
<context position="2238" citStr="Barrault, 2010" startWordPosition="346" endWordPosition="348">to estimate a score for better judging their quality. The challenge of our work is to exploit certain parameters defined by (Almut Siljaand and Vogel, 2008) to calculate word confidence score. These features are detailed in section 4. The approach is evaluated on the internal data of the BOLT project. Some experiments have been performed on the Chinese-English system combination task. The experimental results are presented in section 5. Before that, a quick description of MANY, including recent developments can be found in section 2. 2 System description MANY is a system combination software (Barrault, 2010) based on the decoding of a lattice made of several Confusion Networks (CN). This is a widespread approach in MT system combination, see e.g. (Antti-Veikko I.Rosti and Schwartz, 2007; Damianos Karakos and Dreyer, 2008; Shen et al., 2008; Antti-Veikko I. Rosti and Schw, 2009). MANY can be decomposed in two main modules. The first one is the alignment module which is a modified version of TERp (Matthew G. Snover and Schwartz, 2009). Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network. 1-best hypotheses from all M systems are aligned in orde</context>
</contexts>
<marker>Barrault, 2010</marker>
<rawString>Loic Barrault. 2010. MANY Open Source Machine Translation System Combination. The Prague Bulletin of Mathematical Linguistics, pages 147–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loic Barrault</author>
</authors>
<title>MANY improvements for WMT’11.</title>
<date>2011</date>
<booktitle>Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>135--139</pages>
<contexts>
<context position="6045" citStr="Barrault, 2011" startWordPosition="974" endWordPosition="975">ree 4-gram language models named LM-Web, LM-Tune and LM-Test, are used to interpolate the adapted LM. They were trained respectively on the English web Corpus and the system outputs : development and test sets (except their references) involved in system combination, using the SRILM Toolkit (Stolcke, 2002). The resulting model from the interpolation of LM-Tune and LM-Test is interpolated linearly with the LM-Web to build the adapted LM. These models are tuned to minimize the perplexity on the tune reference. 4 Word confidence score The best hypothesis selection relies on several features. In (Barrault, 2011) decisions taken by the decoder depend mainly on a n-gram language model, but it is sometimes insufficient to evaluate correctly the quality of the hypotheses. In order to improve these decisions, some additional information should be used. Several researches presented some studies of confidence scores at word and sentence level, such as (Almut Siljaand and Vogel, 2008) and (Ueffing and Ney, 2007). A large set of confidence scores were calculated over the n-best list. (Almut Siljaand and Vogel, 2008) defines several features extracted from n-best lists (at the sentence level) to select the bes</context>
</contexts>
<marker>Barrault, 2011</marker>
<rawString>Loic Barrault. 2011. MANY improvements for WMT’11. Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 135– 139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanjeev Khudanpur Damianos Karakos</author>
<author>Jason Eisner</author>
<author>Markus Dreyer</author>
</authors>
<title>Machine Translation System Combination using ITG-based Alignments.</title>
<date>2008</date>
<booktitle>In 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>81--84</pages>
<marker>Karakos, Eisner, Dreyer, 2008</marker>
<rawString>Sanjeev Khudanpur Damianos Karakos, Jason Eisner and Markus Dreyer. 2008. Machine Translation System Combination using ITG-based Alignments. In 46th Annual Meeting of the Association for Computational Linguistics, pages 81–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Dorr Matthew G Snover</author>
<author>Nitin Madnani</author>
<author>Richard Schwartz</author>
</authors>
<title>TER-Plus: Paraphrase, semantic, and alignment enhancements to translation edit rate. Machine Translation journal,</title>
<date>2009</date>
<pages>117--127</pages>
<marker>Snover, Madnani, Schwartz, 2009</marker>
<rawString>Bonnie Dorr Matthew G. Snover, Nitin Madnani and Richard Schwartz. 2009. TER-Plus: Paraphrase, semantic, and alignment enhancements to translation edit rate. Machine Translation journal, pages 117–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wade Shen</author>
<author>Brian Delaney</author>
<author>Tim Anderson</author>
<author>Ray Slyh</author>
</authors>
<date>2008</date>
<booktitle>The MIT-LL/AFRL IWSLT-2008 MT System. In Internationnal Workshop on Spoken Language Translation,</booktitle>
<pages>69--76</pages>
<contexts>
<context position="2474" citStr="Shen et al., 2008" startWordPosition="384" endWordPosition="387"> The approach is evaluated on the internal data of the BOLT project. Some experiments have been performed on the Chinese-English system combination task. The experimental results are presented in section 5. Before that, a quick description of MANY, including recent developments can be found in section 2. 2 System description MANY is a system combination software (Barrault, 2010) based on the decoding of a lattice made of several Confusion Networks (CN). This is a widespread approach in MT system combination, see e.g. (Antti-Veikko I.Rosti and Schwartz, 2007; Damianos Karakos and Dreyer, 2008; Shen et al., 2008; Antti-Veikko I. Rosti and Schw, 2009). MANY can be decomposed in two main modules. The first one is the alignment module which is a modified version of TERp (Matthew G. Snover and Schwartz, 2009). Its role is to incrementally align the hypotheses against a backbone in order to create a confusion network. 1-best hypotheses from all M systems are aligned in order to build M confusion networks (one for each system considered as backbone). These confusion networks are then connected together to create a lattice. This module uses different costs (which corresponds to a match, an insertion, a dele</context>
</contexts>
<marker>Shen, Delaney, Anderson, Slyh, 2008</marker>
<rawString>Wade Shen, Brian Delaney, Tim Anderson, and Ray Slyh. 2008. The MIT-LL/AFRL IWSLT-2008 MT System. In Internationnal Workshop on Spoken Language Translation, pages 69–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings International Conference for Spoken Language Processing,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="5737" citStr="Stolcke, 2002" startWordPosition="925" endWordPosition="926">heses. The first one is adding the count of bi or tri-grams like a new feature to the decoder as mentioned in Section 2. The second method is using an adapted language model (LM) to decode the lattice, in order to modify n-grams probabilities, that have been observed in input hypotheses. Language models Three 4-gram language models named LM-Web, LM-Tune and LM-Test, are used to interpolate the adapted LM. They were trained respectively on the English web Corpus and the system outputs : development and test sets (except their references) involved in system combination, using the SRILM Toolkit (Stolcke, 2002). The resulting model from the interpolation of LM-Tune and LM-Test is interpolated linearly with the LM-Web to build the adapted LM. These models are tuned to minimize the perplexity on the tune reference. 4 Word confidence score The best hypothesis selection relies on several features. In (Barrault, 2011) decisions taken by the decoder depend mainly on a n-gram language model, but it is sometimes insufficient to evaluate correctly the quality of the hypotheses. In order to improve these decisions, some additional information should be used. Several researches presented some studies of confid</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm-an extensible language modeling toolkit. In Proceedings International Conference for Spoken Language Processing, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>WordLevel Confidence Estimation for Machine Translation. Computational Linguistics journal,</title>
<date>2007</date>
<pages>9--40</pages>
<contexts>
<context position="6445" citStr="Ueffing and Ney, 2007" startWordPosition="1036" endWordPosition="1039">nearly with the LM-Web to build the adapted LM. These models are tuned to minimize the perplexity on the tune reference. 4 Word confidence score The best hypothesis selection relies on several features. In (Barrault, 2011) decisions taken by the decoder depend mainly on a n-gram language model, but it is sometimes insufficient to evaluate correctly the quality of the hypotheses. In order to improve these decisions, some additional information should be used. Several researches presented some studies of confidence scores at word and sentence level, such as (Almut Siljaand and Vogel, 2008) and (Ueffing and Ney, 2007). A large set of confidence scores were calculated over the n-best list. (Almut Siljaand and Vogel, 2008) defines several features extracted from n-best lists (at the sentence level) to select the best hypothesis in a combination approach via hypothesis selection. The challenge of our work is to exploit these features to estimate a confidence score at the word level and injecting it into the confusion networks. The following features are considered: Word agreement score based on a window of size t around position i This score represents the relative frequency of hypotheses in the n-best lists </context>
</contexts>
<marker>Ueffing, Ney, 2007</marker>
<rawString>Nicola Ueffing and Hermann Ney. 2007. WordLevel Confidence Estimation for Machine Translation. Computational Linguistics journal, pages 9– 40.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>