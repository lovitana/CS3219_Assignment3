<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007909">
<title confidence="0.999658">
A Comparative Study of Conversion Aided Methods for WordNet
Sentence Textual Similarity
</title>
<author confidence="0.994282">
Muhidin Mohamed M. Oussalah
</author>
<affiliation confidence="0.7896895">
EECE University of Birmingham, EECE University of Birmingham,
Edgbaston, Birmingham, UK Edgbaston, Birmingham, UK
</affiliation>
<email confidence="0.958136">
Mam256@bham.ac.uk M.Oussalah@bham.ac.uk
</email>
<sectionHeader confidence="0.996766" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997919">
In this paper, we present a comparison of three methods for taxonomic-based sentence semantic relatedness, aid-
ed with word parts of speech (PoS) conversion. We use WordNet ontology for determining word level semantic
similarity while augmenting WordNet with two other lexicographical databases; namely Categorial Variation
Database (CatVar) and Morphosemantic Database in assisting the word category conversion. Using a human
annotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r =
0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set.
</bodyText>
<sectionHeader confidence="0.999645" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975142857143">
Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP
tasks including text summarization, document classification, text clustering, topic detection, automatic
question answering, automatic text scoring, plagiarism detection, machine translation, conversational
agents among others (Ali, Ghosh, &amp; Al-Mamun, 2009; Gomaa &amp; Fahmy, 2013; Haque, Naskar, Way,
Costa-Jussà, &amp; Banchs, 2010; K. O’Shea, 2012; Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda,
2012). There are two predominant approaches for sentence similarity: corpus-based and knowledge-
based. The former utilises information exclusively derived from large corpora including word fre-
quency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand,
Knowledge-based measures employ the intrinsic structure of a semantic network including its hierar-
chy to derive the semantic similarity. One of the commonly used knowledge networks for semantic
similarity is WordNet. It is a hierarchical lexical database for English developed at Princeton Universi-
ty (Miller, 1995). The state of the art WordNet sentence similarity is harvested from pairing the con-
stituent words of the two compared sentences. This is based on the intuition that similar sentences in
meaning will indeed comprise semantically related words. However, these pairings only handle nouns
and verbs as other part-of-speech (PoS) attributes are not accounted for in WordNet taxonomy. Taxo-
nomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexical
ontologies. In this study, we use a group of WordNet semantic relations, e.g. synonymy, hyponymy,
for similarity determination and for the approximation of noun equivalents of other PoS words.
In implementing the conversion aided methods, we adapted a publicly available package (Pedersen,
Patwardhan, &amp; Michelizzi, 2004) to measure word level similarity. We computed word similarities
from word senses using Wu and Palmer’s measure (Wu &amp; Palmer, 1994) as given in expression 1.
</bodyText>
<equation confidence="0.885031">
( ) Max ( ( ( ))) ( )
( ) ( ) ( ) ( )
Where ( ) (lowest common subsumer) stands for the synset subsuming concepts and
while depth ( ) indicates the number of nodes from concept to the root node of the hierarchy.
</equation>
<bodyText confidence="0.997458666666667">
Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic simi-
larity, say and using (Malik, Subramaniam, &amp; Kaushik, 2007) like approach, where pairs of the
same PoS tokens from the two sentences are evaluated.
</bodyText>
<equation confidence="0.933561333333333">
( )
( ) [ ∑ ( )
∑
  ||] ( ) ( ) ( )
 ||
In (2), ( ) stands for word level similarity measure in (1).
</equation>
<footnote confidence="0.55842">
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer
are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</footnote>
<page confidence="0.993737">
37
</page>
<note confidence="0.7468575">
Proceedings of the AHA! Workshop on Information Discovery in Text, pages 37–42,
Dublin, Ireland, August 23 2014.
</note>
<bodyText confidence="0.9986465">
Nevertheless, for common natural language texts, it remains biased if only verbs and nouns are used
to measure semantic relatedness ignoring other word categories such as adjectives, adverbs and named
entities. To elaborate that, consider the following pair of semantically identical sentences with differ-
ent word surface forms and classes.
</bodyText>
<listItem confidence="0.493044">
S1: He stated that the construction of the house is complete.
S2: He said in a statement that the house is completely constructed.
</listItem>
<bodyText confidence="0.999950657894737">
Initial preprocessing tasks including tokenization, normalization, and stop-words removal reduce
sentences to their semantic words with S1 yielding (state, construction, house, complete) and (state-
ment, house, completely, construct) for S2. To optimize the semantic similarity of the two sentences,
their scores from the word pairings need to be maximized regardless their associated part of speech.
For S1 and S2, this is only achievable when words are paired as (statement, state), (house, house),
(construction, construct) and (complete, completely). However, using quantification (2) yields a
Sim(S1,S2) score of 0.543. This is justifiable as computing the similarity of the above first, third and
fourth pairs, is out of reach using conventional WordNet measures due to each word pair falling in
different PoS. To handle the above limitation, the idea advocated in this paper is to turn all non-noun
PoS terms into corresponding noun expressions in order to enhance the pairing tasks.
The rationale behind the migration to noun category instead of other PoS categories relies on the in-
herent well elaborated properties of noun category in the taxonomical hierarchy, e.g., number of nouns
is much more important than other attributes in most lexical databases, which increases the chance of
finding noun-counterpart; WordNet 3 has a depth of 20 for nouns and 14 for verbs, which allows for
much more elaborated hyponym/hypernym relations for instance. It is also the case that words in the
lower layers of the deeper hierarchical taxonomy have more specific concepts which consequently
yield a high semantic similarity (Li, McLean, Bandar, O&apos;shea, &amp; Crockett, 2006). This is again sup-
ported by the argument presented in (Bawakid &amp; Oussalah, 2010).
The reasons stated above and WordNet limitation of parts of speech boundary motived the current
study of word PoS conversion in an attempt to improve the measurement of taxonomic-based short
text semantic similarity. In this respect, transforming all other primary word categories1 of the previ-
ous example to nouns using CatVar (Habash &amp; Dorr, 2003) aided conversion has raised the similarity
from 0.543 to 0.86. Since the two sentences of the previous example are intuitively highly semantical-
ly related, the noun-conversion brings the sentence similarity closer to human judgement. This again
highlights the importance of word PoS conversion to move freely beyond the barrier of PoS re-
striction. This paper aims to investigate three distinct word conversion schemes. Although, all the
three approaches use WordNet for measuring the term level similarity, each stands on a distinct exter-
nal lexical resource in converting word’s category; namely, WordNet 3.0, the Categorial Variation
Database (CatVar), and the Morphosemantic Database (Fellbaum, Osherson, &amp; Clark, 2009).
CatVar is a lexical database containing word categorial variations for English lexemes sharing a
common stem, e.g. researchV, researcherN, researchableAJ,. Likewise, Morphosematic Database is a
WordNet-related linguistic resource that links morphologically related nouns and verbs in WordNet.
Both aforementioned databases are solely utilized to aid the PoS conversion of three primary word
classes to nouns. Contributions of this paper are two folded. First, we improved traditional WordNet
sentence similarity by converting poorly or non-hierarchized word categories (e.g. verbs, adverbs and
adjectives) to a class with well-structured and deep taxonomy (nouns) using WordNet relations, Cat-
Var and Morphosemantic databases. Second, we have performed a comparison among the three PoS
conversion techniques to discover the most appropriate supplementary database to WordNet.
</bodyText>
<sectionHeader confidence="0.93115" genericHeader="method">
2 Word Parts of Speech Conversion Methods
</sectionHeader>
<bodyText confidence="0.999955666666667">
The two conversion methods aided with CatVar and Morphosemantics were performed by looking up
the word to be converted from the corresponding database and replacing it with target category word.
For example to convert the verb arouse, a simple look-up database matching yields arousal as an
equivalent noun to arouse in both databases (arouse ⇒ arousal). However, WordNet aided conversion
cannot be accomplished with a simple look up and replacement strategy due to the nature of its lexical
organization that emphasises word semantics rather than their morphology. For this purpose, to con-
</bodyText>
<footnote confidence="0.647814">
1 Verbs, adjectives, adverbs
</footnote>
<page confidence="0.997662">
38
</page>
<bodyText confidence="0.999920416666667">
vert verb category into noun category, we designed a systematic four level conversion procedure start-
ing with a verb surface form where the verb itself is checked for having noun form. If the latter fails,
the second level investigates the synonyms of the verb senses, where each synset is checked whether a
noun-form exists. If a noun member is found a replacement is issued, otherwise, another subsequent
reasoning is applied. The third level differs from the previous two in that it goes down one level to the
child node in the WordNet taxonomy following the hyponymy relation in which case the verb is con-
verted by replacing it by the first encountered node containing the target category. Last but not least,
the fourth level is based on moving one parent node up the taxonomy through the hypernymy relation
where the first obtained noun is used as an approximate noun counterpart. Fig. 1 illustrates the Word-
Net aided conversion levels indicating an example of word conversion achieved at each level (see un-
derneath the figure). On the other hand, derivation rules in WorldNet allow us to convert ad-
vert/adjective categories into their noun counterparts if available.
</bodyText>
<figureCaption confidence="0.995603">
Fig. 1: The 4-level WordNet Aided Parts of Speech (PoS) Conversion
</figureCaption>
<sectionHeader confidence="0.987081" genericHeader="method">
3 Implementation and Experiments
</sectionHeader>
<bodyText confidence="0.99764975">
Figure 2 (a) depicts our layered implementation of the multiple conversion aided sentence semantic
similarity. For every two sentences, we determine how closely the two are semantically related using
scores between 1 and 0 with 1 indicating identical texts. Fig 1 (b) highlights a functional algorithm
that summarizes the word category conversion process. The convert(w) function in the same algorithm
performs the parts of speech conversion from the selected database depending on the active approach
(A in Fig.2 (a)). All text pre-processing tasks including tokenization, parts of speech tagging, and stop
words removal are implemented in layer 1. The second layer houses the three main word category
conversion approaches in discussion. In each experimental run, only one approach is used depending
on the choice of internally hardcoded system logic. The generated output from layer 2 is sentence text
vectors having the same part of speech. These vectors are then fed into the Text Semantic Similarity
Module to measure the similarity score using Wu and Palmer measure (Wu &amp; Palmer, 1994) for word
level similarity and WordNet taxonomy as an information source according to equations (1-2).
</bodyText>
<subsectionHeader confidence="0.992876">
3.1 Data set
</subsectionHeader>
<bodyText confidence="0.9994505">
We conducted system experiments on a pilot benchmark data set created for measuring short-text se-
mantic similarity (O&apos;Shea, Bandar, Crockett, &amp; McLean, 2008). It contains 65 sentence pairs with hu-
</bodyText>
<page confidence="0.99716">
39
</page>
<bodyText confidence="0.9997084">
man similarity judgements assigned to each pair. During this data set creation, 32 graduate native
speakers were assigned to score the degree of similarity using scores from 0 to 4 and following a
guideline of semantic anchor (Charles, 2000) included in Table 2. To make the semantic anchors
comply with our system generated scores (0 to 1), the scale points have been linearly transformed as
indicated in the second column of the same table.
</bodyText>
<table confidence="0.986374470588235">
Algorithm1: Word Parts Of Speech Conversion
Input: sentence with different word classes;
Output: sentence with same word class(CWS);
S &lt;-- Sentence;
CWS&lt;-- { };
C &lt;-- { }
W &lt;-- tokenize(S)
for each wi ϵ W do
If wi = inflected then
wi &lt;-- baseform(wi)
endif
If (wi not in targetcategory)
cw&lt;-- convert (wi)
endif
CWS &lt;-- CWS {cw}
end for
return CWS
</table>
<figure confidence="0.934878">
(a) (b)
</figure>
<figureCaption confidence="0.850763">
Fig. 2: (a) Word POS conversion aided semantic similarity system; (b) Word parts of speech conversion Algorithm
</figureCaption>
<tableCaption confidence="0.995458">
Table 1: Semantic Anchors
</tableCaption>
<table confidence="0.973938142857143">
Scale Transformed Semantic Anchor
Points Scale Points*
0.0 0.0 The sentences are unrelated in meaning
1.0 0.25 The sentences are vaguely similar in meaning
2.0 0.5 The sentences are very much a like in meaning
3.0 0.75 The sentences are strongly related in meaning
4.0 1.0 The sentences are identical in meaning
</table>
<subsectionHeader confidence="0.931117">
3.2 Results and Evaluation
</subsectionHeader>
<bodyText confidence="0.999981529411765">
Our evaluation for all three conversion assisted systems is centered around the human judgements.
Human ratings reflect the extent to which every two sentences are semantically related from the hu-
man perception. A comparison of our conversion aided methods (TW, CwW, CwM, CwC) and the find-
ings of two baseline methods (STASIS, LSA) is presented in Table 2. The notations TW, CwW, CwM,
CwC stand for, traditional WordNet, conversion with WordNet, conversion with Morphosemantics
and conversion with CatVar respectively. We selected the baselines because of their fitness for pur-
pose and their evaluation on the same benchmark data. STASIS, thoroughly described in (Li, et al.,
2006), is a textual similarity measure combining taxonomy and word order information to compute the
semantic relatedness for two sentences. While LSA (latent sematic analysis) (Deerwester et. al, 1990)
is a corpus-based measure developed for indexing and retrieval of text documents but later adapted for
tasks including sentence similarity. In LSA, texts are represented as a matrix, of high dimensional se-
mantic vectors, which is then transformed using Singular Value Decomposition (SVD); namely,
A = TSD T, where A is a term-document matrix, S is the diagonal matrix of the Singular Value De-
composition, while T and D are left and right singular vectors with orthogonal columns. As pointed
out, the results obtained in (J. O’Shea, Bandar, Crockett, &amp; McLean, 2008) have been compared to our
experimental results. Due to the space limitation, results of only 10 randomly selected sentence pairs
from the benchmark data set are listed in Table 2 with the second column being the human ratings.
</bodyText>
<page confidence="0.999229">
40
</page>
<tableCaption confidence="0.99947">
Table 2. Human, STASIS, LSA, TW, CwW, CwM and CwC similarity scores for 10 sentence pairs
</tableCaption>
<table confidence="0.999630454545455">
Sentence Pair Human STASIS LSA TW CwW CwM CwC
1.cord:smile 0.01 0.329 0.51 0.362 0.49 0.57 0.667
9.asylum:fruit 0.005 0.209 0.505 0.430 0.43 0.506 0.522
17.coast:forest 0.063 0.356 0.575 0.616 0.738 0.80 0.791
29.bird:woodland 0.013 0.335 0.505 0.465 0.583 0.665 0.665
33.hill:woodland 0.145 0.59 0.81 0.826 0.826 0.826 0.826
57.forest:woodland 0.628 0.7 0.75 0.709 0.804 0.867 0.867
58.implement:tool 0.59 0.753 0.83 0.781 0.744 0.905 0.885
59.cock:rooster 0.863 1 0.985 1 1 1 1
61.cushion:pillow 0.523 0.662 0.63 0.636 0.637 0.723 0.842
65.gem: jewel 0.653 0.831 0.86 0.717 0.745 0.793 0.778
</table>
<bodyText confidence="0.99845875">
To measure the strength of the linear association measured in terms of the correlation coefficients r,
between the score of each conversion aided method and the human judgements, are computed and pre-
sented in Table 3 using equation 3 where n is the number of sentence pairs while m; and h; represent
machine and human scores, respectively, for the ith pair.
</bodyText>
<equation confidence="0.672517">
∑ ∑ ∑ ( )
</equation>
<bodyText confidence="0.999546">
The performances of all the three methods gradually excel with an increasing shared semantic
strength between the sentence pairs. However, for the less related sentence pairs, it is evident that the
human perception of similarity is more strict than the loose definition of similarity based on lexical
concepts and hierarchical taxonomy. Table 2 shows that all the three conversion aided methods con-
siderably improve semantic scores over the traditional WordNet (TW). Out of the three schemes, Cat-
Var-aided conversion establishes the highest semantic correlation between the sentence pairs corrobo-
rating the hypothesis that CatVar can be used as a supplementary resource to WordNet. Overall, scores
of correlation coefficients of the developed approaches with the baseline methods; STASIS and LSA
and human judgements indicate that CatVar-based conversion provides best performance. On the other
hand, the correlation coefficients (expression 3) between our conversions aided schemes and the two
compared benchmark methods along with the human judgements, summarized in Table 3, shows that
statistically speaking, latent semantic analysis (LSA) provides the best consistency with WordNet-
based similarity measures.
</bodyText>
<tableCaption confidence="0.998708">
Table 3: Correlations Coefficients (r) between machine and human scores
</tableCaption>
<table confidence="0.99794025">
CwW CwM CwC STASIS LSA
Human 0.729826 0.830984 0.881647 0.816 0.838
STASIS 0.771874 0.851675 0.872939 -- 0.76
LSA 0.804518 0.875024 0.822453 0.76 --
</table>
<bodyText confidence="0.999581285714286">
In order to visualize the effect of correlation coefficient across sentence pairs, Fig. 3 illustrates the
association between the human ratings and each of the achieved results. It is evident that all the three
relationships follow a positive linear trend with slightly varying but strong correlation with the human
judgements and without outliers. For those sentence pairs which are either strongly related or identical
in meaning, there is a high agreement between the human evaluation and machine assessment for se-
mantic similarity. The results also confirm that CatVar aided conversion yields a strong positive corre-
lation with the human rating.
</bodyText>
<equation confidence="0.931169">
√( ∑ (∑ ) ) √( ∑ (∑ ) )
</equation>
<page confidence="0.995558">
41
</page>
<figureCaption confidence="0.867057">
Fig. 3: Relationships between the obtained results and human judgements for the benchmark data set
</figureCaption>
<sectionHeader confidence="0.998437" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999966">
To improve the accuracy of capturing semantic textual relatedness, we carried out word parts of
speech conversion by augmenting two lexical databases; CatVar and Morphosemantics to traditional
WordNet similarity. Our comparative analysis with human judgements and two baseline systems
found that WordNet taxonomy can be supplemented with other linguistic resources, such as CatVar, to
enhance the measurement of sentence semantic similarity. The findings revealed that the word parts of
speech conversion captures the sematic correlation between two pieces of text in a way that brings
closer to human perception. As a future work, we plan to improve the suggested conversion aided sim-
ilarity measures and apply them on various large scale data set.
</bodyText>
<sectionHeader confidence="0.999415" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998124">
Ali, M., Ghosh, M. K., &amp; Al-Mamun, A. (2009). Multi-document Text Summarization: SimWithFirst Based
Features and Sentence Co-selection Based Evaluation. Paper presented at the Future Computer and
Communication, 2009. ICFCC 2009. International Conference on.
Bawakid, A., &amp; Oussalah, M. (2010). A semantic-based text classification system. Paper presented at the
Cybernetic Intelligent Systems (CIS), 2010 IEEE 9th International Conference on.
Charles, W. G. (2000). Contextual correlates of meaning. Applied Psycholinguistics, 21(04), 505-524.
Deerwester et. al, S. C. (1990). Indexing by latent semantic analysis. JASIS, 41(6), 391-407.
Fellbaum, C., Osherson, A., &amp; Clark, P. E. (2009). Putting semantics into WordNet’s&amp;quot; morphosemantic&amp;quot; links
Human Language Technology. Challenges of the Information Society (pp. 350-358): Springer.
Gomaa, W. H., &amp; Fahmy, A. A. (2013). A Survey of text similarity approaches. International Journal of
Computer Applications, 68(13), 13-18.
Habash, N., &amp; Dorr, B. (2003). A categorial variation database for English. Paper presented at the Proceedings
of the 2003 Conference of the North American Chapter of the Association for Computational
Linguistics on Human Language Technology-Volume 1.
Haque, R., Naskar, S. K., Way, A., Costa-Jussà, M. R., &amp; Banchs, R. E. (2010). Sentence similarity-based
source context modelling in pbsmt. Paper presented at the Asian Language Processing (IALP), 2010
International Conference on.
Li, Y., McLean, D., Bandar, Z. A., O&apos;shea, J. D., &amp; Crockett, K. (2006). Sentence similarity based on semantic
nets and corpus statistics. Knowledge and Data Engineering, IEEE Transactions on, 18(8), 1138-1150.
Malik, R., Subramaniam, L. V., &amp; Kaushik, S. (2007). Automatically Selecting Answer Templates to Respond to
Customer Emails. Paper presented at the IJCAI.
Miller, G. A. (1995). WordNet: a lexical database for English. Communications of the ACM, 38(11), 39-41.
O&apos;Shea, J., Bandar, Z., Crockett, K., &amp; McLean, D. (2008). Pilot short text semantic similarity benchmark data
set: Full listing and description. Computing.
O’Shea, J., Bandar, Z., Crockett, K., &amp; McLean, D. (2008). A comparative study of two short text semantic
similarity measures Agent and Multi-Agent Systems: Technologies and Applications (pp. 172-181):
Springer.
O’Shea, K. (2012). An approach to conversational agent design using semantic sentence similarity. Applied
Intelligence, 37(4), 558-568.
Osman, A. H., Salim, N., Binwahlan, M. S., Alteeb, R., &amp; Abuobieda, A. (2012). An improved plagiarism
detection scheme based on semantic role labeling. Applied Soft Computing, 12(5), 1493-1502.
Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet:: Similarity: measuring the relatedness of
concepts. Paper presented at the Demonstration Papers at HLT-NAACL 2004.
Wu, Z., &amp; Palmer, M. (1994). Verbs semantics and lexical selection. Paper presented at the Proceedings of the
32nd annual meeting on Association for Computational Linguistics.
</reference>
<page confidence="0.999295">
42
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.534229">
<title confidence="0.998661">A Comparative Study of Conversion Aided Methods for Sentence Textual Similarity</title>
<author confidence="0.999329">Muhidin Mohamed M Oussalah</author>
<affiliation confidence="0.999995">EECE University of Birmingham, EECE University of Birmingham,</affiliation>
<address confidence="0.994758">Edgbaston, Birmingham, UK Edgbaston, Birmingham, UK</address>
<email confidence="0.589187">Mam256@bham.ac.ukM.Oussalah@bham.ac.uk</email>
<abstract confidence="0.982686714285714">In this paper, we present a comparison of three methods for taxonomic-based sentence semantic relatedness, aided with word parts of speech (PoS) conversion. We use WordNet ontology for determining word level semantic similarity while augmenting WordNet with two other lexicographical databases; namely Categorial Variation Database (CatVar) and Morphosemantic Database in assisting the word category conversion. Using a human annotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Ali</author>
<author>M K Ghosh</author>
<author>A Al-Mamun</author>
</authors>
<title>Multi-document Text Summarization: SimWithFirst Based Features and Sentence Co-selection Based Evaluation. Paper presented at the Future Computer and Communication,</title>
<date>2009</date>
<booktitle>ICFCC 2009. International Conference on.</booktitle>
<contexts>
<context position="1298" citStr="Ali, Ghosh, &amp; Al-Mamun, 2009" startWordPosition="169" endWordPosition="173">category conversion. Using a human annotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set. 1 Introduction Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP tasks including text summarization, document classification, text clustering, topic detection, automatic question answering, automatic text scoring, plagiarism detection, machine translation, conversational agents among others (Ali, Ghosh, &amp; Al-Mamun, 2009; Gomaa &amp; Fahmy, 2013; Haque, Naskar, Way, Costa-Jussà, &amp; Banchs, 2010; K. O’Shea, 2012; Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda, 2012). There are two predominant approaches for sentence similarity: corpus-based and knowledgebased. The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity. One of the commonly used knowledge n</context>
</contexts>
<marker>Ali, Ghosh, Al-Mamun, 2009</marker>
<rawString>Ali, M., Ghosh, M. K., &amp; Al-Mamun, A. (2009). Multi-document Text Summarization: SimWithFirst Based Features and Sentence Co-selection Based Evaluation. Paper presented at the Future Computer and Communication, 2009. ICFCC 2009. International Conference on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bawakid</author>
<author>M Oussalah</author>
</authors>
<title>A semantic-based text classification system. Paper presented at the Cybernetic Intelligent Systems (CIS),</title>
<date>2010</date>
<booktitle>IEEE 9th International Conference on.</booktitle>
<contexts>
<context position="6107" citStr="Bawakid &amp; Oussalah, 2010" startWordPosition="917" endWordPosition="920">f noun category in the taxonomical hierarchy, e.g., number of nouns is much more important than other attributes in most lexical databases, which increases the chance of finding noun-counterpart; WordNet 3 has a depth of 20 for nouns and 14 for verbs, which allows for much more elaborated hyponym/hypernym relations for instance. It is also the case that words in the lower layers of the deeper hierarchical taxonomy have more specific concepts which consequently yield a high semantic similarity (Li, McLean, Bandar, O&apos;shea, &amp; Crockett, 2006). This is again supported by the argument presented in (Bawakid &amp; Oussalah, 2010). The reasons stated above and WordNet limitation of parts of speech boundary motived the current study of word PoS conversion in an attempt to improve the measurement of taxonomic-based short text semantic similarity. In this respect, transforming all other primary word categories1 of the previous example to nouns using CatVar (Habash &amp; Dorr, 2003) aided conversion has raised the similarity from 0.543 to 0.86. Since the two sentences of the previous example are intuitively highly semantically related, the noun-conversion brings the sentence similarity closer to human judgement. This again hig</context>
</contexts>
<marker>Bawakid, Oussalah, 2010</marker>
<rawString>Bawakid, A., &amp; Oussalah, M. (2010). A semantic-based text classification system. Paper presented at the Cybernetic Intelligent Systems (CIS), 2010 IEEE 9th International Conference on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Charles</author>
</authors>
<title>Contextual correlates of meaning.</title>
<date>2000</date>
<journal>Applied Psycholinguistics,</journal>
<volume>21</volume>
<issue>04</issue>
<pages>505--524</pages>
<note>Deerwester</note>
<contexts>
<context position="11644" citStr="Charles, 2000" startWordPosition="1771" endWordPosition="1772">rity score using Wu and Palmer measure (Wu &amp; Palmer, 1994) for word level similarity and WordNet taxonomy as an information source according to equations (1-2). 3.1 Data set We conducted system experiments on a pilot benchmark data set created for measuring short-text semantic similarity (O&apos;Shea, Bandar, Crockett, &amp; McLean, 2008). It contains 65 sentence pairs with hu39 man similarity judgements assigned to each pair. During this data set creation, 32 graduate native speakers were assigned to score the degree of similarity using scores from 0 to 4 and following a guideline of semantic anchor (Charles, 2000) included in Table 2. To make the semantic anchors comply with our system generated scores (0 to 1), the scale points have been linearly transformed as indicated in the second column of the same table. Algorithm1: Word Parts Of Speech Conversion Input: sentence with different word classes; Output: sentence with same word class(CWS); S &lt;-- Sentence; CWS&lt;-- { }; C &lt;-- { } W &lt;-- tokenize(S) for each wi ϵ W do If wi = inflected then wi &lt;-- baseform(wi) endif If (wi not in targetcategory) cw&lt;-- convert (wi) endif CWS &lt;-- CWS {cw} end for return CWS (a) (b) Fig. 2: (a) Word POS conversion aided sema</context>
</contexts>
<marker>Charles, 2000</marker>
<rawString>Charles, W. G. (2000). Contextual correlates of meaning. Applied Psycholinguistics, 21(04), 505-524. Deerwester et. al, S. C. (1990). Indexing by latent semantic analysis. JASIS, 41(6), 391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
<author>A Osherson</author>
<author>P E Clark</author>
</authors>
<title>Putting semantics into WordNet’s&amp;quot; morphosemantic&amp;quot; links Human Language Technology.</title>
<date>2009</date>
<journal>Challenges of the Information Society</journal>
<pages>350--358</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="7180" citStr="Fellbaum, Osherson, &amp; Clark, 2009" startWordPosition="1077" endWordPosition="1081">f the previous example are intuitively highly semantically related, the noun-conversion brings the sentence similarity closer to human judgement. This again highlights the importance of word PoS conversion to move freely beyond the barrier of PoS restriction. This paper aims to investigate three distinct word conversion schemes. Although, all the three approaches use WordNet for measuring the term level similarity, each stands on a distinct external lexical resource in converting word’s category; namely, WordNet 3.0, the Categorial Variation Database (CatVar), and the Morphosemantic Database (Fellbaum, Osherson, &amp; Clark, 2009). CatVar is a lexical database containing word categorial variations for English lexemes sharing a common stem, e.g. researchV, researcherN, researchableAJ,. Likewise, Morphosematic Database is a WordNet-related linguistic resource that links morphologically related nouns and verbs in WordNet. Both aforementioned databases are solely utilized to aid the PoS conversion of three primary word classes to nouns. Contributions of this paper are two folded. First, we improved traditional WordNet sentence similarity by converting poorly or non-hierarchized word categories (e.g. verbs, adverbs and adj</context>
</contexts>
<marker>Fellbaum, Osherson, Clark, 2009</marker>
<rawString>Fellbaum, C., Osherson, A., &amp; Clark, P. E. (2009). Putting semantics into WordNet’s&amp;quot; morphosemantic&amp;quot; links Human Language Technology. Challenges of the Information Society (pp. 350-358): Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W H Gomaa</author>
<author>A A Fahmy</author>
</authors>
<title>A Survey of text similarity approaches.</title>
<date>2013</date>
<journal>International Journal of Computer Applications,</journal>
<volume>68</volume>
<issue>13</issue>
<pages>13--18</pages>
<contexts>
<context position="1319" citStr="Gomaa &amp; Fahmy, 2013" startWordPosition="174" endWordPosition="177">uman annotated benchmark data set, all the three approaches achieved a high positive correlation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set. 1 Introduction Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP tasks including text summarization, document classification, text clustering, topic detection, automatic question answering, automatic text scoring, plagiarism detection, machine translation, conversational agents among others (Ali, Ghosh, &amp; Al-Mamun, 2009; Gomaa &amp; Fahmy, 2013; Haque, Naskar, Way, Costa-Jussà, &amp; Banchs, 2010; K. O’Shea, 2012; Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda, 2012). There are two predominant approaches for sentence similarity: corpus-based and knowledgebased. The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity. One of the commonly used knowledge networks for semantic </context>
</contexts>
<marker>Gomaa, Fahmy, 2013</marker>
<rawString>Gomaa, W. H., &amp; Fahmy, A. A. (2013). A Survey of text similarity approaches. International Journal of Computer Applications, 68(13), 13-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
<author>B Dorr</author>
</authors>
<title>A categorial variation database for English. Paper presented at the</title>
<date>2003</date>
<booktitle>Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1.</booktitle>
<contexts>
<context position="6458" citStr="Habash &amp; Dorr, 2003" startWordPosition="972" endWordPosition="975">words in the lower layers of the deeper hierarchical taxonomy have more specific concepts which consequently yield a high semantic similarity (Li, McLean, Bandar, O&apos;shea, &amp; Crockett, 2006). This is again supported by the argument presented in (Bawakid &amp; Oussalah, 2010). The reasons stated above and WordNet limitation of parts of speech boundary motived the current study of word PoS conversion in an attempt to improve the measurement of taxonomic-based short text semantic similarity. In this respect, transforming all other primary word categories1 of the previous example to nouns using CatVar (Habash &amp; Dorr, 2003) aided conversion has raised the similarity from 0.543 to 0.86. Since the two sentences of the previous example are intuitively highly semantically related, the noun-conversion brings the sentence similarity closer to human judgement. This again highlights the importance of word PoS conversion to move freely beyond the barrier of PoS restriction. This paper aims to investigate three distinct word conversion schemes. Although, all the three approaches use WordNet for measuring the term level similarity, each stands on a distinct external lexical resource in converting word’s category; namely, W</context>
</contexts>
<marker>Habash, Dorr, 2003</marker>
<rawString>Habash, N., &amp; Dorr, B. (2003). A categorial variation database for English. Paper presented at the Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Haque</author>
<author>S K Naskar</author>
<author>A Way</author>
<author>M R Costa-Jussà</author>
<author>R E Banchs</author>
</authors>
<title>Sentence similarity-based source context modelling in pbsmt. Paper presented at the Asian Language Processing (IALP),</title>
<date>2010</date>
<booktitle>International Conference on.</booktitle>
<contexts>
<context position="1368" citStr="Haque, Naskar, Way, Costa-Jussà, &amp; Banchs, 2010" startWordPosition="178" endWordPosition="184">ark data set, all the three approaches achieved a high positive correlation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set. 1 Introduction Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP tasks including text summarization, document classification, text clustering, topic detection, automatic question answering, automatic text scoring, plagiarism detection, machine translation, conversational agents among others (Ali, Ghosh, &amp; Al-Mamun, 2009; Gomaa &amp; Fahmy, 2013; Haque, Naskar, Way, Costa-Jussà, &amp; Banchs, 2010; K. O’Shea, 2012; Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda, 2012). There are two predominant approaches for sentence similarity: corpus-based and knowledgebased. The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity. One of the commonly used knowledge networks for semantic similarity is WordNet. It is a hierarchical lexic</context>
</contexts>
<marker>Haque, Naskar, Way, Costa-Jussà, Banchs, 2010</marker>
<rawString>Haque, R., Naskar, S. K., Way, A., Costa-Jussà, M. R., &amp; Banchs, R. E. (2010). Sentence similarity-based source context modelling in pbsmt. Paper presented at the Asian Language Processing (IALP), 2010 International Conference on.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Li</author>
<author>D McLean</author>
<author>Z A Bandar</author>
<author>J D O&apos;shea</author>
<author>K Crockett</author>
</authors>
<title>Sentence similarity based on semantic nets and corpus statistics. Knowledge and Data Engineering,</title>
<date>2006</date>
<journal>IEEE Transactions on,</journal>
<volume>18</volume>
<issue>8</issue>
<pages>1138--1150</pages>
<contexts>
<context position="6025" citStr="Li, McLean, Bandar, O&apos;shea, &amp; Crockett, 2006" startWordPosition="900" endWordPosition="906"> to noun category instead of other PoS categories relies on the inherent well elaborated properties of noun category in the taxonomical hierarchy, e.g., number of nouns is much more important than other attributes in most lexical databases, which increases the chance of finding noun-counterpart; WordNet 3 has a depth of 20 for nouns and 14 for verbs, which allows for much more elaborated hyponym/hypernym relations for instance. It is also the case that words in the lower layers of the deeper hierarchical taxonomy have more specific concepts which consequently yield a high semantic similarity (Li, McLean, Bandar, O&apos;shea, &amp; Crockett, 2006). This is again supported by the argument presented in (Bawakid &amp; Oussalah, 2010). The reasons stated above and WordNet limitation of parts of speech boundary motived the current study of word PoS conversion in an attempt to improve the measurement of taxonomic-based short text semantic similarity. In this respect, transforming all other primary word categories1 of the previous example to nouns using CatVar (Habash &amp; Dorr, 2003) aided conversion has raised the similarity from 0.543 to 0.86. Since the two sentences of the previous example are intuitively highly semantically related, the noun-c</context>
<context position="13360" citStr="Li, et al., 2006" startWordPosition="2052" endWordPosition="2055">ered around the human judgements. Human ratings reflect the extent to which every two sentences are semantically related from the human perception. A comparison of our conversion aided methods (TW, CwW, CwM, CwC) and the findings of two baseline methods (STASIS, LSA) is presented in Table 2. The notations TW, CwW, CwM, CwC stand for, traditional WordNet, conversion with WordNet, conversion with Morphosemantics and conversion with CatVar respectively. We selected the baselines because of their fitness for purpose and their evaluation on the same benchmark data. STASIS, thoroughly described in (Li, et al., 2006), is a textual similarity measure combining taxonomy and word order information to compute the semantic relatedness for two sentences. While LSA (latent sematic analysis) (Deerwester et. al, 1990) is a corpus-based measure developed for indexing and retrieval of text documents but later adapted for tasks including sentence similarity. In LSA, texts are represented as a matrix, of high dimensional semantic vectors, which is then transformed using Singular Value Decomposition (SVD); namely, A = TSD T, where A is a term-document matrix, S is the diagonal matrix of the Singular Value Decomposition</context>
</contexts>
<marker>Li, McLean, Bandar, O&apos;shea, Crockett, 2006</marker>
<rawString>Li, Y., McLean, D., Bandar, Z. A., O&apos;shea, J. D., &amp; Crockett, K. (2006). Sentence similarity based on semantic nets and corpus statistics. Knowledge and Data Engineering, IEEE Transactions on, 18(8), 1138-1150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Malik</author>
<author>L V Subramaniam</author>
<author>S Kaushik</author>
</authors>
<title>Automatically Selecting Answer Templates to Respond to Customer Emails. Paper presented at the IJCAI.</title>
<date>2007</date>
<contexts>
<context position="3369" citStr="Malik, Subramaniam, &amp; Kaushik, 2007" startWordPosition="487" endWordPosition="491"> conversion aided methods, we adapted a publicly available package (Pedersen, Patwardhan, &amp; Michelizzi, 2004) to measure word level similarity. We computed word similarities from word senses using Wu and Palmer’s measure (Wu &amp; Palmer, 1994) as given in expression 1. ( ) Max ( ( ( ))) ( ) ( ) ( ) ( ) ( ) Where ( ) (lowest common subsumer) stands for the synset subsuming concepts and while depth ( ) indicates the number of nodes from concept to the root node of the hierarchy. Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic similarity, say and using (Malik, Subramaniam, &amp; Kaushik, 2007) like approach, where pairs of the same PoS tokens from the two sentences are evaluated. ( ) ( ) [ ∑ ( ) ∑ ||] ( ) ( ) ( ) || In (2), ( ) stands for word level similarity measure in (1). This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 37 Proceedings of the AHA! Workshop on Information Discovery in Text, pages 37–42, Dublin, Ireland, August 23 2014. Nevertheless, for common natural language texts, it remains biased if only verbs and</context>
</contexts>
<marker>Malik, Subramaniam, Kaushik, 2007</marker>
<rawString>Malik, R., Subramaniam, L. V., &amp; Kaushik, S. (2007). Automatically Selecting Answer Templates to Respond to Customer Emails. Paper presented at the IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: a lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<pages>39--41</pages>
<contexts>
<context position="2040" citStr="Miller, 1995" startWordPosition="278" endWordPosition="279">ieda, 2012). There are two predominant approaches for sentence similarity: corpus-based and knowledgebased. The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity. One of the commonly used knowledge networks for semantic similarity is WordNet. It is a hierarchical lexical database for English developed at Princeton University (Miller, 1995). The state of the art WordNet sentence similarity is harvested from pairing the constituent words of the two compared sentences. This is based on the intuition that similar sentences in meaning will indeed comprise semantically related words. However, these pairings only handle nouns and verbs as other part-of-speech (PoS) attributes are not accounted for in WordNet taxonomy. Taxonomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexical ontologies. In this study, we use a group of WordNet semantic relations, e.g. synonymy, hyponymy, for similarity deter</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>Miller, G. A. (1995). WordNet: a lexical database for English. Communications of the ACM, 38(11), 39-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J O&apos;Shea</author>
<author>Z Bandar</author>
<author>K Crockett</author>
<author>D McLean</author>
</authors>
<title>Pilot short text semantic similarity benchmark data set: Full listing and description.</title>
<date>2008</date>
<journal>Computing.</journal>
<contexts>
<context position="11360" citStr="O&apos;Shea, Bandar, Crockett, &amp; McLean, 2008" startWordPosition="1720" endWordPosition="1725"> in discussion. In each experimental run, only one approach is used depending on the choice of internally hardcoded system logic. The generated output from layer 2 is sentence text vectors having the same part of speech. These vectors are then fed into the Text Semantic Similarity Module to measure the similarity score using Wu and Palmer measure (Wu &amp; Palmer, 1994) for word level similarity and WordNet taxonomy as an information source according to equations (1-2). 3.1 Data set We conducted system experiments on a pilot benchmark data set created for measuring short-text semantic similarity (O&apos;Shea, Bandar, Crockett, &amp; McLean, 2008). It contains 65 sentence pairs with hu39 man similarity judgements assigned to each pair. During this data set creation, 32 graduate native speakers were assigned to score the degree of similarity using scores from 0 to 4 and following a guideline of semantic anchor (Charles, 2000) included in Table 2. To make the semantic anchors comply with our system generated scores (0 to 1), the scale points have been linearly transformed as indicated in the second column of the same table. Algorithm1: Word Parts Of Speech Conversion Input: sentence with different word classes; Output: sentence with sam</context>
</contexts>
<marker>O&apos;Shea, Bandar, Crockett, McLean, 2008</marker>
<rawString>O&apos;Shea, J., Bandar, Z., Crockett, K., &amp; McLean, D. (2008). Pilot short text semantic similarity benchmark data set: Full listing and description. Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J O’Shea</author>
<author>Z Bandar</author>
<author>K Crockett</author>
<author>D McLean</author>
</authors>
<title>A comparative study of two short text semantic similarity measures Agent and Multi-Agent Systems: Technologies and Applications</title>
<date>2008</date>
<pages>172--181</pages>
<publisher>Springer.</publisher>
<marker>O’Shea, Bandar, Crockett, McLean, 2008</marker>
<rawString>O’Shea, J., Bandar, Z., Crockett, K., &amp; McLean, D. (2008). A comparative study of two short text semantic similarity measures Agent and Multi-Agent Systems: Technologies and Applications (pp. 172-181): Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K O’Shea</author>
</authors>
<title>An approach to conversational agent design using semantic sentence similarity.</title>
<date>2012</date>
<journal>Applied Intelligence,</journal>
<volume>37</volume>
<issue>4</issue>
<pages>558--568</pages>
<marker>O’Shea, 2012</marker>
<rawString>O’Shea, K. (2012). An approach to conversational agent design using semantic sentence similarity. Applied Intelligence, 37(4), 558-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A H Osman</author>
<author>N Salim</author>
<author>M S Binwahlan</author>
<author>R Alteeb</author>
<author>A Abuobieda</author>
</authors>
<title>An improved plagiarism detection scheme based on semantic role labeling.</title>
<date>2012</date>
<journal>Applied Soft Computing,</journal>
<volume>12</volume>
<issue>5</issue>
<pages>1493--1502</pages>
<contexts>
<context position="1437" citStr="Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda, 2012" startWordPosition="188" endWordPosition="194">rrelation reaching up to (r = 0.881647) with comparison to human ratings and two other baselines evaluated on the same benchmark data set. 1 Introduction Sentence textual similarity is a crucial and a prerequisite subtask for many text processing and NLP tasks including text summarization, document classification, text clustering, topic detection, automatic question answering, automatic text scoring, plagiarism detection, machine translation, conversational agents among others (Ali, Ghosh, &amp; Al-Mamun, 2009; Gomaa &amp; Fahmy, 2013; Haque, Naskar, Way, Costa-Jussà, &amp; Banchs, 2010; K. O’Shea, 2012; Osman, Salim, Binwahlan, Alteeb, &amp; Abuobieda, 2012). There are two predominant approaches for sentence similarity: corpus-based and knowledgebased. The former utilises information exclusively derived from large corpora including word frequency of occurrence, and latent semantic analysis, to infer semantic similarity. On the other hand, Knowledge-based measures employ the intrinsic structure of a semantic network including its hierarchy to derive the semantic similarity. One of the commonly used knowledge networks for semantic similarity is WordNet. It is a hierarchical lexical database for English developed at Princeton University (Miller, 19</context>
</contexts>
<marker>Osman, Salim, Binwahlan, Alteeb, Abuobieda, 2012</marker>
<rawString>Osman, A. H., Salim, N., Binwahlan, M. S., Alteeb, R., &amp; Abuobieda, A. (2012). An improved plagiarism detection scheme based on semantic role labeling. Applied Soft Computing, 12(5), 1493-1502.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet:: Similarity: measuring the relatedness of concepts. Paper presented at the Demonstration Papers at HLT-NAACL</title>
<date>2004</date>
<contexts>
<context position="2842" citStr="Pedersen, Patwardhan, &amp; Michelizzi, 2004" startWordPosition="392" endWordPosition="396">hat similar sentences in meaning will indeed comprise semantically related words. However, these pairings only handle nouns and verbs as other part-of-speech (PoS) attributes are not accounted for in WordNet taxonomy. Taxonomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexical ontologies. In this study, we use a group of WordNet semantic relations, e.g. synonymy, hyponymy, for similarity determination and for the approximation of noun equivalents of other PoS words. In implementing the conversion aided methods, we adapted a publicly available package (Pedersen, Patwardhan, &amp; Michelizzi, 2004) to measure word level similarity. We computed word similarities from word senses using Wu and Palmer’s measure (Wu &amp; Palmer, 1994) as given in expression 1. ( ) Max ( ( ( ))) ( ) ( ) ( ) ( ) ( ) Where ( ) (lowest common subsumer) stands for the synset subsuming concepts and while depth ( ) indicates the number of nodes from concept to the root node of the hierarchy. Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic similarity, say and using (Malik, Subramaniam, &amp; Kaushik, 2007) like approach, where pairs of the same PoS tokens from the two sentence</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet:: Similarity: measuring the relatedness of concepts. Paper presented at the Demonstration Papers at HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verbs semantics and lexical selection.</title>
<date>1994</date>
<booktitle>Paper presented at the Proceedings of the 32nd annual meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2974" citStr="Wu &amp; Palmer, 1994" startWordPosition="414" endWordPosition="417">ech (PoS) attributes are not accounted for in WordNet taxonomy. Taxonomic similarity is a conceptual relatedness derived from hyponymy/hypernymy relations of lexical ontologies. In this study, we use a group of WordNet semantic relations, e.g. synonymy, hyponymy, for similarity determination and for the approximation of noun equivalents of other PoS words. In implementing the conversion aided methods, we adapted a publicly available package (Pedersen, Patwardhan, &amp; Michelizzi, 2004) to measure word level similarity. We computed word similarities from word senses using Wu and Palmer’s measure (Wu &amp; Palmer, 1994) as given in expression 1. ( ) Max ( ( ( ))) ( ) ( ) ( ) ( ) ( ) Where ( ) (lowest common subsumer) stands for the synset subsuming concepts and while depth ( ) indicates the number of nodes from concept to the root node of the hierarchy. Next, the above word-to-word semantic similarity is extended to sentence-to-sentence semantic similarity, say and using (Malik, Subramaniam, &amp; Kaushik, 2007) like approach, where pairs of the same PoS tokens from the two sentences are evaluated. ( ) ( ) [ ∑ ( ) ∑ ||] ( ) ( ) ( ) || In (2), ( ) stands for word level similarity measure in (1). This work is lice</context>
<context position="11088" citStr="Wu &amp; Palmer, 1994" startWordPosition="1681" endWordPosition="1684">ding on the active approach (A in Fig.2 (a)). All text pre-processing tasks including tokenization, parts of speech tagging, and stop words removal are implemented in layer 1. The second layer houses the three main word category conversion approaches in discussion. In each experimental run, only one approach is used depending on the choice of internally hardcoded system logic. The generated output from layer 2 is sentence text vectors having the same part of speech. These vectors are then fed into the Text Semantic Similarity Module to measure the similarity score using Wu and Palmer measure (Wu &amp; Palmer, 1994) for word level similarity and WordNet taxonomy as an information source according to equations (1-2). 3.1 Data set We conducted system experiments on a pilot benchmark data set created for measuring short-text semantic similarity (O&apos;Shea, Bandar, Crockett, &amp; McLean, 2008). It contains 65 sentence pairs with hu39 man similarity judgements assigned to each pair. During this data set creation, 32 graduate native speakers were assigned to score the degree of similarity using scores from 0 to 4 and following a guideline of semantic anchor (Charles, 2000) included in Table 2. To make the semantic a</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Wu, Z., &amp; Palmer, M. (1994). Verbs semantics and lexical selection. Paper presented at the Proceedings of the 32nd annual meeting on Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>