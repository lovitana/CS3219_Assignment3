<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9245965">
Interactive Annotation for Event Modality in Modern Standard
and Egyptian Arabic Tweets
</title>
<author confidence="0.891186">
Rania Al-Sabbagh†, Roxana Girju†, Jana Diesner‡†Department of Linguistics and Beckman Institute
</author>
<affiliation confidence="0.997062">
‡School of Library and Information Science
University of Illinois at Urbana-Champaign, USA
</affiliation>
<email confidence="0.991646">
{alsabba1, girju, jdiesner} @illinois.edu
</email>
<sectionHeader confidence="0.994588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9991926">
We present an interactive procedure to annotate a large-scale corpus of Modern Standard and
Egyptian Arabic tweets for event modality that comprises obligation, permission, commitment,
ability, and volition. The procedure splits up the annotation process into a series of simplified
questions, dispenses with the requirement of expert linguistic knowledge, and captures nested
modality triggers and their attributes semi-automatically.
</bodyText>
<sectionHeader confidence="0.999061" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99933609375">
Event modality, according to Palmer (2001), describes events that are not actualized but are
merely potential. It comprises obligation, permission, commitment, ability, and volition. Both
obligation and permission emanate from an external authority such as the law; whereas
commitments are the obligations placed by speakers on themselves as in promises. Ability is the
(in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and
preferences. Event modality is used for several NLP tasks, including sales and marketing
analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et
al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification
of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012).
To-date, there are no large-scale Arabic corpora annotated for event modality compared to
English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010),
Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the
creation of modality-annotated corpora is the lack of consensus definitions of modality and its
attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality
annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic
background; hence, annotation typically takes place in in-lab settings at small scales.
In this paper, we present an interactive annotation procedure to annotate event modality and
its attributes of sense, polarity, intensification, tense, holders, and scopes in Modern Standard
and Egyptian Arabic tweets. The procedure depicts the following ideas: first, it defines each
annotation task as a series of questions displayed&apos;/hidden based on prior answers; second, it
avoids lengthy theoretically-sophisticated definitions and uses the questions instead as
simplified self-explanatory annotation prompts; and third, based on the elicited answers it
automatically determines nested triggers and their attributes. The fact that our procedure does
not require special linguistic background and consists of easy-to-administer questions makes it
eligible for large-scale crowdsourcing annotation.
Our corpus comprises 9949 unique tweets, annotated for 12134 tokens that map to 315 unique
types of event modality triggers and their attributes of sense, polarity, intensification, tense,
holders, and scopes. The reason to work on the genre of tweets is that our corpus is part of a
larger project to incorporate linguistic features, such as modality, with network-based features
to automatically identify the key players of political discourse on Twitter for countries with
fast-changing politics such as Egypt. The fact that our corpus is harvested from the Arabic
Egyptian Twitter entails that the corpus is diglossic for Modern Standard Arabic (MSA), the
</bodyText>
<note confidence="0.702663">
This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and
proceedings footer are added by the organizers. License details: http:// creativecommons.org/licenses/by/4.0/
</note>
<page confidence="0.953599">
139
</page>
<note confidence="0.6701445">
LAW VIII - The 8th Linguistic Annotation Workshop, pages 139–148,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.998887583333333">
formal Arabic variety, and Egyptian Arabic (EA), the native Arabic dialect of Egypt. We
evaluate the annotation results with Krippendorff&apos;s alpha (Krippendorff 2011). Results show
high inter-annotator reliability rates, indicating that our annotation scheme and procedure are
effective. The contribution of this paper, therefore, is twofold: first, we create a novel annotated
resource for Arabic NLP that is larger than existing corpora even for languages other than
Arabic; and second, we present an efficient and easy-to-administer annotation procedure with
interactive crowdsourcing potentials.
The rest of this paper is organized as follows: Section 2 outlines the annotation scheme,
guidelines and the interactive procedure; Section 3 gives examples for the final output
representations; Section 4 describes corpus harvesting and sampling; Section 5 provides the
annotation results and disagreement analysis; and Section 6 compares and contrasts our work
with related work.
</bodyText>
<sectionHeader confidence="0.837521" genericHeader="method">
2 Annotation Scheme: Tasks and Guidelines
</sectionHeader>
<bodyText confidence="0.99878">
Our annotation scheme comprises six tasks to label sense, polarity, intensification, tense,
holders, and scopes for each event modality. Prior to the beginning of the interactive procedure,
we highlight all event modalities in each tweet using a string-match algorithm and the lexicons
from Al-Sabbagh et al. (2013, 2014a). The algorithm finds all potential event modality triggers
(i.e. words/phrases that convey event modality) within each tweet in our corpus and marks them
as annotation units. A total of 12134 candidate triggers are highlighted in 9949 tweets.
</bodyText>
<subsectionHeader confidence="0.991568">
2.1 Task 1: Sense
</subsectionHeader>
<bodyText confidence="0.99907625">
Sense annotation is to decide for each candidate trigger in context whether it actually conveys
event modality given the tweet&apos;s context. The same present participle u4 HAbb in example 1 is
a volition trigger meaning I want/desire; whereas in example 2 it is a non-modal present
participle meaning like/prefer/respect.
</bodyText>
<listItem confidence="0.8636062">
1. [�: �s^ وs^�] ..•:� � uأ txط&apos;
TbEA &gt;nA m$ HAbb [Emrw mwsY yksb]
Definitely, I do not want [Amr Moussa to win].
2. as = yأ &amp;quot;U. L�&amp;quot; VUZ1ا ����ر :��دأ و_�­ #egypt #qalyoum
Emrw &gt;dyb: rsmyA AlktAtny m$ HAbb &gt;bw HAmd #egypt #qalyoum
</listItem>
<subsectionHeader confidence="0.957464">
Amr Adeeb: Alkatatny does not officially like Abu Hamed #egypt #qalyoum
</subsectionHeader>
<bodyText confidence="0.999758166666667">
We define sense annotation as a synonymy judgment task, following Al-Sabbagh et al. (2013,
2014b). Each event modality sense is represented by an exemplar set manually selected so that:
(1) each exemplar is an unambiguous event modality trigger; (2) exemplars are in both MSA
and EA; (3) exemplars comprise both simple words and multiword expressions; (4) exemplars
are both affirmative and negative; and (5) exemplars are of different intensities. Presented with
a pre-highlighted candidate trigger in context and the exemplar sets, annotations are to decide
whether the candidate trigger is synonymous with any of the exemplar sets. If not, the trigger is
then assumed as non-modal.
If an annotator decides that a given candidate trigger is a non-modal, no further questions
about polarity, intensification, tense, holders, or scopes are displayed. In order to guarantee that
annotators do not select the non-modal option as an easy escape, they are not allowed to move
forward without giving at least one synonym of their own to the candidate trigger.
</bodyText>
<subsectionHeader confidence="0.998002">
2.2 Task 2: Polarity
</subsectionHeader>
<bodyText confidence="0.999759666666667">
Task 2 uses as input the candidates labeled as valid event modality triggers in Task 1 and label
each as either affirmative (AFF) or negative (NEG). To decide, annotators are instructed to
consider the absence/presence of:
</bodyText>
<listItem confidence="0.99993">
• Negation particles such as 01&amp;quot; m$ (not), V lA (not), and ��� gyr (not), among others.
• Negation affixes, especially in EA, like the circumfix m...$ in ����� mqdr$ (I cannot).
</listItem>
<bodyText confidence="0.563315">
&apos; Throughout the examples, modality triggers are marked in boldface, and scopes are in-between brackets.
</bodyText>
<page confidence="0.958394">
140
</page>
<listItem confidence="0.98575">
• Negative polarity items like ي-&gt;— Emry (never) and -4 � lm yEd (no longer).
• Negative auxiliaries where negation is placed on the past tense auxiliary as in ���� �����
mknt$ EAyz (I did not want).
• Inherently-negative triggers that encode negation in their lexical meanings such as yL�
EAjz (incapable) and t!-, ymnE (prohibit).
• Embedding under negated epistemic modality triggers as in `.&apos;-: ,:,أ »أ V lA &gt;Etqd &gt;nh
yjb (I do not think it is necessary) which entails that the speaker is not actually setting
an obligation.
</listItem>
<bodyText confidence="0.816127">
Annotators are instructed that using multiple negation markers results in an affirmative sense.
Thus, + � lm yEjz (he was not unable to) means that he was actually able to. Annotators are
required to give the reason for negation if they decide that a given trigger is negative.
</bodyText>
<subsectionHeader confidence="0.997772">
2.3 Task 3: Intensification
</subsectionHeader>
<bodyText confidence="0.994465">
Event modality triggers have different lexical intensities (i.e. intensities encoded in the lexical
meaning of the word/phrase regardless of the context). In obligation triggers, for instance, even
without a context, Arabic speakers know that يرو�� Drwry (necessary) expresses a higher
necessity than ضو.&gt;!J AlmfrwD (should). When used in context, the trigger&apos;s lexical intensity
can be maintained as is, or amplified/mitigated by such linguistic means as:
</bodyText>
<listItem confidence="0.941080916666667">
• Modification: adverbs like L�L�� tmAmA (absolutely) amplify lexical intensity; whereas
mitigation is invoked by such adverbs as L4 gAlbA (most probably).
• Categorical negation typically amplifies lexical intensity as in ا�#أ ضو�!��ا LAI m$
AlmfrwD &gt;bdA (it should never be).
• Emphatic expressions such as A qd (indeed), ﷲو wAllh (I swear), and 6,4&apos; cls &amp;- mn kl
qlby (wholeheartedly), among others, lead to lexical intensity amplification.
• Coordination of two or more triggers typically results in intensity amplification as in
يرو و مز&apos;J lAzm wDrwry (must and necessary).
• Embedding under epistemic modality triggers can affect the lexical intensities of event
modality triggers. In نأ يرو�(�ا )� i-=أ &gt;Etqd mn AlDrwry &gt;n (I think it is necessary
to) the strong obligation associated with يرو�(�ا AlDrwry (necessary) is mitigated by
the moderate-intensity epistemic T=أ &gt;Etqd (I think), being embedded under it.
</listItem>
<bodyText confidence="0.999944">
The annotators&apos; task for intensification annotation is to decide for each candidate labeled as a
valid event modality trigger in Task 1 whether its lexical intensity is amplified (AMP), mitigated
(MTG) or maintained (AS IS). During interactive annotation, annotators are asked to provide the
reason for their selection; that is, whether the lexical intensity is affected by modification,
coordination, negation, embedding or any other reason whether listed above or not.
</bodyText>
<subsectionHeader confidence="0.989234">
2.4 Task 4: Tense
</subsectionHeader>
<bodyText confidence="0.999721">
In this version of our event modality corpus, we work on the present and past tenses only. Thus,
Task 4 is to decide for each valid event modality trigger from Task 1 whether it is present (PRS)
or past (PST). Annotators are required to give their reasons for selecting either PRS or PST.
</bodyText>
<subsectionHeader confidence="0.994872">
2.5 Task 5: Holders
</subsectionHeader>
<bodyText confidence="0.999856">
Holder annotation identifies the source of the obligation, permission, commitment, ability, or
volition. In example 3, the source that sets the obligation that Egyptians have to learn the
meaning of democracy is the Twitter user.
</bodyText>
<figure confidence="0.301673">
3. [ لو�ا ��طا�����د ��إ ���� ا������ �������ا ] مز�
tAzm [AlmSryyn ytElmwA yEny &lt;yh dymwqrATyp Al&gt;wl]
</figure>
<subsectionHeader confidence="0.828221">
[Egyptians have to learn what democracy is first]
</subsectionHeader>
<bodyText confidence="0.9830225">
The holder is not always the Twitter user, however. In example 4, the Twitter user quotes
Kamal Alganzoury - a former Egyptian Prime Minster - stating that he does not want to
</bodyText>
<page confidence="0.992081">
141
</page>
<bodyText confidence="0.999454333333333">
continue as the Prime Minister. Therefore, the holder of the negated volition trigger *+&amp;ر ي-�, ,ul
lys ldy rgbp (not have a will) is Alganzoury not the Twitter user. This is an example of the
nested holder notion first proposed by Wiebe et al. (2005) and Saurí and Pustejovsky (2009).
</bodyText>
<listItem confidence="0.893143">
4. [را����.ا ] �� ���ر يn1 -4 :يرو*�+1ا لL-5 رy,nll #SCAF #Tahrir #Egypt
</listItem>
<subsubsectionHeader confidence="0.385867">
Aldktwr kmAl Aljnzwry: lys ldy rgbp fy [AlAstmrAr] #SCAF #Tahrir #Egypt
</subsubsectionHeader>
<subsectionHeader confidence="0.558102">
Dr. Kamal Alganzoury: I do not wish to [continue] #SCAF #Tahrir #Egypt
</subsectionHeader>
<bodyText confidence="0.99955825">
Another example of nested holders is example 5. We know that the regime is incapable of
maintaining security and protecting the people only because the Twitter user says so. Put
differently, the best way to understand this tweet is that according to what the Twitter user holds
as a true proposition, the regime is unable to maintain security and protect the people.
</bodyText>
<listItem confidence="0.657952">
5. [&apos;��طا_.J &amp;quot;;,,1.— وأ &apos;-!ا jo-0] Lc رد�l y/ مl1�ll
</listItem>
<subsubsectionHeader confidence="0.42361">
AlnZAm gyr qAdr ElY [twfyr Al&gt;mn &gt;w HmAyp AlmwATnyn]
</subsubsectionHeader>
<bodyText confidence="0.893474333333333">
The regime is not able to [maintain security and protect the people]
We can have two or more nested holders. In example 4, the two holders are Alganzoury who
expresses his unwillingness to continue as a Prime Minster and the Twitter user who is quoting
Alganzoury. In example 5, the two holders are the regime that is incapable of marinating
security and protecting its people and the Twitter user who holds this proposition as true. In
example 6, we have three nested holders: the Iranians who are unwilling to confront the outside
world, Obama who holds that as a true proposition about Iranians, and the Twitter user who is
quoting Obama stating his proposition.
6. [�7رli1ا 4�Wا 5� &amp;quot;67ا,.°1ا] ,� .A-9 -4 4� ��ا��.ا ��3�ا :L-�,وا
</bodyText>
<subsubsectionHeader confidence="0.681988">
AwbAmA: Al$Eb AlAyrAny lm yEd yrgb fy [AlmwAjhp mE AlEAlm AlxArjy]
</subsubsectionHeader>
<bodyText confidence="0.961924777777778">
Obama: the Iranians no longer want to [confront the other countries].
During the interactive procedure, annotators are first asked whether the holder is the same as
the Twitter user. If not, more questions are displayed to determine (1) who the real holder is; (2)
whether the tweet is a(n) (in)direct quote; or it conveys the Twitter user&apos;s assumptions.
When the holder is not the Twitter user, annotators are asked to mark the boundaries of the
linguistic unit that corresponds to the holder in the tweet&apos;s text. Annotators are instructed to use
the maximal length principle from Szarvas et al. (2008) so that they mark the largest possible
meaningful linguistic unit. Thus, in example 4 the holder is يرو����ا لL-. ر/�.��ا Aldktwr kmAl
Aljnzwry (Dr. Kamal Alganzoury) not only Kamal Alganzoury.
</bodyText>
<subsectionHeader confidence="0.992224">
2.6 Task 6: Scopes
</subsectionHeader>
<bodyText confidence="0.989347888888889">
Scopes are the events modified by the trigger, syntactically realized as clauses, verb phrases,
deverbal nouns or to-infinitives, according to Al-Sabbagh et al. (2013). We use the same
maximal length principle from Task 5 so that the marked scope segment corresponds to the
largest meaningful linguistic unit that describes the event. Typically, scope segments are
delimited by: (1) punctuation markers and (2) subordinate conjunctions.
Annotators are instructed that: (1) a single trigger may have one or more scopes; (2) two or
more triggers - especially conjoined by coordinating particles - can share the same scope; and
(3) scopes are not necessarily adjacent to their triggers. Examples 7, 8 and 9 illustrate each of
these guidelines, repecetively.
</bodyText>
<figure confidence="0.496734555555556">
7. [&amp;quot;�U}Iا ق4-1 ةد���ا ] و [&apos;�&lt;�ا ] &amp;Ie&amp;quot; 94:; _4_ا sl
lw AstbEd $fyq ystTyE [AlTEn] w[AlEwdp lsbAq Alr}Asp]
If Shafiq is excluded, he can [appeal] and [run again for presidency].
8. [@��(��ا 9— 46� AB.1:] -,ajو يرو.raو L�i&apos;-و مزi j(� هju ,&amp;�ا &apos;iwr(�lا &apos;~~D-
mlAyyn AlmSryyn Ally brh mSr lAzm wHtmA wDrwry wyjb [ybqY lhm Hq AltSwyt]
It is necessary, it is a must, it is a need that [Egyptians abroad are given the right to vote].
9. [~~~au s&amp;, A&amp;-او &apos;—ا y(�# فy;ا] تyoا L. G�# a+� ﷲو W,.L
nfsy wAllh bjd qbl mA Amwt [A$wf #mSr AHsn wAHlY bld fAldnyA]
I really wish before I die to [see #Egypt becoming one of the best counties in the world].
</figure>
<sectionHeader confidence="0.99034" genericHeader="method">
3 Final Output Representation
</sectionHeader>
<bodyText confidence="0.9992165">
All elicited answers during annotation are organized into the representations illustrated in the
following examples. The representation of example 10 reads as: the Twitter USER strongly did
</bodyText>
<page confidence="0.991879">
142
</page>
<bodyText confidence="0.999852">
not want Shafiq to win the presidential elections. The trigger 04�ا Atmnyt (wished) is tagged as
synonymous with the volition exemplar set; therefore, it denotes a DESIRE. It is then labeled as a
past tense (PST), negative (NEG) trigger. Furthermore, its lexical intensity is labeled as amplified
(AMP) because of the categorical negation L- ي-&gt;— Emry mA (never ever). Originally, 04�ا
Atmnyt (wished) is of moderate lexical intensity, being less intense than 0�2�3ا A$thyt (longed
for) but more intense than تدرأ &gt;rdt (wanted). Given the categorical negation, the lexical
intensity of 0~44 Atmnyt (wished) goes up the scale from moderate to strong (STRG).
</bodyText>
<figure confidence="0.542484333333333">
10. ���� # &amp;quot;7�� &apos;� �����J� ���ر ﷲ ��J�ا .[���� 9�:; ] نا ��4a1� ي���
Emry mAtmnyt An [$fyq yksb]. AlHmd Allh rbnA mHrmny$ mn HAjp #mrsy
I have never ever wished [Shafiq to win]. Thank God! #Morsi.
</figure>
<figureCaption confidence="0.228039">
rep. USER, STRG PST NEG DESIRE ($fyq yksb)
</figureCaption>
<bodyText confidence="0.921920833333333">
Example 11 reads as: the Twitter USER reports Hegazy stating that he has the ability to
become the Muslim&apos;s caliphate. The trigger 678أ &gt;SlH (can) is labeled as synonymous with the
ability exemplar set. It is also labeled as a present (PRS), affirmative (AFF) trigger whose lexical
intensity is maintained (AS IS) in the context. Therefore, its lexical intensity is maintained to its
original level which is moderate (MOD).
11. 4 ll ةد�- نsS:-و [&apos;��&amp;��&amp;� ً&amp;quot;:�&amp;M ن-,أ] نأ LLI-i Uأ :يزL+� #Ikhwan
</bodyText>
<subsubsectionHeader confidence="0.497562">
HjAzy: &gt;nA &gt;SlH &gt;n [&gt;kwn xlyfp llmslmyn] wsnkwn sAdp AlEAlm #Ikhwan
</subsubsectionHeader>
<bodyText confidence="0.91465725">
Hegazy: I can [be the Muslims&apos; caliphate] and we will become the world&apos;s masters. #Ikhwan
rep. USER, report, (HjAzy, MOD PRS AFF ABLE, (&gt;kwn xlyfp llmslmyn))
Example 12 shows a Twitter user who holds as true that the only thing Egypt needed was a
wise politician to avoid the bloodshed. The trigger جti-1 tHtAj (needs) is labeled as an obligation
trigger synonymous with L411-- ttTlb (requires). It is also labeled as past tense (PST) given the
preceding past tense auxiliary L9 tkn (was). The assigned strong (STRG) lexical intensity label is
attributed to the fact that the original moderate intensity of جti-1 tHtAj (needs) is amplified by
the categorical negation structure Yإ ... � lm ... &lt;lA (nothing but).
12. [ءL--s ا &amp;quot;#ارا نو-u تlaز.ا &apos;- جj8= G#�- G7ر] .ا !rtl%&apos; uS, P --#
#mSr lm tkn tHtAj AlA [rjl EAql yxrj mn AlAzmAt bdwn ArAqp AldmA&apos;]
#Egypt needed nothing but [a rational politician who solves crises without bloodshed]
rep. USER, true, (mSr , STRG PST AFF REQUIRE (rjl EAql yxrj mn AlAzmAt bdwn ArAqp AldmA&apos;))
Example 13 illustrates the representation of three-level nested holders. It reads as: the USER
reports Obama&apos;s assumption as the latter holds as true that the Iranians do not want to confront
other countries.
13. [�7رl8lا 4Itxlا 5� &amp;quot;67ا�a!ا] �� ���� k� 4� ��اt+.ا ��3�ا :L4lsوا
</bodyText>
<subsubsectionHeader confidence="0.752536">
AwbAmA: Al$Eb AlAyrAny lm yEd yrgb fy [AlmwAjhp mE AlEAlm AlxArjy]
</subsubsectionHeader>
<bodyText confidence="0.8155377">
Obama: the Iranians no longer want to [confront other countries].
rep. USER, report, (AwbAmA, true, (Al$Eb AlAyrAny, MOD PRS NEG DESIRE, (AlmwAjhp mE
AlEAlm AlxArjy)))
Example 14 shows how two conjoined triggers (i.e. مز&apos;J lAzm (must) and يرو�� Drwry
(necessary)) that share the same holder and scope are merged into one representation, and the
conjunction leads to amplifying the intensity of the obligation set by them both.
14. [-�=-�ا ةرjO UL -و &amp;quot;-,LJJ -;- ماA نyS&apos; Lit] ����� و t, V
lAzm wDrwry [klnA nkwn qdAm mqr AlmHAkmp wmEAnA Swrp Alr)ys]
We must and it is necessary that [we go to the court with President&apos;s pictures].
rep. USER, STRG PRS AFF REQUIRE, (klnA nkwn qdAm mqr AlmHAkmp wmEAnA Swrp Alr)ys)
</bodyText>
<sectionHeader confidence="0.965448" genericHeader="method">
4 Corpus Harvesting
</sectionHeader>
<bodyText confidence="0.9996605">
Tweets are harvested from the Arabic Egyptian Twitter provided that (1) each tweet has at least
one trendy political English or Arabic hashtag; and (2) each tweet has at least one candidate
event modality trigger from the Arabic modality lexicons (Al-Sabbagh et al. 2013, 2014a). We
harvest tweets from a variety of users such as newspapers, TV stations, political and
humanitarian campaigns, politicians, celebrities, and ordinary people. Thus, our corpus
comprises both MSA, the formal Arabic variety, and EA, the native Arabic dialect of Egypt.
The harvested corpus comprises 9949 unique tweets, with 12134 tokens of event modality
triggers that map to 315 unique types.
</bodyText>
<page confidence="0.999292">
143
</page>
<sectionHeader confidence="0.995276" genericHeader="method">
5 Annotation Results
</sectionHeader>
<subsectionHeader confidence="0.998503">
5.1 Evaluation Methodology and Metrics
</subsectionHeader>
<bodyText confidence="0.999937">
Our annotation tasks are of two types: (1) Tasks 1-4 are label-based where there is a pre-defined
set of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where the
output of the annotation is a text segment. For the segmentation-based tasks, we use an all-or-
nothing method to measure inter-annotator reliability: for segments to be considered as
agreement, they must share both the beginning and end boundaries. We use Krippendorff&apos;s
alpha α (Krippendorff 2011) as our inter-annotator reliability measure, following the most
recent work on modality annotation for other languages including English (Rubinstein et al.
2013) and Chinese (Cui and Chi 2013). For more details on Krippendorff&apos;s alpha and a, we refer
the reader to Artstein and Poesio (2008).
</bodyText>
<subsectionHeader confidence="0.767572">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.999888857142857">
We use the surveygizmo survey services2 to implement our interactive annotation procedure
given that their survey structure is one that uses conditional branching and skip logic. We
distribute the survey on Twitter and we have three annotators participating. According to the
short qualifying quiz given at the beginning of the survey, all three participants are native
Egyptian Arabic (EA) speakers who have at least two-year experience with Twitter. They are
also university graduates who, therefore, master MSA. None of the participants has a linguistics
background. Table 1 shows alpha rates for each annotation task.
</bodyText>
<table confidence="0.998986571428571">
Sense Polarity Intensification Tense Holder Scope
Obligation 0.890 0.893 0.892 0.978 0.829 0.744
Permission 0.864 0.905 0.821 0.983 0.800 0.739
Commitment 0.760 0.794 0.783 0.947 0.702 0.654
Ability 0.895 0.914 0.905 0.950 0.828 0.763
Volition 0.921 0.921 0.867 0.982 0.858 0.779
Averages 0.866 0.885 0.854 0.968 0.803 0.736
</table>
<tableCaption confidence="0.999936">
Table 1: Krippendorff&apos;s alpha rates for inter-annotator reliability
</tableCaption>
<subsectionHeader confidence="0.892347">
5.3 Discussion and Disagreement Analysis
</subsectionHeader>
<bodyText confidence="0.999953">
Among the factors that lead to high inter-annotator reliability are that: (1) the vast majority of
negation is explicitly marked by negation particles that are easy to detect by human annotators;
</bodyText>
<listItem confidence="0.981021">
(2) the vast majority of triggers are used without any amplification or mitigation markers; and
(3) punctuation markers are surprisingly informative for marking scope boundaries and direct
quotations; and hence, holders.
</listItem>
<bodyText confidence="0.998799875">
Sense-related disagreement is attributed to: (1) nominal triggers, (2) highly-polysemous
triggers, and (3) different interpretations invoked by the −RATIONAL (i.e. non-human) holders.
Typically, event modality triggers are adjunct constituents that add an extra-layer of meaning
and can be removed without disturbing the syntactic structure. Yet, in example 15, �&lt;او wAjb (a
must) and �&lt;وأ &gt;wjb (a more important must) have main grammatical functions as the
predicates of the phrases they modify. Most of the exemplars from Section 2.1 are adjuncts;
and, thus, none can substitute �&lt;او wAjb (a must) or �&lt;وأ &gt;wjb (a more important must) in such
a context.
</bodyText>
<equation confidence="0.809445">
15. S&amp;M -_4ا] ��� ��او [ ةر�P�ا ف�&lt;�Mا &apos;� Q:J��ا ]
[AltHfZ mn AxtTAf Alvwrp] wAjb lkn [AltwHd xlf m$rwE] &gt;wjb
</equation>
<bodyText confidence="0.945928">
[Being cautious about manipulating the revolution] is a must but [getting united for one project]
is a more important must.
Highly-polysemous triggers invoke disagreement because in many cases even the context is
ambiguous. In example 16, i=&gt;أ &gt;qsm (I swear) has two eligible interpretations: an epistemic
trigger interpretation I assure (you) that and a commitment trigger interpretation I promise (you)
</bodyText>
<footnote confidence="0.968784">
2 http://www.surveygizmo.com/
</footnote>
<page confidence="0.997279">
144
</page>
<bodyText confidence="0.784439">
that. Even the context is not enough to disambiguate the two interpretations and annotators go
by the most common sense for the trigger according to their own opinions.
16. 4 VB�61ھ ةرL;إ Lr-و نs:&amp;~ 90 L-; USا ،[yoa# JJL� Hyl] T ?&amp;quot;i :&amp;quot;دأ و���
Emrw &gt;dyb: &gt;qsm bAllh [ln tsqT #mSr], AHnA $Eb 90 mlywn wm$ &lt;$Arp htsqT bld
Amr Adeeb: I promise/assure (you) by God that [#Egypt will not collapse]. We are 90 million
Egyptians and we will not be defeated by a sign.
Non-human or −RATIONAL holders invoke disagreement, especially for obligation versus
volition triggers. The most common sense of such triggers as ة���� EAyzp (want) is volition.
Yet, when the holder is −RATIONAL like ت1#�@1Yا AlAntxAbAt (the elections) in example 17,
annotators disagree as to whether ة��1L EAyzp means want (i.e. a volition trigger) or need (i.e. an
obligation trigger).
17. �6��ا�� 4,+p&apos; با*�!ا تD و [&apos;�J;�� ] i j4LP تl�L�ii.ا
AlAntxAbAt EAyzp [mr$Hyn] wHmlAt Al&gt;HzAb tyjy brAHthA
Elections want/need [candidates] and later we can establish the political parties.
Intensity-related disagreement is attributed mostly to progressive verb aspect. Some
annotators consider progressive verb aspect as indicated by the EA prefix b as a marker for
</bodyText>
<listItem confidence="0.832553166666667">
lexical intensity amplification. Thus they tag the volition trigger + btmnY (I wish) in example
18 as amplified, especially it is modified by م/o, A. kl ywm (everyday).
18. [ ���� # 4
~ ط�B� ] ����� م�� G,
kl ywm btmnY [sqwT Hkm #mrsy]
Every day, I wish for [#Morsi&apos;s regime to fall].
</listItem>
<bodyText confidence="0.992541">
Polarity-related disagreement is mainly caused by (1) negated holders and (2) contextual
negation. In رA+ — �-,— mfy$ Hd yqdr (no one can), annotators disagree as to whether رA+ yqdr
(can) should be labeled as affirmative or negative. By contextual negation we mean examples
like نأ C!� نأ ,.,.D1ا )� mn AlSEb &gt;n ntmnY &gt;n (it is hard to wish to), which entails negation
due to the adjective L.,.D ا AlSEb (hard).
Holder-related disagreement is attributed mainly to generic nouns and impersonal pronouns
like ��E�ا Al$Eb (the people) and —ا/�ا AlwAHd (one), respectively. They are interpreted by
some annotators as referring implicitly to the Twitter USER. Therefore, the annotators select the
USER as the only holder with zero nesting. Other annotators interpret them as referring to people
in general not necessarily the Twitter USER and thus they consider these as instances of nested
holders.
Scope-related disagreement is attributed to (1) ambiguous subordinate conjunctions, (2)
triggers&apos; modifiers, and (3) absent punctuation markers.
Tense yields almost perfect inter-annotator reliability rates. Annotation disagreement does not
show any particular pattern. Therefore, we attribute minor disagreement to random errors,
resulting from fatigue.
</bodyText>
<subsectionHeader confidence="0.996585">
5.4 Majority Statistics
</subsectionHeader>
<bodyText confidence="0.995747333333333">
Based on majority annotations, Table 2 gives the statistics for our corpus in terms of sense,
polarity, intensification, and tense. As for holder annotations, approximately 60.5% of the
triggers have zero-nested holders (i.e. the tweet&apos;s writer is the same as the holder).
</bodyText>
<table confidence="0.99933">
Sense Polarity Intensification Tense
MD NMD AFF NEG AMP MTG ASIS PRS PST
Ability 1729 920 1047 682 348 308 1073 1175 554
Commitment 1048 495 599 449 221 220 607 639 409
Obligation 1786 848 1059 727 369 399 1018 1018 768
Permission 1699 980 1054 645 286 428 985 1053 646
Volition 1622 1007 974 648 341 292 989 1038 584
Totals 7884 4250 4733 3151 1565 1647 4672 4923 2961
</table>
<tableCaption confidence="0.993068666666667">
Table 2: Token statistics for each annotation task per event modality sense where MD is modal, NMD is
non-modal, AFF is affirmative, NEG is negative, AMP is amplified, MTG is mitigated, ASIS is as is, PRS is
present, and PST is past
</tableCaption>
<page confidence="0.998924">
145
</page>
<sectionHeader confidence="0.999612" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.933991314285714">
Event modality is the focus of many annotation projects. Matsuyoshi et al. (2010) annotate a
corpus of English and Japanese blog posts for a number of modality senses including volition,
wishes, and permission. They annotate sense, tense, polarity, holders as well as other attributes
that we have not covered in our scheme such as grammatical mood. They report macro kappa
inter-annotator agreement rates of 0.69, 0.70, 0.66 and 0.72 for holders, tense, sense, and
polarity, respectively.
Baker et al. (2010, 2012) simultaneously annotate modality and modality-based negation for
Urdu-English machine translation systems. Among the modality senses they work on are
requirement, permission, success, intention, ability, and desires. They report macro kappa inter-
annotator agreement rates of 0.82 for sense annotation and 0.76 for scopes. They, however, do
not annotate holders and do not consider nested modalities.
Hendrickx et al. (2012) annotate eleven modality senses in Portuguese, including necessity,
capacity, permission, obligation, and volition, among others. They report a macro kappa inter-
annotator rate of 0.85 for sense annotation.
Rubinstein et al. (2013) propose a linguistically-motivated annotation scheme for modalities
in the MPQA English corpus. They annotate sense, polarity, holders, and scopes, among other
annotation units. They work on obligation, ability, and volition among other modality senses.
They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope,
respectively.
Cui and Chi (2013) apply the same scheme of Rubinstein et al. (2013) to the Chinese Penn
Treebank and get alpha inter-annotator reliability rates of 0.81 and 0.39 for sense and scope
annotation, respectively.
Finally, Al-Sabbagh et al. (2013) annotate event modality in MSA and EA tweets. We attain
kappa inter-annotator agreement rates of 0.90 and 0.93 for sense and scope annotation,
respectively, for only 772 tokens of event modality triggers.
Our annotation results, therefore, are comparable to the results in the literature. Furthermore,
our annotation scheme and its tasks are orthogonal to most of the aforementioned schemes.
However, the key differences between our work and related work are:
• We use a standardized taxonomy of event modality - Palmer&apos;s (2001) - that has been
proved valid for a variety of languages, including Arabic, according to Mitchell and
Al-Hassan (1994), Brustad (2000), and Moshref (2012).
• We annotate nested holders unlike some of the aforementioned studies (e.g. Baker et
al. 2010, 2012) and use a wider range of negation and intensification markers.
• We use crowdsourcing with simplified guidelines implemented interactively to
annotate a larger-scale corpus of 12134 tokens for event modality and its attributes.
</bodyText>
<sectionHeader confidence="0.971017" genericHeader="conclusions">
7 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.999890066666667">
We presented a large-scale corpus annotated for event modality in MSA and EA tweets. We use
a simplified annotation procedure that defines each annotation task as a series of questions,
implemented interactively. Our scheme covers a wide range of the most common annotation
units mentioned in the literature, including modality sense, polarity, intensification, tense,
holders, and scopes. We deal with nested holders - which are crucial in a highly interactive
genre such as tweets where users frequently quote others and make assumptions about them.
We also automatically merge triggers with shared holders and scopes based on elicited
annotators&apos; answers. The annotation procedure yields reliable results and creates a novel
resources for Arabic NLP. The current version of our corpus does not, however, cover a number
of issues including: the future tense, grammatical moods other than the declarative, and
modality entailment. By modality entailment, we mean, for example, when a tweet&apos;s user
criticizes the obligation of another quoted person, this entails that the user does not consider
such an event as required. For a future version of the corpus, we plan to cover such points.
Furthermore, we will use the corpus to train and test a machine learning system for the
automatic processing of Arabic event modality.
</bodyText>
<page confidence="0.998296">
146
</page>
<sectionHeader confidence="0.976625" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981930458333334">
Rania Al-Sabbagh, Jana Diesner and Roxana Girju. 2013. Using the Semantic-Syntactic Interface for
Reliable Arabic Modality Annotation. In Proceedings of IJCNLP&apos;13, pages 410-418, October 14-18,
2013, Nagoya, Japan.
Rania Al-Sabbagh, Roxana Girju and Jana Diesner. 2014a. Unsupervised Construction of a Lexicon and a
Pattern Repository of Arabic Modal Multiword Expressions. In Proceedings of the 10th Workshop of
Multiword Expressions at EACL&apos;14, April 26-27, 2014, Gothenburg, Sweden.
Rania Al-Sabbagh, Roxana Girju and Jana Diesner. 2014b. 3arif: A Corpus of Modern Standard and
Egyptian Arabic Tweets Annotated for Epistemic Modality Using Interactive Crowdsourcing. In
Proceedings of the 25th International Conference on Computational Linguistics, August 23-29, 2014,
Dublin, Ireland.
Ron Artstein and Massimo Poesio. 2008. Inter-Coder Agreement for Computational Linguistics.
Computational Linguistics, volume 34, issue 4, pages 555-596.
Kathrin Baker, Michael Bloodgood, Mona Diab, Bonnie Dorr, Nathaniel W. Filardo, Lori Levin and
Christine Piatko. 2010. A Modality Lexicon and its Use in Automatic Tagging. In Proceedings of the
7th International Conference on Language Resources and Evaluation (LREC&apos;10), pages 1402-1405,
May 19-21, 2010, Valetta, Malta.
Kathryn Baker, Michael Bloodgood, Bonnie J. Dorr, Chris Callison-Burch, Nathaniel W. Filardo,
Christine Piatko, Lori Levin and Scott Miller. 2012. Modality and Negation in SIMT. Computational
Linguistics. volume 38, issue 2, pages 411-438.
Samuel R. Bowman and Harshit Chopra. 2012. Automatic Animacy Classification. In Proceedings of the
NAACL HTL 2012 Student Research Workshop, pages 7-10, June 3-8, 2012, Montreal, Canada.
Kristen E. Brustad. 2000. The Syntax of Spoken Arabic: A Comparative Study of Moroccan, Egyptian,
Syrian and Kuwaiti Dialects. Georgetown University Press, Washington DC, USA.
Cohan Sujay Carlos and Madulika Yalamanchi. 2012. Intention Analysis for Sales, Marketing and
Customer Service. In Processing of COLING 2012: Demonstration Papers, pages 33-40, December
2012, Mumbai, India.
Baptiste Chardon, Farah Benamara, Yannick Mathieu, Vladimir Popescu and Nicholas Asher. 2013.
Sentiment Composition Using a Parabolic Model. In Proceedings of the 10th International Conference
on Computational Semantics (IWCS 2013), pages 47-58, March 20-22, 2013, Potsdam, Germany.
Yanyan Cui and Ting Chi. 2013. Annotating Modal Expressions in the Chinese Treebank. In Proceedings
of the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM), pages 24-
32, March 2013, Potsdam, Germany.
Iris Hendrickx, Amàlia Mendes and Silvia Mencarelti. 2012. Modality in Text: A Proposal for Corpus
Annotation. In Proceedings of the 8th International Conference on Language Resources and Evaluation
(LREC&apos;12), pages 1805-1812, May 21-27, 2012, Istanbul, Turkey.
Klaus Krippendorff. 2011. Computing Krippendorff&apos;s Alpha-Reliability. Annenberg School of
Communication, Departmental Papers: University of Pennsylvania.
Andrew Lampert, Robert Dale and Cecile Paris. 2010. Detecting Emails Containing Requests for Action.
In Proceedings of Human Language Technologies: the 2010 Annual Conference of the North American
Chapter of the ACL, pages 984-992, June 2010, Los Angles, California.
Ying-Shu Liao and Ting-Gen Liao. 2009. Modal Verbs for the Advice Move in Advice Columns. In
Proceedings of the 23rd Pacific Asia Conference on language, Information and Computation, pages
307-316, December 3-5, 2009, Hong Kong, China.
Suguru Matsuyoshi, Megumi Eguchi, Chitose Sao, Koji Murakami, Kentaro Inui and Yuji Matsumoto.
2010. Annotating Event Mentions in Text with Modality, Focus and Source Information. In
Proceedings of LREC&apos;10, pages 1456-1463, May 19-21, 2010, Valletta, Malta.
T. F. Mitchell and S. A. Al-Hassan. 1994. Modality, Mood and Aspect in Spoken Arabic with Special
Reference to Egypt and the Levant. London and NY: Kegan Paul International.
</reference>
<page confidence="0.988677">
147
</page>
<reference confidence="0.986151315789474">
Ola Moshref. 2012. Corpus Study of Tense, Aspect, and Modality in Diglossic Speech in Cairene Arabic.
PhD Thesis. University of Illinois at Urbana-Champaign.
Frank R. Palmer. 2001. Mood and Modality. 2nd Edition. Cambridge University Press, Cambridge, UK.
J. Ramanand, Krishna Bhavsar and Niranjan Pedanekar. 2010. Wishful Thinking: Finding Suggestions
and &amp;quot;Buy&amp;quot; Wishes for Product Reviews. In Proceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to the Analysis and Generation of Emotion in Text, pages 54-61, June
2010, Los Angeles, California.
Aynat Rubinstein, Hillary Harner, Elizabeth Krawczyk, Daniel Simoson, Graham Katz and Paul Portner.
2013. Toward Fine-Grained Annotation of Modality in Text. In Proceedings of the IWC 2013Workshop
on Annotation of Modal Meaning in Natural Language (WAMM), pages 38-46, March 2013, Potsdam,
Germany.
Roser Saurí and James Pustejovsky. 2009. FactBank: A Corpus Annotated with Event Factuality.
Language Resources and Evaluation, 43:227-268
György Szarvas, Veronika Vincze, Richárd Farkas and János Csirik. 2008. The BioScope Corpus:
Annotation for Negation, Uncertainty and their Scope in Biomedical Texts. In Proceedings of BioNLP
2008: Current Trends in Biomedical Natural Language Processing, pages 38-45, June 2008,
Columbus, Ohio, USA.
Janyce Wiebe, Theresa Wilson and Claire Cardie. 2005. Annotating Expressions of Opinions and
Emotions in Language. Language Resources and Evaluation, volume 39, issue 203, pages 1663-210.
</reference>
<page confidence="0.996843">
148
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948733">
<title confidence="0.993547">Interactive Annotation for Event Modality in Modern and Egyptian Arabic Tweets</title>
<author confidence="0.99952">Roxana Jana of Linguistics</author>
<author confidence="0.99952">Beckman</author>
<affiliation confidence="0.995756">of Library and Information University of Illinois at Urbana-Champaign,</affiliation>
<email confidence="0.986973">alsabba1@illinois.edu</email>
<email confidence="0.986973">girju@illinois.edu</email>
<email confidence="0.986973">jdiesner@illinois.edu</email>
<abstract confidence="0.9969095">We present an interactive procedure to annotate a large-scale corpus of Modern Standard and Egyptian Arabic tweets for event modality that comprises obligation, permission, commitment, ability, and volition. The procedure splits up the annotation process into a series of simplified questions, dispenses with the requirement of expert linguistic knowledge, and captures nested modality triggers and their attributes semi-automatically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Reliable Arabic Modality Annotation.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCNLP&apos;13,</booktitle>
<pages>410--418</pages>
<location>Nagoya, Japan.</location>
<contexts>
<context position="14173" citStr="(2013)" startWordPosition="2192" endWordPosition="2192">the Twitter user, annotators are asked to mark the boundaries of the linguistic unit that corresponds to the holder in the tweet&apos;s text. Annotators are instructed to use the maximal length principle from Szarvas et al. (2008) so that they mark the largest possible meaningful linguistic unit. Thus, in example 4 the holder is يرو����ا لL-. ر/�.��ا Aldktwr kmAl Aljnzwry (Dr. Kamal Alganzoury) not only Kamal Alganzoury. 2.6 Task 6: Scopes Scopes are the events modified by the trigger, syntactically realized as clauses, verb phrases, deverbal nouns or to-infinitives, according to Al-Sabbagh et al. (2013). We use the same maximal length principle from Task 5 so that the marked scope segment corresponds to the largest meaningful linguistic unit that describes the event. Typically, scope segments are delimited by: (1) punctuation markers and (2) subordinate conjunctions. Annotators are instructed that: (1) a single trigger may have one or more scopes; (2) two or more triggers - especially conjoined by coordinating particles - can share the same scope; and (3) scopes are not necessarily adjacent to their triggers. Examples 7, 8 and 9 illustrate each of these guidelines, repecetively. 7. [&amp;quot;�U}Iا ق</context>
<context position="28243" citStr="(2013)" startWordPosition="4449" endWordPosition="4449">sed negation for Urdu-English machine translation systems. Among the modality senses they work on are requirement, permission, success, intention, ability, and desires. They report macro kappa interannotator agreement rates of 0.82 for sense annotation and 0.76 for scopes. They, however, do not annotate holders and do not consider nested modalities. Hendrickx et al. (2012) annotate eleven modality senses in Portuguese, including necessity, capacity, permission, obligation, and volition, among others. They report a macro kappa interannotator rate of 0.85 for sense annotation. Rubinstein et al. (2013) propose a linguistically-motivated annotation scheme for modalities in the MPQA English corpus. They annotate sense, polarity, holders, and scopes, among other annotation units. They work on obligation, ability, and volition among other modality senses. They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope, respectively. Cui and Chi (2013) apply the same scheme of Rubinstein et al. (2013) to the Chinese Penn Treebank and get alpha inter-annotator reliability rates of 0.81 and 0.39 for sense and scope annotation, respectively. Finally, Al-Sabbagh et al.</context>
</contexts>
<marker>2013</marker>
<rawString>Reliable Arabic Modality Annotation. In Proceedings of IJCNLP&apos;13, pages 410-418, October 14-18, 2013, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rania Al-Sabbagh</author>
<author>Roxana Girju</author>
<author>Jana Diesner</author>
</authors>
<title>Unsupervised Construction of a Lexicon and a Pattern Repository of Arabic Modal Multiword Expressions.</title>
<date>2014</date>
<booktitle>In Proceedings of the 10th Workshop of Multiword Expressions at EACL&apos;14,</booktitle>
<location>Gothenburg,</location>
<marker>Al-Sabbagh, Girju, Diesner, 2014</marker>
<rawString>Rania Al-Sabbagh, Roxana Girju and Jana Diesner. 2014a. Unsupervised Construction of a Lexicon and a Pattern Repository of Arabic Modal Multiword Expressions. In Proceedings of the 10th Workshop of Multiword Expressions at EACL&apos;14, April 26-27, 2014, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rania Al-Sabbagh</author>
<author>Roxana Girju</author>
<author>Jana Diesner</author>
</authors>
<title>3arif: A Corpus of Modern Standard and Egyptian Arabic Tweets Annotated for Epistemic Modality Using Interactive Crowdsourcing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics,</booktitle>
<location>Dublin, Ireland.</location>
<marker>Al-Sabbagh, Girju, Diesner, 2014</marker>
<rawString>Rania Al-Sabbagh, Roxana Girju and Jana Diesner. 2014b. 3arif: A Corpus of Modern Standard and Egyptian Arabic Tweets Annotated for Epistemic Modality Using Interactive Crowdsourcing. In Proceedings of the 25th International Conference on Computational Linguistics, August 23-29, 2014, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Inter-Coder Agreement for Computational Linguistics.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<pages>555--596</pages>
<contexts>
<context position="20706" citStr="Artstein and Poesio (2008)" startWordPosition="3268" endWordPosition="3271"> 5-6 are segmentation-based where the output of the annotation is a text segment. For the segmentation-based tasks, we use an all-ornothing method to measure inter-annotator reliability: for segments to be considered as agreement, they must share both the beginning and end boundaries. We use Krippendorff&apos;s alpha α (Krippendorff 2011) as our inter-annotator reliability measure, following the most recent work on modality annotation for other languages including English (Rubinstein et al. 2013) and Chinese (Cui and Chi 2013). For more details on Krippendorff&apos;s alpha and a, we refer the reader to Artstein and Poesio (2008). 5.2 Results We use the surveygizmo survey services2 to implement our interactive annotation procedure given that their survey structure is one that uses conditional branching and skip logic. We distribute the survey on Twitter and we have three annotators participating. According to the short qualifying quiz given at the beginning of the survey, all three participants are native Egyptian Arabic (EA) speakers who have at least two-year experience with Twitter. They are also university graduates who, therefore, master MSA. None of the participants has a linguistics background. Table 1 shows al</context>
</contexts>
<marker>Artstein, Poesio, 2008</marker>
<rawString>Ron Artstein and Massimo Poesio. 2008. Inter-Coder Agreement for Computational Linguistics. Computational Linguistics, volume 34, issue 4, pages 555-596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathrin Baker</author>
<author>Michael Bloodgood</author>
<author>Mona Diab</author>
<author>Bonnie Dorr</author>
<author>Nathaniel W Filardo</author>
<author>Lori Levin</author>
<author>Christine Piatko</author>
</authors>
<title>A Modality Lexicon and its Use in Automatic Tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC&apos;10),</booktitle>
<pages>1402--1405</pages>
<location>Valetta,</location>
<contexts>
<context position="1716" citStr="Baker et al. 2010" startWordPosition="234" endWordPosition="237">rs on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales. In this paper, we present an interactive annotation procedure to annota</context>
<context position="27581" citStr="Baker et al. (2010" startWordPosition="4354" endWordPosition="4357">gative, AMP is amplified, MTG is mitigated, ASIS is as is, PRS is present, and PST is past 145 6 Related Work Event modality is the focus of many annotation projects. Matsuyoshi et al. (2010) annotate a corpus of English and Japanese blog posts for a number of modality senses including volition, wishes, and permission. They annotate sense, tense, polarity, holders as well as other attributes that we have not covered in our scheme such as grammatical mood. They report macro kappa inter-annotator agreement rates of 0.69, 0.70, 0.66 and 0.72 for holders, tense, sense, and polarity, respectively. Baker et al. (2010, 2012) simultaneously annotate modality and modality-based negation for Urdu-English machine translation systems. Among the modality senses they work on are requirement, permission, success, intention, ability, and desires. They report macro kappa interannotator agreement rates of 0.82 for sense annotation and 0.76 for scopes. They, however, do not annotate holders and do not consider nested modalities. Hendrickx et al. (2012) annotate eleven modality senses in Portuguese, including necessity, capacity, permission, obligation, and volition, among others. They report a macro kappa interannotat</context>
<context position="29629" citStr="Baker et al. 2010" startWordPosition="4657" endWordPosition="4660">only 772 tokens of event modality triggers. Our annotation results, therefore, are comparable to the results in the literature. Furthermore, our annotation scheme and its tasks are orthogonal to most of the aforementioned schemes. However, the key differences between our work and related work are: • We use a standardized taxonomy of event modality - Palmer&apos;s (2001) - that has been proved valid for a variety of languages, including Arabic, according to Mitchell and Al-Hassan (1994), Brustad (2000), and Moshref (2012). • We annotate nested holders unlike some of the aforementioned studies (e.g. Baker et al. 2010, 2012) and use a wider range of negation and intensification markers. • We use crowdsourcing with simplified guidelines implemented interactively to annotate a larger-scale corpus of 12134 tokens for event modality and its attributes. 7 Conclusion and Outlook We presented a large-scale corpus annotated for event modality in MSA and EA tweets. We use a simplified annotation procedure that defines each annotation task as a series of questions, implemented interactively. Our scheme covers a wide range of the most common annotation units mentioned in the literature, including modality sense, pola</context>
</contexts>
<marker>Baker, Bloodgood, Diab, Dorr, Filardo, Levin, Piatko, 2010</marker>
<rawString>Kathrin Baker, Michael Bloodgood, Mona Diab, Bonnie Dorr, Nathaniel W. Filardo, Lori Levin and Christine Piatko. 2010. A Modality Lexicon and its Use in Automatic Tagging. In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC&apos;10), pages 1402-1405, May 19-21, 2010, Valetta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathryn Baker</author>
<author>Michael Bloodgood</author>
<author>Bonnie J Dorr</author>
<author>Chris Callison-Burch</author>
<author>Nathaniel W Filardo</author>
<author>Christine Piatko</author>
<author>Lori Levin</author>
<author>Scott Miller</author>
</authors>
<date>2012</date>
<booktitle>Modality and Negation in SIMT. Computational Linguistics.</booktitle>
<volume>38</volume>
<pages>411--438</pages>
<marker>Baker, Bloodgood, Dorr, Callison-Burch, Filardo, Piatko, Levin, Miller, 2012</marker>
<rawString>Kathryn Baker, Michael Bloodgood, Bonnie J. Dorr, Chris Callison-Burch, Nathaniel W. Filardo, Christine Piatko, Lori Levin and Scott Miller. 2012. Modality and Negation in SIMT. Computational Linguistics. volume 38, issue 2, pages 411-438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel R Bowman</author>
<author>Harshit Chopra</author>
</authors>
<title>Automatic Animacy Classification.</title>
<date>2012</date>
<booktitle>In Proceedings of the NAACL HTL 2012 Student Research Workshop,</booktitle>
<pages>7--10</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="1598" citStr="Bowman and Chopra 2012" startWordPosition="216" endWordPosition="219"> and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically t</context>
</contexts>
<marker>Bowman, Chopra, 2012</marker>
<rawString>Samuel R. Bowman and Harshit Chopra. 2012. Automatic Animacy Classification. In Proceedings of the NAACL HTL 2012 Student Research Workshop, pages 7-10, June 3-8, 2012, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristen E Brustad</author>
</authors>
<title>The Syntax of Spoken Arabic: A Comparative Study of Moroccan, Egyptian, Syrian and Kuwaiti Dialects.</title>
<date>2000</date>
<publisher>Georgetown University Press,</publisher>
<location>Washington DC, USA.</location>
<contexts>
<context position="29513" citStr="Brustad (2000)" startWordPosition="4640" endWordPosition="4641"> attain kappa inter-annotator agreement rates of 0.90 and 0.93 for sense and scope annotation, respectively, for only 772 tokens of event modality triggers. Our annotation results, therefore, are comparable to the results in the literature. Furthermore, our annotation scheme and its tasks are orthogonal to most of the aforementioned schemes. However, the key differences between our work and related work are: • We use a standardized taxonomy of event modality - Palmer&apos;s (2001) - that has been proved valid for a variety of languages, including Arabic, according to Mitchell and Al-Hassan (1994), Brustad (2000), and Moshref (2012). • We annotate nested holders unlike some of the aforementioned studies (e.g. Baker et al. 2010, 2012) and use a wider range of negation and intensification markers. • We use crowdsourcing with simplified guidelines implemented interactively to annotate a larger-scale corpus of 12134 tokens for event modality and its attributes. 7 Conclusion and Outlook We presented a large-scale corpus annotated for event modality in MSA and EA tweets. We use a simplified annotation procedure that defines each annotation task as a series of questions, implemented interactively. Our scheme</context>
</contexts>
<marker>Brustad, 2000</marker>
<rawString>Kristen E. Brustad. 2000. The Syntax of Spoken Arabic: A Comparative Study of Moroccan, Egyptian, Syrian and Kuwaiti Dialects. Georgetown University Press, Washington DC, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cohan Sujay Carlos</author>
<author>Madulika Yalamanchi</author>
</authors>
<title>Intention Analysis for Sales, Marketing and Customer Service.</title>
<date>2012</date>
<booktitle>In Processing of COLING 2012: Demonstration Papers,</booktitle>
<pages>33--40</pages>
<location>Mumbai, India.</location>
<contexts>
<context position="1389" citStr="Carlos and Yalamanchi 2012" startWordPosition="184" endWordPosition="187">1 Introduction Event modality, according to Palmer (2001), describes events that are not actualized but are merely potential. It comprises obligation, permission, commitment, ability, and volition. Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be ren</context>
</contexts>
<marker>Carlos, Yalamanchi, 2012</marker>
<rawString>Cohan Sujay Carlos and Madulika Yalamanchi. 2012. Intention Analysis for Sales, Marketing and Customer Service. In Processing of COLING 2012: Demonstration Papers, pages 33-40, December 2012, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baptiste Chardon</author>
<author>Farah Benamara</author>
<author>Yannick Mathieu</author>
<author>Vladimir Popescu</author>
<author>Nicholas Asher</author>
</authors>
<title>Sentiment Composition Using a Parabolic Model.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013),</booktitle>
<pages>47--58</pages>
<location>Potsdam, Germany.</location>
<contexts>
<context position="1431" citStr="Chardon et al. 2013" startWordPosition="190" endWordPosition="193">r (2001), describes events that are not actualized but are merely potential. It comprises obligation, permission, commitment, ability, and volition. Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines</context>
</contexts>
<marker>Chardon, Benamara, Mathieu, Popescu, Asher, 2013</marker>
<rawString>Baptiste Chardon, Farah Benamara, Yannick Mathieu, Vladimir Popescu and Nicholas Asher. 2013. Sentiment Composition Using a Parabolic Model. In Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013), pages 47-58, March 20-22, 2013, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanyan Cui</author>
<author>Ting Chi</author>
</authors>
<title>Annotating Modal Expressions in the Chinese Treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM),</booktitle>
<pages>24--32</pages>
<location>Potsdam, Germany.</location>
<contexts>
<context position="1850" citStr="Cui and Chi 2013" startWordPosition="255" endWordPosition="258">es, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales. In this paper, we present an interactive annotation procedure to annotate event modality and its attributes of sense, polarity, intensification, tense, holders, and scopes in Modern Standard and Egyptian A</context>
<context position="20607" citStr="Cui and Chi 2013" startWordPosition="3251" endWordPosition="3254">sed where there is a pre-defined set of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where the output of the annotation is a text segment. For the segmentation-based tasks, we use an all-ornothing method to measure inter-annotator reliability: for segments to be considered as agreement, they must share both the beginning and end boundaries. We use Krippendorff&apos;s alpha α (Krippendorff 2011) as our inter-annotator reliability measure, following the most recent work on modality annotation for other languages including English (Rubinstein et al. 2013) and Chinese (Cui and Chi 2013). For more details on Krippendorff&apos;s alpha and a, we refer the reader to Artstein and Poesio (2008). 5.2 Results We use the surveygizmo survey services2 to implement our interactive annotation procedure given that their survey structure is one that uses conditional branching and skip logic. We distribute the survey on Twitter and we have three annotators participating. According to the short qualifying quiz given at the beginning of the survey, all three participants are native Egyptian Arabic (EA) speakers who have at least two-year experience with Twitter. They are also university graduates </context>
<context position="28626" citStr="Cui and Chi (2013)" startWordPosition="4500" endWordPosition="4503">012) annotate eleven modality senses in Portuguese, including necessity, capacity, permission, obligation, and volition, among others. They report a macro kappa interannotator rate of 0.85 for sense annotation. Rubinstein et al. (2013) propose a linguistically-motivated annotation scheme for modalities in the MPQA English corpus. They annotate sense, polarity, holders, and scopes, among other annotation units. They work on obligation, ability, and volition among other modality senses. They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope, respectively. Cui and Chi (2013) apply the same scheme of Rubinstein et al. (2013) to the Chinese Penn Treebank and get alpha inter-annotator reliability rates of 0.81 and 0.39 for sense and scope annotation, respectively. Finally, Al-Sabbagh et al. (2013) annotate event modality in MSA and EA tweets. We attain kappa inter-annotator agreement rates of 0.90 and 0.93 for sense and scope annotation, respectively, for only 772 tokens of event modality triggers. Our annotation results, therefore, are comparable to the results in the literature. Furthermore, our annotation scheme and its tasks are orthogonal to most of the aforeme</context>
</contexts>
<marker>Cui, Chi, 2013</marker>
<rawString>Yanyan Cui and Ting Chi. 2013. Annotating Modal Expressions in the Chinese Treebank. In Proceedings of the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM), pages 24-32, March 2013, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iris Hendrickx</author>
<author>Amàlia Mendes</author>
<author>Silvia Mencarelti</author>
</authors>
<title>Modality in Text: A Proposal for Corpus Annotation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC&apos;12),</booktitle>
<pages>1805--1812</pages>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="1818" citStr="Hendrickx et al. 2012" startWordPosition="249" endWordPosition="252"> defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales. In this paper, we present an interactive annotation procedure to annotate event modality and its attributes of sense, polarity, intensification, tense, holders, and scopes i</context>
<context position="28012" citStr="Hendrickx et al. (2012)" startWordPosition="4414" endWordPosition="4417"> scheme such as grammatical mood. They report macro kappa inter-annotator agreement rates of 0.69, 0.70, 0.66 and 0.72 for holders, tense, sense, and polarity, respectively. Baker et al. (2010, 2012) simultaneously annotate modality and modality-based negation for Urdu-English machine translation systems. Among the modality senses they work on are requirement, permission, success, intention, ability, and desires. They report macro kappa interannotator agreement rates of 0.82 for sense annotation and 0.76 for scopes. They, however, do not annotate holders and do not consider nested modalities. Hendrickx et al. (2012) annotate eleven modality senses in Portuguese, including necessity, capacity, permission, obligation, and volition, among others. They report a macro kappa interannotator rate of 0.85 for sense annotation. Rubinstein et al. (2013) propose a linguistically-motivated annotation scheme for modalities in the MPQA English corpus. They annotate sense, polarity, holders, and scopes, among other annotation units. They work on obligation, ability, and volition among other modality senses. They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope, respectively. Cui </context>
</contexts>
<marker>Hendrickx, Mendes, Mencarelti, 2012</marker>
<rawString>Iris Hendrickx, Amàlia Mendes and Silvia Mencarelti. 2012. Modality in Text: A Proposal for Corpus Annotation. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC&apos;12), pages 1805-1812, May 21-27, 2012, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Krippendorff</author>
</authors>
<title>Computing Krippendorff&apos;s Alpha-Reliability. Annenberg</title>
<date>2011</date>
<institution>School of Communication, Departmental Papers: University of Pennsylvania.</institution>
<contexts>
<context position="4192" citStr="Krippendorff 2011" startWordPosition="585" endWordPosition="586">t our corpus is harvested from the Arabic Egyptian Twitter entails that the corpus is diglossic for Modern Standard Arabic (MSA), the This work is licensed under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http:// creativecommons.org/licenses/by/4.0/ 139 LAW VIII - The 8th Linguistic Annotation Workshop, pages 139–148, Dublin, Ireland, August 23-24 2014. formal Arabic variety, and Egyptian Arabic (EA), the native Arabic dialect of Egypt. We evaluate the annotation results with Krippendorff&apos;s alpha (Krippendorff 2011). Results show high inter-annotator reliability rates, indicating that our annotation scheme and procedure are effective. The contribution of this paper, therefore, is twofold: first, we create a novel annotated resource for Arabic NLP that is larger than existing corpora even for languages other than Arabic; and second, we present an efficient and easy-to-administer annotation procedure with interactive crowdsourcing potentials. The rest of this paper is organized as follows: Section 2 outlines the annotation scheme, guidelines and the interactive procedure; Section 3 gives examples for the f</context>
<context position="20415" citStr="Krippendorff 2011" startWordPosition="3225" endWordPosition="3226">tokens of event modality triggers that map to 315 unique types. 143 5 Annotation Results 5.1 Evaluation Methodology and Metrics Our annotation tasks are of two types: (1) Tasks 1-4 are label-based where there is a pre-defined set of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where the output of the annotation is a text segment. For the segmentation-based tasks, we use an all-ornothing method to measure inter-annotator reliability: for segments to be considered as agreement, they must share both the beginning and end boundaries. We use Krippendorff&apos;s alpha α (Krippendorff 2011) as our inter-annotator reliability measure, following the most recent work on modality annotation for other languages including English (Rubinstein et al. 2013) and Chinese (Cui and Chi 2013). For more details on Krippendorff&apos;s alpha and a, we refer the reader to Artstein and Poesio (2008). 5.2 Results We use the surveygizmo survey services2 to implement our interactive annotation procedure given that their survey structure is one that uses conditional branching and skip logic. We distribute the survey on Twitter and we have three annotators participating. According to the short qualifying qu</context>
</contexts>
<marker>Krippendorff, 2011</marker>
<rawString>Klaus Krippendorff. 2011. Computing Krippendorff&apos;s Alpha-Reliability. Annenberg School of Communication, Departmental Papers: University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Lampert</author>
<author>Robert Dale</author>
<author>Cecile Paris</author>
</authors>
<title>Detecting Emails Containing Requests for Action.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: the 2010 Annual Conference of the North American Chapter of the ACL,</booktitle>
<pages>984--992</pages>
<location>Los Angles, California.</location>
<contexts>
<context position="1496" citStr="Lampert et al. 2010" startWordPosition="200" endWordPosition="203"> potential. It comprises obligation, permission, commitment, ability, and volition. Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated</context>
</contexts>
<marker>Lampert, Dale, Paris, 2010</marker>
<rawString>Andrew Lampert, Robert Dale and Cecile Paris. 2010. Detecting Emails Containing Requests for Action. In Proceedings of Human Language Technologies: the 2010 Annual Conference of the North American Chapter of the ACL, pages 984-992, June 2010, Los Angles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying-Shu Liao</author>
<author>Ting-Gen Liao</author>
</authors>
<title>Modal Verbs for the Advice Move in Advice Columns.</title>
<date>2009</date>
<booktitle>In Proceedings of the 23rd Pacific Asia Conference on language, Information and Computation,</booktitle>
<pages>307--316</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="1573" citStr="Liao and Liao 2009" startWordPosition="212" endWordPosition="215">ion. Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; henc</context>
</contexts>
<marker>Liao, Liao, 2009</marker>
<rawString>Ying-Shu Liao and Ting-Gen Liao. 2009. Modal Verbs for the Advice Move in Advice Columns. In Proceedings of the 23rd Pacific Asia Conference on language, Information and Computation, pages 307-316, December 3-5, 2009, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suguru Matsuyoshi</author>
<author>Megumi Eguchi</author>
<author>Chitose Sao</author>
<author>Koji Murakami</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating Event Mentions in Text with Modality, Focus and Source Information.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC&apos;10,</booktitle>
<pages>1456--1463</pages>
<location>Valletta,</location>
<contexts>
<context position="1782" citStr="Matsuyoshi et al. 2010" startWordPosition="244" endWordPosition="247"> to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales. In this paper, we present an interactive annotation procedure to annotate event modality and its attributes of sense, polarity, intensifi</context>
<context position="27154" citStr="Matsuyoshi et al. (2010)" startWordPosition="4287" endWordPosition="4290">y 1729 920 1047 682 348 308 1073 1175 554 Commitment 1048 495 599 449 221 220 607 639 409 Obligation 1786 848 1059 727 369 399 1018 1018 768 Permission 1699 980 1054 645 286 428 985 1053 646 Volition 1622 1007 974 648 341 292 989 1038 584 Totals 7884 4250 4733 3151 1565 1647 4672 4923 2961 Table 2: Token statistics for each annotation task per event modality sense where MD is modal, NMD is non-modal, AFF is affirmative, NEG is negative, AMP is amplified, MTG is mitigated, ASIS is as is, PRS is present, and PST is past 145 6 Related Work Event modality is the focus of many annotation projects. Matsuyoshi et al. (2010) annotate a corpus of English and Japanese blog posts for a number of modality senses including volition, wishes, and permission. They annotate sense, tense, polarity, holders as well as other attributes that we have not covered in our scheme such as grammatical mood. They report macro kappa inter-annotator agreement rates of 0.69, 0.70, 0.66 and 0.72 for holders, tense, sense, and polarity, respectively. Baker et al. (2010, 2012) simultaneously annotate modality and modality-based negation for Urdu-English machine translation systems. Among the modality senses they work on are requirement, pe</context>
</contexts>
<marker>Matsuyoshi, Eguchi, Sao, Murakami, Inui, Matsumoto, 2010</marker>
<rawString>Suguru Matsuyoshi, Megumi Eguchi, Chitose Sao, Koji Murakami, Kentaro Inui and Yuji Matsumoto. 2010. Annotating Event Mentions in Text with Modality, Focus and Source Information. In Proceedings of LREC&apos;10, pages 1456-1463, May 19-21, 2010, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T F Mitchell</author>
<author>S A Al-Hassan</author>
</authors>
<title>Modality, Mood and Aspect in Spoken Arabic with Special Reference to Egypt and the Levant. London and NY:</title>
<date>1994</date>
<publisher>Cambridge University Press,</publisher>
<institution>Kegan Paul International. PhD Thesis. University of Illinois</institution>
<location>Cambridge, UK.</location>
<contexts>
<context position="29497" citStr="Mitchell and Al-Hassan (1994)" startWordPosition="4636" endWordPosition="4639">dality in MSA and EA tweets. We attain kappa inter-annotator agreement rates of 0.90 and 0.93 for sense and scope annotation, respectively, for only 772 tokens of event modality triggers. Our annotation results, therefore, are comparable to the results in the literature. Furthermore, our annotation scheme and its tasks are orthogonal to most of the aforementioned schemes. However, the key differences between our work and related work are: • We use a standardized taxonomy of event modality - Palmer&apos;s (2001) - that has been proved valid for a variety of languages, including Arabic, according to Mitchell and Al-Hassan (1994), Brustad (2000), and Moshref (2012). • We annotate nested holders unlike some of the aforementioned studies (e.g. Baker et al. 2010, 2012) and use a wider range of negation and intensification markers. • We use crowdsourcing with simplified guidelines implemented interactively to annotate a larger-scale corpus of 12134 tokens for event modality and its attributes. 7 Conclusion and Outlook We presented a large-scale corpus annotated for event modality in MSA and EA tweets. We use a simplified annotation procedure that defines each annotation task as a series of questions, implemented interacti</context>
</contexts>
<marker>Mitchell, Al-Hassan, 1994</marker>
<rawString>T. F. Mitchell and S. A. Al-Hassan. 1994. Modality, Mood and Aspect in Spoken Arabic with Special Reference to Egypt and the Levant. London and NY: Kegan Paul International. PhD Thesis. University of Illinois at Urbana-Champaign. Frank R. Palmer. 2001. Mood and Modality. 2nd Edition. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ramanand</author>
<author>Krishna Bhavsar</author>
<author>Niranjan Pedanekar</author>
</authors>
<title>Wishful Thinking: Finding Suggestions and &amp;quot;Buy&amp;quot; Wishes for Product Reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to the Analysis and Generation of Emotion in Text,</booktitle>
<pages>54--61</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="1360" citStr="Ramanand et al. 2010" startWordPosition="180" endWordPosition="183">s semi-automatically. 1 Introduction Event modality, according to Palmer (2001), describes events that are not actualized but are merely potential. It comprises obligation, permission, commitment, ability, and volition. Both obligation and permission emanate from an external authority such as the law; whereas commitments are the obligations placed by speakers on themselves as in promises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality</context>
</contexts>
<marker>Ramanand, Bhavsar, Pedanekar, 2010</marker>
<rawString>J. Ramanand, Krishna Bhavsar and Niranjan Pedanekar. 2010. Wishful Thinking: Finding Suggestions and &amp;quot;Buy&amp;quot; Wishes for Product Reviews. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to the Analysis and Generation of Emotion in Text, pages 54-61, June 2010, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aynat Rubinstein</author>
<author>Hillary Harner</author>
<author>Elizabeth Krawczyk</author>
<author>Daniel Simoson</author>
<author>Graham Katz</author>
<author>Paul Portner</author>
</authors>
<title>Toward Fine-Grained Annotation of Modality in Text.</title>
<date>2013</date>
<booktitle>In Proceedings of the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM),</booktitle>
<pages>38--46</pages>
<location>Potsdam, Germany.</location>
<contexts>
<context position="1747" citStr="Rubinstein et al. 2013" startWordPosition="239" endWordPosition="242">omises. Ability is the (in)capacity to do something. Volition is broadly defined as intensions, desires, wishes, and preferences. Event modality is used for several NLP tasks, including sales and marketing analysis (Ramanand et al. 2010, Carlos and Yalamanchi 2012), sentiment analysis (Chardon et al. 2013), the automatic detection of request emails (Lampert et al. 2010), and the classification of animacy and writers&apos; emotions (Liao and Liao 2009, Bowman and Chopra 2012). To-date, there are no large-scale Arabic corpora annotated for event modality compared to English (Baker et al. 2010, 2012; Rubinstein et al. 2013), Japanese (Matsuyoshi et al. 2010), Portuguese (Hendrickx et al. 2012), and Chinese (Cui and Chi 2013). One obstacle for the creation of modality-annotated corpora is the lack of consensus definitions of modality and its attributes to be rendered into annotation tasks and guidelines. Furthermore, most modality annotation schemes use sophisticated theoretical guidelines that need annotators with linguistic background; hence, annotation typically takes place in in-lab settings at small scales. In this paper, we present an interactive annotation procedure to annotate event modality and its attri</context>
<context position="20576" citStr="Rubinstein et al. 2013" startWordPosition="3245" endWordPosition="3248">two types: (1) Tasks 1-4 are label-based where there is a pre-defined set of labels from which annotators choose; and (2) Tasks 5-6 are segmentation-based where the output of the annotation is a text segment. For the segmentation-based tasks, we use an all-ornothing method to measure inter-annotator reliability: for segments to be considered as agreement, they must share both the beginning and end boundaries. We use Krippendorff&apos;s alpha α (Krippendorff 2011) as our inter-annotator reliability measure, following the most recent work on modality annotation for other languages including English (Rubinstein et al. 2013) and Chinese (Cui and Chi 2013). For more details on Krippendorff&apos;s alpha and a, we refer the reader to Artstein and Poesio (2008). 5.2 Results We use the surveygizmo survey services2 to implement our interactive annotation procedure given that their survey structure is one that uses conditional branching and skip logic. We distribute the survey on Twitter and we have three annotators participating. According to the short qualifying quiz given at the beginning of the survey, all three participants are native Egyptian Arabic (EA) speakers who have at least two-year experience with Twitter. They</context>
<context position="28243" citStr="Rubinstein et al. (2013)" startWordPosition="4446" endWordPosition="4449">ty and modality-based negation for Urdu-English machine translation systems. Among the modality senses they work on are requirement, permission, success, intention, ability, and desires. They report macro kappa interannotator agreement rates of 0.82 for sense annotation and 0.76 for scopes. They, however, do not annotate holders and do not consider nested modalities. Hendrickx et al. (2012) annotate eleven modality senses in Portuguese, including necessity, capacity, permission, obligation, and volition, among others. They report a macro kappa interannotator rate of 0.85 for sense annotation. Rubinstein et al. (2013) propose a linguistically-motivated annotation scheme for modalities in the MPQA English corpus. They annotate sense, polarity, holders, and scopes, among other annotation units. They work on obligation, ability, and volition among other modality senses. They attain macro alpha inter-annotator reliability rates of 0.89 and 0.65 for sense and scope, respectively. Cui and Chi (2013) apply the same scheme of Rubinstein et al. (2013) to the Chinese Penn Treebank and get alpha inter-annotator reliability rates of 0.81 and 0.39 for sense and scope annotation, respectively. Finally, Al-Sabbagh et al.</context>
</contexts>
<marker>Rubinstein, Harner, Krawczyk, Simoson, Katz, Portner, 2013</marker>
<rawString>Aynat Rubinstein, Hillary Harner, Elizabeth Krawczyk, Daniel Simoson, Graham Katz and Paul Portner. 2013. Toward Fine-Grained Annotation of Modality in Text. In Proceedings of the IWC 2013Workshop on Annotation of Modal Meaning in Natural Language (WAMM), pages 38-46, March 2013, Potsdam, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Saurí</author>
<author>James Pustejovsky</author>
</authors>
<title>FactBank: A Corpus Annotated with Event Factuality. Language Resources and Evaluation,</title>
<date>2009</date>
<pages>43--227</pages>
<contexts>
<context position="11698" citStr="Saurí and Pustejovsky (2009)" startWordPosition="1777" endWordPosition="1780">tter user. 3. [ لو�ا ��طا�����د ��إ ���� ا������ �������ا ] مز� tAzm [AlmSryyn ytElmwA yEny &lt;yh dymwqrATyp Al&gt;wl] [Egyptians have to learn what democracy is first] The holder is not always the Twitter user, however. In example 4, the Twitter user quotes Kamal Alganzoury - a former Egyptian Prime Minster - stating that he does not want to 141 continue as the Prime Minister. Therefore, the holder of the negated volition trigger *+&amp;ر ي-�, ,ul lys ldy rgbp (not have a will) is Alganzoury not the Twitter user. This is an example of the nested holder notion first proposed by Wiebe et al. (2005) and Saurí and Pustejovsky (2009). 4. [را����.ا ] �� ���ر يn1 -4 :يرو*�+1ا لL-5 رy,nll #SCAF #Tahrir #Egypt Aldktwr kmAl Aljnzwry: lys ldy rgbp fy [AlAstmrAr] #SCAF #Tahrir #Egypt Dr. Kamal Alganzoury: I do not wish to [continue] #SCAF #Tahrir #Egypt Another example of nested holders is example 5. We know that the regime is incapable of maintaining security and protecting the people only because the Twitter user says so. Put differently, the best way to understand this tweet is that according to what the Twitter user holds as a true proposition, the regime is unable to maintain security and protect the people. 5. [&apos;��طا_.J &amp;quot;;</context>
</contexts>
<marker>Saurí, Pustejovsky, 2009</marker>
<rawString>Roser Saurí and James Pustejovsky. 2009. FactBank: A Corpus Annotated with Event Factuality. Language Resources and Evaluation, 43:227-268</rawString>
</citation>
<citation valid="true">
<authors>
<author>György Szarvas</author>
<author>Veronika Vincze</author>
<author>Richárd Farkas</author>
<author>János Csirik</author>
</authors>
<title>The BioScope Corpus: Annotation for Negation, Uncertainty and their Scope in Biomedical Texts.</title>
<date>2008</date>
<booktitle>In Proceedings of BioNLP 2008: Current Trends in Biomedical Natural Language Processing,</booktitle>
<pages>38--45</pages>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="13792" citStr="Szarvas et al. (2008)" startWordPosition="2131" endWordPosition="2134">E AlEAlm AlxArjy] Obama: the Iranians no longer want to [confront the other countries]. During the interactive procedure, annotators are first asked whether the holder is the same as the Twitter user. If not, more questions are displayed to determine (1) who the real holder is; (2) whether the tweet is a(n) (in)direct quote; or it conveys the Twitter user&apos;s assumptions. When the holder is not the Twitter user, annotators are asked to mark the boundaries of the linguistic unit that corresponds to the holder in the tweet&apos;s text. Annotators are instructed to use the maximal length principle from Szarvas et al. (2008) so that they mark the largest possible meaningful linguistic unit. Thus, in example 4 the holder is يرو����ا لL-. ر/�.��ا Aldktwr kmAl Aljnzwry (Dr. Kamal Alganzoury) not only Kamal Alganzoury. 2.6 Task 6: Scopes Scopes are the events modified by the trigger, syntactically realized as clauses, verb phrases, deverbal nouns or to-infinitives, according to Al-Sabbagh et al. (2013). We use the same maximal length principle from Task 5 so that the marked scope segment corresponds to the largest meaningful linguistic unit that describes the event. Typically, scope segments are delimited by: (1) pun</context>
</contexts>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>György Szarvas, Veronika Vincze, Richárd Farkas and János Csirik. 2008. The BioScope Corpus: Annotation for Negation, Uncertainty and their Scope in Biomedical Texts. In Proceedings of BioNLP 2008: Current Trends in Biomedical Natural Language Processing, pages 38-45, June 2008, Columbus, Ohio, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<date>2005</date>
<booktitle>Annotating Expressions of Opinions and Emotions in Language. Language Resources and Evaluation,</booktitle>
<volume>39</volume>
<pages>1663--210</pages>
<contexts>
<context position="11665" citStr="Wiebe et al. (2005)" startWordPosition="1772" endWordPosition="1775"> of democracy is the Twitter user. 3. [ لو�ا ��طا�����د ��إ ���� ا������ �������ا ] مز� tAzm [AlmSryyn ytElmwA yEny &lt;yh dymwqrATyp Al&gt;wl] [Egyptians have to learn what democracy is first] The holder is not always the Twitter user, however. In example 4, the Twitter user quotes Kamal Alganzoury - a former Egyptian Prime Minster - stating that he does not want to 141 continue as the Prime Minister. Therefore, the holder of the negated volition trigger *+&amp;ر ي-�, ,ul lys ldy rgbp (not have a will) is Alganzoury not the Twitter user. This is an example of the nested holder notion first proposed by Wiebe et al. (2005) and Saurí and Pustejovsky (2009). 4. [را����.ا ] �� ���ر يn1 -4 :يرو*�+1ا لL-5 رy,nll #SCAF #Tahrir #Egypt Aldktwr kmAl Aljnzwry: lys ldy rgbp fy [AlAstmrAr] #SCAF #Tahrir #Egypt Dr. Kamal Alganzoury: I do not wish to [continue] #SCAF #Tahrir #Egypt Another example of nested holders is example 5. We know that the regime is incapable of maintaining security and protecting the people only because the Twitter user says so. Put differently, the best way to understand this tweet is that according to what the Twitter user holds as a true proposition, the regime is unable to maintain security and pr</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson and Claire Cardie. 2005. Annotating Expressions of Opinions and Emotions in Language. Language Resources and Evaluation, volume 39, issue 203, pages 1663-210.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>