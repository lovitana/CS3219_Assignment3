<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002065">
<title confidence="0.72512">
Towards Model Driven Architectures for Human Language Technologies
</title>
<note confidence="0.959916333333333">
Alessandro Di Bari Kateryna Tymoshenko Guido Vetere
IBM Center for Trento RISE IBM Center for
Advanced Studies of Trento Povo di Trento Advanced Studies of Trento
Povo di Trento Via Sommarive 18 Povo di Trento
Piazza Manci 12 k.tymoshenko@trentorise.eu Piazza Manci 12
alessandro dibari@it.ibm.com guido vetere@it.ibm.com
</note>
<sectionHeader confidence="0.978064" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999874818181818">
Developing multi-purpose Human Language Technologies (HLT) pipelines and integrating them
into the large scale software environments is a complex software engineering task. One needs
to orchestrate a variety of new and legacy Natural Language Processing components, language
models, linguistic and encyclopedic knowledge resources. This requires working with a variety
of different APIs, data formats and knowledge models. In this paper, we propose to employ
the Model Driven Development (MDD) approach to software engineering, which provides rich
structural and behavioral modeling capabilities and solid software support for model transforma-
tion and code generation. These benefits help to increase development productivity and quality
of HLT assets. We show how MDD techniques and tools facilitate working with different data
formats, adapting to new languages and domains, managing UIMA type systems, and accessing
the external knowledge bases.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999894">
Modern architectures of knowledge-based computing (cognitive computing) require HLT components
to interact with increasingly many sources and services, such as Open Data and APIs, which may not
be known before the system is designed. IBM’s Watson1, for instance, works on textual documents to
provide question answering and other knowledge-based services by integrating lexical resources, ontolo-
gies, encyclopaedic data, and potentially any available information source. Also, they combine a variety
of analytical procedures, which may use search, reasoning services, database queries, to provide answers
based on many kinds of evidence (IJRD, 2012). Development platforms such as UIMA2 or GATE3 facil-
itate the development of HLT components to a great extent, by providing tools for annotating texts, based
on vocabularies and ontologies, training and evaluating pipeline components, etc. However, in general,
they focus on working with specific analytical structures (annotations), rather than integrating distributed
services and heterogeneous resources. Such integration requires great flexibility in the way linguistic and
conceptual data are encoded and exchanged, since each independent service or resource may adopt dif-
ferent representations for notions whose standardization is still in progress. Therefore, developing HLT
systems and working with them in such environments requires modeling, representing, mapping, manip-
ulating, and exchanging linguistic and conceptual data in a robust and flexible way. Supporting these
tasks with mature methodologies, representational languages, and development environments appears to
be of paramount importance.
Since the early 90s, Computer Sciences have envisioned methodologies, languages, practices, and
tools for driving the development of software architectures by models (Model Driven Architecture,
MDA)4. The MDA approach starts from providing formal descriptions (models) of requirements, inter-
actions, data structures, protocols and many other aspects of the desired system. Then, models are turned
</bodyText>
<footnote confidence="0.909505">
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings
footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/
1http://www.ibm.com/innovation/us/watson/
2http://uima.apache.org/
3https://gate.ac.uk/
4http://www.omg.org/mda/ 23
</footnote>
<note confidence="0.986101">
Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 23–33,
Dublin, Ireland, August 23rd 2014.
</note>
<bodyText confidence="0.999960230769231">
into technical resources (e.g. schemes and software modules) by means of programmable transforma-
tion procedures. Model-to-model transformations, both at schema and instance level, are also supported,
based on model correspondence rules (mappings) that can be programmed in a declarative way.
As part of the development of UIMA-based NLP components, easily pluggable in services ecosystems,
we are working on an open, flexible and interoperable pipeline, based on MDA. We want our platform
to be language agnostic and domain independent, to facilitate its use across projects and geographies.
To achieve this, we adopted the Eclipse Modeling Framework5 as modeling and developing platform,
and we generate UIMA resources (Type System) as a Platform Specific Model, by means of a specific
transformation. We started by designing models of all the required components, and analyzed the way to
improve usability and facilitate interoperability by providing appropriate abstraction and layering.
In the present paper we provide the motivation of our architectural choices, we illustrate the basic
features, and discuss relevant issues. Also, we provide some example of how MDA facilitates the design
and the implementation of open and easily adaptable HLT functionalities.
</bodyText>
<sectionHeader confidence="0.824313" genericHeader="method">
2 Model-driven Development and NLP
</sectionHeader>
<subsectionHeader confidence="0.872504">
2.1 Model-driven Development
</subsectionHeader>
<bodyText confidence="0.999658636363636">
Generally speaking, we talk about a “modeling” language when it is possible to visually represent (or
model) objects under construction (such as services and objects) from both a structural and behav-
ioral point of view. The most popular (software) modeling language is the Unified Modeling Language
(UML)(Rumbaugh et al., 2005). One of the strengths of such language is that it allows clear and trans-
parent communication among different stakeholders and roles such as developers, architects, analyst,
project managers and testers.
Model Driven Development (MDD) is a software development approach aimed at improving quality
and productivity by raising the level of abstraction of services and related objects under development.
Given an application domain, we usually have a “business” model that allows for fast and highly expres-
sive representation of specific domain objects. Based on business models, the MDD tooling provides
facilities to generate a variety of platform specific “executable models”6
</bodyText>
<subsectionHeader confidence="0.998377">
2.2 Model-driven Architecture
</subsectionHeader>
<bodyText confidence="0.999403428571429">
Model Driven Architecture (MDA)(Miller and Mukerji, 2003) is a development approach, strictly based
on formal specifications of information structures and behaviors, and their semantics. MDA is promoted
by the Object Management Group (OMG)7 based on several modeling standards such as: Unified Mod-
eling Language (UML)8, Meta-Object Facility (MOF9), XML Metadata Interchange (XMI) and others.
The aim is to provide complex software environments with a higher level of abstraction, so that the
application (or service) can be completely designed independently from the underlying technological
platform. To this end, MDA defines three macro modeling layers:
</bodyText>
<listItem confidence="0.971876833333333">
• Computation Independent Model (CIM) abstract from any possible (software) automation; usu-
ally business processes are represented at this layer
• Platform Independent Model (PIM) represents any software automation (that supports the CIM)
but this representation is really independent from any technological constraint such as the running
platform or related middleware, or any third party software. Usually, the skeleton or structure of
such a model is automatically generated from the CIM but it is expected to be further expanded for
</listItem>
<footnote confidence="0.999716333333333">
5http://www.eclipse.org/modeling/emf/
6For a typical MDD approach, there are two different possible implementation strategies: the first one is to customize
generic modeling languages (such as UML) by providing specific profiles (representing the business domain) for the language
(UML is very generic and it offers several extensibility mechanisms such as profiles); the second one is a stronger approach
that leads to what we call a DSL (Domain Specific Language), a fully specified, vertical language for a particular domain. Such
a language is usually built in order to allow business experts to directly work on it, without the need of technological skills.
7http://omg.org/
8http://www.uml.org/
9http://www.omg.org/mof/ 24
</footnote>
<listItem confidence="0.8878326">
a fully specification. PIM can be expressed in UML (Rumbaugh et al., 2005) or EMF10 but also in
any peculiar DSL (domain specific language).
• Platform Specific Model (PSM) can be completely generated from the PIM. Among other things,
this requires PIM to be able to represent every aspect of the solution under development: both
structural and behavioral parts have to be fully specified at this level.
</listItem>
<subsectionHeader confidence="0.99523">
2.3 Eclipse Modeling Framework (EMF)
</subsectionHeader>
<bodyText confidence="0.999974">
We chose to adopt EMF as the underlying modeling framework and tooling for our model-driven ap-
proach. EMF is an Eclipse11-based modeling framework and code generation facility. Ecore is the core
meta-model for EMF. Ecore represents the reference implementation of OMG’s EMOF (Essential Meta-
Object Facility). EMF is at the heart of several important tools and applications and it is often used
to represent meta-models and their instances (models) management. Just as an example, UML open
source implementation defines its meta-model in terms of EMF-Ecore. Applications or tools that use
Ecore to represent their meta model can leverage the EMF tooling to accomplish several goals such as
the code generation for model management, diagramming and editing of models, transformations visual
development and so on.
</bodyText>
<subsectionHeader confidence="0.957606">
2.4 Model-driven NLP
</subsectionHeader>
<bodyText confidence="0.99249125">
We considered the main features of the Model Driven approach as a powerful way to handle the com-
plexity of modern HLT use cases (Di Bari et al., 2013). In adopting this approach, we chose UIMA12 as
a standardized and well supported tool to deploy our Platform Specific models.
With respect to the basic features of the UIMA platform, we wanted to enhance:
</bodyText>
<listItem confidence="0.999635666666667">
• The representation, visualization and management of complex linguistic and conceptual models
• The use of many kinds of data specifications
• The interaction with many kinds of platforms and services
</listItem>
<bodyText confidence="0.999971">
Therefore, we decided to design a set of models in EMF, considering this as our PIM layer. From these
models, we can generate PSM components to support a variety of tasks, including:
</bodyText>
<listItem confidence="0.99997825">
• A UIMA Type System for implementing NLP pipelines
• A set of data format transformations for working with linguistic corpora
• A set of basic interfaces to access linguistic and knowledge services
• A Business Object Model (BOM) to work with rule engines (business rules management systems)
</listItem>
<sectionHeader confidence="0.821982" genericHeader="method">
3 Modeling NLP with EMF and UIMA
</sectionHeader>
<subsectionHeader confidence="0.999973">
3.1 Working with data formats
</subsectionHeader>
<bodyText confidence="0.9999902">
In order to train our statistical parser based on OpenNLP13 and UIMA, we had to adapt different corpora
formats, (such as PENN14 and CONLL15), because OpenNLP requests them for different analysis classes
(such as named entity, part-of-speech, chunking, etc.). In fact, we had to transform available corpora
from standard formats to OpenNLP specific ones. We represented standard formats with EMF (an Ecore
model for each one) and we created specific transformations using Java Emitter Templates (JET)16, a
</bodyText>
<footnote confidence="0.999773428571429">
10http://www.eclipse.org/modeling/emf/
11http://eclipse.org/
12http://uima.apache.org/
13http://opennlp.apache.org/
14http://www.cis.upenn.edu/˜treebank/
15http://ilk.uvt.nl/conll/#dataformat
16http://www.eclipse.org/modeling/m2t/?project=jet
</footnote>
<page confidence="0.996374">
25
</page>
<bodyText confidence="0.996121">
framework for fast code generation based on EMF. This solution gives us a lot of flexibility: if the parser
or corpora formats change, we just have to adapt EMF models and/or JET templates consistently. For a
better understanding, we show here an example of the JET template used for transforming from CONLL
to OpenNLP POSTag format:
</bodyText>
<figure confidence="0.935578833333333">
&lt;c:setVariable select=&amp;quot;/contents&amp;quot; var=&amp;quot;root&amp;quot;/&gt;
&lt;c:iterate select=&amp;quot;$root/sentence&amp;quot; var=&amp;quot;sentence&amp;quot;&gt;
&lt;c:iterate select=&amp;quot;$sentence/token&amp;quot; var=&amp;quot;token&amp;quot;&gt;
&lt;c:get select=&amp;quot;$token/@FORM&amp;quot;/&gt;_&lt;c:get select=&amp;quot;$token/@CPOSTAG&amp;quot;/&gt;
&lt;/c:iterate&gt;
&lt;/c:iterate&gt;
</figure>
<bodyText confidence="0.958512833333333">
Having the simple CONLL Ecore model (in Figure 1) available, this template is the only artifact realizing
the needed transformation. This template simply iterates over all sentences of a document (root),
then over all tokens of a sentence and print out the form and its postag in the requested format.
Other format conversions are done with the same technique. Notice that this tool allows to write (even
complex) transformation without requiring programming skills, thus ensuring a greater maintainability
and lowering the overall cost of the project.
</bodyText>
<figureCaption confidence="0.9999945">
Figure 1: A simple EMF model representing CONLL format
Figure 2: A sentence represented in PENN format (EMF editor on the left)
</figureCaption>
<bodyText confidence="0.9996648">
Further, as we can notice from the Figure 2, EMF provides very powerful MDD capabilities also from
the modeling instantiation and editing point of view. Notice that these are two view of the very same
resource (a PENN file). This is done by “teaching” the EMF framework how to parse the underlying per-
sisted data, by providing an implementation (that can be done manually or using some parser generation
tool in its turn) through a specific EMF extension26point. From that point on, the framework will always
be able to open and manage PENN resources as instances (with all semantic constraints and validation
available) of the PENN Ecore model. Furthermore, the editor and all the specific model management
tooling are automatically generated by the EMF platform. This way, all instance management (and edit-
ing) tasks are transferred to the EMF framework, which reduces costs and helps developers focusing on
NLP tasks.
</bodyText>
<subsectionHeader confidence="0.999379">
3.2 Managing the UIMA Type System
</subsectionHeader>
<bodyText confidence="0.999603857142857">
In order to manage a (complex enough) UIMA Type System, we fully leveraged the EMF/UIMA in-
teroperability provided by the UIMA framework. UIMA already provides simple transformations from
EMF to a UIMA type system and viceversa; furthermore, UIMA provides the XMI serialization so that
an instance of a type system can be read as an instance of the corresponding EMF model. However,
we had to modify the transformation from EMF to UIMA (type system) in order to reach our “model
driven” goals and also to handle several dependent, but separated EMF modules. Specifically, our model
is organized around the following modules (packages):
</bodyText>
<listItem confidence="0.999927555555556">
• Text. A model of linguistic occurrences in their context, which are given to the parser (token,
sentences, named entities, parse) and get annotated by the underlying document analysis framework
(e.g. UIMA).
• Linguistics A model that abstracts the linguistic apparatus, including categories, morphological and
syntactic features, and relationships. This is the key for the multilinguality we walk through in the
next section. We can see a fragment of this model in Figure 3
• Ontology An abstract representation of any entity and concept, along with a uniform interface to a
variety of existing knowledge bases
• Mapping A model that allows bridging any tag-set, also explained in next section.
</listItem>
<figureCaption confidence="0.966338">
Figure 3: A fragment of the Linguistic model
</figureCaption>
<subsectionHeader confidence="0.996547">
3.3 Adapting to new languages and domains
</subsectionHeader>
<bodyText confidence="0.736329333333333">
Given this basis, we can now illustrate how we are able to incorporate new linguistic resources (such as
vocabularies, ontologies, training corpora with different formats, tag-sets, etc) obtaining UIMA-based
pipeline components. Given an (untrained) statistical library for parsing (such as OpenNLP or others)
and a new natural language to represent, we do the following:
1. Analyze the format requested for the training corpora by the NLP parsing library versus the available
training data for the new language. Most likely the training data will be in some standard format
(e.g. CONLL, PENN, IOB) that is already represented by a suitable Ecore (EMF) model. If not yet
present, we have to write a transformation (usually a simple JET template) from the standard to the
specific one requested by the parser. 27
</bodyText>
<listItem confidence="0.998050444444444">
2. Train the parser for the specific language and tag-set.
3. Given the linguistic knowledge for the new language, and the task at hand, we adopt/modify/extend
a suitable Linguistics model. If needed, we generate the UIMA Type System portion corre-
sponding to the requested features.17
4. In case of a new business domain also, we adopt/modify/extend the ontology. If needed, we wrap
business knowledge bases where the ontology is instantiated.18
5. Given the tag-set in use, we represent the mapping with the linguistic model, by instantiating a
suitable Mapping model. At run-time, the (UIMA-based) parser asks (the mapping manager) to
get a Linguistic Category (see Figure 4) of a given tag (the key feature in the Mapping model).
</listItem>
<bodyText confidence="0.9994956">
Given the workflow above, we can figure out how the Linguistics and Mapping model are play-
ing a key role for achieving a multi-language solution. Just as an example, for the Italian language, the
Linguistics model defines 55 Word Classes (part of speech), 6 morpho-syntactic attributes com-
posed by 22 morpho-syntactic features and 27 syntactic dependencies. The mapping model for the
EVALITA19tagset, contains 115 mapping elements.
</bodyText>
<figureCaption confidence="0.999211">
Figure 4: A fragment of the mapping between tag-set and the Linguistic model
</figureCaption>
<bodyText confidence="0.9997725">
We can now prove how the specific language knowledge has been encapsulated in the suitable model so
that for example, the code that manages the parser results and creates UIMA annotations does not change
for a new language. Correspondingly, no programming skills are needed to represent this linguistic
knowledge.
</bodyText>
<subsectionHeader confidence="0.79378">
3.4 Benefits for NLP development
</subsectionHeader>
<bodyText confidence="0.995289">
To show the benefits of our approach, we summarize here the following remarks:
</bodyText>
<listItem confidence="0.9077755">
• Whereas we consider UIMA the reference framework for document management and annotation,
we also leveraged the features of a mature and stable modeling framework such as EMF. For in-
</listItem>
<bodyText confidence="0.8284045">
stance, we could exploit diagramming, model and instance management and code generation. In
sum, we saved significant development time by means of higher level of abstraction that allowed us
to easily create transformations, create mapping models, smoothly use different format for the same
data and so on.
</bodyText>
<listItem confidence="0.7639845">
• Having an additional level of abstraction can lead in thinking there is an additional cost; however, as
stated above, this is not the case for transforming from EMF to UIMA. The only, real additional cost
is represented by the effort of developing transformations. Nevertheless, this is quickly absorbed as
soon as the transformation is re-used. In our case, just for data conversions, we re-used the same
</listItem>
<footnote confidence="0.990079666666667">
17Steps 2, 3, 4 are done through our Eclipse-based tooling.
18The benefit of abstracting semantic information from the Type System has been illustrated in (Verspoor et al., 2009)
19http://www.evalita.it/ 28
</footnote>
<bodyText confidence="0.995542">
EMF models (and their underlying data parsing capabilities we implemented) several times. Each
time we wanted to change a parser library, or new corpora were available, we reused the same EMF
models and techniques.
• The abstraction introduced by the Linguistic model, allowed us to create a language-
independent parsing software layer. Furthermore, the same model was leveraged in order to allow
interoperability between different parsers that were using different tagsets.
</bodyText>
<sectionHeader confidence="0.914202" genericHeader="method">
4 Using an External Knowledge Base
</sectionHeader>
<bodyText confidence="0.999972891891892">
State-of-the-art NLP algorithms frequently employ semantic knowledge about entities or concepts, men-
tioned in the text being processed. This kind of knowledge is typically extracted from the external
lexicons and knowledge bases (KB)20, e.g. WordNet (Fellbaum, 1998) or Wikipedia21. Therefore, in
our NLP stack, we have to model extraction, usage and representation of semantic knowledge from the
external KBs each of which might have different structure and access protocols. Moreover, we may
need to plug new KBs into our software environment, with the least effort. Finally, in complex services
ecosystems, we might also need to use the KB outside of the NLP system, e.g. in a remote reasoning
system, and we should be able to reuse the same model for these purposes.
MDD allows us to define the a single ontology/knowledge base (KB) abstraction, i.e. KB PIM, based
on the high-level requirements of our software system, regardless of the actual implementation details of
the KBs to be used. In contrast to UIMA type systems, which are limited to type hierarchies and type
feature structures with the respective getters and setters, MDD allows to specify also functionalities, i.e.
methods, such as querying and updating the KB. Figure 5 demonstrates a diagram of a KB abstraction that
we employ in the Ontology module. In this abstraction KnowledgeBase is a collection of Individuals
and Concepts, Relationships and Roles, which all are subclasses of the Entity abstraction. The figure
contains also the visualizations of some components from the Text module, which show how we model
annotating text with references to the KB elements. For this purpose we have a special kind of TextUnit
called EntityToken used to encode the fact that a certain span in a text denotes a specific Entity. Note that
this is a high-level abstract schema without any platform-related details. This KB PIM may be invoked
in the various parts of the full system PIM model, not necessarily within the NLP stack. We can use this
schema to generate different PSMs depending on our needs.
One of the core benefits of MDD are the transformations. After we have defined our high-level KB
PIM conceptual model we may define a set of transformations which will convert it to the PSM mod-
els, which contain the implementation details of the conceptual model within a specific platform. For
example, it can be Jena TDB22, a framework for storing and managing structured knowledge models, or
a SQL relational database. PIM-to-PSM transformations can be defined programmatically, by means of
special tools such as IBM Rational Software Architect23, or by means of a specific modeling language,
e.g. ATL Transformation Language (Jouault et al., 2006). Finally, we can use a number of tools for code
generation from the PSM model, thus facilitating and speeding up the software development process.
Depending on the task, our Ontology PIM may be instantiated both as an UIMA PSM or as a PSM
for another platform. More specifically, we have the following scenarios for the KB usage.
Within NLP stack. This may be required, for example, if some annotators in the NLP UIMA pipeline,
such as a relation extractor or a coreference resolver, require knowledge about types of the individuals
(entities) mentioned in a text. In such case, in order to annotate the text with information about individu-
als and their classes from an external KB we can transform the PIM model to a UIMA Type System (TS).
We define a transformation which converts TextUnit to a subclass of UIMA Annotation24, and the Entity
element in Ontology to a direct subclass of UIMA TOP25. Therefore, for example, within our model
</bodyText>
<footnote confidence="0.970164571428571">
20Here we use the term “knowledge base” to refer to any external resource containing structured semantic knowledge
21http://en.wikipedia.org/
22http://jena.apache.org/documentation/tdb/index.html
23http://www-03.ibm.com/software/products/en/ratisoftarch
24https://uima.apache.org/d/uimaj-2.6.0/apidocs/org/apache/uima/jcas/tcas/
Annotation.html
25https://uima.apache.org/d/uimaj-2.6.3/9
</footnote>
<page confidence="0.681988">
apidocs/org/apache/uima/jcas/cas/TOP.html
</page>
<figureCaption confidence="0.999695">
Figure 5: Fragments of the Ontology and Text models
</figureCaption>
<bodyText confidence="0.999986142857143">
illustrated in Figure 5, Individual abstraction, which is a subclass of Entity, becomes a subclass of UIMA
TOP. The EntityToken annotations from Text are converted to a subclass of UIMA Annotation and are
used to mark the spans of the Individual’s mentions in a text. In the original PIM model EntityTokens
have property references which is a collection of pointers to the respective entities. In UIMA PSM this
property is converted to a UIMA TS feature.
KnowledgeBase is an abstraction for an external KB resource to be plugged into the UIMA NLP stack.
UIMA contains a mechanism for plugging in external resources26 such as KBs. Each resource is defined
by its name, location and a name of the class which implements handling this resource. MDA and PIM-
to-PSM transformations can simplify modeling the resource implementations for different platforms,
and EMF tools can further help with automatic code generation. We can define a transformation which
would convert platform independent KnowledgeBase model elements to a platform-specific models, for
instance a class diagram for implementing a KnowledgeBase within Jena TDB platform. Then we can
use code generation tools for further facilitation of software development.
Within a reasoning component of a QA system. We may need to use both the output of the NLP
stack and information stored in a KB within some reasoning platform. For instance, this could be needed
within a Question Answering system which provides an answer to the input question based on both text
evidence coming from the UIMA pipeline, e.g. syntactic parse information, and a KB. In this case, the
PIM representations of linguistic annotations (Text and Linguistics packages) and KB knowledge
(Ontology package) may be instantiated as PSMs relative to the specific reasoning (rule- or statistic-
based) framework. UIMA annotations previously obtained within the UIMA can be converted to the
format required by the reasoning framework by means of model-to-model transformations.
</bodyText>
<sectionHeader confidence="0.999876" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999087428571429">
In the recent years, a number of approaches to modeling annotations and language in NLP software
systems and increasing interoperability of distinct NLP components have been proposed (Hellmann et
al., 2013; Ide and Romary, 2006; McCrae et al., 2011).
The most widely-accepted solutions for assembling NLP pipelines are UIMA and the GATE (Cun-
ningham et al., 2011) frameworks. They both use annotation models based on referential and feature
structures and allow to define custom language models called UIMA type system (TS) or GATE annota-
tion schema in an XML descriptor file. There are ongoing efforts to develop all-purpose UIMA-based
</bodyText>
<footnote confidence="0.669525">
26http://uima.apache.org/downloads/releaseDocs/2.1.0-incubating/docs/html/
tutorials_and_users_guides/tutorials_and�users_guides.html#ugr.tug.aae.accessing_
</footnote>
<bodyText confidence="0.995165217391304">
external resource files 3
NLP toolkits , such as DKPro27 or ClearTK (Ogren et al., 2009), with TSs describing a variety of lin-
guistic phenomena. UIMA is accompanied with a UIMAfit toolkit (Ogren and Bethard, 2009), which
contains a set of utilities that facilitate construction and testing of UIMA pipelines. The two frameworks
are compatible, and GATE provides means to integrate GATE with UIMA and vice versa by using XML
mapping files to reconcile the annotation schemes and software wrappers to integrate the components28.
From the MDA perspective, UIMA and GATE type/annotation systems are platform specific models.
Defining a language model as a platform independent EMF model results in greater expressivity. For
example, in UIMA TS one can model only type class hierarchy and type features, while in EMF model
we can also encode the types behavior, i.e. their methods. Moreover, MDA allows to model the usage of
the annotation produced by an NLP pipeline within a larger system. For instance, this could be a question
answering system which uses both information extracted from text (e.g. question parse) and information
extracted from a knowledge base (e.g. query results) and provides tools to facilitate the code generation.
Certain effort has been made on reconciling the different annotation formats. For example, Ide et al.
(2003) and Ide and Suderman (2007) proposed Linguistic Annotation Framework (LAF), a graph-based
annotation model, and its extension, Graph Annotation Format (GrAF), an XML serialization of LAF, for
representing various corpora annotations. It can be used as a pivot format to run the transformations be-
tween different annotation models that adhere to the abstract data model. The latter contains referential
structures for associating annotations with the original data and uses feature structure graphs to describe
the annotations. Ide and Suderman (2009) show how one may perform GrAF-UIMA-GrAF and GrAF-
GATE-GrAF transformations and provide the corresponding software. However, in GrAF representation
feature values are strings, and additionally, it is not possible to derive information about annotations
types hierarchy from the GrAF file only, therefore, the resulting UIMA TS would be shallow and with all
feature values types being string, unless additional information is provided (Ide and Suderman, 2009).
At the same time, MDD tools like EMF provide a both a modeling language with high expressiveness
and solid support to any transformation. We show how MDD facilitates conversion between different
formats in Section 3.1. Additionaly, MDD tools like EMF have a solid sofware support for complex
model visualization, this helps to facilitate understanding and managing large models.
After the emergence of the Semantic Web, RDF/OWL formalisms have been used to describe language
and annotation models (Hellmann et al., 2013; McCrae et al., 2011; Liu et al., 2012). For instance, NLP
Interchange Format, NIF, (Hellmann et al., 2013) is intended to allow various NLP tools to interact on
web in a decentralized manner. Its annotation model, NIF Core Ontology, encoded in OWL, provides
means to describe strings, documents, spans, and their relations. Choice of a language model depends
on the developers of the NLP tools, however, they are recommended to reuse existing ontologies, e.g.
Ontologies of Linguistic Annotations (OLiA) (Chiarcos, 2012). Another effort, Lemon (McCrae et al.,
2011), is a common RDF meta-model for describing lexicons for ontologies and linking them with
ontologies. Its core element is a lexical entry which has a number of properties, e.g. semantic roles
or morpho-syntactic properties. There has also been research on converting UIMA type systems to the
OWL format (Liu et al., 2012). OWL is highly expressive, and a number of tools exists for reasoning
upon OWL/RDF models or visualizing them, e.g. Prot´eg´e29, or for aligning them (Volz et al., 2009).
Expressiveness of UML, which is typically used to encode the PIM models in MDD, is comparable to that
of the ontology description languages (Guizzardi et al., 2004), and it may be reasoned upon (Calvanese et
al., 2005). However, differently from the OWL models, there is a number of software solutions which are
able to generate code on top of UML representations. Therefore, when using MDD we benefit both from
the high expressiveness of the modeling language and the solid software engineering support provided
by the MDD tools.
</bodyText>
<footnote confidence="0.996881">
27http://www.ukp.tu-darmstadt.de/software/dkpro-core/
28http://gate.ac.uk/sale/tao/splitch21.html
29http://protege.stanford.edu/ 11
</footnote>
<sectionHeader confidence="0.994203" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999744454545455">
Model Driven Development and Architecture is a successful paradigm for tackling the complexity of
modern software infrastructures, well supported by tools and standards. We have discussed how the
basic principles behind MDD/A are relevant for Human Language Technologies, when approaching the
coming era of high-level cognitive functionalities delivered by interconnected software services, and
grounded on open data. Model-to-model transformations, supported by specific tools, offer the possi-
bility to rapidly integrate different platforms, and to work with many kinds of data representations. To
get the best of this approach, it is important to carefully analyze the layering and interconnections of
different models, and to provide them with a suitable design. In our work, we are learning the benefit
of modeling aspects such as morpho-syntax and semantics separately, to foster adaptability across lan-
guages and domains. A complete and principled analysis of such general design is yet to come. Here we
have presented some preliminary result of our experiences, and shared what we achieved so far.
</bodyText>
<sectionHeader confidence="0.997602" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998729">
This research is partially supported by the EU FP7 / Marie Curie Industry-Academia Partnerships and
Pathways schema / PEOPLE Work Programme (Grant agreement no.: 286348, K-Drive project) and by
the IBM Center for Advanced Studies of Trento, Italy.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9985016">
D. Calvanese, G. De Giacomo, D. Lembo, M. Lenzerini, and R. Rosati. 2005. DL-Lite: Tractable description
logics for ontologies. In AAAI, pages 602–607.
C. Chiarcos. 2012. Ontologies of linguistic annotation: Survey and perspectives. In LREC, pages 303–310.
H. Cunningham, D. Maynard, K. Bontcheva, V. Tablan, N. Aswani, I. Roberts, G. Gorrell, A. Funk, A. Roberts,
D. Damljanovic, T. Heitz, M. A. Greenwood, H. Saggion, J. Petrak, Y. Li, and W. Peters. 2011. Text Processing
with GATE (Version 6). University of Sheffield Department of Computer Science.
A. Di Bari, A. Faraotti, C. Gambardella, and G. Vetere. 2013. A Model-driven approach to NLP programming
with UIMA. In 3rd Workshop on Unstructured Information Management Architecture, pages 2–9.
C. Fellbaum. 1998. WordNet: An electronic lexical database. The MIT press.
G. Guizzardi, G. Wagner, and H. Herre. 2004. On the foundations of uml as an ontology representation language.
In E. Motta, N. Shadbolt, A. Stutt, and N. Gibbins, editors, EKAW, volume 3257 of Lecture Notes in Computer
Science, pages 47–62. Springer.
S. Hellmann, J. Lehmann, S. Auer, and M. Br¨ummer. 2013. Integrating NLP using Linked Data. In ISWC.
N. Ide and L. Romary. 2006. Representing linguistic corpora and their annotations. In LREC.
N. Ide and K. Suderman. 2007. GrAF: A graph-based format for linguistic annotations. In Proceedings of the
Linguistic Annotation Workshop, pages 1–8. Association for Computational Linguistics.
N. Ide and K. Suderman. 2009. Bridging the gaps: interoperability for GrAF, GATE, and UIMA. In Third
Linguistic Annotation Workshop, pages 27–34. Association for Computational Linguistics.
N. Ide, L. Romary, and E. de la Clergerie. 2003. International standard for a linguistic annotation framework. In
HLT-NAACL workshop on Software engineering and architecture of language technology systems, pages 25–30.
Association for Computational Linguistics.
IJRD. 2012. This is Watson [Special issue]. IBM Journal of Research and Development, editor Clifford A.
Pickover, 56(3.4).
F. Jouault, F. Allilaire, J. B´ezivin, I. Kurtev, and P. Valduriez. 2006. ATL: a QVT-like transformation language. In
Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and
</reference>
<page confidence="0.731443">
32
</page>
<reference confidence="0.999462421052632">
applications, pages 719–720. ACM.
H. Liu, S. Wu, C. Tao, and C. Chute. 2012. Modeling UIMA type system using web ontology language: towards
interoperability among UIMA-based NLP tools. In 2nd international workshop on Managing interoperability
and compleXity in health systems, pages 31–36. ACM.
J. McCrae, D. Spohr, and P. Cimiano. 2011. Linking lexical resources and ontologies on the semantic web with
lemon. In The Semantic Web: Research and Applications, pages 245–259. Springer.
J. Miller and J. Mukerji. 2003. MDA Guide Version 1.0.1. Technical report, Object Management Group (OMG).
P. Ogren and S. Bethard. 2009. Building test suites for UIMA components. In Workshop on Software Engineering,
Testing, and Quality Assurance for Natural Language Processing, pages 1–4. Association for Computational
Linguistics, June.
P. V. Ogren, P.G. Wetzler, and S. J. Bethard. 2009. ClearTK: a framework for statistical natural language process-
ing. In Unstructured Information Management Architecture Workshop at the Conference of the German Society
for Computational Linguistics and Language Technology.
J. Rumbaugh, I. Jacobson, and G. Booch. 2005. The Unified Modeling Language Reference Manual. Addison-
Wesley, Boston, MA, 2 edition.
K. Verspoor, W. Baumgartner Jr, C. Roeder, and L. Hunter. 2009. Abstracting the types away from a UIMA type
system. From Form to Meaning: Processing Texts Automatically. T¨ubingen:Narr, pages 249–256.
J. Volz, C. Bizer, M. Gaedke, and G. Kobilarov. 2009. Silk - A Link Discovery Framework for the Web of Data.
In LDOW.
</reference>
<page confidence="0.999377">
33
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.120741">
<title confidence="0.999972">Towards Model Driven Architectures for Human Language Technologies</title>
<author confidence="0.999938">Alessandro Di_Kateryna Guido</author>
<affiliation confidence="0.775149">IBM Center Trento IBM Center Advanced Studies of Povo di Advanced Studies of</affiliation>
<author confidence="0.631242666666667">Povo di_Via Sommarive Povo di_Piazza Manci k tymoshenkotrentorise eu Piazza Manci alessandro dibariit ibm com guido vetereit ibm com</author>
<abstract confidence="0.999389916666667">Developing multi-purpose Human Language Technologies (HLT) pipelines and integrating them into the large scale software environments is a complex software engineering task. One needs to orchestrate a variety of new and legacy Natural Language Processing components, language models, linguistic and encyclopedic knowledge resources. This requires working with a variety of different APIs, data formats and knowledge models. In this paper, we propose to employ the Model Driven Development (MDD) approach to software engineering, which provides rich structural and behavioral modeling capabilities and solid software support for model transformation and code generation. These benefits help to increase development productivity and quality of HLT assets. We show how MDD techniques and tools facilitate working with different data formats, adapting to new languages and domains, managing UIMA type systems, and accessing the external knowledge bases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Calvanese</author>
<author>G De Giacomo</author>
<author>D Lembo</author>
<author>M Lenzerini</author>
<author>R Rosati</author>
</authors>
<title>DL-Lite: Tractable description logics for ontologies.</title>
<date>2005</date>
<journal>C. Chiarcos.</journal>
<booktitle>In AAAI,</booktitle>
<pages>602--607</pages>
<marker>Calvanese, De Giacomo, Lembo, Lenzerini, Rosati, 2005</marker>
<rawString>D. Calvanese, G. De Giacomo, D. Lembo, M. Lenzerini, and R. Rosati. 2005. DL-Lite: Tractable description logics for ontologies. In AAAI, pages 602–607. C. Chiarcos. 2012. Ontologies of linguistic annotation: Survey and perspectives. In LREC, pages 303–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>K Bontcheva</author>
<author>V Tablan</author>
<author>N Aswani</author>
<author>I Roberts</author>
<author>G Gorrell</author>
<author>A Funk</author>
<author>A Roberts</author>
<author>D Damljanovic</author>
<author>T Heitz</author>
<author>M A Greenwood</author>
<author>H Saggion</author>
<author>J Petrak</author>
<author>Y Li</author>
<author>W Peters</author>
</authors>
<date>2011</date>
<journal>Text Processing with GATE (Version</journal>
<volume>6</volume>
<institution>University of Sheffield Department of Computer Science.</institution>
<contexts>
<context position="25527" citStr="Cunningham et al., 2011" startWordPosition="3815" endWordPosition="3819">ed as PSMs relative to the specific reasoning (rule- or statisticbased) framework. UIMA annotations previously obtained within the UIMA can be converted to the format required by the reasoning framework by means of model-to-model transformations. 5 Related Work In the recent years, a number of approaches to modeling annotations and language in NLP software systems and increasing interoperability of distinct NLP components have been proposed (Hellmann et al., 2013; Ide and Romary, 2006; McCrae et al., 2011). The most widely-accepted solutions for assembling NLP pipelines are UIMA and the GATE (Cunningham et al., 2011) frameworks. They both use annotation models based on referential and feature structures and allow to define custom language models called UIMA type system (TS) or GATE annotation schema in an XML descriptor file. There are ongoing efforts to develop all-purpose UIMA-based 26http://uima.apache.org/downloads/releaseDocs/2.1.0-incubating/docs/html/ tutorials_and_users_guides/tutorials_and�users_guides.html#ugr.tug.aae.accessing_ external resource files 3 NLP toolkits , such as DKPro27 or ClearTK (Ogren et al., 2009), with TSs describing a variety of linguistic phenomena. UIMA is accompanied with</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, Aswani, Roberts, Gorrell, Funk, Roberts, Damljanovic, Heitz, Greenwood, Saggion, Petrak, Li, Peters, 2011</marker>
<rawString>H. Cunningham, D. Maynard, K. Bontcheva, V. Tablan, N. Aswani, I. Roberts, G. Gorrell, A. Funk, A. Roberts, D. Damljanovic, T. Heitz, M. A. Greenwood, H. Saggion, J. Petrak, Y. Li, and W. Peters. 2011. Text Processing with GATE (Version 6). University of Sheffield Department of Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Di Bari</author>
<author>A Faraotti</author>
<author>C Gambardella</author>
<author>G Vetere</author>
</authors>
<title>A Model-driven approach to NLP programming with UIMA.</title>
<date>2013</date>
<booktitle>In 3rd Workshop on Unstructured Information Management Architecture,</booktitle>
<pages>pages</pages>
<publisher>The MIT press.</publisher>
<marker>Di Bari, Faraotti, Gambardella, Vetere, 2013</marker>
<rawString>A. Di Bari, A. Faraotti, C. Gambardella, and G. Vetere. 2013. A Model-driven approach to NLP programming with UIMA. In 3rd Workshop on Unstructured Information Management Architecture, pages 2–9. C. Fellbaum. 1998. WordNet: An electronic lexical database. The MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Guizzardi</author>
<author>G Wagner</author>
<author>H Herre</author>
</authors>
<title>On the foundations of uml as an ontology representation language. In</title>
<date>2004</date>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>3257</volume>
<pages>47--62</pages>
<editor>E. Motta, N. Shadbolt, A. Stutt, and N. Gibbins, editors, EKAW,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="30055" citStr="Guizzardi et al., 2004" startWordPosition="4494" endWordPosition="4497">escribing lexicons for ontologies and linking them with ontologies. Its core element is a lexical entry which has a number of properties, e.g. semantic roles or morpho-syntactic properties. There has also been research on converting UIMA type systems to the OWL format (Liu et al., 2012). OWL is highly expressive, and a number of tools exists for reasoning upon OWL/RDF models or visualizing them, e.g. Prot´eg´e29, or for aligning them (Volz et al., 2009). Expressiveness of UML, which is typically used to encode the PIM models in MDD, is comparable to that of the ontology description languages (Guizzardi et al., 2004), and it may be reasoned upon (Calvanese et al., 2005). However, differently from the OWL models, there is a number of software solutions which are able to generate code on top of UML representations. Therefore, when using MDD we benefit both from the high expressiveness of the modeling language and the solid software engineering support provided by the MDD tools. 27http://www.ukp.tu-darmstadt.de/software/dkpro-core/ 28http://gate.ac.uk/sale/tao/splitch21.html 29http://protege.stanford.edu/ 11 6 Conclusion Model Driven Development and Architecture is a successful paradigm for tackling the comp</context>
</contexts>
<marker>Guizzardi, Wagner, Herre, 2004</marker>
<rawString>G. Guizzardi, G. Wagner, and H. Herre. 2004. On the foundations of uml as an ontology representation language. In E. Motta, N. Shadbolt, A. Stutt, and N. Gibbins, editors, EKAW, volume 3257 of Lecture Notes in Computer Science, pages 47–62. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hellmann</author>
<author>J Lehmann</author>
<author>S Auer</author>
<author>M Br¨ummer</author>
</authors>
<title>Integrating NLP using Linked Data. In</title>
<date>2013</date>
<booktitle>ISWC. N. Ide</booktitle>
<marker>Hellmann, Lehmann, Auer, Br¨ummer, 2013</marker>
<rawString>S. Hellmann, J. Lehmann, S. Auer, and M. Br¨ummer. 2013. Integrating NLP using Linked Data. In ISWC. N. Ide and L. Romary. 2006. Representing linguistic corpora and their annotations. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>K Suderman</author>
</authors>
<title>GrAF: A graph-based format for linguistic annotations.</title>
<date>2007</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27330" citStr="Ide and Suderman (2007)" startWordPosition="4078" endWordPosition="4081">odel only type class hierarchy and type features, while in EMF model we can also encode the types behavior, i.e. their methods. Moreover, MDA allows to model the usage of the annotation produced by an NLP pipeline within a larger system. For instance, this could be a question answering system which uses both information extracted from text (e.g. question parse) and information extracted from a knowledge base (e.g. query results) and provides tools to facilitate the code generation. Certain effort has been made on reconciling the different annotation formats. For example, Ide et al. (2003) and Ide and Suderman (2007) proposed Linguistic Annotation Framework (LAF), a graph-based annotation model, and its extension, Graph Annotation Format (GrAF), an XML serialization of LAF, for representing various corpora annotations. It can be used as a pivot format to run the transformations between different annotation models that adhere to the abstract data model. The latter contains referential structures for associating annotations with the original data and uses feature structure graphs to describe the annotations. Ide and Suderman (2009) show how one may perform GrAF-UIMA-GrAF and GrAFGATE-GrAF transformations an</context>
</contexts>
<marker>Ide, Suderman, 2007</marker>
<rawString>N. Ide and K. Suderman. 2007. GrAF: A graph-based format for linguistic annotations. In Proceedings of the Linguistic Annotation Workshop, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>K Suderman</author>
</authors>
<title>Bridging the gaps: interoperability for GrAF, GATE, and UIMA.</title>
<date>2009</date>
<booktitle>In Third Linguistic Annotation Workshop,</booktitle>
<pages>27--34</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27853" citStr="Ide and Suderman (2009)" startWordPosition="4153" endWordPosition="4156">nciling the different annotation formats. For example, Ide et al. (2003) and Ide and Suderman (2007) proposed Linguistic Annotation Framework (LAF), a graph-based annotation model, and its extension, Graph Annotation Format (GrAF), an XML serialization of LAF, for representing various corpora annotations. It can be used as a pivot format to run the transformations between different annotation models that adhere to the abstract data model. The latter contains referential structures for associating annotations with the original data and uses feature structure graphs to describe the annotations. Ide and Suderman (2009) show how one may perform GrAF-UIMA-GrAF and GrAFGATE-GrAF transformations and provide the corresponding software. However, in GrAF representation feature values are strings, and additionally, it is not possible to derive information about annotations types hierarchy from the GrAF file only, therefore, the resulting UIMA TS would be shallow and with all feature values types being string, unless additional information is provided (Ide and Suderman, 2009). At the same time, MDD tools like EMF provide a both a modeling language with high expressiveness and solid support to any transformation. We </context>
</contexts>
<marker>Ide, Suderman, 2009</marker>
<rawString>N. Ide and K. Suderman. 2009. Bridging the gaps: interoperability for GrAF, GATE, and UIMA. In Third Linguistic Annotation Workshop, pages 27–34. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>L Romary</author>
<author>E de la Clergerie</author>
</authors>
<title>International standard for a linguistic annotation framework.</title>
<date>2003</date>
<booktitle>In HLT-NAACL workshop on Software engineering and architecture of language technology systems,</booktitle>
<pages>25--30</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27302" citStr="Ide et al. (2003)" startWordPosition="4073" endWordPosition="4076">, in UIMA TS one can model only type class hierarchy and type features, while in EMF model we can also encode the types behavior, i.e. their methods. Moreover, MDA allows to model the usage of the annotation produced by an NLP pipeline within a larger system. For instance, this could be a question answering system which uses both information extracted from text (e.g. question parse) and information extracted from a knowledge base (e.g. query results) and provides tools to facilitate the code generation. Certain effort has been made on reconciling the different annotation formats. For example, Ide et al. (2003) and Ide and Suderman (2007) proposed Linguistic Annotation Framework (LAF), a graph-based annotation model, and its extension, Graph Annotation Format (GrAF), an XML serialization of LAF, for representing various corpora annotations. It can be used as a pivot format to run the transformations between different annotation models that adhere to the abstract data model. The latter contains referential structures for associating annotations with the original data and uses feature structure graphs to describe the annotations. Ide and Suderman (2009) show how one may perform GrAF-UIMA-GrAF and GrAF</context>
</contexts>
<marker>Ide, Romary, Clergerie, 2003</marker>
<rawString>N. Ide, L. Romary, and E. de la Clergerie. 2003. International standard for a linguistic annotation framework. In HLT-NAACL workshop on Software engineering and architecture of language technology systems, pages 25–30. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IJRD</author>
</authors>
<title>This is Watson [Special issue].</title>
<date>2012</date>
<journal>IBM Journal of Research</journal>
<pages>56--3</pages>
<editor>and Development, editor Clifford A. Pickover,</editor>
<contexts>
<context position="2011" citStr="IJRD, 2012" startWordPosition="279" endWordPosition="280">d computing (cognitive computing) require HLT components to interact with increasingly many sources and services, such as Open Data and APIs, which may not be known before the system is designed. IBM’s Watson1, for instance, works on textual documents to provide question answering and other knowledge-based services by integrating lexical resources, ontologies, encyclopaedic data, and potentially any available information source. Also, they combine a variety of analytical procedures, which may use search, reasoning services, database queries, to provide answers based on many kinds of evidence (IJRD, 2012). Development platforms such as UIMA2 or GATE3 facilitate the development of HLT components to a great extent, by providing tools for annotating texts, based on vocabularies and ontologies, training and evaluating pipeline components, etc. However, in general, they focus on working with specific analytical structures (annotations), rather than integrating distributed services and heterogeneous resources. Such integration requires great flexibility in the way linguistic and conceptual data are encoded and exchanged, since each independent service or resource may adopt different representations </context>
</contexts>
<marker>IJRD, 2012</marker>
<rawString>IJRD. 2012. This is Watson [Special issue]. IBM Journal of Research and Development, editor Clifford A. Pickover, 56(3.4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jouault</author>
<author>F Allilaire</author>
<author>J B´ezivin</author>
<author>I Kurtev</author>
<author>P Valduriez</author>
</authors>
<title>ATL: a QVT-like transformation language.</title>
<date>2006</date>
<booktitle>In Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications,</booktitle>
<pages>719--720</pages>
<publisher>ACM.</publisher>
<marker>Jouault, Allilaire, B´ezivin, Kurtev, Valduriez, 2006</marker>
<rawString>F. Jouault, F. Allilaire, J. B´ezivin, I. Kurtev, and P. Valduriez. 2006. ATL: a QVT-like transformation language. In Companion to the 21st ACM SIGPLAN symposium on Object-oriented programming systems, languages, and applications, pages 719–720. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Liu</author>
<author>S Wu</author>
<author>C Tao</author>
<author>C Chute</author>
</authors>
<title>Modeling UIMA type system using web ontology language: towards interoperability among UIMA-based NLP tools.</title>
<date>2012</date>
<booktitle>In 2nd international workshop on Managing interoperability and compleXity in health systems,</booktitle>
<pages>31--36</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="28871" citStr="Liu et al., 2012" startWordPosition="4307" endWordPosition="4310">itional information is provided (Ide and Suderman, 2009). At the same time, MDD tools like EMF provide a both a modeling language with high expressiveness and solid support to any transformation. We show how MDD facilitates conversion between different formats in Section 3.1. Additionaly, MDD tools like EMF have a solid sofware support for complex model visualization, this helps to facilitate understanding and managing large models. After the emergence of the Semantic Web, RDF/OWL formalisms have been used to describe language and annotation models (Hellmann et al., 2013; McCrae et al., 2011; Liu et al., 2012). For instance, NLP Interchange Format, NIF, (Hellmann et al., 2013) is intended to allow various NLP tools to interact on web in a decentralized manner. Its annotation model, NIF Core Ontology, encoded in OWL, provides means to describe strings, documents, spans, and their relations. Choice of a language model depends on the developers of the NLP tools, however, they are recommended to reuse existing ontologies, e.g. Ontologies of Linguistic Annotations (OLiA) (Chiarcos, 2012). Another effort, Lemon (McCrae et al., 2011), is a common RDF meta-model for describing lexicons for ontologies and l</context>
</contexts>
<marker>Liu, Wu, Tao, Chute, 2012</marker>
<rawString>H. Liu, S. Wu, C. Tao, and C. Chute. 2012. Modeling UIMA type system using web ontology language: towards interoperability among UIMA-based NLP tools. In 2nd international workshop on Managing interoperability and compleXity in health systems, pages 31–36. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCrae</author>
<author>D Spohr</author>
<author>P Cimiano</author>
</authors>
<title>Linking lexical resources and ontologies on the semantic web with lemon.</title>
<date>2011</date>
<booktitle>In The Semantic Web: Research and Applications,</booktitle>
<tech>Technical report,</tech>
<pages>245--259</pages>
<publisher>Springer.</publisher>
<institution>Object Management Group (OMG).</institution>
<contexts>
<context position="25414" citStr="McCrae et al., 2011" startWordPosition="3798" endWordPosition="3801"> linguistic annotations (Text and Linguistics packages) and KB knowledge (Ontology package) may be instantiated as PSMs relative to the specific reasoning (rule- or statisticbased) framework. UIMA annotations previously obtained within the UIMA can be converted to the format required by the reasoning framework by means of model-to-model transformations. 5 Related Work In the recent years, a number of approaches to modeling annotations and language in NLP software systems and increasing interoperability of distinct NLP components have been proposed (Hellmann et al., 2013; Ide and Romary, 2006; McCrae et al., 2011). The most widely-accepted solutions for assembling NLP pipelines are UIMA and the GATE (Cunningham et al., 2011) frameworks. They both use annotation models based on referential and feature structures and allow to define custom language models called UIMA type system (TS) or GATE annotation schema in an XML descriptor file. There are ongoing efforts to develop all-purpose UIMA-based 26http://uima.apache.org/downloads/releaseDocs/2.1.0-incubating/docs/html/ tutorials_and_users_guides/tutorials_and�users_guides.html#ugr.tug.aae.accessing_ external resource files 3 NLP toolkits , such as DKPro27</context>
<context position="28852" citStr="McCrae et al., 2011" startWordPosition="4303" endWordPosition="4306">ng string, unless additional information is provided (Ide and Suderman, 2009). At the same time, MDD tools like EMF provide a both a modeling language with high expressiveness and solid support to any transformation. We show how MDD facilitates conversion between different formats in Section 3.1. Additionaly, MDD tools like EMF have a solid sofware support for complex model visualization, this helps to facilitate understanding and managing large models. After the emergence of the Semantic Web, RDF/OWL formalisms have been used to describe language and annotation models (Hellmann et al., 2013; McCrae et al., 2011; Liu et al., 2012). For instance, NLP Interchange Format, NIF, (Hellmann et al., 2013) is intended to allow various NLP tools to interact on web in a decentralized manner. Its annotation model, NIF Core Ontology, encoded in OWL, provides means to describe strings, documents, spans, and their relations. Choice of a language model depends on the developers of the NLP tools, however, they are recommended to reuse existing ontologies, e.g. Ontologies of Linguistic Annotations (OLiA) (Chiarcos, 2012). Another effort, Lemon (McCrae et al., 2011), is a common RDF meta-model for describing lexicons f</context>
</contexts>
<marker>McCrae, Spohr, Cimiano, 2011</marker>
<rawString>J. McCrae, D. Spohr, and P. Cimiano. 2011. Linking lexical resources and ontologies on the semantic web with lemon. In The Semantic Web: Research and Applications, pages 245–259. Springer. J. Miller and J. Mukerji. 2003. MDA Guide Version 1.0.1. Technical report, Object Management Group (OMG).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ogren</author>
<author>S Bethard</author>
</authors>
<title>Building test suites for UIMA components.</title>
<date>2009</date>
<booktitle>In Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>1--4</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="26171" citStr="Ogren and Bethard, 2009" startWordPosition="3896" endWordPosition="3899">th use annotation models based on referential and feature structures and allow to define custom language models called UIMA type system (TS) or GATE annotation schema in an XML descriptor file. There are ongoing efforts to develop all-purpose UIMA-based 26http://uima.apache.org/downloads/releaseDocs/2.1.0-incubating/docs/html/ tutorials_and_users_guides/tutorials_and�users_guides.html#ugr.tug.aae.accessing_ external resource files 3 NLP toolkits , such as DKPro27 or ClearTK (Ogren et al., 2009), with TSs describing a variety of linguistic phenomena. UIMA is accompanied with a UIMAfit toolkit (Ogren and Bethard, 2009), which contains a set of utilities that facilitate construction and testing of UIMA pipelines. The two frameworks are compatible, and GATE provides means to integrate GATE with UIMA and vice versa by using XML mapping files to reconcile the annotation schemes and software wrappers to integrate the components28. From the MDA perspective, UIMA and GATE type/annotation systems are platform specific models. Defining a language model as a platform independent EMF model results in greater expressivity. For example, in UIMA TS one can model only type class hierarchy and type features, while in EMF m</context>
</contexts>
<marker>Ogren, Bethard, 2009</marker>
<rawString>P. Ogren and S. Bethard. 2009. Building test suites for UIMA components. In Workshop on Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 1–4. Association for Computational Linguistics, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P V Ogren</author>
<author>P G Wetzler</author>
<author>S J Bethard</author>
</authors>
<title>ClearTK: a framework for statistical natural language processing.</title>
<date>2009</date>
<booktitle>In Unstructured Information Management Architecture Workshop at the Conference of the German Society for Computational Linguistics and Language Technology.</booktitle>
<contexts>
<context position="26046" citStr="Ogren et al., 2009" startWordPosition="3876" endWordPosition="3879">dely-accepted solutions for assembling NLP pipelines are UIMA and the GATE (Cunningham et al., 2011) frameworks. They both use annotation models based on referential and feature structures and allow to define custom language models called UIMA type system (TS) or GATE annotation schema in an XML descriptor file. There are ongoing efforts to develop all-purpose UIMA-based 26http://uima.apache.org/downloads/releaseDocs/2.1.0-incubating/docs/html/ tutorials_and_users_guides/tutorials_and�users_guides.html#ugr.tug.aae.accessing_ external resource files 3 NLP toolkits , such as DKPro27 or ClearTK (Ogren et al., 2009), with TSs describing a variety of linguistic phenomena. UIMA is accompanied with a UIMAfit toolkit (Ogren and Bethard, 2009), which contains a set of utilities that facilitate construction and testing of UIMA pipelines. The two frameworks are compatible, and GATE provides means to integrate GATE with UIMA and vice versa by using XML mapping files to reconcile the annotation schemes and software wrappers to integrate the components28. From the MDA perspective, UIMA and GATE type/annotation systems are platform specific models. Defining a language model as a platform independent EMF model resul</context>
</contexts>
<marker>Ogren, Wetzler, Bethard, 2009</marker>
<rawString>P. V. Ogren, P.G. Wetzler, and S. J. Bethard. 2009. ClearTK: a framework for statistical natural language processing. In Unstructured Information Management Architecture Workshop at the Conference of the German Society for Computational Linguistics and Language Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rumbaugh</author>
<author>I Jacobson</author>
<author>G Booch</author>
</authors>
<title>The Unified Modeling Language Reference Manual.</title>
<date>2005</date>
<volume>2</volume>
<pages>edition.</pages>
<publisher>AddisonWesley,</publisher>
<location>Boston, MA,</location>
<contexts>
<context position="5539" citStr="Rumbaugh et al., 2005" startWordPosition="760" endWordPosition="763"> of our architectural choices, we illustrate the basic features, and discuss relevant issues. Also, we provide some example of how MDA facilitates the design and the implementation of open and easily adaptable HLT functionalities. 2 Model-driven Development and NLP 2.1 Model-driven Development Generally speaking, we talk about a “modeling” language when it is possible to visually represent (or model) objects under construction (such as services and objects) from both a structural and behavioral point of view. The most popular (software) modeling language is the Unified Modeling Language (UML)(Rumbaugh et al., 2005). One of the strengths of such language is that it allows clear and transparent communication among different stakeholders and roles such as developers, architects, analyst, project managers and testers. Model Driven Development (MDD) is a software development approach aimed at improving quality and productivity by raising the level of abstraction of services and related objects under development. Given an application domain, we usually have a “business” model that allows for fast and highly expressive representation of specific domain objects. Based on business models, the MDD tooling provide</context>
<context position="8242" citStr="Rumbaugh et al., 2005" startWordPosition="1151" endWordPosition="1154">es (such as UML) by providing specific profiles (representing the business domain) for the language (UML is very generic and it offers several extensibility mechanisms such as profiles); the second one is a stronger approach that leads to what we call a DSL (Domain Specific Language), a fully specified, vertical language for a particular domain. Such a language is usually built in order to allow business experts to directly work on it, without the need of technological skills. 7http://omg.org/ 8http://www.uml.org/ 9http://www.omg.org/mof/ 24 a fully specification. PIM can be expressed in UML (Rumbaugh et al., 2005) or EMF10 but also in any peculiar DSL (domain specific language). • Platform Specific Model (PSM) can be completely generated from the PIM. Among other things, this requires PIM to be able to represent every aspect of the solution under development: both structural and behavioral parts have to be fully specified at this level. 2.3 Eclipse Modeling Framework (EMF) We chose to adopt EMF as the underlying modeling framework and tooling for our model-driven approach. EMF is an Eclipse11-based modeling framework and code generation facility. Ecore is the core meta-model for EMF. Ecore represents t</context>
</contexts>
<marker>Rumbaugh, Jacobson, Booch, 2005</marker>
<rawString>J. Rumbaugh, I. Jacobson, and G. Booch. 2005. The Unified Modeling Language Reference Manual. AddisonWesley, Boston, MA, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Verspoor</author>
<author>W Baumgartner Jr</author>
<author>C Roeder</author>
<author>L Hunter</author>
</authors>
<title>Abstracting the types away from a UIMA type system. From Form to Meaning: Processing Texts Automatically. T¨ubingen:Narr,</title>
<date>2009</date>
<pages>249--256</pages>
<contexts>
<context position="18473" citStr="Verspoor et al., 2009" startWordPosition="2734" endWordPosition="2737">format for the same data and so on. • Having an additional level of abstraction can lead in thinking there is an additional cost; however, as stated above, this is not the case for transforming from EMF to UIMA. The only, real additional cost is represented by the effort of developing transformations. Nevertheless, this is quickly absorbed as soon as the transformation is re-used. In our case, just for data conversions, we re-used the same 17Steps 2, 3, 4 are done through our Eclipse-based tooling. 18The benefit of abstracting semantic information from the Type System has been illustrated in (Verspoor et al., 2009) 19http://www.evalita.it/ 28 EMF models (and their underlying data parsing capabilities we implemented) several times. Each time we wanted to change a parser library, or new corpora were available, we reused the same EMF models and techniques. • The abstraction introduced by the Linguistic model, allowed us to create a languageindependent parsing software layer. Furthermore, the same model was leveraged in order to allow interoperability between different parsers that were using different tagsets. 4 Using an External Knowledge Base State-of-the-art NLP algorithms frequently employ semantic kno</context>
</contexts>
<marker>Verspoor, Jr, Roeder, Hunter, 2009</marker>
<rawString>K. Verspoor, W. Baumgartner Jr, C. Roeder, and L. Hunter. 2009. Abstracting the types away from a UIMA type system. From Form to Meaning: Processing Texts Automatically. T¨ubingen:Narr, pages 249–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Volz</author>
<author>C Bizer</author>
<author>M Gaedke</author>
<author>G Kobilarov</author>
</authors>
<title>Silk - A Link Discovery Framework for the Web of Data.</title>
<date>2009</date>
<booktitle>In LDOW.</booktitle>
<contexts>
<context position="29889" citStr="Volz et al., 2009" startWordPosition="4467" endWordPosition="4470">ting ontologies, e.g. Ontologies of Linguistic Annotations (OLiA) (Chiarcos, 2012). Another effort, Lemon (McCrae et al., 2011), is a common RDF meta-model for describing lexicons for ontologies and linking them with ontologies. Its core element is a lexical entry which has a number of properties, e.g. semantic roles or morpho-syntactic properties. There has also been research on converting UIMA type systems to the OWL format (Liu et al., 2012). OWL is highly expressive, and a number of tools exists for reasoning upon OWL/RDF models or visualizing them, e.g. Prot´eg´e29, or for aligning them (Volz et al., 2009). Expressiveness of UML, which is typically used to encode the PIM models in MDD, is comparable to that of the ontology description languages (Guizzardi et al., 2004), and it may be reasoned upon (Calvanese et al., 2005). However, differently from the OWL models, there is a number of software solutions which are able to generate code on top of UML representations. Therefore, when using MDD we benefit both from the high expressiveness of the modeling language and the solid software engineering support provided by the MDD tools. 27http://www.ukp.tu-darmstadt.de/software/dkpro-core/ 28http://gate</context>
</contexts>
<marker>Volz, Bizer, Gaedke, Kobilarov, 2009</marker>
<rawString>J. Volz, C. Bizer, M. Gaedke, and G. Kobilarov. 2009. Silk - A Link Discovery Framework for the Web of Data. In LDOW.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>