<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.057700">
<title confidence="0.9980255">
Real Time Adaptive Machine Translation for Post-Editing with
cdec and TransCenter
</title>
<author confidence="0.988863">
Michael Denkowski Alon Lavie Isabel Lacruz* Chris Dyer
</author>
<affiliation confidence="0.9744645">
Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA 15213 USA
*Institute for Applied Linguistics, Kent State University, Kent, OH 44242 USA
</affiliation>
<email confidence="0.999304">
{mdenkows,alavie,cdyer}@cs.cmu.edu ilacruz@kent.edu
</email>
<sectionHeader confidence="0.997396" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999786722222222">
Using machine translation output as a
starting point for human translation has
recently gained traction in the transla-
tion community. This paper describes
cdec Realtime, a framework for build-
ing adaptive MT systems that learn from
post-editor feedback, and TransCenter, a
web-based translation interface that con-
nects users to Realtime systems and logs
post-editing activity. This combination
allows the straightforward deployment of
MT systems specifically for post-editing
and analysis of human translator produc-
tivity when working with these systems.
All tools, as well as actual post-editing
data collected as part of a validation exper-
iment, are freely available under an open
source license.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999986243243243">
This paper describes the end-to-end machine
translation post-editing setup provided by cdec
Realtime and TransCenter. As the quality of MT
systems continues to improve, the idea of using
automatic translation as a primary technology in
assisting human translators has become increas-
ingly attractive. Recent work has explored the
possibilities of integrating MT into human transla-
tion workflows by providing MT-generated trans-
lations as a starting point for translators to cor-
rect, as opposed to translating source sentences
from scratch. The motivation for this process is
to dramatically reduce human translation effort
while improving translator productivity and con-
sistency. This computer-aided approach is directly
applicable to the wealth of scenarios that still re-
quire precise human-quality translation that MT
is currently unable to deliver, including an ever-
increasing number of government, commercial,
and community-driven projects.
The software described in the following sec-
tions enables users to translate documents with
the assistance of an adaptive MT system using
a web-based interface. The system learns from
user feedback, improving translation quality as
users work. All user interaction is logged, al-
lowing post-editing sessions to be replayed and
analyzed. All software is freely available under
an open source license, allowing anyone to eas-
ily build, deploy, and evaluate MT systems specif-
ically for post-editing. We first describe the under-
lying adaptive MT paradigm (§2) and the Realtime
implementation (§3). We then describe Trans-
Center (§4) and the results of an end-to-end post-
editing experiment with human translators (§5).
All data collected as part of this validation experi-
ment is also publicly available.
</bodyText>
<sectionHeader confidence="0.995806" genericHeader="introduction">
2 Adaptive Machine Translation
</sectionHeader>
<bodyText confidence="0.9983525">
Traditional machine translation systems operate in
batch mode: statistical translation models are es-
timated from large volumes of sentence-parallel
bilingual text and then used to translate new text.
Incorporating new data requires a full system re-
build, an expensive operation taking up to days of
time. As such, MT systems in production scenar-
ios typically remain static for large periods of time
(months or even indefinitely). Recently, an adap-
tive MT paradigm has been introduced specifi-
cally for post-editing (Denkowski et al., 2014).
Three major MT system components are extended
to support online updates, allowing human post-
editor feedback to be immediately incorporated:
</bodyText>
<listItem confidence="0.999750166666666">
• An online translation model is updated to in-
clude new translations extracted from post-
editing data.
• A dynamic language model is updated to in-
clude post-edited target language text.
• An online update is made to the system’s
</listItem>
<bodyText confidence="0.61155">
feature weights after each sentence is post-
edited.
</bodyText>
<page confidence="0.972046">
72
</page>
<bodyText confidence="0.989654913043479">
Workshop on Humans and Computer-assisted Translation, pages 72–77,
Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics
These extensions allow the MT system to gener-
ate improved translations that require significantly
less effort to correct for later sentences in the doc-
ument. This paradigm is now implemented in
the freely available cdec (Dyer et al., 2010) ma-
chine translation toolkit as Realtime, part of the
pycdec (Chahuneau et al., 2012) Python API.
Standard MT systems use aggregate statistics
from all training text to learn a single large
translation grammar (in the case of cdec’s hi-
erarchical phrase-based model (Chiang, 2007), a
synchronous context-free grammar) consisting of
rules annotated with feature scores. As an alter-
native, the bitext can be indexed using a suffix ar-
ray (Lopez, 2008), a data structure allowing fast
source-side lookups. When a new sentence is to be
translated, training sentences that share spans of
text with the input sentence are sampled from the
suffix array. Statistics from the sample are used to
learn a small, sentence-specific grammar on-the-
fly. The adaptive paradigm extends this approach
to support online updates by also indexing the
new bilingual sentences generated as a post-editor
works. When a new sentence is translated, match-
ing sentences are sampled from the post-editing
data as well as the suffix array. All feature scores
that can be computed on a suffix array sample can
be identically computed on the combined sample,
allowing uniform handling of all data. An addi-
tional “post-edit support” feature is included that
indicates whether a grammar rule was extracted
from the post-editing data. This allows an opti-
mizer to learn to prefer translations that originate
from human feedback. This adaptation approach
also serves as a platform for exploring expanded
post-editing-aware feature sets; any feature that
can be computed from standard text can be added
to the model and will automatically include post-
editing data. Implementationally, feature scoring
is broken out into a single Python source file con-
taining a single function for each feature score.
New feature functions can be added easily.
The adaptive paradigm uses two language mod-
els. A standard (static) n-gram language model es-
timated on large monolingual text allows the sys-
tem to prefer translations more similar to human-
generated text in the target language. A (dy-
namic) Bayesian n-gram language model (Teh,
2006) can be updated with observations of the
post-edited output in a straightforward way. This
smaller model exactly covers the training bitext
and all post-editing data, letting the system up-
weight translations with newly learned vocabu-
lary and phrasing absent in the large monolingual
text. Finally, the margin-infused relaxed algorithm
(MIRA) (Crammer et al., 2006; Eidelman, 2012)
is used to make an online parameter update after
each sentence is post-edited, minimizing model er-
ror. This allows the system to continuously rescale
weights for translation and language model fea-
tures that adapt over time.
Since true post-editing data is infeasible to col-
lect during system development and internal test-
ing, as standard MT pipelines require tens of thou-
sands of sentences to be translated with low la-
tency, a simulated post-editing paradigm (Hardt
and Elming, 2010) can be used, wherein pre-
generated reference translations act as a stand-in
for actual post-editing. This approximation is ef-
fective for tuning and internal evaluation when
real post-editing data is unavailable. In simulated
post-editing tasks, decoding (for both the test cor-
pus and each pass over the development corpus
during optimization) begins with baseline mod-
els trained on standard bilingual and monolingual
text. After each sentence is translated, the fol-
lowing take place in order: First, MIRA uses the
new source–reference pair to update weights for
the current models. Second, the source is aligned
to the reference using word-alignment models
learned from the initial data and used to update the
translation grammar. Third, the reference is added
to the Bayesian language model. As sentences are
translated, the models gain valuable context infor-
mation, allowing them to adapt to the specific tar-
get document and translator. Context is reset at the
start of each development or test corpus. Systems
optimized with simulated post-editing can then be
deployed to serve real human translators without
further modification.
</bodyText>
<sectionHeader confidence="0.952514" genericHeader="method">
3 cdec Realtime
</sectionHeader>
<bodyText confidence="0.999975625">
Now included as part of the free, open source
cdec machine translation toolkit (Dyer et al.,
2010), Realtime1 provides an efficient implemen-
tation of the adaptive MT paradigm that can serve
an arbitrary number of unique post-editors concur-
rently. A full Realtime tutorial, including step-
by-step instructions for installing required soft-
ware and building full adaptive systems, is avail-
</bodyText>
<footnote confidence="0.9949885">
1https://github.com/redpony/cdec/tree/
master/realtime
</footnote>
<page confidence="0.996354">
73
</page>
<figure confidence="0.9865106">
import rt
# Start new Realtime translator using a Spanish--English
# system and automatic, language-independent text normalization
# (pre-tokenization and post-detokenization)
translator = rt.RealtimeTranslator(’es-en.d’, tmpdir=’/tmp’, cache_size=5,
norm=True)
# Translate a sentence for user1
translation = translator.translate(’Muchas gracias Chris.’, ctx_name=’user1’)
# Learn from user1’s post-edited transaltion
translator.learn(’Muchas gracias Chris.’, ’Thank you so much, Chris.’,
ctx_name=’user1’)
# Save, free, and reload state for user1
translator.save_state(file_or_stringio=’user1.state’, ctx_name=’user1’)
translator.drop_ctx(ctx_name=’user1’)
translator.load_state(file_or_stringio=’user1.state’, ctx_name=’user1’)
</figure>
<figureCaption confidence="0.999947">
Figure 1: Sample code using the Realtime Python API to translate and learn from post-editing.
</figureCaption>
<bodyText confidence="0.999948666666667">
able online.2 Building an adaptive system begins
with the usual MT pipeline steps: word alignment,
bitext indexing (for suffix array grammar extrac-
tion), and standard n-gram language model esti-
mation. Additionally, the cpyp3 package, also
freely available, is used to estimate a Bayesian
n-gram language model on the target side of the
bitext. The cdec grammar extractor and dy-
namic language model implementations both in-
clude support for efficient inclusion of incremental
data, allowing optimization with simulated post-
editing to be parallelized. The resulting system,
optimized for post-editing, is then ready for de-
ployment with Realtime.
At runtime, a Realtime system operates as fol-
lows. A single instance of the indexed bitext is
loaded into memory for grammar extraction. Sin-
gle instances of the directional word alignment
models are loaded into memory for force-aligning
post-edited data. When a new user requests a
translation, a new context is started. The follow-
ing are loaded into memory: a table of all post-
edited data from the user, a user-specific dynamic
language model, and a user-specific decoder (in
this case an instance of MIRA that has a user-
specific decoder and set of weights). Each user
also requires an instance of the large static lan-
guage model, though all users effectively share a
single instance through the memory mapped im-
plementation of KenLM (Heafield, 2011). When a
</bodyText>
<footnote confidence="0.998264">
2http://www.cs.cmu.edu/mdenkows/
cdec-realtime.html
3https://github.com/redpony/cpyp
</footnote>
<bodyText confidence="0.999790230769231">
new sentence is to be translated, the grammar ex-
tractor samples from the shared background data
plus the user-specific post-editing data to generate
a sentence-specific grammar incorporating data
from all prior sentences translated by the same
user. The sentence is then decoded using the user
and time-specific grammar, current weights, and
current dynamic language model. When a post-
edited sentence is available as feedback, the fol-
lowing happen in order: (1) the source-reference
pair is used to update feature weights with MIRA,
(2) the source-reference pair is force-aligned and
added to the indexed post-editing data, and (3) the
dynamic language model is updated with the ref-
erence. User state (current weights and indexed
post-edited data for grammars and the language
model) can be saved and loaded, allowing mod-
els to be loaded and freed from memory as trans-
lators start and stop their work. Figure 1 shows
a minimal example of the above using the Real-
time package. While this paper describes integra-
tion with TransCenter, a tool primarily targeting
data collection and analysis, the Realtime Python
API allows straightforward integration with other
computer-assisted translation tools such as full-
featured translation workbench environments.
</bodyText>
<sectionHeader confidence="0.952635" genericHeader="method">
4 TransCenter: Web-Based Translation
Research Suite
</sectionHeader>
<bodyText confidence="0.9998955">
The TransCenter software (Denkowski and Lavie,
2012) dramatically lowers barriers in post-editing
data collection and increases the accuracy and de-
scriptiveness of the collected data. TransCenter
</bodyText>
<page confidence="0.998492">
74
</page>
<figureCaption confidence="0.999996">
Figure 2: Example of editing and rating machine translations with the TransCenter web interface.
Figure 3: Example TransCenter summary report for a single user on a document.
</figureCaption>
<bodyText confidence="0.999759965517241">
provides a web-based translation editing interface
that remotely monitors and records user activity.
The “live” version4 now uses cdec Realtime to
provide on-demand MT that automatically learns
from post-editor feedback. Translators use a web
browser to access a familiar two-column editing
environment (shown in Figure 2) from any com-
puter with an Internet connection. The left column
displays the source sentences, while the right col-
umn, initially empty, is incrementally populated
with translations from the Realtime system as the
user works. For each sentence, the translator ed-
its the MT output to be grammatically correct and
convey the same information as the source sen-
tence. During editing, all user actions (key presses
and mouse clicks) are logged so that the full edit-
ing process can be replayed and analyzed. After
editing, the final translation is reported to the Re-
altime system for learning and the next transla-
tion is generated. The user is additionally asked
to rate the amount of work required to post-edit
each sentence immediately after completing it,
yielding maximally accurate feedback. The rating
scale ranges from 5 (no post-editing required) to
1 (requires total re-translation). TransCenter also
records the number of seconds each sentence is
focused, allowing for exact timing measurements.
A pause button is available if the translator needs
to take breaks. TransCenter can generate reports
</bodyText>
<footnote confidence="0.8889685">
4https://github.com/mjdenkowski/
transcenter-live
</footnote>
<bodyText confidence="0.988471888888889">
of translator effort as measured by (1) keystroke,
(2) exact timing, and (3) actual translator post-
assessment. Final translations are also available
for calculating edit distance. Millisecond-level
timing of all user actions further facilitates time
sequence analysis of user actions and pauses. Fig-
ure 3 shows an example summary report gener-
ated by TransCenter showing a user’s activity on
each sentence in a document. This information
is also output in a simple comma-separated value
format for maximum interoperability with other
standards-compliant tools.
TransCenter automatically handles resource
management with Realtime. When a TransCenter
server is started, it loads a Realtime system with
zero contexts into memory. As users log in to work
on documents, new contexts are created to deliver
on-demand translations. As users finish work-
ing or take extended breaks, contexts automati-
cally time out and resources are freed. Translator
and document-specific state is automatically saved
when contexts time out and reloaded when transla-
tors resume work with built-in safeguards against
missing or duplicating any post-editing data due
to timeouts or Internet connectivity issues. This
allows any number of translators to work on trans-
lation tasks at their convenience.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.997291">
In a preliminary experiment to evaluate the impact
of adaptive MT in real-world post-editing scenar-
</bodyText>
<page confidence="0.99767">
75
</page>
<table confidence="0.992885333333333">
HTER Rating
Baseline 19.26 4.19
Adaptive 17.01 4.31
</table>
<tableCaption confidence="0.999261">
Table 1: Aggregate HTER scores and average
</tableCaption>
<bodyText confidence="0.972282418604651">
translator self-ratings (5 point scale) of post-
editing effort for translations of TED talks from
Spanish into English.
ios, we compare a static Spanish–English MT sys-
tem to a comparable adaptive system on a blind
out-of-domain test. Competitive with the current
state-of-the-art, both systems are trained on the
2012 NAACL WMT (Callison-Burch et al., 2012)
constrained resources (2 million bilingual sen-
tences) using the cdec toolkit (Dyer et al., 2010).
Blind post-editing evaluation sets are drawn from
the Web Inventory of Transcribed and Translated
Talks (WIT3) corpus (Cettolo et al., 2012) that
makes transcriptions of TED talks5 available in
several languages, including English and Spanish.
We select 4 excerpts from Spanish talk transcripts
(totaling 100 sentences) to be translated into En-
glish. Five students training to be professional
translators post-edit machine translations of these
excerpts using TransCenter. Translations are pro-
vided by either the static or fully adaptive system.
Tasks are divided such that each user translates
2 excerpts with the static system and 2 with the
adaptive system and each excerpt is post-edited ei-
ther 2 or 3 times with each system. Users do not
know which system is providing the translations.
Using the data collected by TransCenter, we
evaluate post-editing effort with the established
human-targeted translation edit rate (HTER) met-
ric (Snover et al., 2006). HTER computes an
edit distance score between initial MT outputs and
the “targeted” references created by human post-
editing, with lower scores being better. Results
for the two systems are aggregated over all users
and documents. Shown in Table 1, introducing
an adaptive MT system results in a significant re-
duction in editing effort. We additionally aver-
age the user post-ratings for each translation by
system to evaluate user perception of the adap-
tive system compared to the static baseline. Also
shown in Table 1, we see a slight preference for
the adaptive system. This data, as well as precise
keystroke, mouse click, and timing information is
</bodyText>
<footnote confidence="0.724333">
5http://www.ted.com/talks
</footnote>
<bodyText confidence="0.997237333333333">
made freely available for further analysis.6 Trans-
Center records all data necessary for more sophis-
ticated editing time analysis (Koehn, 2012) as well
as analysis of translator behavior, including pauses
(used as an indicator of cognitive effort) (Lacruz et
al., 2012).
</bodyText>
<sectionHeader confidence="0.999851" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999740294117647">
There has been a recent push for new computer-
aided translation (CAT) tools that leverage adap-
tive machine translation. The CASMACAT7
project (Alabau et al., 2013) focuses on building
state-of-the-art tools for computer-aided transla-
tion. This includes translation predictions backed
by machine translation systems that incrementally
update model parameters as users edit translations
(Martinez-G´omez et al., 2012; L´opez-Salcedo et
al., 2012). The MateCat8 project (Cattelan, 2013)
specifically aims to integrate machine translation
(including online model adaptation and translation
quality estimation) into a web-based CAT tool.
Bertoldi et al. (2013) show improvements in trans-
lator productivity when using the MateCat tool
with an adaptive MT system that uses cache-based
translation and language models.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999213777777778">
This paper describes the free, open source MT
post-editing setup provided by cdec Realtime
and TransCenter. All software and the data col-
lected for a preliminary post-editing experiment
are all freely available online. A live demon-
stration of adaptive MT post-editing powered by
Realtime and TransCenter is scheduled for the
2014 EACL Workshop on Humans and Computer-
assisted Translation (HaCaT 2014).
</bodyText>
<sectionHeader confidence="0.996504" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997746166666667">
This work is supported in part by the National Sci-
ence Foundation under grant IIS-0915327, by the
Qatar National Research Fund (a member of the
Qatar Foundation) under grant NPRP 09-1140-1-
177, and by the NSF-sponsored XSEDE program
under grant TG-CCR110017.
</bodyText>
<footnote confidence="0.9999815">
6www.cs.cmu.edu/˜mdenkows/
transcenter-round1.tar.gz
7http://casmacat.eu/
8http://www.matecat.com/
</footnote>
<page confidence="0.986581">
76
</page>
<sectionHeader confidence="0.996152" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999809737864078">
Vicent Alabau, Ragnar Bonk, Christian Buck, Michael
Carl, Francisco Casacuberta, Mercedes Garcfa-
Martfnez, Jes´us Gonz´alez-Rubio, Philipp Koehn,
Luis A. Leiva, Bartolom´e Mesa-Lao, Daniel Ortiz-
Martfnez, Herv´e Saint-Amand, Germ´an Sanchis-
Trilles, and Chara Tsoukala. 2013. Casmacat:
An open source workbench for advanced computer
aided translation. In The Prague Bulletin of Mathe-
matical Linguistics, pages 101–112.
Nicola Bertoldi, Mauro Cettolo, and Marcello Fed-
erico. 2013. Cache-based online adaptation for ma-
chine translation enhanced computer assisted trans-
lation. In Proceedings of the XIV Machine Transla-
tion Summit, pages 35–42.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical ma-
chine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, pages
10–51, Montr´eal, Canada, June. Association for
Computational Linguistics.
Alessandro Cattelan. 2013. Second version of Mate-
Cat tool. Deliverable 4.2.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. Wit3: Web inventory of transcribed
and translated talks. In Proceedings of the Sixteenth
Annual Conference of the European Association for
Machine Translation.
Victor Chahuneau, Noah A. Smith, and Chris Dyer.
2012. pycdec: A python interface to cdec. The
Prague Bulletin ofMathematical Linguistics, 98:51–
61.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics, 33.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. Journal of Machine
Learning Research, pages 551–558, March.
Michael Denkowski and Alon Lavie. 2012. Trans-
Center: Web-based translation research suite. In
AMTA 2012 Workshop on Post-Editing Technology
and Practice Demo Session.
Michael Denkowski, Chris Dyer, and Alon Lavie.
2014. Learning from post-editing: Online model
adaptation for statistical machine translation. In
Proceedings of the 14th Conference of the European
Chapter of the Association for Computational Lin-
guistics.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Seti-
awan, Vladimir Eidelman, and Philip Resnik. 2010.
cdec: A decoder, alignment, and learning framework
for finite-state and context-free translation models.
In Proceedings of the ACL 2010 System Demonstra-
tions, pages 7–12, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Vladimir Eidelman. 2012. Optimization strategies for
online large-margin learning in machine translation.
In Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 480–489, Montr´eal,
Canada, June. Association for Computational Lin-
guistics.
Daniel Hardt and Jakob Elming. 2010. Incremental
re-training for post-editing smt. In Proceedings of
the Ninth Conference of the Association for Machine
Translation in the Americas.
Kenneth Heafield. 2011. KenLM: faster and smaller
language model queries. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
187–197, Edinburgh, Scotland, United Kingdom,
July.
Philipp Koehn. 2012. Computer-aided translation.
Machine Translation Marathon.
Isabel Lacruz, Gregory M. Shreve, and Erik Angelone.
2012. Average Pause Ratio as an Indicator of Cogni-
tive Effort in Post-Editing: A Case Study. In AMTA
2012 Workshop on Post-Editing Technology and
Practice (WPTP 2012), pages 21–30, San Diego,
USA, October. Association for Machine Translation
in the Americas (AMTA).
Adam Lopez. 2008. Machine translation by pattern
matching. In Dissertation, University of Maryland,
March.
Francisco-Javier L´opez-Salcedo, Germ´an Sanchis-
Trilles, and Francisco Casacuberta. 2012. On-
line learning of log-linear weights in interactive ma-
chine translation. Advances in Speech and Lan-
guage Technologies for Iberian Languages, pages
277–286.
Pascual Martfnez-G´omez, Germ´an Sanchis-Trilles, and
Francisco Casacuberta. 2012. Online adaptation
strategies for statistical machine translation in post-
editing scenarios. Pattern Recognition, 45:3193–
3203.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study
of translation edit rate with targeted human annota-
tion. In Proceedings of the 7th Conference of the.
Association for Machine Translation of the Ameri-
cas, pages 223–231.
Yee Whye Teh. 2006. A hierarchical Bayesian lan-
guage model based on Pitman-Yor processes. In
Proc. of ACL.
</reference>
<page confidence="0.999128">
77
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.259402">
<title confidence="0.9415505">Real Time Adaptive Machine Translation for Post-Editing TransCenter</title>
<author confidence="0.701343">Denkowski Alon Lavie Isabel Chris</author>
<address confidence="0.473108">Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA 15213 for Applied Linguistics, Kent State University, Kent, OH 44242</address>
<email confidence="0.991686">ilacruz@kent.edu</email>
<abstract confidence="0.999041947368421">Using machine translation output as a starting point for human translation has recently gained traction in the translation community. This paper describes a framework for building adaptive MT systems that learn from post-editor feedback, and TransCenter, a web-based translation interface that connects users to Realtime systems and logs post-editing activity. This combination allows the straightforward deployment of MT systems specifically for post-editing and analysis of human translator productivity when working with these systems. All tools, as well as actual post-editing data collected as part of a validation experiment, are freely available under an open source license.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Vicent Alabau</author>
<author>Ragnar Bonk</author>
<author>Christian Buck</author>
<author>Michael Carl</author>
<author>Francisco Casacuberta</author>
<author>Mercedes GarcfaMartfnez</author>
<author>Jes´us Gonz´alez-Rubio</author>
<author>Philipp Koehn</author>
<author>Luis A Leiva</author>
</authors>
<title>Bartolom´e Mesa-Lao, Daniel OrtizMartfnez, Herv´e Saint-Amand, Germ´an SanchisTrilles, and Chara Tsoukala.</title>
<date>2013</date>
<booktitle>In The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>101--112</pages>
<marker>Alabau, Bonk, Buck, Carl, Casacuberta, GarcfaMartfnez, Gonz´alez-Rubio, Koehn, Leiva, 2013</marker>
<rawString>Vicent Alabau, Ragnar Bonk, Christian Buck, Michael Carl, Francisco Casacuberta, Mercedes GarcfaMartfnez, Jes´us Gonz´alez-Rubio, Philipp Koehn, Luis A. Leiva, Bartolom´e Mesa-Lao, Daniel OrtizMartfnez, Herv´e Saint-Amand, Germ´an SanchisTrilles, and Chara Tsoukala. 2013. Casmacat: An open source workbench for advanced computer aided translation. In The Prague Bulletin of Mathematical Linguistics, pages 101–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>Cache-based online adaptation for machine translation enhanced computer assisted translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the XIV Machine Translation Summit,</booktitle>
<pages>35--42</pages>
<contexts>
<context position="18716" citStr="Bertoldi et al. (2013)" startWordPosition="2783" endWordPosition="2786"> new computeraided translation (CAT) tools that leverage adaptive machine translation. The CASMACAT7 project (Alabau et al., 2013) focuses on building state-of-the-art tools for computer-aided translation. This includes translation predictions backed by machine translation systems that incrementally update model parameters as users edit translations (Martinez-G´omez et al., 2012; L´opez-Salcedo et al., 2012). The MateCat8 project (Cattelan, 2013) specifically aims to integrate machine translation (including online model adaptation and translation quality estimation) into a web-based CAT tool. Bertoldi et al. (2013) show improvements in translator productivity when using the MateCat tool with an adaptive MT system that uses cache-based translation and language models. 7 Conclusion This paper describes the free, open source MT post-editing setup provided by cdec Realtime and TransCenter. All software and the data collected for a preliminary post-editing experiment are all freely available online. A live demonstration of adaptive MT post-editing powered by Realtime and TransCenter is scheduled for the 2014 EACL Workshop on Humans and Computerassisted Translation (HaCaT 2014). Acknowledgements This work is </context>
</contexts>
<marker>Bertoldi, Cettolo, Federico, 2013</marker>
<rawString>Nicola Bertoldi, Mauro Cettolo, and Marcello Federico. 2013. Cache-based online adaptation for machine translation enhanced computer assisted translation. In Proceedings of the XIV Machine Translation Summit, pages 35–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<title>Findings of the 2012 workshop on statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>10--51</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="16041" citStr="Callison-Burch et al., 2012" startWordPosition="2380" endWordPosition="2383">anslators to work on translation tasks at their convenience. 5 Experiments In a preliminary experiment to evaluate the impact of adaptive MT in real-world post-editing scenar75 HTER Rating Baseline 19.26 4.19 Adaptive 17.01 4.31 Table 1: Aggregate HTER scores and average translator self-ratings (5 point scale) of postediting effort for translations of TED talks from Spanish into English. ios, we compare a static Spanish–English MT system to a comparable adaptive system on a blind out-of-domain test. Competitive with the current state-of-the-art, both systems are trained on the 2012 NAACL WMT (Callison-Burch et al., 2012) constrained resources (2 million bilingual sentences) using the cdec toolkit (Dyer et al., 2010). Blind post-editing evaluation sets are drawn from the Web Inventory of Transcribed and Translated Talks (WIT3) corpus (Cettolo et al., 2012) that makes transcriptions of TED talks5 available in several languages, including English and Spanish. We select 4 excerpts from Spanish talk transcripts (totaling 100 sentences) to be translated into English. Five students training to be professional translators post-edit machine translations of these excerpts using TransCenter. Translations are provided by</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Post, Soricut, Specia, 2012</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012. Findings of the 2012 workshop on statistical machine translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 10–51, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Cattelan</author>
</authors>
<title>Second version of MateCat tool.</title>
<date>2013</date>
<journal>Deliverable</journal>
<volume>4</volume>
<contexts>
<context position="18544" citStr="Cattelan, 2013" startWordPosition="2762" endWordPosition="2763">s analysis of translator behavior, including pauses (used as an indicator of cognitive effort) (Lacruz et al., 2012). 6 Related Work There has been a recent push for new computeraided translation (CAT) tools that leverage adaptive machine translation. The CASMACAT7 project (Alabau et al., 2013) focuses on building state-of-the-art tools for computer-aided translation. This includes translation predictions backed by machine translation systems that incrementally update model parameters as users edit translations (Martinez-G´omez et al., 2012; L´opez-Salcedo et al., 2012). The MateCat8 project (Cattelan, 2013) specifically aims to integrate machine translation (including online model adaptation and translation quality estimation) into a web-based CAT tool. Bertoldi et al. (2013) show improvements in translator productivity when using the MateCat tool with an adaptive MT system that uses cache-based translation and language models. 7 Conclusion This paper describes the free, open source MT post-editing setup provided by cdec Realtime and TransCenter. All software and the data collected for a preliminary post-editing experiment are all freely available online. A live demonstration of adaptive MT post</context>
</contexts>
<marker>Cattelan, 2013</marker>
<rawString>Alessandro Cattelan. 2013. Second version of MateCat tool. Deliverable 4.2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Christian Girardi</author>
<author>Marcello Federico</author>
</authors>
<title>Wit3: Web inventory of transcribed and translated talks.</title>
<date>2012</date>
<booktitle>In Proceedings of the Sixteenth Annual Conference of the European Association for Machine Translation.</booktitle>
<contexts>
<context position="16280" citStr="Cettolo et al., 2012" startWordPosition="2416" endWordPosition="2419">e HTER scores and average translator self-ratings (5 point scale) of postediting effort for translations of TED talks from Spanish into English. ios, we compare a static Spanish–English MT system to a comparable adaptive system on a blind out-of-domain test. Competitive with the current state-of-the-art, both systems are trained on the 2012 NAACL WMT (Callison-Burch et al., 2012) constrained resources (2 million bilingual sentences) using the cdec toolkit (Dyer et al., 2010). Blind post-editing evaluation sets are drawn from the Web Inventory of Transcribed and Translated Talks (WIT3) corpus (Cettolo et al., 2012) that makes transcriptions of TED talks5 available in several languages, including English and Spanish. We select 4 excerpts from Spanish talk transcripts (totaling 100 sentences) to be translated into English. Five students training to be professional translators post-edit machine translations of these excerpts using TransCenter. Translations are provided by either the static or fully adaptive system. Tasks are divided such that each user translates 2 excerpts with the static system and 2 with the adaptive system and each excerpt is post-edited either 2 or 3 times with each system. Users do n</context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012. Wit3: Web inventory of transcribed and translated talks. In Proceedings of the Sixteenth Annual Conference of the European Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
<author>Chris Dyer</author>
</authors>
<title>pycdec: A python interface to cdec. The Prague Bulletin ofMathematical Linguistics,</title>
<date>2012</date>
<pages>98--51</pages>
<contexts>
<context position="4281" citStr="Chahuneau et al., 2012" startWordPosition="629" endWordPosition="632">dated to include post-edited target language text. • An online update is made to the system’s feature weights after each sentence is postedited. 72 Workshop on Humans and Computer-assisted Translation, pages 72–77, Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics These extensions allow the MT system to generate improved translations that require significantly less effort to correct for later sentences in the document. This paradigm is now implemented in the freely available cdec (Dyer et al., 2010) machine translation toolkit as Realtime, part of the pycdec (Chahuneau et al., 2012) Python API. Standard MT systems use aggregate statistics from all training text to learn a single large translation grammar (in the case of cdec’s hierarchical phrase-based model (Chiang, 2007), a synchronous context-free grammar) consisting of rules annotated with feature scores. As an alternative, the bitext can be indexed using a suffix array (Lopez, 2008), a data structure allowing fast source-side lookups. When a new sentence is to be translated, training sentences that share spans of text with the input sentence are sampled from the suffix array. Statistics from the sample are used to l</context>
</contexts>
<marker>Chahuneau, Smith, Dyer, 2012</marker>
<rawString>Victor Chahuneau, Noah A. Smith, and Chris Dyer. 2012. pycdec: A python interface to cdec. The Prague Bulletin ofMathematical Linguistics, 98:51– 61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<contexts>
<context position="4475" citStr="Chiang, 2007" startWordPosition="661" endWordPosition="662">ges 72–77, Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics These extensions allow the MT system to generate improved translations that require significantly less effort to correct for later sentences in the document. This paradigm is now implemented in the freely available cdec (Dyer et al., 2010) machine translation toolkit as Realtime, part of the pycdec (Chahuneau et al., 2012) Python API. Standard MT systems use aggregate statistics from all training text to learn a single large translation grammar (in the case of cdec’s hierarchical phrase-based model (Chiang, 2007), a synchronous context-free grammar) consisting of rules annotated with feature scores. As an alternative, the bitext can be indexed using a suffix array (Lopez, 2008), a data structure allowing fast source-side lookups. When a new sentence is to be translated, training sentences that share spans of text with the input sentence are sampled from the suffix array. Statistics from the sample are used to learn a small, sentence-specific grammar on-thefly. The adaptive paradigm extends this approach to support online updates by also indexing the new bilingual sentences generated as a post-editor w</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>551--558</pages>
<contexts>
<context position="6643" citStr="Crammer et al., 2006" startWordPosition="1000" endWordPosition="1003">es two language models. A standard (static) n-gram language model estimated on large monolingual text allows the system to prefer translations more similar to humangenerated text in the target language. A (dynamic) Bayesian n-gram language model (Teh, 2006) can be updated with observations of the post-edited output in a straightforward way. This smaller model exactly covers the training bitext and all post-editing data, letting the system upweight translations with newly learned vocabulary and phrasing absent in the large monolingual text. Finally, the margin-infused relaxed algorithm (MIRA) (Crammer et al., 2006; Eidelman, 2012) is used to make an online parameter update after each sentence is post-edited, minimizing model error. This allows the system to continuously rescale weights for translation and language model features that adapt over time. Since true post-editing data is infeasible to collect during system development and internal testing, as standard MT pipelines require tens of thousands of sentences to be translated with low latency, a simulated post-editing paradigm (Hardt and Elming, 2010) can be used, wherein pregenerated reference translations act as a stand-in for actual post-editing</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. Journal of Machine Learning Research, pages 551–558, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>TransCenter: Web-based translation research suite.</title>
<date>2012</date>
<booktitle>In AMTA 2012 Workshop on Post-Editing Technology and Practice Demo Session.</booktitle>
<contexts>
<context position="12407" citStr="Denkowski and Lavie, 2012" startWordPosition="1834" endWordPosition="1837">ost-edited data for grammars and the language model) can be saved and loaded, allowing models to be loaded and freed from memory as translators start and stop their work. Figure 1 shows a minimal example of the above using the Realtime package. While this paper describes integration with TransCenter, a tool primarily targeting data collection and analysis, the Realtime Python API allows straightforward integration with other computer-assisted translation tools such as fullfeatured translation workbench environments. 4 TransCenter: Web-Based Translation Research Suite The TransCenter software (Denkowski and Lavie, 2012) dramatically lowers barriers in post-editing data collection and increases the accuracy and descriptiveness of the collected data. TransCenter 74 Figure 2: Example of editing and rating machine translations with the TransCenter web interface. Figure 3: Example TransCenter summary report for a single user on a document. provides a web-based translation editing interface that remotely monitors and records user activity. The “live” version4 now uses cdec Realtime to provide on-demand MT that automatically learns from post-editor feedback. Translators use a web browser to access a familiar two-co</context>
</contexts>
<marker>Denkowski, Lavie, 2012</marker>
<rawString>Michael Denkowski and Alon Lavie. 2012. TransCenter: Web-based translation research suite. In AMTA 2012 Workshop on Post-Editing Technology and Practice Demo Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
</authors>
<title>Learning from post-editing: Online model adaptation for statistical machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3382" citStr="Denkowski et al., 2014" startWordPosition="489" endWordPosition="492">his validation experiment is also publicly available. 2 Adaptive Machine Translation Traditional machine translation systems operate in batch mode: statistical translation models are estimated from large volumes of sentence-parallel bilingual text and then used to translate new text. Incorporating new data requires a full system rebuild, an expensive operation taking up to days of time. As such, MT systems in production scenarios typically remain static for large periods of time (months or even indefinitely). Recently, an adaptive MT paradigm has been introduced specifically for post-editing (Denkowski et al., 2014). Three major MT system components are extended to support online updates, allowing human posteditor feedback to be immediately incorporated: • An online translation model is updated to include new translations extracted from postediting data. • A dynamic language model is updated to include post-edited target language text. • An online update is made to the system’s feature weights after each sentence is postedited. 72 Workshop on Humans and Computer-assisted Translation, pages 72–77, Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics These extensions allow th</context>
</contexts>
<marker>Denkowski, Dyer, Lavie, 2014</marker>
<rawString>Michael Denkowski, Chris Dyer, and Alon Lavie. 2014. Learning from post-editing: Online model adaptation for statistical machine translation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Adam Lopez</author>
<author>Juri Ganitkevitch</author>
<author>Jonathan Weese</author>
<author>Ferhan Ture</author>
<author>Phil Blunsom</author>
<author>Hendra Setiawan</author>
<author>Vladimir Eidelman</author>
<author>Philip Resnik</author>
</authors>
<title>cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models.</title>
<date>2010</date>
<contexts>
<context position="4196" citStr="Dyer et al., 2010" startWordPosition="615" endWordPosition="618">w translations extracted from postediting data. • A dynamic language model is updated to include post-edited target language text. • An online update is made to the system’s feature weights after each sentence is postedited. 72 Workshop on Humans and Computer-assisted Translation, pages 72–77, Gothenburg, Sweden, 26 April 2014. c�2014 Association for Computational Linguistics These extensions allow the MT system to generate improved translations that require significantly less effort to correct for later sentences in the document. This paradigm is now implemented in the freely available cdec (Dyer et al., 2010) machine translation toolkit as Realtime, part of the pycdec (Chahuneau et al., 2012) Python API. Standard MT systems use aggregate statistics from all training text to learn a single large translation grammar (in the case of cdec’s hierarchical phrase-based model (Chiang, 2007), a synchronous context-free grammar) consisting of rules annotated with feature scores. As an alternative, the bitext can be indexed using a suffix array (Lopez, 2008), a data structure allowing fast source-side lookups. When a new sentence is to be translated, training sentences that share spans of text with the input</context>
<context position="8392" citStr="Dyer et al., 2010" startWordPosition="1274" endWordPosition="1277">sing word-alignment models learned from the initial data and used to update the translation grammar. Third, the reference is added to the Bayesian language model. As sentences are translated, the models gain valuable context information, allowing them to adapt to the specific target document and translator. Context is reset at the start of each development or test corpus. Systems optimized with simulated post-editing can then be deployed to serve real human translators without further modification. 3 cdec Realtime Now included as part of the free, open source cdec machine translation toolkit (Dyer et al., 2010), Realtime1 provides an efficient implementation of the adaptive MT paradigm that can serve an arbitrary number of unique post-editors concurrently. A full Realtime tutorial, including stepby-step instructions for installing required software and building full adaptive systems, is avail1https://github.com/redpony/cdec/tree/ master/realtime 73 import rt # Start new Realtime translator using a Spanish--English # system and automatic, language-independent text normalization # (pre-tokenization and post-detokenization) translator = rt.RealtimeTranslator(’es-en.d’, tmpdir=’/tmp’, cache_size=5, norm</context>
<context position="16138" citStr="Dyer et al., 2010" startWordPosition="2395" endWordPosition="2398">valuate the impact of adaptive MT in real-world post-editing scenar75 HTER Rating Baseline 19.26 4.19 Adaptive 17.01 4.31 Table 1: Aggregate HTER scores and average translator self-ratings (5 point scale) of postediting effort for translations of TED talks from Spanish into English. ios, we compare a static Spanish–English MT system to a comparable adaptive system on a blind out-of-domain test. Competitive with the current state-of-the-art, both systems are trained on the 2012 NAACL WMT (Callison-Burch et al., 2012) constrained resources (2 million bilingual sentences) using the cdec toolkit (Dyer et al., 2010). Blind post-editing evaluation sets are drawn from the Web Inventory of Transcribed and Translated Talks (WIT3) corpus (Cettolo et al., 2012) that makes transcriptions of TED talks5 available in several languages, including English and Spanish. We select 4 excerpts from Spanish talk transcripts (totaling 100 sentences) to be translated into English. Five students training to be professional translators post-edit machine translations of these excerpts using TransCenter. Translations are provided by either the static or fully adaptive system. Tasks are divided such that each user translates 2 e</context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models.</rawString>
</citation>
<citation valid="true">
<date></date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations,</booktitle>
<pages>7--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker></marker>
<rawString>In Proceedings of the ACL 2010 System Demonstrations, pages 7–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Eidelman</author>
</authors>
<title>Optimization strategies for online large-margin learning in machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>480--489</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="6660" citStr="Eidelman, 2012" startWordPosition="1004" endWordPosition="1005">. A standard (static) n-gram language model estimated on large monolingual text allows the system to prefer translations more similar to humangenerated text in the target language. A (dynamic) Bayesian n-gram language model (Teh, 2006) can be updated with observations of the post-edited output in a straightforward way. This smaller model exactly covers the training bitext and all post-editing data, letting the system upweight translations with newly learned vocabulary and phrasing absent in the large monolingual text. Finally, the margin-infused relaxed algorithm (MIRA) (Crammer et al., 2006; Eidelman, 2012) is used to make an online parameter update after each sentence is post-edited, minimizing model error. This allows the system to continuously rescale weights for translation and language model features that adapt over time. Since true post-editing data is infeasible to collect during system development and internal testing, as standard MT pipelines require tens of thousands of sentences to be translated with low latency, a simulated post-editing paradigm (Hardt and Elming, 2010) can be used, wherein pregenerated reference translations act as a stand-in for actual post-editing. This approximat</context>
</contexts>
<marker>Eidelman, 2012</marker>
<rawString>Vladimir Eidelman. 2012. Optimization strategies for online large-margin learning in machine translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 480–489, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
<author>Jakob Elming</author>
</authors>
<title>Incremental re-training for post-editing smt.</title>
<date>2010</date>
<booktitle>In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="7144" citStr="Hardt and Elming, 2010" startWordPosition="1080" endWordPosition="1083"> phrasing absent in the large monolingual text. Finally, the margin-infused relaxed algorithm (MIRA) (Crammer et al., 2006; Eidelman, 2012) is used to make an online parameter update after each sentence is post-edited, minimizing model error. This allows the system to continuously rescale weights for translation and language model features that adapt over time. Since true post-editing data is infeasible to collect during system development and internal testing, as standard MT pipelines require tens of thousands of sentences to be translated with low latency, a simulated post-editing paradigm (Hardt and Elming, 2010) can be used, wherein pregenerated reference translations act as a stand-in for actual post-editing. This approximation is effective for tuning and internal evaluation when real post-editing data is unavailable. In simulated post-editing tasks, decoding (for both the test corpus and each pass over the development corpus during optimization) begins with baseline models trained on standard bilingual and monolingual text. After each sentence is translated, the following take place in order: First, MIRA uses the new source–reference pair to update weights for the current models. Second, the source</context>
</contexts>
<marker>Hardt, Elming, 2010</marker>
<rawString>Daniel Hardt and Jakob Elming. 2010. Incremental re-training for post-editing smt. In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<location>Edinburgh, Scotland, United Kingdom,</location>
<contexts>
<context position="10955" citStr="Heafield, 2011" startWordPosition="1625" endWordPosition="1626"> Single instances of the directional word alignment models are loaded into memory for force-aligning post-edited data. When a new user requests a translation, a new context is started. The following are loaded into memory: a table of all postedited data from the user, a user-specific dynamic language model, and a user-specific decoder (in this case an instance of MIRA that has a userspecific decoder and set of weights). Each user also requires an instance of the large static language model, though all users effectively share a single instance through the memory mapped implementation of KenLM (Heafield, 2011). When a 2http://www.cs.cmu.edu/mdenkows/ cdec-realtime.html 3https://github.com/redpony/cpyp new sentence is to be translated, the grammar extractor samples from the shared background data plus the user-specific post-editing data to generate a sentence-specific grammar incorporating data from all prior sentences translated by the same user. The sentence is then decoded using the user and time-specific grammar, current weights, and current dynamic language model. When a postedited sentence is available as feedback, the following happen in order: (1) the source-reference pair is used to update</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, United Kingdom, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Computer-aided translation. Machine Translation Marathon.</title>
<date>2012</date>
<contexts>
<context position="17919" citStr="Koehn, 2012" startWordPosition="2673" endWordPosition="2674"> users and documents. Shown in Table 1, introducing an adaptive MT system results in a significant reduction in editing effort. We additionally average the user post-ratings for each translation by system to evaluate user perception of the adaptive system compared to the static baseline. Also shown in Table 1, we see a slight preference for the adaptive system. This data, as well as precise keystroke, mouse click, and timing information is 5http://www.ted.com/talks made freely available for further analysis.6 TransCenter records all data necessary for more sophisticated editing time analysis (Koehn, 2012) as well as analysis of translator behavior, including pauses (used as an indicator of cognitive effort) (Lacruz et al., 2012). 6 Related Work There has been a recent push for new computeraided translation (CAT) tools that leverage adaptive machine translation. The CASMACAT7 project (Alabau et al., 2013) focuses on building state-of-the-art tools for computer-aided translation. This includes translation predictions backed by machine translation systems that incrementally update model parameters as users edit translations (Martinez-G´omez et al., 2012; L´opez-Salcedo et al., 2012). The MateCat8</context>
</contexts>
<marker>Koehn, 2012</marker>
<rawString>Philipp Koehn. 2012. Computer-aided translation. Machine Translation Marathon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Lacruz</author>
<author>Gregory M Shreve</author>
<author>Erik Angelone</author>
</authors>
<title>Average Pause Ratio as an Indicator of Cognitive Effort in Post-Editing: A Case Study.</title>
<date>2012</date>
<booktitle>In AMTA 2012 Workshop on Post-Editing Technology and Practice (WPTP 2012),</booktitle>
<pages>21--30</pages>
<location>San Diego, USA,</location>
<contexts>
<context position="18045" citStr="Lacruz et al., 2012" startWordPosition="2691" endWordPosition="2694">g effort. We additionally average the user post-ratings for each translation by system to evaluate user perception of the adaptive system compared to the static baseline. Also shown in Table 1, we see a slight preference for the adaptive system. This data, as well as precise keystroke, mouse click, and timing information is 5http://www.ted.com/talks made freely available for further analysis.6 TransCenter records all data necessary for more sophisticated editing time analysis (Koehn, 2012) as well as analysis of translator behavior, including pauses (used as an indicator of cognitive effort) (Lacruz et al., 2012). 6 Related Work There has been a recent push for new computeraided translation (CAT) tools that leverage adaptive machine translation. The CASMACAT7 project (Alabau et al., 2013) focuses on building state-of-the-art tools for computer-aided translation. This includes translation predictions backed by machine translation systems that incrementally update model parameters as users edit translations (Martinez-G´omez et al., 2012; L´opez-Salcedo et al., 2012). The MateCat8 project (Cattelan, 2013) specifically aims to integrate machine translation (including online model adaptation and translatio</context>
</contexts>
<marker>Lacruz, Shreve, Angelone, 2012</marker>
<rawString>Isabel Lacruz, Gregory M. Shreve, and Erik Angelone. 2012. Average Pause Ratio as an Indicator of Cognitive Effort in Post-Editing: A Case Study. In AMTA 2012 Workshop on Post-Editing Technology and Practice (WPTP 2012), pages 21–30, San Diego, USA, October. Association for Machine Translation in the Americas (AMTA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Machine translation by pattern matching.</title>
<date>2008</date>
<institution>In Dissertation, University of Maryland,</institution>
<contexts>
<context position="4643" citStr="Lopez, 2008" startWordPosition="688" endWordPosition="689">t require significantly less effort to correct for later sentences in the document. This paradigm is now implemented in the freely available cdec (Dyer et al., 2010) machine translation toolkit as Realtime, part of the pycdec (Chahuneau et al., 2012) Python API. Standard MT systems use aggregate statistics from all training text to learn a single large translation grammar (in the case of cdec’s hierarchical phrase-based model (Chiang, 2007), a synchronous context-free grammar) consisting of rules annotated with feature scores. As an alternative, the bitext can be indexed using a suffix array (Lopez, 2008), a data structure allowing fast source-side lookups. When a new sentence is to be translated, training sentences that share spans of text with the input sentence are sampled from the suffix array. Statistics from the sample are used to learn a small, sentence-specific grammar on-thefly. The adaptive paradigm extends this approach to support online updates by also indexing the new bilingual sentences generated as a post-editor works. When a new sentence is translated, matching sentences are sampled from the post-editing data as well as the suffix array. All feature scores that can be computed </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Adam Lopez. 2008. Machine translation by pattern matching. In Dissertation, University of Maryland, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco-Javier L´opez-Salcedo</author>
<author>Germ´an SanchisTrilles</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online learning of log-linear weights in interactive machine translation.</title>
<date>2012</date>
<booktitle>Advances in Speech and Language Technologies for Iberian Languages,</booktitle>
<pages>277--286</pages>
<marker>L´opez-Salcedo, SanchisTrilles, Casacuberta, 2012</marker>
<rawString>Francisco-Javier L´opez-Salcedo, Germ´an SanchisTrilles, and Francisco Casacuberta. 2012. Online learning of log-linear weights in interactive machine translation. Advances in Speech and Language Technologies for Iberian Languages, pages 277–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascual Martfnez-G´omez</author>
<author>Germ´an Sanchis-Trilles</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online adaptation strategies for statistical machine translation in postediting scenarios. Pattern Recognition,</title>
<date>2012</date>
<volume>45</volume>
<pages>3203</pages>
<marker>Martfnez-G´omez, Sanchis-Trilles, Casacuberta, 2012</marker>
<rawString>Pascual Martfnez-G´omez, Germ´an Sanchis-Trilles, and Francisco Casacuberta. 2012. Online adaptation strategies for statistical machine translation in postediting scenarios. Pattern Recognition, 45:3193– 3203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the. Association for Machine Translation of the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="17098" citStr="Snover et al., 2006" startWordPosition="2542" endWordPosition="2545">nto English. Five students training to be professional translators post-edit machine translations of these excerpts using TransCenter. Translations are provided by either the static or fully adaptive system. Tasks are divided such that each user translates 2 excerpts with the static system and 2 with the adaptive system and each excerpt is post-edited either 2 or 3 times with each system. Users do not know which system is providing the translations. Using the data collected by TransCenter, we evaluate post-editing effort with the established human-targeted translation edit rate (HTER) metric (Snover et al., 2006). HTER computes an edit distance score between initial MT outputs and the “targeted” references created by human postediting, with lower scores being better. Results for the two systems are aggregated over all users and documents. Shown in Table 1, introducing an adaptive MT system results in a significant reduction in editing effort. We additionally average the user post-ratings for each translation by system to evaluate user perception of the adaptive system compared to the static baseline. Also shown in Table 1, we see a slight preference for the adaptive system. This data, as well as preci</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the. Association for Machine Translation of the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
</authors>
<title>A hierarchical Bayesian language model based on Pitman-Yor processes.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="6280" citStr="Teh, 2006" startWordPosition="948" endWordPosition="949">ng-aware feature sets; any feature that can be computed from standard text can be added to the model and will automatically include postediting data. Implementationally, feature scoring is broken out into a single Python source file containing a single function for each feature score. New feature functions can be added easily. The adaptive paradigm uses two language models. A standard (static) n-gram language model estimated on large monolingual text allows the system to prefer translations more similar to humangenerated text in the target language. A (dynamic) Bayesian n-gram language model (Teh, 2006) can be updated with observations of the post-edited output in a straightforward way. This smaller model exactly covers the training bitext and all post-editing data, letting the system upweight translations with newly learned vocabulary and phrasing absent in the large monolingual text. Finally, the margin-infused relaxed algorithm (MIRA) (Crammer et al., 2006; Eidelman, 2012) is used to make an online parameter update after each sentence is post-edited, minimizing model error. This allows the system to continuously rescale weights for translation and language model features that adapt over t</context>
</contexts>
<marker>Teh, 2006</marker>
<rawString>Yee Whye Teh. 2006. A hierarchical Bayesian language model based on Pitman-Yor processes. In Proc. of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>