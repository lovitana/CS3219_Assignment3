<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.152550">
<title confidence="0.99556">
Latent User Models for Online River Information Tailoring
</title>
<author confidence="0.997915">
Xiwu Han1, Somayajulu Sripada1, Kit (CJA) Macleod2, and Antonio A. R. Ioris3
</author>
<affiliation confidence="0.977962666666667">
Department of Computing Sciences, University of Aberdeen, UK1
James Hutton Institute, Aberdeen; University of Exeter, Exeter, UK2
School of GeoSciences, University of Edinburgh, UK3
</affiliation>
<email confidence="0.993683666666667">
{xiwuhan,yaji.sripada}@abdn.ac.uk
kit.macleod@hutton.ac.uk
a.ioris@ed.ac.uk
</email>
<sectionHeader confidence="0.993807" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999424230769231">
This paper explores Natural Language Genera-
tion techniques for online river information
tailoring. To solve the problem of unknown
users, we propose ‘latent models’, which relate
typical visitors to river web pages, river data
types, and river related activities. A hierarchy
is used to integrate domain knowledge and la-
tent user knowledge, and serves as the search
space for content selection, which triggers us-
er-oriented selection rules when they visit a
page. Initial feedback received from user
groups indicates that the latent models deserve
further research efforts.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975843137255">
Within recent decades, access to online river in-
formation has increased exponentially thanks to
great progresses in data collection and storage
technologies employed by hydrological organiza-
tions worldwide (Dixon, 2010). Local residents
nearby rivers and those engaged in river related
activities are now much better informed and
more engaged with data providers than decades
ago. However, organizations such as SEPA
(Scottish Environment Protection Agency), CEH
(Centre for Ecology and Hydrology), EA (Envi-
ronment Agency) in UK, and quite a few Cana-
dian and Australian ones are working to improve
the presentation of river information further.
Many of these data providers, who are mostly
government agencies, provide descriptive texts
along with archived data of flow, level, flood and
temperature along with their graphs and/or ta-
bles. A typical example of linguistic description
from the EA website is shown below:
The river level at Morwick is 0.65 me-
tres. This measurement was recorded at
08:45 on 23/01/2013. The typical river
level range for this location is between
0.27 metres and 2.60 metres. The highest
river level recorded at this location is 6.32
metres and the river level reached 6.32 me-
tres on 07/09/2008.1
The above descriptive text could vary to some
extent according to different river users. For in-
stance, it may provide information perceived as
good news by farmers whilst other users e.g. ca-
noeists or paddlers may interpret the information
as bad news for their activity. Such tailored in-
formation provision promotes communication
efficiency between stakeholders and the relevant
government offices (Macleod et al., 2012). We
explored data-to-text techniques (Reiter, 2007) in
promoting online river information provision.
Our engagement activities with river stakehold-
ers showed that there could be great difficulties
in specifying user groups for online river infor-
mation tailoring. First, the relations between do-
main knowledge and user knowledge are difficult
to be acquired due to domain sensitive challeng-
es. Second, for online communication, the issue
that users themselves sometimes are not sure
about their tasks further hinders user modeling.
This paper proposes an alternative approach of
latent user models, instead of directly asking us-
ers to indicate what they are interested in.
</bodyText>
<sectionHeader confidence="0.950568" genericHeader="method">
2 User Modeling Problem
</sectionHeader>
<bodyText confidence="0.999762125">
It has long been argued in NLG research that
contents of generated texts should be oriented to
users’ tasks and existing knowledge. User mod-
els are usually employed for the tailoring task.
However, user models may not be easily ac-
quired. Reiter et al (2003a) claimed that no NLG
system actually used detailed user models with
non-trivial numbers of users. Most commercial
</bodyText>
<footnote confidence="0.996403">
1 http://www.environment-agency.gov.uk/homeandleisure/
floods/riverlevels/120694.aspx?stationId=8143
</footnote>
<page confidence="0.984326">
133
</page>
<bodyText confidence="0.97895352">
Proceedings of the 8th International Natural Language Generation Conference, pages 133–137,
Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics
NLG systems would rather do with very limited
user models, and examples are STOP (Reiter et
al., 2003b), SUMTIME-MOUSAM (Sripada et
al., 2002), and GIRL (Williams, 2002).
Recent research on user modeling falls into
roughly three categories, i.e. explicit, implicit
and hybrid approaches2. All approaches start
with knowledge acquisition. Explicit models then
define a finite number of user groups, and finally
generate tailored texts for users to choose from,
or choose to generate for a unique group at each
time, e.g. (Molina, 2011 and 2012). Implicit
models, e.g. (Mairesse and Walker, 2011), then
construct a framework of human computer inter-
action to learn about the values of a finite set of
features, and finally generate tailored texts ac-
cording to the intersection between domain
knowledge and feature values. Hybrid models,
e.g. (Bouayad-Agha et al, 2012) and (Dannels et
al, 2012), specify both a finite set of user groups
and a human computer interaction framework,
and finally classify online users into defined
groups for tailored generation.
</bodyText>
<sectionHeader confidence="0.943269" genericHeader="method">
3 Latent User Models
</sectionHeader>
<bodyText confidence="0.990777321428571">
Online river information tailoring involves a
website, such as SEPA’s, which provides map
based (or text based) searchable river infor-
mation 3. The NLG task is to generate user-
oriented texts while users are navigating the
website. Both explicit and implicit user models
can be employed for online river information
tailoring. A finite set of user groups could be
defined according to river-related activities, such
as flooding, fishing, canoeing, etc. along with a
set of features such as level trends, temperature
ranges, etc. Then an interactive navigation mech-
anism could ask a user to either choose a group
or tailor his/her own parameters, and relevant
texts can be generated thereafter.
Unfortunately, our engagement activities with
stakeholders showed that it is almost impossible
to define user models using mappings from river-
related activities to river data features. Further-
more, frequent users are reluctant to spend time
on specifying their preferences before viewing
the river information. For such an NLG task, the
uncertainty comes not only from a large variety
of river users and stakeholders, but also from the
issue that users themselves sometimes are not
2 Note the difference between NLG and HCI user models.
The former tailor the output of NLG systems, while the later
tailor the systems themselves.
</bodyText>
<footnote confidence="0.701318">
3 http://sepa.org.uk/water/river_levels/river_level_data.aspx
</footnote>
<bodyText confidence="0.999785375">
sure of what data features are associated with
making decisions about their activities.
Our efforts on dealing with NLG domain
knowledge and user models brought about the
idea of extending domain knowledge to statisti-
cally cover user knowledge, without explicitly
defining user groups or implicitly modeling po-
tential users. We argue that non-trivial number of
uncertain users can be dynamically and statisti-
cally modeled by integrating a module for web
mining and Google analytics into the NLG pipe-
line system. We regard these statistically estab-
lished models as latent since they are hidden be-
neath the domain knowledge, and the latent vari-
able of typical users is linked to river data types
and river related activities.
</bodyText>
<figureCaption confidence="0.998472">
Figure 1. Domain Knowledge with Latent Models
</figureCaption>
<bodyText confidence="0.999984761904762">
The domain knowledge and latent user models
are constructed as a whole in a hierarchical struc-
ture, as in Figure 1. We technically maintain this
hierarchy as an ontology based on existing ap-
proaches e.g. (Bontcheva, 2005; Bouayad-Agha
et al, 2012). The general part of the main frame
was extracted from hydrology or environment
websites, such as SEPA, CEH and EA, with the
view that these websites were deliberately estab-
lished hierarchically by manual work of domain
experts in the fields of hydrology, ecology and/or
geology. This part serves as the center of our
domain knowledge, which starts with a root node
and branches to river catchments, rivers, river
stations and river data, while river data consists
of water level, water flow, water temperature,
etc. There are also some non-hierarchical rela-
tions embedded, namely the tributary relation
between rivers, the upriver relation between river
stations, and the relationship between certain
river data and river related activities. In addition
</bodyText>
<page confidence="0.994506">
134
</page>
<bodyText confidence="0.999646857142857">
to the time series on the status of the rivers, other
information is integrated offline. Then, the do-
main knowledge was extended to cover potential
users’ knowledge and online visiting behaviors.
The extended information, or the latent user
models, as denoted in italic fonts in Figure 1,
includes three parts, i.e. the webpage visiting
frequency, the relevance degrees between certain
river data and river related activities, and the
ranking of popularities of river-related activities
for each river station.
Our extension process includes three stages,
i.e. web mining, Google analytics, and engage-
ment activities. At first, basic and rough infor-
mation about river stations was statistically gath-
ered by using free or trial version web mining
tools, such as spiders and crawlers, and corpus
analysis tools. For all combinations of elements
respectively from each pair of columns in Table
1, we simply count the tokens of co-occurrence
within an empirical window of 10 words. For the
co-occurring tokens between a given river station
and related activities, the top five tokens were
selected by filtering according to one threshold
on co-occurrence frequencies and another
threshold on frequency differences between ad-
jacent ranked types. For the co-occurring tokens
between a given activity and river data type, rel-
evant tokens were chosen by only one threshold
on the co-occurrence frequencies. Finally, the co-
occurring types of river stations and river data
with high frequencies were used to fine-tune the
previously acquired results, supposing that some
river stations seldom or never provide some
types of river data.
</bodyText>
<table confidence="0.9994838">
River Stations Related River Data
Activities Type
Aberlour Farming Level
Aberuchill Fishing Flow
Aberuthven Canoeing Temperature
Abington Swimming Width
Alford Kayaking Rainfall
Allnabad Rowing Wind
Almondell Boating Pollution
Alness Research Birds
Ancrum Education Animals
Anie Hiking Fishes
Apigill Cycling ...
Arbroath ... ...
... ...
</table>
<tableCaption confidence="0.999835">
Table 1. Basic Domain Knowledge for Extension
</tableCaption>
<bodyText confidence="0.99996064516129">
We further had the statistically acquired re-
sults complemented and modified by Google
analytics data for river websites and engagement
activities with domain experts and users. Google
analytics provided us with webpage visiting fre-
quencies for each hydrological station, and con-
tributed to the ranking of river-related activity
for a given station. Knowledge gathered from
engagement activities, such as semi-structured
interviews and focus groups, was mainly used to
confirm the statistically gathered information
during the first two stages (as well as refine our
overall understanding of data demands, water-
related activities and perception of existing
communication tools). For example, flood warn-
ing information was moved up in the ranks since
over 5 million people in England and Wales live
and work in properties that are at risk of flooding
from rivers or the sea4 (Marsh and Hannaford,
2007). Our present research is limited to rivers in
Scotland, involving 107 river catchments, 233
rivers, and 339 river stations. The webpage visit-
ing frequencies for these stations were gathered
from Google analytics data for the website of
SEPA5. The page visiting frequency for each riv-
er station is represented by a time series with
yearly periodicity, and each period includes 12
numeric elements calculated by dividing the
number of monthly visiting times of the station
by the total number of monthly visiting times of
all river stations.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="method">
4 NLG for Online Tailoring
</sectionHeader>
<bodyText confidence="0.999947818181818">
Our NLG pipeline system takes numeric data of
a given river station as input, and outputs a tai-
lored description for that river station. The sys-
tem analyzes data of water level, flow, and tem-
perature as similar to time series analysis tasks
presented in (Turner et al., 2006). Then, the ana-
lyzed patterns are interpreted into symbolic con-
ceptual representations, including vague expres-
sions, which might facilitate users’ understand-
ing (van Deemter, 2010). SEPA defines normal
ranges for river levels and we use these defini-
tions in our computations to generate vague ex-
pressions. For content selection, we define five
sets: S = {s1, s2, ...} the set of stations; A = {a1,
a2, ...} the set of activities for a given station; D
= {d1, d2, ...}= {{d11, d12, ...}, {d21, d22, ...}, ...}
the set of river data sets for a given station; AD =
{a1d1, a1d2, ..., a2d1, ...} where aidj refers to in-
formation from the interpretation of an activity ai
under the condition of data dj; and SAD an over-
view on one station. For a river station, using the
domain knowledge hierarchy, which embeds la-
</bodyText>
<footnote confidence="0.989277666666667">
4 http://www.environment-agency.gov.uk/homeandleisure/
floods/default.aspx.
5 http://www.sepa.org.uk.
</footnote>
<page confidence="0.997177">
135
</page>
<figure confidence="0.633536">
tent user models implicitly (Figure 1), we select
A ∪ D ∪ AD ∪ SAD as the initial contents.
</figure>
<figureCaption confidence="0.998347">
Figure 2. Statistical Schemas
</figureCaption>
<bodyText confidence="0.973716848484849">
A schema-based approach was employed for
document planning. Each schema at the high lev-
el is made up of three components: Introduction,
Events and Summary. Each of these components
has its own substructure as shown in examples in
Figure 4. With the estimated probabilistic distri-
bution we generate schemas for a station based
on its popular activities. We then tailor the text
by randomly selecting from users’ favorite vo-
cabulary, which was acquired from online corpus
for different river-related activities. Other words
for structural purposes are dependent on certain
schemas. Realization was performed using the
simpleNLG library (Gatt and Reiter, 2009), and
some generated examples are listed in Table 2.
Schema (1) The Tyne at Nungate boasts its excellent salm-
on catches. Now with medium steady water
level and comparatively low water temperature,
many people want to fish some salmons in pools
between the rapids or experience whitewater
rafting within them, which makes the periphery
of Nungate a hot spot.
Schema (2) The periphery of Tyne at Nungate poses a hot
spot now, where many people are fishing or
canoeing while appreciating the medium steady
water level and comparatively low water tem-
perature. No wonder Nungate can boast one of
the best salmon catching places.
Schema (3) The Tyne at Nungate boasts its excellent salm-
on catches. Many people may now fish or canoe
there thanks to the medium steady water level
and comparatively low water temperature, mak-
ing the periphery of Nungate a hot spot.
</bodyText>
<tableCaption confidence="0.989605">
Table 2. Some Tailored NLG Examples (Italic fonts
denote the tailored lexical realization)
</tableCaption>
<sectionHeader confidence="0.969588" genericHeader="method">
5 Initial Feedback and Conclusion
</sectionHeader>
<bodyText confidence="0.999956115384615">
This research is still underway and a thorough
evaluation is still pending. We have received
valuable feedback from small user groups. Sup-
portive examples are: a. An overview about pop-
ular river stations can help users’ further explora-
tion of information to a significant extent; b. A
general comprehension for a given river station
can be more easily built up by simply reading the
generated descriptions, than by solely reading the
data and its related graphics; c. Along with the
graphics, the generated descriptions can improve
the communication efficiency by a large degree.
Examples recommending further improve-
ment/focus include: a. Schemas filled in with
acquired vocabulary sometimes endow the gen-
erated document a syntactically and/or semanti-
cally unexpected flavor; b. Established users de-
mand more linguistic varieties than new users.
Present feedback implicates that latent user
models deserve further research. Our future ef-
forts will focus on a. extending the domain
knowledge to cover all river stations, b. develop-
ing generic methodology for acquiring latent user
models for other online NLG tasks (e.g. generat-
ing descriptions of Census data), and c. integrat-
ing an automatic update of latent models.
</bodyText>
<sectionHeader confidence="0.969896" genericHeader="conclusions">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9827656">
This research is supported by an award from the
RCUK DE programme: EP/G066051/1. The au-
thors are also grateful to Dr. Rene van der Wal,
Dr. Koen Arts, and the three anonymous review-
ers for improving the quality of this paper.
</bodyText>
<page confidence="0.998257">
136
</page>
<sectionHeader confidence="0.989973" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999814974358975">
K. Bontcheva. 2005. Generating Tailored Textual
Summaries from Ontologies. The Semantic Web:
Research and Applications, Lecture Notes in Com-
puter Science, Vol. 3532, pages 531-545. Springer-
Verlag.
N. Bouayad-Agha, G. Casamayor, Simon Mille, et al.
2012. From Ontology to NL: Generation of Multi-
lingual User-Oriented Environmental Reports.
Natural Language Processing and Information
Systems, Lecture Notes in Computer Science Vol.
7337, pages 216-221. Springer-Verlag.
Dana Dannells, Mariana Damova, Ramona Enache
and Milen Chechev. 2012. Multilingual Online
Generation from Semantic Web Ontologies. WWW
2012 – European Projects Track, pages 239-242.
H. Dixon. 2010. Managing national hydrometric data:
from data to information. Global Change: Facing
Risks and Threats to Water Resources. Walling-
ford, UK, IAHS Press, pages 451-458.
A. Gatt and Ehud Reiter. 2009. Simplenlg: A Realiza-
tion Engine for Practical Applications. Proceedings
ENLG-2009, pages 90-93.
K. Macleod, S. Sripada, A. Ioris, K. Arts and R. Van
der Wal. 2012. Communicating River Level Data
and Information to Stakeholders with Different In-
terests: the Participative Development of an Inter-
active Online Service. International Environmental
Modeling and Software Society (iEMSs): Interna-
tional Congress on Environmental Modeling and
Software Managing Resources of a Limited Planet,
Sixth Biennial Meeting, Leipzig, Germany. R.
Seppelt, A.A. Voinov, S. Lange, D. Bankamp
(Eds.) pages 33-40.
Francois Mairesse and Marilyn A. Walker. 2011.
Controlling User Perceptions of Linguistic Style:
Trainable Generation of Personality Traits. Compu-
tational Linguistics, Volume 37 Issue 3, September
2011, pages 455-488.
T. J. Marsh and J. Hannaford. 2007. The summer
2007 floods in England and Wales – a hydrological
appraisal. Centre for Ecology &amp; Hydrology, UK.
M. Molina. 2012. Simulating Data Journalism to
Communicate Hydrological Information from Sen-
sor Networks. Proceedings of IBERAMIA, pages
722-731.
M. Molina, A. Stent, and E. Parodi. 2011. Generating
Automated News to Explain the Meaning of Sen-
sor Data. In: Gama, J., Bradley, E., Hollmen, J.
(eds.) IDA 2011. LNCS, vol. 7014, pages 282-293.
Springer, Heidelberg.
Ehud Reiter, Somayajulu Sripada, and Sandra Wil-
liams. 2003a. Acquiring and Using Limited User
Models in NLG. In Proceedings of the 9th Europe-
an Workshop on Natural Language Generation,
pages 13-14, Budapest, Hungary.
Ehud Reiter, Roma Robertson, and Liesl Osman.
2003b. Lessons from a failure: Generating tailored
smoking cessation letters. Artificial Intelligence,
144(1-2), pages 41-58.
Ehud Reiter. 2007. An Architecture for Data-to-Text
Systems. Proceedings of ENLG-2007, pages 97-
104.
S. Sripada, Ehud Reiter, Jim Hunter, and Jin Yu.
2002. Segmenting time series for weather fore-
casting. Applications and Innovations in Intelli-
gent Systems X, pages 105-118. Springer-Verlag.
R. Turner, S. Sripada, E. Reiter and I. Davy. 2006.
Generating Spatio-Temporal Descriptions in Pollen
Forecasts. Proceedings of EACL06 poster session,
pages 163-166.
K. van Deemter. 2010. Vagueness Facilitates Search.
Proceedings of the 2009 Amsterdam Colloquium,
Springer Lecture Notes in Computer Science
(LNCS). FoLLI LNAI 6042.
Sandra Williams. 2002. Natural language generation
of discourse connectives for different reading lev-
els. In Proceedings of the 5th Annual CLUK Re-
search Colloquium, Leeds, UK.
</reference>
<page confidence="0.997818">
137
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.800415">
<title confidence="0.999024">Latent User Models for Online River Information Tailoring</title>
<author confidence="0.999322">Somayajulu Kit</author>
<author confidence="0.999322">A R Antonio</author>
<affiliation confidence="0.940760666666667">of Computing Sciences, University of Aberdeen, Hutton Institute, Aberdeen; University of Exeter, Exeter, of GeoSciences, University of Edinburgh,</affiliation>
<email confidence="0.987164">xiwuhan@abdn.ac.uka.ioris@ed.ac.uk</email>
<email confidence="0.987164">yaji.sripada@abdn.ac.uka.ioris@ed.ac.uk</email>
<abstract confidence="0.997668928571429">This paper explores Natural Language Generation techniques for online river information tailoring. To solve the problem of unknown users, we propose ‘latent models’, which relate typical visitors to river web pages, river data types, and river related activities. A hierarchy is used to integrate domain knowledge and latent user knowledge, and serves as the search space for content selection, which triggers user-oriented selection rules when they visit a page. Initial feedback received from user groups indicates that the latent models deserve further research efforts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Bontcheva</author>
</authors>
<title>Generating Tailored Textual Summaries from Ontologies. The Semantic Web: Research and Applications,</title>
<date>2005</date>
<journal>Lecture Notes in Computer Science,</journal>
<volume>3532</volume>
<pages>531--545</pages>
<publisher>SpringerVerlag.</publisher>
<contexts>
<context position="7449" citStr="Bontcheva, 2005" startWordPosition="1121" endWordPosition="1122">s can be dynamically and statistically modeled by integrating a module for web mining and Google analytics into the NLG pipeline system. We regard these statistically established models as latent since they are hidden beneath the domain knowledge, and the latent variable of typical users is linked to river data types and river related activities. Figure 1. Domain Knowledge with Latent Models The domain knowledge and latent user models are constructed as a whole in a hierarchical structure, as in Figure 1. We technically maintain this hierarchy as an ontology based on existing approaches e.g. (Bontcheva, 2005; Bouayad-Agha et al, 2012). The general part of the main frame was extracted from hydrology or environment websites, such as SEPA, CEH and EA, with the view that these websites were deliberately established hierarchically by manual work of domain experts in the fields of hydrology, ecology and/or geology. This part serves as the center of our domain knowledge, which starts with a root node and branches to river catchments, rivers, river stations and river data, while river data consists of water level, water flow, water temperature, etc. There are also some non-hierarchical relations embedded</context>
</contexts>
<marker>Bontcheva, 2005</marker>
<rawString>K. Bontcheva. 2005. Generating Tailored Textual Summaries from Ontologies. The Semantic Web: Research and Applications, Lecture Notes in Computer Science, Vol. 3532, pages 531-545. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bouayad-Agha</author>
<author>G Casamayor</author>
<author>Simon Mille</author>
</authors>
<title>From Ontology to NL: Generation of Multilingual User-Oriented Environmental Reports. Natural Language Processing and Information Systems,</title>
<date>2012</date>
<journal>Lecture Notes in Computer Science</journal>
<volume>7337</volume>
<pages>216--221</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="4862" citStr="Bouayad-Agha et al, 2012" startWordPosition="714" endWordPosition="717"> i.e. explicit, implicit and hybrid approaches2. All approaches start with knowledge acquisition. Explicit models then define a finite number of user groups, and finally generate tailored texts for users to choose from, or choose to generate for a unique group at each time, e.g. (Molina, 2011 and 2012). Implicit models, e.g. (Mairesse and Walker, 2011), then construct a framework of human computer interaction to learn about the values of a finite set of features, and finally generate tailored texts according to the intersection between domain knowledge and feature values. Hybrid models, e.g. (Bouayad-Agha et al, 2012) and (Dannels et al, 2012), specify both a finite set of user groups and a human computer interaction framework, and finally classify online users into defined groups for tailored generation. 3 Latent User Models Online river information tailoring involves a website, such as SEPA’s, which provides map based (or text based) searchable river information 3. The NLG task is to generate useroriented texts while users are navigating the website. Both explicit and implicit user models can be employed for online river information tailoring. A finite set of user groups could be defined according to riv</context>
<context position="7476" citStr="Bouayad-Agha et al, 2012" startWordPosition="1123" endWordPosition="1126">lly and statistically modeled by integrating a module for web mining and Google analytics into the NLG pipeline system. We regard these statistically established models as latent since they are hidden beneath the domain knowledge, and the latent variable of typical users is linked to river data types and river related activities. Figure 1. Domain Knowledge with Latent Models The domain knowledge and latent user models are constructed as a whole in a hierarchical structure, as in Figure 1. We technically maintain this hierarchy as an ontology based on existing approaches e.g. (Bontcheva, 2005; Bouayad-Agha et al, 2012). The general part of the main frame was extracted from hydrology or environment websites, such as SEPA, CEH and EA, with the view that these websites were deliberately established hierarchically by manual work of domain experts in the fields of hydrology, ecology and/or geology. This part serves as the center of our domain knowledge, which starts with a root node and branches to river catchments, rivers, river stations and river data, while river data consists of water level, water flow, water temperature, etc. There are also some non-hierarchical relations embedded, namely the tributary rela</context>
</contexts>
<marker>Bouayad-Agha, Casamayor, Mille, 2012</marker>
<rawString>N. Bouayad-Agha, G. Casamayor, Simon Mille, et al. 2012. From Ontology to NL: Generation of Multilingual User-Oriented Environmental Reports. Natural Language Processing and Information Systems, Lecture Notes in Computer Science Vol. 7337, pages 216-221. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dana Dannells</author>
<author>Mariana Damova</author>
<author>Ramona Enache</author>
<author>Milen Chechev</author>
</authors>
<date>2012</date>
<booktitle>Multilingual Online Generation from Semantic Web Ontologies. WWW 2012 – European Projects Track,</booktitle>
<pages>239--242</pages>
<marker>Dannells, Damova, Enache, Chechev, 2012</marker>
<rawString>Dana Dannells, Mariana Damova, Ramona Enache and Milen Chechev. 2012. Multilingual Online Generation from Semantic Web Ontologies. WWW 2012 – European Projects Track, pages 239-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dixon</author>
</authors>
<title>Managing national hydrometric data: from data to information. Global Change: Facing Risks and Threats to Water Resources.</title>
<date>2010</date>
<pages>451--458</pages>
<publisher>IAHS Press,</publisher>
<location>Wallingford, UK,</location>
<contexts>
<context position="1210" citStr="Dixon, 2010" startWordPosition="165" endWordPosition="166">to river web pages, river data types, and river related activities. A hierarchy is used to integrate domain knowledge and latent user knowledge, and serves as the search space for content selection, which triggers user-oriented selection rules when they visit a page. Initial feedback received from user groups indicates that the latent models deserve further research efforts. 1 Introduction Within recent decades, access to online river information has increased exponentially thanks to great progresses in data collection and storage technologies employed by hydrological organizations worldwide (Dixon, 2010). Local residents nearby rivers and those engaged in river related activities are now much better informed and more engaged with data providers than decades ago. However, organizations such as SEPA (Scottish Environment Protection Agency), CEH (Centre for Ecology and Hydrology), EA (Environment Agency) in UK, and quite a few Canadian and Australian ones are working to improve the presentation of river information further. Many of these data providers, who are mostly government agencies, provide descriptive texts along with archived data of flow, level, flood and temperature along with their gr</context>
</contexts>
<marker>Dixon, 2010</marker>
<rawString>H. Dixon. 2010. Managing national hydrometric data: from data to information. Global Change: Facing Risks and Threats to Water Resources. Wallingford, UK, IAHS Press, pages 451-458.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gatt</author>
<author>Ehud Reiter</author>
</authors>
<title>Simplenlg: A Realization Engine for Practical Applications.</title>
<date>2009</date>
<booktitle>Proceedings ENLG-2009,</booktitle>
<pages>90--93</pages>
<contexts>
<context position="13682" citStr="Gatt and Reiter, 2009" startWordPosition="2097" endWordPosition="2100">d for document planning. Each schema at the high level is made up of three components: Introduction, Events and Summary. Each of these components has its own substructure as shown in examples in Figure 4. With the estimated probabilistic distribution we generate schemas for a station based on its popular activities. We then tailor the text by randomly selecting from users’ favorite vocabulary, which was acquired from online corpus for different river-related activities. Other words for structural purposes are dependent on certain schemas. Realization was performed using the simpleNLG library (Gatt and Reiter, 2009), and some generated examples are listed in Table 2. Schema (1) The Tyne at Nungate boasts its excellent salmon catches. Now with medium steady water level and comparatively low water temperature, many people want to fish some salmons in pools between the rapids or experience whitewater rafting within them, which makes the periphery of Nungate a hot spot. Schema (2) The periphery of Tyne at Nungate poses a hot spot now, where many people are fishing or canoeing while appreciating the medium steady water level and comparatively low water temperature. No wonder Nungate can boast one of the best </context>
</contexts>
<marker>Gatt, Reiter, 2009</marker>
<rawString>A. Gatt and Ehud Reiter. 2009. Simplenlg: A Realization Engine for Practical Applications. Proceedings ENLG-2009, pages 90-93.</rawString>
</citation>
<citation valid="false">
<authors>
<author>K Macleod</author>
<author>S Sripada</author>
<author>A Ioris</author>
<author>K Arts</author>
<author>R Van der Wal</author>
</authors>
<title>Communicating River Level Data and Information to Stakeholders with Different Interests: the Participative Development of an Interactive Online Service.</title>
<date>2012</date>
<booktitle>International Environmental Modeling and Software Society (iEMSs): International Congress on Environmental Modeling and Software Managing Resources of a Limited Planet, Sixth Biennial Meeting,</booktitle>
<pages>33--40</pages>
<location>Leipzig,</location>
<marker>Macleod, Sripada, Ioris, Arts, Van der Wal, 2012</marker>
<rawString>K. Macleod, S. Sripada, A. Ioris, K. Arts and R. Van der Wal. 2012. Communicating River Level Data and Information to Stakeholders with Different Interests: the Participative Development of an Interactive Online Service. International Environmental Modeling and Software Society (iEMSs): International Congress on Environmental Modeling and Software Managing Resources of a Limited Planet, Sixth Biennial Meeting, Leipzig, Germany. R. Seppelt, A.A. Voinov, S. Lange, D. Bankamp (Eds.) pages 33-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francois Mairesse</author>
<author>Marilyn A Walker</author>
</authors>
<title>Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits.</title>
<date>2011</date>
<journal>Computational Linguistics, Volume</journal>
<volume>37</volume>
<pages>455--488</pages>
<contexts>
<context position="4591" citStr="Mairesse and Walker, 2011" startWordPosition="671" endWordPosition="674">n for Computational Linguistics NLG systems would rather do with very limited user models, and examples are STOP (Reiter et al., 2003b), SUMTIME-MOUSAM (Sripada et al., 2002), and GIRL (Williams, 2002). Recent research on user modeling falls into roughly three categories, i.e. explicit, implicit and hybrid approaches2. All approaches start with knowledge acquisition. Explicit models then define a finite number of user groups, and finally generate tailored texts for users to choose from, or choose to generate for a unique group at each time, e.g. (Molina, 2011 and 2012). Implicit models, e.g. (Mairesse and Walker, 2011), then construct a framework of human computer interaction to learn about the values of a finite set of features, and finally generate tailored texts according to the intersection between domain knowledge and feature values. Hybrid models, e.g. (Bouayad-Agha et al, 2012) and (Dannels et al, 2012), specify both a finite set of user groups and a human computer interaction framework, and finally classify online users into defined groups for tailored generation. 3 Latent User Models Online river information tailoring involves a website, such as SEPA’s, which provides map based (or text based) sear</context>
</contexts>
<marker>Mairesse, Walker, 2011</marker>
<rawString>Francois Mairesse and Marilyn A. Walker. 2011. Controlling User Perceptions of Linguistic Style: Trainable Generation of Personality Traits. Computational Linguistics, Volume 37 Issue 3, September 2011, pages 455-488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J Marsh</author>
<author>J Hannaford</author>
</authors>
<title>The summer 2007 floods in England and Wales – a hydrological appraisal. Centre for Ecology &amp;</title>
<date>2007</date>
<publisher>Hydrology, UK.</publisher>
<contexts>
<context position="11146" citStr="Marsh and Hannaford, 2007" startWordPosition="1683" endWordPosition="1686"> contributed to the ranking of river-related activity for a given station. Knowledge gathered from engagement activities, such as semi-structured interviews and focus groups, was mainly used to confirm the statistically gathered information during the first two stages (as well as refine our overall understanding of data demands, waterrelated activities and perception of existing communication tools). For example, flood warning information was moved up in the ranks since over 5 million people in England and Wales live and work in properties that are at risk of flooding from rivers or the sea4 (Marsh and Hannaford, 2007). Our present research is limited to rivers in Scotland, involving 107 river catchments, 233 rivers, and 339 river stations. The webpage visiting frequencies for these stations were gathered from Google analytics data for the website of SEPA5. The page visiting frequency for each river station is represented by a time series with yearly periodicity, and each period includes 12 numeric elements calculated by dividing the number of monthly visiting times of the station by the total number of monthly visiting times of all river stations. 4 NLG for Online Tailoring Our NLG pipeline system takes nu</context>
</contexts>
<marker>Marsh, Hannaford, 2007</marker>
<rawString>T. J. Marsh and J. Hannaford. 2007. The summer 2007 floods in England and Wales – a hydrological appraisal. Centre for Ecology &amp; Hydrology, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Molina</author>
</authors>
<title>Simulating Data Journalism to Communicate Hydrological Information from Sensor Networks.</title>
<date>2012</date>
<booktitle>Proceedings of IBERAMIA,</booktitle>
<pages>722--731</pages>
<marker>Molina, 2012</marker>
<rawString>M. Molina. 2012. Simulating Data Journalism to Communicate Hydrological Information from Sensor Networks. Proceedings of IBERAMIA, pages 722-731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Molina</author>
<author>A Stent</author>
<author>E Parodi</author>
</authors>
<title>Generating Automated News to Explain the Meaning of Sensor Data.</title>
<date>2011</date>
<volume>7014</volume>
<pages>282--293</pages>
<editor>In: Gama, J., Bradley, E., Hollmen, J. (eds.) IDA 2011. LNCS,</editor>
<publisher>Springer,</publisher>
<location>Heidelberg.</location>
<marker>Molina, Stent, Parodi, 2011</marker>
<rawString>M. Molina, A. Stent, and E. Parodi. 2011. Generating Automated News to Explain the Meaning of Sensor Data. In: Gama, J., Bradley, E., Hollmen, J. (eds.) IDA 2011. LNCS, vol. 7014, pages 282-293. Springer, Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Somayajulu Sripada</author>
<author>Sandra Williams</author>
</authors>
<title>Acquiring and Using Limited User Models in NLG.</title>
<date>2003</date>
<booktitle>In Proceedings of the 9th European Workshop on Natural Language Generation,</booktitle>
<pages>13--14</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="3590" citStr="Reiter et al (2003" startWordPosition="537" endWordPosition="540">fficult to be acquired due to domain sensitive challenges. Second, for online communication, the issue that users themselves sometimes are not sure about their tasks further hinders user modeling. This paper proposes an alternative approach of latent user models, instead of directly asking users to indicate what they are interested in. 2 User Modeling Problem It has long been argued in NLG research that contents of generated texts should be oriented to users’ tasks and existing knowledge. User models are usually employed for the tailoring task. However, user models may not be easily acquired. Reiter et al (2003a) claimed that no NLG system actually used detailed user models with non-trivial numbers of users. Most commercial 1 http://www.environment-agency.gov.uk/homeandleisure/ floods/riverlevels/120694.aspx?stationId=8143 133 Proceedings of the 8th International Natural Language Generation Conference, pages 133–137, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics NLG systems would rather do with very limited user models, and examples are STOP (Reiter et al., 2003b), SUMTIME-MOUSAM (Sripada et al., 2002), and GIRL (Williams, 2002). Recent research on use</context>
</contexts>
<marker>Reiter, Sripada, Williams, 2003</marker>
<rawString>Ehud Reiter, Somayajulu Sripada, and Sandra Williams. 2003a. Acquiring and Using Limited User Models in NLG. In Proceedings of the 9th European Workshop on Natural Language Generation, pages 13-14, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Roma Robertson</author>
<author>Liesl Osman</author>
</authors>
<title>Lessons from a failure: Generating tailored smoking cessation letters.</title>
<date>2003</date>
<journal>Artificial Intelligence,</journal>
<volume>144</volume>
<issue>1</issue>
<pages>41--58</pages>
<contexts>
<context position="3590" citStr="Reiter et al (2003" startWordPosition="537" endWordPosition="540">fficult to be acquired due to domain sensitive challenges. Second, for online communication, the issue that users themselves sometimes are not sure about their tasks further hinders user modeling. This paper proposes an alternative approach of latent user models, instead of directly asking users to indicate what they are interested in. 2 User Modeling Problem It has long been argued in NLG research that contents of generated texts should be oriented to users’ tasks and existing knowledge. User models are usually employed for the tailoring task. However, user models may not be easily acquired. Reiter et al (2003a) claimed that no NLG system actually used detailed user models with non-trivial numbers of users. Most commercial 1 http://www.environment-agency.gov.uk/homeandleisure/ floods/riverlevels/120694.aspx?stationId=8143 133 Proceedings of the 8th International Natural Language Generation Conference, pages 133–137, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics NLG systems would rather do with very limited user models, and examples are STOP (Reiter et al., 2003b), SUMTIME-MOUSAM (Sripada et al., 2002), and GIRL (Williams, 2002). Recent research on use</context>
</contexts>
<marker>Reiter, Robertson, Osman, 2003</marker>
<rawString>Ehud Reiter, Roma Robertson, and Liesl Osman. 2003b. Lessons from a failure: Generating tailored smoking cessation letters. Artificial Intelligence, 144(1-2), pages 41-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>An Architecture for Data-to-Text Systems.</title>
<date>2007</date>
<booktitle>Proceedings of ENLG-2007,</booktitle>
<pages>97--104</pages>
<contexts>
<context position="2689" citStr="Reiter, 2007" startWordPosition="396" endWordPosition="397">s and 2.60 metres. The highest river level recorded at this location is 6.32 metres and the river level reached 6.32 metres on 07/09/2008.1 The above descriptive text could vary to some extent according to different river users. For instance, it may provide information perceived as good news by farmers whilst other users e.g. canoeists or paddlers may interpret the information as bad news for their activity. Such tailored information provision promotes communication efficiency between stakeholders and the relevant government offices (Macleod et al., 2012). We explored data-to-text techniques (Reiter, 2007) in promoting online river information provision. Our engagement activities with river stakeholders showed that there could be great difficulties in specifying user groups for online river information tailoring. First, the relations between domain knowledge and user knowledge are difficult to be acquired due to domain sensitive challenges. Second, for online communication, the issue that users themselves sometimes are not sure about their tasks further hinders user modeling. This paper proposes an alternative approach of latent user models, instead of directly asking users to indicate what the</context>
</contexts>
<marker>Reiter, 2007</marker>
<rawString>Ehud Reiter. 2007. An Architecture for Data-to-Text Systems. Proceedings of ENLG-2007, pages 97-104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sripada</author>
<author>Ehud Reiter</author>
<author>Jim Hunter</author>
<author>Jin Yu</author>
</authors>
<title>Segmenting time series for weather forecasting.</title>
<date>2002</date>
<booktitle>Applications and Innovations in Intelligent Systems X,</booktitle>
<pages>105--118</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="4139" citStr="Sripada et al., 2002" startWordPosition="602" endWordPosition="605">ask. However, user models may not be easily acquired. Reiter et al (2003a) claimed that no NLG system actually used detailed user models with non-trivial numbers of users. Most commercial 1 http://www.environment-agency.gov.uk/homeandleisure/ floods/riverlevels/120694.aspx?stationId=8143 133 Proceedings of the 8th International Natural Language Generation Conference, pages 133–137, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics NLG systems would rather do with very limited user models, and examples are STOP (Reiter et al., 2003b), SUMTIME-MOUSAM (Sripada et al., 2002), and GIRL (Williams, 2002). Recent research on user modeling falls into roughly three categories, i.e. explicit, implicit and hybrid approaches2. All approaches start with knowledge acquisition. Explicit models then define a finite number of user groups, and finally generate tailored texts for users to choose from, or choose to generate for a unique group at each time, e.g. (Molina, 2011 and 2012). Implicit models, e.g. (Mairesse and Walker, 2011), then construct a framework of human computer interaction to learn about the values of a finite set of features, and finally generate tailored text</context>
</contexts>
<marker>Sripada, Reiter, Hunter, Yu, 2002</marker>
<rawString>S. Sripada, Ehud Reiter, Jim Hunter, and Jin Yu. 2002. Segmenting time series for weather forecasting. Applications and Innovations in Intelligent Systems X, pages 105-118. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Turner</author>
<author>S Sripada</author>
<author>E Reiter</author>
<author>I Davy</author>
</authors>
<title>Generating Spatio-Temporal Descriptions in Pollen Forecasts.</title>
<date>2006</date>
<booktitle>Proceedings of EACL06 poster session,</booktitle>
<pages>163--166</pages>
<contexts>
<context position="11989" citStr="Turner et al., 2006" startWordPosition="1824" endWordPosition="1827">he website of SEPA5. The page visiting frequency for each river station is represented by a time series with yearly periodicity, and each period includes 12 numeric elements calculated by dividing the number of monthly visiting times of the station by the total number of monthly visiting times of all river stations. 4 NLG for Online Tailoring Our NLG pipeline system takes numeric data of a given river station as input, and outputs a tailored description for that river station. The system analyzes data of water level, flow, and temperature as similar to time series analysis tasks presented in (Turner et al., 2006). Then, the analyzed patterns are interpreted into symbolic conceptual representations, including vague expressions, which might facilitate users’ understanding (van Deemter, 2010). SEPA defines normal ranges for river levels and we use these definitions in our computations to generate vague expressions. For content selection, we define five sets: S = {s1, s2, ...} the set of stations; A = {a1, a2, ...} the set of activities for a given station; D = {d1, d2, ...}= {{d11, d12, ...}, {d21, d22, ...}, ...} the set of river data sets for a given station; AD = {a1d1, a1d2, ..., a2d1, ...} where aid</context>
</contexts>
<marker>Turner, Sripada, Reiter, Davy, 2006</marker>
<rawString>R. Turner, S. Sripada, E. Reiter and I. Davy. 2006. Generating Spatio-Temporal Descriptions in Pollen Forecasts. Proceedings of EACL06 poster session, pages 163-166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
</authors>
<title>Vagueness Facilitates Search.</title>
<date>2010</date>
<booktitle>Proceedings of the 2009 Amsterdam Colloquium, Springer Lecture Notes in Computer Science (LNCS). FoLLI LNAI</booktitle>
<pages>6042</pages>
<marker>van Deemter, 2010</marker>
<rawString>K. van Deemter. 2010. Vagueness Facilitates Search. Proceedings of the 2009 Amsterdam Colloquium, Springer Lecture Notes in Computer Science (LNCS). FoLLI LNAI 6042.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Williams</author>
</authors>
<title>Natural language generation of discourse connectives for different reading levels.</title>
<date>2002</date>
<booktitle>In Proceedings of the 5th Annual CLUK Research Colloquium,</booktitle>
<location>Leeds, UK.</location>
<contexts>
<context position="4166" citStr="Williams, 2002" startWordPosition="608" endWordPosition="609"> be easily acquired. Reiter et al (2003a) claimed that no NLG system actually used detailed user models with non-trivial numbers of users. Most commercial 1 http://www.environment-agency.gov.uk/homeandleisure/ floods/riverlevels/120694.aspx?stationId=8143 133 Proceedings of the 8th International Natural Language Generation Conference, pages 133–137, Philadelphia, Pennsylvania, 19-21 June 2014. c�2014 Association for Computational Linguistics NLG systems would rather do with very limited user models, and examples are STOP (Reiter et al., 2003b), SUMTIME-MOUSAM (Sripada et al., 2002), and GIRL (Williams, 2002). Recent research on user modeling falls into roughly three categories, i.e. explicit, implicit and hybrid approaches2. All approaches start with knowledge acquisition. Explicit models then define a finite number of user groups, and finally generate tailored texts for users to choose from, or choose to generate for a unique group at each time, e.g. (Molina, 2011 and 2012). Implicit models, e.g. (Mairesse and Walker, 2011), then construct a framework of human computer interaction to learn about the values of a finite set of features, and finally generate tailored texts according to the intersec</context>
</contexts>
<marker>Williams, 2002</marker>
<rawString>Sandra Williams. 2002. Natural language generation of discourse connectives for different reading levels. In Proceedings of the 5th Annual CLUK Research Colloquium, Leeds, UK.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>