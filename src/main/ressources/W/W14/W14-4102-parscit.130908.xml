<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013465">
<title confidence="0.999067">
Your click decides your fate: Inferring Information Processing and
Attrition Behavior from MOOC Video Clickstream Interactions
</title>
<author confidence="0.999881">
Tanmay Sinha1, Patrick Jermann2, Nan Li3, Pierre Dillenbourg3
</author>
<affiliation confidence="0.937715333333333">
1Language Technologies Institute, Carnegie Mellon University, Pittsburgh PA 15213, USA
2Center for Digital Education, EPFL, CH 1015, Switzerland
3Computer-Human Interaction in Learning and Instruction, EPFL, CH 1015, Switzerland
</affiliation>
<email confidence="0.989029">
1tanmays@andrew.cmu.edu, 2,3&lt;firstname.lastname&gt;@epfl.ch
</email>
<sectionHeader confidence="0.993512" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980210526316">
In this work, we explore video lec-
ture interaction in Massive Open Online
Courses (MOOCs), which is central to stu-
dent learning experience on these educa-
tional platforms. As a research contribu-
tion, we operationalize video lecture click-
streams of students into cognitively plau-
sible higher level behaviors, and construct
a quantitative information processing in-
dex, which can aid instructors to better un-
derstand MOOC hurdles and reason about
unsatisfactory learning outcomes. Our re-
sults illustrate how such a metric inspired
by cognitive psychology can help answer
critical questions regarding students’ en-
gagement, their future click interactions
and participation trajectories that lead to
in-video &amp; course dropouts. Implications
for research and practice are discussed.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999980355932204">
Mushrooming as a scalable lifelong learn-
ing paradigm, Massive Open Online Courses
(MOOCs) have enjoyed significant limelight in re-
cent years, both in industry and academia (Hag-
gard et al., 2013). The euphoria is about the
transformative potential of MOOCs to revolution-
ize online education (North et al., 2014), by con-
necting and fostering interaction among millions
of learners who otherwise would never have met
and providing autonomy to these learners to grap-
ple with the course instruction at their own pace of
understanding. However, despite this expediency,
there is also considerable skepticism in the learn-
ing analytics research community about MOOC
productiveness (Nawrot and Antoine, 2014), pri-
marily because of unsatisfactory learning out-
comes that plague these educational platforms and
induce a funnel of participation (Clow, 2013).
With a “one size fits all” approach that MOOCs
follow, scaled up class sizes and lack of face to
face interaction coupled with such high student
teacher ratios (Guo and Katharina, 2014), stu-
dents’ motivation to follow the course oscillates
(Davis et al., 2014). This is comprehensibly re-
flected in escalating attrition rates in MOOCs, ever
since they have started maturing (Belanger and
Thornton, 2013; Schmidt and Zach, 2013; Yang et
al., 2013). Because it is not feasible for MOOC in-
structors to manually provide individualized atten-
tion that caters to different backgrounds, diverse
skill levels, learning goals and preferences of stu-
dents, there is an increasing need to make directed
efforts towards automatically providing better per-
sonalized content in e-learning (Sinha et al., 2013;
Lie et al., 2014; Sinha, 2014a). The provision
of guidance with regard to the organization of the
study and regulation of learning is a domain that
also needs to be addressed.
A prerequisite for such an undertaking is that
we, as MOOC researchers, understand how di-
verse ecologies of participation develop as stu-
dents interact with the course material (Fischer,
2011), and how learners distribute their attention
with multiple forms of computer mediated inputs
in MOOCs. Learning in a MOOC requires that
students apply self regulation. While substantial
research has been done on studying MOOC dis-
cussion forums (Ramesh et al., 2013; Brinton et
al., 2013; Anderson et al., 2014; Sinha, 2014b),
grading strategies for assignments (Tillmann et al.,
2013; Kulkarni et al., 2014) and deployment of
reputation systems (Coetzee et al., 2014), inner
workings of students’ interaction while watching
MOOC video lectures have been much less fo-
cused upon. Given that roughly 5% (Huang et al.,
2014) of students actually participate in MOOC
discussion forums, it would be legitimate to ask
whether choosing video lectures as units of analy-
sis would be more insightful. After 330,000 reg-
</bodyText>
<page confidence="0.982591">
3
</page>
<note confidence="0.9097775">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3–14,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999937250000001">
istrations in MOOC courses at EPFL in 2013, our
experience reflects that out of the 100% students
who register, 75% show up: 50% of them primar-
ily watch video lectures and the rest 25% addition-
ally work out homeworks and assignments. Thus,
majority of students have video lecture viewing as
their primary MOOC activity.
Video lectures form a primary and an extremely
crucial part of MOOC instruction design. They
serve as gateways to draw students into the course.
Concept discussions, demos and tutorials that are
held within these short video lectures, not only
guide learners to complete course assignments,
but also encourage them to discuss the taught
syllabus on MOOC discussion forums. Specific
to the context of video lectures, prior work has
cut teeth on a)how video production style (slides,
code, classroom, khan academy style etc) relates
to students’ engagement (Guo et al., 2014), b)what
features of the video lecture and instruction de-
livery, such as slide transitions (change in visual
content), instructor changing topic (topic model-
ing and ngram analysis) or variations in instruc-
tor’s acoustic stream (volume, pitch, speaking
rate), lead to peaks in viewership activity (Kim
et al., 2014b). There has been increasing focus
on unveiling numerous facets of complexity of
raw click-level interactions resulting from student
activities within individual MOOC videos (Kim
et al., 2014a; Sinha et al., 2014). However, to
the best of our knowledge, we present the first
study that describes usage of such detailed click-
stream information to form cognitive video watch-
ing states that summarize student clickstream. In-
stead of using summative features that express stu-
dent engagement, we leverage recurring click be-
haviors of students interacting with MOOC video
lectures, to construct their video watching profile.
Based on these richly logged interactions of stu-
dents, we develop computational methods that an-
swer critical questions such as a)how long will stu-
dents grapple with the course material and what
will their engagement trajectory look like, b)what
future click interactions will characterize their be-
havior, c)whether students are ultimately going to
survive through the end of the video and course.
As an effort to improve the second generation of
MOOC offerings, we perform a hierarchical three
level clickstream analysis, rooted in foundations
of cognitive psychology. Incidentally, we explore
at a micro level whether, and how, cognitive mind
states govern the formation and occurrence of mi-
cro level click patterns. Towards this end, we also
develop a quantitative information processing in-
dex and monitor its variations among different stu-
dent partitions that we define for the MOOC. Such
an operationalization can help course instructors
to reason how students’ navigational style reflects
cognitive resource allocation for meaning process-
ing and retention of concepts taught in the MOOC.
Our metric aids MOOC designers in identifying
which part of the videos might require editing.
The goal is to develop an explanatory techno-
cognitive model which shows that a set of metrics
derived from low-level behaviors are meaningful,
and can in turn be used to make effective predic-
tions on high-level behaviors intuitively.
In the remainder of this paper, we describe our
study context in the next section. In section 3,
we motivate our three level hierarchical MOOC
video clickstream analysis (operations, actions, in-
formation processing activities), describing rele-
vant related work along the way, along with the
technical approach followed. In section 4, we val-
idate our developed methodology by setting up
certain machine learning experiments, specifically
engagement prediction, next click state prediction,
in-video and complete course dropout prediction.
Implications for future work and conclusion is pre-
sented in section 5.
</bodyText>
<sectionHeader confidence="0.981606" genericHeader="method">
2 Study Context
</sectionHeader>
<bodyText confidence="0.99996185">
The data for our current study comes from an in-
troductory programming MOOC “Functional Pro-
gramming in Scala” that was offered on the Cours-
era MOOC platform in 2012. This MOOC com-
prises 48 video lectures (10 Gb of JSON data),
which has been parsed and preprocessed into a
convenient format for experimentation. In these
interaction logs, every click of students on the
MOOC video player is registered (play, pause,
seek forward, seek backward, scroll forward,
scroll backward, ratechange). We have informa-
tion about the rate at which the video lecture is
played, total time spent on playing the video and
time spent on/in-between various click events such
as play, pause, seek etc. In total, 65969 stu-
dents registered for the course, and 36536 of them
had 762137 logged video interaction sessions con-
taining the aforementioned types of click events.
If a video is played till the end, then an auto-
matic video-end pause is generated. Otherwise,
</bodyText>
<page confidence="0.994623">
4
</page>
<bodyText confidence="0.999842714285714">
the Coursera platform unfortunately does not log
whether or not a student has left the video in the
middle, leaving the true video engagement time
unknown. To avoid biased data, we only include
video sessions containing video-end pauses. This
has yielded a dataset of 222021 video sessions
from 21952 students for our analysis in this paper.
</bodyText>
<sectionHeader confidence="0.927115" genericHeader="method">
3 Operationalizing the Clickstream
</sectionHeader>
<subsectionHeader confidence="0.99655">
3.1 Level 1(Operations)
</subsectionHeader>
<bodyText confidence="0.999911142857143">
From our raw clickstream data, we construct a de-
tailed encoding of students’ clicks in the follow-
ing 8 categories: Play (Pl), Pause (Pa), SeekFw
(Sf), SeekBw (Sb), ScrollFw (SSf), ScrollBw
(SSb), RatechangeFast (Rf), RatechangeSlow
(Rs). When two seeks happen within a small time
range (&lt; 1 sec), we group these seek events into a
scroll. Additionally, to encode ‘Rf’ and ‘Rs’, we
look for the playrate of the click event that occurs
just before the ‘Ratechange’ click and compare it
with students’ currently changed playrate, to de-
termine whether he has sped up/slowed down his
playing speed. The reason behind encoding click-
streams to such specific categories, accommodat-
ing scrolling behavior and clicks representative of
increase and decrease in video playing speed, is to
experimentally analyze and understand the impact
of such a granularity on our experiments, which
are designed with an objective to capture the mot-
ley of differently motivated behavioral watching
style in students.
As a next step, we concatenate these click
events for every student, for every video lec-
ture watched. Thus, the output from level 1 is
this string of symbols that characterizes the se-
quence of clickstream events (video watching state
sequence). For e.g: PlPaSfSfPaSbPa.., PlSSb-
PaRsRsPl..
</bodyText>
<subsectionHeader confidence="0.998818">
3.2 Level 2 (Behavioral Actions)
</subsectionHeader>
<bodyText confidence="0.999341714285714">
Existing literature on web usage mining says that
representing clicks using higher level categories,
instead of raw clicks, better exposes the brows-
ing pattern of users. This might be because high
level categories have better noise tolerance than
naive clickstream logs. The results obtained from
grouping clickstream sequences at per click res-
olution are often difficult to interpret, as such
a fine resolution leads to a wide variety of se-
quences, many of which are semantically equiv-
alent. Therefore, to get more insights into stu-
dent behavior in MOOCs, we group clicks en-
coded at very fine granularity into meaningful be-
havioral categories. Doing this also reduces se-
quence length which is easily interpretable. There
is some existing literature (Banerjee and Ghosh,
2000; Wang et al., 2013), that just considers click
as a binary event (yes/no) and discusses formation
of concept based categories based on the area/sub
area of the stimulus where the click was made.
To summarize a students’ clickstream, we ob-
tain n-grams with maximum frequency from the
clickstream sequence (a contiguous sequence of
‘n’ click actions). Such a simple n-gram represen-
tation convincingly captures the most frequently
occurring click actions that students make in con-
junction with each other (n=4 was empirically de-
termined as a good limit on clickstream subse-
quence overspecificity). Then, we construct seven
semantically meaningful behavioral categories us-
ing these discovered n-grams, selecting represen-
tative click groups that occur within top ‘k’ most
frequent n-grams (k=100). Each behavioral cate-
gory acts like a latent variable, which is difficult to
measure from data directly.
</bodyText>
<listItem confidence="0.998826423076923">
• Rewatch: PlPaSbPl, PlSbPaPl, PaSbPlSb,
SbSbPaPl, SbPaPlPa, PaPlSbPa
• Skipping:SfSfSfSf, PaPlSfSf, PlSfSfSf, SfS-
fSfPa, SfSfPaPl, SfSfSfSSf, SfSfSSfSf, Sf-
PaPlPa, PlPaPlSf
• Fast Watching: PaPlRfRf, RfPaPlPa, RfRf-
PaPl, RsPaPlRf, PlPaPlRf (click group of
Ratechange fast clicks while playing or paus-
ing video lecture content, indicating speeding
up)
• Slow Watching: RsRsPaPl, RsPaPlPa,
PaPlRsRs, PlPaPlRs, PaPlRsPa, PlRsPaPl
(click group of Ratechange slow clicks while
playing or pausing video lecture content, in-
dicating slowing down)
• Clear Concept: PaSbPlSSb, SSbSbPaPl,
PaPlSSbSb, PlSSbSbPa (a combination of
SeekBw and ScrollBw clicks, indicating high
tussle with the video lecture content)
• Checkback Reference: SbSbSbSb, PlSbS-
bSb, SbSbSbPa, SbSbSbSf, SfSbSbSb, Sb-
PlSbSb, SSbSbSbSb (a wave of SeekBw
clicks)
• Playrate Transition: RfRfRsRs, RfRfRfRs,
RfRsRsRs, RsRsRsRf, RsRsRfRf, RfRfRfRf
(a wave of ratechange clicks)
</listItem>
<page confidence="0.963894">
5
</page>
<table confidence="0.532768">
Case (Full, No, Partial Clickstream A Clickstream B Fuzzy string matching
match) verdict
1:Varying clickstream PlPaPlSfPaSfSbSbPl PlPaPlSfPaSfSbSbPlPaSbSbSbRfRsRf Weight(P,A)&gt;Weight(P,B)
length (learner has performed lot more clicks)
2:Behavioral pattern ap- PlPaPlSfPaSfSbSbPl PlPaPlSfPaSfSbSbPlPlSfPaSf Weight(P,A)&lt;Weight(P,B)
pears more than once (pattern is more characteristic as it ap-
pears 2 times)
3:No appearance of be- RfSbSbRs SSfSSfRsRsRsSfSfSfSfRfRfRfRfRf Weight(P,A)54(P,B)
havioral pattern (string length doesn’t matter) (very low weight)
4:Variation in number of RfSbSbRsPlSbPaSb RfSbSbRsPlSbSfPaSfSb Weight(P,A)&lt;Weight(P,B)
individual clicks (more clicks from pattern appear)
5:Variation in scattering RfSbRsPlSbSfPaSfSb RfSbRsPlSbSSbSfPlSbRsPaSbRfSf Weight(P,A)&gt;Weight(P,B)
of individual clicks (less scattering) (more scattering)
6:Reverse order of indi- RfRsSbSfPaSfSbPl RfRsPlSbSfPaSfSb Weight(P,A)&lt;Weight(P,B)
vidual click appearance (order reversed) (order maintained)
</table>
<tableCaption confidence="0.869316">
Table 1: Fuzzy string similarity weights for the sample behavioral action P(“PlSfPaSf”). Weight(P, A/B)
</tableCaption>
<bodyText confidence="0.993816348837209">
represents the similarity of the pattern P w.r.t clickstream sequence A or B.
In an attempt to quantify the importance of each
of the above behavioral actions in characterizing
the clickstream, we adopt a fuzzy string match-
ing approach. Using this approach, we assign
a weight to each of the grouped behavioral pat-
terns for a given students’ video watching state se-
quence (based on similarity of click groups present
in each behavioral category, with the full click-
stream sequence). The fuzzy string method (Van,
2014) is justified because it caters to the noise that
might be present in raw clickstream logs of stu-
dents, in six different ways, as mentioned in Ta-
ble 1. After identifying these cases and meticu-
lous experimental evaluation, we apply the follow-
ing distance metrics and tuning parameters: Co-
sine similarity metric between the vector of counts
of n-gram (n=4) occurrences for Cases 1 and 2,
Levenshtein similarity metric for Cases 3 (weight
for deletion=0, weight for insertion and substitu-
tion=1), 4, 5, 6 (weight for deletion=0.1, weight
for insertion, substitution=1).
As a next step, all subcategories of click groups
that lie within each behavioral category are aggre-
gated by summing up the individual fuzzy string
similarity weights that are obtained with respect
to every students’ clickstream sequence. Then,
we perform a discretization of these summed up
weights, for each behavioral category, by equal
frequency (High/Low). The concern of adding up
two distance metrics that do not lie in the same
range, is thus alleviated, because the dichotomiza-
tion automatically places highly negative values in
the “Low” category and positive values closer to
0 in the “High” category. The result is a click-
stream vector for each video viewing session of
the student, where every element of the vector
tells us about the weight (importance) of a behav-
ioral category for characterizing the clickstream.
Thus, the output from level 2 is such a summarized
clickstream vector. For e.g: (Skipping=High, Fast
Watching=High, Checkback Reference=Low, Re-
watch=Low, ....).
</bodyText>
<subsectionHeader confidence="0.998597">
3.3 Level 3 (Information Processing)
</subsectionHeader>
<bodyText confidence="0.999989">
Watching MOOC videos is an interaction between
the student and the medium, and therefore the con-
ceptualization of higher-order thinking eventually
leading to knowledge acquisition (Chi, 2000), is
under control of both the a)student (who decides
what video segment to watch, when and in what
order to watch, how hard an effort be made to
try and understand a specific video segment) and,
b)medium/video lecture (the content or features
of which decides what capacity allocation is re-
quired by the student to fully process the informa-
tion contained).
Research has consistently found that the level
of cognitive engagement is an important aspect of
student participation (Carini et al., 2006). This
cognitive processing is influenced by the appeti-
tive (approach) and aversive (avoidance) motiva-
tional systems of a student, which activate in re-
sponse to motivationally relevant stimuli in the en-
vironment (Cacioppo and Wendi, 1999). For ex-
ample, in the context of MOOCs, the appetitive
system’s goal is in-depth exploration and infor-
mation intake, while the aversive system primar-
ily serves as a motivator for not attending to cer-
tain MOOC video segments. Thus, click behaviors
representative of appetitive motivational system
are rewatch/clear concept/slow watching, while
click behaviors representative of aversive motiva-
</bodyText>
<page confidence="0.99556">
6
</page>
<figureCaption confidence="0.99352">
Figure 1: Relating students’ information processing to click behaviors exhibited in the MOOC, based on
video lecture perception
</figureCaption>
<bodyText confidence="0.97856953125">
tional system are skipping/fast watching. In this
work, we try to construct students’ information
processing index, based on the “Limited Capacity
Information Processing Approach” (Basil, 1994;
Lang et al., 1996; Lang, 2000), which asserts that
people independently allocate limited amount of
cognitive resources to tasks from a shared pool.
Figure 1 depicts this idea.
We must acknowledge the fact that video watch-
ing in MOOCs requires students to recall facts that
they already know (specific chunks of declarative
knowledge (Anderson, 2014). This helps them to
build a mental representation of the information
presented in a MOOC video lecture segment, fol-
low and understand the concept being currently
taught. However, it must be noted that depending
on the a)expertise level, which decides how avail-
able the past knowledge is and how hard is it to
retrieve the previously known facts, b)perception
of video lecture as difficult or simple to under-
stand, c)motivation to learn or just have a look at
the video lecture to seek specific outcomes, cog-
nitive resource allocation would vary among these
time sensitive subprocesses in stage 1 and 2 of the
pipeline (depicted in Figure 1). This in turn, would
be reflected by the underlying non linear navi-
gational patterns that students have, specifically
the nature of clicks which they make to adjust
the speed of information processing (by pausing,
seeking forward/backward, ratechange clicks), as
responses to the stimuli.
Consider an example of students who watch the
MOOC lecture, primarily because of reasons such
as gaining familiarity with the topic. Such stu-
dents would purposely not allocate their process-
ing resources to “memory” part of the information
processing pipeline (encode, store, retrieve). Ad-
ditionally, they will decode and process minimal
information that is required to follow the story.
On the contrary, students who watch the MOOC
lecture, with the aim of scoring well in post-tests
(MOOC quizzes and assignments), would allocate
high cognitive processing to understand, learn and
retain information from the lecture. Thus, such
students would process information more fully
and thoroughly, despite a possibility of cognitive
overload.
In order to relate our behavioral actions con-
structed from the raw clickstream with this rich
and informative stream of literature, we create a
taxonomy of behavioral actions exhibited in the
clickstream to construct a quantitative “Informa-
tion Processing Index (IPI)”. Figure 2 reflects
the proposed hierarchy of information processing
from high to low using linear weight assignments.
We omit the line of reasoning that goes behind
defining the precise position of each behavioral ac-
tion in this hierarchy due to lack of space. How-
ever, the details can be found in (Sinha, 2014c).
Negative weights are necessary to distinguish be-
tween “high” and “low” weights for each behav-
ioral action. For example, if skipping=high is
weighted -3, skipping=low will be weighted +3 on
the information processing index. Students’ infor-
</bodyText>
<page confidence="0.994058">
7
</page>
<figure confidence="0.858996142857143">
mation processing index is defined as follows:
Information Processing Index (IPI) =
7
(−1)j E WeightAssign(Behavioral Action i),
8=1
j=1,2 depending on whether the behavioral action
is weighted low or high.
</figure>
<figureCaption confidence="0.83322">
Figure 2: Linear weight assignments for behav-
ioral clickstream actions, according to the infor-
mation processing hierarchy developed
</figureCaption>
<bodyText confidence="0.999991588235294">
One of the focal utilities of developing such
a quantitative index is that meaningful interven-
tion could be provided in real time to students, as
they steadily build up their video watching pro-
file while interacting with MOOC video lectures.
Viewing throught the lens of the Goldilocks prin-
ciple (Kidd et al., 2012), our metric can poten-
tially help instructors in understanding and differ-
entiating between students looking away from the
MOOC visual sequence, because of too simple or
too complex representation. Adaptive presenta-
tion of instructional materials is another learning
science application where leveraging our metric
would be beneficial.
Specifically, when IPI &gt; 0, it can be inferred
that high information processing is being done
by students. Therefore MOOC instructors need
to check for coherency in pace of instruction de-
livery and students’ understanding. This might
also hint towards redesigning specific video lec-
ture segments and simplifying them so that they
become easier to follow. On the contrary, when
IPI &lt; 0, low information processing is being done
by students. Therefore MOOC instructors need
to help students better engage with the course,
by providing them additional interesting read-
ing/assignment material, or fixing video lecture
content such that it captures students’ attention.
The neutral case of IPI = 0 occurs when students’
locally exhibited high and low information pro-
cessing needs in their evolving clickstream se-
quence counterbalance each other. So, interven-
tions need to made depending on the video lecture
segment, where IPI was &gt;0 or &lt;0.
</bodyText>
<sectionHeader confidence="0.990386" genericHeader="method">
4 Validation Experiments
</sectionHeader>
<bodyText confidence="0.999784785714286">
We use machine learning to validate the method-
ology developed in section 3.1 and 3.2 for sum-
marizing students’ clickstream, ensuring that the
same student does not appear in the train and test
folds. The motivation behind setting up these ex-
periments is to automatically measure students’
length of interaction with MOOC video lectures,
understand how they develop their video watch-
ing profile and discern what viewing profile of stu-
dents leads to in-video and course dropouts. Fur-
thermore, we validate the methodology developed
in section 3.3 by statistically analyzing variations
of IPI and testing its sensitivity to student attrition
using survival models.
</bodyText>
<subsectionHeader confidence="0.9007305">
4.1 Machine Learning Experiment Design
4.1.1 How much do you engage?
</subsectionHeader>
<bodyText confidence="0.999973615384615">
Students, while watching MOOC video lectures
can pause, seek, scroll and change rate of the
video. Thus, it is meaningful to quantify students’
engagement as the summation of video playing
time, seeks &amp; pauses, multiplied by the playback
rate. For example, if a student plays 700 secs out
of a 1000 sec video, pauses 2 times for 100 secs
each, at an average play rate of 1.5, he effectively
engages with the video for (700+200)∗1.5=1350
secs. Such an interaction measure multiplied by
playback rate, is representative of effective video
lecture content covered.
Research Question 1: Can students’ click-
stream sequence predict length of students’ inter-
action with the video lecture?
Settings: The data for this experiment comes
from a randomly chosen video lecture 4-6 (6th lec-
ture in the 4th week of the course, with not too
many initial lurkers and not too many dropouts).
For experimental purposes, engagement times for
students are discretized by equal frequency into 2
categories (High/Low). The dependent variable is
student engagement (High: 1742 examples, Low:
1741 examples). L2 regularized Logistic Regres-
sion is used as the training algorithm (with 10
fold cross validation annotated by student-id and
</bodyText>
<page confidence="0.99522">
8
</page>
<bodyText confidence="0.999918333333333">
rare feature extraction threshold being 2). As fea-
tures, we extract N-grams of length 4 and 5, se-
quence length and regular expressions from stu-
dents’ clickstream sequences. In the changed
setup, we consider summarized behavioral action
vectors (output from level 2) as column features.
</bodyText>
<subsectionHeader confidence="0.683598">
4.1.2 Are you bored or challenged?
</subsectionHeader>
<bodyText confidence="0.999977071428572">
Next, we focus our attention on how clickstream
sequences evolve. If we know that students’ in-
teraction with the video lecture is going to be
for a long time (reflected by high engagement),
it could have been the case that they were strug-
gling at the current level of instruction (for exam-
ple, a high combination of pause/seek backward
events). Therefore, if such a phenomenon can
be detected in real time video lecture interaction,
such learners can be presented with reinforcement
course material before moving forward. Alterna-
tively, if we know that students’ interaction with
the video lecture is going to be for a short time (re-
flected by low engagement), they could be bored
or are quite likely to skip course content forward
often. Such students can be presented with ad-
vanced study material. However, in order to de-
velop such a real time knowledge model and tailor
targeted interventions at students, we need to study
the trajectory of click sequence formation.
Research Question 2: Can we precisely predict
what will be the next sequence of clicks that leads
students to different engagement states?
Settings: The data for this experiment comes
from the same video lecture 4-6 (6th lecture in
the 4th week of the course). The dependent
variable is next click state of students (Pa, Pl,
Sf, SSf, Sb, SSb, Rf, Rs). L2 regularized Lo-
gistic Regression is used as the training algo-
rithm (with 5 fold cross validation annotated by
student-id and rare feature extraction threshold
being 5). If we want to predict the click at
the ith instant, we extract the following features
from 0 till (i-1)th instant: a)Engagement with the
video lecture as defined for Research Question
1(High/Low); b)Proportion of click events belong-
ing to Pl/Pa/Sf/SSf/Sb/SSb/Rf/Rs (representative
of kind of interaction with the stimulus); c)N-
grams of length 4,5 and sequence length from
students’ clickstream sequences. In the changed
setup, we consider summarized behavioral action
vectors (output from level 2) as column features.
</bodyText>
<subsectionHeader confidence="0.721102">
4.1.3 Will you drop out of the video?
</subsectionHeader>
<bodyText confidence="0.99982793877551">
As students progress through the video, they
slowly build up their video watching profile by
interacting with the stimulus in different propor-
tions, which in turn depend on their click action
sequences. This motivates our next machine learn-
ing experiment, which seeks to derive utility from
the first two experiments. Navigating away from
the video without completing it fully is an out-
come of low student engagement. A student is
more likely to watch till the end of a video, if the
lecture activates his thinking. Thus, it would be in-
teresting to investigate, whether the nature of stu-
dents’ interaction provides us a hint about in-video
dropout behavior. Prior work has made a prelim-
inary study on how in-video dropout is correlated
with length of the video, and how in-video dropout
varies among first time watchers and rewatchers
(Kim et al., 2014a). However, we consider video
interaction features at a much finer granularity,
representative of how students progress through
the video. In doing so, we use detailed clickstream
information, including seek, scroll and ratechange
behavior, in addition to merely play and pause in-
formation.
Research Question 3: What video watching
profile of students leads to in-video dropouts?
Settings: The data for this experiment comes
from the same video lecture 4-6 (6th lecture in
the 4th week of the course). The dependent
variable is the binary variable, in-video dropout
(0/1). To address the skewed class distribution,
cost sensitive L2 regularized Logistic Regression
is used as the training algorithm (with 10 fold
cross validation annotated by student-id and rare
feature extraction threshold being 2). To ex-
tract the interaction footprint of students before
they drop out of the video, we extract the fol-
lowing features: a)N-grams of length 4,5 and
sequence length from students’ clickstream se-
quences; b)Proportion of click events belonging to
Pl/Pa/Sf/SSf/Sb/SSb/Rf/Rs (representative of kind
of interaction with the stimulus); c)Engagement
with the video lecture as defined for Research
Question 1(High/Low); e)Last click action before
dropout happened; f)Time spent after the last click
action was made (discretized by equal frequency
to High/Low). In the changed setup, we con-
sider summarized behavioral action vectors (out-
put from level 2) as column features.
</bodyText>
<page confidence="0.994775">
9
</page>
<note confidence="0.6414435">
4.1.4 Will you watch videos and stay till the
course end?
</note>
<bodyText confidence="0.998658606557377">
We may expect that when students find the course
too tough to follow, uninteresting or boring, they
will not engage with future videos. On the con-
trary, when students seem very interested in un-
derstanding the video and exhibit lots of rewatch-
ing behavior, we might expect them to stay on till
the course end video lectures. Students who do
not stay till the last week of the course (exhibit any
video lecture viewing), are considered as complete
course dropouts. One principal application of de-
tecting these dropouts early could be recommen-
dation of selected future video lectures to watch
(for example, where an interesting concept, case
study or application is going to be discussed), to
positively motivate and pull these students back
into the MOOC.
Research Question 4: Can we discover pat-
terns in the video watching trajectory of students
that can predict when are students most likely not
to view future video lectures?
Settings: The data for this experiment comes
from all 48 videos of “Functional Program-
ming in Scala” MOOC (4710 non-dropouts, 9596
dropouts). To address the skewed class distribu-
tion, cost sensitive L2 regularized Logistic Re-
gression is used as the training algorithm (with 5
fold cross validation annotated by student-id and
rare feature extraction threshold being 5). The
dependent variable is the binary variable, com-
plete course dropout (0/1), indicating whether the
student ultimately stayed on (watched any video
lecture) till the last course week. Engagement
(time in seconds) of a student is discretized by
equal frequency into High and Low categories,
considering all interactions in each video lecture
separately (because length of each video differs,
so the discretization criteria would also differ for
each video). Video play proportion((video played
length/video length)*100*average play rate) for a
student is discretized by equal width (Very Low:
&lt;50%, Low: 50-100%, High: 100-150%, Very
High: &gt;150%). IPI for a student is discretized by
equal frequency (Very Low: &lt;-1.00, Low: [-1.00,
1.00], High: [1.00, 3.00], Very High: &gt;3.00).
The discretization criteria (equal width, frequency
and number of bins) was experimentally deter-
mined. Development of trajectories for each of
these factors is indicated in Figure 3. To extract
the interaction footprint of students before they
drop out of the course, we extract the following
features: a)N-grams of length 4,5 and sequence
length from “Engagement trajectory”, “Video Play
Proportion trajectory” and “IPI trajectory” of stu-
dents for the videos watched from 0 to (n-1)th in-
stant, b)Engagement, Video Play Proportion and
IPI trajectories for the nth instance (attribute for
the last video lecture watched before dropping
out), c)Proportion of different symbol representa-
tions in the trajectories (for example, in a trajec-
tory such as HLLHH, proportion(H)=60%, pro-
portion(L)=40%.
</bodyText>
<figureCaption confidence="0.9855395">
Figure 3: Example depicting how different opera-
tionalized trajectories of students are formed
</figureCaption>
<subsectionHeader confidence="0.822007">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.999842230769231">
Results of the four machine learning experiments,
along with the most representative (weighted) fea-
tures that characterize classes, are reported in table
2. There are two important positives here: a)The
summarized behavioral action vectors from level
2 are able to achieve nearly similar values of ac-
curacy and kappa when compared to the raw level
clicks. This means that we can reason different
meaningful video viewing behaviors of students
without getting our hands dirty in examining noisy
and continually occurring raw clicks, b)Our met-
ric of interest, i.e the false negative rate1 is lower
for Case 1.B and Case 3.B, as compared to Case
1.A and Case 3.A, which shows the effectiveness
of the clickstream summarization approach (level
2) in pre-deciphering the fate of students to some
extent.
Additionally, we leverage a statistical analy-
sis technique referred as survival analysis (Miller,
2011), to quantify the extent to which our summa-
rized behavioral clickstream action vectors and IPI
are sensitive to students’ dropout. In this model-
ing scheme, dropout variable is 1 on the students’
last week of active participation (in terms of video
lecture viewing), and is 0 for all other weeks.
Our investigation results indicate that a)Students’
</bodyText>
<footnote confidence="0.9756965">
1False negative rate of 0.x means that we correctly iden-
tify (100-(100*0.x))% of dropouts
</footnote>
<page confidence="0.98583">
10
</page>
<table confidence="0.999837931034483">
Research Condition Accuracy False Negative Most representative (weighted) features that char-
Question Kappa Rate acterize classes
1. Engagement A)Raw Clicks 0.81 0.24 High (skipping=low, playrate transition=low, re-
Prediction B)Summarized 0.63 0.15 watch=high, slow watching=low, checkback refer-
Behavioral 0.75 ence=low, clear concept=high)
Action 0.49 Low (skipping=high, playrate transition=high, re-
Vectors watch=low, slow watching=high, checkback refer-
ence=high, clear concept=low)
2. Next Click A)Raw Clicks 0.68 - SeekFw (playratetransition=low, skipping=low, fast
Prediction B)Summarized 0.57 - watching=high, clearconcept=low)
Behavioral 0.66 SeekBw (checkbackreference=high, rewatch=low,
Action 0.54 playratetransition=low, propSeekBw, clearcon-
Vectors cept=high)
Ratechangefast (playratetransition=high, re-
watch=low, checkbackreference=low)
Ratechangeslow (playratetransition=high, clearcon-
cept=high)
3. In-video A)Raw Clicks 0.90 0.19 Non dropouts (skipping=low, clearconcept=high,
dropout B)Summarized 0.69 0.15 slow watching=high, Checkbackreference=low,
Prediction Behavioral 0.90 rewatch=high, engagementfromStart=low, engage-
Action 0.70 mentlastClick=high)
Vectors Dropouts (skipping=high, clearconcept=low,
slow watching=low, engagementfromStart=high,
rewatch=low, engagementlastClick=low, checkback-
reference=high)
4. Complete Operationalized 0.80 0.143 Non dropouts (trajectory IPI=H H H H, trajec-
Course dropout trajectories 0.57 tory eng=H H H VL H, trajectory vpp=H H H L H)
Prediction Dropouts (trajectory IPI=H H VL VL VL, trajec-
tory eng=H L H L L, trajectory vpp=H H H H VL)
</table>
<tableCaption confidence="0.999542">
Table 2: Performance metrics for machine learning experiments. Random baseline performance is 0.5
</tableCaption>
<bodyText confidence="0.999955980769231">
dropout in the MOOC is 37% less likely, if they
have one standard deviation greater IPI than aver-
age (Hazard ratio: 0.6367, p&lt;0.001). Such stu-
dents grapple more with the course material to
achieve their desired learning outcomes (as re-
flected by their video lecture participation), b)If
students’ rewatching behavior changes from low
to high, they are 33% less likely to dropout (Haz-
ard ratio: 0.6734, p&lt;0.001), c)As students start
watching more proportion of the video lecture,
they are 37% less likely to dropout of the MOOC
(Hazard ratio: 0.6334, p&lt;0.001). This is indica-
tive of their continued interest in the video lecture.
Next, to discern how IPI fluctuates among dif-
ferent student partitions and validate whether our
operationalization produces meaningful results,
we plot figures 4, 5 and perform statistical tests,
specifically z test (testing significance of differ-
ence between means for large sample sizes, when
population standard deviation is known). Pop-
ulation refers to all students in the MOOC be-
ing currently studied. The right half of figure 4
depicts the variation of average IPI, among high
versus low engagers and in-video dropouts ver-
sus non dropouts, in the same video lecture 4-
6 from the course, that we have been perform-
ing our experiments on. Similar findings were
also confirmed with other randomly chosen course
videos. The left half of figure 4 shows the fre-
quency distribution of average IPI. This figure
concurs with our intuitions. The average IPI is
significantly higher for students with “High” en-
gagement (Izl=8.296, p&lt;0.01) and “Non In-video
dropouts” (Izl=22.54, p&lt;0.01). This is also re-
flected in the histogram, which clearly shows
that many non in-video dropouts have positive
IPI that pushes up the average. Because the ef-
fect is smaller in low engagers versus high en-
gagers, we see a more similar frequency distri-
bution of average information processing indices
in these 2 bins, as compared to contrasting differ-
ences in the histogram for in-video dropouts and
non dropouts. In order to generalize these find-
ings, we also look at the variations of average
IPI among some other student partitions that we
made for the whole course. “Viewers” are stu-
dents who have watched or interacted with some
video lecture but have not done the exercises; the
“Active” students additionally turn in homework
also. MOOC dropouts are those students who
cease to actively participate in the MOOC (we are
concerned with video lecture viewing only) before
</bodyText>
<page confidence="0.998605">
11
</page>
<figureCaption confidence="0.9999975">
Figure 4: Variation of Average Information Processing Indices(IPI) for Video 4-6
Figure 5: Variation of Average Information Processing Indices(IPI) for the full course
</figureCaption>
<bodyText confidence="0.9999330625">
the last week, i.e, students who do not finish the
course. An important observation in figure 5 is
that IPI is clearly able to distinguish between Non-
dropouts and Dropouts (|z|=9.06, p&lt;0.01). This
is also reflected in the histogram in the left half of
figure 5, which verifies that more “Non dropouts”
have positive IPI. More is the information pro-
cessing done by students, greater is the video lec-
ture involvement, higher are the chances to derive
true utility from video lecture and remain excited
and motivated to stay in the course. We also ob-
tain striking differences between “Active” versus
“Viewers” (Izl=10.45, p&lt;0.01). Intuitively too,
we expect “Viewers” to have higher IPI than “Ac-
tive” class, because as their primary MOOC activ-
ity, “Viewers” grapple more with the video lecture.
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999983967741936">
In this work, we have begun to lay a foundation for
research investigating students’ information pro-
cessing behavior while interacting with MOOC
video lectures. Focusing the center of gravity on
the human mind, we applied a cognitive video
watching model to explain the dynamic process
of cognition involved in MOOC video clickstream
interaction. This paved way for the development
of a simple, yet potent IPI using linear weight as-
signments, which can be effectively used as an
operationalization for making predictions regard-
ing critical learner behavior. We could contem-
plate that IPI significantly varies among different
student partitions. This actually happens because
of presence of smaller substructures inside these
larger groupings, that are similar in their click be-
haviors. Deciphering unique ways of video lec-
ture interaction in such smaller clusters using ap-
proaches such as Markov based clustering, would
be very meaningful for course instructors, to de-
sign customized learning solutions for students
within them (Sinha, 2014c). It would make sense
to incorporate student demographics to better un-
derstand some latent factors, such as playback
speed choices due to native language differences
versus engagement etc. In our recent work (Sinha
et al., 2014), we have been seeking to gain bet-
ter visibility into how combined representations of
video clickstream behavior and discussion forum
footprint can provide insights on interaction path-
ways that lead students to central activities.
</bodyText>
<page confidence="0.998189">
12
</page>
<sectionHeader confidence="0.996372" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999872122641509">
Anderson, A., Huttenlocher, D., Kleinberg, J., &amp;
Leskovec, J. (2014, April). “Engaging with massive
online courses”. In Proceedings of the 23rd interna-
tional conference on World wide web (pp. 687-698).
International World Wide Web Conferences Steering
Committee.
Anderson, J. R. (2014). “Rules of the mind”. Psychol-
ogy Press.
Banerjee, A., &amp; Ghosh, J. (2000). “Concept-based
clustering of clickstream data”.
Basil, M. D. (1994). “Multiple resource theory I ap-
plication to television viewing”. Communication Re-
search, 21(2), 177-207
Belanger, Y., &amp; Thornton, J. (2013). “Bioelectricity:
A Quantitative Approach Duke Universitys First
MOOC”.
Brinton, C. G., Chiang, M., Jain, S., Lam, H., Liu,
Z., &amp; Wong, F. M. F. (2013). “Learning about so-
cial learning in moocs: From statistical analysis to
generative model”. arXiv preprint arXiv:1312.2159.
Cacioppo, J. T., and Wendi L. G. (1999). “Emotion”.
Annual Reviews: Psychology, 50, 191-214.
Carini, R. M., Kuh, G. D., &amp; Klein, S. P. (2006). “Stu-
dent engagement and student learning: Testing the
linkages”. Research in Higher Education, 47(1), 1-
32.
Chi, M. T. (2000). “Self-explaining expository texts:
The dual processes of generating inferences and re-
pairing mental models”. Advances in instructional
psychology, 5, 161-238.
Clow, D. (2013). “MOOCs and the funnel of participa-
tion” In Proceedings of the Third International Con-
ference on Learning Analytics and Knowledge, pp.
185-189. ACM
Coetzee, D., Fox, A., Hearst, M. A., &amp; Hartmann,
B. (2014, February). “Should your MOOC forum
use a reputation system?”. In Proceedings of the
17th ACM conference on Computer supported coop-
erative work &amp; social computing (pp. 1176-1187).
ACM.
Davis, H. C., Dickens, K., Leon Urrutia, M., Vera, S.,
del Mar, M., &amp; White, S. (2014). “MOOCs for Uni-
versities and Learners An analysis of motivating fac-
tors”.
Fischer, G. (2011). “Understanding, fostering, and sup-
porting cultures of participation”. Interactions 18,
no. 3: 42-53.
Guo, P. J., &amp; Reinecke, K. (2014, March). “Demo-
graphic differences in how students navigate through
MOOCs”. In Proceedings of the first ACM confer-
ence on Learning@ scale conference (pp. 21-30).
ACM.
Guo, Philip J., Juho Kim, and Rob Rubin. (2014).
“How video production affects student engagement:
An empirical study of mooc videos” ACM Learing
at Scale(L@S), pp. 41-50.
Haggard, S., S. Brown, R. Mills, A. Tait, S. Warburton,
W. Lawton, and T. Angulo. (2013). “The maturing
of the MOOC: Literature review of Massive Open
Online Courses and other forms of online distance
learning” BIS Research Paper 130
Huang, J., Dasgupta, A., Ghosh, A., Manning, J., &amp;
Sanders, M. (2014, March). “Superposter behav-
ior in MOOC forums”. In Proceedings of the first
ACM conference on Learning@ scale conference
(pp. 117-126). ACM.
Kidd, C., Piantadosi, S. T., &amp; Aslin, R. N. (2012). “The
Goldilocks effect: Human infants allocate attention
to visual sequences that are neither too simple nor
too complex”. PLoS One, 7(5), e36399.
Kim, J., Guo, P. J., Seaton, D. T., Mitros, P., Gajos,
K. Z., &amp; Miller, R. C. (2014a, March). “Understand-
ing in-video dropouts and interaction peaks inonline
lecture videos”. In Proceedings of the first ACM con-
ference on Learning@ scale conference (pp. 31-40).
ACM.
Kim, J., Shang-Wen L., Carrie J. C., Krzysztof Z. G.,
Robert C. M. (2014b). “Leveraging Video Interac-
tion Data and Content Analysis to Improve Video
Learning” CHI 2014 Workshop on Learning Inno-
vation at Scale
Kulkarni, C. E., Socher, R., Bernstein, M. S., &amp; Klem-
mer, S. R. (2014, March). “Scaling short-answer
grading by combining peer assessment with algo-
rithmic scoring”. In Proceedings of the first ACM
conference on Learning@ scale conference (pp. 99-
108). ACM.
Lang, A., John N., and Byron R. (1996). “Negative
video as structure: Emotion, attention, capacity,
and memory”. Journal ofBroadcasting &amp; Electronic
Media, 40(4), 460-477
Lang, A. (2000). “The limited capacity model of me-
diated message processing”. Journal of communica-
tion, 50(1), 46-70.
Lie M. T., Debjanee B., Judy K. (2014). “Online learn-
ing at scale: user modeling requirements towards
motivation and personalisation”. In Learning Inno-
vations at Scale CHI’ 14 Workshop
Miller Jr, Rupert G. (2011). “Survival analysis”. Vol.
66. John Wiley &amp; Sons
Nawrot, I., and Antoine D. (2014). “Building engage-
ment for MOOC students: introducing support for
time management on online learning platforms.” In
Proceedings of the companion publication of the
23rd international conference on World wide web
companion, pp. 1077-1082.
</reference>
<page confidence="0.987762">
13
</page>
<reference confidence="0.999560490196079">
North, S. M., Ronny R., and Max M. N. (2014). “To
Adapt MOOCS, or Not? That is No Longer the
Question.” Universal Journal of Educational Re-
search 2(1): 69-72
Ramesh, A., Goldwasser, D., Huang, B., Daum H. III,
and Getoor, L. (2013). “Modeling Learner Engage-
ment in MOOCs using Probabilistic Soft Logic”. In
NIPS Workshop on Data Driven Education
Schmidt, D. C., and Zach M. (2013). “Producing and
Delivering a Coursera MOOC on Pattern-Oriented
Software Architecture for Concurrent and Net-
worked Software”
Sinha, T., Banka, A., Kang, D. K., (2013). “Leveraging
user profile attributes for improving pedagogical ac-
curacy of learning pathways”. In Proceedings of 3rd
Annual International Conference on Education and
E-Learning(EeL 2013), Singapore
Sinha, T. (2014a). “Together we stand, Together we
fall, Together we win: Dynamic team formation in
massive open online courses” In Fifth International
Conference on the Applications of Digital Informa-
tion and Web Technologies (ICADIWT) pp. 107-112.
IEEE
Sinha, T. (2014b). “Supporting MOOC Instruction
with Social Network Analysis”. arXiv preprint
arXiv:1401.5175
Sinha, T. (2014c). “Your click decides your fate”:
Leveraging clickstream patterns from MOOC videos
to infer students’ information processing &amp; attrition
behavior. arXiv preprint arXiv:1407.7143.
Sinha, T., Li, N., Jermann, P., Dillenbourg, P. (2014).
Capturing attrition intensifying structural traits from
didactic interaction sequences of MOOC learners.
Proceedings of the 2014 Empirical Methods in Nat-
ural Language Processing Workshop on Modeling
Large Scale Social Interaction in Massively Open
Online Courses, Qatar, October 2014
Tillmann, N., De Halleux, J., Xie, T., Gulwani, S., and
Bishop, J. (2013). “Teaching and learning program-
ming and software engineering via interactive gam-
ing”. In ICSE, 11171126
Van der L., Mark PJ. (2014). “The stringdist Package
for Approximate String Matching” The R Journal
Wang, G., Tristan K., Christo W., Xiao W., Haitao
Z., and Ben Y. Z. (2013). “You are how you click:
Clickstream analysis for sybil detection” In USENIX
Security Symposium (Washington, DC)
Yang, D., Sinha T., Adamson D., and Rose C. P. (2013).
“Turn on, Tune in, Drop out: Anticipating student
dropouts in Massive Open Online Courses” In NIPS
Workshop on Data Driven Education
</reference>
<page confidence="0.999241">
14
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.195124">
<title confidence="0.9988685">Your click decides your fate: Inferring Information Processing Attrition Behavior from MOOC Video Clickstream Interactions</title>
<author confidence="0.998252">Patrick Nan Pierre</author>
<address confidence="0.444865666666667">Technologies Institute, Carnegie Mellon University, Pittsburgh PA 15213, for Digital Education, EPFL, CH 1015, Interaction in Learning and Instruction, EPFL, CH 1015,</address>
<abstract confidence="0.99486055">In this work, we explore video lecture interaction in Massive Open Online Courses (MOOCs), which is central to student learning experience on these educational platforms. As a research contribution, we operationalize video lecture clickstreams of students into cognitively plausible higher level behaviors, and construct a quantitative information processing index, which can aid instructors to better understand MOOC hurdles and reason about unsatisfactory learning outcomes. Our results illustrate how such a metric inspired by cognitive psychology can help answer critical questions regarding students’ engagement, their future click interactions and participation trajectories that lead to in-video &amp; course dropouts. Implications for research and practice are discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Anderson</author>
<author>D Huttenlocher</author>
<author>J Kleinberg</author>
<author>J Leskovec</author>
</authors>
<title>Engaging with massive online courses”.</title>
<date>2014</date>
<booktitle>In Proceedings of the 23rd international conference on World wide web</booktitle>
<pages>687--698</pages>
<institution>International World Wide Web Conferences Steering Committee.</institution>
<contexts>
<context position="3590" citStr="Anderson et al., 2014" startWordPosition="530" endWordPosition="533">ce with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), page</context>
</contexts>
<marker>Anderson, Huttenlocher, Kleinberg, Leskovec, 2014</marker>
<rawString>Anderson, A., Huttenlocher, D., Kleinberg, J., &amp; Leskovec, J. (2014, April). “Engaging with massive online courses”. In Proceedings of the 23rd international conference on World wide web (pp. 687-698). International World Wide Web Conferences Steering Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Anderson</author>
</authors>
<title>Rules of the mind”.</title>
<date>2014</date>
<publisher>Psychology Press.</publisher>
<contexts>
<context position="18614" citStr="Anderson, 2014" startWordPosition="2803" endWordPosition="2804">lick behaviors exhibited in the MOOC, based on video lecture perception tional system are skipping/fast watching. In this work, we try to construct students’ information processing index, based on the “Limited Capacity Information Processing Approach” (Basil, 1994; Lang et al., 1996; Lang, 2000), which asserts that people independently allocate limited amount of cognitive resources to tasks from a shared pool. Figure 1 depicts this idea. We must acknowledge the fact that video watching in MOOCs requires students to recall facts that they already know (specific chunks of declarative knowledge (Anderson, 2014). This helps them to build a mental representation of the information presented in a MOOC video lecture segment, follow and understand the concept being currently taught. However, it must be noted that depending on the a)expertise level, which decides how available the past knowledge is and how hard is it to retrieve the previously known facts, b)perception of video lecture as difficult or simple to understand, c)motivation to learn or just have a look at the video lecture to seek specific outcomes, cognitive resource allocation would vary among these time sensitive subprocesses in stage 1 and</context>
</contexts>
<marker>Anderson, 2014</marker>
<rawString>Anderson, J. R. (2014). “Rules of the mind”. Psychology Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Banerjee</author>
<author>J Ghosh</author>
</authors>
<title>Concept-based clustering of clickstream data”.</title>
<date>2000</date>
<contexts>
<context position="11586" citStr="Banerjee and Ghosh, 2000" startWordPosition="1783" endWordPosition="1786"> pattern of users. This might be because high level categories have better noise tolerance than naive clickstream logs. The results obtained from grouping clickstream sequences at per click resolution are often difficult to interpret, as such a fine resolution leads to a wide variety of sequences, many of which are semantically equivalent. Therefore, to get more insights into student behavior in MOOCs, we group clicks encoded at very fine granularity into meaningful behavioral categories. Doing this also reduces sequence length which is easily interpretable. There is some existing literature (Banerjee and Ghosh, 2000; Wang et al., 2013), that just considers click as a binary event (yes/no) and discusses formation of concept based categories based on the area/sub area of the stimulus where the click was made. To summarize a students’ clickstream, we obtain n-grams with maximum frequency from the clickstream sequence (a contiguous sequence of ‘n’ click actions). Such a simple n-gram representation convincingly captures the most frequently occurring click actions that students make in conjunction with each other (n=4 was empirically determined as a good limit on clickstream subsequence overspecificity). Then</context>
</contexts>
<marker>Banerjee, Ghosh, 2000</marker>
<rawString>Banerjee, A., &amp; Ghosh, J. (2000). “Concept-based clustering of clickstream data”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D Basil</author>
</authors>
<title>Multiple resource theory I application to television viewing”.</title>
<date>1994</date>
<journal>Communication Research,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>177--207</pages>
<contexts>
<context position="18263" citStr="Basil, 1994" startWordPosition="2748" endWordPosition="2749">ation intake, while the aversive system primarily serves as a motivator for not attending to certain MOOC video segments. Thus, click behaviors representative of appetitive motivational system are rewatch/clear concept/slow watching, while click behaviors representative of aversive motiva6 Figure 1: Relating students’ information processing to click behaviors exhibited in the MOOC, based on video lecture perception tional system are skipping/fast watching. In this work, we try to construct students’ information processing index, based on the “Limited Capacity Information Processing Approach” (Basil, 1994; Lang et al., 1996; Lang, 2000), which asserts that people independently allocate limited amount of cognitive resources to tasks from a shared pool. Figure 1 depicts this idea. We must acknowledge the fact that video watching in MOOCs requires students to recall facts that they already know (specific chunks of declarative knowledge (Anderson, 2014). This helps them to build a mental representation of the information presented in a MOOC video lecture segment, follow and understand the concept being currently taught. However, it must be noted that depending on the a)expertise level, which decid</context>
</contexts>
<marker>Basil, 1994</marker>
<rawString>Basil, M. D. (1994). “Multiple resource theory I application to television viewing”. Communication Research, 21(2), 177-207</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Belanger</author>
<author>J Thornton</author>
</authors>
<title>Bioelectricity: A Quantitative Approach Duke Universitys First MOOC”.</title>
<date>2013</date>
<contexts>
<context position="2522" citStr="Belanger and Thornton, 2013" startWordPosition="360" endWordPosition="363">alytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undert</context>
</contexts>
<marker>Belanger, Thornton, 2013</marker>
<rawString>Belanger, Y., &amp; Thornton, J. (2013). “Bioelectricity: A Quantitative Approach Duke Universitys First MOOC”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C G Brinton</author>
<author>M Chiang</author>
<author>S Jain</author>
<author>H Lam</author>
<author>Z Liu</author>
<author>F M F Wong</author>
</authors>
<title>Learning about social learning in moocs: From statistical analysis to generative model”. arXiv preprint arXiv:1312.2159.</title>
<date>2013</date>
<contexts>
<context position="3567" citStr="Brinton et al., 2013" startWordPosition="526" endWordPosition="529">he provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods in Natural Language P</context>
</contexts>
<marker>Brinton, Chiang, Jain, Lam, Liu, Wong, 2013</marker>
<rawString>Brinton, C. G., Chiang, M., Jain, S., Lam, H., Liu, Z., &amp; Wong, F. M. F. (2013). “Learning about social learning in moocs: From statistical analysis to generative model”. arXiv preprint arXiv:1312.2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J T Cacioppo</author>
<author>L G Wendi</author>
</authors>
<date>1999</date>
<journal>Emotion”. Annual Reviews: Psychology,</journal>
<volume>50</volume>
<pages>191--214</pages>
<contexts>
<context position="17549" citStr="Cacioppo and Wendi, 1999" startWordPosition="2644" endWordPosition="2647">tch, how hard an effort be made to try and understand a specific video segment) and, b)medium/video lecture (the content or features of which decides what capacity allocation is required by the student to fully process the information contained). Research has consistently found that the level of cognitive engagement is an important aspect of student participation (Carini et al., 2006). This cognitive processing is influenced by the appetitive (approach) and aversive (avoidance) motivational systems of a student, which activate in response to motivationally relevant stimuli in the environment (Cacioppo and Wendi, 1999). For example, in the context of MOOCs, the appetitive system’s goal is in-depth exploration and information intake, while the aversive system primarily serves as a motivator for not attending to certain MOOC video segments. Thus, click behaviors representative of appetitive motivational system are rewatch/clear concept/slow watching, while click behaviors representative of aversive motiva6 Figure 1: Relating students’ information processing to click behaviors exhibited in the MOOC, based on video lecture perception tional system are skipping/fast watching. In this work, we try to construct st</context>
</contexts>
<marker>Cacioppo, Wendi, 1999</marker>
<rawString>Cacioppo, J. T., and Wendi L. G. (1999). “Emotion”. Annual Reviews: Psychology, 50, 191-214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Carini</author>
<author>G D Kuh</author>
<author>S P Klein</author>
</authors>
<date>2006</date>
<booktitle>Student engagement and student learning: Testing the linkages”. Research in Higher Education,</booktitle>
<volume>47</volume>
<issue>1</issue>
<pages>1--32</pages>
<contexts>
<context position="17311" citStr="Carini et al., 2006" startWordPosition="2608" endWordPosition="2611">dium, and therefore the conceptualization of higher-order thinking eventually leading to knowledge acquisition (Chi, 2000), is under control of both the a)student (who decides what video segment to watch, when and in what order to watch, how hard an effort be made to try and understand a specific video segment) and, b)medium/video lecture (the content or features of which decides what capacity allocation is required by the student to fully process the information contained). Research has consistently found that the level of cognitive engagement is an important aspect of student participation (Carini et al., 2006). This cognitive processing is influenced by the appetitive (approach) and aversive (avoidance) motivational systems of a student, which activate in response to motivationally relevant stimuli in the environment (Cacioppo and Wendi, 1999). For example, in the context of MOOCs, the appetitive system’s goal is in-depth exploration and information intake, while the aversive system primarily serves as a motivator for not attending to certain MOOC video segments. Thus, click behaviors representative of appetitive motivational system are rewatch/clear concept/slow watching, while click behaviors rep</context>
</contexts>
<marker>Carini, Kuh, Klein, 2006</marker>
<rawString>Carini, R. M., Kuh, G. D., &amp; Klein, S. P. (2006). “Student engagement and student learning: Testing the linkages”. Research in Higher Education, 47(1), 1-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Chi</author>
</authors>
<title>Self-explaining expository texts: The dual processes of generating inferences and repairing mental models”.</title>
<date>2000</date>
<booktitle>Advances in instructional psychology,</booktitle>
<volume>5</volume>
<pages>161--238</pages>
<contexts>
<context position="16813" citStr="Chi, 2000" startWordPosition="2528" endWordPosition="2529">ory. The result is a clickstream vector for each video viewing session of the student, where every element of the vector tells us about the weight (importance) of a behavioral category for characterizing the clickstream. Thus, the output from level 2 is such a summarized clickstream vector. For e.g: (Skipping=High, Fast Watching=High, Checkback Reference=Low, Rewatch=Low, ....). 3.3 Level 3 (Information Processing) Watching MOOC videos is an interaction between the student and the medium, and therefore the conceptualization of higher-order thinking eventually leading to knowledge acquisition (Chi, 2000), is under control of both the a)student (who decides what video segment to watch, when and in what order to watch, how hard an effort be made to try and understand a specific video segment) and, b)medium/video lecture (the content or features of which decides what capacity allocation is required by the student to fully process the information contained). Research has consistently found that the level of cognitive engagement is an important aspect of student participation (Carini et al., 2006). This cognitive processing is influenced by the appetitive (approach) and aversive (avoidance) motiva</context>
</contexts>
<marker>Chi, 2000</marker>
<rawString>Chi, M. T. (2000). “Self-explaining expository texts: The dual processes of generating inferences and repairing mental models”. Advances in instructional psychology, 5, 161-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Clow</author>
</authors>
<title>MOOCs and the funnel of participation”</title>
<date>2013</date>
<booktitle>In Proceedings of the Third International Conference on Learning Analytics and Knowledge,</booktitle>
<pages>185--189</pages>
<publisher>ACM</publisher>
<contexts>
<context position="2119" citStr="Clow, 2013" startWordPosition="297" endWordPosition="298">ive potential of MOOCs to revolutionize online education (North et al., 2014), by connecting and fostering interaction among millions of learners who otherwise would never have met and providing autonomy to these learners to grapple with the course instruction at their own pace of understanding. However, despite this expediency, there is also considerable skepticism in the learning analytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels</context>
</contexts>
<marker>Clow, 2013</marker>
<rawString>Clow, D. (2013). “MOOCs and the funnel of participation” In Proceedings of the Third International Conference on Learning Analytics and Knowledge, pp. 185-189. ACM</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Coetzee</author>
<author>A Fox</author>
<author>M A Hearst</author>
<author>B Hartmann</author>
</authors>
<title>Should your MOOC forum use a reputation system?”.</title>
<date>2014</date>
<booktitle>In Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing</booktitle>
<pages>1176--1187</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3748" citStr="Coetzee et al., 2014" startWordPosition="553" endWordPosition="556"> is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3–14, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics istrations in MOOC courses at EPFL in 2013, our experience reflects</context>
</contexts>
<marker>Coetzee, Fox, Hearst, Hartmann, 2014</marker>
<rawString>Coetzee, D., Fox, A., Hearst, M. A., &amp; Hartmann, B. (2014, February). “Should your MOOC forum use a reputation system?”. In Proceedings of the 17th ACM conference on Computer supported cooperative work &amp; social computing (pp. 1176-1187). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H C Davis</author>
<author>K Dickens</author>
<author>Leon Urrutia</author>
<author>M Vera</author>
<author>del Mar S</author>
<author>M</author>
<author>S White</author>
</authors>
<title>MOOCs for Universities and Learners An analysis of motivating factors”.</title>
<date>2014</date>
<contexts>
<context position="2381" citStr="Davis et al., 2014" startWordPosition="339" endWordPosition="342">uction at their own pace of understanding. However, despite this expediency, there is also considerable skepticism in the learning analytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with rega</context>
</contexts>
<marker>Davis, Dickens, Urrutia, Vera, S, M, White, 2014</marker>
<rawString>Davis, H. C., Dickens, K., Leon Urrutia, M., Vera, S., del Mar, M., &amp; White, S. (2014). “MOOCs for Universities and Learners An analysis of motivating factors”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Fischer</author>
</authors>
<title>Understanding, fostering, and supporting cultures of participation”.</title>
<date>2011</date>
<journal>Interactions</journal>
<volume>18</volume>
<pages>42--53</pages>
<contexts>
<context position="3280" citStr="Fischer, 2011" startWordPosition="483" endWordPosition="484">caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5%</context>
</contexts>
<marker>Fischer, 2011</marker>
<rawString>Fischer, G. (2011). “Understanding, fostering, and supporting cultures of participation”. Interactions 18, no. 3: 42-53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Guo</author>
<author>K Reinecke</author>
</authors>
<title>Demographic differences in how students navigate through MOOCs”.</title>
<date>2014</date>
<booktitle>In Proceedings of the first ACM conference on Learning@ scale conference</booktitle>
<pages>21--30</pages>
<publisher>ACM.</publisher>
<marker>Guo, Reinecke, 2014</marker>
<rawString>Guo, P. J., &amp; Reinecke, K. (2014, March). “Demographic differences in how students navigate through MOOCs”. In Proceedings of the first ACM conference on Learning@ scale conference (pp. 21-30). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Guo</author>
<author>Juho Kim</author>
<author>Rob Rubin</author>
</authors>
<title>How video production affects student engagement: An empirical study of mooc videos”</title>
<date>2014</date>
<journal>ACM Learing at Scale(L@S),</journal>
<pages>41--50</pages>
<contexts>
<context position="5174" citStr="Guo et al., 2014" startWordPosition="778" endWordPosition="781">ure viewing as their primary MOOC activity. Video lectures form a primary and an extremely crucial part of MOOC instruction design. They serve as gateways to draw students into the course. Concept discussions, demos and tutorials that are held within these short video lectures, not only guide learners to complete course assignments, but also encourage them to discuss the taught syllabus on MOOC discussion forums. Specific to the context of video lectures, prior work has cut teeth on a)how video production style (slides, code, classroom, khan academy style etc) relates to students’ engagement (Guo et al., 2014), b)what features of the video lecture and instruction delivery, such as slide transitions (change in visual content), instructor changing topic (topic modeling and ngram analysis) or variations in instructor’s acoustic stream (volume, pitch, speaking rate), lead to peaks in viewership activity (Kim et al., 2014b). There has been increasing focus on unveiling numerous facets of complexity of raw click-level interactions resulting from student activities within individual MOOC videos (Kim et al., 2014a; Sinha et al., 2014). However, to the best of our knowledge, we present the first study that </context>
</contexts>
<marker>Guo, Kim, Rubin, 2014</marker>
<rawString>Guo, Philip J., Juho Kim, and Rob Rubin. (2014). “How video production affects student engagement: An empirical study of mooc videos” ACM Learing at Scale(L@S), pp. 41-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Haggard</author>
<author>S Brown</author>
<author>R Mills</author>
<author>A Tait</author>
<author>S Warburton</author>
<author>W Lawton</author>
<author>T Angulo</author>
</authors>
<title>The maturing of the MOOC: Literature review of Massive Open Online Courses and other forms of online distance learning”</title>
<date>2013</date>
<journal>BIS Research Paper</journal>
<volume>130</volume>
<contexts>
<context position="1469" citStr="Haggard et al., 2013" startWordPosition="197" endWordPosition="201">, which can aid instructors to better understand MOOC hurdles and reason about unsatisfactory learning outcomes. Our results illustrate how such a metric inspired by cognitive psychology can help answer critical questions regarding students’ engagement, their future click interactions and participation trajectories that lead to in-video &amp; course dropouts. Implications for research and practice are discussed. 1 Introduction Mushrooming as a scalable lifelong learning paradigm, Massive Open Online Courses (MOOCs) have enjoyed significant limelight in recent years, both in industry and academia (Haggard et al., 2013). The euphoria is about the transformative potential of MOOCs to revolutionize online education (North et al., 2014), by connecting and fostering interaction among millions of learners who otherwise would never have met and providing autonomy to these learners to grapple with the course instruction at their own pace of understanding. However, despite this expediency, there is also considerable skepticism in the learning analytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms</context>
</contexts>
<marker>Haggard, Brown, Mills, Tait, Warburton, Lawton, Angulo, 2013</marker>
<rawString>Haggard, S., S. Brown, R. Mills, A. Tait, S. Warburton, W. Lawton, and T. Angulo. (2013). “The maturing of the MOOC: Literature review of Massive Open Online Courses and other forms of online distance learning” BIS Research Paper 130</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Huang</author>
<author>A Dasgupta</author>
<author>A Ghosh</author>
<author>J Manning</author>
<author>M Sanders</author>
</authors>
<title>Superposter behavior in MOOC forums”.</title>
<date>2014</date>
<booktitle>In Proceedings of the first ACM conference on Learning@ scale conference</booktitle>
<pages>117--126</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3901" citStr="Huang et al., 2014" startWordPosition="578" endWordPosition="581">and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3–14, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics istrations in MOOC courses at EPFL in 2013, our experience reflects that out of the 100% students who register, 75% show up: 50% of them primarily watch video lectures and the rest 25% additionally work out homeworks and</context>
</contexts>
<marker>Huang, Dasgupta, Ghosh, Manning, Sanders, 2014</marker>
<rawString>Huang, J., Dasgupta, A., Ghosh, A., Manning, J., &amp; Sanders, M. (2014, March). “Superposter behavior in MOOC forums”. In Proceedings of the first ACM conference on Learning@ scale conference (pp. 117-126). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kidd</author>
<author>S T Piantadosi</author>
<author>R N Aslin</author>
</authors>
<title>The Goldilocks effect: Human infants allocate attention to visual sequences that are neither too simple nor too complex”.</title>
<date>2012</date>
<journal>PLoS One,</journal>
<volume>7</volume>
<issue>5</issue>
<pages>36399</pages>
<contexts>
<context position="21759" citStr="Kidd et al., 2012" startWordPosition="3295" endWordPosition="3298">s follows: Information Processing Index (IPI) = 7 (−1)j E WeightAssign(Behavioral Action i), 8=1 j=1,2 depending on whether the behavioral action is weighted low or high. Figure 2: Linear weight assignments for behavioral clickstream actions, according to the information processing hierarchy developed One of the focal utilities of developing such a quantitative index is that meaningful intervention could be provided in real time to students, as they steadily build up their video watching profile while interacting with MOOC video lectures. Viewing throught the lens of the Goldilocks principle (Kidd et al., 2012), our metric can potentially help instructors in understanding and differentiating between students looking away from the MOOC visual sequence, because of too simple or too complex representation. Adaptive presentation of instructional materials is another learning science application where leveraging our metric would be beneficial. Specifically, when IPI &gt; 0, it can be inferred that high information processing is being done by students. Therefore MOOC instructors need to check for coherency in pace of instruction delivery and students’ understanding. This might also hint towards redesigning s</context>
</contexts>
<marker>Kidd, Piantadosi, Aslin, 2012</marker>
<rawString>Kidd, C., Piantadosi, S. T., &amp; Aslin, R. N. (2012). “The Goldilocks effect: Human infants allocate attention to visual sequences that are neither too simple nor too complex”. PLoS One, 7(5), e36399.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
<author>P J Guo</author>
<author>D T Seaton</author>
<author>P Mitros</author>
<author>K Z Gajos</author>
<author>R C Miller</author>
</authors>
<title>Understanding in-video dropouts and interaction peaks inonline lecture videos”.</title>
<date>2014</date>
<booktitle>In Proceedings of the first ACM conference on Learning@ scale conference</booktitle>
<pages>31--40</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5487" citStr="Kim et al., 2014" startWordPosition="826" endWordPosition="829"> course assignments, but also encourage them to discuss the taught syllabus on MOOC discussion forums. Specific to the context of video lectures, prior work has cut teeth on a)how video production style (slides, code, classroom, khan academy style etc) relates to students’ engagement (Guo et al., 2014), b)what features of the video lecture and instruction delivery, such as slide transitions (change in visual content), instructor changing topic (topic modeling and ngram analysis) or variations in instructor’s acoustic stream (volume, pitch, speaking rate), lead to peaks in viewership activity (Kim et al., 2014b). There has been increasing focus on unveiling numerous facets of complexity of raw click-level interactions resulting from student activities within individual MOOC videos (Kim et al., 2014a; Sinha et al., 2014). However, to the best of our knowledge, we present the first study that describes usage of such detailed clickstream information to form cognitive video watching states that summarize student clickstream. Instead of using summative features that express student engagement, we leverage recurring click behaviors of students interacting with MOOC video lectures, to construct their vide</context>
<context position="28221" citStr="Kim et al., 2014" startWordPosition="4331" endWordPosition="4334">earning experiment, which seeks to derive utility from the first two experiments. Navigating away from the video without completing it fully is an outcome of low student engagement. A student is more likely to watch till the end of a video, if the lecture activates his thinking. Thus, it would be interesting to investigate, whether the nature of students’ interaction provides us a hint about in-video dropout behavior. Prior work has made a preliminary study on how in-video dropout is correlated with length of the video, and how in-video dropout varies among first time watchers and rewatchers (Kim et al., 2014a). However, we consider video interaction features at a much finer granularity, representative of how students progress through the video. In doing so, we use detailed clickstream information, including seek, scroll and ratechange behavior, in addition to merely play and pause information. Research Question 3: What video watching profile of students leads to in-video dropouts? Settings: The data for this experiment comes from the same video lecture 4-6 (6th lecture in the 4th week of the course). The dependent variable is the binary variable, in-video dropout (0/1). To address the skewed clas</context>
</contexts>
<marker>Kim, Guo, Seaton, Mitros, Gajos, Miller, 2014</marker>
<rawString>Kim, J., Guo, P. J., Seaton, D. T., Mitros, P., Gajos, K. Z., &amp; Miller, R. C. (2014a, March). “Understanding in-video dropouts and interaction peaks inonline lecture videos”. In Proceedings of the first ACM conference on Learning@ scale conference (pp. 31-40). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kim</author>
<author>L Shang-Wen</author>
<author>J C Carrie</author>
<author>Z G Krzysztof</author>
<author>C M Robert</author>
</authors>
<date>2014</date>
<booktitle>Leveraging Video Interaction Data and Content Analysis to Improve Video Learning” CHI 2014 Workshop on Learning Innovation at Scale</booktitle>
<contexts>
<context position="5487" citStr="Kim et al., 2014" startWordPosition="826" endWordPosition="829"> course assignments, but also encourage them to discuss the taught syllabus on MOOC discussion forums. Specific to the context of video lectures, prior work has cut teeth on a)how video production style (slides, code, classroom, khan academy style etc) relates to students’ engagement (Guo et al., 2014), b)what features of the video lecture and instruction delivery, such as slide transitions (change in visual content), instructor changing topic (topic modeling and ngram analysis) or variations in instructor’s acoustic stream (volume, pitch, speaking rate), lead to peaks in viewership activity (Kim et al., 2014b). There has been increasing focus on unveiling numerous facets of complexity of raw click-level interactions resulting from student activities within individual MOOC videos (Kim et al., 2014a; Sinha et al., 2014). However, to the best of our knowledge, we present the first study that describes usage of such detailed clickstream information to form cognitive video watching states that summarize student clickstream. Instead of using summative features that express student engagement, we leverage recurring click behaviors of students interacting with MOOC video lectures, to construct their vide</context>
<context position="28221" citStr="Kim et al., 2014" startWordPosition="4331" endWordPosition="4334">earning experiment, which seeks to derive utility from the first two experiments. Navigating away from the video without completing it fully is an outcome of low student engagement. A student is more likely to watch till the end of a video, if the lecture activates his thinking. Thus, it would be interesting to investigate, whether the nature of students’ interaction provides us a hint about in-video dropout behavior. Prior work has made a preliminary study on how in-video dropout is correlated with length of the video, and how in-video dropout varies among first time watchers and rewatchers (Kim et al., 2014a). However, we consider video interaction features at a much finer granularity, representative of how students progress through the video. In doing so, we use detailed clickstream information, including seek, scroll and ratechange behavior, in addition to merely play and pause information. Research Question 3: What video watching profile of students leads to in-video dropouts? Settings: The data for this experiment comes from the same video lecture 4-6 (6th lecture in the 4th week of the course). The dependent variable is the binary variable, in-video dropout (0/1). To address the skewed clas</context>
</contexts>
<marker>Kim, Shang-Wen, Carrie, Krzysztof, Robert, 2014</marker>
<rawString>Kim, J., Shang-Wen L., Carrie J. C., Krzysztof Z. G., Robert C. M. (2014b). “Leveraging Video Interaction Data and Content Analysis to Improve Video Learning” CHI 2014 Workshop on Learning Innovation at Scale</rawString>
</citation>
<citation valid="true">
<authors>
<author>C E Kulkarni</author>
<author>R Socher</author>
<author>M S Bernstein</author>
<author>S R Klemmer</author>
</authors>
<title>Scaling short-answer grading by combining peer assessment with algorithmic scoring”.</title>
<date>2014</date>
<booktitle>In Proceedings of the first ACM conference on Learning@ scale conference</booktitle>
<pages>99--108</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3688" citStr="Kulkarni et al., 2014" startWordPosition="544" endWordPosition="547">needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 3–14, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics istrati</context>
</contexts>
<marker>Kulkarni, Socher, Bernstein, Klemmer, 2014</marker>
<rawString>Kulkarni, C. E., Socher, R., Bernstein, M. S., &amp; Klemmer, S. R. (2014, March). “Scaling short-answer grading by combining peer assessment with algorithmic scoring”. In Proceedings of the first ACM conference on Learning@ scale conference (pp. 99-108). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lang</author>
<author>N John</author>
<author>R Byron</author>
</authors>
<title>Negative video as structure: Emotion, attention, capacity, and memory”.</title>
<date>1996</date>
<journal>Journal ofBroadcasting &amp; Electronic Media,</journal>
<volume>40</volume>
<issue>4</issue>
<pages>460--477</pages>
<contexts>
<context position="18282" citStr="Lang et al., 1996" startWordPosition="2750" endWordPosition="2753"> while the aversive system primarily serves as a motivator for not attending to certain MOOC video segments. Thus, click behaviors representative of appetitive motivational system are rewatch/clear concept/slow watching, while click behaviors representative of aversive motiva6 Figure 1: Relating students’ information processing to click behaviors exhibited in the MOOC, based on video lecture perception tional system are skipping/fast watching. In this work, we try to construct students’ information processing index, based on the “Limited Capacity Information Processing Approach” (Basil, 1994; Lang et al., 1996; Lang, 2000), which asserts that people independently allocate limited amount of cognitive resources to tasks from a shared pool. Figure 1 depicts this idea. We must acknowledge the fact that video watching in MOOCs requires students to recall facts that they already know (specific chunks of declarative knowledge (Anderson, 2014). This helps them to build a mental representation of the information presented in a MOOC video lecture segment, follow and understand the concept being currently taught. However, it must be noted that depending on the a)expertise level, which decides how available th</context>
</contexts>
<marker>Lang, John, Byron, 1996</marker>
<rawString>Lang, A., John N., and Byron R. (1996). “Negative video as structure: Emotion, attention, capacity, and memory”. Journal ofBroadcasting &amp; Electronic Media, 40(4), 460-477</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lang</author>
</authors>
<title>The limited capacity model of mediated message processing”.</title>
<date>2000</date>
<journal>Journal of communication,</journal>
<volume>50</volume>
<issue>1</issue>
<pages>46--70</pages>
<contexts>
<context position="18295" citStr="Lang, 2000" startWordPosition="2754" endWordPosition="2755"> system primarily serves as a motivator for not attending to certain MOOC video segments. Thus, click behaviors representative of appetitive motivational system are rewatch/clear concept/slow watching, while click behaviors representative of aversive motiva6 Figure 1: Relating students’ information processing to click behaviors exhibited in the MOOC, based on video lecture perception tional system are skipping/fast watching. In this work, we try to construct students’ information processing index, based on the “Limited Capacity Information Processing Approach” (Basil, 1994; Lang et al., 1996; Lang, 2000), which asserts that people independently allocate limited amount of cognitive resources to tasks from a shared pool. Figure 1 depicts this idea. We must acknowledge the fact that video watching in MOOCs requires students to recall facts that they already know (specific chunks of declarative knowledge (Anderson, 2014). This helps them to build a mental representation of the information presented in a MOOC video lecture segment, follow and understand the concept being currently taught. However, it must be noted that depending on the a)expertise level, which decides how available the past knowle</context>
</contexts>
<marker>Lang, 2000</marker>
<rawString>Lang, A. (2000). “The limited capacity model of mediated message processing”. Journal of communication, 50(1), 46-70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M T Lie</author>
<author>B Debjanee</author>
<author>K Judy</author>
</authors>
<title>Online learning at scale: user modeling requirements towards motivation and personalisation”.</title>
<date>2014</date>
<booktitle>In Learning Innovations at Scale CHI’ 14 Workshop</booktitle>
<contexts>
<context position="2929" citStr="Lie et al., 2014" startWordPosition="424" endWordPosition="427">nts’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ram</context>
</contexts>
<marker>Lie, Debjanee, Judy, 2014</marker>
<rawString>Lie M. T., Debjanee B., Judy K. (2014). “Online learning at scale: user modeling requirements towards motivation and personalisation”. In Learning Innovations at Scale CHI’ 14 Workshop</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miller Jr</author>
<author>G Rupert</author>
</authors>
<title>Survival analysis”.</title>
<date>2011</date>
<volume>66</volume>
<publisher>John Wiley &amp; Sons</publisher>
<marker>Jr, Rupert, 2011</marker>
<rawString>Miller Jr, Rupert G. (2011). “Survival analysis”. Vol. 66. John Wiley &amp; Sons</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Nawrot</author>
<author>D Antoine</author>
</authors>
<title>Building engagement for MOOC students: introducing support for time management on online learning platforms.”</title>
<date>2014</date>
<booktitle>In Proceedings of the companion publication of the 23rd international conference on World wide web companion,</booktitle>
<pages>1077--1082</pages>
<contexts>
<context position="1974" citStr="Nawrot and Antoine, 2014" startWordPosition="274" endWordPosition="277">Courses (MOOCs) have enjoyed significant limelight in recent years, both in industry and academia (Haggard et al., 2013). The euphoria is about the transformative potential of MOOCs to revolutionize online education (North et al., 2014), by connecting and fostering interaction among millions of learners who otherwise would never have met and providing autonomy to these learners to grapple with the course instruction at their own pace of understanding. However, despite this expediency, there is also considerable skepticism in the learning analytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Becaus</context>
</contexts>
<marker>Nawrot, Antoine, 2014</marker>
<rawString>Nawrot, I., and Antoine D. (2014). “Building engagement for MOOC students: introducing support for time management on online learning platforms.” In Proceedings of the companion publication of the 23rd international conference on World wide web companion, pp. 1077-1082.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M North</author>
<author>R Ronny</author>
<author>M N Max</author>
</authors>
<title>To Adapt MOOCS, or Not? That is No Longer the Question.”</title>
<date>2014</date>
<journal>Universal Journal of Educational Research</journal>
<volume>2</volume>
<issue>1</issue>
<pages>69--72</pages>
<contexts>
<context position="1585" citStr="North et al., 2014" startWordPosition="216" endWordPosition="219">esults illustrate how such a metric inspired by cognitive psychology can help answer critical questions regarding students’ engagement, their future click interactions and participation trajectories that lead to in-video &amp; course dropouts. Implications for research and practice are discussed. 1 Introduction Mushrooming as a scalable lifelong learning paradigm, Massive Open Online Courses (MOOCs) have enjoyed significant limelight in recent years, both in industry and academia (Haggard et al., 2013). The euphoria is about the transformative potential of MOOCs to revolutionize online education (North et al., 2014), by connecting and fostering interaction among millions of learners who otherwise would never have met and providing autonomy to these learners to grapple with the course instruction at their own pace of understanding. However, despite this expediency, there is also considerable skepticism in the learning analytics research community about MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up</context>
</contexts>
<marker>North, Ronny, Max, 2014</marker>
<rawString>North, S. M., Ronny R., and Max M. N. (2014). “To Adapt MOOCS, or Not? That is No Longer the Question.” Universal Journal of Educational Research 2(1): 69-72</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ramesh</author>
<author>D Goldwasser</author>
<author>B Huang</author>
<author>H Daum</author>
<author>L Getoor</author>
</authors>
<title>Modeling Learner Engagement in MOOCs using Probabilistic Soft Logic”.</title>
<date>2013</date>
<booktitle>In NIPS Workshop on Data Driven Education</booktitle>
<contexts>
<context position="3545" citStr="Ramesh et al., 2013" startWordPosition="522" endWordPosition="525">014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2013; Brinton et al., 2013; Anderson et al., 2014; Sinha, 2014b), grading strategies for assignments (Tillmann et al., 2013; Kulkarni et al., 2014) and deployment of reputation systems (Coetzee et al., 2014), inner workings of students’ interaction while watching MOOC video lectures have been much less focused upon. Given that roughly 5% (Huang et al., 2014) of students actually participate in MOOC discussion forums, it would be legitimate to ask whether choosing video lectures as units of analysis would be more insightful. After 330,000 reg3 Proceedings of the 2014 Conference on Empirical Methods</context>
</contexts>
<marker>Ramesh, Goldwasser, Huang, Daum, Getoor, 2013</marker>
<rawString>Ramesh, A., Goldwasser, D., Huang, B., Daum H. III, and Getoor, L. (2013). “Modeling Learner Engagement in MOOCs using Probabilistic Soft Logic”. In NIPS Workshop on Data Driven Education</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Schmidt</author>
<author>M Zach</author>
</authors>
<date>2013</date>
<booktitle>Producing and Delivering a Coursera MOOC on Pattern-Oriented Software Architecture for Concurrent and Networked Software”</booktitle>
<contexts>
<context position="2546" citStr="Schmidt and Zach, 2013" startWordPosition="364" endWordPosition="367">out MOOC productiveness (Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOO</context>
</contexts>
<marker>Schmidt, Zach, 2013</marker>
<rawString>Schmidt, D. C., and Zach M. (2013). “Producing and Delivering a Coursera MOOC on Pattern-Oriented Software Architecture for Concurrent and Networked Software”</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sinha</author>
<author>A Banka</author>
<author>D K Kang</author>
</authors>
<title>Leveraging user profile attributes for improving pedagogical accuracy of learning pathways”.</title>
<date>2013</date>
<booktitle>In Proceedings of 3rd Annual International Conference on Education and E-Learning(EeL 2013), Singapore</booktitle>
<contexts>
<context position="2911" citStr="Sinha et al., 2013" startWordPosition="420" endWordPosition="423">harina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC disc</context>
</contexts>
<marker>Sinha, Banka, Kang, 2013</marker>
<rawString>Sinha, T., Banka, A., Kang, D. K., (2013). “Leveraging user profile attributes for improving pedagogical accuracy of learning pathways”. In Proceedings of 3rd Annual International Conference on Education and E-Learning(EeL 2013), Singapore</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sinha</author>
</authors>
<title>Together we stand, Together we fall, Together we win: Dynamic team formation in massive open online courses”</title>
<date>2014</date>
<booktitle>In Fifth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT)</booktitle>
<pages>107--112</pages>
<publisher>IEEE</publisher>
<contexts>
<context position="2942" citStr="Sinha, 2014" startWordPosition="428" endWordPosition="429"> follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2</context>
<context position="20861" citStr="Sinha, 2014" startWordPosition="3158" endWordPosition="3159">sibility of cognitive overload. In order to relate our behavioral actions constructed from the raw clickstream with this rich and informative stream of literature, we create a taxonomy of behavioral actions exhibited in the clickstream to construct a quantitative “Information Processing Index (IPI)”. Figure 2 reflects the proposed hierarchy of information processing from high to low using linear weight assignments. We omit the line of reasoning that goes behind defining the precise position of each behavioral action in this hierarchy due to lack of space. However, the details can be found in (Sinha, 2014c). Negative weights are necessary to distinguish between “high” and “low” weights for each behavioral action. For example, if skipping=high is weighted -3, skipping=low will be weighted +3 on the information processing index. Students’ infor7 mation processing index is defined as follows: Information Processing Index (IPI) = 7 (−1)j E WeightAssign(Behavioral Action i), 8=1 j=1,2 depending on whether the behavioral action is weighted low or high. Figure 2: Linear weight assignments for behavioral clickstream actions, according to the information processing hierarchy developed One of the focal </context>
</contexts>
<marker>Sinha, 2014</marker>
<rawString>Sinha, T. (2014a). “Together we stand, Together we fall, Together we win: Dynamic team formation in massive open online courses” In Fifth International Conference on the Applications of Digital Information and Web Technologies (ICADIWT) pp. 107-112. IEEE</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sinha</author>
</authors>
<title>Supporting MOOC Instruction with Social Network Analysis”. arXiv preprint arXiv:1401.5175</title>
<date>2014</date>
<contexts>
<context position="2942" citStr="Sinha, 2014" startWordPosition="428" endWordPosition="429"> follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2</context>
<context position="20861" citStr="Sinha, 2014" startWordPosition="3158" endWordPosition="3159">sibility of cognitive overload. In order to relate our behavioral actions constructed from the raw clickstream with this rich and informative stream of literature, we create a taxonomy of behavioral actions exhibited in the clickstream to construct a quantitative “Information Processing Index (IPI)”. Figure 2 reflects the proposed hierarchy of information processing from high to low using linear weight assignments. We omit the line of reasoning that goes behind defining the precise position of each behavioral action in this hierarchy due to lack of space. However, the details can be found in (Sinha, 2014c). Negative weights are necessary to distinguish between “high” and “low” weights for each behavioral action. For example, if skipping=high is weighted -3, skipping=low will be weighted +3 on the information processing index. Students’ infor7 mation processing index is defined as follows: Information Processing Index (IPI) = 7 (−1)j E WeightAssign(Behavioral Action i), 8=1 j=1,2 depending on whether the behavioral action is weighted low or high. Figure 2: Linear weight assignments for behavioral clickstream actions, according to the information processing hierarchy developed One of the focal </context>
</contexts>
<marker>Sinha, 2014</marker>
<rawString>Sinha, T. (2014b). “Supporting MOOC Instruction with Social Network Analysis”. arXiv preprint arXiv:1401.5175</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sinha</author>
</authors>
<title>Your click decides your fate”: Leveraging clickstream patterns from MOOC videos to infer students’ information processing &amp; attrition behavior. arXiv preprint arXiv:1407.7143.</title>
<date>2014</date>
<contexts>
<context position="2942" citStr="Sinha, 2014" startWordPosition="428" endWordPosition="429"> follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, understand how diverse ecologies of participation develop as students interact with the course material (Fischer, 2011), and how learners distribute their attention with multiple forms of computer mediated inputs in MOOCs. Learning in a MOOC requires that students apply self regulation. While substantial research has been done on studying MOOC discussion forums (Ramesh et al., 2</context>
<context position="20861" citStr="Sinha, 2014" startWordPosition="3158" endWordPosition="3159">sibility of cognitive overload. In order to relate our behavioral actions constructed from the raw clickstream with this rich and informative stream of literature, we create a taxonomy of behavioral actions exhibited in the clickstream to construct a quantitative “Information Processing Index (IPI)”. Figure 2 reflects the proposed hierarchy of information processing from high to low using linear weight assignments. We omit the line of reasoning that goes behind defining the precise position of each behavioral action in this hierarchy due to lack of space. However, the details can be found in (Sinha, 2014c). Negative weights are necessary to distinguish between “high” and “low” weights for each behavioral action. For example, if skipping=high is weighted -3, skipping=low will be weighted +3 on the information processing index. Students’ infor7 mation processing index is defined as follows: Information Processing Index (IPI) = 7 (−1)j E WeightAssign(Behavioral Action i), 8=1 j=1,2 depending on whether the behavioral action is weighted low or high. Figure 2: Linear weight assignments for behavioral clickstream actions, according to the information processing hierarchy developed One of the focal </context>
</contexts>
<marker>Sinha, 2014</marker>
<rawString>Sinha, T. (2014c). “Your click decides your fate”: Leveraging clickstream patterns from MOOC videos to infer students’ information processing &amp; attrition behavior. arXiv preprint arXiv:1407.7143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Sinha</author>
<author>N Li</author>
<author>P Jermann</author>
<author>P Dillenbourg</author>
</authors>
<title>Capturing attrition intensifying structural traits from didactic interaction sequences of MOOC learners.</title>
<date>2014</date>
<booktitle>Proceedings of the 2014 Empirical Methods in Natural Language Processing Workshop on Modeling Large Scale Social Interaction in Massively Open Online Courses,</booktitle>
<location>Qatar,</location>
<contexts>
<context position="5701" citStr="Sinha et al., 2014" startWordPosition="857" endWordPosition="860"> code, classroom, khan academy style etc) relates to students’ engagement (Guo et al., 2014), b)what features of the video lecture and instruction delivery, such as slide transitions (change in visual content), instructor changing topic (topic modeling and ngram analysis) or variations in instructor’s acoustic stream (volume, pitch, speaking rate), lead to peaks in viewership activity (Kim et al., 2014b). There has been increasing focus on unveiling numerous facets of complexity of raw click-level interactions resulting from student activities within individual MOOC videos (Kim et al., 2014a; Sinha et al., 2014). However, to the best of our knowledge, we present the first study that describes usage of such detailed clickstream information to form cognitive video watching states that summarize student clickstream. Instead of using summative features that express student engagement, we leverage recurring click behaviors of students interacting with MOOC video lectures, to construct their video watching profile. Based on these richly logged interactions of students, we develop computational methods that answer critical questions such as a)how long will students grapple with the course material and what </context>
</contexts>
<marker>Sinha, Li, Jermann, Dillenbourg, 2014</marker>
<rawString>Sinha, T., Li, N., Jermann, P., Dillenbourg, P. (2014). Capturing attrition intensifying structural traits from didactic interaction sequences of MOOC learners. Proceedings of the 2014 Empirical Methods in Natural Language Processing Workshop on Modeling Large Scale Social Interaction in Massively Open Online Courses, Qatar, October 2014</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Tillmann</author>
<author>J De Halleux</author>
<author>T Xie</author>
<author>S Gulwani</author>
<author>J Bishop</author>
</authors>
<title>Teaching and learning programming and software engineering via interactive gaming”.</title>
<date>2013</date>
<booktitle>In ICSE,</booktitle>
<pages>11171126</pages>
<marker>Tillmann, De Halleux, Xie, Gulwani, Bishop, 2013</marker>
<rawString>Tillmann, N., De Halleux, J., Xie, T., Gulwani, S., and Bishop, J. (2013). “Teaching and learning programming and software engineering via interactive gaming”. In ICSE, 11171126</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark PJ Van der L</author>
</authors>
<title>The stringdist Package for Approximate String</title>
<date>2014</date>
<journal>Matching” The R Journal</journal>
<marker>Van der L, 2014</marker>
<rawString>Van der L., Mark PJ. (2014). “The stringdist Package for Approximate String Matching” The R Journal</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Wang</author>
<author>K Tristan</author>
<author>W Christo</author>
<author>W Xiao</author>
<author>Z Haitao</author>
<author>Y Z Ben</author>
</authors>
<title>You are how you click: Clickstream analysis for sybil detection”</title>
<date>2013</date>
<booktitle>In USENIX Security Symposium</booktitle>
<location>(Washington, DC)</location>
<contexts>
<context position="11606" citStr="Wang et al., 2013" startWordPosition="1787" endWordPosition="1790">ght be because high level categories have better noise tolerance than naive clickstream logs. The results obtained from grouping clickstream sequences at per click resolution are often difficult to interpret, as such a fine resolution leads to a wide variety of sequences, many of which are semantically equivalent. Therefore, to get more insights into student behavior in MOOCs, we group clicks encoded at very fine granularity into meaningful behavioral categories. Doing this also reduces sequence length which is easily interpretable. There is some existing literature (Banerjee and Ghosh, 2000; Wang et al., 2013), that just considers click as a binary event (yes/no) and discusses formation of concept based categories based on the area/sub area of the stimulus where the click was made. To summarize a students’ clickstream, we obtain n-grams with maximum frequency from the clickstream sequence (a contiguous sequence of ‘n’ click actions). Such a simple n-gram representation convincingly captures the most frequently occurring click actions that students make in conjunction with each other (n=4 was empirically determined as a good limit on clickstream subsequence overspecificity). Then, we construct seven</context>
</contexts>
<marker>Wang, Tristan, Christo, Xiao, Haitao, Ben, 2013</marker>
<rawString>Wang, G., Tristan K., Christo W., Xiao W., Haitao Z., and Ben Y. Z. (2013). “You are how you click: Clickstream analysis for sybil detection” In USENIX Security Symposium (Washington, DC)</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yang</author>
<author>T Sinha</author>
<author>D Adamson</author>
<author>C P Rose</author>
</authors>
<title>Turn on, Tune in, Drop out: Anticipating student dropouts</title>
<date>2013</date>
<booktitle>in Massive Open Online Courses” In NIPS Workshop on Data Driven Education</booktitle>
<contexts>
<context position="2566" citStr="Yang et al., 2013" startWordPosition="368" endWordPosition="371">(Nawrot and Antoine, 2014), primarily because of unsatisfactory learning outcomes that plague these educational platforms and induce a funnel of participation (Clow, 2013). With a “one size fits all” approach that MOOCs follow, scaled up class sizes and lack of face to face interaction coupled with such high student teacher ratios (Guo and Katharina, 2014), students’ motivation to follow the course oscillates (Davis et al., 2014). This is comprehensibly reflected in escalating attrition rates in MOOCs, ever since they have started maturing (Belanger and Thornton, 2013; Schmidt and Zach, 2013; Yang et al., 2013). Because it is not feasible for MOOC instructors to manually provide individualized attention that caters to different backgrounds, diverse skill levels, learning goals and preferences of students, there is an increasing need to make directed efforts towards automatically providing better personalized content in e-learning (Sinha et al., 2013; Lie et al., 2014; Sinha, 2014a). The provision of guidance with regard to the organization of the study and regulation of learning is a domain that also needs to be addressed. A prerequisite for such an undertaking is that we, as MOOC researchers, under</context>
</contexts>
<marker>Yang, Sinha, Adamson, Rose, 2013</marker>
<rawString>Yang, D., Sinha T., Adamson D., and Rose C. P. (2013). “Turn on, Tune in, Drop out: Anticipating student dropouts in Massive Open Online Courses” In NIPS Workshop on Data Driven Education</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>