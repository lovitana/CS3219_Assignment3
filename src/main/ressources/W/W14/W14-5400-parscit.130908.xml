<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.845325">
V&amp;L Net 2014
</note>
<title confidence="0.9103725">
The 3rd Annual Meeting Of The EPSRC Network On
Vision &amp; Language
</title>
<note confidence="0.328652">
and
</note>
<title confidence="0.7688998">
The 1st Technical Meeting of the European Network on
Integrating Vision and Language
A Workshop of the 25th International Conference on
Computational Linguistics (COLING 2014)
Proceedings
</title>
<author confidence="0.22105">
August 23, 2014
Dublin, Ireland
</author>
<sectionHeader confidence="0.588075" genericHeader="abstract">
ISBN 978-1-873769-28-1
</sectionHeader>
<bodyText confidence="0.982748333333333">
This workshop is partly supported by ICT COST Action IC1307, the European Network on Integrating
Vision and Language (iV&amp;L Net): Combining Computer Vision and Language Processing For Advanced
Search, Retrieval, Annotation and Description of Visual Data, and partly by the EPSRC Network on
Vision and Language (V&amp;L Net).
ESF provides the COST Office through an EC contract
COST is supported by the EU RTD Framework Programme
</bodyText>
<page confidence="0.466789">
ii
</page>
<note confidence="0.507838">
Preface
</note>
<bodyText confidence="0.9900135">
The Workshop on Vision and Language 2014 (VL’14) took place in Dublin on 23rd July 2014, as part
of COLING’14. It was the joint 3rd meeting of the EPSRC Network On Vision and Language and 1st
technical meeting of the new European Network on Integrating Vision and Language which is funded as
a European COST Action. The VL workshops have the general aims:
</bodyText>
<listItem confidence="0.9889845">
1. to provide a forum for reporting and discussing planned, ongoing and completed research that
involves both language and vision; and
2. to enable NLP and computer vision researchers to meet, exchange ideas, expertise and technology,
and form new research partnerships.
</listItem>
<bodyText confidence="0.966380821428572">
As funding for the V&amp;L EPSRC Network (EP/H018557) ends and funding for the iV&amp;L Net European
COST Action (IC1307) starts, the focus of the VL workshops will shift onto integration and joint
modelling of language and vision. iV&amp;L Net will take over the organisation of annual VL workshops
for the next four years as the flagship workshop of this new COST Action.
The call for papers for VL’14 was issued in May 2014 and elicited a good number of high-
quality submissions, each of which was peer-reviewed by three members of the programme committee.
The interest in the workshop from leading NLP and computer vision researchers and the quality of
submissions was high, so we aimed to be as inclusive as possible within the practical constraints of the
workshop. In the end we accepted 14 submissions as long papers, and eight as short papers.
The resulting workshop programme packed a lot of exciting content into one day. We were delighted
to be able to include in the programme a keynote presentation by Alex Jaimes of Yahoo! Inc., an
internationally leading vision researcher. Our technical programme combined seven oral papers, seven
long poster papers and seven short poster papers. Some thematic clusters emerged: combined text and
image processing (Nguyen et al., Sakaki et al., Jones et al., Zhang et al., HaCohen-Kerner et al.), image
description, annotation and labelling (Elliott, Liparas et al., Wang et al., Jokinen and Wilcock), data set
creation (Weiland et al., Le et al., McGuinness et al.), situated dialogue (Summers-Stay et al., Schütte et
al.), video analysis (Bhat and Olszewska, Shrestha et al.), aids for visually impaired people (Safi et al.,
Belz and Bharath), and visual analysis supported by text/speech features (Anbarjafari and Aabloo). The
programme also included a discussion session on future directions for the VL community and workshops,
including plans for shared task competitions.
We would like to thank all the people who have contributed to the organisation and delivery
of this workshop: the authors who submitted such high quality papers; the programme committee
for their prompt and effective reviewing; our keynote speaker, Alex Jaimes; the COLING 2014
organising committee, especially the workshops chairs, Jennifer Foster, Dan Gildea, and Tim Baldwin;
the participants in the workshop; and future readers of these proceedings for your shared interest in this
exciting new area of research.
August 2014 Anja Belz, Marie-Francine Moens and Alan F. Smeaton
iii
</bodyText>
<subsectionHeader confidence="0.322382">
Organising Committee
</subsectionHeader>
<affiliation confidence="0.996922166666667">
Anja Belz, University of Brighton
Darren Cosker, University of Bath
Frank Keller, University of Edinburgh
Marie-Francine Moens, University of Leuven
Alan F. Smeaton, Dublin City University
William Smith, University of York
</affiliation>
<author confidence="0.843944">
Program Committee:
</author>
<affiliation confidence="0.903693">
Yannis Aloimonos, University of Maryland, US
Tamara Berg, Stony Brook, US
Desmond Elliot, University of Edinburgh, UK
Erkut Erdem, Hacettepe University, Turkey
Sergio Escalera, Autonomous University of Barcelona, Spain
Claire Gardent, CNRS/LORIA, France
Jordi Gonzales, Universita Autonoma de Barcelona, Spain
Lewis Griffin, UCL, UK
Julia Hockenmaier, University of Illinois, US
John Kelleher, Dublin Institute of Technology, Ireland
Brian Mac Namee, Dublin Institute of Technology, Ireland
Dimitrios Makris, Kingston University, UK
Margaret Mitchell, University of Aberdeen, UK
Ray Mooney, University of Texas at Austin, US
Lucia Specia, University of Sheffield, UK
Chris Town, University of Cambridge, UK
Isabel Trancoso, INESC-ID, Portugal
David Windridge, University of Surrey, UK
</affiliation>
<table confidence="0.425294333333333">
Invited Keynote Speaker:
Alex Jaimes, Yahoo! Inc.
v
</table>
<tableCaption confidence="0.97885">
Table of Contents
</tableCaption>
<note confidence="0.605807">
The Effect of Sensor Errors in Situated Human-Computer Dialogue
Niels Schütte, John Kelleher and Brian Mac Namee 1
</note>
<figure confidence="0.766835974683544">
Joint Navigation in Commander/Robot Teams: Dialog &amp; Task Performance When Vision is Bandwidth-
Limited
Douglas Summers-Stay, Taylor Cassidy and Clare Voss 9
TUHOI: Trento Universal Human Object Interaction Dataset
Dieu-Thu Le, Jasper Uijlings and Raffaella Bernardi 17
Concept-oriented labelling ofpatent images based on Random Forests and proximity-driven generation
of synthetic data
Dimitris Liparas, Anastasia Moumtzidou, Stefanos Vrochidis and Ioannis Kompatsiaris 25
Exploration offunctional semantics ofprepositions from corpora of descriptions of visual scenes
Simon Dobnik and John Kelleher 33
A Poodle or a Dog? Evaluating Automatic Image Annotation Using Human Descriptions at Different
Levels of Granularity
Josiah Wang, Fei Yan, Ahmet Aker and Robert Gaizauskas 38
Key Event Detection in Video using ASR and Visual Data
Niraj Shrestha, Aparna N. Venkitasubramanian and Marie-Francine Moens 46
Twitter User Gender Inference Using Combined Analysis of Text and Image Processing
Shigeyuki Sakaki, Yasuhide Miura, Xiaojun Ma, Keigo Hattori and Tomoko Ohkuma 54
Semantic and geometric enrichment of 3D geo-spatial models with captioned photos and labelled illus-
trations
Chris Jones, Paul Rosin and Jonathan Slade 62
Weakly supervised construction of a repository of iconic images
Lydia Weiland, Wolfgang Effelsberg and Simone Paolo Ponzetto 68
Cross-media Cross-genre Information Ranking based on Multi-media Information Networks
Tongtao Zhang, Haibo Li, Hongzhao Huang, Heng Ji, Min-Hsuan Tsai, Shen-Fu Tsai and Thomas
Huang 74
Speech-accompanying gestures in Russian: functions and verbal context
Yulia Nikolaeva 82
DALES: Automated Tool for Detection, Annotation, Labelling, and Segmentation of Multiple Objects in
Multi-Camera Video Streams
Mohammad Bhat and Joanna Isabelle Olszewska 87
A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on Touch-Screen Devices
Waseem SAFI, Fabrice Maurel, Jean-Marc Routoure, Pierre Beust and Gaël Dias 95
Expression Recognition by Using Facial and Vocal Expressions
Gholamreza Anbarjafari and Alvo Aabloo 103
vii
Formulating Queries for Collecting Training Examples in Visual Concept Classification
Kevin McGuinness, Feiyan Hu, Rami Albatal and Alan Smeaton 106
Towards Succinct and Relevant Image Descriptions
Desmond Elliott 109
Coloring Objects: Adjective-Noun Visual Semantic Compositionality
Dat Tien Nguyen, Angeliki Lazaridou and Raffaella Bernardi 112
Multi-layered Image Representation for Image Interpretation
Marina Ivasic-Kos, Miran Pobar and Ivo Ipsic 115
The Last 10 Metres: Using Visual Analysis and Verbal Communication in Guiding Visually Impaired
Smartphone Users to Entrances
Anja Belz and Anil Bharath 118
Keyphrase Extraction using Textual and Visual Features
Yaakov HaCohen-Kerner, Stefanos Vrochidis, Dimitris Liparas, Anastasia Moumtzidou and Ioannis
Kompatsiaris 121
Towards automatic annotation of communicative gesturing
Kristiina Jokinen and Graham Wilcock 124
viii
Conference Program
Saturday, 23 August, 2014
(09.00 - 09.15) Introduction and Welcome to Workshop
(09.15 - 10.30) Interaction
The Effect of Sensor Errors in Situated Human-Computer Dialogue
Niels Schütte, John Kelleher and Brian Mac Namee
Joint Navigation in Commander/Robot Teams: Dialog &amp; Task Performance When
Vision is Bandwidth-Limited
Douglas Summers-Stay, Taylor Cassidy and Clare Voss
TUHOI: Trento Universal Human Object Interaction Dataset
Dieu-Thu Le, Jasper Uijlings and Raffaella Bernardi
(10.30 - 11.00) Morning Coffee
(11.00 - 11.40) Invited Keynote Talk - Alex Jaimes, Yahoo ! Inc.
(11.40 - 12.30) Language Descriptors
Concept-oriented labelling of patent images based on Random Forests and
proximity-driven generation of synthetic data
Dimitris Liparas, Anastasia Moumtzidou, Stefanos Vrochidis and Ioannis Kompat-
siaris
Exploration offunctional semantics ofprepositions from corpora of descriptions of
visual scenes
Simon Dobnik and John Kelleher
ix
Saturday, 23 August, 2014 (continued)
(12.30 - 13.30) Lunch
(13.30 - 14.20) Visual Indexing
A Poodle or a Dog? Evaluating Automatic Image Annotation Using Human Descriptions
at Different Levels of Granularity
</figure>
<reference confidence="0.95812525">
Josiah Wang, Fei Yan, Ahmet Aker and Robert Gaizauskas
Key Event Detection in Video using ASR and Visual Data
Niraj Shrestha, Aparna N. Venkitasubramanian and Marie-Francine Moens
(14.20 - 15.00) Poster Boasters
(15.30 - 17.00) Long Poster Papers (Parallel session)
Twitter User Gender Inference Using Combined Analysis of Text and Image Processing
Shigeyuki Sakaki, Yasuhide Miura, Xiaojun Ma, Keigo Hattori and Tomoko Ohkuma
Semantic and geometric enrichment of 3D geo-spatial models with captioned photos and
labelled illustrations
Chris Jones, Paul Rosin and Jonathan Slade
Weakly supervised construction of a repository of iconic images
Lydia Weiland, Wolfgang Effelsberg and Simone Paolo Ponzetto
Cross-media Cross-genre Information Ranking based on Multi-media Information Net-
works
Tongtao Zhang, Haibo Li, Hongzhao Huang, Heng Ji, Min-Hsuan Tsai, Shen-Fu Tsai and
Thomas Huang
Speech-accompanying gestures in Russian: functions and verbal context
Yulia Nikolaeva
DALES: Automated Tool for Detection, Annotation, Labelling, and Segmentation of Mul-
tiple Objects in Multi-Camera Video Streams
Mohammad Bhat and Joanna Isabelle Olszewska
A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on Touch-Screen Devices
Waseem SAFI, Fabrice Maurel, Jean-Marc Routoure, Pierre Beust and Gaël Dias
x
Saturday, 23 August, 2014 (continued)
(15.30 - 17.00) Short Poster Papers (Parallel session)
Expression Recognition by Using Facial and Vocal Expressions
Gholamreza Anbarjafari and Alvo Aabloo
Formulating Queries for Collecting Training Examples in Visual Concept Classification
Kevin McGuinness, Feiyan Hu, Rami Albatal and Alan Smeaton
Towards Succinct and Relevant Image Descriptions
Desmond Elliott
Coloring Objects: Adjective-Noun Visual Semantic Compositionality
Dat Tien Nguyen, Angeliki Lazaridou and Raffaella Bernardi
Multi-layered Image Representation for Image Interpretation
Marina Ivasic-Kos, Miran Pobar and Ivo Ipsic
The Last 10 Metres: Using Visual Analysis and Verbal Communication in Guiding Visually
Impaired Smartphone Users to Entrances
Anja Belz and Anil Bharath
Keyphrase Extraction using Textual and Visual Features
Yaakov HaCohen-Kerner, Stefanos Vrochidis, Dimitris Liparas, Anastasia Moumtzidou
and Ioannis Kompatsiaris
Towards automatic annotation of communicative gesturing
Kristiina Jokinen and Graham Wilcock
</reference>
<page confidence="0.588598">
xi
</page>
<note confidence="0.571105">
Saturday, 23 August, 2014 (continued)
(17.00 - 17.30) Discussion and Closing
</note>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.8749704">V&amp;L Net 2014 The 3rd Annual Meeting Of The EPSRC Network Vision &amp; The 1st Technical Meeting of the European Network Integrating Vision and Language</title>
<note confidence="0.6772999">A Workshop of the 25th International Conference on Computational Linguistics (COLING 2014) Proceedings August 23, Dublin, Ireland ISBN 978-1-873769-28-1 This workshop is partly supported by ICT COST Action IC1307, the European Network on Integrating Vision and Language (iV&amp;L Net): Combining Computer Vision and Language Processing For Advanced Search, Retrieval, Annotation and Description of Visual Data, and partly by the EPSRC Network on Vision and Language (V&amp;L Net).</note>
<abstract confidence="0.9615833">ESF provides the COST Office through an EC contract COST is supported by the EU RTD Framework Programme ii Preface The Workshop on Vision and Language 2014 (VL’14) took place in Dublin on 23rd July 2014, as part of COLING’14. It was the joint 3rd meeting of the EPSRC Network On Vision and Language and 1st technical meeting of the new European Network on Integrating Vision and Language which is funded as a European COST Action. The VL workshops have the general aims: 1. to provide a forum for reporting and discussing planned, ongoing and completed research that involves both language and vision; and 2. to enable NLP and computer vision researchers to meet, exchange ideas, expertise and technology, and form new research partnerships. As funding for the V&amp;L EPSRC Network (EP/H018557) ends and funding for the iV&amp;L Net European COST Action (IC1307) starts, the focus of the VL workshops will shift onto integration and joint modelling of language and vision. iV&amp;L Net will take over the organisation of annual VL workshops for the next four years as the flagship workshop of this new COST Action. The call for papers for VL’14 was issued in May 2014 and elicited a good number of highquality submissions, each of which was peer-reviewed by three members of the programme committee. The interest in the workshop from leading NLP and computer vision researchers and the quality of submissions was high, so we aimed to be as inclusive as possible within the practical constraints of the workshop. In the end we accepted 14 submissions as long papers, and eight as short papers. The resulting workshop programme packed a lot of exciting content into one day. We were delighted to be able to include in the programme a keynote presentation by Alex Jaimes of Yahoo! Inc., an internationally leading vision researcher. Our technical programme combined seven oral papers, seven long poster papers and seven short poster papers. Some thematic clusters emerged: combined text and image processing (Nguyen et al., Sakaki et al., Jones et al., Zhang et al., HaCohen-Kerner et al.), image description, annotation and labelling (Elliott, Liparas et al., Wang et al., Jokinen and Wilcock), data set creation (Weiland et al., Le et al., McGuinness et al.), situated dialogue (Summers-Stay et al., Schütte et al.), video analysis (Bhat and Olszewska, Shrestha et al.), aids for visually impaired people (Safi et al., Belz and Bharath), and visual analysis supported by text/speech features (Anbarjafari and Aabloo). The programme also included a discussion session on future directions for the VL community and workshops, including plans for shared task competitions. We would like to thank all the people who have contributed to the organisation and delivery of this workshop: the authors who submitted such high quality papers; the programme committee for their prompt and effective reviewing; our keynote speaker, Alex Jaimes; the COLING 2014 organising committee, especially the workshops chairs, Jennifer Foster, Dan Gildea, and Tim Baldwin; the participants in the workshop; and future readers of these proceedings for your shared interest in this exciting new area of research. August 2014 Anja Belz, Marie-Francine Moens and Alan F. Smeaton iii</abstract>
<title confidence="0.576657">Organising Committee</title>
<degree confidence="0.548405875">Anja Belz, University of Brighton Darren Cosker, University of Bath Frank Keller, University of Edinburgh Marie-Francine Moens, University of Leuven Alan F. Smeaton, Dublin City University William Smith, University of York Program Committee: Yannis Aloimonos, University of Maryland, US</degree>
<author confidence="0.6556885">Tamara Berg</author>
<author confidence="0.6556885">Stony Brook</author>
<author confidence="0.6556885">US Desmond Elliot</author>
<author confidence="0.6556885">University of Edinburgh</author>
<author confidence="0.6556885">UK</author>
<affiliation confidence="0.617765">Erkut Erdem, Hacettepe University, Turkey</affiliation>
<author confidence="0.727816">Sergio Escalera</author>
<author confidence="0.727816">Autonomous University of Barcelona</author>
<author confidence="0.727816">Spain Claire Gardent</author>
<author confidence="0.727816">France CNRSLORIA</author>
<affiliation confidence="0.347254">Jordi Gonzales, Universita Autonoma de Barcelona, Spain</affiliation>
<address confidence="0.731246">Lewis Griffin, UCL, UK</address>
<author confidence="0.840837666666667">Julia Hockenmaier</author>
<author confidence="0.840837666666667">University of Illinois</author>
<author confidence="0.840837666666667">US John Kelleher</author>
<author confidence="0.840837666666667">Dublin Institute of Technology</author>
<author confidence="0.840837666666667">Ireland Brian Mac Namee</author>
<author confidence="0.840837666666667">Dublin Institute of Technology</author>
<author confidence="0.840837666666667">Ireland</author>
<affiliation confidence="0.871824">Dimitrios Makris, Kingston University, UK</affiliation>
<address confidence="0.810252">Margaret Mitchell, University of Aberdeen, UK</address>
<author confidence="0.851335666666667">Ray Mooney</author>
<author confidence="0.851335666666667">University of Texas at Austin</author>
<author confidence="0.851335666666667">US Lucia Specia</author>
<author confidence="0.851335666666667">University of Sheffield</author>
<author confidence="0.851335666666667">UK Chris Town</author>
<author confidence="0.851335666666667">University of Cambridge</author>
<author confidence="0.851335666666667">UK</author>
<affiliation confidence="0.521912">Isabel Trancoso, INESC-ID, Portugal</affiliation>
<address confidence="0.587687">David Windridge, University of Surrey, UK</address>
<affiliation confidence="0.695775">Invited Keynote Speaker: Alex Jaimes, Yahoo! Inc.</affiliation>
<email confidence="0.869376">v</email>
<title confidence="0.5954185">Table of Contents The Effect of Sensor Errors in Situated Human-Computer Dialogue</title>
<author confidence="0.589995">John Kelleher Schütte</author>
<author confidence="0.589995">Brian Mac Namee</author>
<affiliation confidence="0.5375615">Joint Navigation in Commander/Robot Teams: Dialog &amp; Task Performance When Vision is Bandwidth- Limited</affiliation>
<address confidence="0.584511">Summers-Stay, Taylor Cassidy and Clare Voss9</address>
<affiliation confidence="0.291986">TUHOI: Trento Universal Human Object Interaction Dataset</affiliation>
<address confidence="0.541939">Le, Jasper Uijlings and Raffaella Bernardi 17</address>
<title confidence="0.71003075">Concept-oriented labelling ofpatent images based on Random Forests and proximity-driven generation of synthetic data Liparas, Anastasia Moumtzidou, Stefanos Vrochidis and Ioannis Kompatsiaris25 Exploration offunctional semantics ofprepositions from corpora of descriptions of visual scenes</title>
<author confidence="0.966908">Dobnik</author>
<author confidence="0.966908">John Kelleher</author>
<affiliation confidence="0.976242">A Poodle or a Dog? Evaluating Automatic Image Annotation Using Human Descriptions at Different Levels of Granularity</affiliation>
<address confidence="0.950932">Wang, Fei Yan, Ahmet Aker and Robert Gaizauskas 38</address>
<keyword confidence="0.871108">Key Event Detection in Video using ASR and Visual Data</keyword>
<note confidence="0.470216230769231">Shrestha, Aparna N. Venkitasubramanian and Marie-Francine Moens46 Twitter User Gender Inference Using Combined Analysis of Text and Image Processing Sakaki, Yasuhide Miura, Xiaojun Ma, Keigo Hattori and Tomoko Ohkuma54 Semantic and geometric enrichment of 3D geo-spatial models with captioned photos and labelled illustrations Jones, Paul Rosin and Jonathan Slade62 Weakly supervised construction of a repository of iconic images Weiland, Wolfgang Effelsberg and Simone Paolo Ponzetto68 Cross-media Cross-genre Information Ranking based on Multi-media Information Networks Tongtao Zhang, Haibo Li, Hongzhao Huang, Heng Ji, Min-Hsuan Tsai, Shen-Fu Tsai and Thomas Huang74 Speech-accompanying gestures in Russian: functions and verbal context Yulia Nikolaeva 82</note>
<title confidence="0.930033">DALES: Automated Tool for Detection, Annotation, Labelling, and Segmentation of Multiple Objects in Multi-Camera Video Streams</title>
<author confidence="0.602683">Mohammad Bhat</author>
<author confidence="0.602683">Joanna Isabelle Olszewska</author>
<title confidence="0.945112333333333">A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on Touch-Screen Devices SAFI, Fabrice Maurel, Jean-Marc Routoure, Pierre Beust and Gaël Dias95 Expression Recognition by Using Facial and Vocal Expressions</title>
<author confidence="0.762771">Gholamreza Anbarjafari</author>
<author confidence="0.762771">Alvo Aabloo</author>
<email confidence="0.681224">vii</email>
<title confidence="0.930088">Formulating Queries for Collecting Training Examples in Visual Concept Classification McGuinness, Feiyan Hu, Rami Albatal and Alan Smeaton106 Towards Succinct and Relevant Image Descriptions</title>
<author confidence="0.904634">Elliott</author>
<affiliation confidence="0.530172">Coloring Objects: Adjective-Noun Visual Semantic Compositionality</affiliation>
<address confidence="0.47878">Tien Nguyen, Angeliki Lazaridou and Raffaella Bernardi 112</address>
<title confidence="0.910734">Multi-layered Image Representation for Image Interpretation</title>
<author confidence="0.720799">Marina Ivasic-Kos</author>
<author confidence="0.720799">Miran Pobar</author>
<author confidence="0.720799">Ivo Ipsic</author>
<title confidence="0.683263571428571">The Last 10 Metres: Using Visual Analysis and Verbal Communication in Guiding Visually Impaired Smartphone Users to Entrances Anja Belz and Anil Bharath 118 Keyphrase Extraction using Textual and Visual Features Yaakov HaCohen-Kerner, Stefanos Vrochidis, Dimitris Liparas, Anastasia Moumtzidou and Ioannis Kompatsiaris 121 Towards automatic annotation of communicative gesturing</title>
<author confidence="0.671359">Jokinen</author>
<author confidence="0.671359">Graham Wilcock</author>
<email confidence="0.717576">viii</email>
<affiliation confidence="0.868118">Conference Program</affiliation>
<address confidence="0.913948">Saturday, 23 August, 2014</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Josiah Wang</author>
<author>Fei Yan</author>
</authors>
<title>Ahmet Aker and Robert Gaizauskas Key Event Detection in Video using ASR and Visual Data Niraj Shrestha, Aparna N. Venkitasubramanian and Marie-Francine Moens (14.20 - 15.00) Poster Boasters (15.30 - 17.00) Long Poster Papers (Parallel session) Twitter User Gender Inference Using Combined Analysis of Text and Image Processing Shigeyuki Sakaki, Yasuhide Miura, Xiaojun Ma, Keigo Hattori and Tomoko Ohkuma Semantic and geometric enrichment of 3D geo-spatial models with captioned photos and labelled illustrations</title>
<marker>Wang, Yan, </marker>
<rawString>Josiah Wang, Fei Yan, Ahmet Aker and Robert Gaizauskas Key Event Detection in Video using ASR and Visual Data Niraj Shrestha, Aparna N. Venkitasubramanian and Marie-Francine Moens (14.20 - 15.00) Poster Boasters (15.30 - 17.00) Long Poster Papers (Parallel session) Twitter User Gender Inference Using Combined Analysis of Text and Image Processing Shigeyuki Sakaki, Yasuhide Miura, Xiaojun Ma, Keigo Hattori and Tomoko Ohkuma Semantic and geometric enrichment of 3D geo-spatial models with captioned photos and labelled illustrations</rawString>
</citation>
<citation valid="false">
<authors>
<author>Chris Jones</author>
<author>Paul Rosin</author>
<author>Jonathan Slade</author>
</authors>
<title>Weakly supervised construction of a repository of iconic images Lydia Weiland, Wolfgang Effelsberg and Simone Paolo Ponzetto</title>
<marker>Jones, Rosin, Slade, </marker>
<rawString>Chris Jones, Paul Rosin and Jonathan Slade Weakly supervised construction of a repository of iconic images Lydia Weiland, Wolfgang Effelsberg and Simone Paolo Ponzetto</rawString>
</citation>
<citation valid="false">
<title>Cross-media Cross-genre Information Ranking based on Multi-media Information Networks</title>
<marker></marker>
<rawString>Cross-media Cross-genre Information Ranking based on Multi-media Information Networks</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tongtao Zhang</author>
</authors>
<title>Haibo Li, Hongzhao Huang, Heng Ji, Min-Hsuan Tsai, Shen-Fu Tsai and Thomas Huang Speech-accompanying gestures in Russian: functions and verbal context Yulia Nikolaeva</title>
<marker>Zhang, </marker>
<rawString>Tongtao Zhang, Haibo Li, Hongzhao Huang, Heng Ji, Min-Hsuan Tsai, Shen-Fu Tsai and Thomas Huang Speech-accompanying gestures in Russian: functions and verbal context Yulia Nikolaeva</rawString>
</citation>
<citation valid="false">
<authors>
<author>DALES Automated</author>
</authors>
<title>Tool for Detection, Annotation, Labelling, and Segmentation of Multiple Objects</title>
<booktitle>in Multi-Camera Video Streams Mohammad Bhat and Joanna Isabelle Olszewska</booktitle>
<marker>Automated, </marker>
<rawString>DALES: Automated Tool for Detection, Annotation, Labelling, and Segmentation of Multiple Objects in Multi-Camera Video Streams Mohammad Bhat and Joanna Isabelle Olszewska</rawString>
</citation>
<citation valid="false">
<title>A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on Touch-Screen Devices Waseem SAFI, Fabrice Maurel, Jean-Marc Routoure, Pierre Beust and Gaël Dias x</title>
<marker></marker>
<rawString>A Hybrid Segmentation of Web Pages for Vibro-Tactile Access on Touch-Screen Devices Waseem SAFI, Fabrice Maurel, Jean-Marc Routoure, Pierre Beust and Gaël Dias x</rawString>
</citation>
<citation valid="false">
<authors>
<author>Saturday</author>
</authors>
<title>(continued) (15.30 - 17.00) Short Poster Papers (Parallel session) Expression Recognition by Using Facial and Vocal Expressions Gholamreza Anbarjafari and Alvo Aabloo Formulating Queries for Collecting Training Examples in Visual Concept Classification Kevin McGuinness, Feiyan Hu, Rami Albatal and Alan Smeaton Towards Succinct and Relevant Image Descriptions Desmond Elliott</title>
<date>2014</date>
<marker>Saturday, 2014</marker>
<rawString>Saturday, 23 August, 2014 (continued) (15.30 - 17.00) Short Poster Papers (Parallel session) Expression Recognition by Using Facial and Vocal Expressions Gholamreza Anbarjafari and Alvo Aabloo Formulating Queries for Collecting Training Examples in Visual Concept Classification Kevin McGuinness, Feiyan Hu, Rami Albatal and Alan Smeaton Towards Succinct and Relevant Image Descriptions Desmond Elliott</rawString>
</citation>
<citation valid="false">
<title>Coloring Objects: Adjective-Noun Visual Semantic Compositionality Dat Tien Nguyen, Angeliki Lazaridou and Raffaella Bernardi Multi-layered Image Representation for Image Interpretation Marina Ivasic-Kos, Miran Pobar and Ivo Ipsic</title>
<marker></marker>
<rawString>Coloring Objects: Adjective-Noun Visual Semantic Compositionality Dat Tien Nguyen, Angeliki Lazaridou and Raffaella Bernardi Multi-layered Image Representation for Image Interpretation Marina Ivasic-Kos, Miran Pobar and Ivo Ipsic</rawString>
</citation>
<citation valid="false">
<title>The Last 10 Metres: Using Visual Analysis and Verbal Communication in Guiding Visually Impaired Smartphone Users to Entrances</title>
<marker></marker>
<rawString>The Last 10 Metres: Using Visual Analysis and Verbal Communication in Guiding Visually Impaired Smartphone Users to Entrances</rawString>
</citation>
<citation valid="false">
<authors>
<author>Anja Belz</author>
</authors>
<title>and Anil Bharath Keyphrase Extraction using Textual and Visual Features Yaakov HaCohen-Kerner, Stefanos Vrochidis, Dimitris Liparas, Anastasia Moumtzidou and Ioannis Kompatsiaris Towards automatic annotation of communicative gesturing Kristiina Jokinen and Graham Wilcock</title>
<marker>Belz, </marker>
<rawString>Anja Belz and Anil Bharath Keyphrase Extraction using Textual and Visual Features Yaakov HaCohen-Kerner, Stefanos Vrochidis, Dimitris Liparas, Anastasia Moumtzidou and Ioannis Kompatsiaris Towards automatic annotation of communicative gesturing Kristiina Jokinen and Graham Wilcock</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>