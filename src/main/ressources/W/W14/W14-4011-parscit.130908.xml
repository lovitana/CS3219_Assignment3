<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000015">
<title confidence="0.998043">
A CYK+ Variant for SCFG Decoding Without a Dot Chart
</title>
<author confidence="0.99638">
Rico Sennrich
</author>
<affiliation confidence="0.9983825">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.995365666666667">
10 Crichton Street
Edinburgh EH8 9AB
Scotland, UK
</address>
<email confidence="0.999017">
v1rsennr@staffmail.ed.ac.uk
</email>
<sectionHeader confidence="0.997379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999569214285714">
While CYK+ and Earley-style variants are
popular algorithms for decoding unbina-
rized SCFGs, in particular for syntax-
based Statistical Machine Translation, the
algorithms rely on a so-called dot chart
which suffers from a high memory con-
sumption. We propose a recursive vari-
ant of the CYK+ algorithm that elimi-
nates the dot chart, without incurring an
increase in time complexity for SCFG de-
coding. In an evaluation on a string-to-
tree SMT scenario, we empirically demon-
strate substantial improvements in mem-
ory consumption and translation speed.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970833333333">
SCFG decoding can be performed with monolin-
gual parsing algorithms, and various SMT sys-
tems implement the CYK+ algorithm or a close
Earley-style variant (Zhang et al., 2006; Koehn et
al., 2007; Venugopal and Zollmann, 2009; Dyer
et al., 2010; Vilar et al., 2012). The CYK+ algo-
rithm (Chappelier and Rajman, 1998) generalizes
the CYK algorithm to n-ary rules by performing a
dynamic binarization of the grammar during pars-
ing through a so-called dot chart. The construction
of the dot chart is a major cause of space ineffi-
ciency in SCFG decoding with CYK+, and mem-
ory consumption makes the algorithm impractical
for long sentences without artificial limits on the
span of chart cells.
We demonstrate that, by changing the traver-
sal through the main parse chart, we can elimi-
nate the dot chart from the CYK+ algorithm at no
computational cost for SCFG decoding. Our algo-
rithm improves space complexity, and an empiri-
cal evaluation confirms substantial improvements
in memory consumption over the standard CYK+
algorithm, along with remarkable gains in speed.
This paper is structured as follows. As mo-
tivation, we discuss some implementation needs
and complexity characteristics of SCFG decoding
We then describe our algorithm as a variant of
CYK+, and finally perform an empirical evalua-
tion of memory consumption and translation speed
of several parsing algorithms.
</bodyText>
<sectionHeader confidence="0.997364" genericHeader="method">
2 SCFG Decoding
</sectionHeader>
<bodyText confidence="0.999715518518518">
To motivate our algorithm, we want to highlight
some important differences between (monolin-
gual) CFG parsing and SCFG decoding.
Grammars in SMT are typically several orders
of magnitude larger than for monolingual parsing,
partially because of the large amounts of training
data employed to learn SCFGs, partially because
SMT systems benefit from using contextually rich
rules rather than only minimal rules (Galley et al.,
2006). Also, the same right-hand-side rule on the
source side can be associated with many trans-
lations, and different (source and/or target) left-
hand-side symbols. Consequently, a compact rep-
resentation of the grammar is of paramount impor-
tance.
We follow the implementation in the Moses
SMT toolkit (Koehn et al., 2007) which encodes
an SCFG as a trie in which each node represents
a (partial or completed) rule, and a node has out-
going edges for each possible continuation of the
rule in the grammar, either a source-side termi-
nal symbol or pair of non-terminal-symbols. If a
node represents a completed rule, it is also asso-
ciated with a collection of left-hand-side symbols
and the associated target-side rules and probabil-
ities. A trie data structure allows for an efficient
grammar lookup, since all rules with the same pre-
</bodyText>
<page confidence="0.992209">
94
</page>
<note confidence="0.7850895">
Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 94–102,
October 25, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.99930902173913">
fix are compactly represented by a single node.
Rules are matched to the input in a bottom-up-
fashion as described in the next section. A single
rule or rule prefix can match the input many times,
either by matching different spans of the input, or
by matching the same span, but with different sub-
spans for its non-terminal symbols. Each produc-
tion is uniquely identified by a span, a grammar
trie node, and back-pointers to its subderivations.
The same is true for a partial production (dotted
item).
A key difference between monolingual parsing
and SCFG decoding, whose implications on time
complexity are discussed by Hopkins and Lang-
mead (2010), is that SCFG decoders need to con-
sider language model costs when searching for the
best derivation of an input sentence. This critically
affects the parser’s ability to discard dotted items
early. For CFG parsing, we only need to keep one
partial production per rule prefix and span, or k
for k-best parsing, selecting the one(s) whose sub-
derivations have the lower cost in case of ambigu-
ity. For SCFG decoding, the subderivation with
the higher local cost may be the globally better
choice after taking language model costs into ac-
count. Consequently, SCFG decoders need to con-
sider multiple possible productions for the same
rule and span.
Hopkins and Langmead (2010) provide a run-
time analysis of SCFG decoding, showing that
time complexity depends on the number of choice
points in a rule, i.e. rule-initial, consecutive, or
rule-final non-terminal symbols.1 The number of
choice points (or scope) gives an upper bound to
the number of productions that exist for a rule and
span. If we define the scope of a grammar G to
be the maximal scope of all rules in the grammar,
decoding can be performed in O(nscope(G)) time.
If we retain all partial productions of the same rule
prefix, this also raises the space complexity of the
dot chart from O(n2) to O(nscope(G)). 2
Crucially, the inclusion of language model costs
both increases the space complexity of the dot
chart, and removes one of its benefits, namely the
ability to discard partial productions early without
risking search errors. Still, there is a second way
</bodyText>
<footnote confidence="0.876908857142857">
1Assuming that there is a constant upper bound on the
frequency of each symbol in the input sentence, and on the
length of rules.
2In a left-to-right construction of productions, a rule pre-
fix of a scope-x rule may actually have scope x + 1, namely
if the rule prefix ends in a non-terminal, but the rule does not.
it is a trap it is a trap
</footnote>
<figureCaption confidence="0.97774">
Figure 1: Traditional CYK/CYK+ chart traversal
order (left) and proposed order (right).
</figureCaption>
<bodyText confidence="0.999892896551724">
in which a dot chart saves computational cost in
the CYK+ algorithm. The exact chart traversal or-
der is underspecified in CYK parsing, the only re-
quirement being that all subspans of a given span
need to be visited before the span itself. CYK+
or Earley-style parsers typically traverse the chart
bottom-up left-to-right, as in Figure 1 (left). The
same partial productions are visited throughout
time during chart parsing, and storing them in a
dot chart saves us the cost of recomputing them.
For example, step 10 in Figure 1 (left) re-uses par-
tial productions that were found in steps 1, 5 and
8.
We propose to specify the chart traversal order
to be right-to-left, depth-first, as illustrated on the
right-hand-side in Figure 1. This traversal order
groups all cells with the same start position to-
gether, and offers a useful guarantee. For each
span, all spans that start at a later position have
been visited before. Thus, whenever we generate
a partial production, we can immediately explore
all of its continuations, and then discard the par-
tial production. This eliminates the need for a dot
chart, without incurring any computational cost.
We could also say that the dot chart exists in a
minimal form with at most one item at a time, and
a space complexity of O(1). We proceed with a
description of the proposed algorithm, contrasted
with the closely related CYK+ algorithm.
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="method">
3 Algorithm
</sectionHeader>
<subsectionHeader confidence="0.999821">
3.1 The CYK+ algorithm
</subsectionHeader>
<bodyText confidence="0.98665">
We here summarize the CYK+ algorithm, orig-
inally described by Chappelier and Rajman
(1998).3
</bodyText>
<tableCaption confidence="0.497411333333333">
3Chappelier and Rajman (1998) add the restriction that
rules may not be partially lexicalized; our description of
CYK+, and our own algorithm, do not place this restriction.
</tableCaption>
<figure confidence="0.98830775">
1
2
3
4
5
6
7
8
9
10
2
3
4
5
6
7
8
9
10
1
</figure>
<page confidence="0.996599">
95
</page>
<bodyText confidence="0.9999078">
The main data structure during decoding is a
chart with one cell for each span of words in an
input string w1...wn of length n. Each cell Ti,j
corresponding to the span from wi to wj contains
two lists of items:4
</bodyText>
<listItem confidence="0.943782411764706">
• a list of type-1 items, which are non-
terminals (representing productions).
• a list of type-2 items (dotted items), which
are strings of symbols α that parse the sub-
string wi...wj and for which there is a rule in
the grammar of the form A → αβ, with β
being a non-empty string of symbols. Such
an item may be completed into a type-1 item
at a future point, and is denoted α•.
For each cell (i, j) of the chart, we perform the
following steps:
1. if i = j, search for all rules A → wi-y. If -y is
empty, add A to the type-1 list of cell (i, j);
otherwise, add wi• to the type-2 list of cell
(i,j).
2. if j &gt; i, search for all combinations of a type-
2 item α• in a cell (i, k) and a type-1 item B
</listItem>
<bodyText confidence="0.65474975">
in a cell (k+1, j) for which a rule of the form
A → αB-y exists.5 If -y is empty, add the rule
to the type-1 list of cell (i, j); otherwise, add
αB• to the type-2 list of cell (i, j).
</bodyText>
<listItem confidence="0.916465">
3. for each item B in the type-1 list of the cell
(i, j), if there is a rule of the form A → B-y,
and -y is non-empty, add B• to the type-2 list
of cell (i, j).
</listItem>
<subsectionHeader confidence="0.999643">
3.2 Our algorithm
</subsectionHeader>
<bodyText confidence="0.988897923076923">
The main idea behind our algorithm is that we can
avoid the need to store type-2 lists if we process
the individual cells in a right-to-left, depth-first or-
der, as illustrated in Figure 1. Rules are still com-
pleted left-to-right, but processing the rightmost
cells first allows us to immediately extend partial
productions into full productions instead of storing
them in memory.
We perform the following steps for each cell.
1. if i = j, if there is a rule A → wi, add A to
the type-1 list of cell (i, j).
However, our description excludes non-lexical unary rules,
and epsilon rules.
</bodyText>
<footnote confidence="0.981461">
4For simplicity, we describe a monolingual acceptor.
5To allow mixed-terminal rules, we also search for B =
</footnote>
<equation confidence="0.94969">
wj if j = k + 1.
2. if j &gt; i, search for all combinations of a type-
</equation>
<bodyText confidence="0.991548909090909">
2 item α• and a type-1 item B in a cell (j, k),
with j &lt; k &lt; n for which a rule of the form
C → αB-y exists. In the initial call, we allow
α• = A• for any type-1 item A in cell (i, j −
1).6 If -y is empty, add C to the type-1 list of
cell (i, k); otherwise, recursively repeat this
step, using αB• as α• and k + 1 as j.
To illustrate the difference between the two al-
gorithms, let us consider the chart cell (1, 2), i.e.
the chart cell spanning the substring it is, in Fig-
ure 1, and let us assume the following grammar:
</bodyText>
<equation confidence="0.998457666666667">
S → NP V NP V → is
NP → ART NN ART → a
NP → it NN → trap
</equation>
<bodyText confidence="0.9998265">
In both algorithms, we can combine the sym-
bols NP from cell (1, 1) and V from cell (2, 2) to
partially parse the rule S → NP V NP. How-
ever, in CYK+, we cannot yet know if the rule can
be completed with a cell (3, x) containing symbol
NP, since the cell (3, 4) may be processed after cell
(1, 2). Thus, the partial production is stored in a
type-2 list for later processing.
In our algorithm, we require all cells (3, x) to
be processed before cell (1, 2), so we can imme-
diately perform a recursion with α = NP V and
j = 3. In this recursive step, we search for a sym-
bol NP in any cell (3, x), and upon finding it in
cell (3, 4), add S as type-1 item to cell (1, 4).
We provide side-by-side pseudocode of the two
algorithms in Figure 2.7 The algorithms are
aligned to highlight their similarity, the main dif-
ference between them being that type-2 items are
added to the dot chart in CYK+, and recursively
consumed in our variant. An attractive property
of the dynamic binarization in CYK+ is that each
partial production is constructed exactly once, and
can be re-used to find parses for cells that cover
a larger span. Our algorithm retains this property.
Note that the chart traversal order is different be-
tween the algorithms, as illustrated earlier in Fig-
ure 1. While the original CYK+ algorithm works
with either chart traversal order, our recursive vari-
</bodyText>
<construct confidence="0.650361">
6To allow mixed-terminal rules, we also allow α• = wi•
if j = i + 1, and B = wj if k = j.
</construct>
<footnote confidence="0.78797425">
7Some implementation details are left out for simplicity.
For instance, note that terminal and non-terminal grammar
trie edges can be kept separate to avoid iterating over all ter-
minal edges.
</footnote>
<page confidence="0.993897">
96
</page>
<table confidence="0.304680444444444">
Algorithm 1: CYK+
Input: array w of length N
initialize chart[N, N], collections[N, N],
dotchart[N]
root root node of grammar trie
for span in [1..N]:
for i in [1..(N-span+1)]:
j i+span-1
ifi=j: #step 1
</table>
<construct confidence="0.950957739130435">
if (w[i], X) in arc[root]:
addToChart(X, i, j)
else:
for B in chart[i, j-1]: #step 3
if (B, X) in arc[root]:
if arc[X] is not empty:
add (X, j-1) to dotchart[i]
for (a, k) in dotchart[i]: #step 2
if k+1 = j:
if (w[j], X) in arc[a]:
addToChart(X, i, j)
for (B, X) in arc[a]:
if B in chart[k+1, j]:
addToChart(X, i, j)
chart[i, j] = cube_prune(collections[i, j])
def addToChart(trie node X, int i, int j):
if X has target collection:
add X to collections[i, j]
if arc[X] is not empty:
add (X, j) to dotchart[i]
Algorithm 2: recursive CYK+
Input: array w of length N
initialize chart[N, N], collections[N, N]
</construct>
<bodyText confidence="0.744552">
root root node of grammar trie
for i in [N..1]:
for j in [i..N]:
</bodyText>
<construct confidence="0.98487595">
if i = j: #step 1
if (w[i], X) in arc[root]:
addToChart(X, i, j, false)
else: #step 2
consume(root, i, i, j-1)
chart[i, j] = cube_prune(collections[i, j])
def consume(trie node a, int i, int j, int k):
unary i = j
ifj=k:
if (w[j], X) in arc[a]:
addToChart(X, i, k, unary)
for (B, X) in arc[a]:
if B in chart[j, k]:
addToChart(X, i, k, unary)
def addToChart(trie node X, int i, int j, bool u):
if X has target collection and u is false:
add X to collections[i, j]
if arc[X] is not empty:
for k in [(j+1)..N]:
consume(X, i, j+1, k)
</construct>
<figureCaption confidence="0.9816095">
Figure 2: side-by-side pseudocode of CYK+ (left) and our algorithm (right). Our algorithm uses a new
chart traversal order and recursive consume function instead of a dot chart.
</figureCaption>
<page confidence="0.997325">
97
</page>
<bodyText confidence="0.999781333333333">
ant requires a right-to-left, depth-first chart traver-
sal.
With our implementation of the SCFG as a trie,
a type-2 is identified by a trie node, an array of
back-pointers to antecedent cells, and a span. We
distinguish between type-1 items before and after
cube pruning. Productions, or specifically the tar-
get collections and back-pointers associated with
them, are first added to a collections object, either
synchronously or asynchronously. Cube pruning
is always performed synchronously after all pro-
duction of a cell have been found. Thus, the choice
of algorithm does not change the search space in
cube pruning, or the decoder output. After cube
pruning, the chart cell is filled with a mapping
from a non-terminal symbol to an object that com-
pactly represents a collection of translation hy-
potheses and associated scores.
</bodyText>
<subsectionHeader confidence="0.990266">
3.3 Chart Compression
</subsectionHeader>
<bodyText confidence="0.999846741935484">
Given a partial production for span (i, j), the num-
ber of chart cells in which the production can be
continued is linear to sentence length. The recur-
sive variant explicitly loops through all cells start-
ing at position j + 1, but this search also exists in
the original CYK+ in the form of the same type-2
item being re-used over time.
The guarantee that all cells (j +1, k) are visited
before cell (i, j) in the recursive algorithm allows
for a further optimization. We construct a com-
pressed matrix representation of the chart, which
can be incrementally updated in O(|V |·n2), V be-
ing the vocabulary of non-terminal symbols. For
each start position and non-terminal symbol, we
maintain an array of possible end positions and
the corresponding chart entry, as illustrated in Ta-
ble 1. The array is compressed in that it does not
represent empty chart cells. Using the previous
example, instead of searching all cells (3, x) for
a symbol NP, we only need to retrieve the array
corresponding to start position 3 and symbol NP
to obtain the array of cells which can continue the
partial production.
While not affecting the time complexity of
the algorithm, this compression technique reduces
computational cost in two ways. If the chart is
sparsely populated, i.e. if the size of the arrays is
smaller than n − j, the algorithm iterates through
fewer elements. Even if the chart is dense, we only
perform one chart look-up per non-terminal and
partial production, instead of n − j.
</bodyText>
<table confidence="0.968908">
cell S NP V ART NN
(3,3) 0x81
(3,4) 0x86
start symbol compressed column
3 ART [(3, 0x81)]
3 NP [(4, 0x86)]
3 S,V,NN []
</table>
<tableCaption confidence="0.997071">
Table 1: Matrix representation of all chart en-
</tableCaption>
<bodyText confidence="0.8173955">
tries starting at position 3 (top), and equivalent
compressed representation (bottom). Chart entries
are pointers to objects that represent collection of
translation hypotheses and their scores.
</bodyText>
<sectionHeader confidence="0.999967" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.9902885">
Our proposed algorithm is similar to the work
by Leermakers (1992), who describe a recursive
variant of Earley’s algorithm. While they discuss
function memoization, which takes the place of
charts in their work, as a space-time trade-off, a
key insight of our work is that we can order the
chart traversal in SCFG decoding so that partial
productions need not be tabulated or memoized,
without incurring any trade-off in time complex-
ity.
Dunlop et al. (2010) employ a similar matrix
compression strategy for CYK parsing, but their
method is different to ours in that they employ ma-
trix compression on the grammar, which they as-
sume to be in Chomsky Normal Form, whereas we
represent n-ary grammars as tries, and use matrix
compression for the chart.
An obvious alternative to n-ary parsing is the
use of binary grammars, and early SCFG mod-
els for SMT allowed only binary rules, as in the
hierarchical models by Chiang (2007)8, or bina-
rizable ones as in inversion-transduction grammar
(ITG) (Wu, 1997). Whether an n-ary rule can be
binarized depends on the rule-internal reorderings
between non-terminals; Zhang et al. (2006) de-
scribe a synchronous binarization algorithm.
Hopkins and Langmead (2010) show that the
complexity of parsing n-ary rules is determined
by the number of choice points, i.e. non-terminals
that are initial, consecutive, or final, since terminal
symbols in the rule constrain which cells are pos-
sible application contexts of a non-terminal sym-
bol. They propose pruning of the SCFG to rules
8Specifically, Chiang (2007) allows at most two non-
terminals per rule, and no adjacent non-terminals on the
source side.
</bodyText>
<page confidence="0.994698">
98
</page>
<bodyText confidence="0.999985459459459">
with at most 3 decision points, or scope 3, as an
alternative to binarization that allows parsing in
cubic time. In a runtime evaluation, SMT with
their pruned, unbinarized grammar offers a bet-
ter speed-quality trade-off than synchronous bi-
narization because, even though both have the
same complexity characteristics, synchronous bi-
narization increases both the overall number of
rules, and the number of non-terminals, which in-
creases the grammar constant. In contrast, Chung
et al. (2011) compare binarization and Earley-style
parsing with scope-pruned grammars, and find
Earley-style parsing to be slower. They attribute
the comparative slowness of Earley-style parsing
to the cost of building and storing the dot chart
during decoding, which is exactly the problem that
our paper addresses.
Williams and Koehn (2012) describe a parsing
algorithm motivated by Hopkins and Langmead
(2010) in which they store the grammar in a com-
pact trie with source terminal symbols or a generic
gap symbol as edge labels. Each path through this
trie corresponds to a rule pattern, and is associated
with the set of grammar rules that share the same
rule pattern. Their algorithm initially constructs a
secondary trie that records all rule patterns that ap-
ply to the input sentence, and stores the position of
matching terminal symbols. Then, chart cells are
populated by constructing a lattice for each rule
pattern identified in the initial step, and traversing
all paths through this lattice. Their algorithm is
similar to ours in that they also avoid the construc-
tion of a dot chart, but they construct two other
auxiliary structures instead: a secondary trie and
a lattice for each rule pattern. In comparison, our
algorithm is simpler, and we perform an empirical
comparison of the two in the next section.
</bodyText>
<sectionHeader confidence="0.993275" genericHeader="method">
5 Empirical Results
</sectionHeader>
<bodyText confidence="0.999965142857143">
We empirically compare our algorithm to the
CYK+ algorithm, and the Scope-3 algorithm as
described by Williams and Koehn (2012), in a
string-to-tree SMT task. All parsing algorithms
are equivalent in terms of translation output, and
our evaluation focuses on memory consumption
and speed.
</bodyText>
<subsectionHeader confidence="0.9865">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.614897333333333">
For SMT decoding, we use the Moses toolkit
(Koehn et al., 2007) with KenLM for language
model queries (Heafield, 2011). We use training
</bodyText>
<table confidence="0.99089">
algorithm n = 20 n = 40 n = 80
Scope-3 0.02 0.04 0.34
CYK+ 0.32 2.63 51.64
+ recursive 0.02 0.04 0.15
+ compression 0.02 0.04 0.15
</table>
<tableCaption confidence="0.971522">
Table 2: Peak memory consumption (in GB) of
</tableCaption>
<bodyText confidence="0.997652125">
string-to-tree SMT decoder for sentences of dif-
ferent length n with different parsing algorithms.
data from the ACL 2014 Ninth Workshop on Sta-
tistical Machine Translation (WMT) shared trans-
lation task, consisting of 4.5 million sentence pairs
of parallel data and a total of 120 million sen-
tences of monolingual data. We build a string-
to-tree translation system English→German, us-
ing target-side syntactic parses obtained with the
dependency parser ParZu (Sennrich et al., 2013).
A synchronous grammar is extracted with GHKM
rule extraction (Galley et al., 2004; Galley et al.,
2006), and the grammar is pruned to scope 3.
The synchronous grammar contains 38 million
rule pairs with 23 million distinct source-side
rules. We report decoding time for a random sam-
ple of 1000 sentences from the newstest2013/4
sets (average sentence length: 21.9 tokens), and
peak memory consumption for sentences of 20,
40, and 80 tokens. We do not report the time
and space required for loading the SMT models,
which is stable for all experiments.9 The parsing
algorithm only accounts for part of the cost during
decoding, and the relative gains from optimizing
the parsing algorithm are highest if the rest of the
decoder is fast. For best speed, we use cube prun-
ing with language model boundary word grouping
(Heafield et al., 2013) in all experiments. We set
no limit to the maximal span of SCFG rules, but
only keep the best 100 productions per span for
cube pruning. The cube pruning limit itself is set
to 1000.
</bodyText>
<subsectionHeader confidence="0.999751">
5.2 Memory consumption
</subsectionHeader>
<bodyText confidence="0.999897">
Peak memory consumption for different sentence
lengths is shown in Table 2. For sentences of
length 80, we observe more than 50 GB in peak
memory consumption for CYK+, which makes
it impractical for long sentences, especially for
multi-threaded decoding. Our recursive variants
keep memory consumption small, as does the
</bodyText>
<footnote confidence="0.996057333333333">
9The language model consumes 13 GB of memory, and
the SCFG 37 GB. We leave the task of compacting the gram-
mar to future research.
</footnote>
<page confidence="0.996201">
99
</page>
<figure confidence="0.997347">
0 20 40 60 80
sentence length
</figure>
<figureCaption confidence="0.8664">
Figure 3: Decoding time per sentence as a func-
tion of sentence length for four parsing variants.
Regression curves use least squares fitting on cu-
bic function.
</figureCaption>
<table confidence="0.999508">
algorithm length 80 random
parse total parse total
Scope-3 74.5 81.1 1.9 2.6
CYK+ 358.0 365.4 8.4 9.1
+ recursive 33.7 40.1 1.5 2.2
+ compression 15.0 21.2 1.0 1.7
</table>
<tableCaption confidence="0.997165">
Table 3: Parse time and total decoding time per
</tableCaption>
<bodyText confidence="0.8823535">
sentence (in seconds) of string-to-tree SMT de-
coder with different parsing algorithms.
Scope-3 algorithm. This is in line with our theoret-
ical expectation, since both algorithms eliminate
the dot chart, which is the costliest data structure
in the original CYK+ algorithm.
</bodyText>
<subsectionHeader confidence="0.996327">
5.3 Speed
</subsectionHeader>
<bodyText confidence="0.999987675">
While the main motivation for eliminating the dot
chart was to reduce memory consumption, we also
find that our parsing variants are markedly faster
than the original CYK+ algorithm. Figure 3 shows
decoding time for sentences of different length
with the four parsing variants. Table 3 shows se-
lected results numerically, and also distinguishes
between total decoding time and time spent in the
parsing block, the latter ignoring the cost of cube
pruning and language model scoring. If we con-
sider parse time for sentences of length 80, we ob-
serve a speed-up by a factor of 24 between our
fastest variant (with recursion and chart compres-
sion), and the original CYK+.
The gains from chart compression over the re-
cursive variant – a factor 2 reduction in parse time
for sentences of length 80 – are attributable to a
reduction in the number of computational steps.
The large speed difference between CYK+ and
the recursive variant is somewhat more surpris-
ing, given the similarity of the two algorithms.
Profiling results show that the recursive variant is
not only faster because it saves the computational
overhead of creating and destroying the dot chart,
but that it also has a better locality of reference,
with markedly fewer CPU cache misses.
Time differences are smaller for shorter sen-
tences, both in terms of time spent parsing, and be-
cause the time spent outside of parsing is a higher
proportion of the total. Still, we observe a factor
5 speed-up in total decoding time on our random
translation sample from CYK+ to our fastest vari-
ant. We also observe speed-ups over the Scope-3
parser, ranging from a factor 5 speed-up (parsing
time on sentences of length 80) to a 50% speed-up
(total time on random translation sample). It is un-
clear to what extent these speed differences reflect
the cost of building the auxiliary data structures in
the Scope-3 parser, and how far they are due to
implementation details.
</bodyText>
<subsectionHeader confidence="0.986722">
5.4 Rule prefix scope
</subsectionHeader>
<bodyText confidence="0.999995590909091">
For the CYK+ parser, the growth of both memory
consumption and decoding time exceeds our cubic
growth expectation. We earlier remarked that the
rule prefix of a scope-3 rule may actually be scope-
4 if the prefix ends in a non-terminal, but the rule
itself does not. Since this could increase space and
time complexity of CYK+ to O(n4), we did addi-
tional experiments in which we prune all scope-3
rules with a scope-4 prefix. This affected 1% of
all source-side rules in our model, and only had
a small effect on translation quality (19.76 BLEU
→ 19.73 BLEU on newstest2013). With this addi-
tional pruning, memory consumption with CYK+
is closer to our theoretical expectation, with a peak
memory consumption of 23 GB for sentences of
length 80 (≈ 23 times more than for length 40).
We also observe reductions in parse time as shown
in Table 4. While we do see marked reductions
in parse time for all CYK+ variants, our recursive
variants maintain their efficiency advantage over
the original algorithm. Rule prefix scope is irrel-
evant for the Scope-3 parsing algorithm10, and its
</bodyText>
<footnote confidence="0.892662">
10Despite its name, the Scope-3 parsing algorithm al-
</footnote>
<note confidence="0.776737">
lows grammars of any scope, with a time complexity of
</note>
<figure confidence="0.955247090909091">
O(nscope(G)).
Scope-3 parser
CYK+
+ recursive
+ compression
decoding time (seconds)
400
300
200
100
0
</figure>
<page confidence="0.797032">
100
</page>
<table confidence="0.9960245">
algorithm length 80 random
full pruned full pruned
Scope-3 74.5 70.1 1.9 1.8
CYK+ 358.0 245.5 8.4 6.4
+ recursive 33.7 24.5 1.5 1.2
+ compression 15.0 10.5 1.0 0.8
</table>
<tableCaption confidence="0.979711">
Table 4: Average parse time (in seconds) of string-
</tableCaption>
<bodyText confidence="0.9512352">
to-tree SMT decoder with different parsing algo-
rithms, before and after scope-3 rules with scope-4
prefix have been pruned from grammar.
speed is only marginally affected by this pruning
procedure.
</bodyText>
<sectionHeader confidence="0.999689" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99996648">
While SCFG decoders with dot charts are still
wide-spread, we argue that dot charts are only of
limited use for SCFG decoding. The core contri-
butions of this paper are the insight that a right-
to-left, depth-first chart traversal order allows for
the removal of the dot chart from the popular
CYK+ algorithm without incurring any computa-
tional cost for SCFG decoding, and the presen-
tation of a recursive CYK+ variant that is based
on this insight. Apart from substantial savings
in space complexity, we empirically demonstrate
gains in decoding speed. The new chart traversal
order also allows for a chart compression strategy
that yields further speed gains.
Our parsing algorithm does not affect the search
space or cause any loss in translation quality,
and its speed improvements are orthogonal to im-
provements in cube pruning (Gesmundo et al.,
2012; Heafield et al., 2013). The algorithmic
modifications to CYK+ that we propose are sim-
ple, but we believe that the efficiency gains of
our algorithm are of high practical importance for
syntax-based SMT. An implementation of the al-
gorithm has been released as part of the Moses
SMT toolkit.
</bodyText>
<sectionHeader confidence="0.997752" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9953276">
I thank Matt Post, Philip Williams, Marcin
Junczys-Dowmunt and the anonymous reviewers
for their helpful suggestions and feedback. This
research was funded by the Swiss National Sci-
ence Foundation under grant P2ZHP1_148717.
</bodyText>
<sectionHeader confidence="0.998438" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999913927272728">
Jean-Cédric Chappelier and Martin Rajman. 1998. A
Generalized CYK Algorithm for Parsing Stochastic
CFG. In TAPD, pages 133–137.
David Chiang. 2007. Hierarchical Phrase-Based
Translation. Comput. Linguist., 33(2):201–228.
Tagyoung Chung, Licheng Fang, and Daniel Gildea.
2011. Issues Concerning Decoding with Syn-
chronous Context-free Grammar. In ACL (Short
Papers), pages 413–417. The Association for Com-
puter Linguistics.
Aaron Dunlop, Nathan Bodenstab, and Brian Roark.
2010. Reducing the grammar constant: an analysis
of CYK parsing efficiency. Technical report CSLU-
2010-02, OHSU.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Seti-
awan, Vladimir Eidelman, and Philip Resnik. 2010.
cdec: A Decoder, Alignment, and Learning frame-
work for finite-state and context-free translation
models. In Proceedings of the Association for Com-
putational Linguistics (ACL).
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a Translation Rule?
In HLT-NAACL ’04.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In ACL-
44: Proceedings of the 21st International Confer-
ence on Computational Linguistics and the 44th an-
nual meeting of the Association for Computational
Linguistics, pages 961–968, Sydney, Australia. As-
sociation for Computational Linguistics.
Andrea Gesmundo, Giorgio Satta, and James Hender-
son. 2012. Heuristic Cube Pruning in Linear Time.
In Proceedings of the 50th Annual Meeting of the
Association for Computational Linguistics: Short
Papers - Volume 2, ACL ’12, pages 296–300, Jeju
Island, Korea. Association for Computational Lin-
guistics.
Kenneth Heafield, Philipp Koehn, and Alon Lavie.
2013. Grouping Language Model Boundary Words
to Speed K-Best Extraction from Hypergraphs. In
Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 958–968, Atlanta, Georgia, USA.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
Edinburgh, UK. Association for Computational Lin-
guistics.
Mark Hopkins and Greg Langmead. 2010. SCFG
Decoding Without Binarization. In EMNLP, pages
646–655.
</reference>
<page confidence="0.975825">
101
</page>
<reference confidence="0.999772219512195">
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the ACL-2007 Demo and Poster
Sessions, pages 177–180, Prague, Czech Republic.
Association for Computational Linguistics.
René Leermakers. 1992. A recursive ascent Earley
parser. Information Processing Letters, 41(2):87–
91, February.
Rico Sennrich, Martin Volk, and Gerold Schneider.
2013. Exploiting Synergies Between Open Re-
sources for German Dependency Parsing, POS-
tagging, and Morphological Analysis. In Proceed-
ings of the International Conference Recent Ad-
vances in Natural Language Processing 2013, pages
601–609, Hissar, Bulgaria.
Ashish Venugopal and Andreas Zollmann. 2009.
Grammar based statistical MT on Hadoop: An end-
to-end toolkit for large scale PSCFG based MT. The
Prague Bulletin ofMathematical Linguistics, 91:67–
78.
David Vilar, Daniel Stein, Matthias Huck, and Her-
mann Ney. 2012. Jane: an advanced freely avail-
able hierarchical machine translation toolkit. Ma-
chine Translation, 26(3):197–216.
Philip Williams and Philipp Koehn. 2012. GHKM
Rule Extraction and Scope-3 Parsing in Moses. In
Proceedings of the Seventh Workshop on Statisti-
cal Machine Translation, pages 388–394, Montréal,
Canada, June. Association for Computational Lin-
guistics.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Knight. 2006. Synchronous Binarization for Ma-
chine Translation. In HLT-NAACL. The Association
for Computational Linguistics.
</reference>
<page confidence="0.998621">
102
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.479132">
<title confidence="0.998242">A CYK+ Variant for SCFG Decoding Without a Dot Chart</title>
<author confidence="0.995678">Rico</author>
<affiliation confidence="0.9986735">School of University of</affiliation>
<address confidence="0.749709333333333">10 Crichton Edinburgh EH8 Scotland,</address>
<email confidence="0.993209">v1rsennr@staffmail.ed.ac.uk</email>
<abstract confidence="0.9988236">While CYK+ and Earley-style variants are popular algorithms for decoding unbinarized SCFGs, in particular for syntaxbased Statistical Machine Translation, the algorithms rely on a so-called dot chart which suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jean-Cédric Chappelier</author>
<author>Martin Rajman</author>
</authors>
<title>A Generalized CYK Algorithm for Parsing Stochastic CFG.</title>
<date>1998</date>
<booktitle>In TAPD,</booktitle>
<pages>133--137</pages>
<contexts>
<context position="1072" citStr="Chappelier and Rajman, 1998" startWordPosition="164" endWordPosition="167">. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eliminate the dot chart from the CYK+ algorithm at no computational cost for SCFG decoding. Our algorithm improves space complexity, and an emp</context>
<context position="7707" citStr="Chappelier and Rajman (1998)" startWordPosition="1263" endWordPosition="1266">ater position have been visited before. Thus, whenever we generate a partial production, we can immediately explore all of its continuations, and then discard the partial production. This eliminates the need for a dot chart, without incurring any computational cost. We could also say that the dot chart exists in a minimal form with at most one item at a time, and a space complexity of O(1). We proceed with a description of the proposed algorithm, contrasted with the closely related CYK+ algorithm. 3 Algorithm 3.1 The CYK+ algorithm We here summarize the CYK+ algorithm, originally described by Chappelier and Rajman (1998).3 3Chappelier and Rajman (1998) add the restriction that rules may not be partially lexicalized; our description of CYK+, and our own algorithm, do not place this restriction. 1 2 3 4 5 6 7 8 9 10 2 3 4 5 6 7 8 9 10 1 95 The main data structure during decoding is a chart with one cell for each span of words in an input string w1...wn of length n. Each cell Ti,j corresponding to the span from wi to wj contains two lists of items:4 • a list of type-1 items, which are nonterminals (representing productions). • a list of type-2 items (dotted items), which are strings of symbols α that parse the s</context>
</contexts>
<marker>Chappelier, Rajman, 1998</marker>
<rawString>Jean-Cédric Chappelier and Martin Rajman. 1998. A Generalized CYK Algorithm for Parsing Stochastic CFG. In TAPD, pages 133–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical Phrase-Based Translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="17397" citStr="Chiang (2007)" startWordPosition="3076" endWordPosition="3077">FG decoding so that partial productions need not be tabulated or memoized, without incurring any trade-off in time complexity. Dunlop et al. (2010) employ a similar matrix compression strategy for CYK parsing, but their method is different to ours in that they employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, whereas we represent n-ary grammars as tries, and use matrix compression for the chart. An obvious alternative to n-ary parsing is the use of binary grammars, and early SCFG models for SMT allowed only binary rules, as in the hierarchical models by Chiang (2007)8, or binarizable ones as in inversion-transduction grammar (ITG) (Wu, 1997). Whether an n-ary rule can be binarized depends on the rule-internal reorderings between non-terminals; Zhang et al. (2006) describe a synchronous binarization algorithm. Hopkins and Langmead (2010) show that the complexity of parsing n-ary rules is determined by the number of choice points, i.e. non-terminals that are initial, consecutive, or final, since terminal symbols in the rule constrain which cells are possible application contexts of a non-terminal symbol. They propose pruning of the SCFG to rules 8Specifical</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical Phrase-Based Translation. Comput. Linguist., 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tagyoung Chung</author>
<author>Licheng Fang</author>
<author>Daniel Gildea</author>
</authors>
<title>Issues Concerning Decoding with Synchronous Context-free Grammar.</title>
<date>2011</date>
<booktitle>In ACL (Short Papers),</booktitle>
<pages>413--417</pages>
<institution>The Association for Computer Linguistics.</institution>
<contexts>
<context position="18601" citStr="Chung et al. (2011)" startWordPosition="3260" endWordPosition="3263">les 8Specifically, Chiang (2007) allows at most two nonterminals per rule, and no adjacent non-terminals on the source side. 98 with at most 3 decision points, or scope 3, as an alternative to binarization that allows parsing in cubic time. In a runtime evaluation, SMT with their pruned, unbinarized grammar offers a better speed-quality trade-off than synchronous binarization because, even though both have the same complexity characteristics, synchronous binarization increases both the overall number of rules, and the number of non-terminals, which increases the grammar constant. In contrast, Chung et al. (2011) compare binarization and Earley-style parsing with scope-pruned grammars, and find Earley-style parsing to be slower. They attribute the comparative slowness of Earley-style parsing to the cost of building and storing the dot chart during decoding, which is exactly the problem that our paper addresses. Williams and Koehn (2012) describe a parsing algorithm motivated by Hopkins and Langmead (2010) in which they store the grammar in a compact trie with source terminal symbols or a generic gap symbol as edge labels. Each path through this trie corresponds to a rule pattern, and is associated wit</context>
</contexts>
<marker>Chung, Fang, Gildea, 2011</marker>
<rawString>Tagyoung Chung, Licheng Fang, and Daniel Gildea. 2011. Issues Concerning Decoding with Synchronous Context-free Grammar. In ACL (Short Papers), pages 413–417. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron Dunlop</author>
<author>Nathan Bodenstab</author>
<author>Brian Roark</author>
</authors>
<title>Reducing the grammar constant: an analysis of CYK parsing efficiency.</title>
<date>2010</date>
<tech>Technical report CSLU2010-02, OHSU.</tech>
<contexts>
<context position="16931" citStr="Dunlop et al. (2010)" startWordPosition="2993" endWordPosition="2996">nt compressed representation (bottom). Chart entries are pointers to objects that represent collection of translation hypotheses and their scores. 4 Related Work Our proposed algorithm is similar to the work by Leermakers (1992), who describe a recursive variant of Earley’s algorithm. While they discuss function memoization, which takes the place of charts in their work, as a space-time trade-off, a key insight of our work is that we can order the chart traversal in SCFG decoding so that partial productions need not be tabulated or memoized, without incurring any trade-off in time complexity. Dunlop et al. (2010) employ a similar matrix compression strategy for CYK parsing, but their method is different to ours in that they employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, whereas we represent n-ary grammars as tries, and use matrix compression for the chart. An obvious alternative to n-ary parsing is the use of binary grammars, and early SCFG models for SMT allowed only binary rules, as in the hierarchical models by Chiang (2007)8, or binarizable ones as in inversion-transduction grammar (ITG) (Wu, 1997). Whether an n-ary rule can be binarized depends on the ru</context>
</contexts>
<marker>Dunlop, Bodenstab, Roark, 2010</marker>
<rawString>Aaron Dunlop, Nathan Bodenstab, and Brian Roark. 2010. Reducing the grammar constant: an analysis of CYK parsing efficiency. Technical report CSLU2010-02, OHSU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Adam Lopez</author>
<author>Juri Ganitkevitch</author>
<author>Johnathan Weese</author>
<author>Ferhan Ture</author>
<author>Phil Blunsom</author>
<author>Hendra Setiawan</author>
<author>Vladimir Eidelman</author>
<author>Philip Resnik</author>
</authors>
<title>cdec: A Decoder, Alignment, and Learning framework for finite-state and context-free translation models.</title>
<date>2010</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1001" citStr="Dyer et al., 2010" startWordPosition="152" endWordPosition="155">alled dot chart which suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eliminate the dot chart from the CYK+ algorithm at no computational cost</context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>Chris Dyer, Adam Lopez, Juri Ganitkevitch, Johnathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A Decoder, Alignment, and Learning framework for finite-state and context-free translation models. In Proceedings of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a Translation Rule? In</title>
<date>2004</date>
<booktitle>HLT-NAACL ’04.</booktitle>
<contexts>
<context position="21101" citStr="Galley et al., 2004" startWordPosition="3668" endWordPosition="3671">.02 0.04 0.15 Table 2: Peak memory consumption (in GB) of string-to-tree SMT decoder for sentences of different length n with different parsing algorithms. data from the ACL 2014 Ninth Workshop on Statistical Machine Translation (WMT) shared translation task, consisting of 4.5 million sentence pairs of parallel data and a total of 120 million sentences of monolingual data. We build a stringto-tree translation system English→German, using target-side syntactic parses obtained with the dependency parser ParZu (Sennrich et al., 2013). A synchronous grammar is extracted with GHKM rule extraction (Galley et al., 2004; Galley et al., 2006), and the grammar is pruned to scope 3. The synchronous grammar contains 38 million rule pairs with 23 million distinct source-side rules. We report decoding time for a random sample of 1000 sentences from the newstest2013/4 sets (average sentence length: 21.9 tokens), and peak memory consumption for sentences of 20, 40, and 80 tokens. We do not report the time and space required for loading the SMT models, which is stable for all experiments.9 The parsing algorithm only accounts for part of the cost during decoding, and the relative gains from optimizing the parsing algo</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a Translation Rule? In HLT-NAACL ’04.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In ACL44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>961--968</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="2572" citStr="Galley et al., 2006" startWordPosition="400" endWordPosition="403">ng We then describe our algorithm as a variant of CYK+, and finally perform an empirical evaluation of memory consumption and translation speed of several parsing algorithms. 2 SCFG Decoding To motivate our algorithm, we want to highlight some important differences between (monolingual) CFG parsing and SCFG decoding. Grammars in SMT are typically several orders of magnitude larger than for monolingual parsing, partially because of the large amounts of training data employed to learn SCFGs, partially because SMT systems benefit from using contextually rich rules rather than only minimal rules (Galley et al., 2006). Also, the same right-hand-side rule on the source side can be associated with many translations, and different (source and/or target) lefthand-side symbols. Consequently, a compact representation of the grammar is of paramount importance. We follow the implementation in the Moses SMT toolkit (Koehn et al., 2007) which encodes an SCFG as a trie in which each node represents a (partial or completed) rule, and a node has outgoing edges for each possible continuation of the rule in the grammar, either a source-side terminal symbol or pair of non-terminal-symbols. If a node represents a completed</context>
<context position="21123" citStr="Galley et al., 2006" startWordPosition="3672" endWordPosition="3675">: Peak memory consumption (in GB) of string-to-tree SMT decoder for sentences of different length n with different parsing algorithms. data from the ACL 2014 Ninth Workshop on Statistical Machine Translation (WMT) shared translation task, consisting of 4.5 million sentence pairs of parallel data and a total of 120 million sentences of monolingual data. We build a stringto-tree translation system English→German, using target-side syntactic parses obtained with the dependency parser ParZu (Sennrich et al., 2013). A synchronous grammar is extracted with GHKM rule extraction (Galley et al., 2004; Galley et al., 2006), and the grammar is pruned to scope 3. The synchronous grammar contains 38 million rule pairs with 23 million distinct source-side rules. We report decoding time for a random sample of 1000 sentences from the newstest2013/4 sets (average sentence length: 21.9 tokens), and peak memory consumption for sentences of 20, 40, and 80 tokens. We do not report the time and space required for loading the SMT models, which is stable for all experiments.9 The parsing algorithm only accounts for part of the cost during decoding, and the relative gains from optimizing the parsing algorithm are highest if t</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In ACL44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 961–968, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Gesmundo</author>
<author>Giorgio Satta</author>
<author>James Henderson</author>
</authors>
<title>Heuristic Cube Pruning in Linear Time.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL ’12,</booktitle>
<pages>296--300</pages>
<institution>Jeju Island, Korea. Association for Computational Linguistics.</institution>
<marker>Gesmundo, Satta, Henderson, 2012</marker>
<rawString>Andrea Gesmundo, Giorgio Satta, and James Henderson. 2012. Heuristic Cube Pruning in Linear Time. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers - Volume 2, ACL ’12, pages 296–300, Jeju Island, Korea. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Philipp Koehn</author>
<author>Alon Lavie</author>
</authors>
<title>Grouping Language Model Boundary Words to Speed K-Best Extraction from Hypergraphs.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>958--968</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="21857" citStr="Heafield et al., 2013" startWordPosition="3796" endWordPosition="3799">istinct source-side rules. We report decoding time for a random sample of 1000 sentences from the newstest2013/4 sets (average sentence length: 21.9 tokens), and peak memory consumption for sentences of 20, 40, and 80 tokens. We do not report the time and space required for loading the SMT models, which is stable for all experiments.9 The parsing algorithm only accounts for part of the cost during decoding, and the relative gains from optimizing the parsing algorithm are highest if the rest of the decoder is fast. For best speed, we use cube pruning with language model boundary word grouping (Heafield et al., 2013) in all experiments. We set no limit to the maximal span of SCFG rules, but only keep the best 100 productions per span for cube pruning. The cube pruning limit itself is set to 1000. 5.2 Memory consumption Peak memory consumption for different sentence lengths is shown in Table 2. For sentences of length 80, we observe more than 50 GB in peak memory consumption for CYK+, which makes it impractical for long sentences, especially for multi-threaded decoding. Our recursive variants keep memory consumption small, as does the 9The language model consumes 13 GB of memory, and the SCFG 37 GB. We lea</context>
</contexts>
<marker>Heafield, Koehn, Lavie, 2013</marker>
<rawString>Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2013. Grouping Language Model Boundary Words to Speed K-Best Extraction from Hypergraphs. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 958–968, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and Smaller Language Model Queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="20347" citStr="Heafield, 2011" startWordPosition="3544" endWordPosition="3545">res instead: a secondary trie and a lattice for each rule pattern. In comparison, our algorithm is simpler, and we perform an empirical comparison of the two in the next section. 5 Empirical Results We empirically compare our algorithm to the CYK+ algorithm, and the Scope-3 algorithm as described by Williams and Koehn (2012), in a string-to-tree SMT task. All parsing algorithms are equivalent in terms of translation output, and our evaluation focuses on memory consumption and speed. 5.1 Data For SMT decoding, we use the Moses toolkit (Koehn et al., 2007) with KenLM for language model queries (Heafield, 2011). We use training algorithm n = 20 n = 40 n = 80 Scope-3 0.02 0.04 0.34 CYK+ 0.32 2.63 51.64 + recursive 0.02 0.04 0.15 + compression 0.02 0.04 0.15 Table 2: Peak memory consumption (in GB) of string-to-tree SMT decoder for sentences of different length n with different parsing algorithms. data from the ACL 2014 Ninth Workshop on Statistical Machine Translation (WMT) shared translation task, consisting of 4.5 million sentence pairs of parallel data and a total of 120 million sentences of monolingual data. We build a stringto-tree translation system English→German, using target-side syntactic p</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and Smaller Language Model Queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, Edinburgh, UK. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Greg Langmead</author>
</authors>
<title>SCFG Decoding Without Binarization. In</title>
<date>2010</date>
<booktitle>EMNLP,</booktitle>
<pages>646--655</pages>
<contexts>
<context position="4243" citStr="Hopkins and Langmead (2010)" startWordPosition="671" endWordPosition="675">resented by a single node. Rules are matched to the input in a bottom-upfashion as described in the next section. A single rule or rule prefix can match the input many times, either by matching different spans of the input, or by matching the same span, but with different subspans for its non-terminal symbols. Each production is uniquely identified by a span, a grammar trie node, and back-pointers to its subderivations. The same is true for a partial production (dotted item). A key difference between monolingual parsing and SCFG decoding, whose implications on time complexity are discussed by Hopkins and Langmead (2010), is that SCFG decoders need to consider language model costs when searching for the best derivation of an input sentence. This critically affects the parser’s ability to discard dotted items early. For CFG parsing, we only need to keep one partial production per rule prefix and span, or k for k-best parsing, selecting the one(s) whose subderivations have the lower cost in case of ambiguity. For SCFG decoding, the subderivation with the higher local cost may be the globally better choice after taking language model costs into account. Consequently, SCFG decoders need to consider multiple possi</context>
<context position="17672" citStr="Hopkins and Langmead (2010)" startWordPosition="3113" endWordPosition="3116">employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, whereas we represent n-ary grammars as tries, and use matrix compression for the chart. An obvious alternative to n-ary parsing is the use of binary grammars, and early SCFG models for SMT allowed only binary rules, as in the hierarchical models by Chiang (2007)8, or binarizable ones as in inversion-transduction grammar (ITG) (Wu, 1997). Whether an n-ary rule can be binarized depends on the rule-internal reorderings between non-terminals; Zhang et al. (2006) describe a synchronous binarization algorithm. Hopkins and Langmead (2010) show that the complexity of parsing n-ary rules is determined by the number of choice points, i.e. non-terminals that are initial, consecutive, or final, since terminal symbols in the rule constrain which cells are possible application contexts of a non-terminal symbol. They propose pruning of the SCFG to rules 8Specifically, Chiang (2007) allows at most two nonterminals per rule, and no adjacent non-terminals on the source side. 98 with at most 3 decision points, or scope 3, as an alternative to binarization that allows parsing in cubic time. In a runtime evaluation, SMT with their pruned, u</context>
<context position="19001" citStr="Hopkins and Langmead (2010)" startWordPosition="3318" endWordPosition="3321"> though both have the same complexity characteristics, synchronous binarization increases both the overall number of rules, and the number of non-terminals, which increases the grammar constant. In contrast, Chung et al. (2011) compare binarization and Earley-style parsing with scope-pruned grammars, and find Earley-style parsing to be slower. They attribute the comparative slowness of Earley-style parsing to the cost of building and storing the dot chart during decoding, which is exactly the problem that our paper addresses. Williams and Koehn (2012) describe a parsing algorithm motivated by Hopkins and Langmead (2010) in which they store the grammar in a compact trie with source terminal symbols or a generic gap symbol as edge labels. Each path through this trie corresponds to a rule pattern, and is associated with the set of grammar rules that share the same rule pattern. Their algorithm initially constructs a secondary trie that records all rule patterns that apply to the input sentence, and stores the position of matching terminal symbols. Then, chart cells are populated by constructing a lattice for each rule pattern identified in the initial step, and traversing all paths through this lattice. Their a</context>
</contexts>
<marker>Hopkins, Langmead, 2010</marker>
<rawString>Mark Hopkins and Greg Langmead. 2010. SCFG Decoding Without Binarization. In EMNLP, pages 646–655.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondˇrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-2007 Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Alexandra</location>
<contexts>
<context position="952" citStr="Koehn et al., 2007" startWordPosition="144" endWordPosition="147">Machine Translation, the algorithms rely on a so-called dot chart which suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eliminate the dot chart</context>
<context position="2887" citStr="Koehn et al., 2007" startWordPosition="450" endWordPosition="453">g. Grammars in SMT are typically several orders of magnitude larger than for monolingual parsing, partially because of the large amounts of training data employed to learn SCFGs, partially because SMT systems benefit from using contextually rich rules rather than only minimal rules (Galley et al., 2006). Also, the same right-hand-side rule on the source side can be associated with many translations, and different (source and/or target) lefthand-side symbols. Consequently, a compact representation of the grammar is of paramount importance. We follow the implementation in the Moses SMT toolkit (Koehn et al., 2007) which encodes an SCFG as a trie in which each node represents a (partial or completed) rule, and a node has outgoing edges for each possible continuation of the rule in the grammar, either a source-side terminal symbol or pair of non-terminal-symbols. If a node represents a completed rule, it is also associated with a collection of left-hand-side symbols and the associated target-side rules and probabilities. A trie data structure allows for an efficient grammar lookup, since all rules with the same pre94 Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical</context>
<context position="20292" citStr="Koehn et al., 2007" startWordPosition="3534" endWordPosition="3537">a dot chart, but they construct two other auxiliary structures instead: a secondary trie and a lattice for each rule pattern. In comparison, our algorithm is simpler, and we perform an empirical comparison of the two in the next section. 5 Empirical Results We empirically compare our algorithm to the CYK+ algorithm, and the Scope-3 algorithm as described by Williams and Koehn (2012), in a string-to-tree SMT task. All parsing algorithms are equivalent in terms of translation output, and our evaluation focuses on memory consumption and speed. 5.1 Data For SMT decoding, we use the Moses toolkit (Koehn et al., 2007) with KenLM for language model queries (Heafield, 2011). We use training algorithm n = 20 n = 40 n = 80 Scope-3 0.02 0.04 0.34 CYK+ 0.32 2.63 51.64 + recursive 0.02 0.04 0.15 + compression 0.02 0.04 0.15 Table 2: Peak memory consumption (in GB) of string-to-tree SMT decoder for sentences of different length n with different parsing algorithms. data from the ACL 2014 Ninth Workshop on Statistical Machine Translation (WMT) shared translation task, consisting of 4.5 million sentence pairs of parallel data and a total of 120 million sentences of monolingual data. We build a stringto-tree translati</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the ACL-2007 Demo and Poster Sessions, pages 177–180, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>René Leermakers</author>
</authors>
<title>A recursive ascent Earley parser.</title>
<date>1992</date>
<journal>Information Processing Letters,</journal>
<volume>41</volume>
<issue>2</issue>
<pages>91</pages>
<contexts>
<context position="16539" citStr="Leermakers (1992)" startWordPosition="2930" endWordPosition="2931"> n − j, the algorithm iterates through fewer elements. Even if the chart is dense, we only perform one chart look-up per non-terminal and partial production, instead of n − j. cell S NP V ART NN (3,3) 0x81 (3,4) 0x86 start symbol compressed column 3 ART [(3, 0x81)] 3 NP [(4, 0x86)] 3 S,V,NN [] Table 1: Matrix representation of all chart entries starting at position 3 (top), and equivalent compressed representation (bottom). Chart entries are pointers to objects that represent collection of translation hypotheses and their scores. 4 Related Work Our proposed algorithm is similar to the work by Leermakers (1992), who describe a recursive variant of Earley’s algorithm. While they discuss function memoization, which takes the place of charts in their work, as a space-time trade-off, a key insight of our work is that we can order the chart traversal in SCFG decoding so that partial productions need not be tabulated or memoized, without incurring any trade-off in time complexity. Dunlop et al. (2010) employ a similar matrix compression strategy for CYK parsing, but their method is different to ours in that they employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, wher</context>
</contexts>
<marker>Leermakers, 1992</marker>
<rawString>René Leermakers. 1992. A recursive ascent Earley parser. Information Processing Letters, 41(2):87– 91, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
<author>Martin Volk</author>
<author>Gerold Schneider</author>
</authors>
<title>Exploiting Synergies Between Open Resources for German Dependency Parsing, POStagging, and Morphological Analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<pages>601--609</pages>
<location>Hissar, Bulgaria.</location>
<contexts>
<context position="21018" citStr="Sennrich et al., 2013" startWordPosition="3655" endWordPosition="3658">Scope-3 0.02 0.04 0.34 CYK+ 0.32 2.63 51.64 + recursive 0.02 0.04 0.15 + compression 0.02 0.04 0.15 Table 2: Peak memory consumption (in GB) of string-to-tree SMT decoder for sentences of different length n with different parsing algorithms. data from the ACL 2014 Ninth Workshop on Statistical Machine Translation (WMT) shared translation task, consisting of 4.5 million sentence pairs of parallel data and a total of 120 million sentences of monolingual data. We build a stringto-tree translation system English→German, using target-side syntactic parses obtained with the dependency parser ParZu (Sennrich et al., 2013). A synchronous grammar is extracted with GHKM rule extraction (Galley et al., 2004; Galley et al., 2006), and the grammar is pruned to scope 3. The synchronous grammar contains 38 million rule pairs with 23 million distinct source-side rules. We report decoding time for a random sample of 1000 sentences from the newstest2013/4 sets (average sentence length: 21.9 tokens), and peak memory consumption for sentences of 20, 40, and 80 tokens. We do not report the time and space required for loading the SMT models, which is stable for all experiments.9 The parsing algorithm only accounts for part o</context>
</contexts>
<marker>Sennrich, Volk, Schneider, 2013</marker>
<rawString>Rico Sennrich, Martin Volk, and Gerold Schneider. 2013. Exploiting Synergies Between Open Resources for German Dependency Parsing, POStagging, and Morphological Analysis. In Proceedings of the International Conference Recent Advances in Natural Language Processing 2013, pages 601–609, Hissar, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Andreas Zollmann</author>
</authors>
<title>Grammar based statistical MT on Hadoop: An endto-end toolkit for large scale PSCFG based MT. The Prague Bulletin ofMathematical Linguistics,</title>
<date>2009</date>
<pages>91--67</pages>
<contexts>
<context position="982" citStr="Venugopal and Zollmann, 2009" startWordPosition="148" endWordPosition="151"> the algorithms rely on a so-called dot chart which suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eliminate the dot chart from the CYK+ algorithm at no</context>
</contexts>
<marker>Venugopal, Zollmann, 2009</marker>
<rawString>Ashish Venugopal and Andreas Zollmann. 2009. Grammar based statistical MT on Hadoop: An endto-end toolkit for large scale PSCFG based MT. The Prague Bulletin ofMathematical Linguistics, 91:67– 78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vilar</author>
<author>Daniel Stein</author>
<author>Matthias Huck</author>
<author>Hermann Ney</author>
</authors>
<title>Jane: an advanced freely available hierarchical machine translation toolkit.</title>
<date>2012</date>
<journal>Machine Translation,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="1022" citStr="Vilar et al., 2012" startWordPosition="156" endWordPosition="159">ch suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eliminate the dot chart from the CYK+ algorithm at no computational cost for SCFG decoding. O</context>
</contexts>
<marker>Vilar, Stein, Huck, Ney, 2012</marker>
<rawString>David Vilar, Daniel Stein, Matthias Huck, and Hermann Ney. 2012. Jane: an advanced freely available hierarchical machine translation toolkit. Machine Translation, 26(3):197–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Williams</author>
<author>Philipp Koehn</author>
</authors>
<title>GHKM Rule Extraction and Scope-3 Parsing in Moses.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>388--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montréal, Canada,</location>
<contexts>
<context position="18931" citStr="Williams and Koehn (2012)" startWordPosition="3308" endWordPosition="3311"> speed-quality trade-off than synchronous binarization because, even though both have the same complexity characteristics, synchronous binarization increases both the overall number of rules, and the number of non-terminals, which increases the grammar constant. In contrast, Chung et al. (2011) compare binarization and Earley-style parsing with scope-pruned grammars, and find Earley-style parsing to be slower. They attribute the comparative slowness of Earley-style parsing to the cost of building and storing the dot chart during decoding, which is exactly the problem that our paper addresses. Williams and Koehn (2012) describe a parsing algorithm motivated by Hopkins and Langmead (2010) in which they store the grammar in a compact trie with source terminal symbols or a generic gap symbol as edge labels. Each path through this trie corresponds to a rule pattern, and is associated with the set of grammar rules that share the same rule pattern. Their algorithm initially constructs a secondary trie that records all rule patterns that apply to the input sentence, and stores the position of matching terminal symbols. Then, chart cells are populated by constructing a lattice for each rule pattern identified in th</context>
</contexts>
<marker>Williams, Koehn, 2012</marker>
<rawString>Philip Williams and Philipp Koehn. 2012. GHKM Rule Extraction and Scope-3 Parsing in Moses. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 388–394, Montréal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="17473" citStr="Wu, 1997" startWordPosition="3087" endWordPosition="3088">ut incurring any trade-off in time complexity. Dunlop et al. (2010) employ a similar matrix compression strategy for CYK parsing, but their method is different to ours in that they employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, whereas we represent n-ary grammars as tries, and use matrix compression for the chart. An obvious alternative to n-ary parsing is the use of binary grammars, and early SCFG models for SMT allowed only binary rules, as in the hierarchical models by Chiang (2007)8, or binarizable ones as in inversion-transduction grammar (ITG) (Wu, 1997). Whether an n-ary rule can be binarized depends on the rule-internal reorderings between non-terminals; Zhang et al. (2006) describe a synchronous binarization algorithm. Hopkins and Langmead (2010) show that the complexity of parsing n-ary rules is determined by the number of choice points, i.e. non-terminals that are initial, consecutive, or final, since terminal symbols in the rule constrain which cells are possible application contexts of a non-terminal symbol. They propose pruning of the SCFG to rules 8Specifically, Chiang (2007) allows at most two nonterminals per rule, and no adjacent </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Daniel Gildea</author>
<author>Kevin Knight</author>
</authors>
<title>Synchronous Binarization for Machine Translation. In HLT-NAACL. The Association for Computational Linguistics.</title>
<date>2006</date>
<contexts>
<context position="932" citStr="Zhang et al., 2006" startWordPosition="140" endWordPosition="143">axbased Statistical Machine Translation, the algorithms rely on a so-called dot chart which suffers from a high memory consumption. We propose a recursive variant of the CYK+ algorithm that eliminates the dot chart, without incurring an increase in time complexity for SCFG decoding. In an evaluation on a string-totree SMT scenario, we empirically demonstrate substantial improvements in memory consumption and translation speed. 1 Introduction SCFG decoding can be performed with monolingual parsing algorithms, and various SMT systems implement the CYK+ algorithm or a close Earley-style variant (Zhang et al., 2006; Koehn et al., 2007; Venugopal and Zollmann, 2009; Dyer et al., 2010; Vilar et al., 2012). The CYK+ algorithm (Chappelier and Rajman, 1998) generalizes the CYK algorithm to n-ary rules by performing a dynamic binarization of the grammar during parsing through a so-called dot chart. The construction of the dot chart is a major cause of space inefficiency in SCFG decoding with CYK+, and memory consumption makes the algorithm impractical for long sentences without artificial limits on the span of chart cells. We demonstrate that, by changing the traversal through the main parse chart, we can eli</context>
<context position="17597" citStr="Zhang et al. (2006)" startWordPosition="3103" endWordPosition="3106">or CYK parsing, but their method is different to ours in that they employ matrix compression on the grammar, which they assume to be in Chomsky Normal Form, whereas we represent n-ary grammars as tries, and use matrix compression for the chart. An obvious alternative to n-ary parsing is the use of binary grammars, and early SCFG models for SMT allowed only binary rules, as in the hierarchical models by Chiang (2007)8, or binarizable ones as in inversion-transduction grammar (ITG) (Wu, 1997). Whether an n-ary rule can be binarized depends on the rule-internal reorderings between non-terminals; Zhang et al. (2006) describe a synchronous binarization algorithm. Hopkins and Langmead (2010) show that the complexity of parsing n-ary rules is determined by the number of choice points, i.e. non-terminals that are initial, consecutive, or final, since terminal symbols in the rule constrain which cells are possible application contexts of a non-terminal symbol. They propose pruning of the SCFG to rules 8Specifically, Chiang (2007) allows at most two nonterminals per rule, and no adjacent non-terminals on the source side. 98 with at most 3 decision points, or scope 3, as an alternative to binarization that allo</context>
</contexts>
<marker>Zhang, Huang, Gildea, Knight, 2006</marker>
<rawString>Hao Zhang, Liang Huang, Daniel Gildea, and Kevin Knight. 2006. Synchronous Binarization for Machine Translation. In HLT-NAACL. The Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>