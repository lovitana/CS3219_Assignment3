<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000443">
<title confidence="0.996852">
Initiative Taking in Negotiation
</title>
<author confidence="0.996157">
Elnaz Nouri
</author>
<affiliation confidence="0.8249205">
University of Southern California
Los Angeles, CA, USA
</affiliation>
<email confidence="0.984971">
nouri@ict.usc.edu
</email>
<author confidence="0.967906">
David Traum
</author>
<affiliation confidence="0.952979">
USC Institute for Creative Technologies
</affiliation>
<address confidence="0.8748845">
12015 Waterfront Dr
Playa Vista, CA 90094, USA
</address>
<email confidence="0.998817">
traum@ict.usc.edu
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996911875">
We examine the relationship between ini-
tiative behavior in negotiation dialogues
and the goals and outcomes of the ne-
gotiation. We propose a novel annota-
tion scheme for dialogue initiative, includ-
ing four labels for initiative and response
behavior in a dialogue turn. We anno-
tate an existing human-human negotiation
dataset, and use initiative-based features
to try to predict both negotiation goal and
outcome, comparing our results to prior
work using other (non-initiative) features
sets. Results show that combining initia-
tive features with other features leads to
improvements over either set and a major-
ity class baseline.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999964620689655">
Negotiation is a complex interaction in which two
or more parties confer with one another to arrive
at the settlement of some matter, for example re-
solving a conflict or to share common resources.
The parties involved in the negotiation often have
non-identical preferences and goals that they try to
reach. Sometimes the parties simply try to change
a situation to their favor by haggling over price. In
other cases, there can be a more complex trade-off
between issues. Investigating these rich and com-
plex interactions in a scientific manner has been
important to researchers in different fields due to
the significant implications and potential applica-
tions for business and profit making. Being a good
negotiator is not a skill that all humans naturally
have; therefore, this line of research can poten-
tially be used to help humans become better ne-
gotiators. Computer agents will also benefit from
the ability to understand human negotiators. There
has been a fair amount of previous work in un-
derstanding negotiation dialogs, e.g., (Walton and
McKersie, 1991; Baker, 1994); as well as agents
who can engage in negotiation, e.g. (Jameson et
al., 1994; Sidner, 1994; Kraus et al., 2008; Traum
et al., 2008). In this paper we investigate the role
that dialogue initiative plays in negotiation.
Negotiations can be characterized by both the
goals that each negotiator is trying to achieve, as
well as the outcomes. Even for negotiations that
attempt to partition a set of goods, the participants
may have differences in their valuation of items,
and the negotiations can be very different if peo-
ple are trying to maximize the total gain or their
individual gain, or gain a competitive advantage
over the other.
Negotiations between two people are usually
mixed-initiative (Walker and Whittaker, 1990),
with control of conversation being transferred
from one person to another. To our knowledge,
no previous studies have investigated the relation-
ship between verbal initiative taking patterns and
the goal or the outcome of the negotiation. We
suspected that both of the mentioned characteris-
tics of the negotiation (goal and outcome) might be
correlated with different initiative-taking patterns.
We used an existing negotiation dataset in order
to study the mixed initiative patterns between the
two parties in the negotiation. We describe this
data set in Section 2, as well as previous work that
attempted to predict outcome and goal, using other
features (Nouri et al., 2013).
This paper makes the following contributions:
a new annotation scheme for dialogue initiative is
introduced in Section 3 and used to annotate the
negotiation dataset. We then study the relation-
ship between initiative taking patterns and the goal
and outcome of the negotiation for the participants
(Section 4).
</bodyText>
<sectionHeader confidence="0.997535" genericHeader="introduction">
2 Data
</sectionHeader>
<bodyText confidence="0.972884">
We make use of a previously collected and ana-
lyzed dataset in order to examine the relative con-
</bodyText>
<page confidence="0.984024">
186
</page>
<bodyText confidence="0.9763847">
Proceedings of the SIGDIAL 2014 Conference, pages 186–193,
Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics
tribution of initiative to problems of goal and out-
come detection. We briefly describe the dataset
and relevant prior work on this dataset.
The Farmers Market dataset (Carnevale, 2013)
contains audio, video and transcription of 41
dyadic negotiation sessions. Participants were un-
dergraduate students majoring in business. Each
participant only took part in one negotiation ses-
sion.
Before each negotiation session, the experi-
menter told participants that they were randomly
assigned to represent one of two restaurants in the
task. The owners of the two restaurants had asked
the participants to go to the market and get some
apples, bananas, lemons, peppers and strawber-
ries. The payoff matrix for each restaurant and
type of item is shown in Table 1. There were mul-
tiple items of each type available. Each participant
was only given the pay-off matrix of his assigned
restaurant and the total score of the negotiation for
each participant was calculated by adding up the
points for each item they received in the negotia-
tion. The participants were told that they had 10
minutes to negotiate how to distribute the items on
the table and reach an agreement. As an incentive,
each participant could receive up to 50 dollars de-
pending on the final points earned by each partici-
pant for his/her restaurant.
</bodyText>
<table confidence="0.992272833333333">
R1 R2
Apples 1 3
Bananas 3 3
Lemons 0 0
Peppers 3 1
Strawberries 1 1
</table>
<tableCaption confidence="0.999884">
Table 1: The Payoff Matrix for each Restaurant
</tableCaption>
<subsectionHeader confidence="0.961938">
2.1 Goals
</subsectionHeader>
<bodyText confidence="0.998213666666667">
The study was originally designed to investigate
negotiators’ behavior when they have different
goals in the negotiation. There were three types
of instructions given to the participants. All the
details were the same except for their goal in the
negotiation.
</bodyText>
<listItem confidence="0.92789425">
• In “individualistic” instructions participants
were told that their goal was to get at as many
points as they could for themselves. An ex-
cerpt from an individualistic negotiation is
shown in Table 13 in the Appendix.
• in “cooperative” instructions they were told
that they should try to maximize the joint gain
with the other side of the negotiation. An ex-
cerpt from a cooperative negotiation is shown
in Table 11 in the Appendix.
• in “competitive” instructions they were told
to try to get more points than the other party.
</listItem>
<bodyText confidence="0.8990554">
An excerpt from a competitive negotiation is
shown in Table 12 in the Appendix.
Out of the 41 interactions in the dataset 15 were
competitive, 13 were individualistic and 13 were
cooperative sessions.
</bodyText>
<subsectionHeader confidence="0.974736">
2.2 Outcomes
</subsectionHeader>
<bodyText confidence="0.999993478260869">
The outcome of the negotiation in this case is mea-
sured based on the calculation of the scores corre-
sponding to the items that each negotiator has re-
ceived by the end of the negotiation. In order to
make the prediction of outcome possible based on
our small dataset, we labeled the calculated score
for each participant with one of the three labels:
H,E or L, showing whether the participant had re-
ceived more, equal or fewer points than the other
person.
The goal of the “competitive” instructions was
to get a higher score. For cooperative negotiations,
the relative score did not matter. For the individu-
alistic goal, higher score is somewhat correlated
with the goal, but not absolutely (what matters
is only an individual high score, not the relation
to the other partner). 17 negotiations resulted in
equal final scores for the two parties and 24 with
one side scoring more than the other side. Ta-
ble 2 shows the average scores for each restaurant,
across the three types of goals. The scores are on
average higher in the cooperative negotiations than
in the other two conditions.
</bodyText>
<table confidence="0.9981596">
Average score R1 R2 Joint
Gain
Cooperative 24.9 25.1 50
Competitive 23.7 23.6 47.3
Individualistic 25.5 22.5 48
</table>
<tableCaption confidence="0.99913">
Table 2: Average Score by Restaurant and Goal
</tableCaption>
<bodyText confidence="0.99982225">
The average score for individuals who score
higher (labeled as H) than the other side of the ne-
gotiation was 26.46 whereas the average score for
their counterparts (labeled as L) was 21.65. The
</bodyText>
<page confidence="0.989903">
187
</page>
<bodyText confidence="0.999165">
average score for individuals who ended up in a
tie (labeled as E) was 24.16.
</bodyText>
<subsectionHeader confidence="0.997711">
2.3 Previous Work and Baseline System
</subsectionHeader>
<bodyText confidence="0.999888583333334">
This data set was previously used for various pur-
poses but (Nouri et al., 2013) was most similar
to our current work in that it also tried to pre-
dict the goal and outcome in the negotiation, us-
ing a different set of features, and a slightly dif-
ferent formulation of the problem. (Nouri et al.,
2013) used multimodal features (such as acoustic
features and sentiments of the turns) for this pur-
pose. We use initiative-features to build our pre-
diction models. In order to make a baseline classi-
fier, we used the following automatically derivable
features from (Nouri et al., 2013):
</bodyText>
<listItem confidence="0.97902625">
• The mean and standard deviation of acoustic
features automatically extracted;
• The amount of silence and speaking time for
each speaker;
• Sentiment (positive, negative) and subjectiv-
ity scores calculated for words and turns
• number of words, turns, words per turn and
words related to the negotiation objects
</listItem>
<bodyText confidence="0.999947">
We used only features that were easily and au-
tomatically derivable, excluding features from
(Nouri et al., 2013) such as the number of offers
and the number of rejections or acceptances.
</bodyText>
<sectionHeader confidence="0.990953" genericHeader="method">
3 Initiative Labeling
</sectionHeader>
<bodyText confidence="0.999940246376812">
A common way of structuring dialogue is with
Initiative-Response pairs, or IR units (Dahlb¨ack
and J¨onsson, 1998), which are also similar to adja-
cency pairs (Levinson, 1983), or simple exchange
units (Sinclair and Coulthard, 1975). Several re-
searchers have also proposed multiple levels of
initiative. For example, (Whittaker and Stenton,
1988) had levels based on the type of utterance
(commands, questions, assertions, and prompts).
(Chu-Carroll and Brown, 1997) posit two levels
of initiative: discourse initiative, attained by pro-
viding reasons for responses, and critiques of pro-
posed plans, and task initiative, obtained by sug-
gesting new tasks or plans. Linell et al. exam-
ine several factors, such as initiative vs response,
strength of initiative, adequacy of response, scope
and focality of response (Linell et al., 1988). They
end up with an ordered set of six possible strengths
of initiative. Each of these schemes is somewhat
complicated by the fact that turns can consist of
multiple basic elements.
Analyzing previous work, we can see that initia-
tive breaks down into two distinct concepts. First
there is providing unsolicited, or optional, or ex-
tra material, that is not a required response to a
previous initiative. Second, there is the sense of
putting a new discourse obligation (Traum and
Allen, 1994) on a dialogue partner to respond.
These two concepts often come together, such as
for new questions or proposals that require some
sort of response: they are both unsolicited and im-
pose an obligation, which is why (Whittaker and
Stenton, 1988) indicate that control should belong
to the speaker of these utterances. However, it is
also possible to have each one without the other.
Statements can include new unsolicited material,
without imposing an obligation to respond (other
than the weak obligation to ground understand-
ing of any contribution). Likewise, clarification
questions impose new obligations on the other, but
often do not contribute new material or are not
optional, in that the responder can not reply ap-
propriately without the clarification. For (Whit-
taker and Stenton, 1988), the issue of whether
a question or assertion was a “response” would
determine whether control went to the speaker
or remained with a previous speaker. On the
other hand, (Narayanan et al., 2000) call a re-
sponse that includes unsolicited material “mixed-
initiative” rather than “system initiative” for user
responses that contain only prompted material.
Likewise, response can also be broken down
into two related concepts. One concerns fulfilling
obligations imposed by prior initiatives. To not do
so could be considered rude and a violation of con-
versational norms in some cases. This is only rel-
evant, if there is an existing initiative-related obli-
gation as part of the conversational state. Another
concept generalizes the notion of response to any-
thing that contributes to the same topic and makes
an effort to relate to prior utterances by the other
party, whether or not it fulfills an obligation or
whether there even is a pending obligation. This
is like relevance in the sense of Sperber and Wil-
son (Sperber and Wilson, 1986) and Lascarides
and Asher (Asher and Lascarides, 2003).
Our annotation scheme thus includes four la-
bels, as indicated in Table 4. Each of the labels
can either be present or absent from a dialogue
</bodyText>
<page confidence="0.981803">
188
</page>
<table confidence="0.999913125">
Time/Speaker Example Utterance Labels
(R,F,I,N)
[1 : 58] Person 1: Do you want to do just like one grab at a time?
Or do you know how you want to divvy it up? (-,-,I,N)
[2 : 13] Person 2: Um, I’m just thinking. (R,F,-,-)
[3 : 38] Person 1: Do you want it? I’ll take it. Um, do you want to do any trading? (R,-,I,-)
[4 : 15] Person 2: Um, how much is a banana for you? (-,-,I,N)
[4 : 15] Person 1: For me? A point, or two points. How much is the pepper worth? (R,F,I,N)
</table>
<tableCaption confidence="0.966967">
Table 3: Sample Annotated Utterances
</tableCaption>
<table confidence="0.998112833333333">
Label Description
R directly relates to prior utterance
F fulfills a pending discourse obligation
I imposes a discourse obligation
N provides new material that is optional
and not just fulfilling an obligation.
</table>
<tableCaption confidence="0.999185">
Table 4: Initiative Labels
</tableCaption>
<bodyText confidence="0.999366111111111">
segment. The annotation is done on each turn on
the conversation. In general, a turn can consist of
almost any combination of these four initiative la-
bels (I,R,F,N). We thus treat each of these as an
independent binary dimension, and code each turn
as to which set of these labels it contains. Table 3
shows an example from the corpus with initiative
annotations. More examples can be found in the
Appendix, Tables 11, 12, and 13.
</bodyText>
<subsectionHeader confidence="0.95904">
3.1 Inter Annotator Reliability
</subsectionHeader>
<bodyText confidence="0.999945529411765">
To assess the reliability of our annotations, ap-
proximately 10% of the dialogs (4 dialogs) were
annotated by two annotators. The level of the
agreement was then assessed using the Kappa
statistic (Carletta, 1996; Siegel and Castellan,
1988). Table 5 shows the result of the assessment
of the reliability of the annotations for the four an-
notation labels.1 Based on this metric our results
indicate that the annotators have reasonable level
of agreement in labeling utterances with the I, F
,N labels, though there is less reliability for the
“related” label. Further work is needed to clar-
ify the degree of relation that should count and
also whether relation refers just to the immediately
prior turn or something further back. The remain-
der of the dialogues were annotated by one anno-
tator.
</bodyText>
<footnote confidence="0.959223">
1Chance agreement is the probability of agreement using
the frequencies of each label, but applied randomly.
</footnote>
<table confidence="0.99994725">
R F I N
kappa 0.36 0.64 0.66 0.73
actual agreement 0.76 0.83 0.83 0.86
chance agreement 0.62 0.52 0.49 0.50
</table>
<tableCaption confidence="0.997539">
Table 5: Inter-Annotator Reliability Assessment
</tableCaption>
<subsectionHeader confidence="0.98913">
3.2 Initiative Taking Patterns
</subsectionHeader>
<bodyText confidence="0.999438285714286">
Table 6 shows the average frequency of each ini-
tiative label for each negotiation goal. We can see
that competitive dialogues have more turns that
impose and fulfill obligations than the other con-
ditions, while individualistic dialogues include a
higher percentage of turns introducing new mate-
rial.
</bodyText>
<table confidence="0.99941075">
Label R F I N
Cooperative 0.79 0.35 0.40 0.33
Competitive 0.82 0.38 0.47 0.34
Individualistic 0.82 0.34 0.39 0.40
</table>
<tableCaption confidence="0.992377">
Table 6: Comparison of the Relative Frequency of
</tableCaption>
<bodyText confidence="0.906995454545454">
the Initiative Labels for Each Goal
Table 7 shows the relative frequency of initia-
tive labels for the different outcome conditions.
The higher scoring participants had a higher fre-
quency of initiative-related turns (labels I and N),
while their lower scoring partners had a higher fre-
quency of responsive turns (R,F). Equal scoring
participants tended to pattern closer to higher scor-
ing participants, concerning responses, but closer
to lower scoring participants, considering initia-
tive.
</bodyText>
<subsectionHeader confidence="0.988445">
3.3 Initiative Features
</subsectionHeader>
<bodyText confidence="0.9999035">
After the Initiative annotation was done, the fol-
lowing features were automatically extracted:
</bodyText>
<listItem confidence="0.511651">
• the count of each label (I,F,R,N) per negotia-
tion and per person
</listItem>
<page confidence="0.995609">
189
</page>
<table confidence="0.99967625">
Label R F I N
H 0.80 0.35 0.47 0.38
E 0.81 0.35 0.40 0.34
L 0.84 0.38 0.43 0.36
</table>
<tableCaption confidence="0.989263">
Table 7: Comparison of the Relative Frequency of
</tableCaption>
<table confidence="0.306509">
the Initiative Labels for Each Score Label
</table>
<listItem confidence="0.955084571428571">
• the ratio, difference and absolute difference
of the number of labels for each person
against the number of labels for their nego-
tiation counterpart
• the above measures normalized by the num-
ber of turns in dialog
• Within-turn patterns the number of all pos-
sible combinations of labels for each utter-
ance. There are 16 possible combinations for
the 4 types of labels that can be shown as tu-
ples (R,F,I,N). Refer to Table 5 for examples.
• Across-turn Patterns the number of all pos-
sible sequences of labels across two adjacent
turns. There are also 16 possible combina-
tions capturing how often each label is fol-
lowed by labels. For example, the feature
(I,F) applies to all two-turn sequences where
the first turn contains label I and the second
contains label F, such as in the last two lines
of Figure 3. We count the these features for
the dialogue and for each speaker.
</listItem>
<bodyText confidence="0.99979425">
All of the above features were automatically ex-
tracted from the annotated dialogues. We exam-
ined four different spans of the dialogues, to inves-
tigate whether the most salient initiative informa-
tion comes early in the dialogue or requires the full
dialogue. We calculated features for the first quar-
ter (q1), first half (q2), first three quarters (q3), and
the whole negotiation (q4).
</bodyText>
<sectionHeader confidence="0.996212" genericHeader="method">
4 Prediction Models
</sectionHeader>
<bodyText confidence="0.999990523809524">
We conducted experiments to recognize negotia-
tion goal and score for each of the 82 negotia-
tors. We made prediction models for recognizing
the goal and outcome for each individual.For the
prediction models, we compared the result of sup-
port vector machine (SVM- with the polynomial
kernel function) classifier, Naive Bayes and De-
cision Tree. None of the classifiers outperformed
the others on all cases, we are reporting the result
of SVM classifier here. Considering the size of
our dataset which consists of 82 samples (41 pairs
of individuals) and the distribution of the samples
in different classes, we decided to use the 10-fold
cross validation paradigm for our prediction tasks.
In splitting the dataset into the folds we controlled
so that the participants from the same negotiation
were not split across training and test sets. We
trained and tested at the end of the each quarter
of the negotiation.
We used three sets of features to make three pre-
diction models for each task:
</bodyText>
<listItem confidence="0.999918333333333">
1. Non-initiative features from (Nouri et al.,
2013), described in section 2.3. We refer to
these non-initiative features as IS2013’ from
this point on.
2. Initiative features
3. All features combined.
</listItem>
<bodyText confidence="0.999913444444445">
We compare the performance of these models with
two baseline prediction models: one that chooses
one of the outcomes at random, and one that pre-
dicts the majority class for all instances. In the
upcoming sections, we use q1, q2, q3 and q4 to
refer to the ends of the first, second, third and the
forth quarters of the negotiation (e.g. q3 includes
all data from the first three quarters, but not the
last).
</bodyText>
<subsectionHeader confidence="0.997683">
4.1 Automatic Prediction of Goal
</subsectionHeader>
<bodyText confidence="0.999480636363636">
This task predicts whether the negotiators are fol-
lowing the cooperative, competitive or individual-
istic instructions. It is important to note that none
of the features used require understanding of the
content or a semantic analysis of the conversation.
However, using these basic features it’s possible
to make the classification into the mentioned three
classes with accuracy that is significantly higher
than chance. The average accuracy of prediction
at the four different points in the negotiation are
shown in Table 8.
</bodyText>
<table confidence="0.997817166666667">
q1 q2 q3 q4
Random 0.33 0.33 0.33 ♣ 0.33 ♣
Majority 0.37 0.37 0.37 ♣ 0.37
IS2013 0.41 0.34 0.40 ♣ 0.48 ∗†
Initiative 0.29 ♣ 0.52 ∗†♣ 0.48 ∗† 0.29 ♣
Combined 0.41 0.40 0.57 ∗† 0.44 ∗
</table>
<tableCaption confidence="0.999639">
Table 8: Accuracy of the Prediction of Goal
</tableCaption>
<page confidence="0.99724">
190
</page>
<bodyText confidence="0.999871652173913">
We use the two-sided binomial test to measure
the significance of the differences of the prediction
models’ performances. Table 8 and the upcoming
Tables 9 and 10 use symbols to indicate the results
of these significance tests. Symbols (*),(†) and
(46) show which models’ performances are signif-
icantly different from the random baseline, major-
ity baseline or the “Combined” classifier respec-
tively (p &lt; 0.05).
The combined classifier is always better than
both baselines, as well as the lower of classi-
fiers for the IS2013 and Initiative features. In
q3, where the two are close in performance, the
combined classifier significantly outperforms both
baselines and the IS2013 model. Note that ex-
cept for q3, these numbers are lower than those
reported by (Nouri et al., 2013). However the prior
work did not ensure that both individuals in a ne-
gotiation were in the same training/test partition,
and some features are the same for both partici-
pants. That work also made use of higher-level
features, such as the offers, and final distributions
of items.
</bodyText>
<subsectionHeader confidence="0.993869">
4.2 Automatic Prediction of Outcome
</subsectionHeader>
<bodyText confidence="0.995647571428571">
In this task the goal is to predict how a partic-
ipant in the negotiation is going to do in terms
of the scores at the end of the negotiation. The
model predicts whether the negotiator would score
higher, lower or equal to the other player at the end
of the different quarters of the negotiation. Results
are shown in Table 9.
</bodyText>
<table confidence="0.997831333333333">
q1 q2 q3 q4
Random 0.33 0.33 0.33 0.33 46
Majority 0.41 0.41 0.41 0.41
IS2013 0.43 * 0.34 0.23 *†46 0.39
Initiative 0.37 0.35 0.32 0.39
Combined 0.38 0.40 0.41 0.4 6*
</table>
<tableCaption confidence="0.999708">
Table 9: Accuracy of the Prediction of Outcome
</tableCaption>
<bodyText confidence="0.999752">
Except for the combined model in q4, these
models are not able to significantly outperform the
baseline of selecting the random class (with equal
likelihood). Results were also presented for out-
come in (Nouri et al., 2013), however only the fi-
nal quarter results are comparable, since that paper
predicted interim quarter-end results rather than fi-
nal results. Also, that work did not make sure that
both participants in a negotiation were in the same
training-test partitions, and used features related to
the final deal, that are directly related to outcome.
Because the relative score was not important for
cooperative negotiations, where both sides are just
trying to maximize their combined points, we next
examined outcome for the 28 pairs in individualis-
tic and competitive conditions. Results are shown
in table 10. The combined classifier outperforms
all the other classifiers, starting from quarter 2. At
the end of the negotiation(q4) the performance of
this classifier is significantly better than all other
models.
</bodyText>
<table confidence="0.997400666666667">
q1 q2 q3 q4
Random 0.33 0.33 46 0.33 46 0.33 46
Majority 0.38 0.38 0.38 0.38 46
IS2013 0.39 0.36 46 0.36 46 0.34 46
Initiative 0.27 0.41 0.36 46 0.38 46
Combined 0.35 0.50 * 0.50 * 0.55 *†
</table>
<tableCaption confidence="0.99447">
Table 10: Accuracy of the Prediction of Outcome
for Negotiations that are not Cooperative
</tableCaption>
<sectionHeader confidence="0.998595" genericHeader="method">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999987875">
We demonstrated how discourse initiatives in ne-
gotiation dialog can be used for automatically
making predictions about other aspects of the ne-
gotiation such as the goals of the negotiators. Pre-
vious work has mostly focused on using non-
verbal cues for accomplishing similar tasks but
they have not used discourse features like initia-
tives. We also show that initiative features can
give clues about the final outcome for the negotia-
tors. Making such predictions are generally chal-
lenging tasks even for humans and require under-
standing of the content of the negotiations. From a
dialog system’s perspective our results show how
more information can be derived about the users
intentions and performance by analyzing their dis-
course behavior.
</bodyText>
<sectionHeader confidence="0.999819" genericHeader="method">
6 Future Work
</sectionHeader>
<bodyText confidence="0.999647555555556">
The annotations of the initiative taking patterns
are done manually at this point. Automatic label-
ing of the utterances with the initiative tags is our
next step. We will use the labels in our dataset
for learning how to automatically label new nego-
tiation datasets. We think that HMM and HCRF
methods due to their ability to capture the sequen-
tial and temporal aspect of the negotiation might
be better methods for building the prediction mod-
</bodyText>
<page confidence="0.995601">
191
</page>
<bodyText confidence="0.999845166666667">
els. We are interested in further analysis of the re-
lationship between initiatives and other aspects of
negotiation such as intentions and the use of lan-
guage. We also want to measure the suitability of
our annotation scheme for initiatives for other di-
alogue genres.
</bodyText>
<sectionHeader confidence="0.997714" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99989825">
We like to thank Kristina Striegnitz, Christopher
Wienberg, Angela Nazarian and David DeVault
for their help with this work. The effort described
here has been sponsored by the US Army. Any
opinions, content or information presented does
not necessarily reflect the position or the policy
of the United States Government, and no official
endorsement should be inferred.
</bodyText>
<sectionHeader confidence="0.999399" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.999554524390244">
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
Michael Baker. 1994. A model for negotiation in
teaching-learning dialogues. Journal of artificial in-
telligence in education.
Jean Carletta. 1996. Assessing agreement on classi-
fication tasks: the kappa statistic. Computational
linguistics, 22(2):249–254.
Peter J Carnevale. 2013. Audio/video recordings of bi-
lateral negotiations over synthetic objects on a table
that vary in monetary value. Unpublished raw data.
Jennifer Chu-Carroll and Michael K. Brown. 1997.
Tracking initiative in collaborative dialogue inter-
actions. In Proceedings of the Thirty-Fifth Meet-
ing of the Association for Computational Linguis-
tics, pages 262–270. Association for Computational
Linguistics.
Nils Dahlb¨ack and Arne J¨onsson. 1998. A coding
manual for the link¨oping dialogue model. unpub-
lished manuscript.
Anthony Jameson, Bernhard Kipper, Alassane Ndi-
aye, Ralph Sch¨afer, Joep Simons, Thomas Weis, and
Detlev Zimmermann. 1994. Cooperating to be non-
cooperative: The dialog system PRACMA. Springer.
Sarit Kraus, Penina Hoz-Weiss, Jonathan Wilkenfeld,
David R Andersen, and Amy Pate. 2008. Resolv-
ing crises through automated bilateral negotiations.
Artificial Intelligence, 172(1):1–18.
Stephen C. Levinson. 1983. Pragmatics. Cambridge
University Press.
Per Linell, Lennart Gustavsson, and P¨aivi Juvonen.
1988. Interactional dominance in dyadic communi-
cation: a presentation of initiative-response analysis.
Linguistics, 26(3):415–442.
Shrikanth Narayanan, Giuseppe Di Fabbrizio, Can-
dace A. Kamm, James Hubbell, Bruce Buntschuh,
P. Ruscitti, and Jerry H. Wright. 2000. Effects of
dialog initiative and multi-modal presentation strate-
gies on large directory information access. In IN-
TERSPEECH, pages 636–639. ISCA.
Elnaz Nouri, Sunghyun Park, Stefan Scherer, Jonathan
Gratch, Peter Carnevale, Louie Philippe Morency,
and David Traum. 2013. Prediction of strategy and
outcome as negotiation unfolds by using basic ver-
bal and behavioral features. In proceedings of the
Interspeech conference.
Candace L. Sidner. 1994. An artificial discourse lan-
guage for collaborative negotiation. In Proceedings
of the Fourteenth National Conference of the Amer-
ican Association for Artificial Intelligence (AAAI-
94), pages 814–819.
S. Siegel and N. J. Castellan. 1988. Nonparamet-
ric statistics for the Behavioral Sciences. McGraw-
Hill, 2nd edition.
J. M. Sinclair and R. M. Coulthard. 1975. Towards an
analysis of Discourse: The English used by teachers
and pupils. Oxford University Press.
Dan Sperber and Deirdre Wilson. 1986. Relevence:
Communication and Cognition. Harvard University
Press.
David R. Traum and James F. Allen. 1994. Discourse
obligations in dialogue processing. In Proceedings
of the 32nd Annual Meeting of the Association for
Computational Linguistics, pages 1–8.
David Traum, Stacy C Marsella, Jonathan Gratch, Jina
Lee, and Arno Hartholt. 2008. Multi-party, multi-
issue, multi-strategy negotiation for multi-modal
virtual agents. In Intelligent Virtual Agents, pages
117–130. Springer.
Marilyn Walker and Steve Whittaker. 1990. Mixed ini-
tiative in dialogue: An investigation into discourse
segmentation. In Proceedings of the 28th annual
meeting on Association for Computational Linguis-
tics, pages 70–78. Association for Computational
Linguistics.
Richard E Walton and Robert B McKersie. 1991. A
behavioral theory of labor negotiations: An analysis
of a social interaction system. Cornell University
Press.
Steve Whittaker and Phil Stenton. 1988. Cues and
control in expert-client dialogues. In Proceedings
ACL-88, pages 123–130.
</reference>
<sectionHeader confidence="0.820427" genericHeader="method">
Appendix: Sample Annotated Negotiations
</sectionHeader>
<bodyText confidence="0.976221666666667">
The following tables show examples of each of the
goal conditions with initiative labeling, using the
scheme in Table 4.
</bodyText>
<page confidence="0.996291">
192
</page>
<table confidence="0.986582333333333">
Time Speaker: Utterance Labels
(R,F,I,N)
[2 : 18] 2: So what’s, so what’s everything worth to you? (-,-,I,N)
[2 : 20] Um, so apples are three, bananas are three, strawberries are one, pep- (R,F,-,-)
pers are one, and lemons are nothing.
[2 : 33] Okay so for me peppers are three, bananas are three, and apples and (R,-,-,-)
strawberries are one.
[2 : 39] 1: Lemons are zero. (R,-,-,-)
[2 : 40] 2: Yeah. (R,-,-,)
</table>
<tableCaption confidence="0.994962">
Table 11: Sample Annotated Cooperative Negotiation
</tableCaption>
<table confidence="0.424587727272727">
Time Speaker: Utterance Labels
[1 : 40] 2: So, I think I need peppers and bananas for my restaurant. (-,-,-,N)
[1 : 46] 1: Okay. Um, well I really need. I want five apples and um, five bananas. (R,-,I,N)
Five apples and five bananas.
[2 : 05] 2: Um, how about this: You take five apples, and I take five peppers and (R,F,I,N)
we can share the bananas.
[2 : 13] Okay. If I give you, if I give you five or if I give you, if we were to (R,F,I,N)
share the bananas, if I take three bananas, I’ll give you three lemons.
[2 : 23] But we don’t need lemons in our restaurant. We only use lemons for (R,F,-,N)
our store.
[2 : 27] 1: Okay. So, um, I need bananas, like that’s gonna be my top. (R,-,-,N)
</table>
<tableCaption confidence="0.989745">
Table 12: Sample Annotated Competitive Negotiation
</tableCaption>
<table confidence="0.922410153846154">
Time Speaker: Utterance Labels
[3 : 22] 2: How about we do this. You take two of these, I take one, and since we (-,F,I,N)
have five here, I take three, you take two.
[3 : 37] 1: I’m not interested in lemons at all. But I can give you... (R,F,-,N)
[3 : 52] 2: At my restaurant, one of our dessert dishes is with strawberries, so (-,-,-,N)
strawberries are very important to me.
[4 : 00] 1: Okay. I’m willing to give you all the strawberries if you give me a (R,-,-,N)
banana and two apples. I’m also willing to give you these two.
[4 : 23] 2: So you’re going to give me those two? (R,-,I,-)
[4 : 24] You can have everything on this side, I just want two apples and a (R,F,-,-)
banana.
[4 : 30] Two apples and a banana? Yeah, let’s go. (R,-,-,-)
[4 : 39] 1: We have a deal. (R,F,-,N)
</table>
<tableCaption confidence="0.99471">
Table 13: Sample Annotated Individualistic Negotiation
</tableCaption>
<page confidence="0.998637">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.440066">
<title confidence="0.99945">Initiative Taking in Negotiation</title>
<author confidence="0.940131">Elnaz</author>
<affiliation confidence="0.999764">University of Southern</affiliation>
<address confidence="0.598661">Los Angeles, CA,</address>
<email confidence="0.998408">nouri@ict.usc.edu</email>
<author confidence="0.880836">David</author>
<affiliation confidence="0.999786">USC Institute for Creative</affiliation>
<address confidence="0.9906715">12015 Waterfront Playa Vista, CA 90094,</address>
<email confidence="0.999709">traum@ict.usc.edu</email>
<abstract confidence="0.993401764705882">We examine the relationship between initiative behavior in negotiation dialogues and the goals and outcomes of the negotiation. We propose a novel annotation scheme for dialogue initiative, including four labels for initiative and response behavior in a dialogue turn. We annotate an existing human-human negotiation dataset, and use initiative-based features to try to predict both negotiation goal and outcome, comparing our results to prior work using other (non-initiative) features sets. Results show that combining initiative features with other features leads to improvements over either set and a majority class baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="12240" citStr="Asher and Lascarides, 2003" startWordPosition="1991" endWordPosition="1994">sed by prior initiatives. To not do so could be considered rude and a violation of conversational norms in some cases. This is only relevant, if there is an existing initiative-related obligation as part of the conversational state. Another concept generalizes the notion of response to anything that contributes to the same topic and makes an effort to relate to prior utterances by the other party, whether or not it fulfills an obligation or whether there even is a pending obligation. This is like relevance in the sense of Sperber and Wilson (Sperber and Wilson, 1986) and Lascarides and Asher (Asher and Lascarides, 2003). Our annotation scheme thus includes four labels, as indicated in Table 4. Each of the labels can either be present or absent from a dialogue 188 Time/Speaker Example Utterance Labels (R,F,I,N) [1 : 58] Person 1: Do you want to do just like one grab at a time? Or do you know how you want to divvy it up? (-,-,I,N) [2 : 13] Person 2: Um, I’m just thinking. (R,F,-,-) [3 : 38] Person 1: Do you want it? I’ll take it. Um, do you want to do any trading? (R,-,I,-) [4 : 15] Person 2: Um, how much is a banana for you? (-,-,I,N) [4 : 15] Person 1: For me? A point, or two points. How much is the pepper w</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Baker</author>
</authors>
<title>A model for negotiation in teaching-learning dialogues.</title>
<date>1994</date>
<journal>Journal of artificial</journal>
<note>intelligence in education.</note>
<contexts>
<context position="1967" citStr="Baker, 1994" startWordPosition="304" endWordPosition="305">sues. Investigating these rich and complex interactions in a scientific manner has been important to researchers in different fields due to the significant implications and potential applications for business and profit making. Being a good negotiator is not a skill that all humans naturally have; therefore, this line of research can potentially be used to help humans become better negotiators. Computer agents will also benefit from the ability to understand human negotiators. There has been a fair amount of previous work in understanding negotiation dialogs, e.g., (Walton and McKersie, 1991; Baker, 1994); as well as agents who can engage in negotiation, e.g. (Jameson et al., 1994; Sidner, 1994; Kraus et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain, or gain a com</context>
</contexts>
<marker>Baker, 1994</marker>
<rawString>Michael Baker. 1994. A model for negotiation in teaching-learning dialogues. Journal of artificial intelligence in education.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
</authors>
<title>Assessing agreement on classification tasks: the kappa statistic.</title>
<date>1996</date>
<journal>Computational linguistics,</journal>
<pages>22--2</pages>
<contexts>
<context position="13805" citStr="Carletta, 1996" startWordPosition="2273" endWordPosition="2274">tion. In general, a turn can consist of almost any combination of these four initiative labels (I,R,F,N). We thus treat each of these as an independent binary dimension, and code each turn as to which set of these labels it contains. Table 3 shows an example from the corpus with initiative annotations. More examples can be found in the Appendix, Tables 11, 12, and 13. 3.1 Inter Annotator Reliability To assess the reliability of our annotations, approximately 10% of the dialogs (4 dialogs) were annotated by two annotators. The level of the agreement was then assessed using the Kappa statistic (Carletta, 1996; Siegel and Castellan, 1988). Table 5 shows the result of the assessment of the reliability of the annotations for the four annotation labels.1 Based on this metric our results indicate that the annotators have reasonable level of agreement in labeling utterances with the I, F ,N labels, though there is less reliability for the “related” label. Further work is needed to clarify the degree of relation that should count and also whether relation refers just to the immediately prior turn or something further back. The remainder of the dialogues were annotated by one annotator. 1Chance agreement </context>
</contexts>
<marker>Carletta, 1996</marker>
<rawString>Jean Carletta. 1996. Assessing agreement on classification tasks: the kappa statistic. Computational linguistics, 22(2):249–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter J Carnevale</author>
</authors>
<title>Audio/video recordings of bilateral negotiations over synthetic objects on a table that vary in monetary value. Unpublished raw data.</title>
<date>2013</date>
<contexts>
<context position="4120" citStr="Carnevale, 2013" startWordPosition="644" endWordPosition="645"> annotate the negotiation dataset. We then study the relationship between initiative taking patterns and the goal and outcome of the negotiation for the participants (Section 4). 2 Data We make use of a previously collected and analyzed dataset in order to examine the relative con186 Proceedings of the SIGDIAL 2014 Conference, pages 186–193, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics tribution of initiative to problems of goal and outcome detection. We briefly describe the dataset and relevant prior work on this dataset. The Farmers Market dataset (Carnevale, 2013) contains audio, video and transcription of 41 dyadic negotiation sessions. Participants were undergraduate students majoring in business. Each participant only took part in one negotiation session. Before each negotiation session, the experimenter told participants that they were randomly assigned to represent one of two restaurants in the task. The owners of the two restaurants had asked the participants to go to the market and get some apples, bananas, lemons, peppers and strawberries. The payoff matrix for each restaurant and type of item is shown in Table 1. There were multiple items of e</context>
</contexts>
<marker>Carnevale, 2013</marker>
<rawString>Peter J Carnevale. 2013. Audio/video recordings of bilateral negotiations over synthetic objects on a table that vary in monetary value. Unpublished raw data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Chu-Carroll</author>
<author>Michael K Brown</author>
</authors>
<title>Tracking initiative in collaborative dialogue interactions.</title>
<date>1997</date>
<booktitle>In Proceedings of the Thirty-Fifth Meeting of the Association for Computational Linguistics,</booktitle>
<pages>262--270</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9497" citStr="Chu-Carroll and Brown, 1997" startWordPosition="1546" endWordPosition="1549">omatically derivable, excluding features from (Nouri et al., 2013) such as the number of offers and the number of rejections or acceptances. 3 Initiative Labeling A common way of structuring dialogue is with Initiative-Response pairs, or IR units (Dahlb¨ack and J¨onsson, 1998), which are also similar to adjacency pairs (Levinson, 1983), or simple exchange units (Sinclair and Coulthard, 1975). Several researchers have also proposed multiple levels of initiative. For example, (Whittaker and Stenton, 1988) had levels based on the type of utterance (commands, questions, assertions, and prompts). (Chu-Carroll and Brown, 1997) posit two levels of initiative: discourse initiative, attained by providing reasons for responses, and critiques of proposed plans, and task initiative, obtained by suggesting new tasks or plans. Linell et al. examine several factors, such as initiative vs response, strength of initiative, adequacy of response, scope and focality of response (Linell et al., 1988). They end up with an ordered set of six possible strengths of initiative. Each of these schemes is somewhat complicated by the fact that turns can consist of multiple basic elements. Analyzing previous work, we can see that initiativ</context>
</contexts>
<marker>Chu-Carroll, Brown, 1997</marker>
<rawString>Jennifer Chu-Carroll and Michael K. Brown. 1997. Tracking initiative in collaborative dialogue interactions. In Proceedings of the Thirty-Fifth Meeting of the Association for Computational Linguistics, pages 262–270. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils Dahlb¨ack</author>
<author>Arne J¨onsson</author>
</authors>
<title>A coding manual for the link¨oping dialogue model.</title>
<date>1998</date>
<note>unpublished manuscript.</note>
<marker>Dahlb¨ack, J¨onsson, 1998</marker>
<rawString>Nils Dahlb¨ack and Arne J¨onsson. 1998. A coding manual for the link¨oping dialogue model. unpublished manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Jameson</author>
<author>Bernhard Kipper</author>
<author>Alassane Ndiaye</author>
<author>Ralph Sch¨afer</author>
<author>Joep Simons</author>
<author>Thomas Weis</author>
<author>Detlev Zimmermann</author>
</authors>
<title>Cooperating to be noncooperative: The dialog system PRACMA.</title>
<date>1994</date>
<publisher>Springer.</publisher>
<marker>Jameson, Kipper, Ndiaye, Sch¨afer, Simons, Weis, Zimmermann, 1994</marker>
<rawString>Anthony Jameson, Bernhard Kipper, Alassane Ndiaye, Ralph Sch¨afer, Joep Simons, Thomas Weis, and Detlev Zimmermann. 1994. Cooperating to be noncooperative: The dialog system PRACMA. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarit Kraus</author>
<author>Penina Hoz-Weiss</author>
<author>Jonathan Wilkenfeld</author>
<author>David R Andersen</author>
<author>Amy Pate</author>
</authors>
<title>Resolving crises through automated bilateral negotiations.</title>
<date>2008</date>
<journal>Artificial Intelligence,</journal>
<volume>172</volume>
<issue>1</issue>
<contexts>
<context position="2078" citStr="Kraus et al., 2008" startWordPosition="322" endWordPosition="325">archers in different fields due to the significant implications and potential applications for business and profit making. Being a good negotiator is not a skill that all humans naturally have; therefore, this line of research can potentially be used to help humans become better negotiators. Computer agents will also benefit from the ability to understand human negotiators. There has been a fair amount of previous work in understanding negotiation dialogs, e.g., (Walton and McKersie, 1991; Baker, 1994); as well as agents who can engage in negotiation, e.g. (Jameson et al., 1994; Sidner, 1994; Kraus et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain, or gain a competitive advantage over the other. Negotiations between two people are usually mixed-initiative (Walker and Whi</context>
</contexts>
<marker>Kraus, Hoz-Weiss, Wilkenfeld, Andersen, Pate, 2008</marker>
<rawString>Sarit Kraus, Penina Hoz-Weiss, Jonathan Wilkenfeld, David R Andersen, and Amy Pate. 2008. Resolving crises through automated bilateral negotiations. Artificial Intelligence, 172(1):1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen C Levinson</author>
</authors>
<date>1983</date>
<publisher>Pragmatics. Cambridge University Press.</publisher>
<contexts>
<context position="9206" citStr="Levinson, 1983" startWordPosition="1507" endWordPosition="1508">The amount of silence and speaking time for each speaker; • Sentiment (positive, negative) and subjectivity scores calculated for words and turns • number of words, turns, words per turn and words related to the negotiation objects We used only features that were easily and automatically derivable, excluding features from (Nouri et al., 2013) such as the number of offers and the number of rejections or acceptances. 3 Initiative Labeling A common way of structuring dialogue is with Initiative-Response pairs, or IR units (Dahlb¨ack and J¨onsson, 1998), which are also similar to adjacency pairs (Levinson, 1983), or simple exchange units (Sinclair and Coulthard, 1975). Several researchers have also proposed multiple levels of initiative. For example, (Whittaker and Stenton, 1988) had levels based on the type of utterance (commands, questions, assertions, and prompts). (Chu-Carroll and Brown, 1997) posit two levels of initiative: discourse initiative, attained by providing reasons for responses, and critiques of proposed plans, and task initiative, obtained by suggesting new tasks or plans. Linell et al. examine several factors, such as initiative vs response, strength of initiative, adequacy of respo</context>
</contexts>
<marker>Levinson, 1983</marker>
<rawString>Stephen C. Levinson. 1983. Pragmatics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Per Linell</author>
<author>Lennart Gustavsson</author>
<author>P¨aivi Juvonen</author>
</authors>
<title>Interactional dominance in dyadic communication: a presentation of initiative-response analysis.</title>
<date>1988</date>
<journal>Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<contexts>
<context position="9863" citStr="Linell et al., 1988" startWordPosition="1604" endWordPosition="1607">and Coulthard, 1975). Several researchers have also proposed multiple levels of initiative. For example, (Whittaker and Stenton, 1988) had levels based on the type of utterance (commands, questions, assertions, and prompts). (Chu-Carroll and Brown, 1997) posit two levels of initiative: discourse initiative, attained by providing reasons for responses, and critiques of proposed plans, and task initiative, obtained by suggesting new tasks or plans. Linell et al. examine several factors, such as initiative vs response, strength of initiative, adequacy of response, scope and focality of response (Linell et al., 1988). They end up with an ordered set of six possible strengths of initiative. Each of these schemes is somewhat complicated by the fact that turns can consist of multiple basic elements. Analyzing previous work, we can see that initiative breaks down into two distinct concepts. First there is providing unsolicited, or optional, or extra material, that is not a required response to a previous initiative. Second, there is the sense of putting a new discourse obligation (Traum and Allen, 1994) on a dialogue partner to respond. These two concepts often come together, such as for new questions or prop</context>
</contexts>
<marker>Linell, Gustavsson, Juvonen, 1988</marker>
<rawString>Per Linell, Lennart Gustavsson, and P¨aivi Juvonen. 1988. Interactional dominance in dyadic communication: a presentation of initiative-response analysis. Linguistics, 26(3):415–442.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shrikanth Narayanan</author>
<author>Giuseppe Di Fabbrizio</author>
<author>Candace A Kamm</author>
<author>James Hubbell</author>
<author>Bruce Buntschuh</author>
<author>P Ruscitti</author>
<author>Jerry H Wright</author>
</authors>
<title>Effects of dialog initiative and multi-modal presentation strategies on large directory information access.</title>
<date>2000</date>
<booktitle>In INTERSPEECH,</booktitle>
<pages>636--639</pages>
<publisher>ISCA.</publisher>
<marker>Narayanan, Di Fabbrizio, Kamm, Hubbell, Buntschuh, Ruscitti, Wright, 2000</marker>
<rawString>Shrikanth Narayanan, Giuseppe Di Fabbrizio, Candace A. Kamm, James Hubbell, Bruce Buntschuh, P. Ruscitti, and Jerry H. Wright. 2000. Effects of dialog initiative and multi-modal presentation strategies on large directory information access. In INTERSPEECH, pages 636–639. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elnaz Nouri</author>
<author>Sunghyun Park</author>
<author>Stefan Scherer</author>
<author>Jonathan Gratch</author>
<author>Peter Carnevale</author>
<author>Louie Philippe Morency</author>
<author>David Traum</author>
</authors>
<title>Prediction of strategy and outcome as negotiation unfolds by using basic verbal and behavioral features.</title>
<date>2013</date>
<booktitle>In proceedings of the Interspeech conference.</booktitle>
<contexts>
<context position="3370" citStr="Nouri et al., 2013" startWordPosition="526" endWordPosition="529">rson to another. To our knowledge, no previous studies have investigated the relationship between verbal initiative taking patterns and the goal or the outcome of the negotiation. We suspected that both of the mentioned characteristics of the negotiation (goal and outcome) might be correlated with different initiative-taking patterns. We used an existing negotiation dataset in order to study the mixed initiative patterns between the two parties in the negotiation. We describe this data set in Section 2, as well as previous work that attempted to predict outcome and goal, using other features (Nouri et al., 2013). This paper makes the following contributions: a new annotation scheme for dialogue initiative is introduced in Section 3 and used to annotate the negotiation dataset. We then study the relationship between initiative taking patterns and the goal and outcome of the negotiation for the participants (Section 4). 2 Data We make use of a previously collected and analyzed dataset in order to examine the relative con186 Proceedings of the SIGDIAL 2014 Conference, pages 186–193, Philadelphia, U.S.A., 18-20 June 2014. c�2014 Association for Computational Linguistics tribution of initiative to problem</context>
<context position="8008" citStr="Nouri et al., 2013" startWordPosition="1307" endWordPosition="1310">r in the cooperative negotiations than in the other two conditions. Average score R1 R2 Joint Gain Cooperative 24.9 25.1 50 Competitive 23.7 23.6 47.3 Individualistic 25.5 22.5 48 Table 2: Average Score by Restaurant and Goal The average score for individuals who score higher (labeled as H) than the other side of the negotiation was 26.46 whereas the average score for their counterparts (labeled as L) was 21.65. The 187 average score for individuals who ended up in a tie (labeled as E) was 24.16. 2.3 Previous Work and Baseline System This data set was previously used for various purposes but (Nouri et al., 2013) was most similar to our current work in that it also tried to predict the goal and outcome in the negotiation, using a different set of features, and a slightly different formulation of the problem. (Nouri et al., 2013) used multimodal features (such as acoustic features and sentiments of the turns) for this purpose. We use initiative-features to build our prediction models. In order to make a baseline classifier, we used the following automatically derivable features from (Nouri et al., 2013): • The mean and standard deviation of acoustic features automatically extracted; • The amount of sil</context>
<context position="18321" citStr="Nouri et al., 2013" startWordPosition="3025" endWordPosition="3028">he result of SVM classifier here. Considering the size of our dataset which consists of 82 samples (41 pairs of individuals) and the distribution of the samples in different classes, we decided to use the 10-fold cross validation paradigm for our prediction tasks. In splitting the dataset into the folds we controlled so that the participants from the same negotiation were not split across training and test sets. We trained and tested at the end of the each quarter of the negotiation. We used three sets of features to make three prediction models for each task: 1. Non-initiative features from (Nouri et al., 2013), described in section 2.3. We refer to these non-initiative features as IS2013’ from this point on. 2. Initiative features 3. All features combined. We compare the performance of these models with two baseline prediction models: one that chooses one of the outcomes at random, and one that predicts the majority class for all instances. In the upcoming sections, we use q1, q2, q3 and q4 to refer to the ends of the first, second, third and the forth quarters of the negotiation (e.g. q3 includes all data from the first three quarters, but not the last). 4.1 Automatic Prediction of Goal This task </context>
<context position="20442" citStr="Nouri et al., 2013" startWordPosition="3383" endWordPosition="3386">and 10 use symbols to indicate the results of these significance tests. Symbols (*),(†) and (46) show which models’ performances are significantly different from the random baseline, majority baseline or the “Combined” classifier respectively (p &lt; 0.05). The combined classifier is always better than both baselines, as well as the lower of classifiers for the IS2013 and Initiative features. In q3, where the two are close in performance, the combined classifier significantly outperforms both baselines and the IS2013 model. Note that except for q3, these numbers are lower than those reported by (Nouri et al., 2013). However the prior work did not ensure that both individuals in a negotiation were in the same training/test partition, and some features are the same for both participants. That work also made use of higher-level features, such as the offers, and final distributions of items. 4.2 Automatic Prediction of Outcome In this task the goal is to predict how a participant in the negotiation is going to do in terms of the scores at the end of the negotiation. The model predicts whether the negotiator would score higher, lower or equal to the other player at the end of the different quarters of the ne</context>
</contexts>
<marker>Nouri, Park, Scherer, Gratch, Carnevale, Morency, Traum, 2013</marker>
<rawString>Elnaz Nouri, Sunghyun Park, Stefan Scherer, Jonathan Gratch, Peter Carnevale, Louie Philippe Morency, and David Traum. 2013. Prediction of strategy and outcome as negotiation unfolds by using basic verbal and behavioral features. In proceedings of the Interspeech conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>An artificial discourse language for collaborative negotiation.</title>
<date>1994</date>
<booktitle>In Proceedings of the Fourteenth National Conference of the American Association for Artificial Intelligence (AAAI94),</booktitle>
<pages>814--819</pages>
<contexts>
<context position="2058" citStr="Sidner, 1994" startWordPosition="320" endWordPosition="321">ortant to researchers in different fields due to the significant implications and potential applications for business and profit making. Being a good negotiator is not a skill that all humans naturally have; therefore, this line of research can potentially be used to help humans become better negotiators. Computer agents will also benefit from the ability to understand human negotiators. There has been a fair amount of previous work in understanding negotiation dialogs, e.g., (Walton and McKersie, 1991; Baker, 1994); as well as agents who can engage in negotiation, e.g. (Jameson et al., 1994; Sidner, 1994; Kraus et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain, or gain a competitive advantage over the other. Negotiations between two people are usually mixed-initia</context>
</contexts>
<marker>Sidner, 1994</marker>
<rawString>Candace L. Sidner. 1994. An artificial discourse language for collaborative negotiation. In Proceedings of the Fourteenth National Conference of the American Association for Artificial Intelligence (AAAI94), pages 814–819.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Nonparametric statistics for the Behavioral Sciences. McGrawHill, 2nd edition.</title>
<date>1988</date>
<contexts>
<context position="13834" citStr="Siegel and Castellan, 1988" startWordPosition="2275" endWordPosition="2278">, a turn can consist of almost any combination of these four initiative labels (I,R,F,N). We thus treat each of these as an independent binary dimension, and code each turn as to which set of these labels it contains. Table 3 shows an example from the corpus with initiative annotations. More examples can be found in the Appendix, Tables 11, 12, and 13. 3.1 Inter Annotator Reliability To assess the reliability of our annotations, approximately 10% of the dialogs (4 dialogs) were annotated by two annotators. The level of the agreement was then assessed using the Kappa statistic (Carletta, 1996; Siegel and Castellan, 1988). Table 5 shows the result of the assessment of the reliability of the annotations for the four annotation labels.1 Based on this metric our results indicate that the annotators have reasonable level of agreement in labeling utterances with the I, F ,N labels, though there is less reliability for the “related” label. Further work is needed to clarify the degree of relation that should count and also whether relation refers just to the immediately prior turn or something further back. The remainder of the dialogues were annotated by one annotator. 1Chance agreement is the probability of agreeme</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and N. J. Castellan. 1988. Nonparametric statistics for the Behavioral Sciences. McGrawHill, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Sinclair</author>
<author>R M Coulthard</author>
</authors>
<title>Towards an analysis of Discourse: The English used by teachers and pupils.</title>
<date>1975</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="9263" citStr="Sinclair and Coulthard, 1975" startWordPosition="1513" endWordPosition="1516"> each speaker; • Sentiment (positive, negative) and subjectivity scores calculated for words and turns • number of words, turns, words per turn and words related to the negotiation objects We used only features that were easily and automatically derivable, excluding features from (Nouri et al., 2013) such as the number of offers and the number of rejections or acceptances. 3 Initiative Labeling A common way of structuring dialogue is with Initiative-Response pairs, or IR units (Dahlb¨ack and J¨onsson, 1998), which are also similar to adjacency pairs (Levinson, 1983), or simple exchange units (Sinclair and Coulthard, 1975). Several researchers have also proposed multiple levels of initiative. For example, (Whittaker and Stenton, 1988) had levels based on the type of utterance (commands, questions, assertions, and prompts). (Chu-Carroll and Brown, 1997) posit two levels of initiative: discourse initiative, attained by providing reasons for responses, and critiques of proposed plans, and task initiative, obtained by suggesting new tasks or plans. Linell et al. examine several factors, such as initiative vs response, strength of initiative, adequacy of response, scope and focality of response (Linell et al., 1988)</context>
</contexts>
<marker>Sinclair, Coulthard, 1975</marker>
<rawString>J. M. Sinclair and R. M. Coulthard. 1975. Towards an analysis of Discourse: The English used by teachers and pupils. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Sperber</author>
<author>Deirdre Wilson</author>
</authors>
<title>Relevence: Communication and Cognition.</title>
<date>1986</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="12186" citStr="Sperber and Wilson, 1986" startWordPosition="1983" endWordPosition="1986">d concepts. One concerns fulfilling obligations imposed by prior initiatives. To not do so could be considered rude and a violation of conversational norms in some cases. This is only relevant, if there is an existing initiative-related obligation as part of the conversational state. Another concept generalizes the notion of response to anything that contributes to the same topic and makes an effort to relate to prior utterances by the other party, whether or not it fulfills an obligation or whether there even is a pending obligation. This is like relevance in the sense of Sperber and Wilson (Sperber and Wilson, 1986) and Lascarides and Asher (Asher and Lascarides, 2003). Our annotation scheme thus includes four labels, as indicated in Table 4. Each of the labels can either be present or absent from a dialogue 188 Time/Speaker Example Utterance Labels (R,F,I,N) [1 : 58] Person 1: Do you want to do just like one grab at a time? Or do you know how you want to divvy it up? (-,-,I,N) [2 : 13] Person 2: Um, I’m just thinking. (R,F,-,-) [3 : 38] Person 1: Do you want it? I’ll take it. Um, do you want to do any trading? (R,-,I,-) [4 : 15] Person 2: Um, how much is a banana for you? (-,-,I,N) [4 : 15] Person 1: Fo</context>
</contexts>
<marker>Sperber, Wilson, 1986</marker>
<rawString>Dan Sperber and Deirdre Wilson. 1986. Relevence: Communication and Cognition. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Traum</author>
<author>James F Allen</author>
</authors>
<title>Discourse obligations in dialogue processing.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="10355" citStr="Traum and Allen, 1994" startWordPosition="1686" endWordPosition="1689">such as initiative vs response, strength of initiative, adequacy of response, scope and focality of response (Linell et al., 1988). They end up with an ordered set of six possible strengths of initiative. Each of these schemes is somewhat complicated by the fact that turns can consist of multiple basic elements. Analyzing previous work, we can see that initiative breaks down into two distinct concepts. First there is providing unsolicited, or optional, or extra material, that is not a required response to a previous initiative. Second, there is the sense of putting a new discourse obligation (Traum and Allen, 1994) on a dialogue partner to respond. These two concepts often come together, such as for new questions or proposals that require some sort of response: they are both unsolicited and impose an obligation, which is why (Whittaker and Stenton, 1988) indicate that control should belong to the speaker of these utterances. However, it is also possible to have each one without the other. Statements can include new unsolicited material, without imposing an obligation to respond (other than the weak obligation to ground understanding of any contribution). Likewise, clarification questions impose new obli</context>
</contexts>
<marker>Traum, Allen, 1994</marker>
<rawString>David R. Traum and James F. Allen. 1994. Discourse obligations in dialogue processing. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
<author>Stacy C Marsella</author>
<author>Jonathan Gratch</author>
<author>Jina Lee</author>
<author>Arno Hartholt</author>
</authors>
<title>Multi-party, multiissue, multi-strategy negotiation for multi-modal virtual agents.</title>
<date>2008</date>
<booktitle>In Intelligent Virtual Agents,</booktitle>
<pages>117--130</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2099" citStr="Traum et al., 2008" startWordPosition="326" endWordPosition="329"> fields due to the significant implications and potential applications for business and profit making. Being a good negotiator is not a skill that all humans naturally have; therefore, this line of research can potentially be used to help humans become better negotiators. Computer agents will also benefit from the ability to understand human negotiators. There has been a fair amount of previous work in understanding negotiation dialogs, e.g., (Walton and McKersie, 1991; Baker, 1994); as well as agents who can engage in negotiation, e.g. (Jameson et al., 1994; Sidner, 1994; Kraus et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain, or gain a competitive advantage over the other. Negotiations between two people are usually mixed-initiative (Walker and Whittaker, 1990), with c</context>
</contexts>
<marker>Traum, Marsella, Gratch, Lee, Hartholt, 2008</marker>
<rawString>David Traum, Stacy C Marsella, Jonathan Gratch, Jina Lee, and Arno Hartholt. 2008. Multi-party, multiissue, multi-strategy negotiation for multi-modal virtual agents. In Intelligent Virtual Agents, pages 117–130. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn Walker</author>
<author>Steve Whittaker</author>
</authors>
<title>Mixed initiative in dialogue: An investigation into discourse segmentation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th annual meeting on Association for Computational Linguistics,</booktitle>
<pages>70--78</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2691" citStr="Walker and Whittaker, 1990" startWordPosition="420" endWordPosition="423">s et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain, or gain a competitive advantage over the other. Negotiations between two people are usually mixed-initiative (Walker and Whittaker, 1990), with control of conversation being transferred from one person to another. To our knowledge, no previous studies have investigated the relationship between verbal initiative taking patterns and the goal or the outcome of the negotiation. We suspected that both of the mentioned characteristics of the negotiation (goal and outcome) might be correlated with different initiative-taking patterns. We used an existing negotiation dataset in order to study the mixed initiative patterns between the two parties in the negotiation. We describe this data set in Section 2, as well as previous work that a</context>
</contexts>
<marker>Walker, Whittaker, 1990</marker>
<rawString>Marilyn Walker and Steve Whittaker. 1990. Mixed initiative in dialogue: An investigation into discourse segmentation. In Proceedings of the 28th annual meeting on Association for Computational Linguistics, pages 70–78. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard E Walton</author>
<author>Robert B McKersie</author>
</authors>
<title>A behavioral theory of labor negotiations: An analysis of a social interaction system.</title>
<date>1991</date>
<publisher>Cornell University Press.</publisher>
<contexts>
<context position="1953" citStr="Walton and McKersie, 1991" startWordPosition="300" endWordPosition="303">omplex trade-off between issues. Investigating these rich and complex interactions in a scientific manner has been important to researchers in different fields due to the significant implications and potential applications for business and profit making. Being a good negotiator is not a skill that all humans naturally have; therefore, this line of research can potentially be used to help humans become better negotiators. Computer agents will also benefit from the ability to understand human negotiators. There has been a fair amount of previous work in understanding negotiation dialogs, e.g., (Walton and McKersie, 1991; Baker, 1994); as well as agents who can engage in negotiation, e.g. (Jameson et al., 1994; Sidner, 1994; Kraus et al., 2008; Traum et al., 2008). In this paper we investigate the role that dialogue initiative plays in negotiation. Negotiations can be characterized by both the goals that each negotiator is trying to achieve, as well as the outcomes. Even for negotiations that attempt to partition a set of goods, the participants may have differences in their valuation of items, and the negotiations can be very different if people are trying to maximize the total gain or their individual gain,</context>
</contexts>
<marker>Walton, McKersie, 1991</marker>
<rawString>Richard E Walton and Robert B McKersie. 1991. A behavioral theory of labor negotiations: An analysis of a social interaction system. Cornell University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Phil Stenton</author>
</authors>
<title>Cues and control in expert-client dialogues.</title>
<date>1988</date>
<booktitle>In Proceedings ACL-88,</booktitle>
<pages>123--130</pages>
<contexts>
<context position="9377" citStr="Whittaker and Stenton, 1988" startWordPosition="1529" endWordPosition="1532">words, turns, words per turn and words related to the negotiation objects We used only features that were easily and automatically derivable, excluding features from (Nouri et al., 2013) such as the number of offers and the number of rejections or acceptances. 3 Initiative Labeling A common way of structuring dialogue is with Initiative-Response pairs, or IR units (Dahlb¨ack and J¨onsson, 1998), which are also similar to adjacency pairs (Levinson, 1983), or simple exchange units (Sinclair and Coulthard, 1975). Several researchers have also proposed multiple levels of initiative. For example, (Whittaker and Stenton, 1988) had levels based on the type of utterance (commands, questions, assertions, and prompts). (Chu-Carroll and Brown, 1997) posit two levels of initiative: discourse initiative, attained by providing reasons for responses, and critiques of proposed plans, and task initiative, obtained by suggesting new tasks or plans. Linell et al. examine several factors, such as initiative vs response, strength of initiative, adequacy of response, scope and focality of response (Linell et al., 1988). They end up with an ordered set of six possible strengths of initiative. Each of these schemes is somewhat compl</context>
<context position="11149" citStr="Whittaker and Stenton, 1988" startWordPosition="1811" endWordPosition="1815">solicited and impose an obligation, which is why (Whittaker and Stenton, 1988) indicate that control should belong to the speaker of these utterances. However, it is also possible to have each one without the other. Statements can include new unsolicited material, without imposing an obligation to respond (other than the weak obligation to ground understanding of any contribution). Likewise, clarification questions impose new obligations on the other, but often do not contribute new material or are not optional, in that the responder can not reply appropriately without the clarification. For (Whittaker and Stenton, 1988), the issue of whether a question or assertion was a “response” would determine whether control went to the speaker or remained with a previous speaker. On the other hand, (Narayanan et al., 2000) call a response that includes unsolicited material “mixedinitiative” rather than “system initiative” for user responses that contain only prompted material. Likewise, response can also be broken down into two related concepts. One concerns fulfilling obligations imposed by prior initiatives. To not do so could be considered rude and a violation of conversational norms in some cases. This is only rele</context>
</contexts>
<marker>Whittaker, Stenton, 1988</marker>
<rawString>Steve Whittaker and Phil Stenton. 1988. Cues and control in expert-client dialogues. In Proceedings ACL-88, pages 123–130.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>