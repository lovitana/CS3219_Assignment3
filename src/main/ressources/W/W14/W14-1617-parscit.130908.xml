<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000508">
<title confidence="0.996718">
Hallucinating Phrase Translations for Low Resource MT
</title>
<author confidence="0.98988">
Ann Irvine Chris Callison-Burch
</author>
<affiliation confidence="0.996498">
Center for Language and Speech Processing Computer and Information Science Dept.
Johns Hopkins University University of Pennsylvania
</affiliation>
<sectionHeader confidence="0.989309" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999748947368421">
We demonstrate that “hallucinating”
phrasal translations can significantly im-
prove the quality of machine translation in
low resource conditions. Our hallucinated
phrase tables consist of entries composed
from multiple unigram translations drawn
from the baseline phrase table and from
translations that are induced from mono-
lingual corpora. The hallucinated phrase
table is very noisy. Its translations are low
precision but high recall. We counter this
by introducing 30 new feature functions
(including a variety of monolingually-
estimated features) and by aggressively
pruning the phrase table. Our analysis
evaluates the intrinsic quality of our
hallucinated phrase pairs as well as their
impact in end-to-end Spanish-English and
Hindi-English MT.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957421052632">
In this work, we augment the translation model for
a low-resource phrase-based SMT system by auto-
matically expanding its phrase table. We “halluci-
nate” new phrase table entries by composing the
unigram translations from the baseline system’s
phrase table and translations learned from compa-
rable monolingual corpora. The composition pro-
cess yields a very large number of new phrase pair
translations, which are high recall but low preci-
sion. We filter the phrase table using a new set of
feature functions estimated from monolingual cor-
pora. We evaluate the hallucinated phrase pairs in-
trinsically as well as in end-to-end machine trans-
lation. The augmented phrase table provides more
coverage than the original phrase table, while be-
ing high quality enough to improve translation per-
formance.
We propose a four-part approach to hallucinat-
ing and using new phrase pair translations:
</bodyText>
<listItem confidence="0.971806153846154">
1. Learn potential translations for out-of-
vocabulary (OOV) words from comparable
monolingual corpora
2. “Hallucinate” a large, noisy set of phrase
translations by composing unigram transla-
tions from the baseline model and from the
monolingually-induced bilingual dictionary
3. Use comparable monolingual corpora to
score, rank, and prune the huge number of
hallucinated translations
4. Augment the baseline phrase table with hal-
lucinated translations and new feature func-
tions estimated from monolingual corpora
</listItem>
<bodyText confidence="0.997333666666667">
We define an algorithm for generating loosely
compositional phrase pairs, which we use to hal-
lucinate new translations. In oracle experiments,
we show that such loosely compositional phrase
pairs contribute substantially to the performance
of end-to-end SMT, beyond that of component un-
igram translations. In our non-oracle experiments,
we show that adding a judiciously pruned set of
automatically hallucinated phrase pairs to an end-
to-end baseline SMT model results in a signifi-
cant improvement in translation quality for both
Spanish-English and Hindi-English.
</bodyText>
<sectionHeader confidence="0.996867" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.9969135">
Translation models learned over small amounts
of parallel data suffer from the problem of low
coverage. That is, they do not include trans-
lations for many words and phrases. Unknown
</bodyText>
<page confidence="0.964023">
160
</page>
<note confidence="0.6881235">
Proceedings of the Eighteenth Conference on Computational Language Learning, pages 160–170,
Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999920612903226">
words, or out-of-vocabulary (OOV) words, have
been the focus of previous work on integrating
bilingual lexicon induction and machine transla-
tion (Daum´e and Jagarlamudi, 2011; Irvine and
Callison-Burch, 2013a; Razmara et al., 2013).
Bilingual lexicon induction is the task of learning
translations from monolingual texts, and typical
approaches compare projected distributional sig-
natures of words in the source language with dis-
tributional signatures representing target language
words (Rapp, 1995; Schafer and Yarowsky, 2002;
Koehn and Knight, 2002; Haghighi et al., 2008).
If the source and target language each contain, for
example, 100, 000 words, the number of pairwise
comparisons is about 10 billion, which is signifi-
cant but computationally feasible.
In contrast to unigrams, the difficulty in induc-
ing a comprehensive set of phrase translations is
that the number of both source and target phrases
is immense. For example, there are about 83 mil-
lion unique phrases up to length three in the En-
glish Wikipedia. Pairwise comparisons of two sets
of 100 million phrases corresponds to 1 x 1016.
Thus, even if we limit the task to short phrases, the
number of pairwise phrase comparisons necessary
to do an exhaustive search is infeasible. However,
multi-word translation units have been shown to
improve the quality of SMT dramatically (Koehn
et al., 2003). Phrase translations allow transla-
tion models to memorize local context-dependent
translations and reordering patterns.
</bodyText>
<sectionHeader confidence="0.999151" genericHeader="method">
3 Approach
</sectionHeader>
<bodyText confidence="0.999966774193548">
Rather than compare all source language phrases
with all target language phrases, our approach effi-
ciently proposes a smaller set of hypothesis phrase
translations for each source language phrase. Our
method builds upon the notion that many phrase
translations can be composed from the translations
of its component words and subphrases. For ex-
ample Spanish la bruja verde translates into En-
glish as the green witch. Each Spanish word cor-
responds to exactly one English word. The phrase
pair could be memorized and translated as a unit,
or the English translation could be composed from
the translations of each Spanish unigram.
Zens et al. (2012) found that only 2% of phrase
pairs in German-English, Czech-English, Spanish-
English, and French-English phrase tables consist
of multi-word source and target phrases and are
non-compositional. That is, for these languages,
the vast majority of phrase pairs in a given phrase
table could be composed from smaller units. Our
approach takes advantage of the fact that many
phrases can be translated compositionally.
We describe our approach in three parts. In Sec-
tion 3.1, we begin by inducing translations for un-
known unigrams. Then, in 3.2, we introduce our
algorithm for composing phrase translations. In
order to achieve a high recall in our set of hypoth-
esis translations, we define compositionality more
loosely than is typical. Finally, in 3.3, we use com-
parable corpora to prune the large set of hypothesis
translations for each source phrase.
</bodyText>
<subsectionHeader confidence="0.998817">
3.1 Unigram Translations
</subsectionHeader>
<bodyText confidence="0.999960458333333">
In any low resource setting, many word transla-
tions are likely to be unknown. Therefore, before
moving to phrases, we use a bilingual lexicon in-
duction technique to identify translations for un-
igrams. Specifically, because we assume a set-
ting where we have some small amount of paral-
lel data, we follow our prior work on supervised
bilingual lexicon induction (Irvine and Callison-
Burch, 2013b). We take examples of good transla-
tion pairs from our word aligned training data (de-
scribed in Section 4) and use random word pairs
as negative supervision. We use this supervision
to learn a log-linear classifier that predicts whether
a given word pair is a translation or not. We pair
and score all source language unigrams in our tun-
ing and test sets with target language unigrams that
appear in our comparable corpora. Then, for each
source language unigram, we use the log-linear
model scores to rerank candidate target language
unigram translations. As in our prior work, we
include the following word pair features in our
log-linear classifier: contextual similarity, tempo-
ral similarity, topic similarity, frequency similar-
ity, and orthographic similarity.
</bodyText>
<subsectionHeader confidence="0.999657">
3.2 Loosely Compositional Translations
</subsectionHeader>
<bodyText confidence="0.999740727272728">
We propose a novel technique for loosely compos-
ing phrasal translations from an existing dictio-
nary of unigram translations and stop word lists.
Given a source language phrase, our approach
considers all combinations and all permutations
of all unigram translations for each source phrase
content word. We ignore stop words in the in-
put source phrase and allow any number of stop
words anywhere in the output target phrase. In
order to make the enumeration efficient, we pre-
compute an inverted index that maps sorted target
</bodyText>
<page confidence="0.992104">
161
</page>
<figure confidence="0.950668">
Bilingual Dictionary:
Input Phrase:
</figure>
<figureCaption confidence="0.9877257">
Figure 1: Example of loosely composed translations for the
Spanish input in A, la casa linda. In B, we remove the stop
word la. Then, in C, we enumerate the cartesian product of all
unigram translations in the bilingual dictionary and sort the
words within each alphabetically. Finally, we look up each
list of words in C in the inverted index, and corresponding
target phrases are enumerated in D. The inverted index con-
tains all phrasal combinations and permutations of the word
lists in C which also appear monolingually with some fre-
quency and with, optionally, any number of stop words.
</figureCaption>
<bodyText confidence="0.99613075">
language content words to sets of phrases contain-
ing those words in any order along with, option-
ally, any number of stop words. Our algorithm for
composing candidate phrase translations is given
in Algorithm 1, and an example translation is com-
posed in Figure 1. Although in our experiments
we compose translations for source phrases up to
length three, the algorithm is generally applicable
to any set of source phrases of interest.
Algorithm 1 yields a set of target language
translations for any source language phrase for
which all content unigrams have at least one
known translation. For most phrases, the result-
ing set of hypothesis translations is very large and
the majority are incorrect. In an initial pruning
step, we add a monolingual frequency cutoff to the
composition algorithm and only add target phrases
that have a frequency of at least θFreQT to the in-
verted index. Doing so eliminates improbable tar-
get language constructions early on, for example
house handsome her or cute a house.
Input: A set of source language phrases of interest, S,
each consisting of a sequence of words
sm1 , sm2 , ...smi ; A list of all target language
</bodyText>
<construct confidence="0.585596833333333">
phrases, targetPhrases; Source and target stop
word lists, Stopsrc and Stoptrg; Set of unigram
translations, tsm, for all source language words
sm R Stopsrc;imonolingual target language
phrase frequencies, FreqT; Monolingual
frequency threshold BFreqT
</construct>
<equation confidence="0.881374666666667">
Output: @ Sm P S, a set of candidate phrase
translations, T1m, T2m , ...Tkm
Construct TargetInvertedIndex:
for T P targetPhrases do
if FreqT pTq ě BFreqT then
T&apos; Ðwords tj P T if tj R Stoptrg
Tsorted Ð sortedpT&apos;q
append T to TargetInvertedIndex[T&apos;sorted]
end
end
for Sm P S do
S&apos; Ðwords smi P Sm if sTR Stopsrc
CombsS1 Ð ts11 Ś ts12 Ś ... Ś ts1k
T Ð r s
for cs1 P CombsS1 do
cs1sorted Ð sortedpcs1q
T Ð T`TargetInvertedIndexpcs1sortedq
end
Tm “ T
end
Algorithm 1: Computing a set of candidate composi-
</equation>
<bodyText confidence="0.7025337">
tional phrase translations for each source phrase in the set
S. An inverted index of target phrases is constructed that
maps sorted lists of content words to phrases that contain
those content words, as well as optionally any stop words,
and have a frequency of at least BFreqT . Then, for a given
source phrase Sm, stop words are removed from the phrase.
Next, the cartesian product of all unigram translations is
computed. Each element in the product is sorted and any
corresponding phrases in the inverted index are added to the
output.
</bodyText>
<subsectionHeader confidence="0.9983">
3.3 Pruning Phrase Pairs Using Scores
Derived from Comparable Corpora
</subsectionHeader>
<bodyText confidence="0.999585764705882">
We further prune the large, noisy set of hypothe-
sized phrase translations before augmenting a seed
translation model. To do so, we use a supervised
setup very similar to that used for inducing uni-
gram translations; we estimate a variety of sig-
nals that indicate translation equivalence, includ-
ing temporal, topical, contextual, and string simi-
larity. As we showed in Klementiev et al. (2012),
such signals are effective for identifying phrase
translations as well as unigram translations. We
add ngram length, alignment, and unigram trans-
lation features to the set, listed in Appendix A.
We learn a log-linear model for combining the
features into a single score for predicting the qual-
ity of a given phrase pair. We extract training data
from the seed translation model. We rank hypoth-
esis translations for each source phrase using clas-
</bodyText>
<figure confidence="0.995098">
casa house
linda pretty
linda cute
linda handsome
A
B
casa linda
Cartesian product
of unigram translations
cute, house
C handsome, house
house, pretty
pretty house
the pretty house
D a pretty house
cute house
house and handsome
la casa linda
stop words removed
Inverted Index lookups
</figure>
<page confidence="0.986164">
162
</page>
<bodyText confidence="0.999978166666667">
sification scores and keep the top-k. We found that
using a score threshold sometimes improves pre-
cision. However, as experiments below show, the
recall of the set of phrase pairs is more important,
and we did not observe improvements in transla-
tion quality when we used a score threshold.
</bodyText>
<sectionHeader confidence="0.997371" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999989526315789">
In all of our experiments, we assume that we have
access to only a small parallel corpus. For our
Spanish experiments, we randomly sample 2, 000
sentence pairs (about 57, 000 Spanish words) from
the Spanish-English Europarl v5 parallel corpus
(Koehn, 2005). For Hindi, we use the parallel cor-
pora released by Post et al. (2012). Again, we
randomly sample 2, 000 sentence pairs from the
training corpus (about 39, 000 Hindi words). We
expect that this amount of parallel text could be
compiled for a single text domain and any pair of
modern languages. Additionally, we use approxi-
mately 2, 500 and 1, 000 single-reference parallel
sentences each for tuning and testing our Span-
ish and Hindi models, respectively. Spanish tun-
ing and test sets are newswire articles taken from
the 2010 WMT shared task (Callison-Burch et al.,
2010).1 We use the Hindi development and testing
splits released by Post et al. (2012).
</bodyText>
<subsectionHeader confidence="0.997427">
4.1 Unigram Translations
</subsectionHeader>
<bodyText confidence="0.977302517241379">
Of the 16, 269 unique unigrams in the source side
of our Spanish MT tuning and test sets, 73% are
OOV with respect to our training corpus. 21% of
unigram tokens are OOV. For Hindi, 61% of the
8,137 unique unigrams in the tuning and test sets
are OOV with respect to our training corpus, and
18% of unigram tokens are OOV. However, be-
cause automatic word alignments estimated over
the small parallel training corpora are noisy, we
use bilingual lexicon induction to induce transla-
tions for all unigrams. We use the Wikipedia and
online news web crawls datasets that we released
in Irvine and Callison-Burch (2013b) to estimate
similarity scores. Together, the two datasets con-
tain about 900 million words of Spanish data and
about 50 million words of Hindi data. For both
languages, we limit the set of hypothesis target un-
igram translations to those that appear at least 10
times in our comparable corpora.
We use 3, 000 high probability word translation
1news-test2008 plus news-syscomb2009 for tuning and
newstest2009 for testing.
pairs extracted from each parallel corpus as posi-
tive supervision and 9, 000 random word pairs as
negative supervision. We use Vowpal Wabbit2 for
learning. The top-5 induced translations for each
source language word are used as both a baseline
set of new translations (Section 6.3) and for com-
posing phrase translations.
</bodyText>
<subsectionHeader confidence="0.991798">
4.2 Composing and Pruning Phrase
Translations
</subsectionHeader>
<bodyText confidence="0.953354463414634">
There are about 183 and 66 thousand unique bi-
grams and trigrams in the Spanish and Hindi tun-
ing and test sets, respectively. However, many
of these phrases do not demand new hypothesis
translations. We do not translate those which con-
tain numbers or punctuation. Additionally, for
Spanish, we exclude names, which are typically
translated identically between Spanish and En-
glish.3 We exclude phrases which are sequences of
stop words only. Additionally, we exclude phrases
that appear more than 100 times in the small train-
ing corpus because our seed phrase table likely al-
ready contains high quality translations for them.
Finally, we exclude phrases that appear fewer than
20 times in our comparable corpora as our fea-
tures are unreliable when estimated over so few
tokens. We hypothesize translations for the ap-
proximately 15 and 6 thousand Spanish and Hindi
phrases, respectively, which meet these criteria.
Our approach for inducing translations straightfor-
wardly generalizes to any set of source phrases.
In defining loosely compositional phrase trans-
lations, we use both the induced unigram dictio-
nary (Section 3.1) and the dictionary extracted
from the word aligned parallel corpus. We ex-
pand these dictionaries further by mapping uni-
grams to their five-character word prefixes. We
use monolingual corpora of Wikipedia articles4 to
construct stop word lists, containing the most fre-
quent 300 words in each language, and indexes of
monolingual phrase frequencies. There are about
83 million unique phrases up to length three in
the English Wikipedia. However, we ignore tar-
get phrases that appear fewer than three times, re-
ducing this set to 10 million English phrases. On
2http://hunch.net/˜vw/, version 6.1.4. with
standard learning parameters
3Our names list comes from page titles of Spanish
Wikipedia pages about people. We iterate through years, be-
ginning with 1AD, and extract names from Wikipedia ‘born
in’ category pages, e.g. ‘2013 births,’ or ‘Nacidos en 2013.’
</bodyText>
<footnote confidence="0.782248">
4All inter-lingually linked source language and English
articles.
</footnote>
<page confidence="0.997753">
163
</page>
<bodyText confidence="0.99998447826087">
average, our Spanish model yields 7,986 English
translations for each Spanish bigram, and 9,231
for each trigram, or less than 0.1% of all possi-
ble candidate English phrases. Our Hindi model
yields even fewer candidate English phrases, 826
for each bigram and 1,113 for each trigram, on
average.
We use the same comparable corpora used for
bilingual lexicon induction to estimate features
over hypothesis phrase translations. The full fea-
ture set is listed in Appendix A. We extract su-
pervision from the seed translation models by first
identifying phrase pairs with multi-word source
strings, that appear at least three times in the train-
ing corpus, and that are composeable using base-
line model unigram translations and induced dic-
tionaries. Then, for each language pair, we use
the 3, 000 that have the highest p(f|e) scores as
positive supervision. We randomly sample 9, 000
compositional phrase pairs from those not in each
phrase table as negative supervision. Again, we
use Vowpal Wabbit for learning a log linear model
to score any phrase pair.
</bodyText>
<subsectionHeader confidence="0.994268">
4.3 Machine Translation
</subsectionHeader>
<bodyText confidence="0.999978409090909">
We use GIZA++ to word align each training cor-
pus. We use the Moses SMT framework (Koehn et
al., 2007) and the standard phrase-based MT fea-
ture set, including phrase and lexical translation
probabilities and a lexicalized reordering model.
When we augment our models with new transla-
tions, we use the average reordering scores over
all bilingually estimated phrase pairs. We tune
all models using batch MIRA (Cherry and Fos-
ter, 2012). We average results over three tuning
runs and use approximate randomization to mea-
sure statistical significance (Clark et al., 2011).
For Spanish, we use a 5-gram language model
trained on the English side of the complete Eu-
roparl corpus and for Hindi a 5-gram language
model trained on the English side of the com-
plete training corpus released by Post et al. (2012).
We train our language models using SRILM with
Kneser-Ney smoothing. Our baseline models use
a phrase limit of three, and we augment them with
translations of phrases up to length three in our ex-
periments.
</bodyText>
<sectionHeader confidence="0.998104" genericHeader="method">
5 Oracle Experiment
</sectionHeader>
<bodyText confidence="0.99976612244898">
Before moving to the results of our proposed
approach for composing phrase translations, we
present an oracle experiment to answer these re-
search questions: Would a low resource transla-
tion model benefit from composing its unigram
translations into phrases? Would this be fur-
ther improved by adding unigram translations that
are learned from monolingual texts? We an-
swer these questions by starting with our low-
resource Spanish-English and Hindi-English base-
lines and augmenting each with (1) phrasal trans-
lations composed from baseline model unigram
translations, and (2) phrasal translations composed
of a mix of baseline model unigram translations
and the monolingually-induced unigrams.
Figure 2 illustrates how our hallucinated phrase-
table entries can result in improved translation
quality for Spanish to English translation. Since
the baseline model is trained from such a small
amount of data, it typically translates individual
words instead of phrases. In our augmented sys-
tem, we compose a translation of was no one from
habia nadie, since habia translates as was in the
baseline model, nadie translates as one, and no is
a stop word. We are able to monolingually-induce
translations for the OOVs centros and electorales
before composing the phrase translation polling
stations for centros electorales.
In our oracle experiments, composed transla-
tions are only added to the phrase table if they
are contained in the reference. This eliminates the
huge number of noisy translations that our com-
positional algorithm generates. We augment base-
line models with translations for the same sets of
source language phrases described in Section 4.
We use GIZA++ to word align our tuning and
test sets5 and use a standard phrase pair extraction
heuristic6 to identify oracle phrase translations.
We add oracle translations to each baseline model
without bilingually estimated translation scores7
because such scores are not available for our auto-
matically induced translations. Instead, we score
the oracle phrase pairs using the 30 new phrase ta-
ble features described in Section 3.3.
Table 1 shows the results of our oracle experi-
ments. Augmenting the baselines with the subset
of oracle translations which are composed given
the unigram translations in the baseline models
themselves (i.e. in the small training sets) yields
</bodyText>
<footnote confidence="0.999353">
5For both languages, we learn an alignment over our tun-
ing and test sets and complete parallel training sets.
6grow-diag-final
7We use an indicator feature for distinguishing new com-
posed translations from bilingually extracted phrase pairs.
</footnote>
<page confidence="0.992997">
164
</page>
<figure confidence="0.978903533333333">
Input:
Hallucination
Oracle:
Baseline:
not having dependent on the centros electorales .
no
no was no one in the polling stations .
hab’a
nadie
en
los
centros
electorales .
original composeable original composeable original
from original from induced
</figure>
<figureCaption confidence="0.9711054">
Figure 2: Example output from motivating experiment: a comparison of the baseline and full oracle translations of Spanish
no habia nadie en los centros electorales, which translates correctly as there was nobody at the voting offices. The full oracle
is augmented with translations composed from the seed model as well as induced unigram translations. The phrase was no one
is composeable from habia nadie given the seed model. In contrast, the phrase polling stations is composeable from centros
electorales using induced translations. For each translation, the phrase segmentations used by the decoder are highlighted.
</figureCaption>
<table confidence="0.999892133333333">
Experiment Baseline BLEU
Features Monolingually
Estimated Feats.
Spanish
Low Resource Baseline 13.47 13.35
+ Composeable Oracle 14.90 15.18
from Initial Model
+ Composeable Oracle 15.47 15.94
w/ Induced Unigram Trans.
Hindi
Low Resource Baseline 8.49 8.26
+ Composeable Oracle 9.12 9.54
from Initial Model
+ Composeable Oracle 10.09 10.19
w/ Induced Unigram Trans.
</table>
<tableCaption confidence="0.939706">
Table 1: Motivating Experiment: BLEU results using the
baseline SMT model and composeable oracle translations
with and without induced unigram translations.
</tableCaption>
<bodyText confidence="0.999860611111111">
a BLEU score improvement of about 1.4 points
for Spanish and about 0.6 for Hindi. This find-
ing itself is noteworthy, and we investigated the
reason for it. A representative example of a com-
positional oracle translation that was added to the
Spanish model is para evitarlos, which translates
as to prevent them. In the training corpus, para
translates far more frequently as for than to. Thus,
it is useful for the translation model to know that,
in the context of evitarlos, para should translate
as to and not for. Additionally, evitarlos was ob-
served only translating as the unigram prevent.
The small model fails to align the adjoined clitic
los with its translation them. However, our loose
definition of compositionality allows the English
stop word them to appear anywhere in the target
translation.
In the first result, composeable translations do
not include those that contain new, induced word
translations. Using the baseline model and in-
duced unigram translations to compose phrase
translations results in a 2 and 1.6 BLEU point gain
for Spanish and Hindi, respectively.
The second column of Table 1 shows the results
of augmenting the baseline models with the same
oracle phrase pairs as well as the new features esti-
mated over all phrase pairs. Although the features
do not improve the performance of the baseline
models, this diverse set of scores improves perfor-
mance dramatically when new, oracle phrase pairs
are added. Adding all oracle translations and the
new feature set results in a total gain of about 2.6
BLEU points for Spanish and about 1.9 for Hindi.
These gains are the maximum that we could hope
to achieve by augmenting models with our hallu-
cinated translations and new feature set.
</bodyText>
<sectionHeader confidence="0.995391" genericHeader="method">
6 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.995152">
6.1 Unigram Translations
</subsectionHeader>
<bodyText confidence="0.999988666666667">
Table 2 shows examples of top ranked transla-
tions for several Spanish words. Although per-
formance is generally quite good, we do observe
some instances of false cognates, for example the
top ranked translation for aburridos, which trans-
lates correctly as bored, is burritos. Using au-
tomatic word alignments as a reference, we find
that 44% of Spanish tuning set unigrams have a
correct translation in their top-10 ranked lists and
62% in the top-100. For Hindi, 31% of tuning set
unigrams have a correct translation in their top-10
ranked lists and 43% in the top-100.
</bodyText>
<subsectionHeader confidence="0.998772">
6.2 Hallucinated Phrase Pairs
</subsectionHeader>
<bodyText confidence="0.9998542">
Before moving to end-to-end SMT experiments,
we evaluate the goodness of the hallucinated and
pruned phrase pairs themselves. In order to do so,
we use the same set of oracle phrase translations
described in Section 5.
Table 3 shows the top three English transla-
tions for several Spanish phrases along with their
model scores. Common, loose translations of
some phrases are scored higher than less common
but literal translations. For example, very obvi-
</bodyText>
<page confidence="0.981569">
165
</page>
<bodyText confidence="0.8269725">
Spanish abdominal abejorro abril aburridos accionista aceite actriz
Top 5 abdominal bumblebees april burritos actionists adulterated actress
English abdomen bombus march boredom actionist iooc actor
Translations bowel xylocopa june agatean telmex olive award
appendicitis ilyitch july burrito shareholder milliliters american
acute bumble december poof antagonists canola singer
</bodyText>
<tableCaption confidence="0.991987">
Table 2: Top five induced translations for several source words. Correct translations are bolded. aceite translates as oil.
</tableCaption>
<table confidence="0.9997356875">
Spanish English Score
two parties 5.72
ambos partidos both parties 5.31
and parties 3.16
were supported 4.80
hab´ıa apoyado were members 4.52
had supported 4.39
finnish minister 4.76
ministro neerland`es finnish ministry 2.77
dutch minister 1.31
over a week 4.30
unas cuantas semanas a few weeks 3.72
few weeks 3.22
very obvious 1.88
muy evidentes very evident 1.87
obviously very 1.84
</table>
<tableCaption confidence="0.992045">
Table 3: Top three compositional translations for several
source phrases and their model scores. Correct translations
are bolded.
</tableCaption>
<bodyText confidence="0.99975825">
ous scores higher than very evident as a translation
of Spanish muy evidentes. Similarly, dutch minis-
ter is scored higher than netherlands minister as a
translation for ministro neerland`es.
We use model scores to rerank candidate trans-
lations for each source phrase and keep the top-
k translations. Figure 3 shows the precision and
type-based recall (the percent of source phrases
for which at least one correct translation is gen-
erated) as we vary k for each language pair. At
k = 1, precision and recall are about 27% for
Spanish and about 25% for Hindi.8 At k = 200,
recall increases to 57% for Spanish and precision
drops to 2%. For Hindi, recall increases to 40%
and precision drops to 1%.
Moving from k = 1 to k = 200, precision
drops at about the same rate for the two source lan-
guages. However, recall increases less for Hindi
than for Spanish. We attribute this to two things.
First, Hindi and English are less related than Span-
ish and English, and fewer phrases are translated
compositionally. Our oracle experiments showed
that there is less to gain in composing phrase trans-
lations for Hindi than for Spanish. Second, the
accuracy of our induced unigram translations is
lower for Hindi than it is for Spanish. Without ac-
curate unigram translations, we are unable to com-
pose high quality phrase translations.
</bodyText>
<footnote confidence="0.631931666666667">
8Since we are computing type-based recall, and at k=1,
we produce exactly one translation for each source phrase,
precision and recall are the same.
</footnote>
<figure confidence="0.982937904761905">
13.47
60
40
13.90
14.07
14.30
14.50 14.57
0 10 20 30 40 50 60 70
Recall
(a) Spanish
50
8.49
30
8.16
8.86
8.89
9.00
9.04
0 10 20 30 40 50 60 70
Recall
(b) Hindi
</figure>
<figureCaption confidence="0.996462">
Figure 3: Precision Recall curve with BLEU scores for the
top-k scored hallucinated translations. k varies from 1 to 200.
Baseline model performance is shown with a red triangle.
</figureCaption>
<bodyText confidence="0.999972">
Because we hallucinate translations for source
phrases that appear in the training data up to 100
times, our baseline models include some of the
oracle phrase translations. Not surprisingly, the
bilingually extracted phrase pairs have relatively
high precision (81% and 40% for Spanish and
Hindi, respectively) and low recall (6% and 15%
for Spanish and Hindi, respectively).
</bodyText>
<subsectionHeader confidence="0.989234">
6.3 End-to-End Translation
</subsectionHeader>
<bodyText confidence="0.999539333333333">
Table 4 shows end-to-end translation BLEU score
results (Papineni et al., 2002). Our first baseline
SMT models are trained using only 2, 000 paral-
lel sentences and no new translation model fea-
tures. Our Spanish baseline achieves a BLEU
score of 13.47 and our Hindi baseline a BLEU
score of 8.49. When we add the 30 new feature
functions estimated over comparable monolingual
corpora, performance is slightly lower, 13.35 for
</bodyText>
<figure confidence="0.996349777777778">
Precision
80
20
0
40
Precision
20
10
0
</figure>
<page confidence="0.991101">
166
</page>
<table confidence="0.9993924">
Experiment BLEU
Spanish Hindi
Baseline 13.47 8.49
+ Mono. Scores 13.35 8.26
+ Mono. Scores &amp; OOV Trans 14.01 8.31
+ Phrase Trans, k=1 13.90 8.16
+ Phrase Trans, k=2 14.07 8.86*
+ Phrase Trans, k=5 14.30* 8.89*
+ Phrase Trans, k=25 14.50* 9.00*
+ Phrase Trans, k=200 14.57* 9.04*
</table>
<tableCaption confidence="0.999344">
Table 4: Experimental results. First, the baseline models
</tableCaption>
<bodyText confidence="0.91490695">
are augmented with monolingual phrase table features and
then also with the top-5 induced translations for all OOV un-
igrams. Then, we append the top-k hallucinated phrase trans-
lations to the third baseline models. BLEU scores are aver-
aged over three tuning runs. We measure the statistical sig-
nificance of each +Phrase Trans model in comparison with
the highest performing (bolded) baseline for each language;
* indicates statistical significance with p ă 0.01.
Spanish and 8.26 for Hindi. Our third baselines
augment the second with unigram translations for
all OOV tuning and test set source words using the
bilingual lexicon induction techniques described
in Section 3.1. We append the top-5 translations
for each,9 score both the original and the new
phrase pairs with the new feature set, and retune.
With these additional unigram translations, perfor-
mance increases to 14.01 for Spanish and 8.31 for
Hindi.
We append the top-k composed translations for
the source phrases described in Section 4 to the
third baseline models. Both original and new
phrase pairs are scored using the new feature set.
BLEU score results are shown at different values
of k along the precision-recall plots for each lan-
guage pair in Figure 3 as well as in Table 4. We
would expect that higher precision and higher re-
call would benefit end-to-end SMT. As usual, a
tradeoff exists between precision and recall, how-
ever, in this case, improvements in recall outweigh
the risk of a lower precision. As k increases, pre-
cision decreases but both recall and BLEU scores
increase. For both Spanish and Hindi, BLEU score
gains start to taper off at k values over 25.
In additional experiments, we found that with-
out the new features the same sets of hallucinated
phrase pairs hurt performance slightly in compar-
ison with the baseline augmented with unigram
translations, and results don’t change as we vary
k.10 Thus, the translation models are able to ef-
fectively use the higher recall sets of new phrase
</bodyText>
<footnote confidence="0.971250666666667">
9The same set used for composing phrase translations.
10For all values of k between 1 and 100, without the new
features, BLEU scores are about 13.70 for Spanish
</footnote>
<bodyText confidence="0.996546">
pairs because we also augmented the models with
30 new feature functions, which help them distin-
guish good from bad translations.
</bodyText>
<sectionHeader confidence="0.996921" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999992652173913">
Our results showed that including a high recall
set of “hallucinated” translations in our augmented
phrase table successfully improved the quality of
our machine translations. The algorithm that we
proposed for hypothesizing translations is flexible,
and in future work we plan to modify it slightly
to output even more candidate translations. For
example, we could retrieve target phrases which
contain at least one source word translation instead
of all. Alternatively, we could identify candidates
using entirely different information, for example
the monolingual frequency of a source and target
word, instead of unigram translations. This type
of inverted index may improve recall in the set of
hypothesis phrase translations at the cost of gener-
ating a much bigger set for reranking.
Our new phrase table features were informa-
tive in distinguishing correct from incorrect phrase
translations, and they allowed us to make use of
noisy but high recall supplemental phrase pairs.
This is a critical result for research on identify-
ing phrase translations from non-parallel text. We
also believe that using fairly strong target (En-
glish) language models contributed to our models’
ability to discriminate between good and bad hal-
lucinated phrase pairs. We leave research on the
influence of the language model in our setting to
future work.
In this work, we experimented with two lan-
guage pairs, Spanish-English and Hindi-English.
While Spanish and English are very closely re-
lated, Hindi and English are less related. Our
oracle experiments showed potential for compos-
ing phrase translations for both language pairs,
and, indeed, in our experiments using hallucinated
phrase translations we saw significant translation
quality gains for both. We expect that improving
the quality of induced unigram translations will
yield even more performance gains.
The vast majority of prior work on low resource
MT has focused on Spanish-English (Haghighi
et al., 2008; Klementiev et al., 2012; Ravi and
Knight, 2011; Dou and Knight, 2012; Ravi, 2013;
Dou and Knight, 2013). Although such experi-
ments serve as important proofs of concept, we
found it important to also experiment with a more
</bodyText>
<page confidence="0.994892">
167
</page>
<bodyText confidence="0.99994025">
truly low resource language pair. The success of
our approach that we have seen for Spanish and
Hindi suggests that it is worth pursuing such di-
rections for other even less related and resourced
language pairs. In addition to language pair, text
genre and the degree of looseness or literalness of
given parallel corpora may also affect the amount
of phrase translation compositionality.
</bodyText>
<sectionHeader confidence="0.999819" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999953391304348">
Phrase-based SMT models estimated over very
large parallel corpora are expensive to store and
process. Prior work has reduced the size of SMT
phrase tables in order to improve efficiency with-
out the loss of translation quality (He et al., 2009;
Johnson et al., 2007; Zens et al., 2012). Typi-
cally, the goal of pruning is to identify and re-
move phrase pairs which are likely to be inaccu-
rate, using either the scores and counts of a given
pair itself or those relative to other phrase pairs.
Our work, in contrast, focuses on low resource set-
tings, where training data is limited and provides
incomplete and unreliable scored phrase pairs. We
begin by dramatically increasing the size of our
SMT phrase table in order to expand its coverage
and then use non-parallel data to rescore and filter
the table.
In the decipherment task, translation models
are learned from comparable corpora without any
parallel text (Ravi and Knight, 2011; Dou and
Knight, 2012; Ravi, 2013). In contrast, we be-
gin with a small amount of parallel data and take
a very different approach to learning translation
models. In our prior work (Irvine and Callison-
Burch, 2013b), we showed how effective even
small amounts of bilingual data can be for learning
translations from monolingual texts.
Garera and Yarowsky (2008) pivot through
bilingual dictionaries in several language pairs to
compose translations for compound words. Zhang
and Zong (2013) construct a set of new, additional
phrase pairs for the task of domain adaptation for
machine translation. That work uses two dictio-
naries to bootstrap a set of phrase pair transla-
tions: one probabilistic dictionary extracted from
2 million words of bitext and one manually created
new-domain dictionary of 140, 000 word transla-
tions. Our approach to the construction of new
phrase pairs is somewhat similar to Zhang and
Zong (2013), but we don’t rely on a very large
manually generated dictionary. Additionally, we
focus on the low resource language pair setting,
where a large training corpus is not available.
Deng et al. (2008) work in a standard SMT set-
ting but use a discriminative framework for ex-
tracting phrase pairs from parallel corpora. That
approach yields a phrase table with higher preci-
sion and recall than the table extracted by stan-
dard world alignment based heuristics (Och and
Ney, 2003; Koehn et al., 2003). The discrimi-
native model combines features from word align-
ments and bilingual training data as well as infor-
mation theoretic features estimated over monolin-
gual data into a single log-linear model and then
the phrase pairs are filtered using a threshold on
model scores. The phrase pairs that it extracts are
limited to those that appear in pairs of sentences in
the parallel training data. Our work takes a similar
approach to that of Deng et al. (2008), however,
unlike that work, we hallucinate phrase pairs that
did not appear in training data in order to augment
the original, bilingually extracted phrase table.
Other prior work has used comparable cor-
pora to extract parallel sentences and phrases
(Munteanu and Marcu, 2006; Smith et al., 2010).
Such efforts are orthogonal to our approach. We
use parallel corpora, when available, and hallu-
cinates phrase translations without assuming any
parallel text in our comparable corpora.
</bodyText>
<sectionHeader confidence="0.998348" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999979375">
We showed that “hallucinating” phrasal transla-
tions can significantly improve machine transla-
tion performance in low resource conditions. Our
hallucinated translations are composed from uni-
gram translations. The translations are low preci-
sion but high recall. We countered this by intro-
ducing new feature functions and pruning aggres-
sively.
</bodyText>
<sectionHeader confidence="0.991874" genericHeader="acknowledgments">
10 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9998285">
This material is based on research sponsored by
DARPA under contract HR0011-09-1-0044 and
by the Johns Hopkins University Human Lan-
guage Technology Center of Excellence. The
views and conclusions contained in this publica-
tion are those of the authors and should not be
interpreted as representing official policies or en-
dorsements of DARPA or the U.S. Government.
</bodyText>
<page confidence="0.997689">
168
</page>
<sectionHeader confidence="0.996265" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999544448598131">
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Kay Peterson, Mark Przybocki, and Omar Zaidan.
2010. Findings of the 2010 joint workshop on sta-
tistical machine translation and metrics for machine
translation. In Proceedings of the Workshop on Sta-
tistical Machine Translation (WMT).
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL).
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing
for statistical machine translation: controlling for
optimizer instability. In Proceedings of the Confer-
ence of the Association for Computational Linguis-
tics (ACL).
Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011.
Domain adaptation for machine translation by min-
ing unseen words. In Proceedings of the Confer-
ence of the Association for Computational Linguis-
tics (ACL).
Yonggang Deng, Jia Xu, and Yuqing Gao. 2008.
Phrase table training for precision and recall: What
makes a good phrase and a good phrase pair? In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL).
Qing Dou and Kevin Knight. 2012. Large scale
decipherment for out-of-domain machine transla-
tion. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP/CoNLL).
Qing Dou and Kevin Knight. 2013. Dependency-
based decipherment for resource-limited machine
translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Nikesh Garera and David Yarowsky. 2008. Translating
compounds by learning component gloss translation
models via multiple languages. In Proceedings of
the International Joint Conference on Natural Lan-
guage Processing (IJCNLP).
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexi-
cons from monolingual corpora. In Proceedings of
the Conference of the Association for Computational
Linguistics (ACL).
Zhongjun He, Yao Meng, and Hao Yu. 2009. Dis-
carding monotone composed rule for hierarchical
phrase-based statistical machine translation. In Pro-
ceedings of the 3rd International Universal Commu-
nication Symposium.
Ann Irvine and Chris Callison-Burch. 2013a. Com-
bining bilingual and comparable corpora for low
resource machine translation. In Proceedings of
the Workshop on Statistical Machine Translation
(WMT).
Ann Irvine and Chris Callison-Burch. 2013b. Su-
pervised bilingual lexicon induction with multiple
monolingual signals. In Proceedings of the Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics (NAACL).
Howard Johnson, Joel Martin, George Foster, and
Roland Kuhn. 2007. Improving translation quality
by discarding most of the phrasetable. In Proceed-
ings of the Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP/CoNLL).
Alex Klementiev, Ann Irvine, Chris Callison-Burch,
and David Yarowsky. 2012. Toward statistical ma-
chine translation without parallel corpora. In Pro-
ceedings of the Conference of the European Associ-
ation for Computational Linguistics (EACL).
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
ACL Workshop on Unsupervised Lexical Acquisi-
tion.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL).
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the Conference of the Association for
Computational Linguistics (ACL).
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of the
Machine Translation Summit.
Prasanth Kolachina, Nicola Cancedda, Marc Dymet-
man, and Sriram Venkatapathy. 2012. Prediction of
learning curves in machine translation. In Proceed-
ings of the Conference of the Association for Com-
putational Linguistics (ACL).
Dragos Munteanu and Daniel Marcu. 2006. Extracting
parallel sub-sentential fragments from non-parallel
corpora. In Proceedings of the Conference of the
Association for Computational Linguistics (ACL).
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29(1):19–51,
March.
</reference>
<page confidence="0.986005">
169
</page>
<reference confidence="0.999585551020408">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic
evaluation of machine translation. In Proceedings
of the Conference of the Association for Computa-
tional Linguistics (ACL).
Matt Post, Chris Callison-Burch, and Miles Osborne.
2012. Constructing parallel corpora for six indian
languages via crowdsourcing. In Proceedings of
the Workshop on Statistical Machine Translation
(WMT).
Reinhard Rapp. 1995. Identifying word translations
in non-parallel texts. In Proceedings of the Confer-
ence of the Association for Computational Linguis-
tics (ACL).
Sujith Ravi and Kevin Knight. 2011. Deciphering
foreign language. In Proceedings of the Confer-
ence of the Association for Computational Linguis-
tics (ACL).
Sujith Ravi. 2013. Scalable decipherment for machine
translation via hash sampling. In Proceedings of
the Conference of the Association for Computational
Linguistics (ACL).
Majid Razmara, Maryam Siahbani, Reza Haffari, and
Anoop Sarkar. 2013. Graph propagation for para-
phrasing out-of-vocabulary words in statistical ma-
chine translation. In Proceedings of the Confer-
ence of the Association for Computational Linguis-
tics (ACL).
Charles Schafer and David Yarowsky. 2002. Inducing
translation lexicons via diverse similarity measures
and bridge languages. In Proceedings of the Confer-
ence on Natural Language Learning (CoNLL).
Jason R. Smith, Chris Quirk, and Kristina Toutanova.
2010. Extracting parallel sentences from compara-
ble corpora using document level alignment. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL).
Richard Zens, Daisy Stanton, and Peng Xu. 2012. A
systematic comparison of phrase table pruning tech-
niques. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP/CoNLL).
Jiajun Zhang and Chengqing Zong. 2013. Learning
a phrase-based translation model from monolingual
data with application to domain adaptation. In Pro-
ceedings of the Conference of the Association for
Computational Linguistics (ACL).
</reference>
<sectionHeader confidence="0.950679" genericHeader="references">
Appendix A: Phrase pair filtering features
</sectionHeader>
<bodyText confidence="0.9998326">
The first ten features are similar to those described
by Irvine and Callison-Burch (2013b). Stop words
are defined as the most frequent 300 words in each
language’s Wikipedia, and content words are all
non-stop words.
</bodyText>
<listItem confidence="0.999205473684211">
• Web crawl phrasal context similarity score
• Web crawl lexical context similarity score, averaged over
aligned unigrams
• Web crawl phrasal temporal similarity score
• Web crawl lexical temporal similarity score, averaged
over aligned unigrams
• Wikipedia phrasal context similarity score
• Wikipedia lexical context similarity score, averaged over
aligned unigrams
• Wikipedia phrasal topic similarity score
• Wikipedia lexical topic similarity score, averaged over
aligned unigrams
• Normalized edit distance, averaged over aligned unigrams
• Absolute value of difference between the logs of the
source and target phrase Wikipedia monolingual frequen-
cies
• Log target phrase Wikipedia monolingual frequency
• Log source phrase Wikipedia monolingual frequency
• Indicator: source phrase is longer
• Indicator: target phrase is longer
• Indicator: source and target phrases same length
• Number of source content words higher than target
• Number of target content words higher than source
• Number of source and target content words same
• Number of source stop words higher than target
• Number of target stop words higher than source
• Number of source and target stop words same
• Percent of source words aligned to at least one target word
• Percent of target words aligned to at least one source word
• Percent of source content words aligned to at least one
target word
• Percent of target content words aligned to at least one
source word
• Percent of aligned word pairs aligned in bilingual training
data
• Percent of aligned word pairs in induced dictionary
• Percent of aligned word pairs in stemmed induced dictio-
nary
</listItem>
<page confidence="0.995209">
170
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.373233">
<title confidence="0.99968">Hallucinating Phrase Translations for Low Resource MT</title>
<author confidence="0.991581">Ann Irvine Chris Callison-Burch</author>
<affiliation confidence="0.9055095">Center for Language and Speech Processing Computer and Information Science Dept. Johns Hopkins University University of Pennsylvania</affiliation>
<abstract confidence="0.97250965">We demonstrate that “hallucinating” phrasal translations can significantly improve the quality of machine translation in low resource conditions. Our hallucinated tables consist of entries from multiple unigram translations drawn from the baseline phrase table and from translations that are induced from monolingual corpora. The hallucinated phrase table is very noisy. Its translations are low precision but high recall. We counter this by introducing 30 new feature functions (including a variety of monolinguallyestimated features) and by aggressively pruning the phrase table. Our analysis evaluates the intrinsic quality of our hallucinated phrase pairs as well as their impact in end-to-end Spanish-English and Hindi-English MT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Kay Peterson</author>
<author>Mark Przybocki</author>
<author>Omar Zaidan</author>
</authors>
<title>Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation (WMT).</booktitle>
<contexts>
<context position="13483" citStr="Callison-Burch et al., 2010" startWordPosition="2140" endWordPosition="2143">anish-English Europarl v5 parallel corpus (Koehn, 2005). For Hindi, we use the parallel corpora released by Post et al. (2012). Again, we randomly sample 2, 000 sentence pairs from the training corpus (about 39, 000 Hindi words). We expect that this amount of parallel text could be compiled for a single text domain and any pair of modern languages. Additionally, we use approximately 2, 500 and 1, 000 single-reference parallel sentences each for tuning and testing our Spanish and Hindi models, respectively. Spanish tuning and test sets are newswire articles taken from the 2010 WMT shared task (Callison-Burch et al., 2010).1 We use the Hindi development and testing splits released by Post et al. (2012). 4.1 Unigram Translations Of the 16, 269 unique unigrams in the source side of our Spanish MT tuning and test sets, 73% are OOV with respect to our training corpus. 21% of unigram tokens are OOV. For Hindi, 61% of the 8,137 unique unigrams in the tuning and test sets are OOV with respect to our training corpus, and 18% of unigram tokens are OOV. However, because automatic word alignments estimated over the small parallel training corpora are noisy, we use bilingual lexicon induction to induce translations for all</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Peterson, Przybocki, Zaidan, 2010</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Kay Peterson, Mark Przybocki, and Omar Zaidan. 2010. Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation. In Proceedings of the Workshop on Statistical Machine Translation (WMT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="18551" citStr="Cherry and Foster, 2012" startWordPosition="2956" endWordPosition="2960">itional phrase pairs from those not in each phrase table as negative supervision. Again, we use Vowpal Wabbit for learning a log linear model to score any phrase pair. 4.3 Machine Translation We use GIZA++ to word align each training corpus. We use the Moses SMT framework (Koehn et al., 2007) and the standard phrase-based MT feature set, including phrase and lexical translation probabilities and a lexicalized reordering model. When we augment our models with new translations, we use the average reordering scores over all bilingually estimated phrase pairs. We tune all models using batch MIRA (Cherry and Foster, 2012). We average results over three tuning runs and use approximate randomization to measure statistical significance (Clark et al., 2011). For Spanish, we use a 5-gram language model trained on the English side of the complete Europarl corpus and for Hindi a 5-gram language model trained on the English side of the complete training corpus released by Post et al. (2012). We train our language models using SRILM with Kneser-Ney smoothing. Our baseline models use a phrase limit of three, and we augment them with translations of phrases up to length three in our experiments. 5 Oracle Experiment Befor</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="18685" citStr="Clark et al., 2011" startWordPosition="2977" endWordPosition="2980">el to score any phrase pair. 4.3 Machine Translation We use GIZA++ to word align each training corpus. We use the Moses SMT framework (Koehn et al., 2007) and the standard phrase-based MT feature set, including phrase and lexical translation probabilities and a lexicalized reordering model. When we augment our models with new translations, we use the average reordering scores over all bilingually estimated phrase pairs. We tune all models using batch MIRA (Cherry and Foster, 2012). We average results over three tuning runs and use approximate randomization to measure statistical significance (Clark et al., 2011). For Spanish, we use a 5-gram language model trained on the English side of the complete Europarl corpus and for Hindi a 5-gram language model trained on the English side of the complete training corpus released by Post et al. (2012). We train our language models using SRILM with Kneser-Ney smoothing. Our baseline models use a phrase limit of three, and we augment them with translations of phrases up to length three in our experiments. 5 Oracle Experiment Before moving to the results of our proposed approach for composing phrase translations, we present an oracle experiment to answer these re</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: controlling for optimizer instability. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>Domain adaptation for machine translation by mining unseen words.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Daum´e, Jagarlamudi, 2011</marker>
<rawString>Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Domain adaptation for machine translation by mining unseen words. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Deng</author>
<author>Jia Xu</author>
<author>Yuqing Gao</author>
</authors>
<title>Phrase table training for precision and recall: What makes a good phrase and a good phrase pair?</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="36895" citStr="Deng et al. (2008)" startWordPosition="5915" endWordPosition="5918">et of new, additional phrase pairs for the task of domain adaptation for machine translation. That work uses two dictionaries to bootstrap a set of phrase pair translations: one probabilistic dictionary extracted from 2 million words of bitext and one manually created new-domain dictionary of 140, 000 word translations. Our approach to the construction of new phrase pairs is somewhat similar to Zhang and Zong (2013), but we don’t rely on a very large manually generated dictionary. Additionally, we focus on the low resource language pair setting, where a large training corpus is not available. Deng et al. (2008) work in a standard SMT setting but use a discriminative framework for extracting phrase pairs from parallel corpora. That approach yields a phrase table with higher precision and recall than the table extracted by standard world alignment based heuristics (Och and Ney, 2003; Koehn et al., 2003). The discriminative model combines features from word alignments and bilingual training data as well as information theoretic features estimated over monolingual data into a single log-linear model and then the phrase pairs are filtered using a threshold on model scores. The phrase pairs that it extrac</context>
</contexts>
<marker>Deng, Xu, Gao, 2008</marker>
<rawString>Yonggang Deng, Jia Xu, and Yuqing Gao. 2008. Phrase table training for precision and recall: What makes a good phrase and a good phrase pair? In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Dou</author>
<author>Kevin Knight</author>
</authors>
<title>Large scale decipherment for out-of-domain machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</booktitle>
<contexts>
<context position="34280" citStr="Dou and Knight, 2012" startWordPosition="5482" endWordPosition="5485">lish and Hindi-English. While Spanish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over </context>
<context position="35796" citStr="Dou and Knight, 2012" startWordPosition="5738" endWordPosition="5741">d remove phrase pairs which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from comparable corpora without any parallel text (Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013). In contrast, we begin with a small amount of parallel data and take a very different approach to learning translation models. In our prior work (Irvine and CallisonBurch, 2013b), we showed how effective even small amounts of bilingual data can be for learning translations from monolingual texts. Garera and Yarowsky (2008) pivot through bilingual dictionaries in several language pairs to compose translations for compound words. Zhang and Zong (2013) construct a set of new, additional phrase pairs for the task of domain adaptation for machine translation. That work uses two dictio</context>
</contexts>
<marker>Dou, Knight, 2012</marker>
<rawString>Qing Dou and Kevin Knight. 2012. Large scale decipherment for out-of-domain machine translation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Dou</author>
<author>Kevin Knight</author>
</authors>
<title>Dependencybased decipherment for resource-limited machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="34315" citStr="Dou and Knight, 2013" startWordPosition="5488" endWordPosition="5491">ish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over very large parallel corpora are exp</context>
</contexts>
<marker>Dou, Knight, 2013</marker>
<rawString>Qing Dou and Kevin Knight. 2013. Dependencybased decipherment for resource-limited machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>David Yarowsky</author>
</authors>
<title>Translating compounds by learning component gloss translation models via multiple languages.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP).</booktitle>
<contexts>
<context position="36134" citStr="Garera and Yarowsky (2008)" startWordPosition="5793" endWordPosition="5796">reasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from comparable corpora without any parallel text (Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013). In contrast, we begin with a small amount of parallel data and take a very different approach to learning translation models. In our prior work (Irvine and CallisonBurch, 2013b), we showed how effective even small amounts of bilingual data can be for learning translations from monolingual texts. Garera and Yarowsky (2008) pivot through bilingual dictionaries in several language pairs to compose translations for compound words. Zhang and Zong (2013) construct a set of new, additional phrase pairs for the task of domain adaptation for machine translation. That work uses two dictionaries to bootstrap a set of phrase pair translations: one probabilistic dictionary extracted from 2 million words of bitext and one manually created new-domain dictionary of 140, 000 word translations. Our approach to the construction of new phrase pairs is somewhat similar to Zhang and Zong (2013), but we don’t rely on a very large ma</context>
</contexts>
<marker>Garera, Yarowsky, 2008</marker>
<rawString>Nikesh Garera and David Yarowsky. 2008. Translating compounds by learning component gloss translation models via multiple languages. In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3910" citStr="Haghighi et al., 2008" startWordPosition="563" endWordPosition="566">�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set of phrase translations is that the number of both source and target phrases is immense. For example, there are about 83 million unique phrases up to length three in the English Wikipedia. Pairwise comparisons of two sets of 100 million phrases corresponds to 1 x 1016. Thus, even if we limit the task to short phrases, the number of pairwise </context>
<context position="34210" citStr="Haghighi et al., 2008" startWordPosition="5470" endWordPosition="5473">ork. In this work, we experimented with two language pairs, Spanish-English and Hindi-English. While Spanish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation co</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongjun He</author>
<author>Yao Meng</author>
<author>Hao Yu</author>
</authors>
<title>Discarding monotone composed rule for hierarchical phrase-based statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 3rd International Universal Communication Symposium.</booktitle>
<contexts>
<context position="35084" citStr="He et al., 2009" startWordPosition="5616" endWordPosition="5619">r. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over very large parallel corpora are expensive to store and process. Prior work has reduced the size of SMT phrase tables in order to improve efficiency without the loss of translation quality (He et al., 2009; Johnson et al., 2007; Zens et al., 2012). Typically, the goal of pruning is to identify and remove phrase pairs which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation m</context>
</contexts>
<marker>He, Meng, Yu, 2009</marker>
<rawString>Zhongjun He, Yao Meng, and Hao Yu. 2009. Discarding monotone composed rule for hierarchical phrase-based statistical machine translation. In Proceedings of the 3rd International Universal Communication Symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Combining bilingual and comparable corpora for low resource machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation (WMT).</booktitle>
<contexts>
<context position="3543" citStr="Irvine and Callison-Burch, 2013" startWordPosition="511" endWordPosition="514">r both Spanish-English and Hindi-English. 2 Motivation Translation models learned over small amounts of parallel data suffer from the problem of low coverage. That is, they do not include translations for many words and phrases. Unknown 160 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 160–170, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in indu</context>
<context position="14202" citStr="Irvine and Callison-Burch (2013" startWordPosition="2264" endWordPosition="2267">nigram Translations Of the 16, 269 unique unigrams in the source side of our Spanish MT tuning and test sets, 73% are OOV with respect to our training corpus. 21% of unigram tokens are OOV. For Hindi, 61% of the 8,137 unique unigrams in the tuning and test sets are OOV with respect to our training corpus, and 18% of unigram tokens are OOV. However, because automatic word alignments estimated over the small parallel training corpora are noisy, we use bilingual lexicon induction to induce translations for all unigrams. We use the Wikipedia and online news web crawls datasets that we released in Irvine and Callison-Burch (2013b) to estimate similarity scores. Together, the two datasets contain about 900 million words of Spanish data and about 50 million words of Hindi data. For both languages, we limit the set of hypothesis target unigram translations to those that appear at least 10 times in our comparable corpora. We use 3, 000 high probability word translation 1news-test2008 plus news-syscomb2009 for tuning and newstest2009 for testing. pairs extracted from each parallel corpus as positive supervision and 9, 000 random word pairs as negative supervision. We use Vowpal Wabbit2 for learning. The top-5 induced tran</context>
</contexts>
<marker>Irvine, Callison-Burch, 2013</marker>
<rawString>Ann Irvine and Chris Callison-Burch. 2013a. Combining bilingual and comparable corpora for low resource machine translation. In Proceedings of the Workshop on Statistical Machine Translation (WMT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Supervised bilingual lexicon induction with multiple monolingual signals.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="3543" citStr="Irvine and Callison-Burch, 2013" startWordPosition="511" endWordPosition="514">r both Spanish-English and Hindi-English. 2 Motivation Translation models learned over small amounts of parallel data suffer from the problem of low coverage. That is, they do not include translations for many words and phrases. Unknown 160 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 160–170, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in indu</context>
<context position="14202" citStr="Irvine and Callison-Burch (2013" startWordPosition="2264" endWordPosition="2267">nigram Translations Of the 16, 269 unique unigrams in the source side of our Spanish MT tuning and test sets, 73% are OOV with respect to our training corpus. 21% of unigram tokens are OOV. For Hindi, 61% of the 8,137 unique unigrams in the tuning and test sets are OOV with respect to our training corpus, and 18% of unigram tokens are OOV. However, because automatic word alignments estimated over the small parallel training corpora are noisy, we use bilingual lexicon induction to induce translations for all unigrams. We use the Wikipedia and online news web crawls datasets that we released in Irvine and Callison-Burch (2013b) to estimate similarity scores. Together, the two datasets contain about 900 million words of Spanish data and about 50 million words of Hindi data. For both languages, we limit the set of hypothesis target unigram translations to those that appear at least 10 times in our comparable corpora. We use 3, 000 high probability word translation 1news-test2008 plus news-syscomb2009 for tuning and newstest2009 for testing. pairs extracted from each parallel corpus as positive supervision and 9, 000 random word pairs as negative supervision. We use Vowpal Wabbit2 for learning. The top-5 induced tran</context>
</contexts>
<marker>Irvine, Callison-Burch, 2013</marker>
<rawString>Ann Irvine and Chris Callison-Burch. 2013b. Supervised bilingual lexicon induction with multiple monolingual signals. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Improving translation quality by discarding most of the phrasetable.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</booktitle>
<contexts>
<context position="35106" citStr="Johnson et al., 2007" startWordPosition="5620" endWordPosition="5623"> our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over very large parallel corpora are expensive to store and process. Prior work has reduced the size of SMT phrase tables in order to improve efficiency without the loss of translation quality (He et al., 2009; Johnson et al., 2007; Zens et al., 2012). Typically, the goal of pruning is to identify and remove phrase pairs which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from</context>
</contexts>
<marker>Johnson, Martin, Foster, Kuhn, 2007</marker>
<rawString>Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Klementiev</author>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
<author>David Yarowsky</author>
</authors>
<title>Toward statistical machine translation without parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the European Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="11609" citStr="Klementiev et al. (2012)" startWordPosition="1827" endWordPosition="1830">roduct of all unigram translations is computed. Each element in the product is sorted and any corresponding phrases in the inverted index are added to the output. 3.3 Pruning Phrase Pairs Using Scores Derived from Comparable Corpora We further prune the large, noisy set of hypothesized phrase translations before augmenting a seed translation model. To do so, we use a supervised setup very similar to that used for inducing unigram translations; we estimate a variety of signals that indicate translation equivalence, including temporal, topical, contextual, and string similarity. As we showed in Klementiev et al. (2012), such signals are effective for identifying phrase translations as well as unigram translations. We add ngram length, alignment, and unigram translation features to the set, listed in Appendix A. We learn a log-linear model for combining the features into a single score for predicting the quality of a given phrase pair. We extract training data from the seed translation model. We rank hypothesis translations for each source phrase using clascasa house linda pretty linda cute linda handsome A B casa linda Cartesian product of unigram translations cute, house C handsome, house house, pretty pre</context>
<context position="34235" citStr="Klementiev et al., 2012" startWordPosition="5474" endWordPosition="5477">xperimented with two language pairs, Spanish-English and Hindi-English. While Spanish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related</context>
</contexts>
<marker>Klementiev, Irvine, Callison-Burch, Yarowsky, 2012</marker>
<rawString>Alex Klementiev, Ann Irvine, Chris Callison-Burch, and David Yarowsky. 2012. Toward statistical machine translation without parallel corpora. In Proceedings of the Conference of the European Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In ACL Workshop on Unsupervised Lexical Acquisition.</booktitle>
<contexts>
<context position="3886" citStr="Koehn and Knight, 2002" startWordPosition="559" endWordPosition="562"> USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set of phrase translations is that the number of both source and target phrases is immense. For example, there are about 83 million unique phrases up to length three in the English Wikipedia. Pairwise comparisons of two sets of 100 million phrases corresponds to 1 x 1016. Thus, even if we limit the task to short phrases,</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In ACL Workshop on Unsupervised Lexical Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="4698" citStr="Koehn et al., 2003" startWordPosition="694" endWordPosition="697">onally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set of phrase translations is that the number of both source and target phrases is immense. For example, there are about 83 million unique phrases up to length three in the English Wikipedia. Pairwise comparisons of two sets of 100 million phrases corresponds to 1 x 1016. Thus, even if we limit the task to short phrases, the number of pairwise phrase comparisons necessary to do an exhaustive search is infeasible. However, multi-word translation units have been shown to improve the quality of SMT dramatically (Koehn et al., 2003). Phrase translations allow translation models to memorize local context-dependent translations and reordering patterns. 3 Approach Rather than compare all source language phrases with all target language phrases, our approach efficiently proposes a smaller set of hypothesis phrase translations for each source language phrase. Our method builds upon the notion that many phrase translations can be composed from the translations of its component words and subphrases. For example Spanish la bruja verde translates into English as the green witch. Each Spanish word corresponds to exactly one Englis</context>
<context position="37191" citStr="Koehn et al., 2003" startWordPosition="5966" endWordPosition="5969">40, 000 word translations. Our approach to the construction of new phrase pairs is somewhat similar to Zhang and Zong (2013), but we don’t rely on a very large manually generated dictionary. Additionally, we focus on the low resource language pair setting, where a large training corpus is not available. Deng et al. (2008) work in a standard SMT setting but use a discriminative framework for extracting phrase pairs from parallel corpora. That approach yields a phrase table with higher precision and recall than the table extracted by standard world alignment based heuristics (Och and Ney, 2003; Koehn et al., 2003). The discriminative model combines features from word alignments and bilingual training data as well as information theoretic features estimated over monolingual data into a single log-linear model and then the phrase pairs are filtered using a threshold on model scores. The phrase pairs that it extracts are limited to those that appear in pairs of sentences in the parallel training data. Our work takes a similar approach to that of Deng et al. (2008), however, unlike that work, we hallucinate phrase pairs that did not appear in training data in order to augment the original, bilingually extr</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="18220" citStr="Koehn et al., 2007" startWordPosition="2905" endWordPosition="2908">rs with multi-word source strings, that appear at least three times in the training corpus, and that are composeable using baseline model unigram translations and induced dictionaries. Then, for each language pair, we use the 3, 000 that have the highest p(f|e) scores as positive supervision. We randomly sample 9, 000 compositional phrase pairs from those not in each phrase table as negative supervision. Again, we use Vowpal Wabbit for learning a log linear model to score any phrase pair. 4.3 Machine Translation We use GIZA++ to word align each training corpus. We use the Moses SMT framework (Koehn et al., 2007) and the standard phrase-based MT feature set, including phrase and lexical translation probabilities and a lexicalized reordering model. When we augment our models with new translations, we use the average reordering scores over all bilingually estimated phrase pairs. We tune all models using batch MIRA (Cherry and Foster, 2012). We average results over three tuning runs and use approximate randomization to measure statistical significance (Clark et al., 2011). For Spanish, we use a 5-gram language model trained on the English side of the complete Europarl corpus and for Hindi a 5-gram langua</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the Machine Translation Summit.</booktitle>
<contexts>
<context position="12910" citStr="Koehn, 2005" startWordPosition="2044" endWordPosition="2045">top words removed Inverted Index lookups 162 sification scores and keep the top-k. We found that using a score threshold sometimes improves precision. However, as experiments below show, the recall of the set of phrase pairs is more important, and we did not observe improvements in translation quality when we used a score threshold. 4 Experimental Setup In all of our experiments, we assume that we have access to only a small parallel corpus. For our Spanish experiments, we randomly sample 2, 000 sentence pairs (about 57, 000 Spanish words) from the Spanish-English Europarl v5 parallel corpus (Koehn, 2005). For Hindi, we use the parallel corpora released by Post et al. (2012). Again, we randomly sample 2, 000 sentence pairs from the training corpus (about 39, 000 Hindi words). We expect that this amount of parallel text could be compiled for a single text domain and any pair of modern languages. Additionally, we use approximately 2, 500 and 1, 000 single-reference parallel sentences each for tuning and testing our Spanish and Hindi models, respectively. Spanish tuning and test sets are newswire articles taken from the 2010 WMT shared task (Callison-Burch et al., 2010).1 We use the Hindi develop</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of the Machine Translation Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prasanth Kolachina</author>
<author>Nicola Cancedda</author>
<author>Marc Dymetman</author>
<author>Sriram Venkatapathy</author>
</authors>
<title>Prediction of learning curves in machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<marker>Kolachina, Cancedda, Dymetman, Venkatapathy, 2012</marker>
<rawString>Prasanth Kolachina, Nicola Cancedda, Marc Dymetman, and Sriram Venkatapathy. 2012. Prediction of learning curves in machine translation. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Extracting parallel sub-sentential fragments from non-parallel corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="37923" citStr="Munteanu and Marcu, 2006" startWordPosition="6087" endWordPosition="6090">ormation theoretic features estimated over monolingual data into a single log-linear model and then the phrase pairs are filtered using a threshold on model scores. The phrase pairs that it extracts are limited to those that appear in pairs of sentences in the parallel training data. Our work takes a similar approach to that of Deng et al. (2008), however, unlike that work, we hallucinate phrase pairs that did not appear in training data in order to augment the original, bilingually extracted phrase table. Other prior work has used comparable corpora to extract parallel sentences and phrases (Munteanu and Marcu, 2006; Smith et al., 2010). Such efforts are orthogonal to our approach. We use parallel corpora, when available, and hallucinates phrase translations without assuming any parallel text in our comparable corpora. 9 Conclusions We showed that “hallucinating” phrasal translations can significantly improve machine translation performance in low resource conditions. Our hallucinated translations are composed from unigram translations. The translations are low precision but high recall. We countered this by introducing new feature functions and pruning aggressively. 10 Acknowledgements This material is </context>
</contexts>
<marker>Munteanu, Marcu, 2006</marker>
<rawString>Dragos Munteanu and Daniel Marcu. 2006. Extracting parallel sub-sentential fragments from non-parallel corpora. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="37170" citStr="Och and Ney, 2003" startWordPosition="5962" endWordPosition="5965">ain dictionary of 140, 000 word translations. Our approach to the construction of new phrase pairs is somewhat similar to Zhang and Zong (2013), but we don’t rely on a very large manually generated dictionary. Additionally, we focus on the low resource language pair setting, where a large training corpus is not available. Deng et al. (2008) work in a standard SMT setting but use a discriminative framework for extracting phrase pairs from parallel corpora. That approach yields a phrase table with higher precision and recall than the table extracted by standard world alignment based heuristics (Och and Ney, 2003; Koehn et al., 2003). The discriminative model combines features from word alignments and bilingual training data as well as information theoretic features estimated over monolingual data into a single log-linear model and then the phrase pairs are filtered using a threshold on model scores. The phrase pairs that it extracts are limited to those that appear in pairs of sentences in the parallel training data. Our work takes a similar approach to that of Deng et al. (2008), however, unlike that work, we hallucinate phrase pairs that did not appear in training data in order to augment the origi</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="29241" citStr="Papineni et al., 2002" startWordPosition="4663" endWordPosition="4666">LEU scores for the top-k scored hallucinated translations. k varies from 1 to 200. Baseline model performance is shown with a red triangle. Because we hallucinate translations for source phrases that appear in the training data up to 100 times, our baseline models include some of the oracle phrase translations. Not surprisingly, the bilingually extracted phrase pairs have relatively high precision (81% and 40% for Spanish and Hindi, respectively) and low recall (6% and 15% for Spanish and Hindi, respectively). 6.3 End-to-End Translation Table 4 shows end-to-end translation BLEU score results (Papineni et al., 2002). Our first baseline SMT models are trained using only 2, 000 parallel sentences and no new translation model features. Our Spanish baseline achieves a BLEU score of 13.47 and our Hindi baseline a BLEU score of 8.49. When we add the 30 new feature functions estimated over comparable monolingual corpora, performance is slightly lower, 13.35 for Precision 80 20 0 40 Precision 20 10 0 166 Experiment BLEU Spanish Hindi Baseline 13.47 8.49 + Mono. Scores 13.35 8.26 + Mono. Scores &amp; OOV Trans 14.01 8.31 + Phrase Trans, k=1 13.90 8.16 + Phrase Trans, k=2 14.07 8.86* + Phrase Trans, k=5 14.30* 8.89* +</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Constructing parallel corpora for six indian languages via crowdsourcing.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation (WMT).</booktitle>
<contexts>
<context position="12981" citStr="Post et al. (2012)" startWordPosition="2056" endWordPosition="2059">d keep the top-k. We found that using a score threshold sometimes improves precision. However, as experiments below show, the recall of the set of phrase pairs is more important, and we did not observe improvements in translation quality when we used a score threshold. 4 Experimental Setup In all of our experiments, we assume that we have access to only a small parallel corpus. For our Spanish experiments, we randomly sample 2, 000 sentence pairs (about 57, 000 Spanish words) from the Spanish-English Europarl v5 parallel corpus (Koehn, 2005). For Hindi, we use the parallel corpora released by Post et al. (2012). Again, we randomly sample 2, 000 sentence pairs from the training corpus (about 39, 000 Hindi words). We expect that this amount of parallel text could be compiled for a single text domain and any pair of modern languages. Additionally, we use approximately 2, 500 and 1, 000 single-reference parallel sentences each for tuning and testing our Spanish and Hindi models, respectively. Spanish tuning and test sets are newswire articles taken from the 2010 WMT shared task (Callison-Burch et al., 2010).1 We use the Hindi development and testing splits released by Post et al. (2012). 4.1 Unigram Tra</context>
<context position="18919" citStr="Post et al. (2012)" startWordPosition="3020" endWordPosition="3023">lation probabilities and a lexicalized reordering model. When we augment our models with new translations, we use the average reordering scores over all bilingually estimated phrase pairs. We tune all models using batch MIRA (Cherry and Foster, 2012). We average results over three tuning runs and use approximate randomization to measure statistical significance (Clark et al., 2011). For Spanish, we use a 5-gram language model trained on the English side of the complete Europarl corpus and for Hindi a 5-gram language model trained on the English side of the complete training corpus released by Post et al. (2012). We train our language models using SRILM with Kneser-Ney smoothing. Our baseline models use a phrase limit of three, and we augment them with translations of phrases up to length three in our experiments. 5 Oracle Experiment Before moving to the results of our proposed approach for composing phrase translations, we present an oracle experiment to answer these research questions: Would a low resource translation model benefit from composing its unigram translations into phrases? Would this be further improved by adding unigram translations that are learned from monolingual texts? We answer th</context>
</contexts>
<marker>Post, Callison-Burch, Osborne, 2012</marker>
<rawString>Matt Post, Chris Callison-Burch, and Miles Osborne. 2012. Constructing parallel corpora for six indian languages via crowdsourcing. In Proceedings of the Workshop on Statistical Machine Translation (WMT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3834" citStr="Rapp, 1995" startWordPosition="553" endWordPosition="554">ning, pages 160–170, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set of phrase translations is that the number of both source and target phrases is immense. For example, there are about 83 million unique phrases up to length three in the English Wikipedia. Pairwise comparisons of two sets of 100 million phrases corresponds to 1 x 101</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Deciphering foreign language.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="34258" citStr="Ravi and Knight, 2011" startWordPosition="5478" endWordPosition="5481">uage pairs, Spanish-English and Hindi-English. While Spanish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT </context>
<context position="35774" citStr="Ravi and Knight, 2011" startWordPosition="5734" endWordPosition="5737">uning is to identify and remove phrase pairs which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from comparable corpora without any parallel text (Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013). In contrast, we begin with a small amount of parallel data and take a very different approach to learning translation models. In our prior work (Irvine and CallisonBurch, 2013b), we showed how effective even small amounts of bilingual data can be for learning translations from monolingual texts. Garera and Yarowsky (2008) pivot through bilingual dictionaries in several language pairs to compose translations for compound words. Zhang and Zong (2013) construct a set of new, additional phrase pairs for the task of domain adaptation for machine translation. Tha</context>
</contexts>
<marker>Ravi, Knight, 2011</marker>
<rawString>Sujith Ravi and Kevin Knight. 2011. Deciphering foreign language. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
</authors>
<title>Scalable decipherment for machine translation via hash sampling.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="34292" citStr="Ravi, 2013" startWordPosition="5486" endWordPosition="5487">. While Spanish and English are very closely related, Hindi and English are less related. Our oracle experiments showed potential for composing phrase translations for both language pairs, and, indeed, in our experiments using hallucinated phrase translations we saw significant translation quality gains for both. We expect that improving the quality of induced unigram translations will yield even more performance gains. The vast majority of prior work on low resource MT has focused on Spanish-English (Haghighi et al., 2008; Klementiev et al., 2012; Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013; Dou and Knight, 2013). Although such experiments serve as important proofs of concept, we found it important to also experiment with a more 167 truly low resource language pair. The success of our approach that we have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over very large p</context>
<context position="35809" citStr="Ravi, 2013" startWordPosition="5742" endWordPosition="5743">which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from comparable corpora without any parallel text (Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013). In contrast, we begin with a small amount of parallel data and take a very different approach to learning translation models. In our prior work (Irvine and CallisonBurch, 2013b), we showed how effective even small amounts of bilingual data can be for learning translations from monolingual texts. Garera and Yarowsky (2008) pivot through bilingual dictionaries in several language pairs to compose translations for compound words. Zhang and Zong (2013) construct a set of new, additional phrase pairs for the task of domain adaptation for machine translation. That work uses two dictionaries to boo</context>
</contexts>
<marker>Ravi, 2013</marker>
<rawString>Sujith Ravi. 2013. Scalable decipherment for machine translation via hash sampling. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Majid Razmara</author>
<author>Maryam Siahbani</author>
<author>Reza Haffari</author>
<author>Anoop Sarkar</author>
</authors>
<title>Graph propagation for paraphrasing out-of-vocabulary words in statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="3567" citStr="Razmara et al., 2013" startWordPosition="515" endWordPosition="518">nglish. 2 Motivation Translation models learned over small amounts of parallel data suffer from the problem of low coverage. That is, they do not include translations for many words and phrases. Unknown 160 Proceedings of the Eighteenth Conference on Computational Language Learning, pages 160–170, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set</context>
</contexts>
<marker>Razmara, Siahbani, Haffari, Sarkar, 2013</marker>
<rawString>Majid Razmara, Maryam Siahbani, Reza Haffari, and Anoop Sarkar. 2013. Graph propagation for paraphrasing out-of-vocabulary words in statistical machine translation. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="3862" citStr="Schafer and Yarowsky, 2002" startWordPosition="555" endWordPosition="558">160–170, Baltimore, Maryland USA, June 26-27 2014. c�2014 Association for Computational Linguistics words, or out-of-vocabulary (OOV) words, have been the focus of previous work on integrating bilingual lexicon induction and machine translation (Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013a; Razmara et al., 2013). Bilingual lexicon induction is the task of learning translations from monolingual texts, and typical approaches compare projected distributional signatures of words in the source language with distributional signatures representing target language words (Rapp, 1995; Schafer and Yarowsky, 2002; Koehn and Knight, 2002; Haghighi et al., 2008). If the source and target language each contain, for example, 100, 000 words, the number of pairwise comparisons is about 10 billion, which is significant but computationally feasible. In contrast to unigrams, the difficulty in inducing a comprehensive set of phrase translations is that the number of both source and target phrases is immense. For example, there are about 83 million unique phrases up to length three in the English Wikipedia. Pairwise comparisons of two sets of 100 million phrases corresponds to 1 x 1016. Thus, even if we limit th</context>
</contexts>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>Charles Schafer and David Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. In Proceedings of the Conference on Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason R Smith</author>
<author>Chris Quirk</author>
<author>Kristina Toutanova</author>
</authors>
<title>Extracting parallel sentences from comparable corpora using document level alignment.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="37944" citStr="Smith et al., 2010" startWordPosition="6091" endWordPosition="6094">s estimated over monolingual data into a single log-linear model and then the phrase pairs are filtered using a threshold on model scores. The phrase pairs that it extracts are limited to those that appear in pairs of sentences in the parallel training data. Our work takes a similar approach to that of Deng et al. (2008), however, unlike that work, we hallucinate phrase pairs that did not appear in training data in order to augment the original, bilingually extracted phrase table. Other prior work has used comparable corpora to extract parallel sentences and phrases (Munteanu and Marcu, 2006; Smith et al., 2010). Such efforts are orthogonal to our approach. We use parallel corpora, when available, and hallucinates phrase translations without assuming any parallel text in our comparable corpora. 9 Conclusions We showed that “hallucinating” phrasal translations can significantly improve machine translation performance in low resource conditions. Our hallucinated translations are composed from unigram translations. The translations are low precision but high recall. We countered this by introducing new feature functions and pruning aggressively. 10 Acknowledgements This material is based on research spo</context>
</contexts>
<marker>Smith, Quirk, Toutanova, 2010</marker>
<rawString>Jason R. Smith, Chris Quirk, and Kristina Toutanova. 2010. Extracting parallel sentences from comparable corpora using document level alignment. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Daisy Stanton</author>
<author>Peng Xu</author>
</authors>
<title>A systematic comparison of phrase table pruning techniques.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</booktitle>
<contexts>
<context position="5477" citStr="Zens et al. (2012)" startWordPosition="815" endWordPosition="818">e language phrases with all target language phrases, our approach efficiently proposes a smaller set of hypothesis phrase translations for each source language phrase. Our method builds upon the notion that many phrase translations can be composed from the translations of its component words and subphrases. For example Spanish la bruja verde translates into English as the green witch. Each Spanish word corresponds to exactly one English word. The phrase pair could be memorized and translated as a unit, or the English translation could be composed from the translations of each Spanish unigram. Zens et al. (2012) found that only 2% of phrase pairs in German-English, Czech-English, SpanishEnglish, and French-English phrase tables consist of multi-word source and target phrases and are non-compositional. That is, for these languages, the vast majority of phrase pairs in a given phrase table could be composed from smaller units. Our approach takes advantage of the fact that many phrases can be translated compositionally. We describe our approach in three parts. In Section 3.1, we begin by inducing translations for unknown unigrams. Then, in 3.2, we introduce our algorithm for composing phrase translation</context>
<context position="35126" citStr="Zens et al., 2012" startWordPosition="5624" endWordPosition="5627">have seen for Spanish and Hindi suggests that it is worth pursuing such directions for other even less related and resourced language pairs. In addition to language pair, text genre and the degree of looseness or literalness of given parallel corpora may also affect the amount of phrase translation compositionality. 8 Related Work Phrase-based SMT models estimated over very large parallel corpora are expensive to store and process. Prior work has reduced the size of SMT phrase tables in order to improve efficiency without the loss of translation quality (He et al., 2009; Johnson et al., 2007; Zens et al., 2012). Typically, the goal of pruning is to identify and remove phrase pairs which are likely to be inaccurate, using either the scores and counts of a given pair itself or those relative to other phrase pairs. Our work, in contrast, focuses on low resource settings, where training data is limited and provides incomplete and unreliable scored phrase pairs. We begin by dramatically increasing the size of our SMT phrase table in order to expand its coverage and then use non-parallel data to rescore and filter the table. In the decipherment task, translation models are learned from comparable corpora </context>
</contexts>
<marker>Zens, Stanton, Xu, 2012</marker>
<rawString>Richard Zens, Daisy Stanton, and Peng Xu. 2012. A systematic comparison of phrase table pruning techniques. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP/CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Zhang</author>
<author>Chengqing Zong</author>
</authors>
<title>Learning a phrase-based translation model from monolingual data with application to domain adaptation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="36263" citStr="Zhang and Zong (2013)" startWordPosition="5811" endWordPosition="5814">e. In the decipherment task, translation models are learned from comparable corpora without any parallel text (Ravi and Knight, 2011; Dou and Knight, 2012; Ravi, 2013). In contrast, we begin with a small amount of parallel data and take a very different approach to learning translation models. In our prior work (Irvine and CallisonBurch, 2013b), we showed how effective even small amounts of bilingual data can be for learning translations from monolingual texts. Garera and Yarowsky (2008) pivot through bilingual dictionaries in several language pairs to compose translations for compound words. Zhang and Zong (2013) construct a set of new, additional phrase pairs for the task of domain adaptation for machine translation. That work uses two dictionaries to bootstrap a set of phrase pair translations: one probabilistic dictionary extracted from 2 million words of bitext and one manually created new-domain dictionary of 140, 000 word translations. Our approach to the construction of new phrase pairs is somewhat similar to Zhang and Zong (2013), but we don’t rely on a very large manually generated dictionary. Additionally, we focus on the low resource language pair setting, where a large training corpus is n</context>
</contexts>
<marker>Zhang, Zong, 2013</marker>
<rawString>Jiajun Zhang and Chengqing Zong. 2013. Learning a phrase-based translation model from monolingual data with application to domain adaptation. In Proceedings of the Conference of the Association for Computational Linguistics (ACL).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>