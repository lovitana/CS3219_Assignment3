<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002248">
<title confidence="0.9991185">
Inducing Domain-specific Noun Polarity Guided by Domain-independent
Polarity Preferences of Adjectives
</title>
<author confidence="0.967606">
Manfred Klenner
</author>
<affiliation confidence="0.967855">
Computational Linguistics
University of Zurich
</affiliation>
<address confidence="0.53848">
Switzerland
</address>
<email confidence="0.995159">
klenner@cl.uzh.ch
</email>
<author confidence="0.949491">
Michael Amsler
</author>
<affiliation confidence="0.960029">
Computational Linguistics
University of Zurich
</affiliation>
<address confidence="0.53819">
Switzerland
</address>
<email confidence="0.996661">
mamsler@ifi.uzh.ch
</email>
<author confidence="0.97506">
Nora Hollenstein
</author>
<affiliation confidence="0.9721665">
Computational Linguistics
University of Zurich
</affiliation>
<address confidence="0.538076">
Switzerland
</address>
<email confidence="0.994639">
hollenstein@ifi.uzh.ch
</email>
<sectionHeader confidence="0.99381" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999970761904762">
In this paper, we discuss how domain-
specific noun polarity lexicons can be in-
duced. We focus on the generation of
good candidates and compare two ma-
chine learning scenarios in order to estab-
lish an approach that produces high pre-
cision. Candidates are generated on the
basis of polarity preferences of adjectives
derived from a large domain-independent
corpus. The polarity preference of a word,
here an adjective, reflects the distribution
of positive, negative and neutral arguments
the word takes (here: its nominal head).
Given a noun modified by some adjectives,
a vote among the polarity preferences of
these adjectives establishes a good indica-
tor of the polarity of the noun. In our ex-
periments with five domains, we achieved
f-measure of 59% up to 88% on the basis
of two machine learning approaches car-
ried out on top of the preference votes.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99974447368421">
Polarity lexicons are crucial for fine-grained sen-
timent analysis. For instance, in approaches
carrying out sentiment composition (Moilanen
and Pulman, 2007), where phrase-level polar-
ity is composed out of word level polarity (e.g.
disappointed− hope+ → NP−). However, often
freely available lexicons are domain-independent,
which is a problem with domain-specific texts,
since lexical gaps reduce composition anchors.
But how many domain-specific words do we have
to expect? Is it a real or rather a marginal problem?
In our experiments, we found that domain-specific
nouns do occur quite often - so they do matter. In
one of our domains, we identified about 1000 neg-
ative nouns, 409 were domain-specific. In that do-
main, the finance sector, more than 13’000 noun
types exist that do not occur at all in the DeWac
corpus - a large Web corpus (in German) with over
90 Million sentences. Thus, most of them must
be regarded as domain-specific. It would be quite
time-consuming to go through all of them in order
to identify and annotate the polar ones. Could we,
rather, predict good candidates? We would need
polarity predictors - words that take other, polar
words e.g. as their heads. If they, moreover, had
a clear-cut preference, i.e. they mostly took one
kind of polar words, say negative, then they were
perfect predictors of the polarity of nouns. We
found that adjectives (e.g. acute) can be used as
such polarity predictors (e.g. acute mostly takes
negative nouns, denoted n−, e.g. acute pain)).
Our hypothesis is that the polarity prefer-
ences of adjectives are (more or less) domain-
independent. We can learn the preferences from
domain-independent texts and apply it to domain-
specific texts and get good candidates of domain-
specific polar nouns. Clearly, if the polarity pref-
erences of an adjective are balanced (0.33 for each
polarity), than the predictions could not help at all.
But if one polarity clearly prevails, we might even
get a good performance by just classifying the po-
larity of unknown nouns in a domain according to
the dominant polarity preference of the adjectives
they co-occur with.
In this paper, we show how to generate
such a preference model on the basis of a
large, domain-independent German corpus and
a domain-independent German polarity lexicon.
We use this model to generate candidate nouns
from five domain-specific text collections - rang-
ing from 3’200 up to 37’000 texts per domain.
In order to see how far an automatic induction
of a domain-specific noun lexicon could go, we
also experimented with machine learning scenar-
ios on the output of the baseline system. We ex-
perimented with a distributional feature setting on
the basis of unigrams and used the Maximum En-
</bodyText>
<page confidence="0.987356">
18
</page>
<bodyText confidence="0.97650725">
Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 18–23,
Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics
tropy learner, Megam (Daum´e III, 2004), to learn
a classifier. We also worked with Weka (Frank et
al., 2010) and features derived from the German
polarity lexicon. Both approaches yield significant
gains in terms of precision - so they realize a high-
precision scenario.
</bodyText>
<sectionHeader confidence="0.867272" genericHeader="method">
2 Inducing the Preference Model
</sectionHeader>
<bodyText confidence="0.986590029850746">
We seek to identify adjectives which impose a
clear-cut polar preference on their head nouns.
The polarity preference of an adjective reflects the
distribution of positive, negative and neutral nouns
the adjective modifies given to some text corpus.
We used the domain-independent DeWac corpus
(Baroni M., 2009) comprising about 90 million
German sentences. We selected those adjectives
that frequently co-occurred with polar nouns from
PoLex, a freely available German polarity lexicon
(Clematide and Klenner, 2010). Since the original
polarity lexicon contained no neutral nouns, we
first identified 2100 neutral nouns and expanded
the lexicon1. Altogether 5’500 nouns were avail-
able, 2100 neutral, 2100 negative and 1250 pos-
itive. For each adjective, we counted how often
it took (i.e. modified) positive, negative or neu-
tral nouns in the DeWac corpus and determined
their polarity preferences for each class (positive,
negative and neutral). This way, 28’500 adjec-
tives got a probability distribution, most of them,
however, with a dominating neutral polarity pref-
erence. Two lexicons were derived from it: a pos-
itive and a negative polarity preference lexicon.
An adjective obeys a polar polarity preference if
the sum of its positive and negative polarity pref-
erences is higher than its neutral preference. If the
positive preference is higher than the negative, the
adjective is a positive polarity predictor, otherwise
it is a negative polarity predictor. This procedure
leaves us with 506 adjectives, 401 negative polar-
ity predictors and 105 positive polarity predictors.
Figure 1 shows some examples of negative polar-
ity predictors. It reveals that, for instance, the ad-
jective akut (acute) is mostly coupled with neg-
ative nouns (61.50%). Nouns not in PoLex that
co-occur with an adjective are not considered. We
assume that these unknown nouns of an adjective
follow the same distribution that we are sampling
from the known co-occurring nouns. Note that po-
1We searched for nouns that frequently co-occurred with
the same adjectives the polar nouns from the polarity lexicon
did and stopped annotating when we reached 2’100 neutral
nouns.
larity predictors not necessarily must have a prior
polarity itself. Actually, only 3 of the 12 adjectives
from Figure 1 do have a prior polarity (indicated as
n−). For instance, the adjective pl¨otzlich (immedi-
ate) is not polar but has a negative polarity pref-
erence. The polarity preference of a word is not
useful in composition, it just reveals the empirical
(polar) context of the word. If, however, the polar-
ity of the context word is unknown, the preference
might license an informed polarity guess.
adjective English POS NEG #n−
arg− bad/very 02.65 55.14 301
heftig intensive 07.73 48.77 814
v¨ollig total 25.79 42.43 787
akut acute 06.27 61.50 478
latent latent 07.96 47.76 402
ziemlich rather 14.16 52.36 233
drohend− threatening 35.1 52.54 824
pl¨otzlich immediate 17.78 41.82 703
gravierend grave 04.5 48.5 400
chronisch chronic 03.26 72.11 398
schleichend subtle 03.76 52.97 319
hemmunglos− unscrupulous 15.49 43.19 213
</bodyText>
<figureCaption confidence="0.998805">
Figure 1: Negative Polarity Predictors
</figureCaption>
<bodyText confidence="0.877463230769231">
Here is the formula for the estimation of the
negative polarity preference as given in Figure 1
(n− denotes a negative noun from PoLex, aj an
adjective modifying an instance of n−)2:
prefn−(aj) =#aj n−
#a+,−,=
j
Note that we count the number of adj-noun
types (#aj n−), not tokens. #aj+ ,−,= is the num-
ber of adj-noun types of the adjective aj for all
classes: positive (+), negative(-) and neutral (=).
Figure 2 gives examples of positive polarity pre-
dictors with some of their nouns.
</bodyText>
<figure confidence="0.873110142857143">
German English POS
ungetr¨ubt unclouded joy
unbeirrbar unerring hope
¨uberstr¨omend overwhelming happiness
bewunderswert mirable competence
falschverstanden falsely-understood tolerance
wiedergewonnen regained freedom
</figure>
<figureCaption confidence="0.996582">
Figure 2: Positive Polarity Predictors
</figureCaption>
<sectionHeader confidence="0.941698" genericHeader="method">
3 Applying the Preference Model
</sectionHeader>
<bodyText confidence="0.75979625">
We applied the preference model to texts from five
domains: banks (37’346 texts), transport (3221),
2This could be interpreted as the conditional probability
of a negative noun given the adjective.
</bodyText>
<page confidence="0.997024">
19
</page>
<bodyText confidence="0.9999201">
insurance (4768), politics (3208) and pharma
(4790). These texts have been manually classified
over the last 15 years by an institute carrying out
media monitoring3, not only wrt. their domain,
but also wrt. target-specific polarity (we just use
the domain annotation, currently).
The polarity of a noun is predicted by the vote
of the adjectives it occurred with. The following
formula shows the polarity prediction pol+,−,= for
the class negative (pol−):
</bodyText>
<equation confidence="0.9815775">
11 pol−(ni) = Ai ∗ prefn−(aj)
ajEPM−n�I(aj,ni)
</equation>
<bodyText confidence="0.9999225">
Ai is the number of adjectives that modify the
noun ni in the domain-specific texts. PM− is the
set of adjectives from the polarity model (PM)
with a negative polarity preference and (aj, ni) is
true, if the adjective aj modifies the noun ni ac-
cording to the domain-specific documents.
</bodyText>
<sectionHeader confidence="0.993066" genericHeader="method">
4 Improving the Predictions
</sectionHeader>
<bodyText confidence="0.997318571428571">
The preference model serves two purposes: it gen-
erates a list of candidates for polar nouns and it
establishes a baseline. We experimented with two
feature settings in order to find out whether we
could improve on these results.
In the first setting, the WK setting, we wanted to
exploit the fact that for some adjectives that mod-
ify a noun, we know their prior polarity (from the
polarity lexicon). These adjectives do not nec-
essarily have a clear positive or negative polarity
preference. If not, then they are not used in the
prediction of the noun polarity.
But could the co-occurrence of a noun with ad-
jectives bearing a prior polarity also be indicative
of the noun polarity? For instance, if a noun is
coupled frequently and exclusively with negative
adjectives. Does this indicate something? Ones
intuition might mislead, but a machine learning
approach could reveal correlations. We used Sim-
ple Logistic Regression (SRL) from Weka and the
following features:
</bodyText>
<listItem confidence="0.999117">
1. the number of positive adjectives with a prior
polarity that modify the noun
2. the number of negative adjectives with a prior
polarity that modify the noun
</listItem>
<footnote confidence="0.945463333333333">
3We would like to thank the f¨og institute (cf.
www.foeg.uzh.ch/) for these data (mainly newspaper texts in
German).
</footnote>
<listItem confidence="0.997513875">
3. the difference between 1) and 2): absolute
and ratio
4. the ratio of positive and negative adjectives
5. two binary features indicating the majority
class
6. three features for the output of the prefer-
ence model: the positive, negative and neu-
tral scores: pol−, pol+, pol=, respectively.
</listItem>
<bodyText confidence="0.999514166666667">
In the second setting, the MG setting, we trained
Megam, a Maximum Entropy learner, among the
following lines: we took all polar nouns from
PoLex and extracted from the DeWac corpus all
sentences containing these nouns. For each noun,
all (context) words (nouns, adjectives, verbs) co-
occurring with it in these sentences are used as
bag of words training vectors. In other words, we
learned a tri-partite classifier to predict the polarity
class (positive, negative or neutral) given a target
noun and its context, i.e. those nouns co-occurring
with it in a text collection.
</bodyText>
<sectionHeader confidence="0.99952" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999024730769231">
The goal of our experiments were the prediction
of positive and negative domain-specific nouns in
five domains. We used our preference model to
generate candidates. Then we manually annotated
the results in order to obtain a domain-specific
gold standard. We evaluated the output of the
preference model relative to the new gold stan-
dards and we run our experiments with Megam
and Weka’s Simple Logistic Regression (SRL).
Megam and Weka’s SLR were trained on the basis
of the positive, negative and neutral nouns from
PoLex and the DeWac corpus.
Figure 3 shows the results. #PM gives the num-
ber of nouns predicted by the preference model
to be negative (e.g. 220 in the politics domain).
These are the nouns we annotated for polarity
and that formed our gold standard afterwards (e.g.
75.90 out of 110 predicted are true negative nouns
and are kept as the gold standard). Since the gen-
eration of the gold standard is based on the prefer-
ence model’s output, its recall is 1. We cannot fix
the real recall since this would require to manu-
ally classify all nouns occurring in those texts (e.g.
13’000 in the banks domain). However, since we
wanted to compare the machine learning perfor-
mance with the preference model, we had to mea-
</bodyText>
<page confidence="0.986615">
20
</page>
<table confidence="0.958782666666667">
ID domain texts #PM prec f #WK prec rec f #MG prec rec f
D1 politics 3208 220 75.90 86.29 195 78.97 92.22 83.26 130 81.54 63.48 69.13
D2 transport 3221 141 71.63 83.47 127 73.22 92.07 80.57 64 78.12 49.50 58.54
D3 insurance 4768 255 76.86 86.91 238 78.57 95.40 85.13 155 79.35 62.75 69.09
D4 pharma 4790 257 71.59 83.44 228 76.75 95.11 81.69 137 87.83 65.40 68.35
D5 banks 37346 1013 70.38 88.02 825 77.84 90.07 79.02 437 81.23 49.78 58.32
</table>
<figureCaption confidence="0.998779">
Figure 3: Prediction of Negative Nouns
</figureCaption>
<bodyText confidence="0.996209083333333">
sure recall, otherwise we could not determine the
overall performance.
From Figure 3 we can see that the preference
model (PM) performs best in terms of f-measure
(in bold). Of course, recall (i.e. 1, not shown) is
idealized, since we took the output of the prefer-
ence model to generate the gold standard. Note
however that this was our premise, that we needed
an approach that delivers good candidates, other-
wise we were lost given the vast amount of can-
didate nouns (e.g. remember the 13’000 nouns in
the finance sector).
</bodyText>
<figure confidence="0.844228666666667">
German English
Wertverminderung impairment of assets
Stagflation stagflation
Geldschwemme money glut
¨Uberhitzungssymptom overheating symptom
Hyperinflation hyperinflation
Euroschw¨ache weakness of the euro
Werterosion erosion in value
Nachfrage¨uberhang surplus in demand
Margendruck pressure on margins
Klumpenrisiko cluster risk
Virus virus
Handekzem hand eczema
Schweinegrippe swine flu
Geb¨armutterriss ruptured uterus
Alzheimer Alzheimer
Sehst¨orung defective eye sight
Tinnitus tinnitus
</figure>
<figureCaption confidence="0.999871">
Figure 4: Domain-specific Negative Nouns
</figureCaption>
<bodyText confidence="0.998003264705882">
Figure 4 shows examples of negative nouns
from two domains: banks and pharma. But: are all
found nouns domain-specific negative nouns? In
the bank domain, we have manually annotated for
domain specificity: out of 1013 nouns predicted
to be negative by the model, 409 actually were
domain-specific (40.3 %)4. The other nouns could
also be in a domain-independent polarity lexicon.
Now, we turn to the prediction of positive
domain-specific nouns. It is not really surpris-
ing that the preference model is unbalanced - that
there are far more negative than positive polarity
predictors: 401 compared to 105. PoLex, the pool
451 of the 131 (38.93%) as positive classified nouns actu-
ally were domain-specific.
of nouns used for learning of the polarity prefer-
ences already is unbalanced (2100 negative com-
pared to 1250 positive nouns). Also, the major-
ity of the texts in our five domains are negative
(all texts are annotated for document-level polar-
ity). It is obvious then that our model is better
in the prediction of negative than positive polarity.
Actually, our base model comprising 105 positive
polarity predictors does not trigger often within
the whole corpus. For instance, only 10 predic-
tions were made in the banks domain, despite the
37’346 texts. Clearly, newspaper texts often are
critical and thus more negative than positive vo-
cabulary is used. This explains the very low recall.
However, what if we relaxed our model? If we,
for example, keep those adjectives in our model
that have a positive polarity preference &gt; 0.35, at
least 35 out of 100 nouns co-occurring with those
adjectives should be positive.
</bodyText>
<table confidence="0.998170833333333">
ID #1 prec #2 prec #3 prec #4 prec
D1 18 66.6 25 60.0 25 60.0 8 50
D2 14 85.7 16 75.0 0 0 3 33.3
D3 13 69.2 15 60.0 5 100 1 100
D4 13 84.6 15 80.0 9 55.5 2 100
D5 135 76.2 174 71.2 58 87.9 40 82.5
</table>
<figureCaption confidence="0.999693">
Figure 5: Prediction of Positive Nouns
</figureCaption>
<bodyText confidence="0.999964588235294">
We report the results of two runs. The first one,
labelled #1, where adjectives are used to predict a
positive noun polarity if they have a positive po-
larity preference &gt; 0.35 and where the negative
polarity preference is &lt; 0.1. In the second run, la-
belled #2, we only require the positive preference
to be &gt; 0.35. Table 5 shows the results. We also
show the results of Weka (label #3) and Megam
(label #4) for the candidates generated by #2.
Compared to the negative settings, the number
of found positive nouns is rather low. For instance,
in the banks domain, 174 nouns were suggested
compared to 1013 negative ones. However, pre-
cision has not dropped and it is especially higher
than the threshold value of 0.35 seemed to indi-
cate (as discussed previously). Weka (#3) and
Megam (#4) again show better precision, however
</bodyText>
<page confidence="0.997929">
21
</page>
<bodyText confidence="0.977350461538462">
the number of found nouns is too low (in a setting
that suffers already from low numbers). Figure 6
shows a couple of found positive nouns.
German English
Versammlungsfreiheit
Ausl¨anderintegration
deposit protection
wage transparency
budgetary discipline
marketing strength
confidence of investors
ability for criticism
leadership competencies
</bodyText>
<figureCaption confidence="0.999499">
Figure 6: Predicted Positive Nouns
</figureCaption>
<bodyText confidence="0.999442666666667">
So far, we have discussed a binary approach
where each class (positive, negative) was predicted
and classified independently and where especially
no adjectives with a neutral preference where con-
sidered. What happens if we include these adjec-
tives? The results are given in Figure 7.
</bodyText>
<table confidence="0.9946995">
domain #neg prec #pos prec
banks 288 80.16 3 66.66
pharma 141 70.92 32 68.75
transport 78 67.94 0 0
politics 115 76.52 0 0
insurance 132 66.66 0 0
</table>
<figureCaption confidence="0.999209">
Figure 7: Unrestricted Prediction of Noun Polarity
</figureCaption>
<bodyText confidence="0.999738">
Although precision is good, the results are very
conservative, e.g. in the banks domain, only 288
nouns were found compared to 1013 nouns given
the binary mode. Recall and f-measure are lower
compared to the binary setting. The huge amount
of neutral preference adjectives (about 28’000)
seems to neutralize polar tendencies. But even
then, some predictions survive - so these contexts
seem to be strong.
</bodyText>
<sectionHeader confidence="0.99998" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999992444444445">
The expansion or creation of sentiment lexicons
has been investigated in many variations from dif-
ferent perspectives and for various goals. Liu
and Zhang (2012) subdivide the work in this field
into three groups: manual approaches, dictionary-
based approaches and corpus-based approaches.
While the manual approach is time-consuming, it
is still often used to create core lexicons which are
not domain-specific, e.g. (Taboada et al., 2011).
The dictionary-based approaches which are also
called thesaurus-based approaches (Huang et al.,
2014) try to make use of existing dictionaries or
thesauri like WordNet (e.g. (Esuli and Sebastiani,
2006; Baccianella et al., 2010; Neviarouskaya et
al., 2011)) while the corpus-based approaches rely
on statistical measures based on different con-
cepts, for example, sentiment consistency (Hatzi-
vassiloglou and McKeown, 1997), pointwise mu-
tual information (Turney, 2002), context co-
herency (Kanayama and Nasukawa, 2006), double
propagation (Qiu et al., 2011) or label propagation
(Huang et al., 2014). Our approach is based on the
use of an existing dictionary and of an domain-
independent corpus. But rather than using the cor-
pus to directly detect new entries for the lexicon,
we use it to derive the polarity preference of adjec-
tives which in turn is used to generate candidates
from the domain-specific corpus.
The model most similar to our approach is
(Klenner and Petrakis, 2014), where the contex-
tual and prior polarity of nouns is learned from the
polarity preference of verbs for the verb’s direct
object. However, no attempt is made to induce
domain-specific polarity as we do. We also fo-
cus on the polarity preference of adjectives and we
also try to improve precision by machine learning.
</bodyText>
<sectionHeader confidence="0.999343" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999950863636364">
We have introduced a plain model for the in-
duction of domain-specific noun lexicons. First,
the polarity preferences of adjectives are learned
from domain-independent text and from a gen-
eral polarity lexicon. A voting approach then pre-
dicts noun polarity from adjective noun pairings
sampled from domain-specific texts. The predic-
tions based only on adjectives acting as positive
or negative polarity predictors perform astonish-
ingly well. Machine Learning can be used to im-
prove precision at the cost of recall. Our approach
thus even might be useful for fully automatic gen-
eration of a high precision, domain-specific prior
noun polarity lexicons.
In future work, we will apply our approach to
other languages than German. We then will also
have to cope with multiword expressions as well,
since compounds not longer - as in German - come
as single words. We also would like to carry out
an extrinsic evaluation in order to see how big the
impact of an induced domain-specific lexicon on
polarity text classification actually is.
</bodyText>
<figure confidence="0.555509888888889">
Einlagesicherung
Lohntransparenz
Haushaltsdisziplin
Vertriebsst¨arke
Anlegervertrauen
Kritikf¨ahigkeit
F¨uhrungskompetenz
freedom of assembly
integration of foreigners
</figure>
<page confidence="0.976976">
22
</page>
<sectionHeader confidence="0.989948" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9998767">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. Sentiwordnet 3.0: An enhanced lexical
resource for sentiment analysis and opinion mining.
In Proc. of LREC 2010, volume 10, pages 2200–
2204.
Ferraresi A. Zanchetta E. Baroni M., Bernardini S.
2009. The WaCky Wide Web: A collection of very
large linguistically processed Web-crawled corpora.
Language Resources and Evaluation, 43(3):209–
226.
Simon Clematide and Manfred Klenner. 2010. Eval-
uation and extension of a polarity lexicon for Ger-
man. In Proceedings of the First Workshop on Com-
putational Approaches to Subjectivity and Sentiment
Analysis, pages 7–13.
Hal Daum´e III. 2004. Notes on CG and LM-BFGS
optimization of logistic regression. Paper avail-
able at http://pub.hal3.name#daume04cg-bfgs, im-
plementation available at http://hal3.name/megam.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
wordnet: A publicly available lexical resource for
opinion mining. In Proc. of LREC 2006, volume 6,
pages 417–422.
Eibe Frank, Mark Hall, Geoffrey Holmes, Richard
Kirkby, Bernhard Pfahringer, Ian H. Witten, and Len
Trigg. 2010. Weka-A Machine Learning Work-
bench for Data Mining. In Oded Maimon and Lior
Rokach, editors, Data Mining and Knowledge Dis-
covery Handbook, chapter 66, pages 1269–1277.
Springer US, Boston, MA.
Vasileios Hatzivassiloglou and Kathleen R McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proc. of the ACL 1997, pages 174–181.
Association for Computational Linguistics.
Sheng Huang, Zhendong Niu, and Chongyang Shi.
2014. Automatic construction of domain-specific
sentiment lexicon based on constrained label prop-
agation. Knowledge-Based Systems, 56:191–200.
Hiroshi Kanayama and Tetsuya Nasukawa. 2006.
Fully automatic lexicon expansion for domain-
oriented sentiment analysis. In Proc. of EMNLP
2006, pages 355–363. Association for Computa-
tional Linguistics.
Manfred Klenner and Stefanos Petrakis. 2014. Induc-
ing the contextual and prior polarity of nouns from
the induced polarity preference of verbs. Data &amp;
Knowledge Engineering, 90:13–21.
Bing Liu and Lei Zhang. 2012. A survey of opinion
mining and sentiment analysis. In Mining Text Data,
pages 415–463. Springer.
Karo Moilanen and Stephen Pulman. 2007. Sentiment
composition. In Proc. of RANLP 2007, pages 378–
382, Borovets, Bulgaria, September 27-29.
Alena Neviarouskaya, Helmut Prendinger, and Mitsuru
Ishizuka. 2011. Sentiful: A lexicon for sentiment
analysis. Affective Computing, IEEE Transactions
on, 2(1):22–36.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2011. Opinion word expansion and target extraction
through double propagation. Computational Lin-
guistics, 37(1):9–27.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional Linguistics, 37(2):267–307.
Peter D Turney. 2002. Thumbs up or thumbs down?:
semantic orientation applied to unsupervised clas-
sification of reviews. In Proc. of the ACL 2002,
pages 417–424. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.998932">
23
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.140020">
<title confidence="0.9983745">Inducing Domain-specific Noun Polarity Guided by Polarity Preferences of Adjectives</title>
<author confidence="0.993117">Manfred</author>
<affiliation confidence="0.9936995">Computational University of</affiliation>
<email confidence="0.710649">klenner@cl.uzh.ch</email>
<author confidence="0.947257">Michael</author>
<affiliation confidence="0.9946975">Computational University of</affiliation>
<title confidence="0.362113">mamsler@ifi.uzh.ch</title>
<author confidence="0.901106">Nora</author>
<affiliation confidence="0.9822175">Computational University of</affiliation>
<email confidence="0.620414">hollenstein@ifi.uzh.ch</email>
<abstract confidence="0.998667136363636">In this paper, we discuss how domainspecific noun polarity lexicons can be induced. We focus on the generation of good candidates and compare two machine learning scenarios in order to establish an approach that produces high precision. Candidates are generated on the basis of polarity preferences of adjectives derived from a large domain-independent The preference a word, here an adjective, reflects the distribution of positive, negative and neutral arguments the word takes (here: its nominal head). Given a noun modified by some adjectives, a vote among the polarity preferences of these adjectives establishes a good indicator of the polarity of the noun. In our experiments with five domains, we achieved f-measure of 59% up to 88% on the basis of two machine learning approaches carried out on top of the preference votes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Proc. of LREC</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="18940" citStr="Baccianella et al., 2010" startWordPosition="3049" endWordPosition="3052">cons has been investigated in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adject</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proc. of LREC 2010, volume 10, pages 2200– 2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferraresi A Zanchetta E Baroni M</author>
<author>S Bernardini</author>
</authors>
<title>The WaCky Wide Web: A collection of very large linguistically processed Web-crawled corpora. Language Resources and Evaluation,</title>
<date>2009</date>
<volume>43</volume>
<issue>3</issue>
<pages>226</pages>
<marker>M, Bernardini, 2009</marker>
<rawString>Ferraresi A. Zanchetta E. Baroni M., Bernardini S. 2009. The WaCky Wide Web: A collection of very large linguistically processed Web-crawled corpora. Language Resources and Evaluation, 43(3):209– 226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Clematide</author>
<author>Manfred Klenner</author>
</authors>
<title>Evaluation and extension of a polarity lexicon for German.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,</booktitle>
<pages>7--13</pages>
<contexts>
<context position="5013" citStr="Clematide and Klenner, 2010" startWordPosition="779" endWordPosition="782">ificant gains in terms of precision - so they realize a highprecision scenario. 2 Inducing the Preference Model We seek to identify adjectives which impose a clear-cut polar preference on their head nouns. The polarity preference of an adjective reflects the distribution of positive, negative and neutral nouns the adjective modifies given to some text corpus. We used the domain-independent DeWac corpus (Baroni M., 2009) comprising about 90 million German sentences. We selected those adjectives that frequently co-occurred with polar nouns from PoLex, a freely available German polarity lexicon (Clematide and Klenner, 2010). Since the original polarity lexicon contained no neutral nouns, we first identified 2100 neutral nouns and expanded the lexicon1. Altogether 5’500 nouns were available, 2100 neutral, 2100 negative and 1250 positive. For each adjective, we counted how often it took (i.e. modified) positive, negative or neutral nouns in the DeWac corpus and determined their polarity preferences for each class (positive, negative and neutral). This way, 28’500 adjectives got a probability distribution, most of them, however, with a dominating neutral polarity preference. Two lexicons were derived from it: a pos</context>
</contexts>
<marker>Clematide, Klenner, 2010</marker>
<rawString>Simon Clematide and Manfred Klenner. 2010. Evaluation and extension of a polarity lexicon for German. In Proceedings of the First Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, pages 7–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.name/megam.</title>
<date>2004</date>
<marker>Daum´e, 2004</marker>
<rawString>Hal Daum´e III. 2004. Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.name/megam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentiwordnet: A publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proc. of LREC</booktitle>
<volume>6</volume>
<pages>417--422</pages>
<contexts>
<context position="18914" citStr="Esuli and Sebastiani, 2006" startWordPosition="3045" endWordPosition="3048">r creation of sentiment lexicons has been investigated in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the pol</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. Sentiwordnet: A publicly available lexical resource for opinion mining. In Proc. of LREC 2006, volume 6, pages 417–422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eibe Frank</author>
<author>Mark Hall</author>
<author>Geoffrey Holmes</author>
<author>Richard Kirkby</author>
<author>Bernhard Pfahringer</author>
<author>Ian H Witten</author>
<author>Len Trigg</author>
</authors>
<date>2010</date>
<booktitle>Weka-A Machine Learning Workbench for Data Mining. In Oded Maimon and Lior Rokach, editors, Data Mining and Knowledge Discovery Handbook, chapter 66,</booktitle>
<pages>1269--1277</pages>
<publisher>Springer US,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="4303" citStr="Frank et al., 2010" startWordPosition="674" endWordPosition="677">main. In order to see how far an automatic induction of a domain-specific noun lexicon could go, we also experimented with machine learning scenarios on the output of the baseline system. We experimented with a distributional feature setting on the basis of unigrams and used the Maximum En18 Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 18–23, Baltimore, Maryland, USA. June 27, 2014. c�2014 Association for Computational Linguistics tropy learner, Megam (Daum´e III, 2004), to learn a classifier. We also worked with Weka (Frank et al., 2010) and features derived from the German polarity lexicon. Both approaches yield significant gains in terms of precision - so they realize a highprecision scenario. 2 Inducing the Preference Model We seek to identify adjectives which impose a clear-cut polar preference on their head nouns. The polarity preference of an adjective reflects the distribution of positive, negative and neutral nouns the adjective modifies given to some text corpus. We used the domain-independent DeWac corpus (Baroni M., 2009) comprising about 90 million German sentences. We selected those adjectives that frequently co-</context>
</contexts>
<marker>Frank, Hall, Holmes, Kirkby, Pfahringer, Witten, Trigg, 2010</marker>
<rawString>Eibe Frank, Mark Hall, Geoffrey Holmes, Richard Kirkby, Bernhard Pfahringer, Ian H. Witten, and Len Trigg. 2010. Weka-A Machine Learning Workbench for Data Mining. In Oded Maimon and Lior Rokach, editors, Data Mining and Knowledge Discovery Handbook, chapter 66, pages 1269–1277. Springer US, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proc. of the ACL</booktitle>
<pages>174--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19134" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="3074" endWordPosition="3078">ches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to generate candidates from the domain-specific corpus. The model most similar to our approach is (Klenner and Petrakis, 2014), where the contextual and prior polarity</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R McKeown. 1997. Predicting the semantic orientation of adjectives. In Proc. of the ACL 1997, pages 174–181. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheng Huang</author>
<author>Zhendong Niu</author>
<author>Chongyang Shi</author>
</authors>
<title>Automatic construction of domain-specific sentiment lexicon based on constrained label propagation. Knowledge-Based Systems,</title>
<date>2014</date>
<pages>56--191</pages>
<contexts>
<context position="18814" citStr="Huang et al., 2014" startWordPosition="3029" endWordPosition="3032">ome predictions survive - so these contexts seem to be strong. 6 Related Work The expansion or creation of sentiment lexicons has been investigated in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rath</context>
</contexts>
<marker>Huang, Niu, Shi, 2014</marker>
<rawString>Sheng Huang, Zhendong Niu, and Chongyang Shi. 2014. Automatic construction of domain-specific sentiment lexicon based on constrained label propagation. Knowledge-Based Systems, 56:191–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Kanayama</author>
<author>Tetsuya Nasukawa</author>
</authors>
<title>Fully automatic lexicon expansion for domainoriented sentiment analysis.</title>
<date>2006</date>
<booktitle>In Proc. of EMNLP</booktitle>
<pages>355--363</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19228" citStr="Kanayama and Nasukawa, 2006" startWordPosition="3088" endWordPosition="3091">ming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to generate candidates from the domain-specific corpus. The model most similar to our approach is (Klenner and Petrakis, 2014), where the contextual and prior polarity of nouns is learned from the polarity preference of verbs for the verb’s direct object. Howev</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>Hiroshi Kanayama and Tetsuya Nasukawa. 2006. Fully automatic lexicon expansion for domainoriented sentiment analysis. In Proc. of EMNLP 2006, pages 355–363. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Klenner</author>
<author>Stefanos Petrakis</author>
</authors>
<title>Inducing the contextual and prior polarity of nouns from the induced polarity preference of verbs.</title>
<date>2014</date>
<journal>Data &amp; Knowledge Engineering,</journal>
<pages>90--13</pages>
<contexts>
<context position="19693" citStr="Klenner and Petrakis, 2014" startWordPosition="3168" endWordPosition="3171"> example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to generate candidates from the domain-specific corpus. The model most similar to our approach is (Klenner and Petrakis, 2014), where the contextual and prior polarity of nouns is learned from the polarity preference of verbs for the verb’s direct object. However, no attempt is made to induce domain-specific polarity as we do. We also focus on the polarity preference of adjectives and we also try to improve precision by machine learning. 7 Conclusions We have introduced a plain model for the induction of domain-specific noun lexicons. First, the polarity preferences of adjectives are learned from domain-independent text and from a general polarity lexicon. A voting approach then predicts noun polarity from adjective </context>
</contexts>
<marker>Klenner, Petrakis, 2014</marker>
<rawString>Manfred Klenner and Stefanos Petrakis. 2014. Inducing the contextual and prior polarity of nouns from the induced polarity preference of verbs. Data &amp; Knowledge Engineering, 90:13–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Lei Zhang</author>
</authors>
<title>A survey of opinion mining and sentiment analysis.</title>
<date>2012</date>
<booktitle>In Mining Text Data,</booktitle>
<pages>415--463</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="18433" citStr="Liu and Zhang (2012)" startWordPosition="2975" endWordPosition="2978">nrestricted Prediction of Noun Polarity Although precision is good, the results are very conservative, e.g. in the banks domain, only 288 nouns were found compared to 1013 nouns given the binary mode. Recall and f-measure are lower compared to the binary setting. The huge amount of neutral preference adjectives (about 28’000) seems to neutralize polar tendencies. But even then, some predictions survive - so these contexts seem to be strong. 6 Related Work The expansion or creation of sentiment lexicons has been investigated in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures</context>
</contexts>
<marker>Liu, Zhang, 2012</marker>
<rawString>Bing Liu and Lei Zhang. 2012. A survey of opinion mining and sentiment analysis. In Mining Text Data, pages 415–463. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment composition.</title>
<date>2007</date>
<booktitle>In Proc. of RANLP</booktitle>
<pages>378--382</pages>
<location>Borovets, Bulgaria,</location>
<contexts>
<context position="1422" citStr="Moilanen and Pulman, 2007" startWordPosition="201" endWordPosition="204">e an adjective, reflects the distribution of positive, negative and neutral arguments the word takes (here: its nominal head). Given a noun modified by some adjectives, a vote among the polarity preferences of these adjectives establishes a good indicator of the polarity of the noun. In our experiments with five domains, we achieved f-measure of 59% up to 88% on the basis of two machine learning approaches carried out on top of the preference votes. 1 Introduction Polarity lexicons are crucial for fine-grained sentiment analysis. For instance, in approaches carrying out sentiment composition (Moilanen and Pulman, 2007), where phrase-level polarity is composed out of word level polarity (e.g. disappointed− hope+ → NP−). However, often freely available lexicons are domain-independent, which is a problem with domain-specific texts, since lexical gaps reduce composition anchors. But how many domain-specific words do we have to expect? Is it a real or rather a marginal problem? In our experiments, we found that domain-specific nouns do occur quite often - so they do matter. In one of our domains, we identified about 1000 negative nouns, 409 were domain-specific. In that domain, the finance sector, more than 13’0</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. 2007. Sentiment composition. In Proc. of RANLP 2007, pages 378– 382, Borovets, Bulgaria, September 27-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena Neviarouskaya</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Sentiful: A lexicon for sentiment analysis. Affective Computing,</title>
<date>2011</date>
<journal>IEEE Transactions on,</journal>
<volume>2</volume>
<issue>1</issue>
<contexts>
<context position="18969" citStr="Neviarouskaya et al., 2011" startWordPosition="3053" endWordPosition="3056"> in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to</context>
</contexts>
<marker>Neviarouskaya, Prendinger, Ishizuka, 2011</marker>
<rawString>Alena Neviarouskaya, Helmut Prendinger, and Mitsuru Ishizuka. 2011. Sentiful: A lexicon for sentiment analysis. Affective Computing, IEEE Transactions on, 2(1):22–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<contexts>
<context position="19267" citStr="Qiu et al., 2011" startWordPosition="3094" endWordPosition="3097">ns which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to generate candidates from the domain-specific corpus. The model most similar to our approach is (Klenner and Petrakis, 2014), where the contextual and prior polarity of nouns is learned from the polarity preference of verbs for the verb’s direct object. However, no attempt is made to induce domain</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational Linguistics, 37(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="18711" citStr="Taboada et al., 2011" startWordPosition="3016" endWordPosition="3019">nt of neutral preference adjectives (about 28’000) seems to neutralize polar tendencies. But even then, some predictions survive - so these contexts seem to be strong. 6 Related Work The expansion or creation of sentiment lexicons has been investigated in many variations from different perspectives and for various goals. Liu and Zhang (2012) subdivide the work in this field into three groups: manual approaches, dictionarybased approaches and corpus-based approaches. While the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). </context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proc. of the ACL 2002,</booktitle>
<pages>417--424</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19179" citStr="Turney, 2002" startWordPosition="3083" endWordPosition="3084"> the manual approach is time-consuming, it is still often used to create core lexicons which are not domain-specific, e.g. (Taboada et al., 2011). The dictionary-based approaches which are also called thesaurus-based approaches (Huang et al., 2014) try to make use of existing dictionaries or thesauri like WordNet (e.g. (Esuli and Sebastiani, 2006; Baccianella et al., 2010; Neviarouskaya et al., 2011)) while the corpus-based approaches rely on statistical measures based on different concepts, for example, sentiment consistency (Hatzivassiloglou and McKeown, 1997), pointwise mutual information (Turney, 2002), context coherency (Kanayama and Nasukawa, 2006), double propagation (Qiu et al., 2011) or label propagation (Huang et al., 2014). Our approach is based on the use of an existing dictionary and of an domainindependent corpus. But rather than using the corpus to directly detect new entries for the lexicon, we use it to derive the polarity preference of adjectives which in turn is used to generate candidates from the domain-specific corpus. The model most similar to our approach is (Klenner and Petrakis, 2014), where the contextual and prior polarity of nouns is learned from the polarity prefer</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D Turney. 2002. Thumbs up or thumbs down?: semantic orientation applied to unsupervised classification of reviews. In Proc. of the ACL 2002, pages 417–424. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>