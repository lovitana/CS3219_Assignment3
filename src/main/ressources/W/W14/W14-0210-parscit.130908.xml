<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.052249">
<title confidence="0.983072">
Navigation Dialog of Blind People: Recovery from Getting Lost
</title>
<author confidence="0.945856">
Jan Vystrcil, Ivo Maly, Jan Balata and Zdenek Mikovec
</author>
<affiliation confidence="0.68477">
Czech Technical University in Prague, Faculty Of Electrical Engineering
</affiliation>
<address confidence="0.4824985">
Karlovo nam. 13, 121 35 Praha 2
Czech Republic
</address>
<email confidence="0.971347">
{vystrjan, malyi1, balatjan, xmikovec}@fel.cvut.cz
</email>
<sectionHeader confidence="0.992903" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998645">
Navigation of blind people is different
from the navigation of sighted people and
there is also difference when the blind per-
son is recovering from getting lost. In this
paper we focus on qualitative analysis of
dialogs between lost blind person and nav-
igator, which is done through the mobile
phone. The research was done in two out-
door and one indoor location. The analy-
sis revealed several areas where the dialog
model must focus on detailed information,
like evaluation of instructions provided by
blind person and his/her ability to reliably
locate navigation points.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956108108108">
When blind people travel independently, it may
happen that they get lost. This happens when they
can not find any useful navigation points. Use of
existing GPS based navigation systems is of no use
as the maps do not provide appropriate navigation
points and the GPS localization is imprecise (tens
of meters, where the lost blind person needs preci-
sion at highest in meters). In such situation blind
people typically use one of two following meth-
ods to recover. First they can ask people in their
surrounding for help. Second they can call friend
or dedicated assistance center. The first method
is currently more favorable for blind people, but
they have experience with both methods. In each
method the dialog has different structure due to the
different context information available to the help-
ing person (called navigator) and lost blind person.
In our research we focus on the second method,
navigation through mobile phone call. Balata et
al. (2013b) showed that such method is usable and
navigator can successfully guide blind person in
outdoor environment. This is because the blind
person is able to efficiently describe his/her po-
sition. Balata et al. (2013a) found that there is
quite good coverage of locations that are very well
known to blind persons and that they should be
able to navigate other lost blind person there.
These findings show that building some kind of
assistance center where blind people can help each
other is a promising idea. Our intention is to ex-
tend such a center in a way that the helping per-
son will be replaced by natural language based di-
alog system. According to Pittermann (2005) this
dialog system belongs to the category “Dialog as
purposeful activity” with overlapping to the cate-
gory “Dialogue as collaborative activity”. The key
questions we focus on are:
</bodyText>
<listItem confidence="0.9929896">
• How the selection of an appropriate form of
language depends on aspects of the environ-
ment?
• What is the structure of the dialog with re-
spect to the environment?
</listItem>
<bodyText confidence="0.998812105263158">
In the initial step of this work-in-progress re-
search, we want to analyze the communication be-
tween lost blind person and the navigator in or-
der to analyze the dialog structure and make ini-
tial observation about the context information in-
terchange and verification dialog. Such dialog is
very important for navigator to find out, where ex-
actly the blind person get lost. With the knowl-
edge of the way of communication between lost
blind person and navigator we will be able in the
future replace the navigator with a navigation sys-
tem based on natural language understanding.
In order to gather and analyze initial data we
ran an experiment in which the blind person got
lost and was asked to call the assistance center
which mediated connection to suitable navigator.
Together, they tried to find the actual position of
blind person and they tried to navigate him/her to
end of the track.
</bodyText>
<page confidence="0.987429">
58
</page>
<note confidence="0.820334">
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 58–62,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.998906" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99994336">
Many current dialog systems are based on statisti-
cal approach when analyzing the semantics of spo-
ken dialog as presented by Jurcicek (2007). Us-
ing belief state tracking provides better results for
cases of noisy input. Ma et al. (2012) introduced
system that is combining geographical knowledge
of landmarks with dialog system itself and work
with probabilities of particular locations.
Recovering from lost scenario can be also com-
pared to robot localization problem as presented
by Thrun (1998) and Thrun et al. (2001), more
exactly to kidnapped robot problem, where robot
with knowledge of its position is moved to differ-
ent location without providing this information to
the robot. This scenario is testing the ability of
robot to recover from being lost while expecting
to be on another place. These methods are based
on probabilistic algorithms, working with proba-
bilities of measurement while being on a certain
place.
However we do not expect blind person to wear
any precise sensors for distance measurements and
localization, we can benefit from his/her senses
(touch, hearing and olfaction) that can provide set
of reliable observations.
</bodyText>
<sectionHeader confidence="0.9925" genericHeader="method">
3 Experiment Description
</sectionHeader>
<subsectionHeader confidence="0.998219">
3.1 Collected Data
</subsectionHeader>
<bodyText confidence="0.999969214285714">
We set up an experiment in order to collect and an-
alyze initial data about the dialog structure of lost
blind person and sighted navigator person. During
the experiment we recorded the course of the test
with two cameras, one was on the blind person’s
shoulder and one was used for 3rd person view of
the scene in order to show context (environment)
of the test. Moreover, we recorded the blind per-
son’s position using GPS coordinates in outdoor
and blind person’s interaction with mobile naviga-
tion application. Camera recordings and GPS logs
were used only for post-test evaluation. The di-
alog between the blind person and navigator was
recorded and annotated.
</bodyText>
<subsectionHeader confidence="0.997091">
3.2 Participants
</subsectionHeader>
<bodyText confidence="0.9999386">
For the experiment, 13 blind people, 8 female
and 5 male, were invited by e-mail and following
snowball effect. All the participants had blindness
of category 4 and 5 – according to ICD-10 WHO
classification.
</bodyText>
<subsectionHeader confidence="0.99885">
3.3 Procedure
</subsectionHeader>
<bodyText confidence="0.999935628571428">
In the experiment, we focused on three types of
location, two outdoor and one indoor: city cen-
ter streets (track A), open city park (track B) and
university building (track C). We selected these
three types of location in order to analyze possi-
ble differences in the dialog structure or types of
provided information.
The script of the experiment was similar for
each type of location. The participant was given a
mobile phone with mobile navigation application
for blind called NaviTerier Vystrcil et al. (2012).
NaviTerier provides TTS synthesized description
of the predefined track divided into segments. For
each segment the description of the environment
and navigation to the next segment was tailored
with respect to the way how blind people navi-
gate. Borders of segments are selected on places
that could be easily recognizable by blind people
(e.g. corner of building, doors, etc.). Each partici-
pant had a goal to go from start point to the end of
the track using the mobile navigation application
for blind. In order to put the participant into the
“recovery from lost” situation, the navigation in-
structions were intentionally modified to represent
a mistake in the track description (a realistic mis-
take), which caused that the participant get lost.
When the participant realized that he/she is lost,
a navigator from assistance center was called and
they tried to find out the location of blind person
and navigate him/her to the end of the track.
Navigator was seated in an office without visual
contact to lost blind person. He knew all three
routes very well. The only source of information
about the lost blind person was dialog done by a
phone call.
</bodyText>
<subsectionHeader confidence="0.773961">
3.3.1 Track A - City Center Streets
</subsectionHeader>
<bodyText confidence="0.999929692307692">
In track A the participant was asked to navigate
to the Vaclavska passage, see Figure 1. The nav-
igation instruction were changed so that the two
streets (Trojanova and Jenstejnska) were switched
so that the participant get lost at the T crossing of
Jenstejnska and Vaclavska street. The navigation
using the mobile navigation application for blind
in this type of environment was easy for partici-
pants and they all get lost at the desired location.
The navigator and participant had several nav-
igation points there to get oriented. First of all,
there was a nearby busy street Resslova, which can
be heard. Next there was a closed gateway with
</bodyText>
<page confidence="0.994725">
59
</page>
<bodyText confidence="0.999885333333333">
metal gate, which is quite unique for this location.
There were also waste bins (containers), phone
booth and entrance to the underground garage.
</bodyText>
<subsectionHeader confidence="0.657838">
3.3.2 Track B - Open City Park
</subsectionHeader>
<bodyText confidence="0.999954666666667">
In track B the participant was asked to navigate
through the park to the restaurant, see Figure 1.
The navigation instruction were changed so that
the two junctions were skipped and the participant
ended near the middle of the park, where fountain
is located.
In this type of location, there were also not
many unique navigation points. The most us-
able were two perpendicular streets with trams, the
fountain in the middle of the park and two unique
stairs. There were also multiple benches and grass
plots.
</bodyText>
<subsectionHeader confidence="0.536234">
3.3.3 Track C - Building
</subsectionHeader>
<bodyText confidence="0.999966375">
In track C the participant was asked to navigate
through the building from the entrance to the yard,
see Figure 1. The navigation instructions were
changed so that instead of taking stairs down, the
participant was asked to take stairs up and he/she
got lost in the small corridor, where the last doors
should be located but they were not there. The
navigation using the NaviTerier application in this
type of environment was easy for the participants
and they all get lost at the desired location.
At the place, where the participant got lost,
there were several navigation points. First point
was showcase from metal and glass at the expected
location of doors to the yard. Then there was
wooden door secured with metal bars and wooden
stairs going up and down.
</bodyText>
<sectionHeader confidence="0.999673" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.9900704">
In the track A and track C, the participants got lost
at location very well known to the navigator, thus
the identification of lost blind person location was
mostly fast and easy. In the track B, participants
got sometimes lost at locations unfamiliar for the
navigator due to the ambiguity of the environment
and thus the location identification process was
complicated.
The dialog structure of the communication be-
tween lost blind person and the navigator corre-
sponds to the model introduced by Balata et al.
(2013b). At the beginning the blind person de-
scribes his/her location, track instructions and the
problem description, i.e. what is the difference be-
tween instructions of navigation application and
</bodyText>
<figureCaption confidence="0.9579605">
Figure 1: Visualization of individual tracks A, B
and C used in the experiment. The intended path
</figureCaption>
<bodyText confidence="0.996051777777778">
is shown by solid line. Path shown by dashed line
shows the real path leading to the point, where the
participant got lost – yellow exclamation mark –
and from where the participant was navigated back
to the path.
reality. After the beginning the dialog continues
by iterative searching of unique navigation points
that may help the navigator to find the position and
orientation of the lost blind person, until he/she
gets to the location from which he/she can con-
tinue with the track. The dialog system should
take into account following findings about the di-
alog structure.
When the blind person get lost, he/she uses in-
formation, provided by navigation application for
sections that seemed to him/her correct and cor-
responding with reality, for description of his/her
current position, e.g. “I am in the Vaclavska
street.” The dialog system should take into ac-
count uncertainty of information provided by lost
blind person, possibility that the blind person got
lost much earlier and the navigation instructions
for next several segments were corresponding with
the reality by coincidence.
The fact that the blind person gets lost is lit-
tle bit stressy for him/her. Therefor he/she may
provide illogical answers to some questions, e.g.
</bodyText>
<page confidence="0.996375">
60
</page>
<bodyText confidence="0.998461423076923">
Q: “Could you provide me with the description of
your current position?” and A: “I would rather go
to the start of the track and describe the track from
the beginning.”
Description of current position of blind person
is very different from the description of sighted
person. The dialog system should take into ac-
count that the blind person may not find partic-
ular navigation point, but it does not mean that
the navigation point is not there. Moreover, some
navigation points may be difficult or impossible to
find by blind person. Similar issue is identifica-
tion of particular navigation points. The blind per-
son may have difficulties to distinguish between
bend, turning, intersection and end of pavement.
This may be misleading to dialog system. On the
other hand, when the blind person confirms that
particular navigation point was found, the system
should check, if it is really the one, e.g. when
doors are found, the system should check the ma-
terial or type of the doors.
Blind persons use other senses than sight to scan
the current position and navigation points. Even
though the senses are more sensitive, the provided
information may not be accurate, e.g. the blind
person is reporting inclining pavement and in real-
ity there is flat pavement.
It seems that the preferred sense is connected
with the type of environment. In the track B with
low density of navigation points which are am-
biguous the blind persons preferred hearing.
Some navigation points are not permanent and
may by varying. E.g. when there are two streets,
one near (not busy) and one far (busy) and the
blind person is asked to locate busy street, this
information will depend on the current traffic on
both streets. Together with the fact that term busy
is subjective, the blind person may locate wrong
street.
Some blind persons (the ones with high con-
fidence of independency and orientation skills)
tended to get oriented independently to the dialog
with navigator. That means they provided the nav-
igator with required information, but at the same
time they were moving and they were disrupting
the navigators mental model of the blind person’s
location.
There is not a standardized vocabulary how
blind persons describe objects. Therefore they
tend to use wide range of words and also
metaphoric descriptions to describe the same ob-
ject.
</bodyText>
<sectionHeader confidence="0.975868" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999990833333333">
In this paper, we did initial analysis of dialogs be-
tween blind person, who got lost when walking on
a track with the instructions from mobile naviga-
tion application, and navigator, who is trying to
help him get oriented. The research was done in
three different locations, in city center streets, in
open city park and in building. The dialog be-
tween blind person and navigator was recorded
and qualitatively analyzed in order to reveal dialog
features which can be used for improvement of the
navigation itself and later it can help to replace the
human navigator with automated system.
Initial analysis showed that the type of location
may have impact on strategy, how the blind per-
son explore his/her surroundings and how he/she
tries to get oriented. In city center streets (track
A) and in building (track C) the blind persons
were able to explore their surroundings and they
allowed the navigator to find out, where they prob-
ably are. In open city park (track B) the blind
persons had problem to find navigation points and
sometimes they were trying to get oriented inde-
pendently, which led to the difficulties for naviga-
tor to find their position. In many cases, the blind
persons were using the information from mobile
navigation application until the point where they
got lost. Unfortunately, such information may al-
ready be misleading. As a general finding, the dia-
log should focus also on verification of navigation
points, which may not be permanent (e.g. finding
busy street, when there are more streets around) or
which may be not identified in not enough detail.
In future, we would like to focus on individual
aspects found in qualitative analysis and design
strategies into the dialog model between lost blind
person and navigator and evaluate it quantitatively.
</bodyText>
<sectionHeader confidence="0.998363" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9988825">
This research has been supported by the project
Design of special user interfaces funded by
grant no. SGS13/213/OHK3/3T/13 (FIS 161 –
832130C000).
</bodyText>
<sectionHeader confidence="0.999304" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986026">
J. Balata, J. Franc, Z. Mikovec, and P. Slavik. 2013a.
Collaborative navigation of visually impaired. Jour-
nal on Multimodal User Interfaces, pages 1–11.
</reference>
<page confidence="0.983484">
61
</page>
<reference confidence="0.999619733333333">
J. Balata, Z. Mikovec, and J. Novacek. 2013b. Field
study: How Blind People Communicate While Re-
covering From Loss of Orientation. In Cognitive
Infocommunications (CogInfoCom), 2013 IEEE 4th
International Conference on, pages 313–317, Bu-
dapest. IEEE Hungary Section, University Obuda.
Filip Jurcicek. 2007. Statistical approach to the se-
mantic analysis of spoken dialogues.
Yi Ma, Antoine Raux, Deepak Ramachandran, and
Rakesh Gupta. 2012. Landmark-based location be-
lief tracking in a spoken dialog system. In Proceed-
ings of the 13th Annual Meeting of the Special In-
terest Group on Discourse and Dialogue, SIGDIAL
’12, pages 169–178, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Johannes Pittermann. 2005. Spoken dialogue tech-
nology: Toward the conversational user interface by
michael f. mctear. Comput. Linguist., 31(3):403–
406, September.
Sebastian Thrun, Dieter Fox, Wolfram Burgard, and
Frank Dellaert. 2001. Robust monte carlo local-
ization for mobile robots. Artificial Intelligence,
128(12):99 – 141.
Sebastian Thrun. 1998. Bayesian landmark learning
for mobile robot localization. Machine Learning,
33(1):41–76.
J. Vystrcil, Z. Mikovec, and P. Slavik. 2012. Naviterier
– indoor navigation system for visually impaired. In
SMART HOMES 2012, pages 25–28. Czech Techni-
cal University.
</reference>
<page confidence="0.999184">
62
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.241484">
<title confidence="0.999941">Navigation Dialog of Blind People: Recovery from Getting Lost</title>
<author confidence="0.998314">Jan Vystrcil</author>
<author confidence="0.998314">Ivo Maly</author>
<author confidence="0.998314">Jan Balata</author>
<author confidence="0.998314">Zdenek</author>
<affiliation confidence="0.843078">Czech Technical University in Prague, Faculty Of Electrical</affiliation>
<address confidence="0.701192">Karlovo nam. 13, 121 35 Praha</address>
<note confidence="0.4861995">Czech malyi1, balatjan,</note>
<abstract confidence="0.999692066666667">Navigation of blind people is different from the navigation of sighted people and there is also difference when the blind person is recovering from getting lost. In this paper we focus on qualitative analysis of dialogs between lost blind person and navigator, which is done through the mobile phone. The research was done in two outdoor and one indoor location. The analysis revealed several areas where the dialog model must focus on detailed information, like evaluation of instructions provided by blind person and his/her ability to reliably locate navigation points.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Balata</author>
<author>J Franc</author>
<author>Z Mikovec</author>
<author>P Slavik</author>
</authors>
<title>Collaborative navigation of visually impaired.</title>
<date>2013</date>
<journal>Journal on Multimodal User Interfaces,</journal>
<pages>1--11</pages>
<contexts>
<context position="1839" citStr="Balata et al. (2013" startWordPosition="292" endWordPosition="295"> needs precision at highest in meters). In such situation blind people typically use one of two following methods to recover. First they can ask people in their surrounding for help. Second they can call friend or dedicated assistance center. The first method is currently more favorable for blind people, but they have experience with both methods. In each method the dialog has different structure due to the different context information available to the helping person (called navigator) and lost blind person. In our research we focus on the second method, navigation through mobile phone call. Balata et al. (2013b) showed that such method is usable and navigator can successfully guide blind person in outdoor environment. This is because the blind person is able to efficiently describe his/her position. Balata et al. (2013a) found that there is quite good coverage of locations that are very well known to blind persons and that they should be able to navigate other lost blind person there. These findings show that building some kind of assistance center where blind people can help each other is a promising idea. Our intention is to extend such a center in a way that the helping person will be replaced b</context>
<context position="10400" citStr="Balata et al. (2013" startWordPosition="1727" endWordPosition="1730"> was wooden door secured with metal bars and wooden stairs going up and down. 4 Results and Discussion In the track A and track C, the participants got lost at location very well known to the navigator, thus the identification of lost blind person location was mostly fast and easy. In the track B, participants got sometimes lost at locations unfamiliar for the navigator due to the ambiguity of the environment and thus the location identification process was complicated. The dialog structure of the communication between lost blind person and the navigator corresponds to the model introduced by Balata et al. (2013b). At the beginning the blind person describes his/her location, track instructions and the problem description, i.e. what is the difference between instructions of navigation application and Figure 1: Visualization of individual tracks A, B and C used in the experiment. The intended path is shown by solid line. Path shown by dashed line shows the real path leading to the point, where the participant got lost – yellow exclamation mark – and from where the participant was navigated back to the path. reality. After the beginning the dialog continues by iterative searching of unique navigation p</context>
</contexts>
<marker>Balata, Franc, Mikovec, Slavik, 2013</marker>
<rawString>J. Balata, J. Franc, Z. Mikovec, and P. Slavik. 2013a. Collaborative navigation of visually impaired. Journal on Multimodal User Interfaces, pages 1–11.</rawString>
</citation>
<citation valid="false">
<authors>
<author>2013b</author>
</authors>
<title>Field study: How Blind People Communicate While Recovering From Loss of Orientation.</title>
<booktitle>In Cognitive Infocommunications (CogInfoCom), 2013 IEEE 4th International Conference on,</booktitle>
<pages>313--317</pages>
<institution>Budapest. IEEE Hungary Section, University Obuda.</institution>
<marker>2013b, </marker>
<rawString>J. Balata, Z. Mikovec, and J. Novacek. 2013b. Field study: How Blind People Communicate While Recovering From Loss of Orientation. In Cognitive Infocommunications (CogInfoCom), 2013 IEEE 4th International Conference on, pages 313–317, Budapest. IEEE Hungary Section, University Obuda.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filip Jurcicek</author>
</authors>
<title>Statistical approach to the semantic analysis of spoken dialogues.</title>
<date>2007</date>
<contexts>
<context position="4076" citStr="Jurcicek (2007)" startWordPosition="674" endWordPosition="675">e initial data we ran an experiment in which the blind person got lost and was asked to call the assistance center which mediated connection to suitable navigator. Together, they tried to find the actual position of blind person and they tried to navigate him/her to end of the track. 58 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 58–62, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work Many current dialog systems are based on statistical approach when analyzing the semantics of spoken dialog as presented by Jurcicek (2007). Using belief state tracking provides better results for cases of noisy input. Ma et al. (2012) introduced system that is combining geographical knowledge of landmarks with dialog system itself and work with probabilities of particular locations. Recovering from lost scenario can be also compared to robot localization problem as presented by Thrun (1998) and Thrun et al. (2001), more exactly to kidnapped robot problem, where robot with knowledge of its position is moved to different location without providing this information to the robot. This scenario is testing the ability of robot to reco</context>
</contexts>
<marker>Jurcicek, 2007</marker>
<rawString>Filip Jurcicek. 2007. Statistical approach to the semantic analysis of spoken dialogues.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Ma</author>
<author>Antoine Raux</author>
<author>Deepak Ramachandran</author>
<author>Rakesh Gupta</author>
</authors>
<title>Landmark-based location belief tracking in a spoken dialog system.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL ’12,</booktitle>
<pages>169--178</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4172" citStr="Ma et al. (2012)" startWordPosition="689" endWordPosition="692">e assistance center which mediated connection to suitable navigator. Together, they tried to find the actual position of blind person and they tried to navigate him/her to end of the track. 58 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 58–62, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work Many current dialog systems are based on statistical approach when analyzing the semantics of spoken dialog as presented by Jurcicek (2007). Using belief state tracking provides better results for cases of noisy input. Ma et al. (2012) introduced system that is combining geographical knowledge of landmarks with dialog system itself and work with probabilities of particular locations. Recovering from lost scenario can be also compared to robot localization problem as presented by Thrun (1998) and Thrun et al. (2001), more exactly to kidnapped robot problem, where robot with knowledge of its position is moved to different location without providing this information to the robot. This scenario is testing the ability of robot to recover from being lost while expecting to be on another place. These methods are based on probabili</context>
</contexts>
<marker>Ma, Raux, Ramachandran, Gupta, 2012</marker>
<rawString>Yi Ma, Antoine Raux, Deepak Ramachandran, and Rakesh Gupta. 2012. Landmark-based location belief tracking in a spoken dialog system. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL ’12, pages 169–178, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Pittermann</author>
</authors>
<title>Spoken dialogue technology: Toward the conversational user interface by michael f.</title>
<date>2005</date>
<journal>mctear. Comput. Linguist.,</journal>
<volume>31</volume>
<issue>3</issue>
<pages>406</pages>
<contexts>
<context position="2509" citStr="Pittermann (2005)" startWordPosition="410" endWordPosition="411">n successfully guide blind person in outdoor environment. This is because the blind person is able to efficiently describe his/her position. Balata et al. (2013a) found that there is quite good coverage of locations that are very well known to blind persons and that they should be able to navigate other lost blind person there. These findings show that building some kind of assistance center where blind people can help each other is a promising idea. Our intention is to extend such a center in a way that the helping person will be replaced by natural language based dialog system. According to Pittermann (2005) this dialog system belongs to the category “Dialog as purposeful activity” with overlapping to the category “Dialogue as collaborative activity”. The key questions we focus on are: • How the selection of an appropriate form of language depends on aspects of the environment? • What is the structure of the dialog with respect to the environment? In the initial step of this work-in-progress research, we want to analyze the communication between lost blind person and the navigator in order to analyze the dialog structure and make initial observation about the context information interchange and v</context>
</contexts>
<marker>Pittermann, 2005</marker>
<rawString>Johannes Pittermann. 2005. Spoken dialogue technology: Toward the conversational user interface by michael f. mctear. Comput. Linguist., 31(3):403– 406, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Thrun</author>
<author>Dieter Fox</author>
<author>Wolfram Burgard</author>
<author>Frank Dellaert</author>
</authors>
<title>Robust monte carlo localization for mobile robots.</title>
<date>2001</date>
<journal>Artificial Intelligence,</journal>
<volume>128</volume>
<issue>12</issue>
<pages>141</pages>
<contexts>
<context position="4457" citStr="Thrun et al. (2001)" startWordPosition="732" endWordPosition="735">henburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work Many current dialog systems are based on statistical approach when analyzing the semantics of spoken dialog as presented by Jurcicek (2007). Using belief state tracking provides better results for cases of noisy input. Ma et al. (2012) introduced system that is combining geographical knowledge of landmarks with dialog system itself and work with probabilities of particular locations. Recovering from lost scenario can be also compared to robot localization problem as presented by Thrun (1998) and Thrun et al. (2001), more exactly to kidnapped robot problem, where robot with knowledge of its position is moved to different location without providing this information to the robot. This scenario is testing the ability of robot to recover from being lost while expecting to be on another place. These methods are based on probabilistic algorithms, working with probabilities of measurement while being on a certain place. However we do not expect blind person to wear any precise sensors for distance measurements and localization, we can benefit from his/her senses (touch, hearing and olfaction) that can provide s</context>
</contexts>
<marker>Thrun, Fox, Burgard, Dellaert, 2001</marker>
<rawString>Sebastian Thrun, Dieter Fox, Wolfram Burgard, and Frank Dellaert. 2001. Robust monte carlo localization for mobile robots. Artificial Intelligence, 128(12):99 – 141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Thrun</author>
</authors>
<title>Bayesian landmark learning for mobile robot localization.</title>
<date>1998</date>
<booktitle>Machine Learning,</booktitle>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="4433" citStr="Thrun (1998)" startWordPosition="729" endWordPosition="730"> pages 58–62, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Related Work Many current dialog systems are based on statistical approach when analyzing the semantics of spoken dialog as presented by Jurcicek (2007). Using belief state tracking provides better results for cases of noisy input. Ma et al. (2012) introduced system that is combining geographical knowledge of landmarks with dialog system itself and work with probabilities of particular locations. Recovering from lost scenario can be also compared to robot localization problem as presented by Thrun (1998) and Thrun et al. (2001), more exactly to kidnapped robot problem, where robot with knowledge of its position is moved to different location without providing this information to the robot. This scenario is testing the ability of robot to recover from being lost while expecting to be on another place. These methods are based on probabilistic algorithms, working with probabilities of measurement while being on a certain place. However we do not expect blind person to wear any precise sensors for distance measurements and localization, we can benefit from his/her senses (touch, hearing and olfac</context>
</contexts>
<marker>Thrun, 1998</marker>
<rawString>Sebastian Thrun. 1998. Bayesian landmark learning for mobile robot localization. Machine Learning, 33(1):41–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Vystrcil</author>
<author>Z Mikovec</author>
<author>P Slavik</author>
</authors>
<title>Naviterier – indoor navigation system for visually impaired.</title>
<date>2012</date>
<booktitle>In SMART HOMES 2012,</booktitle>
<pages>25--28</pages>
<institution>Czech Technical University.</institution>
<contexts>
<context position="6545" citStr="Vystrcil et al. (2012)" startWordPosition="1073" endWordPosition="1076">ll the participants had blindness of category 4 and 5 – according to ICD-10 WHO classification. 3.3 Procedure In the experiment, we focused on three types of location, two outdoor and one indoor: city center streets (track A), open city park (track B) and university building (track C). We selected these three types of location in order to analyze possible differences in the dialog structure or types of provided information. The script of the experiment was similar for each type of location. The participant was given a mobile phone with mobile navigation application for blind called NaviTerier Vystrcil et al. (2012). NaviTerier provides TTS synthesized description of the predefined track divided into segments. For each segment the description of the environment and navigation to the next segment was tailored with respect to the way how blind people navigate. Borders of segments are selected on places that could be easily recognizable by blind people (e.g. corner of building, doors, etc.). Each participant had a goal to go from start point to the end of the track using the mobile navigation application for blind. In order to put the participant into the “recovery from lost” situation, the navigation instr</context>
</contexts>
<marker>Vystrcil, Mikovec, Slavik, 2012</marker>
<rawString>J. Vystrcil, Z. Mikovec, and P. Slavik. 2012. Naviterier – indoor navigation system for visually impaired. In SMART HOMES 2012, pages 25–28. Czech Technical University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>