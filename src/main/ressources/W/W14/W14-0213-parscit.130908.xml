<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001232">
<title confidence="0.878433">
Human pause and resume behaviours for
unobtrusive humanlike in-car spoken dialogue systems
</title>
<author confidence="0.809275">
Jens Edlund
</author>
<affiliation confidence="0.331561">
KTH Speech, Music and Hearing
</affiliation>
<address confidence="0.43211">
Stockholm
Sweden
</address>
<email confidence="0.980061">
edlund@speech.kth.se
</email>
<note confidence="0.571494">
Fredrik Edelstam
KTH Speech, Music and Hearing
Stockholm
Sweden
</note>
<email confidence="0.905375">
freede41@kth.se
</email>
<note confidence="0.727023666666667">
Joakim Gustafson
KTH Speech, Music and Hearing
Stockholm
</note>
<address confidence="0.532326">
Sweden
</address>
<email confidence="0.980448">
jocke@speech.kth.se
</email>
<sectionHeader confidence="0.993195" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999849294117647">
This paper presents a first, largely qualitative
analysis of a set of human-human dialogues
recorded specifically to provide insights in how
humans handle pauses and resumptions in
situations where the speakers cannot see each
other, but have to rely on the acoustic signal alone.
The work presented is part of a larger effort to find
unobtrusive human dialogue behaviours that can be
mimicked and implemented in-car spoken
dialogue systems within in the EU project Get
Home Safe, a collaboration between KTH, DFKI,
Nuance, IBM and Daimler aiming to find ways of
driver interaction that minimizes safety issues,. The
analysis reveals several human temporal,
semantic/pragmatic, and structural behaviours that
are good candidates for inclusion in spoken
dialogue systems.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999905175">
In-car spoken dialogue systems face specific
challenges that are of little or no relevance for
systems designed for other environments. The
two most striking of these are (1) the very strong
focus on safety in the driving situation and (2)
the fact that the person who speaks to the system
– its user, in other words the driver in the
majority of cases – does so in an environment
that may change quite drastically from the
beginning of an interaction to its completion. The
most straightforward source for this change is the
fact that the car (and the user) moves through the
environment while the dialogue progresses. The
dynamic and mobile nature of the surrounding
traffic adds to the complexity. Generally
speaking, safety is the key concern when
designing spoken dialogue systems for in-car use.
While poor performance in spoken dialogue
systems can clearly be a nuisance to a driver, the
promise of using properly designed spoken
dialogue instead of other interfaces is increased
safety. This promise is based in the nature of
speech: it does not require the driver to divert the
use hands and eyes from the driving, and it is a
mode of communication that most are quite used
to and comfortable with, so should not induce
great amounts of cognitive load.
We present a corpus consisting of a set of
human-human dialogues recorded specifically to
provide insights in how humans handle
interruptions - how they pause and resume
speaking - in situations where the speakers
cannot see each other, but have to rely on the
acoustic signal alone, and a preliminary analysis
of these which reveals several candidates for
inclusion in in-car spoken dialogue systems.
Finally, we discuss how these can be
implemented and how a selection of them are
included in the Get Home Safe experiment
implementation.
</bodyText>
<sectionHeader confidence="0.570242" genericHeader="introduction">
2 Background and related work
</sectionHeader>
<bodyText confidence="0.950154769230769">
In a government-commissioned survey from
2011, the Swedish National Road and Transport
Research Institute reviews several hundred
research publications on traffic safety and the use
of mobile phones and other communication
devices [Kircher et al., 2011]. Amongst the most
striking findings: although there is a broad
consensus that visual-manual interactions (e.g.
using social media or texting) with
communication devices impair driving
performance, bans have not had any measurable
effects in terms of lowered accident rates or
insurance claims. Ban compliance statistics show
</bodyText>
<page confidence="0.989894">
73
</page>
<note confidence="0.715822">
Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 73–77,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999926629032258">
that bans have an effect on driver behaviour the
first year, after which drivers return to their
former habits. With bans being virtually
ineffective, solutions must be sought elsewhere.
Allowing drivers to manage more tasks using
speech, which does not occupy hands and eyes,
would decrease the time spent in visual-manual
interaction while driving, provided that the
drivers can be persuaded to use the systems.
Clearly, the systems must work well - a large
proportion of errors may well put the driver at
risk (e.g. Kun et al., 2007). It is also unlikely that
drivers can be persuaded to use systems that do
not work well. But using hand-free and eyes-free
controls may not suffice. Kircher et al. (2011)
notes that there is virtually no evidence that
hands-free telephony is less risky than hand-held
use, suggesting that the conversations in
themselves may be a risk factor. Speaking to a
person who is present in the car and who shares
the driver’s situation, however, is much safer
(Peissner et al., 2011), suggesting that a system
that is perceived as and behaves like a co-present
human is a sensible aim. In the EU project Get
Home Safe, of which this research is a part, we
call such systems humanlike proactive systems.
Where a traditional spoken dialogue system
bases its decisions largely on (1) whether it has
something to say, (2) what the user has just said,
and (3) whether the user is speaking or is silent, a
humanlike proactive system will also consider (4)
the (traffic) situation, (5) the user’s (driver&apos;s)
estimated attention, and (6) the urgency of the
task at hand, much like a passenger might.
This paper focusses on two broad types of
proactive humanlike behaviours: user controlled
pacing, referring to the ability to pause at the
whim of the user in the middle of a conversation,
or even an utterance, and then resume the
conversation; and situation sensitive speech, the
ability to allow the situation to affect the manner
in which the system speaks. We are searching for
behaviours that people use when interrupted,
either by their interlocutor or by some event in
their environment, and when they resume the
original dialogue again. We are specifically
interested in behaviours that can be implemented
in the Get Home Safe architecture without major
changes to existing applications. The architecture
allows a central manager to instruct applications
to stop where they are and maintain their inner
state until instructed to either exit or continue
where they were.
The task has been approached by others, albeit
in different manners. Villing (2010) presents an
analysis of interruptions and resumptions in
human-human in-vehicle dialogues, as well as
implications for future in-car dialogue systems,
and Yang et al. (2011) used human-human multi-
tasking dialogues that involved a poker game as
the main task, and a picture game as an
interrupting real-time task.
</bodyText>
<sectionHeader confidence="0.996749" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.99999">
Our goal is to collect and analyse data that will
provide an insight to how a human speaker deals
with interruptions in in-car dialogue (our target
setting) and to find relevant behaviours that can
be successfully mimicked in an in-car human-
computer environment. The question can be
subdivided: How does a human speaker stop
speaking when faced with an (possible)
interruption? How does a human speaker resume
speaking after such an event? Which of these
behaviours are plausible candidates for inclusion
in a spoken dialogue system?
</bodyText>
<subsectionHeader confidence="0.994339">
3.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.999934714285714">
Setting. Collecting data from a real driving
situation is time consuming, not to say dangerous
when adding a secondary task. We have instead
opted to simulate the key elements of interest in
our dialogue recording studio – a safe recording
environment consisting of several physically
distinct locations that are interconnected with
low and constant latency audio and video. The
interlocutors were placed in different rooms, and
communicated through pairs of wireless close-
range microphones and loudspeakers.
Subjects. The purpose of this data collection is
not for example training a recognizer, but the
generation of a consistent set of candidate
</bodyText>
<page confidence="0.993549">
74
</page>
<bodyText confidence="0.999927845070423">
behaviours for implementation in a spoken
dialogue system – one that contains behaviours
that could all plausibly be used by the same
speaker. To achieve this, we consistently use the
same single male speaker in the role as the
system (“speaker”, hereafter) for all recordings.
For the user role (“listener”, hereafter), a
balanced variety of speakers were used: two sets
of 8 listeners, both balanced for gender, were
used. None of the listeners had any previous
knowledge of this research. All listeners were
rewarded with one cinema ticket. They were told
that those who performed the task best would
earn a second ticket, and the top performers from
each setup received a second ticket after the
recordings were completed.
Task. The data collection was designed as a dual
task experiment. The main task for the speaker
was to read three short informative texts about
each of three cities (Paris, Stockholm, and
Tokyo), arranged so that the first is quite general,
the second more specific, and the third deals with
a quite narrow detail with some connection to the
city. This task is equivalent to what one might
expect from a tourist information system. For the
listener, the main task is to listen to the city
information. The listener is motivated by the
knowledge that the reading of each segment -
that is each of the nine informative texts - is
followed by three questions on the content of the
text. Their performance in answering these
questions and in completing the secondary task
counted towards the extra movie ticket. The
secondary task was designed as follows. At
irregular, random intervals, a clearly visible
coloured circle would appear, either in front of
the speaker or the listener. When this happened,
the speaker was under obligation to stop the
narration and instead read a sequence of eight
digits from a list. The listener must then to repeat
the digit sequence back to the speaker, after
which the speaker could resume the narration.
Conditions. We considered two characteristics
of in-car interruptions that we assumed would
have an effect on how humans react to the
interruption and to how they resume speaking
after it: the source of an interruption can be
either internal or external in an in-car dialogue
(our target setting); and the duration and content
of an interruption varies, they can be brief or
even the result of a mistake, or they can be long
and contentful. The condition mapping to the
first of these characteristics was designed such
that the coloured circle signalling an interruption
was presented randomly to either the speaker,
mapping to en external event visible to the
system but not the driver, or to the listener,
mapping to an interruption from the driver to the
system (the listener had to speak up to inform the
speaker that the circle was present). The second
condition was designed such that in one set of
eight dialogues, the coloured circle would start
out yellow, and as soon as the speaker became
silent, it would randomly either disappear
(causing only a short interruption with light or no
content, corresponding to e.g. a false alarm) or
turn red, in which case the sequence of digits
would be read and repeated (a contentful
interruption). In the other set of eight recordings,
the circle always went straight to red, and always
caused digits to be read and repeated.
</bodyText>
<subsectionHeader confidence="0.999683">
3.2 Analysis
</subsectionHeader>
<bodyText confidence="0.9999845">
Each channel of each recording was segmented
into silence delimited speech segments
automatically, and these were transcribed using
Nuance Dragon Dictate. The transcriptions were
then corrected by a human annotator, and
labelled for interruptions and resumptions. In this
initial analysis, we looked at temporal statistics
(e.g. the durations between interruption from the
listener and silence from the speaker),
semantics/pragmatics (e.g. lexical choices,
insertions, repetitions) and syntax (e.g. where in
an utterance resumption begins).
</bodyText>
<sectionHeader confidence="0.999905" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999920142857143">
A categorical difference was found in the
distribution of speaker response times (from the
onset of a listener interruption to the offset of
speaker speech) depending on whether the
interruption occurred in the middle of a phrase or
close to the end of the phrase. In the first case,
the vast majority of the response times are
</bodyText>
<page confidence="0.997256">
75
</page>
<bodyText confidence="0.999983304347826">
distributed between 300 and 700 ms, with a clear
mode around 400 ms. Only a fraction of response
times are slower than 700 ms, and none except
one is faster than 300 ms. Phrase final
interruptions show an almost flat response time
distribution, with only a very weak mode around
500 ms, and a large proportion with response
times longer than 700 ms.
For lexical/pragmatic choices, we find a
categorical variation for the insertion of
vocalizations we somewhat lazily term filled
pauses (e.g. &amp;quot;eh&amp;quot;, &amp;quot;em&amp;quot;) and what we equally
lazily term lexical cue phrases (e.g. &amp;quot;right&amp;quot;, &amp;quot;ok&amp;quot;)
before resumption. The existence of such
insertions, as well as the choice of vocalization,
is straightforwardly dependant on the
contentfulness of the interruption. For short
interruptions of light content, filled pauses are
nearly never inserted before resumption. Lexical
cue phrases are inserted, but rarely. In the typical
case, the speaker goes straight back to the
informational text. For long, contentful
interruptions, resumption is initiated by an
insertion in an overwhelming majority of cases.
If the insertion consists of one vocalization only,
this is nearly always a filled pause. If more than
one vocalization is present, then lexical cue
phrases occur frequently, but overall, lexical cue
phrases are no more common here than in the
case of the short interruptions.
In the case of structural comparisons, the one
clear distinction we found has to do with what, if
any, material is repeated at resumption, a
characteristic that varies strongly with the type of
interruption. For long interruptions, in every
instance but a handful, the speaker either repeats
the entire utterance in which the interruption
occurs, or - in the few cases where an
interruption occurred just as an utterance came to
an end - with the next utterance. For short
interruptions, resumptions also start most
regularly from either the start of the current
utterance or from the start of the next one.
However, starts from the beginning or end of the
current phrase, word, or even part of word are
also frequent.
</bodyText>
<sectionHeader confidence="0.999226" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999990555555556">
We think that the three main findings presented
in the results are all good candidates for
implementation. The different distributions of
response times suggest that if an interruption
occurs centrally, in the midst of a production, the
speaker stops as fast as possible - the distribution
is largely consistent with reaction time
distributions. Towards the end of phrases, the
distribution is flat and quite different to what one
would expect if reaction time was the main
governing factor. The larger proportion of long
response times suggests that when the speaker is
close to the end of a phrase, finishing the phrase
first might be preferable to stopping as soon as
reaction permits. From an implementation
perspective, this is quite encouraging. In order to
create a behaviour consistent with this, we need
to halt system speech with a reaction time of
around 3-500ms. If possible (i.e. if the system
knows how much time remains of its production),
we may instead complete the utterance if less
than, say, 700ms remains.
Seemingly, short light content interruptions
need no specific signalling of resumption. If such
signalling is made, it is in the form of a lexical
cue phrase, such as &amp;quot;ok&amp;quot; or &amp;quot;right&amp;quot;. Resumptions
following longer, contentful interruptions are
routinely initiated by a filled pause. This may be
solely due to the speaker&apos;s need to find the
correct place in the script to start over, but it is
noteworthy that instead of doing this in silence,
the speaker opts to vocalize. For implementation,
resumptions following contentful subdialogues
should start with a filled pause and perhaps a
lexical cue phrase.
The straightforward interpretation of the third
finding is that in the case of short interruptions,
both speaker and listener have the point of
interruption in fresh memory, and need no
reminder, while long interruptions require the
speaker to help the listener out by recapitulating
what was last said. In the latter case, the system
can simply start over with its last utterance
(provided that it produces its synthesis on a
granularity of at least utterance level).
</bodyText>
<page confidence="0.97726">
76
</page>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9782475">
This work was funded by the GetHomeSafe (EU
7th Framework STREP project 288667).
</bodyText>
<sectionHeader confidence="0.995768" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999776904761905">
Kircher, K., Patten, C., &amp; Ahlström, C. (2011).
Mobile telephones and other communication devices
and their impact on traffic safety: a review of the
literature. Technical Report VTI 729A, Stockholm.
Kun, A., Paek, T., &amp; Medenica, Z. (2007). The effect
of speech interface accuracy on driving performance.
In Proc. of Interspeech 2007. Antwerp, Belgium.
Peissner, M., Doebler, V., &amp; Metze, F. (2011). Can
voice interaction help reducing the level of distraction
and prevent accidents? Meta-Study on Driver
Distraction and Voice Interaction. Technical Report,
Fraunhofer, Germany and CMU, USA, Aachen,
Germany.
Villing, J. (2010). Now, where was I? Resumption
strategies for an in-vehicle dialogue system. In The
48th Annual Meeting of the Association for
Computational Linguistics (pp. 798-805). Sweden.
Yang, F., Heeman, P. A., &amp; Kun, A. L. (2011). An
investigation of interruptions and resumptions in
multi-tasking dialogues. Computational inguistics,
27(1), 75-104.
</reference>
<page confidence="0.999126">
77
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.013067">
<title confidence="0.981009">Human pause and resume behaviours unobtrusive humanlike in-car spoken dialogue systems</title>
<author confidence="0.561088666666667">Jens KTH Speech</author>
<author confidence="0.561088666666667">Music</author>
<author confidence="0.561088666666667">Sweden</author>
<email confidence="0.854987">edlund@speech.kth.se</email>
<note confidence="0.242383166666667">Fredrik KTH Speech, Music and freede41@kth.se Joakim KTH Speech, Music and Sweden</note>
<email confidence="0.901441">jocke@speech.kth.se</email>
<abstract confidence="0.9985225">This paper presents a first, largely qualitative analysis of a set of human-human dialogues recorded specifically to provide insights in how humans handle pauses and resumptions in situations where the speakers cannot see each other, but have to rely on the acoustic signal alone. The work presented is part of a larger effort to find unobtrusive human dialogue behaviours that can be mimicked and implemented in-car spoken dialogue systems within in the EU project Get Home Safe, a collaboration between KTH, DFKI, Nuance, IBM and Daimler aiming to find ways of driver interaction that minimizes safety issues,. The analysis reveals several human temporal, semantic/pragmatic, and structural behaviours that are good candidates for inclusion in spoken dialogue systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Kircher</author>
<author>C Patten</author>
<author>C Ahlström</author>
</authors>
<title>Mobile telephones and other communication devices and their impact on traffic safety: a review of the literature.</title>
<date>2011</date>
<tech>Technical Report VTI 729A,</tech>
<location>Stockholm.</location>
<contexts>
<context position="3214" citStr="Kircher et al., 2011" startWordPosition="501" endWordPosition="504">he speakers cannot see each other, but have to rely on the acoustic signal alone, and a preliminary analysis of these which reveals several candidates for inclusion in in-car spoken dialogue systems. Finally, we discuss how these can be implemented and how a selection of them are included in the Get Home Safe experiment implementation. 2 Background and related work In a government-commissioned survey from 2011, the Swedish National Road and Transport Research Institute reviews several hundred research publications on traffic safety and the use of mobile phones and other communication devices [Kircher et al., 2011]. Amongst the most striking findings: although there is a broad consensus that visual-manual interactions (e.g. using social media or texting) with communication devices impair driving performance, bans have not had any measurable effects in terms of lowered accident rates or insurance claims. Ban compliance statistics show 73 Proceedings of the of the EACL 2014 Workshop on Dialogue in Motion (DM), pages 73–77, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics that bans have an effect on driver behaviour the first year, after which drivers return to their </context>
</contexts>
<marker>Kircher, Patten, Ahlström, 2011</marker>
<rawString>Kircher, K., Patten, C., &amp; Ahlström, C. (2011). Mobile telephones and other communication devices and their impact on traffic safety: a review of the literature. Technical Report VTI 729A, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kun</author>
<author>T Paek</author>
<author>Z Medenica</author>
</authors>
<title>The effect of speech interface accuracy on driving performance.</title>
<date>2007</date>
<booktitle>In Proc. of Interspeech</booktitle>
<location>Antwerp, Belgium.</location>
<contexts>
<context position="4253" citStr="Kun et al., 2007" startWordPosition="662" endWordPosition="665">burg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics that bans have an effect on driver behaviour the first year, after which drivers return to their former habits. With bans being virtually ineffective, solutions must be sought elsewhere. Allowing drivers to manage more tasks using speech, which does not occupy hands and eyes, would decrease the time spent in visual-manual interaction while driving, provided that the drivers can be persuaded to use the systems. Clearly, the systems must work well - a large proportion of errors may well put the driver at risk (e.g. Kun et al., 2007). It is also unlikely that drivers can be persuaded to use systems that do not work well. But using hand-free and eyes-free controls may not suffice. Kircher et al. (2011) notes that there is virtually no evidence that hands-free telephony is less risky than hand-held use, suggesting that the conversations in themselves may be a risk factor. Speaking to a person who is present in the car and who shares the driver’s situation, however, is much safer (Peissner et al., 2011), suggesting that a system that is perceived as and behaves like a co-present human is a sensible aim. In the EU project Get</context>
</contexts>
<marker>Kun, Paek, Medenica, 2007</marker>
<rawString>Kun, A., Paek, T., &amp; Medenica, Z. (2007). The effect of speech interface accuracy on driving performance. In Proc. of Interspeech 2007. Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Peissner</author>
<author>V Doebler</author>
<author>F Metze</author>
</authors>
<title>Can voice interaction help reducing the level of distraction and prevent accidents? Meta-Study on Driver Distraction and Voice Interaction.</title>
<date>2011</date>
<tech>Technical Report,</tech>
<location>Fraunhofer, Germany and CMU, USA, Aachen, Germany.</location>
<contexts>
<context position="4729" citStr="Peissner et al., 2011" startWordPosition="743" endWordPosition="746">ded to use the systems. Clearly, the systems must work well - a large proportion of errors may well put the driver at risk (e.g. Kun et al., 2007). It is also unlikely that drivers can be persuaded to use systems that do not work well. But using hand-free and eyes-free controls may not suffice. Kircher et al. (2011) notes that there is virtually no evidence that hands-free telephony is less risky than hand-held use, suggesting that the conversations in themselves may be a risk factor. Speaking to a person who is present in the car and who shares the driver’s situation, however, is much safer (Peissner et al., 2011), suggesting that a system that is perceived as and behaves like a co-present human is a sensible aim. In the EU project Get Home Safe, of which this research is a part, we call such systems humanlike proactive systems. Where a traditional spoken dialogue system bases its decisions largely on (1) whether it has something to say, (2) what the user has just said, and (3) whether the user is speaking or is silent, a humanlike proactive system will also consider (4) the (traffic) situation, (5) the user’s (driver&apos;s) estimated attention, and (6) the urgency of the task at hand, much like a passenge</context>
</contexts>
<marker>Peissner, Doebler, Metze, 2011</marker>
<rawString>Peissner, M., Doebler, V., &amp; Metze, F. (2011). Can voice interaction help reducing the level of distraction and prevent accidents? Meta-Study on Driver Distraction and Voice Interaction. Technical Report, Fraunhofer, Germany and CMU, USA, Aachen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Villing</author>
</authors>
<title>Now, where was I? Resumption strategies for an in-vehicle dialogue system.</title>
<date>2010</date>
<booktitle>In The 48th Annual Meeting of the Association for Computational Linguistics</booktitle>
<pages>798--805</pages>
<contexts>
<context position="6299" citStr="Villing (2010)" startWordPosition="1003" endWordPosition="1004">ystem speaks. We are searching for behaviours that people use when interrupted, either by their interlocutor or by some event in their environment, and when they resume the original dialogue again. We are specifically interested in behaviours that can be implemented in the Get Home Safe architecture without major changes to existing applications. The architecture allows a central manager to instruct applications to stop where they are and maintain their inner state until instructed to either exit or continue where they were. The task has been approached by others, albeit in different manners. Villing (2010) presents an analysis of interruptions and resumptions in human-human in-vehicle dialogues, as well as implications for future in-car dialogue systems, and Yang et al. (2011) used human-human multitasking dialogues that involved a poker game as the main task, and a picture game as an interrupting real-time task. 3 Method Our goal is to collect and analyse data that will provide an insight to how a human speaker deals with interruptions in in-car dialogue (our target setting) and to find relevant behaviours that can be successfully mimicked in an in-car humancomputer environment. The question c</context>
</contexts>
<marker>Villing, 2010</marker>
<rawString>Villing, J. (2010). Now, where was I? Resumption strategies for an in-vehicle dialogue system. In The 48th Annual Meeting of the Association for Computational Linguistics (pp. 798-805). Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Yang</author>
<author>P A Heeman</author>
<author>A L Kun</author>
</authors>
<title>An investigation of interruptions and resumptions in multi-tasking dialogues.</title>
<date>2011</date>
<journal>Computational inguistics,</journal>
<volume>27</volume>
<issue>1</issue>
<pages>75--104</pages>
<contexts>
<context position="6473" citStr="Yang et al. (2011)" startWordPosition="1026" endWordPosition="1029">he original dialogue again. We are specifically interested in behaviours that can be implemented in the Get Home Safe architecture without major changes to existing applications. The architecture allows a central manager to instruct applications to stop where they are and maintain their inner state until instructed to either exit or continue where they were. The task has been approached by others, albeit in different manners. Villing (2010) presents an analysis of interruptions and resumptions in human-human in-vehicle dialogues, as well as implications for future in-car dialogue systems, and Yang et al. (2011) used human-human multitasking dialogues that involved a poker game as the main task, and a picture game as an interrupting real-time task. 3 Method Our goal is to collect and analyse data that will provide an insight to how a human speaker deals with interruptions in in-car dialogue (our target setting) and to find relevant behaviours that can be successfully mimicked in an in-car humancomputer environment. The question can be subdivided: How does a human speaker stop speaking when faced with an (possible) interruption? How does a human speaker resume speaking after such an event? Which of th</context>
</contexts>
<marker>Yang, Heeman, Kun, 2011</marker>
<rawString>Yang, F., Heeman, P. A., &amp; Kun, A. L. (2011). An investigation of interruptions and resumptions in multi-tasking dialogues. Computational inguistics, 27(1), 75-104.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>