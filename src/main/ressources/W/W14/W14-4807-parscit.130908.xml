<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000732">
<title confidence="0.995348">
The ACL RD-TEC: A Dataset for Benchmarking Terminology Extraction
and Classification in Computational Linguistics
</title>
<author confidence="0.960928">
Behrang Q. Zadeh* and Siegfried Handschuh*†
</author>
<affiliation confidence="0.99418125">
*Insight Centre of Data Analytics
National University of Ireland, Galway
†Department of Computer Science and Mathematics
University of Passau, Germany
</affiliation>
<email confidence="0.850145">
{behrang.qasemizadeh, siegfried.handschuh}@insight-centre.org
</email>
<sectionHeader confidence="0.990994" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998924">
This paper introduces ACL RD-TEC: a dataset for evaluating the extraction and classification
of terms from literature in the domain of computational linguistics. The dataset is derived from
the Association for Computational Linguistics anthology reference corpus (ACL ARC). In its
first release, the ACL RD-TEC consists of automatically segmented, part-of-speech-tagged ACL
ARC documents, three lists of candidate terms, and more than 82,000 manually annotated terms.
The annotated terms are marked as either valid or invalid, and valid terms are further classified
as technology and non-technology terms. Technology terms signify methods, algorithms, and
solutions in computational linguistics. The paper describes the dataset and reports the relevant
statistics. We hope the step described in this paper encourages a collaborative effort towards
building a full-fledged annotated corpus from the computational linguistics literature.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.97297888">
Computational terminology (CT) embraces a set of algorithms that extract terms from domain-specific
corpora and arrange them in domain-specific knowledge structures such as a vocabulary, thesaurus or
ontology. Modern methods in CT often take a corpus-based, distributional approach to fulfil their tasks.
These methods exploit data-centric, data-sensitive techniques for mining and organizing terms. Evalu-
ation of these methods—as described in Vivaldi and Rodriguez (2007) and Nazarenko and Zargayouna
(2009)—is inherently a difficult task. Regardless of the employed metric and method for the perfor-
mance comparison of CT algorithms, however, choosing a shared dataset consisting of a fixed set of
documents—which can be accessed freely and easily—is a major step towards alleviating a number of
obstacles in the evaluation process. From a mathematical perspective, changes in the document set will
alter the underlying distribution of words and terms in the benchmark dataset. Consequently, this can
vary the performance of methods. From perspectives that involve meaning interpretation, as described
in L’Homme (2014), terms are defined against a context. This context is the representative of a special-
ized subject field and reflects the requirements of the intended application for the extracted terms. In an
evaluation dataset, the specialized subject field is largely defined by the set of documents in this dataset.
Therefore, variation in the set of documents can result in variant set of terms.
Creating datasets for benchmarking CT techniques have been addressed in several research efforts.
The GENIA corpus is a well-known example of such reference datasets in bio-text mining: a corpus
of 2000 abstracts from scientific publications in biological literature that is accompanied by the anno-
tations of 100,000 terms organized in a well-defined ontology (Kim et al., 2003). The Colorado Richly
Annotated Full Text Corpus (CRAFT) is another example of a bio-text mining dataset, which consists
of 97 articles from the PubMed Central Open Access subset annotated with biomedical concepts such as
‘mouse genes’ (Bada et al., 2012). In a more recent effort, Bernier-Colborne and Drouin (2014) report
on creating a corpus for the evaluation of term extraction in the domain of automotive engineering.
This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer
are added by the organizers. Licence details: http://creativecommons.org/licenses/by/4.0/
</bodyText>
<page confidence="0.978769">
52
</page>
<note confidence="0.984695">
Proceedings of the 4th International Workshop on Computational Terminology, pages 52–63,
Dublin, Ireland, August 23 2014.
</note>
<bodyText confidence="0.9998685">
The use of these datasets for CT research and terminology extraction has one obstacle: the minimal
prerequisite knowledge that is required to understand these specialized discourse and literature. This un-
derstanding of text is, perhaps, essential to enable a CT researcher to first comprehend and then describe
a linguistic phenomenon. Hence, conducting research in these specialized fields requires a training for
terminologists. For example, research in bio-text mining is often conducted by a team that includes ex-
perts in biology, bioinformaticians and computational linguists who have specialized training in this field.
Conducting CT research in these specialized domains, therefore, may not be the first choice for compu-
tational linguists who have a keen interest and specialized knowledge in the computational analysis of
languages—or want to train themselves to gain this knowledge.1
In this paper, we introduce the ACL RD-TEC: a Reference Dataset for Terminology Extraction and
Classification in the domain of computational linguistics. The ACL RD-TEC is drawn from the ACL
ARC (Bird et al., 2008). The ACL ARC is a fixed set of scholarly publications in the domain of compu-
tational linguistics. It has been developed with an aim to provide a platform for benchmarking methods
of scholarly document processing.2 We report further processes and annotations that have been carried
out on the ACL ARC in order to move a step closer to a reference dataset of familiar materials for the
CT research community.
Before describing the dataset, Section 2 delineates the terms that are used in this paper and gives a brief
summary of computational terminology. In Section 3, we explain the automatic and manual processes
performed to create the ACL RD-TEC and summarize the statistics of the current release. Finally, we
conclude and describe our goals for the immediate future in Section 4.
</bodyText>
<sectionHeader confidence="0.981646" genericHeader="method">
2 Computational Terminology
</sectionHeader>
<bodyText confidence="0.999068130434782">
Computational terminology inherits its complexity from the difficulties in the interpretation of meaning
in language. In terminology, these complications are often summarized by the question ‘what counts as
a term?’ The Oxford Dictionary defines a term as
‘a word or phrase used to describe a thing or to express a concept, specially in a particular kind
of language or branch of study’.
According to the International Organization for Standardization (ISO), a term is
‘a verbal designation of a general concept in a specific subject field (ISO 1087-1(2000))’.
As stated by Cabr´e (2010), linguistically, terms are lexical units and carry a special meaning in particular
contexts. A lexical unit is often considered as a lexical form—a single token, part of a word, a word or
a combination of these—that is paired with a single meaning and serves as the basic element of a lan-
guage’s vocabulary. As stated by L’Homme (2014), terms are the denomination of items of knowledge,
i.e. concepts.
According to their lexical forms, terms are usually classified as simple or complex. Simple terms
consist of one token; complex terms are composed of more than one token or word. For instance,
‘lexicography’ and ‘multilingual terminology management’ are, respectively, examples of a simple and
a complex term in the domain of computational linguistics. The extracted lexical units constitute a
terminological resource, also known as terminology: a specialized vocabulary of knowledge in a domain.
Terms and their use are studied in a relatively young discipline, which is also called terminology (Cabr´e,
2003; Kageura, 1999):
‘the field of activity concerned with the collection, description, processing and presentation of
terms (Sager, 1990)’.
While terminology can be approached from several perspectives, e.g. as a branch of philosophy, soci-
ology, or cognitive science, terminology is dominantly considered as a linguistic and cognitive activity.
</bodyText>
<footnote confidence="0.998591">
1Considering that knowledge and vocabulary are highly correlated, and vocabulary can be gained by exposure to literature.
2With an intuition similar to “eating your own dog food”, as proposed in Harrison (2006).
</footnote>
<page confidence="0.998353">
53
</page>
<figure confidence="0.9970495">
Concept Term Text
denotation
signify
writer
Concept Term reader
(a) General Theory of Terminology (b) Terms as Linguistic Units
</figure>
<figureCaption confidence="0.9999085">
Figure 1: Association of meaning in the GTT compared to recent theories of terminology: in the GTT,
terms are linguistic labels and denote concepts that exist a priori. In recent theories of terminology, e.g.
CTT, however, terms are treated like other linguistic units. They signify concepts in a communicative
context. In the figures above, the dashed lines indicate the direction in which the meaning of a term
is elaborated according to these theories. The indicated communicative context (the dotted triangle in
Figure b) can be extended in a number of ways, e.g. by considering the application of terms.
</figureCaption>
<figure confidence="0.9994192">
Concept Concept · · · Concept Term
Concept Concept ···
(c) Polysemous Relation
Term Term Term Term · · ·
(a) One-to-One Relation (b) Synonymous Relation
</figure>
<figureCaption confidence="0.95018">
Figure 2: Relationships between terms and the concepts they signify: Figure 2a illustrates a mono-
</figureCaption>
<bodyText confidence="0.977281961538462">
referential, unambiguous relationship between terms and concepts. Figure 2b shows an ambiguity that
may arise when several terms denote the same concept in a synonymous relation. Figure 2c illustrates an
ambiguous term-concept relation, a polysemous relationship where a term may denote several concepts.
Modern terminology is therefore pursued within a linguistic framework and as the study of specialized
languages (Faber, 2012).
The meanings of terms and the process of concept denomination are studied within the framework of
a ‘theory of terminology’. As stated in Cabr´e (2003), a theory of terminology elaborates the fundamental
problem of interpretation of meaning into a set of questions in which the definition of a terminological
unit—and its characteristics—is the nucleus. The general theory of terminology (GTT) by W¨uster (1974,
as cited in Campo (2013, chap. 2)) is recognized as the first theory of terminology. The GTT, which
is also known as traditional terminology, puts concepts first; terms are unambiguous linguistic labels
that are defined independently of the context in which they are used (L’Homme, 2014) (Figure 1a).
As implied by the given definition in ISO 1087-1(2000), the GTT is the most widely adopted theory
amongst terminologists.3 Consequently, the GTT regards terms and concepts as having mono-referential
relationships (Figure 2a). The objective behind GTT, understandably, is to eliminate ambiguity in natural
language to improve clarity in technical communication.
In an authoritative institutional organization that promotes or enforces standards, terms can be made
and shared in a top-down manner; hence, the meaning of terms can be interpreted by the mechanism
described in the GTT.4 However, in practice and in many organizations, new terms are introduced in a
bottom-up synthesis process. A lexical form (which may or may not be newly invented) in contexts that
bear a concept (which may or may not be newly invented) is used frequently inasmuch as it becomes
a term5 in the organization. In practice, therefore, terms can be ambiguous: a term can refer to several
concepts—similar to polysemy–homonymy in lexical semantics (Figure 2c); or, contrariwise, a particular
concept can be denoted by several terms (Figure 2b). Heid and Gojun (2012) suggest that the rapid
evolution of organizations as well as multi-players that are involved in an uncoordinated way, specifically
in multidisciplinary domains, reinforces this situation and thus term ambiguity.
</bodyText>
<tableCaption confidence="0.4451145">
3Accordingly, Felber (1982) defines terminology as ‘the combined action of groups of subject specialists (terminology
commissions) of specialised organisations’.
</tableCaption>
<footnote confidence="0.999694">
4it is, perhaps, best demonstrated in the applications of controlled natural languages.
5That is, a norm.
</footnote>
<page confidence="0.996681">
54
</page>
<figure confidence="0.977532">
... ...
</figure>
<figureCaption confidence="0.841979333333333">
Figure 3: Lexical unit extraction tasks and the scope of the meaning: the diagram can be extended by
adding new dimensions that take into the consideration characteristics of the communicative context
other than the text size.
</figureCaption>
<bodyText confidence="0.999979861111111">
In contrast to the GTT, recent theories of terminology, e.g. the communicative theory of terminology
(CTT) by Cabr´e (see 1999, chap. 3), acknowledges the situation stated above and takes a bottom-up
distributional approach to terminology in the sense that the meanings of terms, thus the elements of
domain knowledge, are not preconceived. Terms are linguistic units that are understood differently
with regards to the communicative context, e.g. by the text surrounding them, the application they are
used and so on. Terms signify concepts by syntagmatic and paradigmatic relations that they hold in a
specialized communicative discourse (Figure 1b).6 Methods that modern CT embraces, therefore, can
be distinguished and classified by the communicative context in which they are employed.
In CT, the task of automatic term recognition (ATR) is at the centre of attention. The input of ATR is a
large collection of documents, i.e. a domain-specific corpus, and the output is a terminological resource.
In ATR, the meaning of the generated terms is interpreted in a wide spectrum of concepts in the domain
that is being investigated and represented by the input corpus. ATR facilitates the automatic construction
of terminological resources; hence, it is a significant processing resource in knowledge engineering tasks
and applications such as information retrieval and machine translation.
As articulated by Kageura and Umino (1996), ATR deals with the computation of measures known as
unithood and termhood. It is believed that the majority of terms in a domain are complex terms. Unithood
indicates the degree to which a sequence of tokens can be combined to form a complex term. It is, thus,
a measure of the syntagmatic relation between the constituents of complex terms: a lexical association
measure to identify collocations. In the absence of explicit linguistic criteria for distinguishing complex
terms from other natural language text phrases, a unithood measure construes the problem of complex
term identification as the identification of stable lexical units (Sager, 1990).7
Termhood, on the other hand, ‘is the degree to which a stable lexical unit is related to some domain-
specific concepts’ (Kageura and Umino, 1996). It characterizes a paradigmatic relation between lex-
ical units—either simple or complex terms—and the communicative context that verbalizes domain-
concepts. Termhood, thus, envisages the measurement of meaning. In the absence of a formal answer
to the question ‘what domain-specific concepts are?’, devising a termhood measure for distinguishing
terms and non-terms is a difficult and often conflictual task—hence, the evaluation of CT.
In ATR, the communicative context is a domain-specific corpus. ATR, therefore, should not be con-
fused with other tasks in CT—such as keyword extraction, entity recognition, etc.—that bear a close
resemblance to it. These tasks are similar to ATR in the sense that they extract stable lexical units from
natural language text. However, they are different from ATR, because the meaning of the extracted
lexical units, thus the termhood measure, is interpreted in a context other than a domain-specific cor-
pus (Figure 3). For example, an automatic keyphrase extraction algorithm extracts lexical units from
a single document that best describe the content of this document. Both unithood and termhood must
be also measured in automatic keyphrase extraction. However, the criterion for their definition and the
information available for their computation are different than ATR.
</bodyText>
<footnote confidence="0.894893333333333">
6As can be understood, the main difference between the GTT and the CTT is the interpretation of the process of pairing
concepts and lexical forms that is mentioned in the definition of lexical units.
7See Evert (2004) on the application of lexical association measures for the identification of stable lexical units.
</footnote>
<page confidence="0.988188">
55
</page>
<figure confidence="0.9996614">
Term Mapping
Term Extraction
Term Classification
· · · Terminological Resource
Text
</figure>
<figureCaption confidence="0.9982295">
Figure 4: Significant processes in computational terminology and the direction in which they attach terms
and natural language text.
</figureCaption>
<figure confidence="0.995536">
Termhood
Text Candidate Term Extraction Scoring and Ranking Term List
Unithood
</figure>
<figureCaption confidence="0.999949">
Figure 5: Prevalent architecture of the terminology extraction methods.
</figureCaption>
<bodyText confidence="0.999984">
We can further distinguish CT methods based on the direction in which terms and text are related.
Recent developments of ontological resources have stimulated a research strand that targets the reverse
task of intermediary applications. The goal of these applications is to fill the gap between an available
ontology, i.e. a knowledge base, and natural language text. In these tasks, given a particular concept
in a knowledge base (e.g. a class and its instances in an ontology), a method—which we call term
mapping following Krauthammer and Nenadic (2004)—decides if this concept or its instances has been
mentioned in a given text snippet. Entity linking, which has been promoted through the series of Text
Analysis Conferences,8 is another term that characterizes these research efforts (see also Rao et al.,
2013). The familiar task of named entity recognition (NER), as introduced at the Message Understanding
Conference (Grishman and Sundheim, 1996), can also be placed in this category. In NER, the types of
target terms are known prior to the extraction task, e.g. city, location and so on.
In contrast to term mapping techniques, there are methods that organize constituent terms of a termino-
logical resource into a variety of classes. In these methods, the usage of terms in a given domain-specific
corpus is assessed to decide about their membership in concept classes. If the classes are known prior to
the assignment task, then the task is known as term classification; otherwise, if the classes are not known,
the task is called term clustering. As suggested by Krauthammer and Nenadic (2004), these three tasks—
i.e. term recognition, term classification and term mapping—are essential for automatic construction and
maintenance of terminological resources and to form a closed loop between terminology and natural
language text (Figure 4).
A more elaborate taxonomy of CT techniques can be obtained by distinguishing additional elements
and characteristics of the communicative context, e.g. the way in which an end user benefits from the
extracted terms, the role of background knowledge, linguistic characteristics of the extracted terms and
so on. We leave this study for another occasion.
</bodyText>
<subsectionHeader confidence="0.998928">
2.1 Prevalent Mechanism in Term Extraction Tasks
</subsectionHeader>
<bodyText confidence="0.999964076923077">
As suggested in Nakagawa (2001), the algorithms for term recognition are usually in the form of a two-
step procedure: candidate term extraction followed by term scoring and ranking (Figure 5).
Candidate term extraction deals with the term formation and the extraction of candidate terms. In a
few applications, candidate term extraction can assess the morphosyntactic structure of terms, e.g. as
suggested in Ananiadou (1994) and Zweigenbaum and Grabar (1999), to identify candidate terms. In
these methods, existing terminologies are often available before to the extraction task and employed to
identify new candidate terms. Besides this, one can identify four major methods for the extraction of
candidate terms: linguistic filtering based on part of speech (PoS) tag sequences, n-gram technique,
linguistic filtering based on syntactic relations and techniques that rely on the presence of particular
markers in text. Methods for the extraction of candidate terms are not limited to these categories. For
instance, contrastive approaches exploit a reference corpus of general language to identify simple can-
didate terms (Drouin, 2004, 2003); for complex terms, the comparison between corpora is followed by
one of the techniques listed above. A combination of these methods can also be employed to improve
</bodyText>
<footnote confidence="0.9797">
8http://www.nist.gov/tac/about/
</footnote>
<page confidence="0.996388">
56
</page>
<bodyText confidence="0.999773555555555">
the results (e.g. see Aubin and Hamon, 2006).
Linguistic filters in the form of PoS tag sequence patterns are the most widely adopted technique
for the extraction of candidate terms. In this method, any sequence of tokens with certain PoS tags are
assumed as candidate terms (Justeson and Katz, 1995; Daille, 1995). Likewise, the knowledge about PoS
patterns that cannot form candidate terms may be used to restrict the presence of token sequences in a
list of candidate terms (Bourigault, 1992). In the n-gram technique, however, any sequences of tokens of
length n, often 1 &lt; n &lt; 6, that appear in the input text are considered as candidate terms. This method
generates a large set of candidate terms. The number of candidate terms, therefore, is often reduced by
filtering n-grams that contain tokens from a stop-word list. When linguistic processing tools are lacking,
such as the case of under-resourced languages (see e.g. Pinnis et al., 2012), or the computational cost or
accuracy hinders their usage, the n-gram technique is favourable.
Linguistic filters that employ syntactic relations have also been used for the extraction of candidate
terms. The first sub-category of these methods use shallow parsing to identify noun phrases as candidate
terms (Nakagawa, 2001). The second sub-category of these methods generate candidate terms from
available terminological resources to identify term variations (Jacquemin and Tzoukermann, 1999). The
third subcategory, which is often employed for multilingual term extraction, exploits the head-modifier
principle to identify candidate terms (Hippisley et al., 2005). Finally, a category of candidate term
extraction methods takes advantage of the presence of specific markers in input text that can be used to
determine boundaries of terms, e.g. the presence of mark-up metadata in Hartmann et al. (2012).
Subsequent to candidate term extraction, a scoring procedure—which can be seen as a semantic
weighting mechanism—is employed to indicate how likely it is that a candidate term is a term we would
like to extract. As Figure 5 suggests, the scoring procedure usually combines termhood and unithood
scores. Although several categorizations of the scoring and ranking methods can be given from a method-
ological point of view (e.g. statistics-based, machine learning-based, rule-based, etc.) or by the kind of
information that is exploited for weighting (e.g. linguistic-based, statistical-based, hybrid) as stated ear-
lier, all these techniques rely on the text and take a corpus-based distributional approach to score and
rank terms. The usage of candidate terms in a communicative context (e.g. domain-corpus) is formulated
in a machine-tractable format, e.g. in the form of a contingency table or a vector space model. It is
then assessed using statistical measures, similarity metrics, language models or a set of rules, depending
on the method employed and the objective of the task in hand, which defines the type of paradigmatic
relation that the termhood measure characterizes.
The c-value algorithm, for instance, is an statistical method of assigning scores to candidate terms in
an ATR task. It is used as a baseline in a number of ATR evaluation tasks. For each candidate term t, the
c-value score of t is calculated using four criteria (Frantzi et al., 1998): the frequency of t in the corpus;
the frequency of t when it appears nested in other terms longer than t; the number of those longer terms
shown by Tt; and the number of the constituent words of t shown by |t|. The c-value score is given by
</bodyText>
<equation confidence="0.859595833333333">
c-value(t) =
�
log2 |t|f (t) if t V nested
log2 |t  |(f (t) − |Tt |E
∈
b
</equation>
<bodyText confidence="0.874122">
Tt f (b)) otherwise ,(1)
where Tt denotes the set of all the terms that contain t and are longer than t, and f(s) denotes the
frequency of an arbitary term s in the corpus. Other widely applied statistical measures for termhood
assements in ATR include term frequency–inverse document frequency (tf -idf ), term frequency (tf ),
and inverse document frequency (idf ). We leave the study of scoring mechanisms for another occasion.
</bodyText>
<sectionHeader confidence="0.99421" genericHeader="method">
3 The ACL RD-TEC: Further Annotation Layers for ACL ARC
</sectionHeader>
<bodyText confidence="0.990517">
We introduce the ACL RD-TEC, a spin-off of the ACL ARC. In its first release, the ACL RD-TEC
consists of manual annotations that can be used for the evaluation of ATR and term classification tasks
that are explained in the previous section. The current release of the ACL ARC consists of 10,922 articles
that were published between 1965 to 2006. The provided resources in the ACL ARC consist of three
layers: (a) source publications in portable document format (PDF), (b) automatically extracted text from
</bodyText>
<page confidence="0.986433">
57
</page>
<table confidence="0.993121">
Type Token Sentence Paragraph Section Publication
704,085 36,729,513 1,564,430 510,366 92,935 10,922
</table>
<tableCaption confidence="0.994756">
Table 1: Summary statistics of the dataset derived from automatic processing of the ACL ARC.
</tableCaption>
<table confidence="0.9945985">
PoS Tag JJ NN NNP VBG FW (Total)
Frequency 150 17,120 4,520 1255 2 (23,047)
</table>
<tableCaption confidence="0.755614">
Table 2: Summary statistics of the assigned PoS tags to the simple term ‘parsing’. The PoS tags are from
the Penn Treebank PoS tagset.
</tableCaption>
<bodyText confidence="0.999668892857143">
the articles and (c) bibliographic metadata and citation network. Each of the articles in the collection
are assigned to a unique identifier that indicates the source (e.g. journal or conference) and the date (e.g.
1999, 2006, etc.) of publication.
In the preparation of ACL RD-TEC, we further employed the SectLabel module of Luong et al.’s
(2010) ParsCit tool9 for the automatic identification of logical text sections in ACL ARC’s raw text
files. Using a set of heuristics, sections such as ‘bibliography’ and ‘acknowledgements’ are removed
from the corpus and are organized in separate files. In addition, text cleaning is performed, e.g. broken
words and text segments are joined, footnotes and captions are removed and sections are organised into
paragraphs. The sectioning process is followed by the text segmentation process using the OpenNLP
sentence splitter10 and the Stanford tokenizer. The text is then annotated by the Stanford PoS tagger.11
The process is finalized by making an inverted index of the cleansed full-text documents and assigning
unique identifiers to each one of the extracted linguistic units: types (i.e. PoS-tagged and lemmatized
words), sentences, paragraphs and (sub)sections. All of these units are stored in separate flat tables, in
which all units, except types, are presented as tuples, consisting of pairs of unique identifiers and their
relative locations in the text units they constitute. Therefore, text units can be easily traced back to the
publications that they appeared in. The statistics of the resulting data are given in Table 1.
Afterwards, candidate terms are extracted from the processed corpus using three methods: PoS-based
filtering, n-gram-based technique and noun phrase (NP) chunking. In order to devise PoS sequence
patterns and maximum length of candidate terms, we started with an observation of sample valid terms,
their PoS sequences patterns and length in the corpus. We extracted 3301 sentences that contained the
lemma ‘technology’. We then identified 476 valid terms in these sentences, 65% of which had lengths
of 2 and 3 tokens; only 5% were longer than 5 tokens.12 Similar to the method proposed by Ittoo et al.
(2010), to alleviate the problem of erroneous PoS tagging, we formulated the PoS patterns for candidate
term extraction based on the actual output of the employed PoS tagger. All the occurrences of the
identified terms were searched for in the corpus and all the PoS tag sequences assigned to them were
extracted. Amongst the 100 extracted patterns, to keep a balance between correct and incorrect patterns
resulted from erroneous PoS tagging, we chose 31 patterns Pli of maximum length 5 that satisfy the
equation
</bodyText>
<equation confidence="0.7333055">
f(Pli) 1 (2)
Ej:length(Pj)=l f(Pj) &gt; 10l,
</equation>
<bodyText confidence="0.999771">
where f denotes the frequency of a PoS pattern and l is its length.
For example, the term ‘parsing’ is extracted as a valid term in this procedure. This simple term is
encountered 23,047 times in the corpus. As shown in Table 2, the employed PoS tagger assigned several
different PoS tags to this term. Assuming that these PoS tags are the only patterns of length 1, only
NN and NNP satisfy the given formula in Equation 2 above and are added to the inventory of valid PoS
patterns for terms of length l = 1. The rest of PoS patterns—VBG, JJ and FW—are discarded. As it can
be understood from the right hand side of the equation, when the length of PoS patterns increases, the
stated criteria for their selection process becomes easier (e.g. 0.01 for terms of length l = 2 instead of
</bodyText>
<footnote confidence="0.99947">
9Release version 110505 (http://aye.comp.nus.edu.sg/parsCit/).
10Release version 1.5.2 (http://opennlp.apache.org/).
11Release date 9 July 2012; see Toutanova et al. (2003) for a description of the PoS tagger tagset.
12We eliminate definite and indefinite determiners from the terms.
</footnote>
<page confidence="0.99568">
58
</page>
<table confidence="0.9983015">
Method Total# Length = 1 Length = 2 Length = 3 Length = 4 Length = 5
PoS-based 1, 322, 445 271, 064 741, 448 284, 725 23, 384 1, 824
n-gram 9, 339, 303 236, 053 1, 054, 792 2, 187, 041 2, 880, 665 2, 980, 752
NP Chunk 1, 813, 222 142, 636 706, 051 623, 633 248, 505 92, 397
</table>
<tableCaption confidence="0.999901">
Table 3: Summary statistics of the extracted candidate terms.
</tableCaption>
<bodyText confidence="0.988749124999999">
0.1 for terms of length l = 1). The list of devised PoS patterns is included in the distributed package.
We repeated the procedure described above by extracting sentences that contain lemmas other than
‘technology’, e.g. ‘algorithm’, ‘method’, ‘framework’and ‘theory’. There is no evidence to support that
the extracted patterns are specific to a category of terms (e.g. technology terms). These patterns seem
to be generic enough to extract terms of any category. We support this claim based on the conducted
manual verification of the extracted candidate terms. In these extracted sentences, the only terms that are
longer than 5 tokens are various transliteration of the term ‘very-large-vocabulary speaker-independent
continuous speech recognition’. Based on these observations and the previous studies reported on the
length of terms (e.g. see Maynard, 2000; Bonin et al., 2010), we believe the maximum length of 5 tokens
is a fair trade-off between accuracy and recall in the process of candidate term extraction.
The sentences in the corpus are scanned for occurrences of the devised PoS patterns. Any sequences
of tokens that conform to any of these patterns is considered as a candidate term. The extracted token
sequences construct the list of PoS-based candidate terms. Based on the above observation, in the n-
gram-based extraction of candidate terms, n is set to 1 ≤ n ≤ 5 tokens. In addition, n-grams that
begin with a token from a stop-word list13 are discarded. The remaining n-grams form the second list
of candidate terms. The extracted sentences from the corpus are also chunked by the OpenNLP chunker.
NP chunks that are not longer than 5 tokens constitute the third list of candidate terms. As other lists of
candidate terms, determiners are removed from the NP chunks. From all the above lists, we eliminate
candidates that are shorter than 3 characters. Candidate terms are further augmented by their frequency in
the corpus, distinct documents, sections, and paragraphs and stored separately. Table 3 shows a summary
statistics of the extracted candidate terms.
In an ideal scenario, each occurrence of a candidate term in each sentence could have been annotated
to identify the particular concept–class that the term signals in that context. Such annotations could
have been used in all the tasks described in the previous section. In the absence of an agreed taxonomy
of concepts and classes for computational linguistics and—more importantly—the required resources to
carry out this complex manual annotation task, achieving the ideal goal at once and in a single step seems
infeasible. In order to keep it manageable, we begin the manual annotation task by the verification of the
candidate terms in vocabulary lists as is suggested in the previous evaluations of ATR algorithms.
To proceed with the annotation task, the extracted candidate terms are sorted using scores that are
obtained from several ATR algorithms, e.g. the c-value score (Equation 1). The annotators are provided
with an annotation guideline, consisting of basic definitions (such as the given description in the earlier
sections), rules (e.g. how to deal with term variation, misspelled terms and so on) and examples.14 During
this process, the annotators are provided with a tool to access concordance view of candidate terms in
the ACL ARC corpus.15 The annotators are asked to envisage a mind map of computational linguistics
topics and perceive the candidate terms in this map. For a given lexical form t in the list of candidate
terms, if t refers to a significant concept in the computational linguistics domain,16 the annotators are ask
to mark t as valid. However, this does not guarantee that all the occurrences of t in the corpus are valid
terms. For instance, ‘natural language’ is a lexical form that appears in the corpus as a term on several
occasions, e.g. in
‘· · · a natural language is a scheme of communication· · · ’.
</bodyText>
<footnote confidence="0.9985544">
13The SMART stop-word list built by Chris Buckley and Gerard Salton, which can be obtained from goo.gl/rBQNbO.
14The annotator guideline can be accessed in the distributed package.
15We used the preloaded version of the ACL ARC in the Sketch Engine Corpus Query System available at https://the.
sketchengine.co.uk/bonito/run.cgi/first_form?corpname=preloaded/aclarc_1
16That is, if they can situate the term in their envisaged mind map.
</footnote>
<page confidence="0.99314">
59
</page>
<table confidence="0.9997344">
Total# Length = 1 Length = 2 Length = 3 Length = 4 Length = 5
Technology Terms 13,832 757 8,674 3,822 538 41
Invalid Terms 61,818 15,908 33,502 11,027 1,211 170
Valid Terms 22,027 1,495 14,146 5,677 657 52
Total Annotated 83,845 17,403 47,648 16,704 1,868 222
</table>
<tableCaption confidence="0.99201">
Table 4: Summary statistics of the annotated candidate terms.
</tableCaption>
<table confidence="0.976021333333333">
Valid Terms Candidate Terms
Technology Terms All Possible Terms
Annotated Terms
</table>
<figureCaption confidence="0.8008205">
Figure 6: Relationships between candidate terms, valid terms, technology terms and annotated terms.
Candidate term extraction extracts a subset of all possible terms. ATR targets the identification of valid
terms amongst candidate terms. Technology terms are a subset of valid terms. The dashed area shows
the set of annotated terms.
</figureCaption>
<bodyText confidence="0.990218516129032">
However, there are a number of occurrences of ‘natural language’ that cannot be considered as term, e.g.
‘· · · the speech and natural language groups at SRI reported results · · · ’.
On the other hand, if t is annotated as invalid, then there must be no occurrence of t in the corpus that
can be counted as a term. In the current version, 83,845 terms are annotated as either valid or invalid.
Furthermore, valid terms in the annotated list of terms are classified as those that can signal a technol-
ogy concept. If ‘genes’ are an essential category of concepts in an ontology that characterizes biological
discipline, we speculate that the presence of technology as a category of concepts is essential in any
ontology or terminological resource that describes an applied discipline like computational linguistics.
As to our definition, technology terms indicate concepts such as methods, algorithms and processes that
are designed, developed and employed to accomplish a certain task in order to fulfil a practical purpose,
i.e. to address a research problem (see also the task in Kovaevi et al., 2012). In computational linguistics,
examples of these terms are ‘parsing’, ‘information retrieval’, and more delicate terms such as ‘linear
interpolation’.
In order to distinguish technology terms amongst other categories of terms, annotators are provided
with several definitions of technology and its known examples in computational linguistics.17 In addi-
tion, the annotators are exposed to materials on philosophy of technology, e.g. Franssen et al. (2013),
and introduced to the task of ‘tech mining’ in Porter and Cunningham (2005). Despite all these efforts,
because establishing a precise definition of technology is infeasible, classification of valid terms to tech-
nology and non-technology terms, to a great extent, relies on the intuition of experts who participated in
the annotation task. The annotators are allowed to use other sources of information than the ACL ARC,
e.g. web search, in order to decide about the technology class membership of valid terms. The process of
annotating technology terms in the lists of extracted candidate terms is facilitated by supervised machine
learning-based methods of term weighting, e.g. as reported in Zadeh and Handschuh (2014a,b). Table 4
shows the current statistics of the annotated terms. Figure 6 illustrates relationships between candidate
terms, valid terms and technology terms.
Similar to the valid terms, terms that are annotated as technology terms do not exclusively belong to
this class. For example, ‘computational linguistics’ is a lexical form that can be classified as a technology
term, e.g., in
‘· · · promising area of application of computational linguistics techniques· · · ’.
However, it can also signal other concepts such as a scientific discipline, e.g. in
‘· · · theoretical work in computational linguistics· · · ’
</bodyText>
<footnote confidence="0.488859">
17Those terms that are explicitly named as technology in literature are taken as the examples of technology terms. To make
a list of examples, we identified these terms using simple patterns such as ‘· · · X is a technology· · · ’.
</footnote>
<page confidence="0.953302">
60
</page>
<figure confidence="0.998065461538461">
1 Terms Technology Terms Only
0.8
0.6
0.4
0.2
Proportion of 0.3 c-value (PoS-based)
Postive Examples to n 0.2 c-value (n-gram)
0.1 c-value (NP chunk)
0 tf-idf (PoS-based)
tf-idf (n-gram)
tf-idf (NP chunk)
0 500 1,000 1,500 2,000 0 500 1,000 1,500 2,000
Topn Verified Terms Topn Verified Terms
</figure>
<figureCaption confidence="0.999888">
Figure 7: Comparison between c-value and tf -idf .
</figureCaption>
<bodyText confidence="0.999604580645161">
, as well as a community, e.g. in
‘· · · pursued by the computational linguistics community · · · ’.
The data, perhaps, speaks better for itself. Thus, we invite the interested reader to explore the annotated
set of terms in order to gain more insight into the performed annotation task. The dataset can be obtained
freely from the European Language Resources Association, catalogue reference ELRA-T0375.18
While we hope more researchers become involved in the annotation task, in the current release, all
the annotations are made by one person. In order to assess the quality and reliability of the annotations,
we carried out two preliminary experiments. In the first experiment, a list of terms consisting of 250
terms that have been particularly difficult to annotate are annotated by a researcher who is familiar with
terminology. For example, we particularly found it hard and conflicting to annotate terms that start with
words such as ‘automatic, automated, stat-of-the-art, scalable, rapid, full, fast’ and so on, e.g. in terms
such as ‘fast clustering, ‘fast classification, and ‘fast prototyping. In addition, deciding on the inclusion
of certain categories of terms is difficult. For example, one may consider ‘people’ and ‘organizations’ as
valid domain terms, while another person—with her own specific interest and expertise—may consider
these as invalid terms. This problem is more subtle about categories such as ‘languages’ and ‘linguistic
units’. For instance, one may consider ‘English’ and ‘French’ as well as ‘clitic’ and ‘suffix’ as terms;
however, another person may not consider them as valid terms in the domain of computational linguistics
(e.g. one may found them too generic to be considered as valid terms). As to our experience, the more
specific we are about the concept categories, the easier it is to annotate the terms. We made sure sample
of these terms are included in the assessment of the annotations. We report an observed agreement Ao
of 0.758 and Cohen’kappa coefficient I. of 0.517 for this set of terms (see Artstein and Poesio, 2008, for
definition of Ao and I.).
In the second experiment, two postgrad students in the area of natural language processing were given a
list of 389 terms and asked to identify technology terms. The list of annotated terms were then compared
with the annotations in the dataset. The results are Ao = 0.840 and I. = 0.655 for the first comparison
and Ao = 0.775 and I. = 0.533 for the second comparison. These measures over the annotations
generated by the participants in the evaluation task are Ao = 0.828 and I. = 0.627.
As a usage example of the constructed dataset, we use the annotations for the comparison of the top
n terms in the list of candidate terms that are weighted and sorted using Frantzi et al.’s (1998) c-value
and term frequency–inverse document frequency (tf -idf ). We hope other researchers in the domain are
intrigued by the numbers reported in Figure 7 and report the performance of other algorithms.
</bodyText>
<sectionHeader confidence="0.997329" genericHeader="conclusions">
4 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.987785">
The saying ‘the shoemaker’s son goes barefoot’ is perhaps true when it comes to the state of termino-
logical resources that characterize computational linguistics domain. We report a small action towards
</bodyText>
<footnote confidence="0.724467">
18http://catalog.elra.info/index.php; the annotated terms are also available from https://github.
com/languagerecipes/the-acl-rd-tec.
</footnote>
<page confidence="0.998657">
61
</page>
<bodyText confidence="0.999970785714286">
building a terminological resource from the ACL ARC, which can be used for the evaluation of compu-
tational terminology methods. There are currently three sets of candidate terms, which are augmented by
their frequency in various logical text segments in the corpus and are presented in tabulated inverse index
files. More than 82,000 of these terms are annotated manually as valid and invalid, in which valid terms
are further classified as technology and non-technology terms. The built resource can facilitate the eval-
uation of a number of methods in computational terminology. We invite other researchers to embellish
the dataset by adding their own lists of candidate terms and manual annotations.
During the annotation process we have identified several frequent concepts other than technology and
methods in the computational linguistics domain, e.g. grammar formalism, theories, measures, language
resources, tasks and applications. We hope to continue our effort by adding annotations for at least one
of these concepts. Adding a new concept class will allow us to evaluate term disambiguation methods.
The application of clustering techniques for identification of term variations amongst the annotated terms
and their manual annotation is another goal that can be achieved in the near future. These small steps,
collectively, can provide the shoemaker’s son with a fine pair of leather boots.
</bodyText>
<sectionHeader confidence="0.996935" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9980652">
We thank the anonymous reviewers for their constructive comments, which helped us to improve the
paper. In addition, we thank Professor Marie-Claude L’Homme for her helpful advice. We also thank
Kartik Asooja, Georgeta Bordea, Sapna Negi and Bianca Pereira who participated in the inter-annotator
agreement experiment. This publication has emanated from research supported in part by a research
grant from Science Foundation Ireland (SFI) under Grant Number SFI/12/RC/2289.
</bodyText>
<sectionHeader confidence="0.995122" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991412866666667">
2000. ISO 1087-1:2000 terminology — vocabulary — part 1: Theory and application.
Sophia Ananiadou. 1994. A methodology for automatic term recognition. In Proceedings of the 15th conference on Computa-
tional linguistics - Volume 2, COLING ’94, pages 1034–1038.
Ron Artstein and Massimo Poesio. 2008. Inter-coder agreement for computational linguistics. Comput. Linguist., 34(4).
Sophie Aubin and Thierry Hamon. 2006. Improving term extraction with terminological resources. In Advances in Natural
Language Processing, LNCS 4139, pages 380–387.
Michael Bada, Miriam Eckert, Donald Evans, Kristin Garcia, Krista Shipley, Dmitry Sitnikov, William Baumgartner, K Cohen,
Karin Verspoor, Judith Blake, and Lawrence Hunter. 2012. Concept annotation in the craft corpus. BMC Bioinformatics,
13(1):161.
Gabriel Bernier-Colborne and Patrick Drouin. 2014. Creating a test corpus for term extractors through term annotation. Termi-
nology, 20:1:5073.
Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson, Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett Powley, Dragomir
Radev, and Yee Fan Tan. 2008. The ACL anthology reference corpus: A reference dataset for bibliographic research in
computational linguistics. In LREC’08. Marrakech, Morocco.
Francesca Bonin, Felice Dell’Orletta, Simonetta Montemagni, and Giulia Venturi. 2010. A contrastive approach to multi-word
extraction from domain-specific corpora. In LREC’10. ELRA, Valletta, Malta.
Didier Bourigault. 1992. LEXTER: a natural language tool for terminology extraction. In COLING ’92. pages 977–981.
M. Teresa Cabr´e. 1999. TERMINOLOGY: THEORY, METHODS AND APPLICATIONS. John Benjamins.
M. Teresa Cabr´e. 2003. Theories of terminology their description, prescription and explanation. Terminology, 9:2:163–199.
M. Teresa Cabr´e. 2010. Handbook of translation studies, volume 1, chapter Terminology and translation, pages 356–365.
M. Teresa Cabr´e, Anne Condamines, and Fidelia Ibekwe-SanJuan. 2005. Introduction: Application-driven terminology engi-
neering. Terminology, 11:1–19(18).
´Angela Campo. 2013. The reception of Eugen Wsters work and the development of terminology. Ph.D. thesis, Universit´e de
Montr´eal.
Beatrice Daille. 1995. Combined approach for terminology extraction: lexical statistics and linguistic filtering. Technical
report, UCREL, Lancaster University.
Patrick Drouin. 2003. Term extraction using non-technical corpora as a point of leverage. Terminology, 9(1):99–115.
Patrick Drouin. 2004. Detection of domain specific terminology using corpora comparison. In LREC’04.
Stefan Evert. 2004. The Statistics of Word Cooccurrences Word Pairs and Collocations. Ph.D. thesis, Institut f¨ur maschinelle
Sprachverarbeitung, Universit¨at Stuttgart.
</reference>
<page confidence="0.980803">
62
</page>
<reference confidence="0.999755672413793">
Pamela Faber. 2012. A cognitive linguistics view of terminology and specialized language, volume 20, chapter Terminology
and Specialized Language, pages 13–33. Walter de Gruyter.
Helmut Felber. 1982. Computerized terminology in termnet: The role of terminological data banks. Term banks for tomorrows
world: Translating and the Computer, 4:8–20.
Maarten Franssen, Gert-Jan Lokhorst, and Ibo van de Poel. 2013. Philosophy of technology. In The Stanford Encyclopedia of
Philosophy. Winter 2013 edition.
KaterinaT. Frantzi, Sophia Ananiadou, and Junichi Tsujii. 1998. The c-value/nc-value method of automatic recognition for
multi-word terms. In Research and Advanced Technology for Digital Libraries, LNCS 1513, pages 585–604.
Ralph Grishman and Beth Sundheim. 1996. Message understanding conference-6: A brief history. In Proceedings of COLING
(Vol. 96)., pages 466–471.
Warren Harrison. 2006. Eating your own dog food. IEEE Software, 23(3):5–7.
Silvana Hartmann, Gy¨orgy Szarvas, and Iryna Gurevych. 2012. Mining multiword terms from wikipedia. In Semi-Automatic
Ontology Development: Processes and Resources, pages 226–258. IGI Global, Hershey, PA, USA.
Ulrich Heid and Anita Gojun. 2012. Term candidate extraction for terminography and cat: and overview of ttc. In Proceedings
of the 15th Euralex International Congress. Oslo, Norway.
Andrew Hippisley, David Cheng, and Khurshid Ahmad. 2005. The head-modifier principle and multilingual term extraction.
Nat. Lang. Eng., 11(2):129–157.
Ashwin Ittoo, Laura Maruster, Hans Wortmann, and Gosse Bouma. 2010. Textractor: A framework for extracting relevant
domain concepts from irregular corporate textual datasets. In BIS, LNBIP 47, pages 71–82. Springer.
Christian Jacquemin and Evelyne Tzoukermann. 1999. NLP for term variant extraction: synergy between morphology, lexicon
and syntax. Natural language information retrieval, 7:25–74.
John S. Justeson and Slava M. Katz. 1995. Technical terminology: some linguistic properties and an algorithm for identification
in text. Nat. Lang. Eng., 1.1:9–27.
Kyo Kageura. 1999. On the study of dynamics of terminology: A proposal of a theoretical framework. Research Bulletin of the
NACSIS, 11:1–10.
Kyo Kageura and Bin Umino. 1996. Methods of automatic term recognition: A review. Terminology, 3.2 (1996):259–289.
J.. D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. Genia corpus—a semantically annotated corpus for bio-textmining.
Bioinformatics, 19(suppl 1):i180–i182.
Aleksandar Kovaevi, Zora Konjovi, Branko Milosavljevi, and Goran Nenadic. 2012. Mining methodologies from nlp publica-
tions: A case study in automatic terminology recognition. Computer Speech &amp; Language, 26(2):105 – 126.
Michael Krauthammer and Goran Nenadic. 2004. Term identification in the biomedical literature. J. of Biomedical Informatics,
37(6):512–526.
Marie-Claude L’Homme. 2014. Terminologies and taxonomies. Oxford Handbooks Online.
Minh-Thang Luong, Thuy Dung Nguyen, and Min-Yen Kan. 2010. Logical structure recovery in scholarly articles with rich
document features. IJDLS, 1(4):1–23.
Diana Maynard. 2000. Term recognition using combined knowledge sources. Ph.D. thesis, Manchester Metropolitan University.
Hiroshi Nakagawa. 2001. Automatic term recognition based on statistics of compound nouns. Terminology, 6.2:195–210.
Adeline Nazarenko and Haifa Zargayouna. 2009. Evaluating term extraction. In Proceedings of the International Conference
RANLP-2009, pages 299–304. Association for Computational Linguistics, Borovets, Bulgaria.
M¯arcis Pinnis, Nikola Ljubeˇsi´c, Dan S¸tef˘anescu, Inguna Skadin¸a, Marko Tadi´c, and Tatiana Gornostay. 2012. Term extraction,
tagging, and mapping tools for under-resourced languages. In TKE 2012.
Alan L Porter and Scott W Cunningham. 2005. Tech mining. Competitive Intelligence Magazine, 8(1):30–36.
Delip Rao, Paul McNamee, and Mark Dredze. 2013. Entity linking: Finding extracted entities in a knowledge base. In Multi-
source, Multilingual Information Extraction and Summarization, Theory and Applications of Natural Language Processing.
Juan C. Sager. 1990. Practical Course in Terminology Processing, chapter Term Formation: theory and practice, pages 61–87.
John Benjamins Publishing Company.
Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In NAACL ’03. pages 173–180.
Jorge Vivaldi and Horacio Rodr¨ıguez. 2007. Evaluation of terms and term extraction systems: A practical approach. Terminol-
ogy. 13:225–248.
Eugen W¨uster. 1974. Die allgemeine terminologielehre–ein grenzgebiet zwischen sprachwissenschaft, logik, ontologie, infor-
matik und den sachwissenschaften. Linguistics, 12(119):61–106.
Behrang Q. Zadeh and Siegfried Handschuh. 2014a. Evaluation of technology term recognition with random indexing.
LREC’14. ELRA, Reykjavik, Iceland.
Behrang Q. Zadeh and Siegfried Handschuh. 2014b. Investigating context parameters in technology term recognition. COLING
Workshop on Synchronic and Diachronic Approaches to Analyzing Technical Language (SADAATL).
Pierre Zweigenbaum and Natalia Grabar. 1999. Automatic acquisition of morphological knowledge for medical language
processing. In Artificial Intelligence in Medicine, LNCS 1620, pages 416–420.
</reference>
<page confidence="0.999463">
63
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.839938">
<title confidence="0.9949725">The ACL RD-TEC: A Dataset for Benchmarking Terminology Extraction and Classification in Computational Linguistics</title>
<author confidence="0.851186">Q</author>
<author confidence="0.851186">Siegfried</author>
<affiliation confidence="0.999286">Centre of Data National University of Ireland, of Computer Science and University of Passau,</affiliation>
<abstract confidence="0.999337545454545">This paper introduces ACL RD-TEC: a dataset for evaluating the extraction and classification of terms from literature in the domain of computational linguistics. The dataset is derived from the Association for Computational Linguistics anthology reference corpus (ACL ARC). In its first release, the ACL RD-TEC consists of automatically segmented, part-of-speech-tagged ACL documents, three lists of candidate terms, and more than annotated terms. The annotated terms are marked as either valid or invalid, and valid terms are further classified Technology terms signify methods, algorithms, and solutions in computational linguistics. The paper describes the dataset and reports the relevant statistics. We hope the step described in this paper encourages a collaborative effort towards building a full-fledged annotated corpus from the computational linguistics literature.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>ISO 1087-1:2000 terminology — vocabulary — part 1: Theory and application.</title>
<date>2000</date>
<contexts>
<context position="6452" citStr="(2000)" startWordPosition="946" endWordPosition="946">future in Section 4. 2 Computational Terminology Computational terminology inherits its complexity from the difficulties in the interpretation of meaning in language. In terminology, these complications are often summarized by the question ‘what counts as a term?’ The Oxford Dictionary defines a term as ‘a word or phrase used to describe a thing or to express a concept, specially in a particular kind of language or branch of study’. According to the International Organization for Standardization (ISO), a term is ‘a verbal designation of a general concept in a specific subject field (ISO 1087-1(2000))’. As stated by Cabr´e (2010), linguistically, terms are lexical units and carry a special meaning in particular contexts. A lexical unit is often considered as a lexical form—a single token, part of a word, a word or a combination of these—that is paired with a single meaning and serves as the basic element of a language’s vocabulary. As stated by L’Homme (2014), terms are the denomination of items of knowledge, i.e. concepts. According to their lexical forms, terms are usually classified as simple or complex. Simple terms consist of one token; complex terms are composed of more than one tok</context>
<context position="10238" citStr="(2000)" startWordPosition="1529" endWordPosition="1529"> of terminology elaborates the fundamental problem of interpretation of meaning into a set of questions in which the definition of a terminological unit—and its characteristics—is the nucleus. The general theory of terminology (GTT) by W¨uster (1974, as cited in Campo (2013, chap. 2)) is recognized as the first theory of terminology. The GTT, which is also known as traditional terminology, puts concepts first; terms are unambiguous linguistic labels that are defined independently of the context in which they are used (L’Homme, 2014) (Figure 1a). As implied by the given definition in ISO 1087-1(2000), the GTT is the most widely adopted theory amongst terminologists.3 Consequently, the GTT regards terms and concepts as having mono-referential relationships (Figure 2a). The objective behind GTT, understandably, is to eliminate ambiguity in natural language to improve clarity in technical communication. In an authoritative institutional organization that promotes or enforces standards, terms can be made and shared in a top-down manner; hence, the meaning of terms can be interpreted by the mechanism described in the GTT.4 However, in practice and in many organizations, new terms are introduce</context>
</contexts>
<marker>2000</marker>
<rawString>2000. ISO 1087-1:2000 terminology — vocabulary — part 1: Theory and application.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Ananiadou</author>
</authors>
<title>A methodology for automatic term recognition.</title>
<date>1994</date>
<journal>Ron Artstein</journal>
<booktitle>In Proceedings of the 15th conference on Computational linguistics -</booktitle>
<volume>2</volume>
<pages>1034--1038</pages>
<contexts>
<context position="18963" citStr="Ananiadou (1994)" startWordPosition="2859" endWordPosition="2860">erms, the role of background knowledge, linguistic characteristics of the extracted terms and so on. We leave this study for another occasion. 2.1 Prevalent Mechanism in Term Extraction Tasks As suggested in Nakagawa (2001), the algorithms for term recognition are usually in the form of a twostep procedure: candidate term extraction followed by term scoring and ranking (Figure 5). Candidate term extraction deals with the term formation and the extraction of candidate terms. In a few applications, candidate term extraction can assess the morphosyntactic structure of terms, e.g. as suggested in Ananiadou (1994) and Zweigenbaum and Grabar (1999), to identify candidate terms. In these methods, existing terminologies are often available before to the extraction task and employed to identify new candidate terms. Besides this, one can identify four major methods for the extraction of candidate terms: linguistic filtering based on part of speech (PoS) tag sequences, n-gram technique, linguistic filtering based on syntactic relations and techniques that rely on the presence of particular markers in text. Methods for the extraction of candidate terms are not limited to these categories. For instance, contra</context>
</contexts>
<marker>Ananiadou, 1994</marker>
<rawString>Sophia Ananiadou. 1994. A methodology for automatic term recognition. In Proceedings of the 15th conference on Computational linguistics - Volume 2, COLING ’94, pages 1034–1038. Ron Artstein and Massimo Poesio. 2008. Inter-coder agreement for computational linguistics. Comput. Linguist., 34(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophie Aubin</author>
<author>Thierry Hamon</author>
</authors>
<title>Improving term extraction with terminological resources.</title>
<date>2006</date>
<booktitle>In Advances in Natural Language Processing, LNCS 4139,</booktitle>
<pages>380--387</pages>
<contexts>
<context position="19927" citStr="Aubin and Hamon, 2006" startWordPosition="3000" endWordPosition="3003">tag sequences, n-gram technique, linguistic filtering based on syntactic relations and techniques that rely on the presence of particular markers in text. Methods for the extraction of candidate terms are not limited to these categories. For instance, contrastive approaches exploit a reference corpus of general language to identify simple candidate terms (Drouin, 2004, 2003); for complex terms, the comparison between corpora is followed by one of the techniques listed above. A combination of these methods can also be employed to improve 8http://www.nist.gov/tac/about/ 56 the results (e.g. see Aubin and Hamon, 2006). Linguistic filters in the form of PoS tag sequence patterns are the most widely adopted technique for the extraction of candidate terms. In this method, any sequence of tokens with certain PoS tags are assumed as candidate terms (Justeson and Katz, 1995; Daille, 1995). Likewise, the knowledge about PoS patterns that cannot form candidate terms may be used to restrict the presence of token sequences in a list of candidate terms (Bourigault, 1992). In the n-gram technique, however, any sequences of tokens of length n, often 1 &lt; n &lt; 6, that appear in the input text are considered as candidate t</context>
</contexts>
<marker>Aubin, Hamon, 2006</marker>
<rawString>Sophie Aubin and Thierry Hamon. 2006. Improving term extraction with terminological resources. In Advances in Natural Language Processing, LNCS 4139, pages 380–387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Bada</author>
<author>Miriam Eckert</author>
<author>Donald Evans</author>
<author>Kristin Garcia</author>
<author>Krista Shipley</author>
<author>Dmitry Sitnikov</author>
<author>William Baumgartner</author>
<author>K Cohen</author>
<author>Karin Verspoor</author>
<author>Judith Blake</author>
<author>Lawrence Hunter</author>
</authors>
<title>Concept annotation in the craft corpus.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="3469" citStr="Bada et al., 2012" startWordPosition="489" endWordPosition="492">ts for benchmarking CT techniques have been addressed in several research efforts. The GENIA corpus is a well-known example of such reference datasets in bio-text mining: a corpus of 2000 abstracts from scientific publications in biological literature that is accompanied by the annotations of 100,000 terms organized in a well-defined ontology (Kim et al., 2003). The Colorado Richly Annotated Full Text Corpus (CRAFT) is another example of a bio-text mining dataset, which consists of 97 articles from the PubMed Central Open Access subset annotated with biomedical concepts such as ‘mouse genes’ (Bada et al., 2012). In a more recent effort, Bernier-Colborne and Drouin (2014) report on creating a corpus for the evaluation of term extraction in the domain of automotive engineering. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. Licence details: http://creativecommons.org/licenses/by/4.0/ 52 Proceedings of the 4th International Workshop on Computational Terminology, pages 52–63, Dublin, Ireland, August 23 2014. The use of these datasets for CT research and terminology extraction has one obstacle: the min</context>
</contexts>
<marker>Bada, Eckert, Evans, Garcia, Shipley, Sitnikov, Baumgartner, Cohen, Verspoor, Blake, Hunter, 2012</marker>
<rawString>Michael Bada, Miriam Eckert, Donald Evans, Kristin Garcia, Krista Shipley, Dmitry Sitnikov, William Baumgartner, K Cohen, Karin Verspoor, Judith Blake, and Lawrence Hunter. 2012. Concept annotation in the craft corpus. BMC Bioinformatics, 13(1):161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Bernier-Colborne</author>
<author>Patrick Drouin</author>
</authors>
<title>Creating a test corpus for term extractors through term annotation.</title>
<date>2014</date>
<tech>Terminology,</tech>
<pages>20--1</pages>
<contexts>
<context position="3530" citStr="Bernier-Colborne and Drouin (2014)" startWordPosition="498" endWordPosition="501">ddressed in several research efforts. The GENIA corpus is a well-known example of such reference datasets in bio-text mining: a corpus of 2000 abstracts from scientific publications in biological literature that is accompanied by the annotations of 100,000 terms organized in a well-defined ontology (Kim et al., 2003). The Colorado Richly Annotated Full Text Corpus (CRAFT) is another example of a bio-text mining dataset, which consists of 97 articles from the PubMed Central Open Access subset annotated with biomedical concepts such as ‘mouse genes’ (Bada et al., 2012). In a more recent effort, Bernier-Colborne and Drouin (2014) report on creating a corpus for the evaluation of term extraction in the domain of automotive engineering. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. Licence details: http://creativecommons.org/licenses/by/4.0/ 52 Proceedings of the 4th International Workshop on Computational Terminology, pages 52–63, Dublin, Ireland, August 23 2014. The use of these datasets for CT research and terminology extraction has one obstacle: the minimal prerequisite knowledge that is required to understand th</context>
</contexts>
<marker>Bernier-Colborne, Drouin, 2014</marker>
<rawString>Gabriel Bernier-Colborne and Patrick Drouin. 2014. Creating a test corpus for term extractors through term annotation. Terminology, 20:1:5073.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Robert Dale</author>
<author>Bonnie Dorr</author>
<author>Bryan Gibson</author>
<author>Mark Joseph</author>
<author>Min-Yen Kan</author>
<author>Dongwon Lee</author>
<author>Brett Powley</author>
<author>Dragomir Radev</author>
<author>Yee Fan Tan</author>
</authors>
<title>The ACL anthology reference corpus: A reference dataset for bibliographic research in computational linguistics.</title>
<date>2008</date>
<booktitle>In LREC’08.</booktitle>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="5082" citStr="Bird et al., 2008" startWordPosition="723" endWordPosition="726">d by a team that includes experts in biology, bioinformaticians and computational linguists who have specialized training in this field. Conducting CT research in these specialized domains, therefore, may not be the first choice for computational linguists who have a keen interest and specialized knowledge in the computational analysis of languages—or want to train themselves to gain this knowledge.1 In this paper, we introduce the ACL RD-TEC: a Reference Dataset for Terminology Extraction and Classification in the domain of computational linguistics. The ACL RD-TEC is drawn from the ACL ARC (Bird et al., 2008). The ACL ARC is a fixed set of scholarly publications in the domain of computational linguistics. It has been developed with an aim to provide a platform for benchmarking methods of scholarly document processing.2 We report further processes and annotations that have been carried out on the ACL ARC in order to move a step closer to a reference dataset of familiar materials for the CT research community. Before describing the dataset, Section 2 delineates the terms that are used in this paper and gives a brief summary of computational terminology. In Section 3, we explain the automatic and man</context>
</contexts>
<marker>Bird, Dale, Dorr, Gibson, Joseph, Kan, Lee, Powley, Radev, Tan, 2008</marker>
<rawString>Steven Bird, Robert Dale, Bonnie Dorr, Bryan Gibson, Mark Joseph, Min-Yen Kan, Dongwon Lee, Brett Powley, Dragomir Radev, and Yee Fan Tan. 2008. The ACL anthology reference corpus: A reference dataset for bibliographic research in computational linguistics. In LREC’08. Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesca Bonin</author>
<author>Felice Dell’Orletta</author>
<author>Simonetta Montemagni</author>
<author>Giulia Venturi</author>
</authors>
<title>A contrastive approach to multi-word extraction from domain-specific corpora.</title>
<date>2010</date>
<booktitle>In LREC’10. ELRA,</booktitle>
<location>Valletta,</location>
<marker>Bonin, Dell’Orletta, Montemagni, Venturi, 2010</marker>
<rawString>Francesca Bonin, Felice Dell’Orletta, Simonetta Montemagni, and Giulia Venturi. 2010. A contrastive approach to multi-word extraction from domain-specific corpora. In LREC’10. ELRA, Valletta, Malta.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Didier Bourigault</author>
</authors>
<title>LEXTER: a natural language tool for terminology extraction.</title>
<date>1992</date>
<booktitle>In COLING ’92.</booktitle>
<tech>TERMINOLOGY: THEORY, METHODS AND</tech>
<pages>pages</pages>
<contexts>
<context position="20378" citStr="Bourigault, 1992" startWordPosition="3075" endWordPosition="3076">echniques listed above. A combination of these methods can also be employed to improve 8http://www.nist.gov/tac/about/ 56 the results (e.g. see Aubin and Hamon, 2006). Linguistic filters in the form of PoS tag sequence patterns are the most widely adopted technique for the extraction of candidate terms. In this method, any sequence of tokens with certain PoS tags are assumed as candidate terms (Justeson and Katz, 1995; Daille, 1995). Likewise, the knowledge about PoS patterns that cannot form candidate terms may be used to restrict the presence of token sequences in a list of candidate terms (Bourigault, 1992). In the n-gram technique, however, any sequences of tokens of length n, often 1 &lt; n &lt; 6, that appear in the input text are considered as candidate terms. This method generates a large set of candidate terms. The number of candidate terms, therefore, is often reduced by filtering n-grams that contain tokens from a stop-word list. When linguistic processing tools are lacking, such as the case of under-resourced languages (see e.g. Pinnis et al., 2012), or the computational cost or accuracy hinders their usage, the n-gram technique is favourable. Linguistic filters that employ syntactic relation</context>
</contexts>
<marker>Bourigault, 1992</marker>
<rawString>Didier Bourigault. 1992. LEXTER: a natural language tool for terminology extraction. In COLING ’92. pages 977–981. M. Teresa Cabr´e. 1999. TERMINOLOGY: THEORY, METHODS AND APPLICATIONS. John Benjamins. M. Teresa Cabr´e. 2003. Theories of terminology their description, prescription and explanation. Terminology, 9:2:163–199. M. Teresa Cabr´e. 2010. Handbook of translation studies, volume 1, chapter Terminology and translation, pages 356–365.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Teresa Cabr´e</author>
<author>Anne Condamines</author>
<author>Fidelia Ibekwe-SanJuan</author>
</authors>
<title>Introduction: Application-driven terminology engineering.</title>
<date>2005</date>
<journal>Terminology,</journal>
<volume>19</volume>
<issue>18</issue>
<marker>Cabr´e, Condamines, Ibekwe-SanJuan, 2005</marker>
<rawString>M. Teresa Cabr´e, Anne Condamines, and Fidelia Ibekwe-SanJuan. 2005. Introduction: Application-driven terminology engineering. Terminology, 11:1–19(18).</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Angela Campo</author>
</authors>
<title>The reception of Eugen Wsters work and the development of terminology.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>Universit´e de Montr´eal.</institution>
<contexts>
<context position="9906" citStr="Campo (2013" startWordPosition="1476" endWordPosition="1477">onship where a term may denote several concepts. Modern terminology is therefore pursued within a linguistic framework and as the study of specialized languages (Faber, 2012). The meanings of terms and the process of concept denomination are studied within the framework of a ‘theory of terminology’. As stated in Cabr´e (2003), a theory of terminology elaborates the fundamental problem of interpretation of meaning into a set of questions in which the definition of a terminological unit—and its characteristics—is the nucleus. The general theory of terminology (GTT) by W¨uster (1974, as cited in Campo (2013, chap. 2)) is recognized as the first theory of terminology. The GTT, which is also known as traditional terminology, puts concepts first; terms are unambiguous linguistic labels that are defined independently of the context in which they are used (L’Homme, 2014) (Figure 1a). As implied by the given definition in ISO 1087-1(2000), the GTT is the most widely adopted theory amongst terminologists.3 Consequently, the GTT regards terms and concepts as having mono-referential relationships (Figure 2a). The objective behind GTT, understandably, is to eliminate ambiguity in natural language to impro</context>
</contexts>
<marker>Campo, 2013</marker>
<rawString>´Angela Campo. 2013. The reception of Eugen Wsters work and the development of terminology. Ph.D. thesis, Universit´e de Montr´eal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Daille</author>
</authors>
<title>Combined approach for terminology extraction: lexical statistics and linguistic filtering.</title>
<date>1995</date>
<tech>Technical report,</tech>
<institution>UCREL, Lancaster University.</institution>
<contexts>
<context position="20197" citStr="Daille, 1995" startWordPosition="3046" endWordPosition="3047">oit a reference corpus of general language to identify simple candidate terms (Drouin, 2004, 2003); for complex terms, the comparison between corpora is followed by one of the techniques listed above. A combination of these methods can also be employed to improve 8http://www.nist.gov/tac/about/ 56 the results (e.g. see Aubin and Hamon, 2006). Linguistic filters in the form of PoS tag sequence patterns are the most widely adopted technique for the extraction of candidate terms. In this method, any sequence of tokens with certain PoS tags are assumed as candidate terms (Justeson and Katz, 1995; Daille, 1995). Likewise, the knowledge about PoS patterns that cannot form candidate terms may be used to restrict the presence of token sequences in a list of candidate terms (Bourigault, 1992). In the n-gram technique, however, any sequences of tokens of length n, often 1 &lt; n &lt; 6, that appear in the input text are considered as candidate terms. This method generates a large set of candidate terms. The number of candidate terms, therefore, is often reduced by filtering n-grams that contain tokens from a stop-word list. When linguistic processing tools are lacking, such as the case of under-resourced langu</context>
</contexts>
<marker>Daille, 1995</marker>
<rawString>Beatrice Daille. 1995. Combined approach for terminology extraction: lexical statistics and linguistic filtering. Technical report, UCREL, Lancaster University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Drouin</author>
</authors>
<title>Term extraction using non-technical corpora as a point of leverage.</title>
<date>2003</date>
<journal>Terminology,</journal>
<booktitle>In LREC’04.</booktitle>
<volume>9</volume>
<issue>1</issue>
<institution>Patrick Drouin.</institution>
<marker>Drouin, 2003</marker>
<rawString>Patrick Drouin. 2003. Term extraction using non-technical corpora as a point of leverage. Terminology, 9(1):99–115. Patrick Drouin. 2004. Detection of domain specific terminology using corpora comparison. In LREC’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences Word Pairs and Collocations.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Institut f¨ur maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</institution>
<contexts>
<context position="15810" citStr="Evert (2004)" startWordPosition="2375" endWordPosition="2376">n a domain-specific corpus (Figure 3). For example, an automatic keyphrase extraction algorithm extracts lexical units from a single document that best describe the content of this document. Both unithood and termhood must be also measured in automatic keyphrase extraction. However, the criterion for their definition and the information available for their computation are different than ATR. 6As can be understood, the main difference between the GTT and the CTT is the interpretation of the process of pairing concepts and lexical forms that is mentioned in the definition of lexical units. 7See Evert (2004) on the application of lexical association measures for the identification of stable lexical units. 55 Term Mapping Term Extraction Term Classification · · · Terminological Resource Text Figure 4: Significant processes in computational terminology and the direction in which they attach terms and natural language text. Termhood Text Candidate Term Extraction Scoring and Ranking Term List Unithood Figure 5: Prevalent architecture of the terminology extraction methods. We can further distinguish CT methods based on the direction in which terms and text are related. Recent developments of ontologi</context>
</contexts>
<marker>Evert, 2004</marker>
<rawString>Stefan Evert. 2004. The Statistics of Word Cooccurrences Word Pairs and Collocations. Ph.D. thesis, Institut f¨ur maschinelle Sprachverarbeitung, Universit¨at Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela Faber</author>
</authors>
<title>A cognitive linguistics view of terminology and specialized language, volume 20, chapter Terminology and Specialized Language,</title>
<date>2012</date>
<pages>13--33</pages>
<note>Walter de Gruyter.</note>
<contexts>
<context position="9469" citStr="Faber, 2012" startWordPosition="1408" endWordPosition="1409">s Relation Term Term Term Term · · · (a) One-to-One Relation (b) Synonymous Relation Figure 2: Relationships between terms and the concepts they signify: Figure 2a illustrates a monoreferential, unambiguous relationship between terms and concepts. Figure 2b shows an ambiguity that may arise when several terms denote the same concept in a synonymous relation. Figure 2c illustrates an ambiguous term-concept relation, a polysemous relationship where a term may denote several concepts. Modern terminology is therefore pursued within a linguistic framework and as the study of specialized languages (Faber, 2012). The meanings of terms and the process of concept denomination are studied within the framework of a ‘theory of terminology’. As stated in Cabr´e (2003), a theory of terminology elaborates the fundamental problem of interpretation of meaning into a set of questions in which the definition of a terminological unit—and its characteristics—is the nucleus. The general theory of terminology (GTT) by W¨uster (1974, as cited in Campo (2013, chap. 2)) is recognized as the first theory of terminology. The GTT, which is also known as traditional terminology, puts concepts first; terms are unambiguous l</context>
</contexts>
<marker>Faber, 2012</marker>
<rawString>Pamela Faber. 2012. A cognitive linguistics view of terminology and specialized language, volume 20, chapter Terminology and Specialized Language, pages 13–33. Walter de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Felber</author>
</authors>
<title>Computerized terminology in termnet: The role of terminological data banks. Term banks for tomorrows world: Translating and the Computer,</title>
<date>1982</date>
<pages>4--8</pages>
<contexts>
<context position="11567" citStr="Felber (1982)" startWordPosition="1727" endWordPosition="1728">concept (which may or may not be newly invented) is used frequently inasmuch as it becomes a term5 in the organization. In practice, therefore, terms can be ambiguous: a term can refer to several concepts—similar to polysemy–homonymy in lexical semantics (Figure 2c); or, contrariwise, a particular concept can be denoted by several terms (Figure 2b). Heid and Gojun (2012) suggest that the rapid evolution of organizations as well as multi-players that are involved in an uncoordinated way, specifically in multidisciplinary domains, reinforces this situation and thus term ambiguity. 3Accordingly, Felber (1982) defines terminology as ‘the combined action of groups of subject specialists (terminology commissions) of specialised organisations’. 4it is, perhaps, best demonstrated in the applications of controlled natural languages. 5That is, a norm. 54 ... ... Figure 3: Lexical unit extraction tasks and the scope of the meaning: the diagram can be extended by adding new dimensions that take into the consideration characteristics of the communicative context other than the text size. In contrast to the GTT, recent theories of terminology, e.g. the communicative theory of terminology (CTT) by Cabr´e (see</context>
</contexts>
<marker>Felber, 1982</marker>
<rawString>Helmut Felber. 1982. Computerized terminology in termnet: The role of terminological data banks. Term banks for tomorrows world: Translating and the Computer, 4:8–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarten Franssen</author>
<author>Gert-Jan Lokhorst</author>
<author>Ibo van de Poel</author>
</authors>
<title>Philosophy of technology.</title>
<date>2013</date>
<booktitle>In The Stanford Encyclopedia of Philosophy. Winter</booktitle>
<note>edition.</note>
<marker>Franssen, Lokhorst, van de Poel, 2013</marker>
<rawString>Maarten Franssen, Gert-Jan Lokhorst, and Ibo van de Poel. 2013. Philosophy of technology. In The Stanford Encyclopedia of Philosophy. Winter 2013 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Ananiadou Frantzi</author>
<author>Junichi Tsujii</author>
</authors>
<title>The c-value/nc-value method of automatic recognition for multi-word terms.</title>
<date>1998</date>
<booktitle>In Research and Advanced Technology for Digital Libraries, LNCS 1513,</booktitle>
<pages>585--604</pages>
<marker>Frantzi, Tsujii, 1998</marker>
<rawString>KaterinaT. Frantzi, Sophia Ananiadou, and Junichi Tsujii. 1998. The c-value/nc-value method of automatic recognition for multi-word terms. In Research and Advanced Technology for Digital Libraries, LNCS 1513, pages 585–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Beth Sundheim</author>
</authors>
<title>Message understanding conference-6: A brief history.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING</booktitle>
<volume>96</volume>
<pages>466--471</pages>
<contexts>
<context position="17236" citStr="Grishman and Sundheim, 1996" startWordPosition="2587" endWordPosition="2590">owledge base, and natural language text. In these tasks, given a particular concept in a knowledge base (e.g. a class and its instances in an ontology), a method—which we call term mapping following Krauthammer and Nenadic (2004)—decides if this concept or its instances has been mentioned in a given text snippet. Entity linking, which has been promoted through the series of Text Analysis Conferences,8 is another term that characterizes these research efforts (see also Rao et al., 2013). The familiar task of named entity recognition (NER), as introduced at the Message Understanding Conference (Grishman and Sundheim, 1996), can also be placed in this category. In NER, the types of target terms are known prior to the extraction task, e.g. city, location and so on. In contrast to term mapping techniques, there are methods that organize constituent terms of a terminological resource into a variety of classes. In these methods, the usage of terms in a given domain-specific corpus is assessed to decide about their membership in concept classes. If the classes are known prior to the assignment task, then the task is known as term classification; otherwise, if the classes are not known, the task is called term cluster</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>Ralph Grishman and Beth Sundheim. 1996. Message understanding conference-6: A brief history. In Proceedings of COLING (Vol. 96)., pages 466–471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Warren Harrison</author>
</authors>
<title>Eating your own dog food.</title>
<date>2006</date>
<journal>IEEE Software,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="8047" citStr="Harrison (2006)" startWordPosition="1188" endWordPosition="1189">ung discipline, which is also called terminology (Cabr´e, 2003; Kageura, 1999): ‘the field of activity concerned with the collection, description, processing and presentation of terms (Sager, 1990)’. While terminology can be approached from several perspectives, e.g. as a branch of philosophy, sociology, or cognitive science, terminology is dominantly considered as a linguistic and cognitive activity. 1Considering that knowledge and vocabulary are highly correlated, and vocabulary can be gained by exposure to literature. 2With an intuition similar to “eating your own dog food”, as proposed in Harrison (2006). 53 Concept Term Text denotation signify writer Concept Term reader (a) General Theory of Terminology (b) Terms as Linguistic Units Figure 1: Association of meaning in the GTT compared to recent theories of terminology: in the GTT, terms are linguistic labels and denote concepts that exist a priori. In recent theories of terminology, e.g. CTT, however, terms are treated like other linguistic units. They signify concepts in a communicative context. In the figures above, the dashed lines indicate the direction in which the meaning of a term is elaborated according to these theories. The indicat</context>
</contexts>
<marker>Harrison, 2006</marker>
<rawString>Warren Harrison. 2006. Eating your own dog food. IEEE Software, 23(3):5–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silvana Hartmann</author>
<author>Gy¨orgy Szarvas</author>
<author>Iryna Gurevych</author>
</authors>
<title>Mining multiword terms from wikipedia.</title>
<date>2012</date>
<booktitle>In Semi-Automatic Ontology Development: Processes and Resources,</booktitle>
<pages>226--258</pages>
<location>Hershey, PA, USA.</location>
<contexts>
<context position="21739" citStr="Hartmann et al. (2012)" startWordPosition="3280" endWordPosition="3283">hrases as candidate terms (Nakagawa, 2001). The second sub-category of these methods generate candidate terms from available terminological resources to identify term variations (Jacquemin and Tzoukermann, 1999). The third subcategory, which is often employed for multilingual term extraction, exploits the head-modifier principle to identify candidate terms (Hippisley et al., 2005). Finally, a category of candidate term extraction methods takes advantage of the presence of specific markers in input text that can be used to determine boundaries of terms, e.g. the presence of mark-up metadata in Hartmann et al. (2012). Subsequent to candidate term extraction, a scoring procedure—which can be seen as a semantic weighting mechanism—is employed to indicate how likely it is that a candidate term is a term we would like to extract. As Figure 5 suggests, the scoring procedure usually combines termhood and unithood scores. Although several categorizations of the scoring and ranking methods can be given from a methodological point of view (e.g. statistics-based, machine learning-based, rule-based, etc.) or by the kind of information that is exploited for weighting (e.g. linguistic-based, statistical-based, hybrid)</context>
</contexts>
<marker>Hartmann, Szarvas, Gurevych, 2012</marker>
<rawString>Silvana Hartmann, Gy¨orgy Szarvas, and Iryna Gurevych. 2012. Mining multiword terms from wikipedia. In Semi-Automatic Ontology Development: Processes and Resources, pages 226–258. IGI Global, Hershey, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Heid</author>
<author>Anita Gojun</author>
</authors>
<title>Term candidate extraction for terminography and cat: and overview of ttc.</title>
<date>2012</date>
<booktitle>In Proceedings of the 15th Euralex International Congress.</booktitle>
<location>Oslo,</location>
<contexts>
<context position="11327" citStr="Heid and Gojun (2012)" startWordPosition="1693" endWordPosition="1696">s can be interpreted by the mechanism described in the GTT.4 However, in practice and in many organizations, new terms are introduced in a bottom-up synthesis process. A lexical form (which may or may not be newly invented) in contexts that bear a concept (which may or may not be newly invented) is used frequently inasmuch as it becomes a term5 in the organization. In practice, therefore, terms can be ambiguous: a term can refer to several concepts—similar to polysemy–homonymy in lexical semantics (Figure 2c); or, contrariwise, a particular concept can be denoted by several terms (Figure 2b). Heid and Gojun (2012) suggest that the rapid evolution of organizations as well as multi-players that are involved in an uncoordinated way, specifically in multidisciplinary domains, reinforces this situation and thus term ambiguity. 3Accordingly, Felber (1982) defines terminology as ‘the combined action of groups of subject specialists (terminology commissions) of specialised organisations’. 4it is, perhaps, best demonstrated in the applications of controlled natural languages. 5That is, a norm. 54 ... ... Figure 3: Lexical unit extraction tasks and the scope of the meaning: the diagram can be extended by adding </context>
</contexts>
<marker>Heid, Gojun, 2012</marker>
<rawString>Ulrich Heid and Anita Gojun. 2012. Term candidate extraction for terminography and cat: and overview of ttc. In Proceedings of the 15th Euralex International Congress. Oslo, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Hippisley</author>
<author>David Cheng</author>
<author>Khurshid Ahmad</author>
</authors>
<title>The head-modifier principle and multilingual term extraction.</title>
<date>2005</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="21500" citStr="Hippisley et al., 2005" startWordPosition="3241" endWordPosition="3244">rs their usage, the n-gram technique is favourable. Linguistic filters that employ syntactic relations have also been used for the extraction of candidate terms. The first sub-category of these methods use shallow parsing to identify noun phrases as candidate terms (Nakagawa, 2001). The second sub-category of these methods generate candidate terms from available terminological resources to identify term variations (Jacquemin and Tzoukermann, 1999). The third subcategory, which is often employed for multilingual term extraction, exploits the head-modifier principle to identify candidate terms (Hippisley et al., 2005). Finally, a category of candidate term extraction methods takes advantage of the presence of specific markers in input text that can be used to determine boundaries of terms, e.g. the presence of mark-up metadata in Hartmann et al. (2012). Subsequent to candidate term extraction, a scoring procedure—which can be seen as a semantic weighting mechanism—is employed to indicate how likely it is that a candidate term is a term we would like to extract. As Figure 5 suggests, the scoring procedure usually combines termhood and unithood scores. Although several categorizations of the scoring and rank</context>
</contexts>
<marker>Hippisley, Cheng, Ahmad, 2005</marker>
<rawString>Andrew Hippisley, David Cheng, and Khurshid Ahmad. 2005. The head-modifier principle and multilingual term extraction. Nat. Lang. Eng., 11(2):129–157.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashwin Ittoo</author>
<author>Laura Maruster</author>
<author>Hans Wortmann</author>
<author>Gosse Bouma</author>
</authors>
<title>Textractor: A framework for extracting relevant domain concepts from irregular corporate textual datasets.</title>
<date>2010</date>
<booktitle>In BIS, LNBIP 47,</booktitle>
<pages>71--82</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="27113" citStr="Ittoo et al. (2010)" startWordPosition="4156" endWordPosition="4159"> Table 1. Afterwards, candidate terms are extracted from the processed corpus using three methods: PoS-based filtering, n-gram-based technique and noun phrase (NP) chunking. In order to devise PoS sequence patterns and maximum length of candidate terms, we started with an observation of sample valid terms, their PoS sequences patterns and length in the corpus. We extracted 3301 sentences that contained the lemma ‘technology’. We then identified 476 valid terms in these sentences, 65% of which had lengths of 2 and 3 tokens; only 5% were longer than 5 tokens.12 Similar to the method proposed by Ittoo et al. (2010), to alleviate the problem of erroneous PoS tagging, we formulated the PoS patterns for candidate term extraction based on the actual output of the employed PoS tagger. All the occurrences of the identified terms were searched for in the corpus and all the PoS tag sequences assigned to them were extracted. Amongst the 100 extracted patterns, to keep a balance between correct and incorrect patterns resulted from erroneous PoS tagging, we chose 31 patterns Pli of maximum length 5 that satisfy the equation f(Pli) 1 (2) Ej:length(Pj)=l f(Pj) &gt; 10l, where f denotes the frequency of a PoS pattern an</context>
</contexts>
<marker>Ittoo, Maruster, Wortmann, Bouma, 2010</marker>
<rawString>Ashwin Ittoo, Laura Maruster, Hans Wortmann, and Gosse Bouma. 2010. Textractor: A framework for extracting relevant domain concepts from irregular corporate textual datasets. In BIS, LNBIP 47, pages 71–82. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
<author>Evelyne Tzoukermann</author>
</authors>
<title>NLP for term variant extraction: synergy between morphology, lexicon and syntax. Natural language information retrieval,</title>
<date>1999</date>
<pages>7--25</pages>
<contexts>
<context position="21328" citStr="Jacquemin and Tzoukermann, 1999" startWordPosition="3218" endWordPosition="3221">op-word list. When linguistic processing tools are lacking, such as the case of under-resourced languages (see e.g. Pinnis et al., 2012), or the computational cost or accuracy hinders their usage, the n-gram technique is favourable. Linguistic filters that employ syntactic relations have also been used for the extraction of candidate terms. The first sub-category of these methods use shallow parsing to identify noun phrases as candidate terms (Nakagawa, 2001). The second sub-category of these methods generate candidate terms from available terminological resources to identify term variations (Jacquemin and Tzoukermann, 1999). The third subcategory, which is often employed for multilingual term extraction, exploits the head-modifier principle to identify candidate terms (Hippisley et al., 2005). Finally, a category of candidate term extraction methods takes advantage of the presence of specific markers in input text that can be used to determine boundaries of terms, e.g. the presence of mark-up metadata in Hartmann et al. (2012). Subsequent to candidate term extraction, a scoring procedure—which can be seen as a semantic weighting mechanism—is employed to indicate how likely it is that a candidate term is a term w</context>
</contexts>
<marker>Jacquemin, Tzoukermann, 1999</marker>
<rawString>Christian Jacquemin and Evelyne Tzoukermann. 1999. NLP for term variant extraction: synergy between morphology, lexicon and syntax. Natural language information retrieval, 7:25–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: some linguistic properties and an algorithm for identification in text.</title>
<date>1995</date>
<journal>Nat. Lang. Eng.,</journal>
<pages>1--1</pages>
<contexts>
<context position="20182" citStr="Justeson and Katz, 1995" startWordPosition="3042" endWordPosition="3045">ntrastive approaches exploit a reference corpus of general language to identify simple candidate terms (Drouin, 2004, 2003); for complex terms, the comparison between corpora is followed by one of the techniques listed above. A combination of these methods can also be employed to improve 8http://www.nist.gov/tac/about/ 56 the results (e.g. see Aubin and Hamon, 2006). Linguistic filters in the form of PoS tag sequence patterns are the most widely adopted technique for the extraction of candidate terms. In this method, any sequence of tokens with certain PoS tags are assumed as candidate terms (Justeson and Katz, 1995; Daille, 1995). Likewise, the knowledge about PoS patterns that cannot form candidate terms may be used to restrict the presence of token sequences in a list of candidate terms (Bourigault, 1992). In the n-gram technique, however, any sequences of tokens of length n, often 1 &lt; n &lt; 6, that appear in the input text are considered as candidate terms. This method generates a large set of candidate terms. The number of candidate terms, therefore, is often reduced by filtering n-grams that contain tokens from a stop-word list. When linguistic processing tools are lacking, such as the case of under-</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: some linguistic properties and an algorithm for identification in text. Nat. Lang. Eng., 1.1:9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyo Kageura</author>
</authors>
<title>On the study of dynamics of terminology: A proposal of a theoretical framework.</title>
<date>1999</date>
<journal>Terminology,</journal>
<booktitle>Research Bulletin of the NACSIS, 11:1–10. Kyo Kageura and Bin Umino.</booktitle>
<volume>3</volume>
<contexts>
<context position="7510" citStr="Kageura, 1999" startWordPosition="1111" endWordPosition="1112">o their lexical forms, terms are usually classified as simple or complex. Simple terms consist of one token; complex terms are composed of more than one token or word. For instance, ‘lexicography’ and ‘multilingual terminology management’ are, respectively, examples of a simple and a complex term in the domain of computational linguistics. The extracted lexical units constitute a terminological resource, also known as terminology: a specialized vocabulary of knowledge in a domain. Terms and their use are studied in a relatively young discipline, which is also called terminology (Cabr´e, 2003; Kageura, 1999): ‘the field of activity concerned with the collection, description, processing and presentation of terms (Sager, 1990)’. While terminology can be approached from several perspectives, e.g. as a branch of philosophy, sociology, or cognitive science, terminology is dominantly considered as a linguistic and cognitive activity. 1Considering that knowledge and vocabulary are highly correlated, and vocabulary can be gained by exposure to literature. 2With an intuition similar to “eating your own dog food”, as proposed in Harrison (2006). 53 Concept Term Text denotation signify writer Concept Term r</context>
</contexts>
<marker>Kageura, 1999</marker>
<rawString>Kyo Kageura. 1999. On the study of dynamics of terminology: A proposal of a theoretical framework. Research Bulletin of the NACSIS, 11:1–10. Kyo Kageura and Bin Umino. 1996. Methods of automatic term recognition: A review. Terminology, 3.2 (1996):259–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Kim</author>
<author>T Ohta</author>
<author>Y Tateisi</author>
<author>J Tsujii</author>
</authors>
<title>Genia corpus—a semantically annotated corpus for bio-textmining. Bioinformatics,</title>
<date>2003</date>
<pages>1--180</pages>
<contexts>
<context position="3214" citStr="Kim et al., 2003" startWordPosition="449" endWordPosition="452">nded application for the extracted terms. In an evaluation dataset, the specialized subject field is largely defined by the set of documents in this dataset. Therefore, variation in the set of documents can result in variant set of terms. Creating datasets for benchmarking CT techniques have been addressed in several research efforts. The GENIA corpus is a well-known example of such reference datasets in bio-text mining: a corpus of 2000 abstracts from scientific publications in biological literature that is accompanied by the annotations of 100,000 terms organized in a well-defined ontology (Kim et al., 2003). The Colorado Richly Annotated Full Text Corpus (CRAFT) is another example of a bio-text mining dataset, which consists of 97 articles from the PubMed Central Open Access subset annotated with biomedical concepts such as ‘mouse genes’ (Bada et al., 2012). In a more recent effort, Bernier-Colborne and Drouin (2014) report on creating a corpus for the evaluation of term extraction in the domain of automotive engineering. This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organizers. Licence details: http://c</context>
</contexts>
<marker>Kim, Ohta, Tateisi, Tsujii, 2003</marker>
<rawString>J.. D. Kim, T. Ohta, Y. Tateisi, and J. Tsujii. 2003. Genia corpus—a semantically annotated corpus for bio-textmining. Bioinformatics, 19(suppl 1):i180–i182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aleksandar Kovaevi</author>
<author>Zora Konjovi</author>
<author>Branko Milosavljevi</author>
<author>Goran Nenadic</author>
</authors>
<title>Mining methodologies from nlp publications: A case study in automatic terminology recognition.</title>
<date>2012</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>26</volume>
<issue>2</issue>
<pages>126</pages>
<contexts>
<context position="35287" citStr="Kovaevi et al., 2012" startWordPosition="5502" endWordPosition="5505">n signal a technology concept. If ‘genes’ are an essential category of concepts in an ontology that characterizes biological discipline, we speculate that the presence of technology as a category of concepts is essential in any ontology or terminological resource that describes an applied discipline like computational linguistics. As to our definition, technology terms indicate concepts such as methods, algorithms and processes that are designed, developed and employed to accomplish a certain task in order to fulfil a practical purpose, i.e. to address a research problem (see also the task in Kovaevi et al., 2012). In computational linguistics, examples of these terms are ‘parsing’, ‘information retrieval’, and more delicate terms such as ‘linear interpolation’. In order to distinguish technology terms amongst other categories of terms, annotators are provided with several definitions of technology and its known examples in computational linguistics.17 In addition, the annotators are exposed to materials on philosophy of technology, e.g. Franssen et al. (2013), and introduced to the task of ‘tech mining’ in Porter and Cunningham (2005). Despite all these efforts, because establishing a precise definiti</context>
</contexts>
<marker>Kovaevi, Konjovi, Milosavljevi, Nenadic, 2012</marker>
<rawString>Aleksandar Kovaevi, Zora Konjovi, Branko Milosavljevi, and Goran Nenadic. 2012. Mining methodologies from nlp publications: A case study in automatic terminology recognition. Computer Speech &amp; Language, 26(2):105 – 126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Krauthammer</author>
<author>Goran Nenadic</author>
</authors>
<title>Term identification in the biomedical literature.</title>
<date>2004</date>
<journal>J. of Biomedical Informatics,</journal>
<volume>37</volume>
<issue>6</issue>
<contexts>
<context position="16837" citStr="Krauthammer and Nenadic (2004)" startWordPosition="2527" endWordPosition="2530">d Figure 5: Prevalent architecture of the terminology extraction methods. We can further distinguish CT methods based on the direction in which terms and text are related. Recent developments of ontological resources have stimulated a research strand that targets the reverse task of intermediary applications. The goal of these applications is to fill the gap between an available ontology, i.e. a knowledge base, and natural language text. In these tasks, given a particular concept in a knowledge base (e.g. a class and its instances in an ontology), a method—which we call term mapping following Krauthammer and Nenadic (2004)—decides if this concept or its instances has been mentioned in a given text snippet. Entity linking, which has been promoted through the series of Text Analysis Conferences,8 is another term that characterizes these research efforts (see also Rao et al., 2013). The familiar task of named entity recognition (NER), as introduced at the Message Understanding Conference (Grishman and Sundheim, 1996), can also be placed in this category. In NER, the types of target terms are known prior to the extraction task, e.g. city, location and so on. In contrast to term mapping techniques, there are methods</context>
</contexts>
<marker>Krauthammer, Nenadic, 2004</marker>
<rawString>Michael Krauthammer and Goran Nenadic. 2004. Term identification in the biomedical literature. J. of Biomedical Informatics, 37(6):512–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Claude L’Homme</author>
</authors>
<title>Terminologies and taxonomies. Oxford Handbooks Online.</title>
<date>2014</date>
<marker>L’Homme, 2014</marker>
<rawString>Marie-Claude L’Homme. 2014. Terminologies and taxonomies. Oxford Handbooks Online.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minh-Thang Luong</author>
<author>Thuy Dung Nguyen</author>
<author>Min-Yen Kan</author>
</authors>
<title>Logical structure recovery in scholarly articles with rich document features.</title>
<date>2010</date>
<journal>IJDLS,</journal>
<volume>1</volume>
<issue>4</issue>
<marker>Luong, Nguyen, Kan, 2010</marker>
<rawString>Minh-Thang Luong, Thuy Dung Nguyen, and Min-Yen Kan. 2010. Logical structure recovery in scholarly articles with rich document features. IJDLS, 1(4):1–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana Maynard</author>
</authors>
<title>Term recognition using combined knowledge sources.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<pages>6--2</pages>
<institution>Manchester Metropolitan University. Hiroshi Nakagawa.</institution>
<contexts>
<context position="29933" citStr="Maynard, 2000" startWordPosition="4632" endWordPosition="4633">ework’and ‘theory’. There is no evidence to support that the extracted patterns are specific to a category of terms (e.g. technology terms). These patterns seem to be generic enough to extract terms of any category. We support this claim based on the conducted manual verification of the extracted candidate terms. In these extracted sentences, the only terms that are longer than 5 tokens are various transliteration of the term ‘very-large-vocabulary speaker-independent continuous speech recognition’. Based on these observations and the previous studies reported on the length of terms (e.g. see Maynard, 2000; Bonin et al., 2010), we believe the maximum length of 5 tokens is a fair trade-off between accuracy and recall in the process of candidate term extraction. The sentences in the corpus are scanned for occurrences of the devised PoS patterns. Any sequences of tokens that conform to any of these patterns is considered as a candidate term. The extracted token sequences construct the list of PoS-based candidate terms. Based on the above observation, in the ngram-based extraction of candidate terms, n is set to 1 ≤ n ≤ 5 tokens. In addition, n-grams that begin with a token from a stop-word list13 </context>
</contexts>
<marker>Maynard, 2000</marker>
<rawString>Diana Maynard. 2000. Term recognition using combined knowledge sources. Ph.D. thesis, Manchester Metropolitan University. Hiroshi Nakagawa. 2001. Automatic term recognition based on statistics of compound nouns. Terminology, 6.2:195–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adeline Nazarenko</author>
<author>Haifa Zargayouna</author>
</authors>
<title>Evaluating term extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference RANLP-2009,</booktitle>
<pages>299--304</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics, Borovets, Bulgaria.</institution>
<contexts>
<context position="1839" citStr="Nazarenko and Zargayouna (2009)" startWordPosition="239" endWordPosition="242">tive effort towards building a full-fledged annotated corpus from the computational linguistics literature. 1 Introduction Computational terminology (CT) embraces a set of algorithms that extract terms from domain-specific corpora and arrange them in domain-specific knowledge structures such as a vocabulary, thesaurus or ontology. Modern methods in CT often take a corpus-based, distributional approach to fulfil their tasks. These methods exploit data-centric, data-sensitive techniques for mining and organizing terms. Evaluation of these methods—as described in Vivaldi and Rodriguez (2007) and Nazarenko and Zargayouna (2009)—is inherently a difficult task. Regardless of the employed metric and method for the performance comparison of CT algorithms, however, choosing a shared dataset consisting of a fixed set of documents—which can be accessed freely and easily—is a major step towards alleviating a number of obstacles in the evaluation process. From a mathematical perspective, changes in the document set will alter the underlying distribution of words and terms in the benchmark dataset. Consequently, this can vary the performance of methods. From perspectives that involve meaning interpretation, as described in L’</context>
</contexts>
<marker>Nazarenko, Zargayouna, 2009</marker>
<rawString>Adeline Nazarenko and Haifa Zargayouna. 2009. Evaluating term extraction. In Proceedings of the International Conference RANLP-2009, pages 299–304. Association for Computational Linguistics, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M¯arcis Pinnis</author>
<author>Nikola Ljubeˇsi´c</author>
<author>Dan S¸tef˘anescu</author>
<author>Inguna Skadin¸a</author>
<author>Marko Tadi´c</author>
<author>Tatiana Gornostay</author>
</authors>
<title>Term extraction, tagging, and mapping tools for under-resourced languages. In</title>
<date>2012</date>
<booktitle>TKE</booktitle>
<marker>Pinnis, Ljubeˇsi´c, S¸tef˘anescu, Skadin¸a, Tadi´c, Gornostay, 2012</marker>
<rawString>M¯arcis Pinnis, Nikola Ljubeˇsi´c, Dan S¸tef˘anescu, Inguna Skadin¸a, Marko Tadi´c, and Tatiana Gornostay. 2012. Term extraction, tagging, and mapping tools for under-resourced languages. In TKE 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan L Porter</author>
<author>Scott W Cunningham</author>
</authors>
<date>2005</date>
<journal>Tech mining. Competitive Intelligence Magazine,</journal>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="35819" citStr="Porter and Cunningham (2005)" startWordPosition="5578" endWordPosition="5581">ractical purpose, i.e. to address a research problem (see also the task in Kovaevi et al., 2012). In computational linguistics, examples of these terms are ‘parsing’, ‘information retrieval’, and more delicate terms such as ‘linear interpolation’. In order to distinguish technology terms amongst other categories of terms, annotators are provided with several definitions of technology and its known examples in computational linguistics.17 In addition, the annotators are exposed to materials on philosophy of technology, e.g. Franssen et al. (2013), and introduced to the task of ‘tech mining’ in Porter and Cunningham (2005). Despite all these efforts, because establishing a precise definition of technology is infeasible, classification of valid terms to technology and non-technology terms, to a great extent, relies on the intuition of experts who participated in the annotation task. The annotators are allowed to use other sources of information than the ACL ARC, e.g. web search, in order to decide about the technology class membership of valid terms. The process of annotating technology terms in the lists of extracted candidate terms is facilitated by supervised machine learning-based methods of term weighting, </context>
</contexts>
<marker>Porter, Cunningham, 2005</marker>
<rawString>Alan L Porter and Scott W Cunningham. 2005. Tech mining. Competitive Intelligence Magazine, 8(1):30–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Entity linking: Finding extracted entities in a knowledge base.</title>
<date>2013</date>
<booktitle>In Multisource, Multilingual Information Extraction and Summarization, Theory and Applications of Natural Language Processing.</booktitle>
<contexts>
<context position="17098" citStr="Rao et al., 2013" startWordPosition="2568" endWordPosition="2571">e task of intermediary applications. The goal of these applications is to fill the gap between an available ontology, i.e. a knowledge base, and natural language text. In these tasks, given a particular concept in a knowledge base (e.g. a class and its instances in an ontology), a method—which we call term mapping following Krauthammer and Nenadic (2004)—decides if this concept or its instances has been mentioned in a given text snippet. Entity linking, which has been promoted through the series of Text Analysis Conferences,8 is another term that characterizes these research efforts (see also Rao et al., 2013). The familiar task of named entity recognition (NER), as introduced at the Message Understanding Conference (Grishman and Sundheim, 1996), can also be placed in this category. In NER, the types of target terms are known prior to the extraction task, e.g. city, location and so on. In contrast to term mapping techniques, there are methods that organize constituent terms of a terminological resource into a variety of classes. In these methods, the usage of terms in a given domain-specific corpus is assessed to decide about their membership in concept classes. If the classes are known prior to th</context>
</contexts>
<marker>Rao, McNamee, Dredze, 2013</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. 2013. Entity linking: Finding extracted entities in a knowledge base. In Multisource, Multilingual Information Extraction and Summarization, Theory and Applications of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juan C Sager</author>
</authors>
<title>Practical Course in Terminology Processing, chapter Term Formation: theory and practice,</title>
<date>1990</date>
<pages>61--87</pages>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="7629" citStr="Sager, 1990" startWordPosition="1127" endWordPosition="1128">s are composed of more than one token or word. For instance, ‘lexicography’ and ‘multilingual terminology management’ are, respectively, examples of a simple and a complex term in the domain of computational linguistics. The extracted lexical units constitute a terminological resource, also known as terminology: a specialized vocabulary of knowledge in a domain. Terms and their use are studied in a relatively young discipline, which is also called terminology (Cabr´e, 2003; Kageura, 1999): ‘the field of activity concerned with the collection, description, processing and presentation of terms (Sager, 1990)’. While terminology can be approached from several perspectives, e.g. as a branch of philosophy, sociology, or cognitive science, terminology is dominantly considered as a linguistic and cognitive activity. 1Considering that knowledge and vocabulary are highly correlated, and vocabulary can be gained by exposure to literature. 2With an intuition similar to “eating your own dog food”, as proposed in Harrison (2006). 53 Concept Term Text denotation signify writer Concept Term reader (a) General Theory of Terminology (b) Terms as Linguistic Units Figure 1: Association of meaning in the GTT compa</context>
<context position="14133" citStr="Sager, 1990" startWordPosition="2118" endWordPosition="2119">res known as unithood and termhood. It is believed that the majority of terms in a domain are complex terms. Unithood indicates the degree to which a sequence of tokens can be combined to form a complex term. It is, thus, a measure of the syntagmatic relation between the constituents of complex terms: a lexical association measure to identify collocations. In the absence of explicit linguistic criteria for distinguishing complex terms from other natural language text phrases, a unithood measure construes the problem of complex term identification as the identification of stable lexical units (Sager, 1990).7 Termhood, on the other hand, ‘is the degree to which a stable lexical unit is related to some domainspecific concepts’ (Kageura and Umino, 1996). It characterizes a paradigmatic relation between lexical units—either simple or complex terms—and the communicative context that verbalizes domainconcepts. Termhood, thus, envisages the measurement of meaning. In the absence of a formal answer to the question ‘what domain-specific concepts are?’, devising a termhood measure for distinguishing terms and non-terms is a difficult and often conflictual task—hence, the evaluation of CT. In ATR, the com</context>
</contexts>
<marker>Sager, 1990</marker>
<rawString>Juan C. Sager. 1990. Practical Course in Terminology Processing, chapter Term Formation: theory and practice, pages 61–87. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>NAACL ’03.</booktitle>
<pages>173--180</pages>
<contexts>
<context position="28620" citStr="Toutanova et al. (2003)" startWordPosition="4409" endWordPosition="4412">re the only patterns of length 1, only NN and NNP satisfy the given formula in Equation 2 above and are added to the inventory of valid PoS patterns for terms of length l = 1. The rest of PoS patterns—VBG, JJ and FW—are discarded. As it can be understood from the right hand side of the equation, when the length of PoS patterns increases, the stated criteria for their selection process becomes easier (e.g. 0.01 for terms of length l = 2 instead of 9Release version 110505 (http://aye.comp.nus.edu.sg/parsCit/). 10Release version 1.5.2 (http://opennlp.apache.org/). 11Release date 9 July 2012; see Toutanova et al. (2003) for a description of the PoS tagger tagset. 12We eliminate definite and indefinite determiners from the terms. 58 Method Total# Length = 1 Length = 2 Length = 3 Length = 4 Length = 5 PoS-based 1, 322, 445 271, 064 741, 448 284, 725 23, 384 1, 824 n-gram 9, 339, 303 236, 053 1, 054, 792 2, 187, 041 2, 880, 665 2, 980, 752 NP Chunk 1, 813, 222 142, 636 706, 051 623, 633 248, 505 92, 397 Table 3: Summary statistics of the extracted candidate terms. 0.1 for terms of length l = 1). The list of devised PoS patterns is included in the distributed package. We repeated the procedure described above by</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In NAACL ’03. pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorge Vivaldi</author>
<author>Horacio Rodr¨ıguez</author>
</authors>
<title>Evaluation of terms and term extraction systems: A practical approach.</title>
<date>2007</date>
<tech>Terminology. 13:225–248.</tech>
<marker>Vivaldi, Rodr¨ıguez, 2007</marker>
<rawString>Jorge Vivaldi and Horacio Rodr¨ıguez. 2007. Evaluation of terms and term extraction systems: A practical approach. Terminology. 13:225–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugen W¨uster</author>
</authors>
<title>Die allgemeine terminologielehre–ein grenzgebiet zwischen sprachwissenschaft, logik, ontologie, informatik und den sachwissenschaften.</title>
<date>1974</date>
<journal>Linguistics,</journal>
<volume>12</volume>
<issue>119</issue>
<marker>W¨uster, 1974</marker>
<rawString>Eugen W¨uster. 1974. Die allgemeine terminologielehre–ein grenzgebiet zwischen sprachwissenschaft, logik, ontologie, informatik und den sachwissenschaften. Linguistics, 12(119):61–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Q Zadeh</author>
<author>Siegfried Handschuh</author>
</authors>
<title>Evaluation of technology term recognition with random indexing.</title>
<date>2014</date>
<booktitle>LREC’14. ELRA, Reykjavik,</booktitle>
<contexts>
<context position="36464" citStr="Zadeh and Handschuh (2014" startWordPosition="5677" endWordPosition="5680">efforts, because establishing a precise definition of technology is infeasible, classification of valid terms to technology and non-technology terms, to a great extent, relies on the intuition of experts who participated in the annotation task. The annotators are allowed to use other sources of information than the ACL ARC, e.g. web search, in order to decide about the technology class membership of valid terms. The process of annotating technology terms in the lists of extracted candidate terms is facilitated by supervised machine learning-based methods of term weighting, e.g. as reported in Zadeh and Handschuh (2014a,b). Table 4 shows the current statistics of the annotated terms. Figure 6 illustrates relationships between candidate terms, valid terms and technology terms. Similar to the valid terms, terms that are annotated as technology terms do not exclusively belong to this class. For example, ‘computational linguistics’ is a lexical form that can be classified as a technology term, e.g., in ‘· · · promising area of application of computational linguistics techniques· · · ’. However, it can also signal other concepts such as a scientific discipline, e.g. in ‘· · · theoretical work in computational li</context>
</contexts>
<marker>Zadeh, Handschuh, 2014</marker>
<rawString>Behrang Q. Zadeh and Siegfried Handschuh. 2014a. Evaluation of technology term recognition with random indexing. LREC’14. ELRA, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Behrang Q Zadeh</author>
<author>Siegfried Handschuh</author>
</authors>
<title>Investigating context parameters in technology term recognition.</title>
<date>2014</date>
<booktitle>COLING Workshop on Synchronic and Diachronic Approaches to Analyzing Technical Language (SADAATL).</booktitle>
<contexts>
<context position="36464" citStr="Zadeh and Handschuh (2014" startWordPosition="5677" endWordPosition="5680">efforts, because establishing a precise definition of technology is infeasible, classification of valid terms to technology and non-technology terms, to a great extent, relies on the intuition of experts who participated in the annotation task. The annotators are allowed to use other sources of information than the ACL ARC, e.g. web search, in order to decide about the technology class membership of valid terms. The process of annotating technology terms in the lists of extracted candidate terms is facilitated by supervised machine learning-based methods of term weighting, e.g. as reported in Zadeh and Handschuh (2014a,b). Table 4 shows the current statistics of the annotated terms. Figure 6 illustrates relationships between candidate terms, valid terms and technology terms. Similar to the valid terms, terms that are annotated as technology terms do not exclusively belong to this class. For example, ‘computational linguistics’ is a lexical form that can be classified as a technology term, e.g., in ‘· · · promising area of application of computational linguistics techniques· · · ’. However, it can also signal other concepts such as a scientific discipline, e.g. in ‘· · · theoretical work in computational li</context>
</contexts>
<marker>Zadeh, Handschuh, 2014</marker>
<rawString>Behrang Q. Zadeh and Siegfried Handschuh. 2014b. Investigating context parameters in technology term recognition. COLING Workshop on Synchronic and Diachronic Approaches to Analyzing Technical Language (SADAATL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Zweigenbaum</author>
<author>Natalia Grabar</author>
</authors>
<title>Automatic acquisition of morphological knowledge for medical language processing.</title>
<date>1999</date>
<booktitle>In Artificial Intelligence in Medicine, LNCS 1620,</booktitle>
<pages>416--420</pages>
<contexts>
<context position="18997" citStr="Zweigenbaum and Grabar (1999)" startWordPosition="2862" endWordPosition="2865">kground knowledge, linguistic characteristics of the extracted terms and so on. We leave this study for another occasion. 2.1 Prevalent Mechanism in Term Extraction Tasks As suggested in Nakagawa (2001), the algorithms for term recognition are usually in the form of a twostep procedure: candidate term extraction followed by term scoring and ranking (Figure 5). Candidate term extraction deals with the term formation and the extraction of candidate terms. In a few applications, candidate term extraction can assess the morphosyntactic structure of terms, e.g. as suggested in Ananiadou (1994) and Zweigenbaum and Grabar (1999), to identify candidate terms. In these methods, existing terminologies are often available before to the extraction task and employed to identify new candidate terms. Besides this, one can identify four major methods for the extraction of candidate terms: linguistic filtering based on part of speech (PoS) tag sequences, n-gram technique, linguistic filtering based on syntactic relations and techniques that rely on the presence of particular markers in text. Methods for the extraction of candidate terms are not limited to these categories. For instance, contrastive approaches exploit a referen</context>
</contexts>
<marker>Zweigenbaum, Grabar, 1999</marker>
<rawString>Pierre Zweigenbaum and Natalia Grabar. 1999. Automatic acquisition of morphological knowledge for medical language processing. In Artificial Intelligence in Medicine, LNCS 1620, pages 416–420.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>