<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9971055">
A Framework for Learning Morphology using Suffix Association
Matrix
</title>
<author confidence="0.996036">
Shilpa Desai
</author>
<affiliation confidence="0.9431365">
Department of Computer
Science and Technology
Goa University, Goa,
India
</affiliation>
<email confidence="0.997823">
sndesai@gmail.com
</email>
<author confidence="0.993186">
Jyoti Pawar
</author>
<affiliation confidence="0.942769">
Department of Computer
Science and Technology
Goa University, Goa,
India
</affiliation>
<email confidence="0.997805">
jyotidpawar@gmail.com
</email>
<author confidence="0.968249">
Pushpak Bhattacharyya
</author>
<affiliation confidence="0.972688">
Department of Computer
</affiliation>
<address confidence="0.668700666666667">
Science and Engineering
IIT, Powai,
Mumbai India
</address>
<email confidence="0.997515">
pb@cse.iitb.ac.in
</email>
<sectionHeader confidence="0.993856" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998530583333333">
Unsupervised learning of morphology is used for automatic affix identification, morphological segmentation of
words and generating paradigms which give a list of all affixes that can be combined with a list of stems.
Various unsupervised approaches are used to segment words into stem and suffix. Most unsupervised methods
used to learn morphology assume that suffixes occur frequently in a corpus. We have observed that for
morphologically rich Indian Languages like Konkani, 31 percent of suffixes are not frequent. In this paper we
report our framework for Unsupervised Morphology Learner which works for less frequent suffixes. Less
frequent suffixes can be identified using p-similar technique which has been used for suffix identification, but
cannot be used for segmentation of short stem words. Using proposed Suffix Association Matrix, our
Unsupervised Morphology Learner can also do segmentation of short stem words correctly. We tested our
framework to learn derivational morphology for English and two Indian languages, namely Hindi and Konkani.
Compared to other similar techniques used for segmentation, there was an improvement in the precision and
recall.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942090909091">
Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule
based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state
approach as some of the well known methods used to learn morphology by a machine. Rule based
affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al,
2008) depend heavily on linguistic input and require a lot of human effort, especially for
morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus
(Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is
relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to
automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011).
Semi-supervised approaches perform better than pure unsupervised approaches. Finite state
approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state
machines. Finite state approaches require linguistic input in the form of paradigm identification.
Unsupervised and semi-supervised methods can provide input to build finite state based morphology
systems reducing the time taken to build such systems.
In this paper we report the framework for an Unsupervised Morphology Learner. Most
unsupervised segmentation techniques (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011) which
learn morphology from a corpus assume that suffixes are frequent in a corpus. We observed that for
morphologically rich Indian languages like Hindi and Konkani, the assumption that suffixes are
frequent does not hold true. These languages are morphologically rich and 31 percent of verb suffixes
are not frequent in the corpus. Thus, we choose not to make any such assumption about the frequency
of suffix occurrence in our unsupervised learning of morphology. One promising methodology for
unsupervised segmentation which does not make any suffix frequency assumptions is p-similar
</bodyText>
<footnote confidence="0.5964485">
This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/
</footnote>
<page confidence="0.989921">
28
</page>
<note confidence="0.696592">
Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 28–36,
Dublin, Ireland, August 23-29 2014.
</note>
<bodyText confidence="0.999754529411765">
technique for morpheme segmentation first proposed by Gaussier (1999). Researchers have used this
method for suffix identification and not for segmentation (Gaussier, 1999; Sharma, 2006). We
extended this less studied technique to segment words by introducing the concept of suffix association
matrix, thus giving us an unsupervised method which correctly identifies suffixes irrespective of their
frequency of occurrence in the corpus and also segments short stem words. To the best of our
knowledge, most reported work which uses p-similar technique for suffix identification (Gaussier,
1999; Sharma, 2006) enforce a restriction on stem-length that it should be at least five. This restriction
works well for suffix identification but not for segmentation. For Indian languages like Hindi and
Konkani, we observed that the restriction leads to an inability to segment many words with short stem-
length. Especially many verb stems in Indian languages have stem-length less than five. To overcome
this shortcoming, we have proposed an Unsupervised Morphology Learner (UML) framework.
We implemented UML framework for derivational morphology and tested our method for English
language and two Indian languages namely Konkani and Hindi. The rest of the paper is organized as
follows; section 2 is on related work. Section 3 provides the terminology used in the paper. The
motivation for this work is presented in section 4. Unsupervised Morphology Learner (UML)
framework is presented in section 5. Experimental results are discussed in section 6 and finally we
conclude the paper in section 7.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999917052631579">
Unsupervised learning of morphology is done at different levels, namely, affix list identification,
segmenting word into stem and affix, and generating a list of paradigms i.e. a list of all stems with
information of the suffixes that each stem combines with (Hammarström, 2011). In his survey paper,
Hammarström (2011) summarizes work related to unsupervised morphology. Most recent work in
morphology learning is semi-supervised. Such methods use a small set of example paradigms as input
to train the system and classify unseen words into paradigms or learn new paradigms (Lindén, 2009;
Dreyer, 2011).
A popular pure unsupervised morphology technique was first proposed by Goldsmith (2001) which
does not assume any linguistic input. Goldsmith (2001) introduced a set of heuristics that develops a
probabilistic morphological grammar, and used Minimum Description Length (MDL) as a tool to
evaluate it. The technique used for affix and paradigm identification was based on affix occurrence
frequency. Several different authors have appreciated MDL as the motivation for segmentation. Some
authors (Gelbukh et. al., 2004; Bacchin, 2005) have used random segmentation and picked the best
segmentation to minimize size or find splits where constituent morphemes occur in multiple splits.
Our work is inspired by a less studied p-similar technique proposed by Gaussier (1999). p-similar
techniques have been used for suffix identification rather than segmentation in most related
unsupervised morphology learners (Sharma, 2006). Here the restriction on stem-length first proposed
by Gaussier is upheld. Sharma’s (2006) work deals with neutral suffix only and does not capture non-
neutral suffixes. These studies are limited to suffix identification and do not generate paradigms.
</bodyText>
<sectionHeader confidence="0.992668" genericHeader="method">
3 Terminology Used
</sectionHeader>
<bodyText confidence="0.974300454545455">
Let L be a language with alphabet set ∑.
W= {w |w c ∑*} be set of valid words in language L.
Let d: W→W denote a derivation function where d(wx)=wy iff words wx and wy are derivationally
related to each other in L.
Let wxsy denote concatenation of strings wx and sy where wx, sy E ∑*.
Let SN be set of neutral derivational suffixes.
SN = {s|w2=w1s and w2,w1EW and d(w1)=w2 and sE ∑*}
For example, when s=er, w1=farm and w2=farmer
Let SB be set of non-neutral derivational suffixes.
SB = {sx,sy|wsx=wsy and d(wsx)=wsy and w, sx, syE ∑* and w0W }
For example, when sx=ify, sy=ity and w=quant suffixes ify, ity are non neutral suffixes.
</bodyText>
<page confidence="0.997298">
29
</page>
<sectionHeader confidence="0.995193" genericHeader="method">
4 Motivation
</sectionHeader>
<bodyText confidence="0.999650625">
Primarily, frequency based suffix identification techniques (Goldsmith, 2001; Hammarström, 2011)
commonly used in recent times, fail to identify suffixes with low frequency. We explored suffix
identification techniques which could identify suffixes irrespective of frequency of occurrence in the
corpus. We chose one such method p-similar technique. However p-similar technique (Gaussier, 1999)
cannot be used directly for segmentation as it results in a high number of false positives. Hence we
proposed a suffix association matrix to avoid the false positives. According to p-similar technique,
given two words x, y E W, if ∃ b1 such that x=b1s1 and y=b1s2 where b1, s1, s2 E Z+, then b1 is a stem
and s1, s2 are suffixes, provided they satisfy the following conditions:
</bodyText>
<listItem confidence="0.994504666666667">
a. A suffix is valid only when it occurs with at least two different stems
b. A stem is valid when it occurs with at least two identified suffixes
c. Stem length should be five or more
</listItem>
<bodyText confidence="0.999617">
The third condition on stem length was introduced to improve the precision of the suffix list
generated. However the aim was to only generate a suffix list and not segment word into stem + suffix.
We probed the possibility of applying this effective p-similar technique to segment words. We faced
the following issues when trying to use p-similar technique for segmentation:
</bodyText>
<listItem confidence="0.944162428571429">
• The technique failed for short-stem length words because of the restriction placed on stem-length.
Example words with stem like walk, talk are not segmented.
• When words like addiction, addictive, aggression and aggressive are part of the input, suffixes
identified are “on” and “ve” in place of “ion” and “ive”. This problem is called over-stemming.
• When words like cannon, cannot, America, American, agent, agency are part of the input, “n” and
“t” are identified as suffix. Although “n” and “t” are valid suffix for some words,
cannon=canno+n and cannot=canno+t are wrong segmentation.
</listItem>
<bodyText confidence="0.996458">
We realize that the candidate stem-suffix pair bi+si identified using the p-similar technique falls under
one of the following cases:
Case 1: bi is a valid stem and si is a valid suffix for stem bi. For example, mistake+IULL,
mistake+n are valid. Suffixes IULL and n are valid for stem mistake.
Case 2: bi is an invalid stem and si is a invalid suffix. Example addicti+on and addicti+ve and
aggressi+on and aggressi+ve are invalid; addict+ion and addict+ive and aggress+ion and
aggress+ive are valid.
Case 3: bi is a valid stem and si is a invalid suffix for stem bi. For example year+n is invalid.
Suffix n is invalid for stem year while suffix IULL and ly are valid for stem year.
Case 4: bi is an invalid stem for any suffix and si is valid for some other stem. Example canno+n
and canno+t are invalid pairs; absen-ce and absen-t and valid; mistake+IULL and mistake+n are
valid.
To overcome the problems faced in cases 2, 3 and 4 we have proposed the following framework
</bodyText>
<sectionHeader confidence="0.967882" genericHeader="method">
5 Unsupervised Morphology Learner Framework
</sectionHeader>
<bodyText confidence="0.99925975">
UML can be used to learn derivational morphology or inflectional morphology. When the input given
is a lexicon, the framework will learn derivational morphology. If a corpus is used as input it will learn
both derivational and inflectional morphology and not distinguish between the two. We have tested
our framework with lexicon as input to learn derivational morphology. The framework for the
proposed UML is shown below in Figure 1. UML has five modules. It uses a lexicon resource or a
corpus as input. It generates three final resources and two intermediate resources which are enhanced
into the final resources.
The resource used as input could be:
</bodyText>
<listItem confidence="0.997914">
• Lexicon L: It is list of dictionary words found in the language. This resource is generated from a
WordNet of a language used to learn derivational morphology or
• Corpus C: A collection of un-annotated text used to learn both inflectional and derivational
morphology.
</listItem>
<page confidence="0.987227">
30
</page>
<bodyText confidence="0.937116">
The intermediate resource generated:
</bodyText>
<listItem confidence="0.956239625">
• Candidate Stem-Suffix List: It is the initial list of stems and suffixes identified for an input
language using the p-similar technique. It consists of two sets namely set of suffix Ssuffix and set of
stem Sstem. Sample entries in these set for English language are Ssuffix = { er, ic, ly, ness, ment, ...}
and Sstem= {adorn, attack,....}
• Initial Paradigms: This is a list of all stems with information of which suffixes combine with
which stems in the input lexicon L or Corpus. Sample entry in Initial Paradigms List is ic.y=
academ + allerg + geometr + homeopath + horrif + letharg + majest + prehistor + specif +
strateg where “ic” and “y” are suffixes which combine with the stems like adadem.
</listItem>
<bodyText confidence="0.770264">
The final resources generated:
</bodyText>
<listItem confidence="0.999155222222222">
• Stem-Suffix List: This resource is generated from the Candidate Stem-Suffix List resource by
pruning invalid suffixes. It is a useful resource as it gives the stems of words from a lexicon which
could later be used for identifying stems in a corpus for stemming inflectional words.
• Suffix-Association Matrix: This resource helps us identify for how many instances a suffix s1 has
occurred with a suffix s2 in the Lexicon/Corpus. It is a crucial resource in eliminating the
shortcoming of p-similar technique to morphologically segment words with short stem length as
well as overcome chance association of suffix found.
• Morphology Paradigms: This resource contains paradigms extracted from the words found in the
input lexicon/corpus. It is a refined version of Initial Paradigm resource.
</listItem>
<figureCaption confidence="0.990998">
Figure 1: Unsupervised Morphology Learner (UML) Framework
</figureCaption>
<bodyText confidence="0.873195142857143">
UML comprises of five main modules, a brief description and algorithm for each of the module is
given below:
Module 1 - Suffix Identifier
Description: Identifies the Candidate suffixes using p-similar technique. It generates a temporary
resource namely Candidate Stem-Suffix List. For every word in the corpus, it checks if there is another
word with a common stem, adds common stem to stem list and rest to suffix list, provided that a stem
occurs with more than one suffix and a suffix occurs with more than one stem.
</bodyText>
<figure confidence="0.8699415625">
Input: Lexicon /Corpus
Output: Morphology Paradigms
Suffix
Identifier
Morphology Paradigm Generator
Candidate Stem-Suffix
List
Suffix Association Matrix
Stem-Suffix
Pruner
Stem-Suffix List
Suffix Association Matrix
Generator
Primary Paradigm
Generator
Initial Paradigms
</figure>
<page confidence="0.987602">
31
</page>
<bodyText confidence="0.511926">
Input: Lexicon of the language L (or raw un-annotated corpus for inflectional morphology C)
Output: Candidate Stem-Suffix List resource
</bodyText>
<sectionHeader confidence="0.465234" genericHeader="method">
Algorithm:
</sectionHeader>
<bodyText confidence="0.797705333333333">
For each input word p G L,
find q, r, s G L, such that 3 b1, b2, b3
where p=b1s1, q=b1s2, r=b2s1, s= b2s3 where b1, b2, b3, s1, s2, s3 G �*�.
</bodyText>
<figure confidence="0.799660954545454">
Add b1 to set of stems Sstem,
Add s1 to set of suffixes Ssuffix,
EndFor
Module 2 - Stem-suffix pruner:
Description: This module applies heuristic H1 stated below. H1 is framed to correct the stem-suffix
list to fix the problem of over-stemming.
H1: Given suffix si for stem bi if 3 a G ∑* such that asi G Ssuffix and bja=bi and bjG Sstem where Sstem is
set of stems and Ssuffix is set of suffixes then replace bi by bj and si by asi
Input: Candidate Stem-Suffix List resource
Output: Stem-Suffix List resource
Algorithm:
For each suffix s1 from suffix list,
If 3 a G ∑* such that as1 G Ssuffix and b2a=b1 and b1, b2G Sstem then
replace b1 by b2 and s1 by as1.
EndIf
EndFor
Module 3 - Primary Paradigm Generator:
Description: Using Stem-Suffix List this module generates the Initial Paradigms list. A paradigm
is composed of suffixes that go together for a list of stems in the input lexicon/corpus.
Input: Stem-Suffix List resource
Output: Initial Paradigms resource
Algorithm:
</figure>
<bodyText confidence="0.9681788">
For each input word p G L, if p=b1s1 where b1G Sstem and s1G Ssuffix.
Set paradigm-string= s1.
For every q G L such that q= b1s2 where b1G Sstem and s2 G Ssuffix ,
Set paradigm-string = paradigm-string.s2.
Add paradigm-string to Sparadigm, set of paradigm.
EndFor
EndFor
For each paradigm-string p1 G Sparadigm where p1 =”sx1.sx2 ...sxn=b1”
and sx1,sx2 , ..., sxnG Ssuffix and b1G Sstem
Set collapse-paradigm-string = sx1.sx2 ...sxn=b1
If 3 paradigm-string p2G Sparadigm such that p2 =” sx1.sx2 ...sxn =b2” and b2G Sstem
Set collapse-paradigm-string = collapse-paradigm-string + b2
Add collapse-paradigm-string to Sinitial-paradigm, set of Initial Paradigms
EndIf
EndFor
</bodyText>
<subsectionHeader confidence="0.662133">
Module 4- Suffix Association Matrix Generator:
</subsectionHeader>
<bodyText confidence="0.96863925">
Description: From the Initial Paradigms, this module computes the Suffix Association Matrix
resource. Suffix association matrix is a square matrix where each row and column corresponds to a
suffix in suffix list. An entry in this matrix gives how many times a particular suffix occurs with
another suffix in the Initial Paradigms resource.
</bodyText>
<sectionHeader confidence="0.4011995" genericHeader="method">
Input: Initial Paradigms resource
Output: Suffix Association Matrix resource
</sectionHeader>
<page confidence="0.998585">
32
</page>
<sectionHeader confidence="0.74366" genericHeader="method">
Algorithm:
</sectionHeader>
<bodyText confidence="0.877454666666667">
Let M be suffix association matrix which is  |Ssuffix |*  |Ssuffix|. If Ssuffix = {s1, s2, .....sp} M
has dimension p X p.
Initialize M=0;
For each paradigm-string p1 E Sinitial-paradigm where p1 =”sx1.sx2 ...sxn=b1+ b2+ b3+...+ bm”
For i= 1 to n
For j= i+1 to n
</bodyText>
<figure confidence="0.475049090909091">
M[sxi ][sxj]= M[sxi ][sxj] + m; where sxi = sq and sxi = sr and 1&lt;= q, r &lt;=p
EndFor
EndFor
EndFor
Module 5 - Morphology Paradigm Generator:
Description: Using Stem-Suffix List and Suffix Association Matrix this module generates
Morphology Paradigms List resource. It is a pruned version of Initial Paradigms resource which
uses Suffix Association matrix to remove less likely suffix combination in Initial Paradigms
Input: Stem-Suffix List resource
Output: Initial Paradigms resource
Algorithm:
</figure>
<bodyText confidence="0.847466823529412">
For each input word p E L, if p=b1s1 where b1E Sstem and s1E Ssuffix.
Set paradigm-string= s1.
For every q E L such that q= b1s2 where b1E Sstem and s2 E Ssuffix ,
If M[s1][s2] &gt; threshold value
Set paradigm-string = paradigm-string.s2.
Add paradigm-string to Sparadigm, set of paradigm.
EndIf
EndFor
EndFor
For each paradigm-string p1 E Sparadigm where p1 =”sx1.sx2 ...sxn=b1”
and sx1,sx2 , ..., sxnE Ssuffix and b1E Sstem
Set collapse-paradigm-string = sx1.sx2 ...sxn=b1
If 3 paradigm-string p2E Sparadigm such that p2 =” sx1.sx2 ...sxn =b2” and b2E Sstem
Set collapse-paradigm-string = collapse-paradigm-string + b2
Add collapse-paradigm-string to Sinitial-paradigm, set of Initial_Paradigms
EndIf
EndFor
</bodyText>
<subsectionHeader confidence="0.999777">
5.1 Significance of Suffix Association Matrix
</subsectionHeader>
<bodyText confidence="0.945132333333333">
Suffix association matrix is a measure of how many times a particular suffix is associated with
another suffix in the input resource. It is an important contribution as it provides us an alternate
way to prune invalid stem-suffix pairs identified, rather than a restriction on the stem-length.
Suffixes which are associated with each other more frequently are more likely to provide a correct
paradigm than those where we find only a few chance instances of suffix associations.
Figure 2 illustrates an instance of suffix association matrix for the English language
</bodyText>
<table confidence="0.9664402">
NULL er ing ly
NULL - 46 225 129
er 46 - 22 15
ing 225 22 - 0
ly 129 15 0 -
</table>
<figureCaption confidence="0.995484">
Figure 2: Instance of Suffix Association Matrix
</figureCaption>
<bodyText confidence="0.9901335">
This matrix helps handle valid stem with invalid suffix case. For instance wrong segmentation of
the word “bother” as “both+er”. From the Suffix Association Matrix we check with which
</bodyText>
<page confidence="0.997989">
33
</page>
<bodyText confidence="0.999681444444444">
suffixes er is commonly associated. We then make a list of words with stem “both” and other
suffix which commonly associate with suffix “er” like suffix “ing” We search a corpus for
existence of such words like “bothing”. Thus rejecting the segmentation bother=both+er. This
matrix also provides a solution to invalid stem with valid suffix. For instance canno+n and
canno+t are invalid segmentations although the suffix “n” and “t” are valid in some other
context. In such a rare association of a suffix “n” and “t” the corresponding entry in the suffix
association matrix is found to be very low. We ran our algorithm for various values of threshold
and found five as an optimal value. Any suffix association below five were pruned as chance
associations.
</bodyText>
<subsectionHeader confidence="0.999924">
5.2 Significance of heuristic H1
</subsectionHeader>
<bodyText confidence="0.9999645">
This heuristic is used to handle the problem of over-stemming that occurs in p-similar technique. For
example the p-similar technique identifies both “ion” and “on” as suffix. While segmenting a word
like “addiction” we need to decide if “addicti+on” or “addict+ion” is correct. H1 helps us in
correctly segmenting the word as “addict+ion”.
</bodyText>
<subsectionHeader confidence="0.999737">
5.3 Limitations of UML
</subsectionHeader>
<bodyText confidence="0.999762">
UML is restricted to identify concatenative morphology paradigms only. Presently it identifies
suffixes only and does not support irregular morphology wherein the stem undergoes a change before
suffixation.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.9981834">
The implementation of UML is done in Java. After applying our method, the paradigms obtained were
compared to the paradigms obtained using p-similar method with minimum stem-size five. The
precision was computed as ratio of number of words correctly segmented to total number of words
segmented. Recall is computed as ratio of number of words correctly segmented to number of words
in given input which could be segmented. The results have been tabulated in Table 1 below.
</bodyText>
<table confidence="0.996080071428572">
Method Number of Recall Precision F-Score
Paradigms
Language : English
Data Set: English lexicon with 21813 entries was obtained from the English WordNet1
p-similar with stems size &gt;5 1163 0.85 0.93 0.89
UML for derivational morphology 413 0.92 0.93 0.92
Language : Hindi
Data Set: Hindi lexicon with 23807 entries was extracted from the Hindi WordNet2
p-similar with stems size &gt;5 1127 0.83 0.87 0.85
UML for derivational morphology 332 0.87 0.94 0.90
Language : Konkani
Data Set: Konkani lexicon with 25838 entries was extracted from the Konkani WordNet3
p-similar with stems size &gt;5 1088 0.75 0.77 0.75
UML for derivational morphology 274 0.87 0.87 0.87
</table>
<tableCaption confidence="0.998428">
Table 1: Results for English, Hindi and Konkani Language
</tableCaption>
<footnote confidence="0.999267666666667">
1 http://wordnet.princeton.edu/wordnet/download/
2 http://www.cfilt.iitb.ac.in/wordnet/webhwn/
3 http://konkaniwordnet.unigoa.ac.in
</footnote>
<page confidence="0.995032">
34
</page>
<subsectionHeader confidence="0.997943">
6.1 Effect of stem length on recall
</subsectionHeader>
<bodyText confidence="0.9972045">
We list below in Table 2, a few examples of how recall is reduced as words with short stem length
are not segmented, when the minimum stem size is five.
</bodyText>
<table confidence="0.9981338">
Language Suffix for which Number of Few examples of words not segmented
word not words not
segmented segmented
English er 9 eater, farmer, owner...
Hindi ◌ी4 35 अरबी (arabic; arab; name of a country),
(I;;Hindi suffix) आलसी (aalas; lazy; ), आसानी (aasani;
easiness; )
Konkani ◌ी 43 आनंद� (anandi; being happy; ), आरोपी
(I;;Konkani (aaropi; accused; )
suffix)
</table>
<tableCaption confidence="0.999554">
Table 2: Effect of stem length
</tableCaption>
<bodyText confidence="0.99991">
We observe that number of words not segmented in English is relatively very less as compared to the
Indian languages Hindi and Konkani. Thus the restriction on stem-length works efficiently for English
as compared to the Indian languages Hindi and Konkani.
</bodyText>
<subsectionHeader confidence="0.999754">
6.2 Effect of stem length on precision
</subsectionHeader>
<bodyText confidence="0.9978645">
When we restrict the stem-length to five we observe that some wrong segmentation of words are
pruned. Listed below in Table 3, are some examples
</bodyText>
<table confidence="0.995691">
Language Suffix for Number of Few examples of words not segmented
which word not words not (wrongly)
segmented segmented
English er 32 bother, boxer, cater, sober ...
Hindi ◌ी (I;;Hindi 8 चाँद� (chandi; silver; ), चोट� (choti;
suffix) peak;)
Konkani ◌ी (I;;Konkani 6 आजी (Aaji; grandmother; ), काळ~
suffix) (kaalli; black; )
</table>
<tableCaption confidence="0.999872">
Table 3: Effect of stem-length on precision
</tableCaption>
<bodyText confidence="0.999626333333333">
We observe that for English, many word segmentations with stems-length less than five, identified
by p-similar technique are correctly pruned by applying the restriction. We observe that wrong
segmentations in case of Indian languages Hindi and Konkani are less when compared to English.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9985995">
Unsupervised Morphology Learner framework thus can be effectively used to generate paradigms for
Indian languages which have low frequency suffixes and words with short stem lengths. Suffix
Association Matrix and heuristics H1 is advantageous over p-similar technique with stem length
restriction for languages like Konkani and Hindi which have many short length valid stems. The
derivational suffixes obtained from UML with Lexicon as input can be used to distinguish from
inflectional morphology suffixes when the framework is used with a corpus as input.
</bodyText>
<page confidence="0.778375">
4 A word in Indian language is followed by transliteration in Roman Script, translation in English and gloss in brackets
35
</page>
<sectionHeader confidence="0.936512" genericHeader="references">
Reference
</sectionHeader>
<reference confidence="0.998412">
Bacchin, M., Ferro, N., and Melucci, M. (2005). A probabilistic model for stemmer generation. Information
Processing and Management, 41(1):121–137.
Beesley K &amp; Karttunen Lauri. 2003. Finite State Morphology. Stanford, CA: CSLI Publications.
Chan, E. 2008. Structures and Distributions in Morphology Learning. Ph.D thesis, University of Pennsylvania.
Dreyer, M. 2011. A non-parametric model for the discovery of inflectional paradigms from plain text using
graphical models over strings. Ph.D thesis, The Johns Hopkins University, Baltimore, Maryland
Freitag, D. 2005. Morphology induction from term clusters. In Proceedings of the Ninth Conference on
Computational Natural Language Learning (CoNLL-2005), pages 128–135, Ann Arbor, Michigan.
Association for Computational Linguistics.
Gaussier Eric. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL’99
Workshop Proceedings: Unsupervised Learning in Natural Language Processing : 24–30 ACL
Gelbukh, A. F., Alexandrov, M., and Han, S.-Y. (2004). Detecting inflection patterns in natural language by
minimization of morphological model. In Sanfeliu, A., Trinidad, J. F. M., and Carrasco-Ochoa, J. A., editors,
Proceedings of Progress in Pattern Recognition, Image Analysis and Applications, 9th Iberoamerican Congress
on Pattern Recognition, CIARP ’04, volume 3287 of Lecture Notes in Computer Science, pages 432–438.
Springer-Verlag, Berlin.
Goldsmith J A. 2001. Unsupervised learning of the morphology of a natural language. Computational
Linguistics 27(2): 153–198
Hammarstrom Harald and Lars Borin. 2011. Unsupervised learning of morphology. Computational Linguistics,
(2):309–350.
Koskenniemi, K. 1983. Two-level morphology: a general computational model for word-form recognition and
production. Helsinki, Department of General Linguistics, University of Helsinki.
Koskenniemi, K. 1996. Finite-state morphology and information retrieval. Proceedings of the ECAI-96
Workshop on Extended Finite State Models of Language ECAI, Budapest, Hungary : 42-56
Lindén, K. 2008. A probabilistic model for guessing base forms of new words by analogy. In Proceedings of
CICLing-2008: 9th International Conference on Intelligent Text Processing and Computational Linguistics,
volume 4919 of Lecture Notes in Computer Science, pages 106–116. Springer.
Lindén, K. and Tuovila, J. 2009 Corpus-based Paradigm Selection for Morphological Entries. In Proceedings of
NODALIDA 2009, Odense, Denmark, May 2009
Loftsson, H. 2008. Tagging Icelandic text: A linguistic rule-based approach. Nordic Journal of Linguistics 31(1).
47–72.
Lovins J. B. 1968. Development of a stemming algorithm. Mechanical Translation and Computer Linguistic.,
vol.11, no.1/2: 22-31.
Maung, Zin Maung &amp; Yoshiki Mikami. 2008. A rule-based syllable segmentation of myanmar text. In
Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, 51–58. Hyderabad, India:
Asian Federation of Natural Language Processing.
Paice, C.D. 1990. Another stemmer. SIGIR Forum, 24: 56-61
Porter, M. F. 1980. An algorithm for suffix stripping. Program 14 : 130-7.
Sharma U, (2006). Unsupervised Learning of Morphology of a Highly Inflectional Language, Ph.D. thesis,
Tezpur University, Assam, India
</reference>
<page confidence="0.998956">
36
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.091750">
<title confidence="0.9619815">A Framework for Learning Morphology using Suffix Association Matrix</title>
<author confidence="0.948251">Shilpa</author>
<affiliation confidence="0.93848325">Department of Science and Goa University, India</affiliation>
<email confidence="0.999263">sndesai@gmail.com</email>
<author confidence="0.988293">Jyoti</author>
<affiliation confidence="0.9146795">Department of Science and Goa University, India</affiliation>
<email confidence="0.999691">jyotidpawar@gmail.com</email>
<author confidence="0.853547">Pushpak</author>
<affiliation confidence="0.995679666666667">Department of Science and IIT,</affiliation>
<address confidence="0.607881">Mumbai India</address>
<email confidence="0.969144">pb@cse.iitb.ac.in</email>
<abstract confidence="0.898569923076923">Unsupervised learning of morphology is used for automatic affix identification, morphological segmentation of words and generating paradigms which give a list of all affixes that can be combined with a list of stems. Various unsupervised approaches are used to segment words into stem and suffix. Most unsupervised methods used to learn morphology assume that suffixes occur frequently in a corpus. We have observed that for morphologically rich Indian Languages like Konkani, 31 percent of suffixes are not frequent. In this paper we report our framework for Unsupervised Morphology Learner which works for less frequent suffixes. Less frequent suffixes can be identified using p-similar technique which has been used for suffix identification, but cannot be used for segmentation of short stem words. Using proposed Suffix Association Matrix, our Unsupervised Morphology Learner can also do segmentation of short stem words correctly. We tested our framework to learn derivational morphology for English and two Indian languages, namely Hindi and Konkani. Compared to other similar techniques used for segmentation, there was an improvement in the precision and recall.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Bacchin</author>
<author>N Ferro</author>
<author>M Melucci</author>
</authors>
<title>A probabilistic model for stemmer generation.</title>
<date>2005</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>41--1</pages>
<marker>Bacchin, Ferro, Melucci, 2005</marker>
<rawString>Bacchin, M., Ferro, N., and Melucci, M. (2005). A probabilistic model for stemmer generation. Information Processing and Management, 41(1):121–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Beesley</author>
<author>Karttunen Lauri</author>
</authors>
<title>Finite State Morphology.</title>
<date>2003</date>
<booktitle>Structures and Distributions in Morphology Learning. Ph.D thesis,</booktitle>
<publisher>CSLI Publications. Chan, E.</publisher>
<institution>University of Pennsylvania.</institution>
<location>Stanford, CA:</location>
<marker>Beesley, Lauri, 2003</marker>
<rawString>Beesley K &amp; Karttunen Lauri. 2003. Finite State Morphology. Stanford, CA: CSLI Publications. Chan, E. 2008. Structures and Distributions in Morphology Learning. Ph.D thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dreyer</author>
</authors>
<title>A non-parametric model for the discovery of inflectional paradigms from plain text using graphical models over strings.</title>
<date>2011</date>
<tech>Ph.D thesis,</tech>
<institution>The Johns Hopkins University,</institution>
<location>Baltimore, Maryland</location>
<contexts>
<context position="2454" citStr="Dreyer, 2011" startWordPosition="344" endWordPosition="345">arn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state machines. Finite state approaches require linguistic input in the form of paradigm identification. Unsupervised and semi-supervised methods can provide input to build finite state based morphology systems reducing the time taken to build such systems. In this paper we report the framework for an Unsupervised Morphology Learner. Most unsupervised segmentation techniques (Freitag, 2005; Goldsmith, 2001; Hamma</context>
<context position="6257" citStr="Dreyer, 2011" startWordPosition="899" endWordPosition="900">ated Work Unsupervised learning of morphology is done at different levels, namely, affix list identification, segmenting word into stem and affix, and generating a list of paradigms i.e. a list of all stems with information of the suffixes that each stem combines with (Hammarström, 2011). In his survey paper, Hammarström (2011) summarizes work related to unsupervised morphology. Most recent work in morphology learning is semi-supervised. Such methods use a small set of example paradigms as input to train the system and classify unseen words into paradigms or learn new paradigms (Lindén, 2009; Dreyer, 2011). A popular pure unsupervised morphology technique was first proposed by Goldsmith (2001) which does not assume any linguistic input. Goldsmith (2001) introduced a set of heuristics that develops a probabilistic morphological grammar, and used Minimum Description Length (MDL) as a tool to evaluate it. The technique used for affix and paradigm identification was based on affix occurrence frequency. Several different authors have appreciated MDL as the motivation for segmentation. Some authors (Gelbukh et. al., 2004; Bacchin, 2005) have used random segmentation and picked the best segmentation t</context>
</contexts>
<marker>Dreyer, 2011</marker>
<rawString>Dreyer, M. 2011. A non-parametric model for the discovery of inflectional paradigms from plain text using graphical models over strings. Ph.D thesis, The Johns Hopkins University, Baltimore, Maryland</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Freitag</author>
</authors>
<title>Morphology induction from term clusters.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>128--135</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="2177" citStr="Freitag, 2005" startWordPosition="309" endWordPosition="310">recall. 1 Introduction Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state approach as some of the well known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state machines. Finite state approaches require linguistic input in the form of paradigm identification. Unsupervised and semi-supervised m</context>
</contexts>
<marker>Freitag, 2005</marker>
<rawString>Freitag, D. 2005. Morphology induction from term clusters. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 128–135, Ann Arbor, Michigan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gaussier Eric</author>
</authors>
<title>Unsupervised learning of derivational morphology from inflectional lexicons.</title>
<date>1999</date>
<booktitle>In ACL’99 Workshop Proceedings: Unsupervised Learning in Natural Language Processing : 24–30 ACL</booktitle>
<marker>Eric, 1999</marker>
<rawString>Gaussier Eric. 1999. Unsupervised learning of derivational morphology from inflectional lexicons. In ACL’99 Workshop Proceedings: Unsupervised Learning in Natural Language Processing : 24–30 ACL</rawString>
</citation>
<citation valid="false">
<authors>
<author>A F Gelbukh</author>
<author>M Alexandrov</author>
<author>S-Y Han</author>
</authors>
<title>Detecting inflection patterns in natural language by minimization of morphological model.</title>
<date>2004</date>
<booktitle>Proceedings of Progress in Pattern Recognition, Image Analysis and Applications, 9th Iberoamerican Congress on Pattern Recognition, CIARP ’04,</booktitle>
<volume>3287</volume>
<pages>432--438</pages>
<editor>In Sanfeliu, A., Trinidad, J. F. M., and Carrasco-Ochoa, J. A., editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<marker>Gelbukh, Alexandrov, Han, 2004</marker>
<rawString>Gelbukh, A. F., Alexandrov, M., and Han, S.-Y. (2004). Detecting inflection patterns in natural language by minimization of morphological model. In Sanfeliu, A., Trinidad, J. F. M., and Carrasco-Ochoa, J. A., editors, Proceedings of Progress in Pattern Recognition, Image Analysis and Applications, 9th Iberoamerican Congress on Pattern Recognition, CIARP ’04, volume 3287 of Lecture Notes in Computer Science, pages 432–438. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language.</title>
<date>2001</date>
<journal>Computational Linguistics</journal>
<volume>27</volume>
<issue>2</issue>
<pages>153--198</pages>
<contexts>
<context position="2194" citStr="Goldsmith, 2001" startWordPosition="311" endWordPosition="312">duction Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state approach as some of the well known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state machines. Finite state approaches require linguistic input in the form of paradigm identification. Unsupervised and semi-supervised methods can provid</context>
<context position="6346" citStr="Goldsmith (2001)" startWordPosition="911" endWordPosition="912">ix list identification, segmenting word into stem and affix, and generating a list of paradigms i.e. a list of all stems with information of the suffixes that each stem combines with (Hammarström, 2011). In his survey paper, Hammarström (2011) summarizes work related to unsupervised morphology. Most recent work in morphology learning is semi-supervised. Such methods use a small set of example paradigms as input to train the system and classify unseen words into paradigms or learn new paradigms (Lindén, 2009; Dreyer, 2011). A popular pure unsupervised morphology technique was first proposed by Goldsmith (2001) which does not assume any linguistic input. Goldsmith (2001) introduced a set of heuristics that develops a probabilistic morphological grammar, and used Minimum Description Length (MDL) as a tool to evaluate it. The technique used for affix and paradigm identification was based on affix occurrence frequency. Several different authors have appreciated MDL as the motivation for segmentation. Some authors (Gelbukh et. al., 2004; Bacchin, 2005) have used random segmentation and picked the best segmentation to minimize size or find splits where constituent morphemes occur in multiple splits. Our </context>
<context position="8177" citStr="Goldsmith, 2001" startWordPosition="1201" endWordPosition="1202">a derivation function where d(wx)=wy iff words wx and wy are derivationally related to each other in L. Let wxsy denote concatenation of strings wx and sy where wx, sy E ∑*. Let SN be set of neutral derivational suffixes. SN = {s|w2=w1s and w2,w1EW and d(w1)=w2 and sE ∑*} For example, when s=er, w1=farm and w2=farmer Let SB be set of non-neutral derivational suffixes. SB = {sx,sy|wsx=wsy and d(wsx)=wsy and w, sx, syE ∑* and w0W } For example, when sx=ify, sy=ity and w=quant suffixes ify, ity are non neutral suffixes. 29 4 Motivation Primarily, frequency based suffix identification techniques (Goldsmith, 2001; Hammarström, 2011) commonly used in recent times, fail to identify suffixes with low frequency. We explored suffix identification techniques which could identify suffixes irrespective of frequency of occurrence in the corpus. We chose one such method p-similar technique. However p-similar technique (Gaussier, 1999) cannot be used directly for segmentation as it results in a high number of false positives. Hence we proposed a suffix association matrix to avoid the false positives. According to p-similar technique, given two words x, y E W, if ∃ b1 such that x=b1s1 and y=b1s2 where b1, s1, s2 </context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith J A. 2001. Unsupervised learning of the morphology of a natural language. Computational Linguistics 27(2): 153–198</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hammarstrom Harald</author>
<author>Lars Borin</author>
</authors>
<title>Unsupervised learning of morphology.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<pages>2--309</pages>
<marker>Harald, Borin, 2011</marker>
<rawString>Hammarstrom Harald and Lars Borin. 2011. Unsupervised learning of morphology. Computational Linguistics, (2):309–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Two-level morphology: a general computational model for word-form recognition and production.</title>
<date>1983</date>
<institution>Helsinki, Department of General Linguistics, University of Helsinki.</institution>
<contexts>
<context position="2575" citStr="Koskenniemi, 1983" startWordPosition="357" endWordPosition="358">, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state machines. Finite state approaches require linguistic input in the form of paradigm identification. Unsupervised and semi-supervised methods can provide input to build finite state based morphology systems reducing the time taken to build such systems. In this paper we report the framework for an Unsupervised Morphology Learner. Most unsupervised segmentation techniques (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011) which learn morphology from a corpus assume that suffixes are frequent in a corpus. We observed that for mo</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, K. 1983. Two-level morphology: a general computational model for word-form recognition and production. Helsinki, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Koskenniemi</author>
</authors>
<title>Finite-state morphology and information retrieval.</title>
<date>1996</date>
<booktitle>Proceedings of the ECAI-96 Workshop on Extended Finite State Models of Language ECAI,</booktitle>
<pages>42--56</pages>
<location>Budapest, Hungary :</location>
<marker>Koskenniemi, 1996</marker>
<rawString>Koskenniemi, K. 1996. Finite-state morphology and information retrieval. Proceedings of the ECAI-96 Workshop on Extended Finite State Models of Language ECAI, Budapest, Hungary : 42-56</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lindén</author>
</authors>
<title>A probabilistic model for guessing base forms of new words by analogy.</title>
<date>2008</date>
<booktitle>In Proceedings of CICLing-2008: 9th International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<volume>4919</volume>
<pages>106--116</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2427" citStr="Lindén, 2008" startWordPosition="340" endWordPosition="341">l known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Koskenniemi, 1983; Beesley &amp; Kartunnen, 2003) represent morphology using finite state machines. Finite state approaches require linguistic input in the form of paradigm identification. Unsupervised and semi-supervised methods can provide input to build finite state based morphology systems reducing the time taken to build such systems. In this paper we report the framework for an Unsupervised Morphology Learner. Most unsupervised segmentation techniques (Freitag, 2</context>
</contexts>
<marker>Lindén, 2008</marker>
<rawString>Lindén, K. 2008. A probabilistic model for guessing base forms of new words by analogy. In Proceedings of CICLing-2008: 9th International Conference on Intelligent Text Processing and Computational Linguistics, volume 4919 of Lecture Notes in Computer Science, pages 106–116. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Lindén</author>
<author>J Tuovila</author>
</authors>
<title>Corpus-based Paradigm Selection for Morphological Entries.</title>
<date>2009</date>
<booktitle>In Proceedings of NODALIDA 2009,</booktitle>
<location>Odense, Denmark,</location>
<marker>Lindén, Tuovila, 2009</marker>
<rawString>Lindén, K. and Tuovila, J. 2009 Corpus-based Paradigm Selection for Morphological Entries. In Proceedings of NODALIDA 2009, Odense, Denmark, May 2009</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Loftsson</author>
</authors>
<title>Tagging Icelandic text: A linguistic rule-based approach.</title>
<date>2008</date>
<journal>Nordic Journal of Linguistics</journal>
<volume>31</volume>
<issue>1</issue>
<pages>47--72</pages>
<contexts>
<context position="1964" citStr="Loftsson, 2008" startWordPosition="278" endWordPosition="279"> framework to learn derivational morphology for English and two Indian languages, namely Hindi and Konkani. Compared to other similar techniques used for segmentation, there was an improvement in the precision and recall. 1 Introduction Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state approach as some of the well known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state approaches (Kosken</context>
</contexts>
<marker>Loftsson, 2008</marker>
<rawString>Loftsson, H. 2008. Tagging Icelandic text: A linguistic rule-based approach. Nordic Journal of Linguistics 31(1). 47–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J B Lovins</author>
</authors>
<title>Development of a stemming algorithm.</title>
<date>1968</date>
<journal>Mechanical Translation and Computer Linguistic.,</journal>
<volume>11</volume>
<pages>22--31</pages>
<contexts>
<context position="1921" citStr="Lovins, 1968" startWordPosition="272" endWordPosition="273">short stem words correctly. We tested our framework to learn derivational morphology for English and two Indian languages, namely Hindi and Konkani. Compared to other similar techniques used for segmentation, there was an improvement in the precision and recall. 1 Introduction Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state approach as some of the well known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised </context>
</contexts>
<marker>Lovins, 1968</marker>
<rawString>Lovins J. B. 1968. Development of a stemming algorithm. Mechanical Translation and Computer Linguistic., vol.11, no.1/2: 22-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zin Maung Maung</author>
<author>Yoshiki Mikami</author>
</authors>
<title>A rule-based syllable segmentation of myanmar text.</title>
<date>2008</date>
<booktitle>In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, 51–58. Hyderabad, India: Asian Federation of Natural Language Processing.</booktitle>
<marker>Maung, Mikami, 2008</marker>
<rawString>Maung, Zin Maung &amp; Yoshiki Mikami. 2008. A rule-based syllable segmentation of myanmar text. In Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages, 51–58. Hyderabad, India: Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
</authors>
<title>Another stemmer.</title>
<date>1990</date>
<journal>SIGIR Forum,</journal>
<volume>24</volume>
<pages>56--61</pages>
<contexts>
<context position="1948" citStr="Paice, 1990" startWordPosition="276" endWordPosition="277">We tested our framework to learn derivational morphology for English and two Indian languages, namely Hindi and Konkani. Compared to other similar techniques used for segmentation, there was an improvement in the precision and recall. 1 Introduction Learning morphology by a machine is crucial for tasks like stemming, machine translation etc. Rule based affix stripping approach, semi-supervised, unsupervised learning of morphology and finite state approach as some of the well known methods used to learn morphology by a machine. Rule based affix stripping approaches (Lovins, 1968; Porter, 1980; Paice, 1990; Loftsson, 2008; Maung et. al, 2008) depend heavily on linguistic input and require a lot of human effort, especially for morphologically rich languages. Pure unsupervised approaches learn morphology from a corpus (Freitag, 2005; Goldsmith, 2001; Hammarström, 2011). The accuracy of pure unsupervised methods is relatively low. Semi-supervised approaches use minimal linguistic input and unsupervised methods to automate morphology learning process (Forsberg, 2007; Lindén, 2008; Chan, 2008; Dreyer, 2011). Semi-supervised approaches perform better than pure unsupervised approaches. Finite state ap</context>
</contexts>
<marker>Paice, 1990</marker>
<rawString>Paice, C.D. 1990. Another stemmer. SIGIR Forum, 24: 56-61 Porter, M. F. 1980. An algorithm for suffix stripping. Program 14 : 130-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Sharma</author>
</authors>
<title>Unsupervised Learning of Morphology of a Highly Inflectional Language,</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Tezpur University,</institution>
<location>Assam, India</location>
<contexts>
<context position="4233" citStr="Sharma, 2006" startWordPosition="588" endWordPosition="589">x frequency assumptions is p-similar This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http://creativecommons.org/licenses/by/4.0/ 28 Proceedings of the 5th Workshop on South and Southeast Asian NLP, 25th International Conference on Computational Linguistics, pages 28–36, Dublin, Ireland, August 23-29 2014. technique for morpheme segmentation first proposed by Gaussier (1999). Researchers have used this method for suffix identification and not for segmentation (Gaussier, 1999; Sharma, 2006). We extended this less studied technique to segment words by introducing the concept of suffix association matrix, thus giving us an unsupervised method which correctly identifies suffixes irrespective of their frequency of occurrence in the corpus and also segments short stem words. To the best of our knowledge, most reported work which uses p-similar technique for suffix identification (Gaussier, 1999; Sharma, 2006) enforce a restriction on stem-length that it should be at least five. This restriction works well for suffix identification but not for segmentation. For Indian languages like H</context>
<context position="7180" citStr="Sharma, 2006" startWordPosition="1031" endWordPosition="1032">hnique used for affix and paradigm identification was based on affix occurrence frequency. Several different authors have appreciated MDL as the motivation for segmentation. Some authors (Gelbukh et. al., 2004; Bacchin, 2005) have used random segmentation and picked the best segmentation to minimize size or find splits where constituent morphemes occur in multiple splits. Our work is inspired by a less studied p-similar technique proposed by Gaussier (1999). p-similar techniques have been used for suffix identification rather than segmentation in most related unsupervised morphology learners (Sharma, 2006). Here the restriction on stem-length first proposed by Gaussier is upheld. Sharma’s (2006) work deals with neutral suffix only and does not capture nonneutral suffixes. These studies are limited to suffix identification and do not generate paradigms. 3 Terminology Used Let L be a language with alphabet set ∑. W= {w |w c ∑*} be set of valid words in language L. Let d: W→W denote a derivation function where d(wx)=wy iff words wx and wy are derivationally related to each other in L. Let wxsy denote concatenation of strings wx and sy where wx, sy E ∑*. Let SN be set of neutral derivational suffix</context>
</contexts>
<marker>Sharma, 2006</marker>
<rawString>Sharma U, (2006). Unsupervised Learning of Morphology of a Highly Inflectional Language, Ph.D. thesis, Tezpur University, Assam, India</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>