<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001698">
<title confidence="0.986902">
Reducing False Positives in the Construction of Adjective Scales
</title>
<author confidence="0.996475">
Alice Zhang
</author>
<affiliation confidence="0.9691395">
Princeton University
Princeton, New Jersey, USA.
</affiliation>
<email confidence="0.998457">
alicez@princeton.edu
</email>
<sectionHeader confidence="0.993893" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99954452631579">
Many adjectives that appear to be syn-
onyms of one another differ in their inten-
sity. Distinguishing the nuances between
adjective synonyms is vital to linguistic
understanding of a language, but WordNet
currently does not encode the relative in-
tensities of adjective synonyms that lie on
the scale. Sheinman &amp; Tokunaga (2009)
proposed a solution of constructing Adjec-
tive Scales by data mining a web corpus.
However, this process suffers from some
limitations, most notably that of False Pos-
itives, which inaccurately suggest that ad-
jective X is more or less intense than Y.
This paper classifies the types of false pos-
itives that Sheinman’s method generates,
then proposes a method to diminish the
quantity of these false positives using lin-
guistic searches in WordNet.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999954075471698">
Adjectives are currently represented in WordNet
in a dumbbell structure, such that antonymous ad-
jective pairs like ”wet-dry” and ”early-late” are
connected with a single antonym link. Each word
of the antonym pair is represented as one of two
centroids on the dumbbells, and each of their syn-
onyms are spread out radially around the cen-
troid. This representation is problematic because
1) it suggests that all adjectives within a synset
are equally similar to the centroid and 2) because
many similar adjectives are misclassified as mem-
bers of the same clusters, indicating that they de-
scribe the same types of objects, when in reality
they are very different.
In their paper Large, huge or gigantic?: Identi-
fying and encoding intensity relations in WordNet,
Sheinman et al. (2013) proposed a method to un-
cover the differing intensity relationships amongst
a set of adjective synonyms by mining a web cor-
pus. In particular, Sheinman noticed particular
patterns that occurred naturally in English speech
that already codified the intensity relationships be-
tween the adjectives that were used within the pat-
tern. For example, one of these semantic patterns
is ”X but not Y,” where Y is implied to be more in-
tense than X, e.g. ”good but not great” implies that
”great” is more intense than its synonym ”good”
based merely on the pattern ”X but not Y” In fact,
these patterns occur in both directions, such that
while some patterns imply that X is more intense
than Y, while others imply that X is less intense
than Y. By discovering pairs of adjectives that oc-
curred in the natural patterns, Sheinman was able
to construct scales of adjective synonyms, where
each adjective was listed according to its relative
intensity.
While Sheinman’s method seems, in large part,
successful in constructing adjective scales, it also
suffers from limitations of false positives, which
appear when certain adjective pairs show up in
the linguistic patterns, but do not actually indi-
cate that adjective Y is more or less intense than
X. For instance, the natural phrase ”good but not
good enough” would seem to suggest that ”good”
is more intense than ”good” based merely on the
battern ”X but not Y,” even though this is not
true. These false positives are significant: a simple
Google News search of the phrase ”hot but not”
will return false positives for over half of the re-
sults. This paper classifies the different types of
false positives that can be generated and proposes
an algorithm that utilizes WordNet to be able to
detect these false positives.
</bodyText>
<sectionHeader confidence="0.940942" genericHeader="method">
2 Type A False Positives
</sectionHeader>
<subsectionHeader confidence="0.801258">
2.1 Classification
</subsectionHeader>
<bodyText confidence="0.577496">
Type A false positives are phrases where adjective
Y is classified as being more intense than adjective
</bodyText>
<table confidence="0.997137111111111">
Intense Patterns
(is / are) X but not Y
(is / are) very X Y
extremely X Y
not X (hardy / barely / let alone) Y
X (but / yet / though) never Y
X (but / yet / though) hardly Y
X (even / perhaps) Y
X (perhaps / and) even Y
X (almost / no / if not / sometimes) Y
Mild Patterns
if not X at least Y
but Y but X enough
not Y (just / merely / only) X
not Y not even X
not Y but still very X
though not Y (at least X)
Y (very / unbelievably) X
</table>
<tableCaption confidence="0.975043">
Table 1 Examples of the linguistic patterns that
Sheinman et al. noticed in natural language. X and
Y represent adjectives such that X is more intense
than Y.
</tableCaption>
<bodyText confidence="0.999697972222222">
X, even though both X and Y fall on the same ad-
jective scale, but Y is not more intense than X. In
particular, Type A False Positives can be further
classified into three particular types: repetitions,
antonyms, and reversals.
Repetitions occur when both adjectives X and
Y are the same word. For example, one naturally
occurring English phrase that follows the ”X but
not Y” pattern that Sheinman noted is the phrase
”It was good, but not good enough.” Another ex-
ample would be the phrase ”It was good, but not
as good as it could have been.” In both instances,
the two adjectives that are being compared cannot
have one be more intense than the other because
they are the same.
Antonyms occur when X and Y are direct
antonyms of one another - both X and Y fall on
the same scale, but they cannot be synonyms of
one another because they lie on opposite ends of
the same scale. For example, consider the fol-
lowing sentence: ”He is not tall, but not short ei-
ther.” Sheinman’s method would falsely classify
”short” as a more intense synonym to the word
”tall,” which is a misclassification.
Finally, reversals occur where X and Y are real
adjective synonyms of one another, but X is a more
intense adjective than Y. For example, the sen-
tences ”This artifact is ancient, perhaps even old
enough to have existed before dinosaurs,” ”The
water was scorching, but not hot enough to kill
the bacteria,” and ”President Taft was extremely
obese, fat to the point of getting stuck in his own
bathtub” are all instances that would seem, based
on Sheinman’s method, to suggest that Y is more
intense than X, when in reality, X is more intense
than Y.
</bodyText>
<subsectionHeader confidence="0.999875">
2.2 Correcting Type A False Positives
</subsectionHeader>
<bodyText confidence="0.999966105263158">
To identify Type A false positives, one only needs
an algorithm that can detect instances of repeti-
tions, antonyms, and reversals.
Checking for repetitions is a trivial task: one
simply needs to determine if X and Y are the same
word.
To detect antonyms, one can take advantage of
the pointers that are built into WordNet to check
if any of the direct or indirect antonyms of X is
equal to Y, or alternatively, that any of the direct
or indirect antonyms of Y is equal to X.
Finally, we can fix reversals by taking advan-
tage of a web database. Let the phrase p1 be the
original phrase, and let p2 be the original phrase
with X and Y swapped. After conducting queries
on a search engine for both p1 and p2, we can de-
termine that the query for which more results ap-
pear is the correct intensity ordering of the two ad-
jectives.
</bodyText>
<sectionHeader confidence="0.982139" genericHeader="method">
3 Type B False Positives
</sectionHeader>
<subsectionHeader confidence="0.993153">
3.1 Classification
</subsectionHeader>
<bodyText confidence="0.999966133333333">
The second type of false positives is Type B false
positives, which are phrases wherein Y is inaccu-
rately classified as being a more intense synonym
of X because X and Y are adjectives that do not
fall on the same scale.
For example, consider the sentence ”Stevie
Wonder is very good, but not lyrical.” Using
Sheinman’s method of pattern extraction, one
would falsely infer that ”lyrical” is a more intense
synonym to ”good,” which cannot be true, as ”lyri-
cal” is not even a synonym for ”good”, much less
a more intense form of it.
Furthermore, Type B false positives occur fre-
quently in human speech, as it is very common to
switch scales when using a particular pattern.
</bodyText>
<subsectionHeader confidence="0.99997">
3.2 Correction with Level 1 Searches
</subsectionHeader>
<bodyText confidence="0.96830940625">
The most straightforward way of fixing Type B
false positives is to performa simple search, test-
ing to see if X falls under the synset - a word’s set
of synonyms - of Y, or if Y falls under the synset of
x. This term can be classified as a Level 1 search.
Level 1 searches are searches conducted in
WordNet, wherein only the two synsets of words
X and Y will be explored. They differ from Level
2 searches, which increase the depth of the search.
In general, a Level N search searches through a set
of words w, then a Level N+1 search will search
through all synsets for each word contained in w.
Thus a Level 2 search will search through all the
synsets of words contained in synsets of words X
and Y.
The Level 1 searches are successfully able to
eliminate a large number of Type B false positives.
For instance, TYPEB-LEVEL1 can correctly iden-
tify ”good but not lyrical” and ”tasty but not ex-
pensive” as false positives.
These types of false positives are interesting be-
cause they reveal innate patterns of cultural think-
ing. People sometimes associate a given quality
or attribute with another, such as price and qual-
ity. A phrase such as ”wealthy but not arrogant”
might seem to suggest that human thinking asso-
ciates the wealthy as having arrogant qualities, or
a phrase such as ”fat but not jolly” might seem to
suggest that a culture views associates fat people
with being jolly. Future work might be to further
investigate Type B false positives to extract cul-
tural associations from the linguistic patterns.
The problem is that Level 1 searches overgen-
erate the number of false positives. The following
table lists a collection of instances where the Level
1 searches classify the phrases as a false positive,
even though intuition as an English speaker tells
us otherwise.
X Y LEVEL1(X, Y)
good wonderful true
good awesome true
good amazing true
wonderful awesome true
elephantine monstrous true
gnomish pocket-size true
Table 2 Misclassified examples from a Level 1
search.
As evidenced, these examples suggest that
Level-1 searches overgenerate the actual number
of false positives. Further investigation allows us
to see why: if we take all of the words included
in the synset of good and all the words included
in the synset of wonderful, we can observe that
neither word appears in the other’s synset.
However, we can observe that triangulation
appears in the synsets: great appears as one
of the words contained in the synset of good,
and the words great and wonderful both have
the word extraordinary contained in both their
synsets. Something that is good must also be
great, which is also extraordinary. Since some-
thing wonderful is also extraordinary, it fol-
lows that good and wonderful are, indeed, true
synonyms of one another.
</bodyText>
<subsectionHeader confidence="0.999693">
3.3 Correction with Level 2 Searches
</subsectionHeader>
<bodyText confidence="0.999092407407407">
We have observed that two synonymous words
that differ in intensity may not be included in
each other’s synsets, but may nonetheless share
a common word between the two synsets. The
word wonderful does not appear in the synset of
good and good does not appear in the synset of
wonderful, but both good and wonderful share
great in their synsets. This leads us to believe that
many of the falsely identified false positives could
be eliminated by performing a Level 2 search in-
stead of a Level 1 search.
A Level 2 search performs its searches one level
deeper. A Level 2 search chooses one of the pair
(X, Y ) as its base, and then calculates the synset
of the other word. For each word in the synset,
the Level 2 search performs a Level 1 search
against the base word that it chose earlier. Then,
it switches the base word and performs the same
set of Level 1 searches on the opposite synset. For
each Level 1 search, if the the algorithm has found
a word common to both X and Y ’s synsets, the
checker identifies the pair as a false positive. Oth-
erwise, if every synset pair has been searched and
no word has been found common to both synsets,
the algorithm identifies the pair as a false positive.
The pseudocode for a Level 2 search is given in
Algorithm 1.
</bodyText>
<sectionHeader confidence="0.907139" genericHeader="method">
3.4 Results
</sectionHeader>
<bodyText confidence="0.992748520833334">
Performing Level-2 searches on Type B false pos-
itives eliminates overgeneration of false positives,
but also yields the problem of undergeneration be-
cause of word sense disambiguation. Each of the
Algorithm 1 This function returns true if phrase
X and Y are identified as being a Type B false
positive, and returns false otherwise.
procedure TYPEB-LEVEL2(X, Y )
synsetx ← GETADJECTIVESYNSET(X)
for all i in synsetx do &gt; Search for Y in
the synsets of X
if TYPEA(i, Y ) is false and TYPEB-
LEVEL1(i, Y ) is false then
return false
synsety ← GETADJECTIVESYNSET(Y)
for all i in synsety do &gt; Search for X in
the synsets of Y
if TYPEA(i, X) is false and TYPEB-
LEVEL1(i, X) is false then
return false
return true
synsets contain so many different senses that a
Level-2 search could easily identify two words as
synonyms based off of a faulty ”common word.”
Sample adjective queries are shown in the table
below, along with the adjective pair that was found
to be a successful Level-1 pair and the word that
the two adjectives held in common.
(X, Y) Adj. Pair Common Adj.
tall, thin tall, thin gangling
fat, smart fat, intense thick
short, rich rich, dumpy fat
happy, tasty tasty, prosperous rich
fat, red red, rich colorful
tall, awful tall, tremendous large
up, wide up, broad high
big, pretty big, pretty bad
strong, fat strong, fat fertile
good, big good, large ample
fat, atomic fat, little dumpy
sad, fat sad, heavy distressing
Table 3 Misclassified examples from a Level 2
search.
Our goal now is to reconcile the undergenera-
tion of Level 1 searches with the overgeneration of
the Level 2 searches. We do not consider searches
deeper than a Level 2 search, because a Level 2
search already overgenerates.
</bodyText>
<sectionHeader confidence="0.992129" genericHeader="method">
4 Attributes
</sectionHeader>
<bodyText confidence="0.999623916666667">
WordNet pointers contain information about a
word’s attribute, which stores the word’s category,
e.g. ”size” for the adjectives ”big” and ”small.”
Adding checks that discard words of different
attributes successfuly eliminates all the searches
stored in Table 3.
The pseudocode for the altered algorithm,
which includes attribute checks, is included as Al-
gorithm 3. Running this altered algorithm corrects
all of the results found in Table 3.
Algorithm 2 Returns true if X and Y are Type B
false positives, and false otherwise.
</bodyText>
<equation confidence="0.7149555">
procedure TYPEB-LEVEL2-ATTR(X, Y )
Ax ← GETATTRIBUTE(X)
Ay ← GETATTRIBUTE(Y)
if Ax is not null and Ay is not null and Ax
</equation>
<bodyText confidence="0.550177238095238">
is not equal to Ay then
return true
synsetx ← GETADJECTIVESYNSET(X)
for all i in synsetx do
AZ ← GETATTRIBUTE(i)
if Ay is not null and AZ is not null and
Ay is not AZ then
continue
if TYPEA(i, Y ) is false and TYPEB-
LEVEL1(i, Y ) is false then
return false
synsety ← GETADJECTIVESYNSET(Y)
for all i in synsety do
AZ ← GETATTRIBUTE(i)
if Ax is not null and AZ is not null and
Ax is not AZ then
continue
if TYPEA(i, X) is false and TYPEB-
LEVEL1(i, X) is false then
return false
return true
</bodyText>
<subsectionHeader confidence="0.995478">
4.1 Limitations
</subsectionHeader>
<bodyText confidence="0.999971666666667">
The most notable limitation is that the set of adjec-
tives that have attributes is extremely small, and
are thus susceptible to all of the pitfalls of the
Level-2 searches described in Algorithm 3. In fact,
most of the adjectives contained in WordNet do
not have attribute pointers. Our algorithm could be
substantially improved by encoding the attribute
pointer more consistently in WordNet.
There are also a few exceptional cases, where
two adjectives are actually synonyms, but Word-
Net gives the two words different pointers. For ex-
ample, the word ”good” has an attribute of ”qual-
ity” whereas the word ”extraordinary” has an at-
tribute of ”ordinariness.” Speakers of the English
language can recognize that ”good” and ”extraor-
dinary” are synonyms, but the algorithm would
immediately reject them because they have differ-
ent attributes.
</bodyText>
<sectionHeader confidence="0.764173" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.9999926875">
To test the algorithm, we ran four adjective pairs
on it, selecting the phrases by the following crite-
ria: 1) Returning a high enough number of hits on
Google News so that the results can be considered
significant, 2) Returning a low enough number of
hits on Google News so that it is not overstrenuous
to hand-classify each of the results, and 3) Adjec-
tives that could be represented on a scale.
The searches were run by typing the pattern into
a Google News search query in quotes (e.g. ”hot
but not”). Then, each search was classified by run-
ning it into the False Positive Checker described
in Algorithm 1, and the accuracy of the classifica-
tions were checked by hand.
Overall, the False Positive Checker returns ro-
bust results for most adjectives. The vast majority
of the errors occured because their attribute point-
ers returned null, leaving them susceptible to the
Type 2 errors.
Altogether, for the two example searches listed
above, the algorithm had 18 misclassifications
out of 823 search results, for a total accuracy of
97.81%. All 823 instances described in Table 4
are instances of positives generated by Sheinman’s
method, but classifying these as true positives or
false positives is left up to our algorithm. The
high degree of accuracy from from the searches
suggests that this algorithm is successfully able
to classify Sheinman’s phrases a true positives or
false positives. If one could encode adjective at-
tributes more consistently in WordNet, most of
these errors would be able to be eliminated.
</bodyText>
<subsectionHeader confidence="0.999811">
4.3 Limitations of WordNet
</subsectionHeader>
<bodyText confidence="0.999785">
All of our searches rely on the ability of WordNet
to classify adjectives correctly. However, many of
our searches using the False Positive Checker in-
dicate that there are gaps in WordNet’s structure.
More specifically, limitations on attribute pointers
make it difficult to completely eliminate the ap-
pearance of false positives in Sheinman’s method.
</bodyText>
<table confidence="0.549442833333333">
phrase misclassified/total percentage
hot but not 9/148 93.92%
big but not 5/423 98.82%
old but not 2/136 98.53%
happy but not 2/116 98.28%
Total 18/823 97.81%
</table>
<tableCaption confidence="0.5412805">
Table 4 Accuracy of phrases searched on Google
News.
</tableCaption>
<bodyText confidence="0.99959535">
Furthermore, synset membership is not always
consistent with human intuition. For instance,
both the words ”subatomic” and ”gnomish” might
be included in the synset for ”small,” but ”sub-
atomic” is used to describe particles, whereas
”gnomish” is used to describe people. These flaws
suggest that WordNet needs to be more consistent
in its attribute pointers for adjectives, as well as
in how it links its adjectives together in synsets.
In order to consistently be able to detect the false
positive errors using Sheinman’s method, it is vital
for WordNet to be improve the quality of synsets,
as well as to vastly expand the coverage of its at-
tribute pointers.
Finally, the dumbbell structure of WordNet as
it is renders it difficult to encode adjective scales
within each synset. For future use, it would be
important to rework the organization of WordNet
such that adjective scales could be extracted more
easily.
</bodyText>
<sectionHeader confidence="0.999272" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99993072">
Type A false positives suggest that adjectives X
and Y are on the same scale, but that Y is not more
intense than X. There are three types of Type A
false positives: repetitions, antonyms, and rever-
sals, and all of these can be corrected relatively
easily. Type B false positives occur when X and Y
are not synonyms of one another and also do not
fall on th same scale. Performing a Level 1 search
on WordNet undergenerates false positives, but a
Level 2 search overgenerates them. To solve this
issue, we must use the attribute pointers, which
can accurately classify the category of many of the
adjectives contained in WordNet.
After conducting tests, the False Positive
Checker accurately classified 97.81% of all
phrases conducted through a test. These results
could be further improved by improving the struc-
ture of WordNet by improving both the precision
and the coverage of its attribute pointer.
All in all, the ability to distinguish the differ-
ing intensities of adjective synonyms is vital to be-
ing able to master the nuances of the English lan-
gauge. By improving the accuracy of Sheinman’s
method, we can continue to improve our ability to
encode these unstated nuances into a lexical tool.
</bodyText>
<sectionHeader confidence="0.999535" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999988">
I would like to thank my advisor, Professor Chris-
tiane Fellbaum, for her support and guidance in
helping me with this paper. She has provided
valuable assistance to the undertaking of the work
summarized here. I am also grateful to Prince-
ton University’s Student Activities Funding En-
gine (SAFE) for their generous sponsorship of my
travel to the Global WordNet Conference.
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999701764705882">
Fellbaum, Christiane. 1998. WordNet: an electronic
lexical database. MIT Press WordNet is avail-
able from http://www.cogsci.princeton.
edu/wn. 2010.
Vera Sheinman, Christiane Fellbaum, Isaac Julien, Pe-
ter Schulam, Takenobu Tokunaga. 2013. Large,
huge or gigantic? Identifying and encoding intensity
relations among adjectives in WordNet. Language
Resources and Evaluation, 47:1-20.
Vera Sheinman, Takenobu Tokunaga. 2009. Ad-
jscales: Differentiating between similar adjectives
for language learners. Proceedings of the Interna-
tional conference on computer supported education
(CSEDU-09), 229-235.
Mark Finlayson. 2013. Java Wordnet Interface (JWI)
2.2.4. MIT. http://projects.csail.mit.
edu/jwi/.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.344999">
<title confidence="0.996962">Reducing False Positives in the Construction of Adjective Scales</title>
<author confidence="0.82608">Alice</author>
<affiliation confidence="0.6186905">Princeton Princeton, New Jersey,</affiliation>
<email confidence="0.999874">alicez@princeton.edu</email>
<abstract confidence="0.99604365">Many adjectives that appear to be synonyms of one another differ in their intensity. Distinguishing the nuances between adjective synonyms is vital to linguistic understanding of a language, but WordNet currently does not encode the relative intensities of adjective synonyms that lie on the scale. Sheinman &amp; Tokunaga (2009) proposed a solution of constructing Adjective Scales by data mining a web corpus. However, this process suffers from some limitations, most notably that of False Positives, which inaccurately suggest that admore or less intense than This paper classifies the types of false positives that Sheinman’s method generates, then proposes a method to diminish the quantity of these false positives using linguistic searches in WordNet.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press</publisher>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, Christiane. 1998. WordNet: an electronic lexical database. MIT Press WordNet is available from http://www.cogsci.princeton. edu/wn. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Sheinman</author>
<author>Christiane Fellbaum</author>
<author>Isaac Julien</author>
<author>Peter Schulam</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Large, huge or gigantic? Identifying and encoding intensity relations among adjectives in WordNet. Language Resources and Evaluation,</title>
<date>2013</date>
<pages>47--1</pages>
<contexts>
<context position="1723" citStr="Sheinman et al. (2013)" startWordPosition="270" endWordPosition="273">h a single antonym link. Each word of the antonym pair is represented as one of two centroids on the dumbbells, and each of their synonyms are spread out radially around the centroid. This representation is problematic because 1) it suggests that all adjectives within a synset are equally similar to the centroid and 2) because many similar adjectives are misclassified as members of the same clusters, indicating that they describe the same types of objects, when in reality they are very different. In their paper Large, huge or gigantic?: Identifying and encoding intensity relations in WordNet, Sheinman et al. (2013) proposed a method to uncover the differing intensity relationships amongst a set of adjective synonyms by mining a web corpus. In particular, Sheinman noticed particular patterns that occurred naturally in English speech that already codified the intensity relationships between the adjectives that were used within the pattern. For example, one of these semantic patterns is ”X but not Y,” where Y is implied to be more intense than X, e.g. ”good but not great” implies that ”great” is more intense than its synonym ”good” based merely on the pattern ”X but not Y” In fact, these patterns occur in </context>
</contexts>
<marker>Sheinman, Fellbaum, Julien, Schulam, Tokunaga, 2013</marker>
<rawString>Vera Sheinman, Christiane Fellbaum, Isaac Julien, Peter Schulam, Takenobu Tokunaga. 2013. Large, huge or gigantic? Identifying and encoding intensity relations among adjectives in WordNet. Language Resources and Evaluation, 47:1-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Sheinman</author>
<author>Takenobu Tokunaga</author>
</authors>
<title>Adjscales: Differentiating between similar adjectives for language learners.</title>
<date>2009</date>
<booktitle>Proceedings of the International conference on computer supported education (CSEDU-09),</booktitle>
<pages>229--235</pages>
<marker>Sheinman, Tokunaga, 2009</marker>
<rawString>Vera Sheinman, Takenobu Tokunaga. 2009. Adjscales: Differentiating between similar adjectives for language learners. Proceedings of the International conference on computer supported education (CSEDU-09), 229-235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Finlayson</author>
</authors>
<title>Java Wordnet Interface (JWI)</title>
<date>2013</date>
<note>2.2.4. MIT. http://projects.csail.mit. edu/jwi/.</note>
<marker>Finlayson, 2013</marker>
<rawString>Mark Finlayson. 2013. Java Wordnet Interface (JWI) 2.2.4. MIT. http://projects.csail.mit. edu/jwi/.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>